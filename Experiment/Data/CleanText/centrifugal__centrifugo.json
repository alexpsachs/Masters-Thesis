{
    "FZambia": "Hello:)\nJust released all the things I've done, Centrifugo 0.1.0 is the first release, Note though, that at work we still use Centrifuge in production and will migrate to Centrifugo in several weeks - we are planning to see how it behaves - is it stable enough or not.\n. @thedeadofblackfire, to be fair I don't know which of servers better. I used a benchmark tool with up to 10k connections, but I did not try to connect more than 10k clients. And I don't see much sense in this - depending on application there will be different amount of clients, channels, messages per second - all of these need additional CPU and memory \u2013 so the way to decide when resource limit of one server reached - CPU and memory usage monitoring.\n. Ok, thanks, I am here and looking forward for your results. If you need any help \u2013 feel free to ask\n. We finally replaced Centrifuge with Centrifugo in production 2 days ago. As we did this - we found problem with Redis engine resulting it message lost. That problem with Redis engine already fixed in version 0.2.3\nYesterday everything worked fine with updated code. Will see how it behaves.\n. So I think Centrifugo is pretty stable at moment. In our project it works without any downtime since my last message. If you use Centrifugo please write me a message here or via email about your use case.\n. Closing this as Centrifugo > 1.0 already out\ud83c\udf7e\n. Thanks for such a great advice. Moved read-only things to RWMutex in application.go but missed hubs.go... I'll go through all methods you pointed and make changes.\n. Fixed in 3e4ecaa78f6f3e29f356c4ab429047014b0d209d and in d9638c25dc9899fb8341fe4381ef2b7924eb4e78\n. Thanks again!\nIn this case presence information can contain any decoded JSON object provided by web application on connect. What do you mean under more \"controlled\" type? keep that data as JSON string without decoding first and decode from string when actually requested?\n. Yes, this feels like a much more cleaner way. One question - will this result in double encoded JSON in the response output for default_info and channel_info or json.RawMessage must be unmarshalled manually later when building a final response?\n. Maybe it's a good idea to skip unmarshalling this custom JSON at all and just let client side to deal with JSON string in default_info and channel_info when it's needed?\n. > To a long time gopher it hurts to see\nGot it, will try to get rid of such map[string]interface{} usages in near perspective\n. Started refactoring in strong_types branch. Added ClientInfo struct:\ngo\n// ClientInfo contains information about client to use in message\n// meta information, presence information, join/leave events etc.\ntype ClientInfo struct {\n    User        string           `json:\"user\"`\n    Client      string           `json:\"client\"`\n    DefaultInfo *json.RawMessage `json:\"default_info\"`\n    ChannelInfo *json.RawMessage `json:\"channel_info\"`\n}\nAnd Message struct:\ngo\ntype Message struct {\n    Uid       string      `json:\"uid\"`\n    Timestamp string      `json:\"timestamp\"`\n    Info      *ClientInfo `json:\"info\"`\n    Channel   string      `json:\"channel\"`\n    Data      interface{} `json:\"data\"`\n}\nI think we need to use json.RawMessage for Data too (as Data travels unmodified through Centrifugo)?\n. Replaced\nData      interface{} `json:\"data\"`\nwith \nData     *json.RawMessage `json:\"data\"`\nin a0bd971927273c5f44dba117c2e2332f75daff51\nSo no interface{} types left\n. Merged all of these changes into master. There are still lots of places left though where map[string]interface{} used to create response bodies \u2013 created another issue #10 to refactor this\n. @klauspost could you check this? is the problem gone away?\n. @klauspost hope you will find a time to review changes made, I am closing this as I think race in memoryPresenceHub was fixed.\n. Thanks, do you mean a situation when channel options changed between those calls?\n. This is possible theoretically - I just asked to make sure I understood a problem correctly.\n. I refactored a bit.\nBut it seems that still can be race as getChannelOptions returns a pointer to ChannelOptions \ngo\n// getChannelOptions returns channel options for channel using structure\nfunc (app *application) getChannelOptions(projectKey, channel string) *ChannelOptions {\n    app.RLock()\n    defer app.RUnlock()\n    namespaceName := app.extractNamespaceName(channel)\n    return app.structure.getChannelOptions(projectKey, namespaceName)\n}\nMaybe this method should be rewritten as:\ngo\n// getChannelOptions returns channel options for channel using structure\nfunc (app *application) getChannelOptions(projectKey, channel string) ChannelOptions {\n    app.RLock()\n    defer app.RUnlock()\n    namespaceName := app.extractNamespaceName(channel)\n    return *app.structure.getChannelOptions(projectKey, namespaceName)\n}\nI  am a bit confused - will we get a copy of ChannelOptions in this case?\n. OK, thx, will make this change\n. Btw it can be nil in case when namespace not found...Maybe returning second return boolean value (found) will make sense\n. @klauspost , please, look at current code - is problem solved?\n. Thanks a lot for your advices - I am so grateful. This is valid point again - I did not know about json.RawMessage before and will try to refactor this.\n. Did this also in strong_types branch in this commit a0bd971927273c5f44dba117c2e2332f75daff51 - seems to work\n. Merged that branch, also refactored the last place left \u2013  in engineredis.go \u2013 in handling API request.\n. I think we can close this?\n. Thanks!\n. Added this implementation in a8bcf0218651e1e0c2b8c2f7bbd94417eba52469\n. Hmm, I temporarily returned an old implementation in this commit  8b8e064108ba9a302c8513641b9989c88bfcd238 . I found a place (https://github.com/centrifugal/centrifugo/blob/master/libcentrifugo/handlers.go#L394) where I do not encode response using toJson() method but using Encoder \u2013 and this breaks things. What do you think \u2013 should I always use toJson and use your implementation or go with custom marshalling?\n. Thanks a lot:)\n. This looks fantastic! Thanks so much for your help, I'll check and merge this in the evening after my work.\n. Merged!\n. Thanks! Btw what do you think is adding a check for providedToken length a good idea? As we use sha256 - so if incoming token length not equal to 64 - we can return false early from all check functions\n. Ok, thanks again for pointing at timing attack, I'll merge this later today and will also add check for token length.\n. Merged!\n. Done in 473dd719724acbb0ea15d0da03a42e1e635fbe03\n. Oh.. such a hard work! And yes, all my method names came from Python))\nIf you rebase \u2013 it will be fine! I like and agree with most of changes except several ones:\n- Lifetime - I prefer ConnectionLifetime (as this will be read as project lifetime which is semantically wrong because this is connection lifetime and I also like that it corresponds to name in json)\n- projByKey - I think projectByKey better\n- ses - think sess better\n-  I'd try to change c.Info in some way as info() returns ClientInfo full of different fields while c.Info is just default []byte client info\n- privateCh - I prefer privateChannel as I think Ch is frequently used for Go channels\n- and the last one - IMO namespaceName() is better than channelNs because Ns is not so common abbreviation\nI can do all changes myself after merge - absolutely no problem\nThanks a lot for all you do for Centrifugo - your help is priceless!\n. I think this must be called just a defaultInfo\n. Merged!\n. Thank you very much!\n. hmm..I personally don't think this is a good idea. It will make code harder to read for me. When I see string - I know what is it, but when I see pID \u2013 I had to think about what is it.\n. You are right that map[projectID]map[channelID] is much more readable. This is much more persuading example. But I still don't like names for types. When I see namespaceID I think about something incremental or unique sequence of symbols (like uuid). The same for channelID. In Centrifugo both (and Project Key too) are just human readable strings - like news, chat, public, gossips etc\nMaybe the way to go is naming those types in a more Centrifugo-specific manner:\ngo\ntype (\n    ProjectKey string\n    Channel string\n    UserID  string\n)\nNamespace...maybe leave it as string? It appears in a couple of places only. Or NamespaceKey, or NamespaceName...\nWhat do you think?\n. Ok let's rename all to \ngo\ntype (\n    ProjectKey string\n    NamespaceKey string\n    Channel string\n    UserID string\n)\nMaybe these names a bit longer but they will allow to make function arguments shorter so instead \ngo\nfunc (s *structure) channelOpts(projectKey, namespaceName string) *ChannelOptions {\n}\nwe can write\ngo\nfunc (s *structure) channelOpts(pk ProjectKey, nk NamespaceKey) *ChannelOptions {\n}\n. Could you also change ChannelID to just Channel? I don't like ID suffix when it's not an ID actually - channels can be the same in different projects.\n. Yep, thanks a lot!\n. mm.. just looked at code more carefully. Let's look at this method:\ngo\nfunc (app *application) projectChannel(pk ProjectKey, ch Channel) Channel {\n    return Channel(app.config.channelPrefix + \".\" + string(pk) + \".\" + string(ch))\n}\nUntil this moment Channel is what we mean as channel in Centrifugo - but the result of this method can't be Channel too. So the result must be ChannelID\ngo\nfunc (app *application) projectChannel(pk ProjectKey, ch Channel) ChannelID {\n    return ChannelID(app.config.channelPrefix + \".\" + string(pk) + \".\" + string(ch))\n}\nI think in this case we will get a nice separation between what is Channel and what is ChannelID\n. and this must be something like:\ngo\nfunc (app *application) channelID(pk ProjectKey, ch Channel) ChannelID {\n    return ChannelID(app.config.channelPrefix + \".\" + string(pk) + \".\" + string(ch))\n}\nas I learned from all your changes)))\n. I'll make it!\n. ooops:) just pushed my own changes:)\n. Now master in proper state)))\n. Hello! Thanks for a report. This is very strange as I deployed demo instance several times via this button. It seems that something wrong with Heroku itself as it requires app-LONG-STRANGE-PROJECT-UID.json in project repo at moment.\n. Also their official button tutorial repo also throws an error (https://github.com/heroku/node-js-sample). So I think this problem must go away soon.\n. Thank you, let's keep this open until resolving\n. @jancel it works now!\n. No, just patience:D\n. Just transferred admin changes myself)))\n. Have a nice weekend! \n. Hello!\nHmm.. I never created official Docker image for Centrifuge. Just Dockerfile to make one.\nAnyway having image on dockerhub is nice.\n. @clintonbosch I remember about this - just could not find time.\nAt moment I am planning to make something like this:\n```\nFROM centos:6\nRUN \\\n  curl https://github.com/centrifugal/centrifugo/releases/download/v0.2.0/centrifugo-0.2.0-1434542239.x86_64.rpm -L -o /tmp/centrifugo.x86_64.rpm && \\\n  rpm -Uvh /tmp/centrifugo.x86_64.rpm && \\\n  rm -r /tmp/centrifugo.x86_64.rpm\nVOLUME [\"/etc/centrifugo\",  \"/var/log/centrifugo\"]\nCMD [\"centrifugo\"]\nEXPOSE 8000\n```\nTo run:\ndocker run -d -v `pwd`:/etc/centrifugo -p 8000:8000 centrifugo_test_image centrifugo -c /etc/centrifugo/config.json -w /opt/centrifugo/web\nI have not used Docker a lot - what do you think about Dockerfile above? \nUpdate. Fixed issue with missing wget\n. Hello @palazzem !\nThanks for a help - as we don't use Docker at work yet I have a little experience with it - just played a little to get a basic understanding.\nI already registered this repo on Docker Hub so the last thing missing is proper Dockerfile.\nI have several questions:\n- do you see something wrong with Dockerfile in comments above?\n- is it necessary to create centrifugo group and user as rpm already creates them (spec)?\n- Could you show a command to run your Centrifugo container? I am interested in config file and logs.\n- I thought Docker Hub automatically works with repo tags (I create tag and docker pull fzambia/centrifugo:v0.2.1 will automatically work) \u2013 am I wrong and I need to turn it on somewhere (if yes point me in right direction please)?\n. In this case your custom config located in /home/foo/bar/config.json?\n. Thanks for a great explanation!\nMaybe using rpm for building image is not a good idea at all?\nI see several disadvantages in building from rpm:\n- no need in registering in service i.e. service centrifugo start/stop/restart/reload not needed\n- no need in built in logrotate which I configure in rpm spec\n- building from just a release zip archive is much more explicit - things are not hidden in rpm spec\nSo something like this in Dockerfile can do the work:\n```\nFROM centos:7\nENV VERSION 0.2.1\nENV DOWNLOAD https://github.com/centrifugal/centrifugo/releases/download/v$VERSION/centrifugo-$VERSION-linux-amd64.zip\nRUN curl -sSL \"$DOWNLOAD\" -o /tmp/centrifugo.zip && \\\n    yum install -y unzip && \\\n    unzip -jo /tmp/centrifugo.zip -d /tmp/ && \\\n    mv /tmp/centrifugo /usr/bin/centrifugo && \\\n    rm -f /tmp/centrifugo.zip && \\\n    echo \"centrifugo - nofile 65536\" >> /etc/security/limits.d/centrifugo.nofiles.conf\nRUN groupadd -r centrifugo && useradd -r -g centrifugo centrifugo\nRUN mkdir /centrifugo && chown centrifugo:centrifugo /centrifugo && \\\n    mkdir /var/log/centrifugo && chown centrifugo:centrifugo /var/log/centrifugo\nVOLUME [\"/centrifugo\", \"/var/log/centrifugo\"]\nWORKDIR /centrifugo\nCMD [\"centrifugo\"]\nUSER centrifugo\nEXPOSE 8000\n```\nThe only thing missing here is web interface but I think it's possible to put it into Docker image from https://github.com/centrifugal/centrifugo/tree/master/extras/web directory.\nAlso I set USER directive - I ran container built from this Dockerfile and it seems to work fine but I am not sure that USER is a replacement for gosu?\n. I think it's totally ok to have all-in-one container as web interface not used by default - it must be explicitly set via --web option. There is no need to run update.sh - as this will download actual version of web interface which is not good for building containers as builds won't be repeatable. So the goal is include version of web interface compatible with Centrifugo server release.\n. Another option - as web interface is just a directory with files - maybe its ok to just provide it in mounted volume? In this case there is no micromanagement with compatible web interface version.\n. You are right, we are all lazy:) Thanks @palazzem for your suggestions about pull request - but that was very interesting to try so I've made it myself) Just released new version with new Dockerfile - hope that I've made everything right - please check it out - is it ok?\n. Thanks!\n. Tried to pull by tag - no success, Docker Hub builds only master branch with latest tag automatically. Added 0.2.2 manually though so it's now possible to run docker pull fzambia/centrifugo:0.2.2. But as far as I understand there is no way to build new version tags automatically.\n. Yes, also saw this issue while searching for solution. So I think we are done here - not so difficult to add tags manually:)\n. This is a SockJS protocol specific error code. Please, see this and also this. I don't really know why 3000 so just followed conventions I saw. In case of raw websocket I just implemented Close(status uint32, reason string) error to fit SockJS session interface\n. yes, why not\n. Added a constant in a21ee1ff00fe14c7c1c8b9a133ca7c5e64ae7840\n. It's too late in Moscow, will see at all you propose here tomorrow!\n. When I wrote this I thought that this can prevent blocking when slow client does not read from socket fast enough. Your last solution will help with arbitrary throughput - but what if send blocks and m will grow more and more? I don't have strong understanding if this blocking possible or not.\n. For raw websocket connection there is SetWriteDeadline (godoc) method available, but SockJS session has no such possibility.\n. Maybe the best way right now - make buffer larger and make it configurable and see how it goes? And then after writing some benchmark tests it will be more clear what's the right solution to this?\n. Looks very interesting! Not sure this line necessary as clean method must be called anyway. There is old benchmark for Centrifuge - will try to run it after work to see memory and performance impact of these changes.\n. Hello! It's not possible as to use Redis when deploying via \"Deploy to Heroku\" button in this repo. Redis  must be set in addons array in app.json file. And also Procfile must be something like:\nweb: centrifugo --config=config.json --port=$PORT --address=0.0.0.0 --web=./extras/web/app --config=./extras/heroku/config.json``` --engine=redis --redis_url=$REDISTOGO_URL\nSo it's possible to run Centrifugo with Redis engine on Heroku but using custom receipt.\nAlso note that free Heroku dynos go to sleeping mode sometimes so Centrifugo does not feel good in such conditions. Free Heroku instances are perfect for demo and test purposes. I personally used only free dynos and can't say how non-free behave with Centrifugo but as far as I know if application has > 1 dyno it never goes to sleeping mode\n. Added you to Centrifugo team, have not found your email address, could you write an email to me (in profile) so we could find a way to discuss related things in a more comfortable way. I will create chat on https://gitter.im - never used it before - let's give a try))\n. Just ran a benchmark.\nFirst \u2013 without ring queue\nFirst column - amount of connected clients, second - nanoseconds between moment when one message sent into channel and moment when all clients received that message from channel:\nMacAir:benchmarks fz$ go run benchmark.go ws://127.0.0.1:8000/connection/websocket development secret 10000 1000 30\n1433269899\nmax clients: 10000\nincrement: 1000\nrepeat: 30\n1000    16708499\n2000    30078912\n3000    41459100\n4000    54806012\n5000    74290028\n6000    91229309\n7000    104538608\n8000    112292043\n9000    121811160\n10000   148505642\nMemory usage: 581mb\nAnd with queue:\nMacAir:benchmarks fz$ go run benchmark.go ws://127.0.0.1:8000/connection/websocket development secret 10000 1000 30\n1433270163\nmax clients: 10000\nincrement: 1000\nrepeat: 30\n1000    22178297\n2000    43288456\n3000    53741986\n4000    78144522\n5000    94671665\n6000    114886631\n7000    138078154\n8000    155005984\n9000    178497946\n10000   185657515\nMemory: 564mb\nAs we can see memory usage reduced a little and performance for this task ~25% worse. GOMAXPROCS=1.\nWith GOMAXPROCS=2 which is optimal for my old Mac Air:\nWithout queue:\nMacAir:benchmarks fz$ go run benchmark.go ws://127.0.0.1:8000/connection/websocket development secret 10000 1000 30\n1433271313\nmax clients: 10000\nincrement: 1000\nrepeat: 30\n1000    13462864\n2000    22556269\n3000    31261169\n4000    46361146\n5000    61516916\n6000    69018288\n7000    70037870\n8000    80599602\n9000    81334544\n10000   107770691\nWith queue:\nMacAir:benchmarks fz$ go run benchmark.go ws://127.0.0.1:8000/connection/websocket development secret 10000 1000 30\n1433271109\nmax clients: 10000\nincrement: 1000\nrepeat: 30\n1000    13935637\n2000    24814715\n3000    38827647\n4000    50307733\n5000    59065724\n6000    67227032\n7000    87391316\n8000    91397998\n9000    113766341\n10000   122585935\nMemory usage again a bit less, performance impact ~15%\nWhat do you think about this results? It's a bit upset to lose 20% but we theoretically get more predictable system\n. Yep (compare with top most result GOMAXPROCS=1, no queue)\nmax clients: 10000\nincrement: 1000\nrepeat: 30\n1000    17974868\n2000    30902744\n3000    42228004\n4000    58556314\n5000    74047742\n6000    81232314\n7000    100688710\n8000    107233599\n9000    128464179\n10000   133358961\n. Can we merge this into master or it's in progress? Feel free to do it when ready\n. Thanks!\n. As far as I know Godep just remembers commits of library version - you don't need to add shutdown to any register. We just need to update Godeps using one of godep tool commands\nIn Redis.There is a queue of API messages, presence and history. Presence will be removed automatically as we unsubscribe from all channels. History is OK to stay in Redis. And we don't need to clean queue as we shutdown one instance of Centrifugo and this queue will be used by other instances. So nothing to do with Redis I think.\n. Personally I think that unsubscribing from channels on shutdown is enough - all other things just make code more complicated and do not give any prize in practice in my opinion. How users of Centrifugo should behave when shutdown occurres?\nWe can flush remaining messages - but anyway some messages will be lost when client will reconnect after disconnect. So I don't think we need this at moment\nWe also need to not accept new API requests in apiHandler - but what will application do in this case? I don't think someone will implement sending retry in case of response with shutdown warning \n. I also think that the faster actual shutdown will occur the faster load balancer will start routing new requests to other instances\n. Thought about this a little more while went from work to home:) In practice at our work we remove node from upstream in Nginx - so API requests and connections go to another node. And then stop a node. Sending remaining messages suppose high message rate - in this case client will lose new messages anyway while reconnecting. Moreover it will miss some messages as we don't send new messages to him. Unsubscribing from channels is a nice new feature because we get actual presence info in Redis. Otherwice old connections will be in presence info until expire (~25 sec).\n. I still can not understand why sending remaining messages to clients is important.\nWithout sending remaining messages when node stops:\n- client unsubscribed from all channels\n- node stopped, client disconnected\n- client loses new messages while reconnecting to another node\n- client reconnects and everything is fine again\nWith sending remaining:\n- client unsubscribed from all channels\n- then we send remaining messages (btw clients already technically already unsubscribed from all channels and should not receive those messages)\n- node stopped, client disconnected\n- client loses new messages while reconnecting to another node\n- client reconnects and everything is fine again\nIn both cases client can lose messages so in my opinion flushing remaining messages is overcomplicated and unnecessary step. And it's absolutely OK to just unsubscribe clients from channels and stop a node. Maybe I miss something?\n. Still don't agree. Imagine a situation. One of Centrifugo nodes is under heavy load, too many messages queued up and there are clients to which sending remaining messages takes a lot of time. We added another couple of nodes to upstream and want clients to reconnect to it. As connections persistent we want to restart a node which is under load so clients reconnect to old one and newly added nodes from scratch. In this case we will be waiting a long time to stop a node and then start it. Meanwhile we lose or drop a lot of new messages. Why new messages are less important than old queued messages? I think Centrifugo is a type of server for which fast restart makes sense.\n. I have a sense that you are right in everything you say. But I also think that Centrifugo does not need this at moment as code become too complicated while I still don't see lot of practical benefit from these changes. Maybe several installations in production in future reveal the need and real benefit of sending remaining messages. Can we just leave unsubscribing from all channels for now and see how it goes?\n. :(\nThe option does not remove code complexity added here. I think that in early development stages simple code base is very important (for me). I am not comfortable with shutdown code changes - too many logic which does not help with losing messages as client will lose them anyway while reconnecting. Please, let's go with unsubscribing clients from channels only at moment and will add sending remaining messages to clients only if really needed in future releases?\n. Ok, sorry for conflicts, will try to add unsubscribing myself today in the evening:)\n. Hello, we are running Centrifugo behind Nginx. And it's strongly recommended to run Centrifugo behind Nginx or sth similar. So we just configure SSL in Nginx configuration - see commented ssl directives in configuration example.\nAlso I can add TLS built in (http://golang.org/pkg/net/http/#ListenAndServeTLS) - this requires some work but you will be able to run Centrifugo providing cert.pem and key.pem files. Is it necessary or you can go with Nginx?\n. @klauspost thanks a lot! @yagobski I will make new 0.2.2 release later today\n. If you mean how I create binary releases then see release.sh (https://github.com/centrifugal/centrifugo/blob/master/release.sh)\nIt requires Go installed, also godep and gox tools.\nIf you have Go installed then something like this should do a work:\ngit clone https://github.com/centrifugal/centrifugo.git\ncd centrifugo\ngo get go get github.com/tools/godep\ngodep restore\ngo get github.com/mitchellh/gox\n./release.sh 0.2.1\nNot tested steps above though - maybe forgot something\n. @yagobski v0.2.2 released!\n. http://stackoverflow.com/questions/23688565/failed-to-load-resource-neterr-insecure-response\nAs you are using self signed certificate you should open https://centrifuge_address:8000/connection/info in browser tab and allow ssl connection\n. Don't understand what you mean under bundle certificate problem?\nJust created self signed certificate using instruction from https://devcenter.heroku.com/articles/ssl-certificate-self , then opened https://localhost:8000/connection/info in chrome and allowed ssl connection. Both ws and sockjs endpoints work fine. And I am using Mac OS too.\n. I am not an expert in tls configuration - but maybe that chain file can be concatenated into cert file which Centrifugo accepts - see last messages in this thread  https://groups.google.com/forum/m/#!topic/golang-nuts/TnwfKyotEIY - sounds similar, can it help?\n. Nice! You are welcome, I will appreciate if you write full receipt how to build such certificate here - can be useful for someone in future\n. Merged, it works! Thanks a lot for your care!\n. Hello! Thanks a lot! Did not know about secret generators before. I am on vacation at moment, will read about them and merge in 5 days.\n. Thanks - I merged this but then changed web password back - as in other case user must look at application settings to get password for web interface - which can be confusing for Centrifugo newcomers. But having autogenerated project secret and web secret is great!\n. Release of Centrifugo v1.0.0 is planned on this weekend!\nHere is current changelog (something can change, feel free to write your opinion):\n- works with single project only. No more project key. secret the only required configuration option.\n- web interface is now embedded, this means that downloading binary release you get possibility to run Centrifugo web interface just providing --web flag when starting process.\n- when secret set via environment variable CENTRIFUGO_SECRET then configuration file is not required anymore. But when Centrifugo configured via environment variables it's not possible to reload configuration sending HUP signal to process.\n- new stats command to export various stats and metrics over API call.\n- new insecure_api option to turn on insecure HTTP API mode. Read more in docs chapter.\n- minor clean-ups in client protocol. As protocol incapsulated in javascript client library you only need to update it.\n- all supported libraries also got 1.0 versions\nHow to migrate\n\nUse new versions of Centrifugal libraries. Project key not needed in client connection parameters, in client token generation, in HTTP API client initialization.\n--web is now a boolean flag. Previously it was used to set path to admin web interface. Now it indicates whether or not Centrifugo must serve web interface. To provide path to custom web application directory use --web_path string option.\n\nI.e. before v1 you started Centrifugo like this to use web interface:\ncentrifugo --config=config.json --web=/path/to/web/app\nNow all you need to do is run:\ncentrifugo --config=config.json --web\nAnd no need to download web interface repository at all! Just run command above and check http://localhost:8000.\nIf you don't want to use embedded web interface you can still specify path to your own web interface directory:\ncentrifugo --config=config.json --web --web_path=/path/to/web/app\n. Centrifugo v1.0.0 released\n. Hi! Which command have you used to run it?\nHere is one from docs:\ndocker run -v /your/host/dir/containing/config/file:/centrifugo -p 8000:8000 fzambia/centrifugo centrifugo -c config.json\nAt first glance it seems that you have not provided configuration file to use.\n. Did it help?\n. Yep, thanks\n. Hello! Thanks for a report - it's a bug.\nI fixed it. And as soon as I didn't announce v1.0.0 anywhere I will recreate v1.0.0 release with fixed binaries later today. Will write here as soon as upload fixed binaries to latest release\n. It happened because now it's possible to set secret key via environment variable CENTRIFUGO_SECRET and start Centrifugo without config file for the simplest usage.\n. @andremendonca just updated binaries in 1.0.0 release, thanks again for opening issue.\n. I can update release binaries again in the evening as I made several changes I want to be in 1.0.0.\n. Done! Updated tag and binaries. I've made several changes to reduce memory consumption a bit and deal with stale connections, i.e. connections which join Websocket or SockJS endpoint and do not send connect client protocol command. Hopefully release is done now:)\n. Hello! Centrifugo can not daemonize itself. You can use other daemonize tools such as supervisord, upstart etc. Depending on operating system and linux distribution you are using.\nWe are using Centos and run Centrifugo using supervisord or just built-in daemon function (init.d)\n. Helpful discussion on Reddit\n. You are welcome! There is also discussion in Go mailing list about program daemonization. And general opinion is let external daemon program do this.\n. Hello! User ID can be a non number, for example MongoDB object id, so explicitly providing string as it happens now seems to be a right way.\nI also don't think that we need to typecast timestamp because lots of libraries in languages return timestamp with microseconds while we need only seconds. The result of type cast can be even more non obvious. I think providing utility functions like the one from centrifuge-go is a better way. \n. Yep, commited\n. Hello!\nUnfortunately I have not heard about such SDKs. I personally don't know Objective-C/Swift and Java so can't implement it myself:( I got emails from people who successfully connected from IOS device using SocketRocket websocket library but code is not available. So I hope on community help - maybe one day someone will try to make a client for mobile. Javascript and Go clients can be used as reference to implement client in another programming language.\nI am planning to improve that chapter in docs in near future!\n. Thanks! No, never used, I am too far from mobile dev and even not familiar with Ionic / Cordova:) Hopefully js client will work - if you try please tell me about results!\n. @SammyVimes that's really great news! Thanks for sharing\nAre you planning to work on other features in this client - retrieving presence and history, handling join/leave events etc?\n. @SammyVimes cool, keep me posted!\nCentrifugo can't do this automatically. This is one of the most tricky parts. First of all - Centrifugo does not keep message history by default - as you know it must be turned on via channel options. So by default Centrifugo drops message as soon as it was sent to all currently connected clients. \nHaving history for all channels isn't a good idea. We can't figure out how long client was missing and how big this cache must be. But at moment channel history is something like configurable cache for messages in channels.\nSo two possible workarounds here. First - remember last message uid and call history to get missing messages. But it's possible to lost messages anyway if history size less than messages missed or time of reconnect greater than history lifetime.\nAnother one - get missing messages from application backend in some way. I prefer this approach as Centrifugo's role is just to do fast message broadcast to currently active clients. Also your client could be disconnected for a day for example - in this case it's a bad idea to rely on Centrifugo to deal with this situation.\nI thought about channel option that will automatically send messages from history to resubscribed client (if last message uid provided in subscription request) but decided that this can not redeliver all missing messages in case of long disconnect period and can be done on client side.\nIf Centrifugo get engine with message history on disk (there are some thoughts on early stages) then in theory such option makes sense to be built-in so Centrifugo users could decide themselves when they need it for channel.\n. Hello, @gedw99 !\nI've heard about it and already thought a bit about making shared library. 2 problems that prevented work in this direction were the fact that I still need to know Java and iOS and their environment to test resulting library somehow. And as far as I know there are limitations for types that can be exported via public API.\nBut I'll try to storm this idea again looking through your links first. Maybe this is really not so hard to implement as I thought initially. Moreover our go-client not so big (< 1000 lines of code) so it's comfortable to experiment with.\n. @gedw99 just tried to make shared library from existing go-client. It seems that at moment gomobile supports only basic types which is not enough in our case... It can't work with []libcentrifugo.Message, map[libcentrifugo.ConnID]ClientInfo and all named types:\nunsupported named type time.Duration\nunsupported, direct named type time.Duration: int64\nunsupported named type github.com/centrifugal/centrifuge-go.DisconnectHandler\nunsupported, direct named type github.com/centrifugal/centrifuge-go.DisconnectHandler: func(*github.com/centrifugal/centrifuge-go.Centrifuge) error\nunsupported named type github.com/centrifugal/centrifuge-go.PrivateSubHandler\nunsupported, direct named type github.com/centrifugal/centrifuge-go.PrivateSubHandler: func(*github.com/centrifugal/centrifuge-go.Centrifuge, *github.com/centrifugal/centrifuge-go.PrivateRequest) (*github.com/centrifugal/centrifuge-go.PrivateSign, error)\nunsupported named type github.com/centrifugal/centrifuge-go.RefreshHandler\nunsupported, direct named type github.com/centrifugal/centrifuge-go.RefreshHandler: func(*github.com/centrifugal/centrifuge-go.Centrifuge) (*github.com/centrifugal/centrifuge-go.Credentials, error)\nunsupported named type github.com/centrifugal/centrifuge-go.MessageHandler\nunsupported, direct named type github.com/centrifugal/centrifuge-go.MessageHandler: func(*github.com/centrifugal/centrifuge-go.Sub, github.com/centrifugal/centrifugo/libcentrifugo.Message) error\nunsupported named type github.com/centrifugal/centrifuge-go.JoinHandler\nunsupported, direct named type github.com/centrifugal/centrifuge-go.JoinHandler: func(*github.com/centrifugal/centrifuge-go.Sub, github.com/centrifugal/centrifugo/libcentrifugo.ClientInfo) error\nunsupported named type github.com/centrifugal/centrifuge-go.LeaveHandler\nunsupported, direct named type github.com/centrifugal/centrifuge-go.LeaveHandler: func(*github.com/centrifugal/centrifuge-go.Sub, github.com/centrifugal/centrifugo/libcentrifugo.ClientInfo) error\nunsupported named type github.com/centrifugal/centrifuge-go.UnsubscribeHandler\nunsupported, direct named type github.com/centrifugal/centrifuge-go.UnsubscribeHandler: func(*github.com/centrifugal/centrifuge-go.Sub) error\n. @SammyVimes just proposed pull request (https://github.com/centrifugal/centrifugo/pull/42). This is related to what I wrote about missed messages.\n. @SammyVimes yep, you are right! @flc if you still interested in this \u2013 please look at our new clients.\n. Just thought how to implement this - there are several barriers. Every channel has its own options defined over namespaces. And every message sent has unique id and channel name. So at server side we have to anyway iterate over all channels and create message for each of them, apply namespace rules and finally publish into the wire. Also what if there will be an error publishing into one of those channels - how can Centrifugo return a response for this?\nWhen using current implementation to publish into multiple channels there are no problems described above:\ncommand = [\n    {\"method\": \"publish\", \"params\": {\"channel\": \"channelA\", \"data\": {\"input\": \"xxx\"}},\n    {\"method\": \"publish\", \"params\": {\"channel\": \"channelB\", \"data\": {\"input\": \"xxx\"}},\n    {\"method\": \"publish\", \"params\": {\"channel\": \"channelC\", \"data\": {\"input\": \"xxx\"}},\n]\nAnd Centrifugo just returns 3 unique response objects for each publish command in request.\nSo the only real benefit here is traffic and a better looking publish code, due to the logic for each channel performance gain will most probably be minimal.\n. Yes, it seems reasonable for use this with Redis API only. And maybe it's better to make this as new command and call method as something like publish_many (or just broadcast) to prevent breaking semantics of current publish command.\n. done in efc52ad6eb65aab8565ab5bb125c181df23e9ec5, it can be used over HTTP API too.\npython\nfrom cent.core import Client\nclient = Client(\"http://localhost:8000\", \"secret\")\nparams = {\"channels\": [\"public:test\", \"public:chat\"], \"data\": {\"input\": \"hello\"}}\nclient.add(\"broadcast\", params)\nclient.send()\nIt will publish data into channels until first error occurres. This error then set as response error and publishing stops. In case of using Redis API queue error will be logged. There is no currently mechanism on API client side to determine channels to which publishing was successful in case of error. Maybe I will add this as response body for publish and broadcast commands later. \n. This will be released in v1.2.0 and I'll also update docs\n. Wow, the difference is really essential! \nSeveral moments here. First, what about tweaking nofile limit? Also, I am not a docker user yet, how to run centrifugo from centrifugo user? I am also not sure is it ok to just change base image (as existing users already use image based on centos 7)? Are there any known open-source network servers that use this base image?\n. Ah, it seems that I missed some instructions as they were suppressed in Github diff - I missed USER directive already used in Dockerfile:( So no questions about running as user anymore.\nBtw it's time to add SHA256 sum into Dockerfile.\nSo the last thing that confuses me \u2013 backwards compatibility concerns. Can we can just change base image in Dockerfile? Also ulimit must be configured from outside now (which I think is nice but breaks current usage scenarios relying on large nofile by default).\n. @yurtaev added your Dockerfile into documentation in Docker chapter - https://fzambia.gitbooks.io/centrifugal/content/deploy/docker.html\nBtw do you know will Docker override limits set in /etc/security/limits.d when we provide limits via command-line arguments when starting container?\n. @yurtaev Egor, just created image based on your pull request in another repo (https://github.com/centrifugal/centrifugo-docker) - also on Docker hub https://hub.docker.com/r/centrifugo/centrifugo/ - I think this will resolve all my doubts about compatibility\n. Thanks a lot for your contribution!\n. Hello!\nAbout Web UI. At moment you can start Centrifugo without UI at all just omitting --web flag. Also if no password set in config file then we can just skip login screen (must be easy to implement).\nCould you configure access on location level? For example something like this in Nginx:\nlocation / {\n    allow 127.0.0.1;\n    deny  all;\n}\n?\nAbout API. There is option --insecure_api which can disable sign check so you can send unsigned requests with JSON commands in request body. Again - is it possible in your case to just restrict access to API endpoint /api/?\nHope I understood issue correctly. \n. I think it's better to do as much as possible before forking to custom version. This can happen eventually but at moment all these things seems reasonable.\nI think a combination of your points must be done here:\n- if web_password and web_secret are empty then we will skip auth (we can't make it false as config parser expects string). Warning in docs needed here.\n- option to disable http API disable_api - for those who use Nginx.\n- add api_port and web_port options\n- /auth/, /info/ and /action/ APIs should only be enabled if web is enabled (strange that I have not done this before).\nI am considering to add some logic into /socket endpoint i.e. use it not just for web interface needs. But it will be another option so now we can just leave it disabled if web disabled. \n. Started implementing this in separate branch (https://github.com/centrifugal/centrifugo/tree/separate_ports), changed some points above:\n- explicit insecure_web option instead of empty web_password and web_secret.\n- use \u00a0admin_port instead of web_port for option name as this port will most probably be used not only by web interface in future.\n- as you don't need disable_api then I think it's better to not add it right now\n. Will be released with v1.3.0\n. I've seen both and even got some inspiration out of them while writing Centrifugo and Go client for it. Great messaging servers!\nThere several requirements for engine - storage to keep data (for channel history and channel presence, this should not be necessarily disk storage, keeping data in memory is ok), PUB/SUB mechanism (publishing new messages, publishing internal Centrifugo messages between nodes), expiration mechanism (history and presence data should expire).\nFor in-memory engine all of these requirements implemented directly in Centrifugo. Redis provides all these features out of the box. Due to its built-in structures it was possible to implement history of fixed size with expiration and presence with expiration.\nNATs and NSQ don't fit these requirements well as both of them more like Centrifugo itself while Centrifugo needs something like database with some special requirements above as engine. There are not so many options for engine that can support all Centrifugo requirements.\nThere is another approach - use NSQ or NATs for PUB/SUB only, use Redis as storage backend. I.e. having engine composed out of 2 different external systems. The benefit is that if you don't need history and presence you can go just with NSQ... But to support such combined engines there must be a mechanism to keep their code outside Centrifugo core and a way to configure it separately. I don't see a good approach how to do this at moment. Maybe running engine as daemon near every Centrifugo node and communicate over protobuffers/flatbuffers? Seems interesting. But also complex and I am not sure  is this a good architecture decision.\n. @joeblew99 I think I missed an idea:(\n. Sorry I still can not understand your last thoughts. Could you tell what you mean in another words?\nAlso what do you mean under HTTP/2 push? As far as I understand HTTP/2 push will be used to push media resources into browsers and it's not related to bidirectional communication between browser and server (what Websockets used for).\n. It's a nice area - integrating Centrifugo with app using RethinkDB. As @banks noted - this is not an engine, but just a layer that publishes messages received from Rethink by application to Centrifugo. In this case there are more entities participate in a game - Rethink, Centrifugo, Redis, application backend... But as result you can get an interesting set of features.\n. I see your point, but at moment I don't think it would be easy to implement all Centrifugo engine needs on top of rethinkdb.\nLet's look at our requirements and what rethinkdb currently has:\n- storage to keep data (history, presence) - yes\n- PUB/SUB mechanism - maybe, it seems this can be implemented of top of changefeeds feature - https://www.rethinkdb.com/docs/publish-subscribe/javascript/.\n- expiration mechanism (history and presence data should expire) - not yet https://github.com/rethinkdb/rethinkdb/issues/746\nAs rethinkdb user please correct me - maybe I am missing something. We can be on the alert though.\n. Let's summarise what we have in this discussion at this moment.\nNot so many databases can offer everything to support all Centrifugo features out of the box. Redis is perfect in this.\nNATS and NSQ are more messaging systems. It would be possible though implement PUB/SUB on top of them and other features on top of other databases. Also it could be possible to implement only PUB/SUB for example and let other features like history and presence as not implemented. But in this case with those features left we also loose something that makes Centrifugo unique. So I think it would be possible only if in future we find a way to make engines pluggable. And keep such engines out of core.\nIf we consider databases capable to support all our features - at moment I see 2 real candidates here: RethinkDB and Tarantool. Tarantool don't have truly PUB/SUB at moment (but something can be implemented on top of lua). Tarantool is fast and flexible, has master-master replication, not so popular in the world yet unfortunately. RethinkDB don't have TTL yet and a bit different in terms what is this and how it works. But both look promising in some aspects. RethinkDB is quite popular (btw I see a lot of hype about Rethink but I don't really know is it used widely now?) and can be a good companion for Centrifugo - as both positioned as tools for real-time web. Also it seems it scales well.\nBut we need a real use case scenario and users that need alternative engine implementation to promote this further - otherwise we will grow wide but stay at the same place. Lets keep this question open, maybe we can just experiment with something and see how it goes.\n. @joeblew99 let's keep it open so our users know about current state of alternative engine support in Centrifugo - this is an important topic anyway.\n. @CodingNemesis no unfortunately. There is a work in issue #100  to decouple Centrifugo packages so it would be possible to write custom engines. As LedisDB has no PUB/SUB support then it will be impossible to implement scaling Centrifugo to several machines on top of it. I think we will need some extra code that will allow to connect Centrifugo nodes into cluster to communicate with one another without any third-party database (like Redis at moment). And use this code inside custom engine implementation.  Then choosing database to keep temporary data would be much easier.\n. @banks I agree with risks, I think it will be theoretically possible without separating pub/sub part from engine. Engine still needs to provide what it does now but inside custom implementation sth like NATS could be used. Let's put this another way - I think we could write some code that uses another PUB/SUB providers (like NATS) that users could use in there custom engine implementations. Of course it could be possible to make PUB/SUB part separate - but current Redis implementation shows that we don't need to make it fully separate as Redis provides everything Centrifugo needs.\n. Centrifugo v1.6.0 has a pluggable engine mechanism. But I have not found anything better then Redis for engine. I  created Nats-based PUB/SUB engine as a proof of concept. It works but lacks our features such as recovery and presence. So anyway sth like Redis required to make it fully functional.. @criloz cool! Please tell if you end up with something interesting \u2013 and you can always write into our gitter chat. Thanks for suggestion! I asked for custom free plan for open-source project on packagecloud.io - waiting for answer from them\n. Just got an email with great news from packagecloud.io - 5GB of storage without package limits - more than enough I think. So we can keep going here:)\n. @Sulverus @rtsisyk I almost done with this in #70 , I don't use cloud build, just building in travis using fpm and push to packagecloud.io - please look maybe you have comments, there could be lots of caveats. I also decided to support only linux distributions for this moment that Digital Ocean offers for droplets - assuming those are the most popular for server machines now. \n. @roytan883 looks like pretty reasonable and useful suggestion. \nI doubt though that it's possible to implement in a way you've written - 2 reasons against:\n lastClientSubTime is not a correct value to rely on in this case. As client connection can live days and subscription could be created a week ago for example. But we can look at unsubscribe time in this case - i.e sth like lastClientActivityTime. But...\n ...but lastClientSubTime (or lastClientActivityTime from first point) is not known on every Centrifugo node. New message can come to any node and we could not have information about  lastClientSubTime for this subscription on this node. I am not sure we have to keep this in Redis...\nI have another idea - can't decide now is it pretty or ugly:) Or will it even work?:)\nAnyway: when last user in channel disconnects from node we usually unsubscribe this node from channel in Redis. What if we won't unsubscribe node until history TTL time expires. This way we will have subscription on Redis channel and message will be saved into history. This behaviour must be optional. And it's not simple to implement as I can see.. Sorry, I am not sure that I understood you right - especially part about any of 3 points (I only understand point 1). We already check if engine.publish() actually delivered to anyone for example\n\nAlso I think the first rule can optimize the history_drop_inactive performance in real world.\n\nhistory_drop_inactive already have no performance overhead.\nI understand what you want here and understand how we can solve this (my suggestion above and your suggestion from point 1). Maybe you could write more accurately what you mean in other parts of your previous comment.. @banks it's an interesting idea - I have not thought about this from a side that we can just create history key with TTL or prolong existing on TTL.\nLet me clarify - you mean \"null\" messages that will be published in Redis and not actually added into history and won't be published into channel right? The goal is just to touch history TTL.\nMaybe we should do this as separate routine without mixing publish logic with such history touch. It's an implementation detail of course but could be semantically cleaner and not exposed to public API anyway. Also need to think about mass resubscription case after reconnect to Redis and how this will affect existing metrics.. Got it, thanks! Will try to make proof of concept, maybe some details will arise in process.. @roytan883 @banks I ended up with pull request #148 - please have a look!. Just merged in master\n. Thanks a lot @banks ! Will see at pull request as soon as possible.\nI don't have strict strategy how to update docs, but usually I am writing and updating docs at the same day when releasing. We can create chapter in docs now in separate branch and make pull request that just merge later.\nYes, tests needs some improvements here:(\nBtw what's your client code to determine queue to which you put message? Something like crc16 mod N?\n. As we already discussed in gitter chat error handling can really be better.\nI am preparing v1.3.0 release at moment and for now commited small change that must help to prevent permanent disconnect in case of internal server error.\n. Now in v1.3.2 errors can contain optional advice (fix or retry). fix means that developer using Centrifugo did something wrong, i.e. using unknown namespace in channels or channels too long - so developer should fix this in order things to work properly. retry signals temporary error that could theoretically be successful if client try executing command again. These advices do not handled by javascript client automatically but included in error context.\ndisconnect command with reconnect boolean flag used to control client's connection - disconnect forever or disconnect with reconnect. ErrInternalServerError results in sending disconnect command with reconnect.\n. I think this is not actual anymore - many improvements here have been done, some will be released with Centrifugo v1.6.0, let's close this.. Empty string already used as a sign to make operation with all things - in unsubscribe command empty channel unsubscribes user from all channels. So I think empty string should be ok to keep support the same semantics. At moment Centrifugo just closes connections when processes disconnect API cmd, now we need to send disconnect message to clients. As you know there is reconnect flag in it. This reconnect flag will be optionally set in web interface and by default will be true I suppose - so even if disconnect button was pressed accidentally from web interface - users will reconnect.\n. Can make this empty string const at moment and then move to configuration if needed. The problem I came across while thinking how to make this is that disconnecting all users is operation that takes a time - so some of users can disconnect and even reconnect during this operation (especially if application has many users). So I can't decide - is this ok or not? What can we do with this case and should we? Just locking client hub won't help as new connections will be just queued for a while. Setting extra flags on the time of operation looks like overengineering. @banks whats your thoughts?\n. Trick with altering secret should help.\nThere is already shutdown method called when SIGINT received. And shutdown property in application. Maybe try to make shutdown as button in web interface? At moment on shutdown connections just closed - so will reconnect, maybe shutdown with optional reconnect flag? But anyway there may be some users that have not processed disconnect message and will try to reconnect.\n. Closing with won't do resolution, because as time goes there is still no obvious solution. Hopefully this is a rare requirement and changing secret can be a reasonable workaround to solve this case.. fixed in 13462ab4e73ce0a03f763fd058062599d764d9c8\n. @banks great work! thanks!\n. Could you explain what you mean under:\n\nthe application itself will need to support batch publish API requests (should we make new API call? Or breaking change to current API params?\n\nI supposed that this must be transparent for applications i.e. apps just send the same requests as before but they batched in Centrifugo before publishing. Seems I miss something?\n. Part one done via #61 \n. Part two. Yesterday I made proof of concept showing that we can actually batch publish requests to Redis over pipeline and this makes things more performant as we save time on RTT to Redis. But the hardest part is how to seamlessly add batching support to existing API.\n1) Option 1. Make redis_batch_* options - to batch all published messages in time interval (or configured amount reached).\n2) Option 2. Add batch option to internal API, so only use it when needed - for example we don't really need batching when single messages come to HTTP API - because they will use different connections to Redis from pool. But we need batching when lots of messages to publish come in one HTTP request. Most probably some changes in engine will be required.\n3) Option 3. Add batch option to external API, so developers can decide when they need batching. I like this option less than others because it's in general more to do for our users.\n4) ?\nAlso we should keep the behaviour in which call to history after publish always return correct history containing messages just published. So we can't just publish asynchronously - we need a way to only return response to API client when publish has been done.\n. Actually I thought about this option (I meant this as solution if choose option 1). But I thought to do this just for publish operation \u2013 do you mean that we should try to do all engine operations over pipeline - i.e. including history, presence etc?\n. Part two released with v1.4.2\n@banks do you have any thoughts about what should be done in next iteration? Maybe special async  flag in publish message to tell Centrifugo not to wait for response so batching could be used when messages published over publish command. So as far as I can see at moment batching in Redis engine will be used if:\n- broadcast command used\n- for parallel requests over HTTP API\n- for parallel processing of API messages coming from different API Redis queues.\nRequests like this (two publish commands in one request):\njavascript\n[\n    {\n        \"method\": \"publish\",\n        \"params\": {\n            \"channel\": \"channel1\",\n            \"data\": {}\n        }\n    },\n    {\n        \"method\": \"publish\",\n        \"params\": {\n            \"channel\": \"channel2\",\n            \"data\": {}\n        }\n    },\n]\nWill wait for at least 2 round-trips to Redis anyway, because Centrifugo will wait for response from publishing into channel1 before starting publishing into channel2, so sth like async option should help. But in general I personally don't need this at moment - so maybe we should wait to do this if no one needs this. \n. As #90 merged I think we are done here (as far as I can see we've made all proposals and much more with that refactoring).\n. @banks @jeberly I have doubts that draft promoting specification for web push server will be approved in near future - I don't understand the motivation behind this - allowing any server to be web push server means that every site will create separate connection to separate domains in Service Workers. Is this reasonable to have? When Firefox and Chrome have its own web push servers (GCM or Mozilla\u2019s Web Push service) it's reasonable because this could be single connection for all sites.\n. Yep, I agree that overall this is a good feature. Just as far as I understand push-api was invented with device battery life in mind and having lots of connections to various servers in background don't fit well into this paradigm. But maybe in practice this won't be a problem? Anyway let's watch on the spec draft, just discovered another link with more actual version\n. @MadHamza do you have more questions? Can we close this?\n. fixed in d729ec5de170267e5bdfd21411ceba9b431f2148\n. @banks I've made this not to optimise overall performance. Just thought that relaxing receiver goroutine is good from point that in that receiver goroutine we just need to read from Redis as fast as possible. But then I found this answer on SO \u2013 and it seems that there is no real need to optimise this. So you are right, this is useless. But I will try to play more with this code though just out of curiosity - and then most likely will close pull request if I don't find something to reason about.\n. Ah, you are right. Fixed, thanks a lot!\n. Hello! Thanks for detailed proposal!\nI agree with almost everything, the only thing: at work we send metrics directly to Graphite and just want to see actual values aggregated over one minute interval, so for us it's important to keep current behaviour with counters. So it seems we need to support both ways\nAnd I especially agree with you thoughts about current timer behaviour - absolutely useless:)\n. Our main site written in Django and we use Celery to do async or periodic jobs, so we just ask stats from Centrifugo every minute and send returned metrics into Graphite.\n``` python\n@app.task\ndef export_centrifugo_metrics():\n    client = Client(settings.CENTRIFUGO_ADDRESS, settings.CENTRIFUGO_SECRET, timeout=2)\n    stats, error = client.stats()\n    if error:\n        raise error\nfields = (\n    \"cpu_usage\", \"num_goroutine\", \"num_msg_published\",\n    \"time_api_max\", \"num_api_requests\", \"time_client_max\",\n    \"time_client_mean\", \"num_unique_clients\", \"num_msg_queued\",\n    \"memory_sys\", \"bytes_client_in\", \"num_cpu\", \"num_clients\",\n    \"time_api_mean\", \"num_client_requests\", \"num_msg_sent\",\n    \"bytes_client_out\", \"gomaxprocs\", \"num_channels\"\n)\n\nnodes = stats[\"nodes\"]\nfor node_info in nodes:\n    name = node_info[\"name\"]\n    for field in fields:\n        value = node_info.get(field)\n        graphite_key = \"centrifugo.%s.%s\" % (name, field)\n        send_to_graphite([graphite_key, value, time.time()])\n\n```\n. lol, just thought that we have a problem with counters with this approach:)\nUPD: no problem - forgot how metrics in Centrifugo work))\n. @banks created separate issue for timers, closing this one, thanks a lot!\n. @banks wonderful! Thanks a lot!\n. I expected you ask about this eventually:) There are two reasons I see:\n1) Messages for client first go to client's queue - so I afraid that close will be fired before disconnect message from queue actually sent to client's connection.\n2) Just don't give a simple way for malformed clients spam server with lots of malformed messages. Still possible of course using many parallel clients but can save from stupid mistake. \n. done in #97 , will be released with next Centrifugo version \n. I am not very happy with how metrics currently implemented. This is  current NodeInfo struct:\ngo\ntype NodeInfo struct {\n    mu         sync.RWMutex\n    UID        string `json:\"uid\"`\n    Name       string `json:\"name\"`\n    Goroutines int    `json:\"num_goroutine\"`\n    Clients    int    `json:\"num_clients\"`\n    Unique     int    `json:\"num_unique_clients\"`\n    Channels   int    `json:\"num_channels\"`\n    Started    int64  `json:\"started_at\"`\n    Gomaxprocs int    `json:\"gomaxprocs\"`\n    NumCPU     int    `json:\"num_cpu\"`\n    metrics\n    updated int64\n}\nIt's located in metrics.go but actually only part of it are metrics... Something like this would be much better:\ngo\ntype NodeInfo struct {\n    mu       sync.RWMutex\n    UID      string `json:\"uid\"`\n    Name     string `json:\"name\"`\n    Metrics  map[string]int64 `json:\"metrics\"`\n    updated  int64\n}\nThis will allow to abstract various counters and operate by semantic names in code rather than concrete struct fields (i.e. something like Histogram registry but for counters). Also I think it's a good idea to include latencies into that metrics map as flat keys without extra latencies level as it now. Also I don't think we will need floats for metrics. This will allow to keep metrics specific code into separate package.\nThis is a breaking change unfortunately:(\n. Current latencies implementation is like quantum measurement:) Asking for metrics affects latency metrics significantly. So per specific API command histograms could really make sense. But this is only possible to insert after net/http and request decoding work already done. Will try to investigate this more.\n. done in v1.6.0. The work started here and first changes appeared in 1.4.2 release. Though still more work needed to make admin websocket able to be an way to work from application backends - need to add queue to admin connection similar to client's queue.\n. Message queue added in 71faa51a8bdcee51947e336be03a859b3f1a8a97\n. @odin3 thanks a lot for the report! Please, give us answers for questions @banks asked.\n@banks it was long time ago I last ran Centrifugo under race detector. Looks like there are some problems: https://gist.github.com/FZambia/261b1b15d7f059035f4f\n. One more: https://gist.github.com/FZambia/88bc50efec3728ea7f85 seems very similar to panic above\n. @banks Paul, please look at pr above - not sure I did it in optimal way but races gone away. Maybe you see a better way?\n. @odin3 I'll make new release with fix of race condition that most probably caused that panic later today. But just to be more sure we still need some answers on questions above from you - because if this happens reliably and you can easily reproduce this - our theory ruins:)\n. @odin3 seems this caused because you are using 32-bit architecture. Unfortunately I can't proceed with this today because it's too late in Moscow, but this issue is the highest priority now - so will continue tomorrow.\n. @odin3 we were able to reliably reproduce that panic on 32-bit Centos. The problem was not in race conditions we assumed initially but in bug on some architectures (see this link). Now it should be fixed, just made new release (v1.4.1) that must resolve this issue. Please, try it out.\n. I posted links to gists in comments with races or what you mean?\n. That struct does not contain int64 values we access in atomic way, should it still be aligned? Will try to reproduce panic on 32-bit machine now...\n. @banks just tried on Centos 6 32-bit. Reproduced panic - happens after every request to API. No problems with version built from this branch (btw still panics in current master branch - so the problem is really in aligning).\nI understand that your code was a bit more generic in the end. But with this approach we preserve the same exported structs as before, so gocent continues to work. And this approach is a bit more simple to understand in my opinion because we don't need to have custom marshalers and clone counters. \n. Loading deltas atomically seems really non needed - will fix right now\n. hm, I have not thought about this. ok, let's move it in the end and comment then.\n. This is very interesting and cognitive. Thanks a lot @banks !\n. At moment I came up with writing a small library on top of Redigo which allows to add basic Sentinel support.\n. Done in v1.4.2\n. Hello @oddurmagg , does that workaround work fine for your case? If having environment variable is more convenient for you - I can add it in next release.\n. Ok! Added in 9c3942b5f33b8ce8bc4656232c2aec8fd9fce341. I am planning to finish #73 and then make new release - hopefully during this week.\n. @oddurmagg unfortunately still can not release new version, because I want to include 2 pull requests into new version: #83 and #84 \n. Finally released!\n. To summarize what have been done here:\nNew option admin - it enables admin socket which is now off by default. For backwards compatibility web option also enables admin socket automatically (because web uses this socket).\nSo to start Centrifugo with admin socket enabled:\ncentrifugo --config=config.json --admin\nBut this will also enable admin socket handler (and additionally will serve web interface):\ncentrifugo --config=config.json --web\nAlso --insecure_web is now --insecure_admin but old option still supported to not break things.\nweb_password and web_secret are now admin_password and admin_secret but old option names supported as well.\nAlso web interface can now use only AuthHandler and admin websocket for everything - so I removed InfoHandler and ActionHandler. Refactored web interface frontend at moment sits in its own branch in web repo - will embed it in the end.\nAlso the work here is not complete because I think it will be good to add message queue for admin connection (like client's message queue) - but this does not affect old functionality so can be done later.\n. To summarize things done in this pr:\nAdded pubRequest struct and pubCh to Redis Engine. Now every publish results in sending pubRequest to pubCh - and one goroutine reads from that channel, batches publish requests and sends to Redis (keeping publish engine method synchronous). Almost the same like @banks already did for managing subscriptions.\n. Actually that was not so simple because we don't call engine method directly from broadcastCmd - we call application's publish method which contains lot of helper logic.\nBut anyway I think I changed it in a way you suggested - not adding new engine method though but returning error channel from existing and added helper method to publish synchronously to Application.\nResult is wonderful: broadcast now 2 times faster for 10000 channels than version with goroutines. So overall performance improvement for broadcast is about 11-12x\n. ok, thanks a lot for looking! I can't find something I can improve here at moment - so going to merge this then. This async publish method in engine opens a road to further optimizations maybe - i.e. something like async: true in publish command if user don't need to wait for publish result to speed up publish commands coming from single Redis queue for example. But let's discuss this later outside this pr.\n. Yep, I think a little sleep in runForever func will fix this. \n. Thanks!\n. Hello! Thanks for work on this but I don't feel this is correct place to use constants. In my opinion with this patch we have less readable file \u2013 when we want to see available options we should first look at places where we bind viper variables and then find a value in a list of constants. So general impression here is that we changed string constants to constants defined as variables.\nI like the idea to be more DRY in places where we bind variables though. But without using variable constants. I mean sth like this:\n``` go\nbindEnvs := []string{\"debug\", \"engine\", \"insecure\", ...}\nfor _, env := range bindEnvs {\n    viper.BindEnv(env)\n}\n```\nInstead of this:\n``` go\nbindEnvs := []string{DEBUG, ENGINE, INSECURE...}\nfor _, env := range bindEnvs {\n    viper.BindEnv(env)\n}\n``\n. I still convinced that we lose in readability introducing constants here. It was never a problem modifying options in this file and all these options are not going to change often as we mostly only add new. I'll fix repeatitions in.BindEnvand.BindPFlag` though.\n. Changed in eb363e4b2332677c8ae7583c1acbe2ca16579526. Sorry for not accepting your changes \u2013 maybe I realize my wrong vision later and refactor like you suggested.\n. Added benchmark to estimate how much work required to handle one message from PUB/SUB:\n``` go\nfunc BenchmarkClientMsg(b *testing.B) {\n    app := testMemoryApp()\n// create one client so clientMsg really marshal into client response JSON.\nc, _ := newClient(app, &testSession{})\n\nmessagePoolSize := 1000\n\nmessagePool := make([][]byte, messagePoolSize)\n\nfor i := 0; i < len(messagePool); i++ {\n    channel := Channel(\"test\" + strconv.Itoa(i))\n    // subscribe client to channel so we need to encode message to JSON\n    app.clients.addSub(channel, c)\n    // add message to pool so we have messages for different channels.\n    testMsg := newMessage(channel, []byte(\"{\\\"hello world\\\": true}\"), \"\", nil)\n    byteMessage, _ := testMsg.Marshal() // protobuf\n    messagePool[i] = byteMessage\n}\n\nb.ResetTimer()\nfor i := 0; i < b.N; i++ {\n    var msg Message\n    err := msg.Unmarshal(messagePool[i%len(messagePool)]) // unmarshal from protobuf\n    if err != nil {\n        panic(err)\n    }\n    err = app.clientMsg(Channel(\"test\"+strconv.Itoa(i%len(messagePool))), &msg)\n    if err != nil {\n        panic(err)\n    }\n}\n\n}\n```\nResults:\nPASS\nBenchmarkClientMsg-2      200000          8767 ns/op         753 B/op         12 allocs/op\n. I've added custom manual marshaling for client message, join, leave JSON responses so benchmark now looks like:\nBenchmarkPubSubMessageReceive-2   500000          3189 ns/op         223 B/op          6 allocs/op\nSo I don't think this place will be a bottleneck in any setup as node now able to process more than 300k NEW messages from engine on my machine (working in one goroutine, it will be possible to spread a work among workers based on channel name if we need this).\n. As a note, if we need to process messages coming from Redis in different goroutines here is a gist with implementation of this: https://gist.github.com/FZambia/1864a76e9c51f8e3eea5d0f8bdc2f739\n. So after all changes some interesting times, all without connected clients just to show how unnecessary JSON encoding of every message affected performance.\nBroadcast one message into 100000 channels:\nMemory engine:\nmaster branch:\n[I]: 2016/05/19 12:58:36 POST /api/ from [::1]:50040 completed in 744.333891ms\ngogoprotobuf branch:\n[I]: 2016/05/19 12:57:53 POST /api/ from [::1]:50023 completed in 349.8216ms\nRedis engine:\nmaster branch:\n[I]: 2016/05/19 12:58:48 POST /api/ from [::1]:50047 completed in 1.146819458s\ngogoprotobuf:\n[I]: 2016/05/19 12:58:11 POST /api/ from [::1]:50033 completed in 801.090882ms\nPublish 50000 messages in one request into different channels:\nmaster branch:\n[I]: 2016/05/19 13:09:05 POST /api/ from [::1]:50129 completed in 916.376917ms\ngogoprotobuf branch:\n[I]: 2016/05/19 13:06:18 POST /api/ from [::1]:50102 completed in 668.998574ms\nRedis engine:\nmaster branch:\n[I]: 2016/05/19 13:08:30 POST /api/ from [::1]:50126 completed in 10.846997003s\ngogoprotobuf:\n[I]: 2016/05/19 13:07:27 POST /api/ from [::1]:50113 completed in 10.56859332s\nHuge numbers when publishing 50k into Redis because we don't utilize batching for commands in one request (as I wrote here) so we wait for 50k RTT. In practice I dont think someone will send such requests - all publishes will be in separate requests to API.\nAlso the most actual bench of PUB/SUB receive shows this on Mac Pro 2012:\nBenchmarkPubSubMessageReceive-2  1000000          2426 ns/op         232 B/op          6 allocs/op\n. Hello @johndoejdg ! I think that the way you found is the correct one. The core Centrifugo concept is to keep it as separate from application as possible - now Centrifugo knows nothing about application backend. In case of webhooks Centrifugo should at least know URL to POST events to application, should deal with timeouts somehow etc \u2013 these all results in more difficult and unpredictable Centrifugo behaviour which I prefer to keep as simple as possible. At moment it's pretty simple to send such events from client side yourself \u2013 moreover you get request already authenticated by your application session mechanism so no extra need in security checks.\nBtw consider such situation \u2013 you have 50k users online and then something bad happens in datacenter and all clients get disconnected for a while from Centrifugo and then reconnect to it. It will be about 100k POST requests from Centrifugo to app backend in just a couple of seconds - I think for most applications it's a real disaster! Though this is also relevant for sending events from client side (but on client side you actually have more control when to send such events to server and when not - because you know if that disconnect action caused by your client).\n. Hello! Do you use Memory or Redis engine? Is this reproduced all the time?\n. Hm.. Can't find what can cause this bug, and can not reproduce it. Could you post all websocket messages from chrome network console (Network -> WS)? \n. I will also try that particular build as soon as I get to linux machine.\n. Just tried to run on Centos 6 \u2013 works well... Could you also show the output of these 2 commands from machine where Centrifugo running (maybe you are using wrong build for your architecture)?\nuname -a\nand\ncat /proc/cpuinfo\n. Can you write into gitter chat - more comfortable to chat when debugging\n. Could you post all the code? Including new Centrifuge(..., subscription, publish etc? Because join messages use connection parameters. Also websocket frames can provide a great help (https://stackoverflow.com/questions/5751495/debugging-websocket-in-google-chrome)\n. @lmj0011 any news on this?\n. @lmj0011 just reproduced this! will try to fix asap.\n. @lmj0011 hope fixed this in 1.5.1 \u2013 could you check it out?\n. Cool! Thanks for report!\n. Also thought about the same things...There are some caveats with other INFO messages, like logging when SIGHUP received for example - it would be nice to see such messages in production when error level set. This whole levelled logging concept looks broken a bit:(\n. I was wrong about such a big performance impact.. Because I used logging into terminal STDOUT when measuring first time. Just tried logging into file and running wrk (on my old macbook air 2011): 17.5k requests/sec (info) vs 19.5 requests/sec (error level). So just too chatty problem should be considered here. \nBtw for someone interested in measuring on its own computer:\ncentrifugo --insecure_api --log_level=error --log_file=/tmp/centrifugo.log\nwrk:\nwrk -t10 -c10 -d10s -s post.lua --latency http://localhost:8000/api/\npost.lua:\nwrk.method = \"POST\"\nwrk.body   = '{\"method\": \"publish\", \"params\": {\"channel\": \"channel1\", \"data\": \"hello\"}}'\nwrk.headers[\"Content-Type\"] = \"application/json\"\n. Another solution - leave API requests and connections as INFO but make logs like reloading configuration on SIGHUP as critical so it will be visible even on error level. If anyone has problems with this I can add new log level (something like system) for important messages from Centrifugo.\n. @banks just made pull request with this\n. Updated stats in first comment here to reflect final metric names (added microseconds quantity to names) and not confuse someone who will read this pr later.\n. I think yes, something like refreshData option in settings to Centrifuge object? At moment we send refresh POST request with empty body (this line - look at empty {} in _ajax call).\nBut could you first describe your use case? Which data you want to send and why you want it to be in body?\n. Added code for this in last commit. Will release new version after finishing work on #99\n. > Does a channel not disconnect automatically when the refreshEndpoint returns error status?\nCurrently it's implemented in a way that channels continue to be available for a client for some time after error refresh response. This was done to give client a window to rescue its connection from being closed. So after 3 seconds it will try to refresh credentials again. And then after some time (expired_connection_close_delay option in configuration, by default 25 seconds) Centrifugo will close its connection automatically.\nI have not used this connection lifetime feature myself in production apps (and I doubt anyone else used it, so you are first maybe). So I just reproduced your case - looks like it works like it should but some tweaks should maybe be made - I mean should client try to reconnect or not after this, should it continue to refresh credentials or not. What is your thoughts about this - what you expect to happen with such client after its credentials expired (I mean after that window to rescue passed and Centrifugo finally disconnected client)?\n\nis there a way to read the response from the refreshEndpoint, from the clientside\n\nWhy do you want this?\n. Ah you have written why you need refresh response callback in gitter chat - so you want to notify user about this. It's not obvious for me why you want this. What you want to write in this alert? Why user should know about this? Again this feature is not fully investigated - so any feedback is valuable to make it comfortable to use.\n. So added 2 new options to javascript client in 3bd82a - refreshAttempts and onSessionExpired:\njavascript\n// initialize Centrifuge object\nvar centrifuge = new Centrifuge({\n    ...\n    refreshAttempts: 1,\n    onSessionExpired: function() {\n        console.log(\"Dear user, your credentials expired, please refresh your page\");\n    }\n});\nBy default everything works like before - i.e. unlimited refresh attempts and no callback. I've also built js files in master branch - could you test it? If ok we can make new release. \n. Just renamed onSessionExpired to refreshFailed to be more semantically correct - as session could be actually expired before all refresh attempts will be used.  So:\njavascript\n// initialize Centrifuge object\nvar centrifuge = new Centrifuge({\n    ...\n    refreshAttempts: 1,\n    refreshFailed: function() {\n        console.log(\"Dear user, your credentials expired, please refresh your page\");\n    }\n});\n. Released centrifuge-js 1.3.6\n. I almost finished splitting everything on packages - there is pull #112 . I can't say that I achieved all goals during this refactoring but at least Centrifugo got several important improvements I described in pr. Will continue to work on it - hopefully till the middle of November I am planning to make release that will contain this work.\nAs this is Go - it's hard to create easy to use plugin system yet. But at least now Centrifugo will have possibility for extending in some way without needing to support separate code base in fork.\n. @vector090 yeah, it would be nice! After release it will be not so simple to change something in backwards incompatible way so any advices much appreciated at this moment.\n. @vector090 - yes, but in its current state you also need to call creating your custom client connection from server handler - i.e. modify this line. Maybe it would be better to create client register or sth like this to modify default client in main.go file.\n. v1.6.0 released. I want to emphasize though that Centrifugo internal Go packages don't have any API stability promise. We can change its API in any moment when we find something that must be fixed/improved. Centrifugo standalone server is our primary goal.. Sorry for late reply, in vacation currently.\nAs @banks said Centrifugo is just a way to quickly deliver real-time messages to connected clients. Any\nadditional logic should be implemented on top of your application layer. This includes message history, permission check when user generates new event, message acknowledgent logic, sending PUSH messages over APNS or CGM to users which have not acknowledged message delivery in some interval. This is design decision and I doubt it will change. The only way is #100 which can theoretically make it possible to write custom parts.\nHere I see reasonable to add logging messages to TRACE log level just to make debugging easier. Any reliable and legal history handling should be in application. Possibility to use Centrifugo without backend only suitable for demos, personal usage or maybe using Centrifugo as microservice on backend (without real users from the wild connected to it).\n. @sandeep-sidhu sorry that docs are not so clear about idiomatic Centrifugo usage. Will try to find a way to emphasize this. Centrifugo is not a chat solution - it's more general purpose - for all kinds of real-time applications (well, except very dynamic multiplayer games), so it can not provide logic specific to concrete real-time app implementation. Its initial goal was to provide a way to create real-time apps to backends which are not very suitable for this - i.e. synchronous worker-model when lots of persistent connections is a big trouble. So it gives a solution for dealing with such connections and design that allows to implement any additional logic on application backend. Which is pretty flexible in many cases and let to keep Centrifugo core small.\n. Closing this - we are not planning to add this functionality to Centrifugo due to reasons described above. Looks like I will add TRACE logging of messages coming to node (already opened pull request with this) but it's just for debugging purposes - you should not rely on it. Because I can not guarantee logging format. And more important - it's not reliable anyway - we can not say exactly if user have read that message or not - handling this is a task for application.\n. Hello! I think this could be nice... But it could be pretty straightforward to implement if we had no metrics yet. As we already have our own metrics collecting mechanism looks that we need a way to integrate it with prometheus. I never worked with prometheus before so need some help here.\nWe have metrics that we can access from handlers in any time. So we can set prometheus metrics once it requests /metrics endpoint? But it will be anyway code duplication - i.e. we need at least initialize counters, gauges from prometheus client library to get a chance to set them. What to do with our latencies based on hdr histograms that will appear in next release - export them as gauge values?\nMaybe I am missing a better way? Maybe we can just export our metrics in Prometheus format without using their client library?\n. I personally prefer the option to just export current metric values into prometheus format on /metric endpoint - as the text format rather trivial. Duplicating instruments using prometheus client library primitives looks not very elegant. Also looks like we need custom authentication for this endpoint - as far as I understand - Bearer token.\n. @oddurmagg I am in process of refactoring Centrifugo internals, this can take some time as this is quite big job, metrics will be slightly changed too I think - I suppose it will be easier to do this issue on top of those changes.\n. I started to implement this recently and the more I think about this the more I feel that this should not be in scope of Centrifugo core functionality - this is a new HTTP endpoint with its own rules (auth). We already provide a way to aggregate stats over time interval and raw node stats. And API to export them - stats (aggregated info) and node (per-node non-aggregated info) commands.\nI see how this can simplify life for Prometheus users though. Python version of Centrifugo (Centrifuge) had a possibility to periodically export metrics into Graphite. Prometheus also has Pushgateway (https://prometheus.io/docs/instrumenting/pushing/). Maybe we should support pushing metrics instead of introducing new endpoints. On the other side having too much functionality in core for all cases does not seem like a good idea - more code to support, more dependencies. So another solution here - build a tool that can grab Centrifugo metrics and export them into desired destination.\n. @nordicdyno if this integration is so painless as @banks described as option 2 I don't see why we should not do it, but personally I didn't look at this yet - if you can investigate is it really possible it could help.. @nanom1t not sure I understand your question right - you can call this stats API command using any of our HTTP API clients and do whatever you need with metric values - as an example you can send them to Graphite and use Grafana for displaying and alerting, or just analize received values and use any graph display/alerting system you have.. @synw I personally agree that metric collector really should be outside of Centrifugo as we can't support all metric storages out of the box. Prometheus is the only exception here I suppose as it looks like standard for instrumenting Go code at moment. So if it's possible to integrate with Prometheus without extra need to write custom HTTP Request Handler manually - we can integrate with it in the core.. @nordicdyno thanks for your attention to this. Btw there is also node API command that returns raw non-aggregated stats per node - it's not implemented in API clients because it behaves differently (other commands are node agnostic). \nBut looks like it's not very comfortable to start and configure custom proxy just to ask that node command from every Centrifugo node and we need to support this out of the box. Maybe refactoring our internal metrics to use Prometheus primitives - not sure about this though, needs investigation.. Implemented in Centrifugo v2! . Hello, it is serialized using google protobuf format. There is message.proto file in libcentrifugo folder with message schema. \n. I think yes - we can add such option. But we need to know what you are trying to achieve first - looks like you are hacking internals for some reason:)\n. But as soon as you already have Laravel backend why not to just save messages just before publish them to Centrifugo API? If you are using direct channel publish you still can call your custom server side endpoint from javascript. Both ways look simplier and you have more control.\n. Also what is message.history channel? There is no such channel in Centrifugo. Is it your own? Centrifugo uses Redis pubsub for distributing messages in channels among nodes and Redis list structure to keep message history cache.\n. Express or Laravel - nevermind, options are still the same.\ncentrifugo.history.list.centrifugo.message is a list data structure in Redis, it's not a PUB/SUB channel.\n. @lmj0011 any updates regarding this issue?\n. Hello! Thanks for proposal, but here you describe concept different from Centrifugo. \nCentrifugo goal is to be just a server keeping persistent connections that provides a way to communicate with connected users over API - i.e. is more like a transport layer for messages. As soon as something like this added you try to put permission handling from your app to Centrifugo. This is not bad in general I think but this is another software - with persistent store to keep such per-user settings after restart for example. That's rather critical change as now we run without any persistence and I see a great benefit in this.\nIdeas you describe can suit your use case but in general this is a shift towards making Centrifugo chat framework - it's not what I want it to be. Centrifugo does not solve permission problem - it does so because it was a design decision to let application implement permissions/storing. That was an initial idea and it works for many apps. This is also like pusher.com works - Centrifugo has lots in common with that service. From conceptual point of view Centrifugo is done. At least I believe so.\nNext, I don't like an idea of running multiple projects over one Centrifugo you mentioned. Multiple project support was removed in version 1.0 - it's still possible with channel prefixes though and one shared secret key but I prefer each project using its own Centrifugo and one project does not affect other in any way.\n. This is anyway must be done with persistent layer if do this right. At moment loosing all information related to channels (presence, history) is not very critical - presence will be restored automatically after some time, history mostly needed for recover mechanism - so in general apps can tolerate it. \nPermissions you suggest require extra HTTP requests from application backend, so it's not easy to restore them when lost.\nAlso I think it could be rather unmanageable concept (requests from backend to Centrifugo every time user connects/disconnects?) - can result it very hard to find bugs. Various race conditions for example.\n. So you continue to hack into Centrifugo internals right? :) This is ping message between nodes, there is no way to turn it off. \nAs you do undocumented stuff I can only say that you need to filter it on your application level - i.e. just ignore messages from channel centrifugo.control. By the way there are messages that can be published into centrifugo.admin channel - you most probably need to filter them too.\nAnd I can not guarantee that something you rely now won't change in future releases.\n. No, centrifuge-js handles that private channel sign response automatically. In connection parameters you only provide connection token for user - i.e. nothing related to private channel.\nHere what happens:\n- you write js code with private channel subscription centrifuge.subscribe(\"$one\", ...)\n- centrifuge-js understands that you want to subscribe on private channel because it starts with $ symbol.\n- before sending subscription request to Centrifugo centrifuge-js sends AJAX request to your custom application auth endpoint which returns that data you showed above.\n- centrifuge-js after receiving response automatically add that sign into subscription request to Centrifugo. \n. Hello @DeepAnchor ! This is quite a big work because we need to update all our client libraries to support this new serialization format. Do you have a real-life use case where you need this?\n. @DeepAnchor yep, we can leave this open for future, not sure though when this will be done \u2013 so even if your game requires one-way server-to-client push you probably will finish your game till that moment :)\nWhat I thought recently is gRPC for client-server communication. It's not possible to use GRPC from web browser yet but I saw they do a research in this area. But even without browser support I can't say a lot how gRPC fit Centrifugo \u2013 maybe someone with gRPC experience can estimate this?\n. @DeepAnchor after refactoring Centrifugo during last 3 months I tried to investigate how difficult it would be to add new serialization format.  And it's generally possible of course. But it's not simple and there is no clear goal in doing such a hard work -  what to do with clients, which format, who will use it. If someone interested in implementing alternative format and can help with this - me and @banks are open to discussion. Until that moment I think we have to close this.. Let's leave it open.. @DeepAnchor sure you are not waiting for this:) But \u2013 Centrifugo v2 supports Protobuf serialization format - here is Protobuf schema.. @narup hello, glad you like it!\nThere is last question in FAQ covering this - see https://fzambia.gitbooks.io/centrifugal/content/FAQ.html page. Its not reliable to just check if user online or not - because he can leave your app right after that moment. So implementing custom ack endpoint in your backend is necessary - so you can push notification after some interval.\n. Could you explain why out of sync issues happen?\nPublish response only knows that message was successfully delivered to Centrifugo internal engine. For example it means that message was published into Redis channel (in case of Redis engine working). And actually there could be lots of active subscribers in channel. So it does not show was message delivered to someone or not.\n. Just to formulate my ack suggestion into some pseudocode.\nOn client side you write sth like this:\njavascript\ncentrifuge.subscribe(\"channel\", function(message) {\n    renderMessage(message);\n    // at this moment you know exactly that message was read by client.\n    // use application specific message id to ack message.\n    sendMessageAckToAppBackend(message.data[\"app_message_id\"]);\n});\nOn backend you have a message table in database with fields like this:\nMessage table:\nid ...\nbody ...\nauthor ...\ntime_sent datetime\nMessageToUser:\nuser_id ...\nmessage_id ...\nack_received bool\npush_sent bool\nSo when sendMessageAckToAppBackend called you send request to app server and set ack_received for message and that user to true.\nPeriodically you can look at time_sent field and send push notifications to all users with messages that have ack_received == false and message.time_sent < now() - 10seconds. Maybe you also need to check push notification delivery status via notification centers API.\nAs option you can also aggregate messages per user during this interval and send one push to them instead of separate for each message. \nIf you think about reliable push notifications then I suppose you already have something like structure above in your database.\n. Even with groups this looks like one query to database to get all messages without acknowlegement. I would be happy if Centrifugo can make this easier but I just dont see how. Do you have any ideas? What kind of hook you mean?\n. Yeah, I understand that Centrifugo does not solve everything application developers need but at the same time it does not limit final possible application functionality too much - i.e. most of missing features can be implemented on application level. \nAbout callback url - it will be almost the same as hook from client side I described above - we will save only few lines of code that initiates HTTP request that should be written now in browser. One of the advantages of making HTTP request manually from browser (and not from Centrifugo internals) is that you get authorized request in application (by native session mechanism used on your backend).\n. @vpdeva hello! Did you make it work?\n. Hi, this is strange. Could you try to use ttl Redis command to see what happens with time?\nttl centrifugo.history.list.centrifugo.message.YOUR_CHANNEL_NAME_HERE\nIt shows how long Redis will keep that key\n. Another suggestion - maybe you have memory limit in Redis and some eviction strategy? See http://redis.io/topics/lru-cache - so Redis starts to remove keys to find a space for new data?\n. You can also use llen to see that there are still items in history list:\nllen centrifugo.history.list.centrifugo.message.$dev+user3\nDon't know why this could happen at moment - Centrifugo never deletes history keys, just sets expire for them. I tried to push some messages into channel before going to sleep - now in the morning history is correct with correct expire ttl.\n. Maybe sth happens with Redis itself? After loosing history try to run Redis INFO command in redis-cli. It can show some useful info - uptime_in_seconds, used_memory, evicted_keys etc\n. Ah, I am confused a bit - so you found that history_lifetime was set to 1800 seconds which explains why it was cleaned so quickly, right?\nCentrifugo does not limit this value (maybe only by maximum possible integer value which is much bigger than you want to set).\n. Ok, cool!:)\n. Done in #120, it will be released with Centrifugo v1.6.0\nAs this compression feature considered experimental in Gorilla Websocket lib - we also should consider it experimental.\nTo enable raw websocket compression set \"websocket_compression\": true in config file.. @roytan883 as far as I understand there is an option in gorilla websocket lib to disable compression before each message write into connection and then turn it on again. Need to check it though. @roytan883 added websocket_compression_min_size in 3d56eba5f9e57072931c3cad08e51f86cf7e7e18 - default 0 i.e. all messages will be compressed when websocket_compression enabled.. v1.6.0 released. Hi! Yes, let's try to understand why it's going on.\nI experimented on tornado_application from examples repo.\nHere is what request headers contains:\nSec-WebSocket-Extensions:permessage-deflate; client_max_window_bits\nAnd what Centrifugo returns in response (among other headers):\nSec-Websocket-Extensions:permessage-deflate; server_no_context_takeover; client_no_context_takeover\nThe first assumption - maybe you are using SockJS? Websocket compression implemented for pure websocket endpoint only.. Yeah, it's not possible at moment to use websocket compression with SockJS. Because SockJS-go library does not support it yet - it requires to use custom Upgrader in this place (https://github.com/igm/sockjs-go/blob/master/sockjs/websocket.go#L20). I'll try to find a way to contribute ws compression into this library - this should not be difficult as it's using the same lib (Gorilla Websocket) for websockets. But at moment it's not possible unfortunately.. Ah, it's a hard question, I personally never put Centrifugo into projects with such concurrent users amount. So I really looking forward for feedback from you.\nYou definetely need to use Redis engine and balance clients between nodes - don't forget sticky sessions for SockJS transports (needed for all except websocket), it's hard to say how many machines you'll need as it's more about message rate, channel options enabled, amount of users in channels and hardware.\nAt least Centrifugo is not obtrusive and can be easily swapped on another solution if you find better. And of course we can work on bottlenecks you discover if any.\nAt moment largest setup I've heard was 50k users online. Maybe there are bigger numbers but I was never told about it.. Hi! Don't understand what you mean, sorry - need examples:)\n. Ah, actually if @johndoejdg mean log rotation then we already support it in our package distributions: using logrotate. Here is an example logrotate config file. \n. Hello! I see message about slow client in the end. I saw this recently - client tries to establish second ws connection while connecting. I fixed this in version 1.3.8 several days ago - could you try it?\n. Could it be that user still used old js client version because he didn't refreshed a page?\n. Ok, keep me posted, hope the problem will go away.\nThere are some messy Centrifugo logs:  client is closed and error sending to - they are not critical errors actually - they can happen even in normal situation under high connect/disconnect rate (just because of performance considerations we don't want to lock client connection to check if it already closed or not), I'll try to remove them (or make it DEBUG maybe) in next release as they can not help to find problem anyway - i.e. just garbage at moment.\n. Also I see \"history_size\": 999999 in your configuration. Looks like you did this to keep all messages during history_lifetime.\nMaybe I need to change configuration logic a bit and allow to let history_size be 0 and  keep all messages that will be removed after history_lifetime. Will think about this in future releases.\n. You mean recover mechanism? If yes - it already works this way - after page refresh client does not have last_message_id so no need to get history.\n. Maybe this is a real problem with slow client and not even a bug? Default client size queue size is 10 mb, I see that after reconnect client get many join messages and then disconnected. Why there are so many join messages in channel?\n. Could you first disable join_leave and see will it help or not? Also how many join messages per second can theoretically this user receive? In general if you get something > 60-100 of any messages per second per client it's a signal that you should refactor application in some way - as client can not deal with such message amount.\n. > Can I up client size queue manually?\nYes, you can using client_queue_max_size (by default its 10485760 - 10mb). It's undocumented because default limit is more than enough for most use cases. But if the problem here is high message rate per client then increasing client_queue_max_size won't help as client won't be able to handle so many messages anyway.\n. Hm.. You have not so many users and channels to exceed 10mb limit.. this is still a mystery for me - I look at you internet traffic and see 10 mb - from where? Do you have very large messages? Even in reconnect loop clients should not generate such traffic amount..\nBtw! Just have an idea - maybe large history_size causes this? If your app actively used then history channel expire time will be updated every time and messages will be collected as there is nothing limiting them. If you then ask for history you get a very large payload in one message. (history_lifetime is not per-message - it's per channel, just to clean up after channel is not used anymore)\n. What about current history size? \n. No, I mean how many messages currently in channels you use? You can ask Centrifugo via history API call (maybe there are lots of them?)\n. No, I mean this. As you have very big upper limit I think you can have a very large history cache in channels now (you can call it from actions tab of web interface).\n. I suppose it's because the history is very big...Do you use Redis Engine?\n. I suppose it's because the history is very big...\nAh I see on screenshot you are using memory engine, could you make history_size 100 and restart centrifugo?\n. That stats in web interface is an aggregation over minute (by default). History size is not related to amount of queued messages. I think it was just a coincidence in numbers.\nThere is a transport exception in PHP client - please, make sure that you are using correct url (with http or https scheme).\nBtw, look at memory usage - it's now 10 mb (previously you had 400mb - maybe mostly because of large message history)\n. There is still suggestion to temporary disable join_leave - to understand if this is a reason. Btw do you have access to browser console where the problem reproduces? If yes - websocket frames could help.\n. I am not sure this was a problem as we saw \u201cslow\u201c reason in logs. This can happen when client message queue exceeds limit.\n. Could you share your final client code with pings?\n. There was a report via email about similar issue and adding pings solved it too.\nAlso found this interesting topic on Server Fault.\nStill don't understand why there was a slow reason in logs - broken connection on browser side? Need to reproduce this somehow. \nI will add pings to client natively, with some logic to prevent sending ping if any other message was sent to server or received from server to reduce performance overhead.\n. Thanks a lot for a detailed report! Will write here as soon as add pings to centrifuge-js \n. What's wrong with very long connection time? It's websocket connection - it can be open for days, weeks etc\nLet's turn back to join messages then - what's the size in bytes of each join message and is it ok that client receives so many of them after reconnect?\nAlso - how do you get client side logs where the problem reproduces? Is it logging system or you can reproduce it yourself?\n. @johndoejdg can we move to Centrifugo gitter chat ? \n. Let's leave it open until we find a reason\n. Specifically, here is an example of configuration with namespace (more in docs)\njavascript\n{\n    \"secret\": \"very-long-secret-key\",\n    \"namespaces\": [\n        {\n          \"name\": \"public\",\n          \"publish\": true,\n          \"presence\": true,\n          \"join_leave\": true,\n          \"anonymous\": true,\n          \"history_size\": 10,\n          \"history_lifetime\": 30,\n          \"recover\": true\n        },\n        {\n          \"name\": \"gossips\",\n          \"watch\": true,\n          \"presence\": true\n        }\n    ]\n}\nNow use namespaces in your channel names: gossips:channel to apply settings specific to namespace\n. Several more notes: \ndue to Go connection finalizers we already handle closed connections properly. This change is to handle situations when connection not closed actually but client doesn't use it anymore (actually this is a bug in SockJS, but this idle check has no overhead so I thought it would be correct to add it). So it's more a supportive feature for client.\nAlso Centrifugo currently relies on Unix time, we need to migrate to monotonic time in future releases.\n. Hello @siddharthlatest , thanks for suggestions!\n\nThe client libraries require a more involved implementation and depend on a library that manages websockets connections.\n\nI think it's not a big problem - there are robust websocket client implementations for most of languages. \n\nThis affects on the server side too, granted SockJS manages the state, the very fact that you have state makes it hard to scale.\n\nSockJS is optional - it's possible to use Centrifugo without using SockJS - pure raw websockets only.\nNext, API Backend --> Centrifugo side of interactions. Now it's done over HTTP POST request to /api/ endpoint. You want streaming chunked requests to Centrifugo? Why do you need this? I don't see a lot of benefit in it at moment. As far as I understand current approach theoretically allows to use Centrifugo API endpoint with HTTP/2 requests using HTTP/2 client (though I have not tried this myself).\nAlso it's now theoretically possible to interact with Centrifugo API over websocket (like admin interface does).\nNow adding third official way to make API requests does not seem necessary  - we can't support everything.\nOn Centrifugo --> Client side this looks interesting. But I can't figure out how to implement it - i.e. Centrifugo not only publishes message updates to channels but also has some client protocol. So in the end we can end up with something similar to SockJS HTTP transports - we can not just create chunked responses and send messages but also need a way to send protocol specific commands from client to Centrifugo. And this means we will have session state on server again. Maybe you mean something that I have not understood - then please provide more details about this part. \n. But this is how SockJS streaming HTTP transports already work at moment.  So suggestion here is to implement the same SockJS already provides fully in Centrifugo? You already mentioned downsides of this approach - there is a need to keep session state, route requests to the same Centrifugo instance.\nHow about streaming endpoint like this:\nhttps://centrifugo.example.com/client/streaming?user=XXX&timestamp=XXX&token=XXX&info=XXX&subscribe=chan1&subscribe=chan2\nI.e. provide everything we need for subscriptions in url parameters and use that url to establish connection and get updates. But it's not a flexible solution because sometimes there is a need to subscribe on new channel (can be solved ending this request and making new one). Also there are private channels - how to provide private channel sign for channels in this case? Also encode them somehow into URL parameters? Maybe we could use POST request for this and put everything in request body? I.e. JSON like this:\n{\n  \"user\": \"XXX\",\n  ...\n  \"subscriptions\": [\n     {\"channel\": \"chan1\", \"last_message_id\": \"XXX\"}, {}, {}, ...\n  ]\n}\nI don't know is this a good idea as I just invented it - could miss something that makes this impossible to implement. At least it requires a proper consideration. Centrifugo v1.6.0 should be pretty flexible for this as it will allow to create custom servers - will give a way to experiment in  separate repo first with ideas like this.\nWhat do you think?. Pushpin approach looks pretty elegant and project looks good in a whole - I've heard about it but have never read how it actually works before. What you suggest though is not just change websocket transport but add entirely new concept into client-server communication. Actually I think it's possible to implement on top of Centrifugo without many modifications in Centrifugo core - it's just a separate server component (but not simple - there would be many lines of code behind).\nWhat I especially like is how pushpin works with authorization - proxying means opaque client auth.\nIn general I found this interesting. Are there any reasons to not just use Pushpin for your case?\nWhat's good in current Centrifugo approach is how it works with lots of clients. It should not know any application endpoints to send requests to it. This is very good in terms of load handling - what if thousands of connections will reconnect at once - this will end with thousands of proxy requests to your application. Does pushpin has an answer for this?\n. Let's write pros and cons of Pushpin-like approach comparing to what Centrifugo currently has:\nPros:\n More opaque for client - i.e. just an url for updates. And 2 extra-urls for history and presence information that Centrifugo can additionally provide. This means that it's simpler to write new client. Suitable for API design.\n Native authorization.\nCons:\n I think in pubsub systems like Centrifugo client side should decide which channel to subscribe - as it makes things more simple to develop real-time apps. Approach with server-side channel decision is suitable when making APIs though.\n Does this really scale well in terms of client amount - i.e. reconnects can result in many requests to app. Coming from Django world I know that 20k requests in a second will destroy almost every Django app. Centrifugo does not eliminate this entirely as we have private channels that also require extra request to app backend. But for non-private channels there are no extra requests.\n* Not so flexible in terms of dynamic subscriptions/unsubscriptions\nPushpin already does this pretty well as far as I understand. It's language agnostic too, so don't think Centrifugo should step into this area. But let's keep it open for a while to think on this more and for some extra opinions maybe. @banks maybe you have thoughts on this?\n. @siddharthlatest I continue to think about this. it can be combined with new Centrifugo approach to separate servers concept - why not to at least try to add this feature.\nI have several questions to you as active pushpin user:\n\nyou originally said about proxing streaming chunked HTTP requests but not about websockets - do you prefer HTTP? Which proxy transport do you use in Pushpin?\nwhat about cookie authorization used by most web sites - Centrifugo should live on the same domain in this case - how Fanout cloud work then if browser does not send cookies to external domain?\nhow your javascript client library look like? You are just using native browser XHR?. All things considered, Pushpin already does this well and actively maintained. It's an interesting approach to real-time and has its advantages. But maintaining both server types in one software seems difficult, I don't think we should blur Centrifugo focus, at least at moment. Interested parties can build this on top of Centrifugo though with not so huge refactoring.. So my specific concerns about sharding as it currently implemented.\n\nI am not sure I found the best way to configure it. What do you think about current sharding configuration format? It's rather simple and intuitive format I think:\ncentrifugo --engine=redis --redis_host=127.0.0.1 --redis_port=6379,6380,6381\nOr \ncentrifugo --engine=redis --redis_host=127.0.0.1,127.0.0.2 --redis_port=6379,6380\nDo you see better ways? \nMaybe this must be more explicit option redis_sharding which is an array of objects each relating to shard config? We can add this later though and start with this simple format.\nAlso current option parsing relies on fact that application will use the same Sentinel addresses for all Redis shard instances - as Sentinel adresses already separated by comma. If this will be a problem then explicit array of objects for sharding config I described above could help in future. Or we can add some other separator for various Sentinel configuration if someone will have problems with it.. OK, I will fix that piece of code, will leave current implementation for simple setups (as it pretty neat for simple setup). And let's just look how it goes and maybe add something extra.\nBtw there is now a way to setup shards almost like you suggested - using --redis_url=redis://:pass@host1:port/db,redis://:pass@host2:port/db - a bit verbose but will work.\nWill try to finish adding tests during this week. And I think it's time for 1.6.0. It will not work with different dbs currently due to how Redis works with PUB/SUB - unlike keyspace operations PUB/SUB messages propagate to all dbs so centrifugo.control and centrifugo.admin and new centrifugo.ping will propagate to all shards and will be handled several times.. Changes from this branch merged in #125 . Using one channel for announcements (or maybe several channels based on different user permissions) could help - if it's possible in your case of course. Also you can tune history_size and history_lifetime to reasonable values as history in Centrifugo exist mostly for recovery mechanism after short network disconnections - if you need large history then it's better to just use your main app database.\nIf you have 100k users online and broadcast 4kb to separate channels then announcement will take about 400mb of memory. With single channel extra memory usage for history will be about 4kb. So in general we already have mechanism to save announcements shared - shared channel.. I first added bounds, but it seemed a bit strange for me so I removed it leaving printing there to look manually. Resharding number assert in the end at least looks not so magical. That jump consistent algorithm works - for 5 shards the number is about 74% after adding new shard, for 10 it's 80%. I have not compared it with other algorithms though.. @chavenor hello!\nCentrifugo and RabbitMQ are completely different purpose servers. Centrifugo's goal is delivering real-time messages to end users of your application with at most once delivery model (fire and forget in general). It has some mechanisms to recover missed messages after short network disconnects though but it's anyway a best-effort transport. Most of real-time client apps can tolerate this (of course there are exceptions). To ensure guaranteed message delivery to client when using Centrifugo additional work must be done on application backend side when needed. For example sending acks manually to your backend.\nCentrifugo is just a PUB/SUB server designed for client applications, it's not suitable for usage on backend side - for example to coordinate microservices. Rabbit can be used as queue, PUB/SUB broker etc. Generally RabbitMQ is something that Centrifugo could be built on top of.\nCentrifugo has some builtin features to help developing real-time apps - authorization, presence, join/leave events, browser/iOS/Android client library.\nMaybe I have not answered your question - then try to ask more concrete. >  I look forward to getting those performance gains.\nSorry, don't understand  - what do you mean saying this?:). Still don't understand your thoughts about performance - maybe English language barrier. Could you rephrase?  . Ah, comparing to another real-time messaging system. Now I see:) Hope it will really perform better for your case.. Hi! I am not sure that you use Centrifugo right. 30 days is not what it was designed for. I understand that for your use case it could be useful but I don't see much potential in this feature for most users. \nBtw there is no concept of own user channel - there could be several users in channel with # separated by comma.. Maybe having this method in server API only would make sense for applications that need to clear history as part of their application logic (clear chat history for example).. @phouverneyuff maybe you better use different Centrifugo instances in your different setup stages. This feature won't help you at all as it's a per-channel call and Centrifugo has more data besides history - presence for example.. @phouverneyuff without diving deep into your setup have you considered FLUSHDB Redis command when you need to clean your Redis data?. Implemented as server API call in Centrifugo v2:) . web_path is a directory where custom web application lies in file system (path to local app dir from https://github.com/centrifugal/web) - it's not an URL path. \nGenerally you need this option only when you want to use custom web interface (if you adapted it for your needs somehow) or during web interface development process (like I usually do).. @MartinsThiago hello! Yes, the best reliable way to ensure your client received message is sending confirmation ack from your client to your application backend as soon as you processed message coming from channel.. @MartinsThiago you are welcome, btw I currently prepare 1.6.0 release and there is a branch in docs that is not merged yet with updated FAQ - maybe you find it useful.. Hi, Centrifugo logs redis engine options on start - https://github.com/centrifugal/centrifugo/blob/v1.5.1/libcentrifugo/engineredis.go#L186 - could you show that line from logs? Also please provide supervisor config file you use.. Related to pattern-based subs. Just tried to create many pattern-based subs and with relatively few subs (just 30000) connection starts timing out. Looks like O(N) where N is amount of patterns client already subscribed to of PSUBSCRIBE is not suitable for us, especially during reconnect to Redis (resubscribe on channels). So we should stay with SUBSCRIBE. I have not found a beautiful way to do this - what I wrote in description is rather hacky - moving all client subscriptions to central store does not seem to be a right design choice.. Hello! Sorry, this is my fault - just fixed this in 913eef992dae771b37d200480d1101748edbef69, will be released in 1.6.1. v1.6.1 released. Hello!  Yeah, why not, I'll look at this soon. Thanks for suggestion. @ramon-ga just added code into autocert branch, you'll need to add into config file:\njson\n{\n  ...  \n  \"ssl_autocert\": true,\n  \"ssl_autocert_host_whitelist\": \"www.example.com\",\n  \"ssl_autocert_cache_dir\": \"/tmp/certs\",\n  \"ssl_autocert_email\": \"user@example.com\"\n}\nEmail is optional, ssl_autocert_host_whitelist and ssl_autocert_cache_dir optional too but recommended (for security and performance as said here). ssl_autocert_host_whitelist can be comma-separated list of hosts.\nCould you test it with real domain?. Great, thanks for testing!\nThen it will be part of v1.6.1 - I think I'll release it very soon as there are several small fixes already in master. . v1.6.1 released. @manson yes, they should (1 week before expiration). @banks here it is, looking in their limit docs it seems that renew requests does not count rate limit and they have 1 week sliding window for limits. So we have to be very unlucky to hit the limit. Let's make it 2 weeks to remove that probability?. @manson it already works with valid HTTPS certificates (you can make sure trying to send request to our demo instance: https://centrifugo.herokuapp.com/). Please, look at this SO answer. Also I see 8000 port in your request url - is it ok?\nWe also can add strictSSL option (see this issue) but maybe there is a secure way to fix this? . > except it complains on unsecured fonts downloading\ncould you tell which fonts?. @manson this is our public demo: it's secret key is secret :)\nMore specifically about SO answer: could you try to inject CA certificates using ssl-root-cas module as suggested in one of answers?\nAbout port: I have never done it myself, but see this - so maybe you have to run Centrifugo on standard 443 port and the problem will go away?\nSo please try options above.\nI think it's worth adding strictSSL option anyway for self-signed certificate cases in development for example.\nThanks for font warning: this is a bit strange - we have not use any of those fonts explicitly - i.e. I grepped over files and have not found them.. Also I have no such warning on our https instances. Maybe they are coming from one of browser extensions (in Chrome you can try to load a page in incognito mode as most extensions disabled in that mode)? \n. @manson ok, keep me posted, please.\nMeanwhile I released jscent library 0.1.2 with support for strictSSL: false - but hope you will get it work without disabling SSL check entirely... @manson it's theoretically possible and maybe it's possible to adapt our browser client to work server-side too - but I just have no resources to develop and support clients for all backend languages. There is already a way to do some callback action just calling it from client (browser) side via AJAX call for example.\nBtw you can ask questions in our chat on Gitter - https://gitter.im/centrifugal/centrifugo. I have not used grace library (or similar) before and can't say at moment is it possible or not in our case as we work with websockets and SockJS server (i.e. not just using standard lib http server and work with long-lived connections) - need to investigate. If you will have more info about this - please share.\nBtw, at moment Centrifugo handles SIGTERM - it sets 503 on HTTP handlers and gracefully closes active connections with reconnect advice so clients will reconnect to another Centrifugo instance or to this instance when become available.. I investigated this question a bit. As I said things a bit different for long-lived connections like websockets. \nGrace starts new server and waits for active connections to finish on old instance. In our case clients won't finish their connections for days. So we eventually will be forced to close them. And we already do this! The only thing that we dont do at moment is draining connections - i.e. send all messages from client queues before closing connection. This was suggested by @klauspost a long time ago but I decided that it was overkill at that moment and there was a way to lose some messages anyway during reconnect - so we put only parts I described in previous comment into shutdown process. Now with message recovery mechanism connection draining on shutdown makes much more sense so I'll try to think about this.\nHere is some useful links to read on this topic that I found while searching for approaches:\nhttp://stackoverflow.com/questions/38194137/graceful-restart-of-a-server-with-active-websocket-connections-in-go\nhttps://github.com/golang/go/issues/17721\nSo looks like we already do almost the best possible effort here... \n. Hi, it's possible, this command works nice for me:\ndocker run --ulimit nofile=65536:65536 -e CENTRIFUGO_SECRET=mysecret -p 8000:8000 centrifugo/centrifugo centrifugo\nConfiguring via env is not flexible enough - as it's not possible to create channel namespace config. But maybe for your case it's OK.\nI can't help you with compose at moment - what's the actual problem you came across? Env vars not set at all?. You are welcome! Btw --web must automatically enable admin socket so you don't need to provide --admin option (as web interface useless without admin socket anyway) - but this is a bug in 1.6.0 - I'll fix it in 1.6.1. v1.6.1 released. Done, will be released in next version.. @banks thanks a lot for checking this out!. Hello, yes, this is correct.\n\nIf it's possible it will be perfect to use it with the packages for ex. ubuntu.\n\nCould you explain what you mean here?. Why not to use SSL server only? I mean that most services in the world now forcely redirect http traffic to https, the same relates to ws  --> wss I think. . Thanks for a report!\nDo you use latest javascript client? Could you try to reproduce this when ping: false in js client options?. Yeah, I see a problem - it's introduced with 1.6.0, will fix it very soon, until that moment you can use ping: false to avoid such disconnects.. @johndoejdg fixed in 1.6.3, many thanks for your detailed report\nAlso I suggest updating centrifuge-js to version 1.4.2 for those who use SockJS polling transports.. @ramon-ga this is where SockJS can help maybe? We can't just fallback connection to HTTP as it's a stateless protocol and requires more care to keep connection session and require sticky connections - what SockJS already solves.\nAnd btw - looks like you use Centrifugo < 1.6.3 right? In Centrifugo 1.6.3 error from connection handshake goes to DEBUG level log so you won't get so many entries by default. I also suggest updating to Centrifugo 1.6.3 - see its changelog to see why.. @ramon-ga yes, this comes from Go standard lib - looks like we can't catch it - will try to investigate from where it come and is there a way to avoid flooding.\n\nSo there isn't a solution for older systems out of the box.\n\nCentrifugo supports SockJS out of the box to deal with old browser clients.. @ramon-ga btw, you are using Go for TLS termination work right? Maybe putting this job on Nginx will allow to deal with such cases? \nUPD.: Actually I am not sure that SockJS will help in this case (if still using Go for TLS job) - as it will fall back to https which most probably result in the same error. Also I have a suggestion that disabling HTTP/2 could help. You can try to run Centrifugo with HTTP/2 disabled using environment var GODEBUG:\nGODEBUG=\"http2server=0\" ./centrifugo ..... @ramon-ga thanks for such a detailed investigation. During last day I also found mentioning this in  Caddy repo and this discussion - sure you also saw this. But it did not helped me a lot in understanding how to fix this especially now after you tried PreferServerCipherSuites and setting cipher suites manually.\n\nMaybe a fallback connection to http?\n\nSorry, I misinterpreted your words in issue description yesterday - so my words about SockJS were not helpful in any way. I suppose now that you meant fallback to plain ws instead of wss. But this anyway looks like a hack (and I don't really see how this could be implemented on client side) that eventually can lead to more issues.\nIt's hard for me to help with this a lot as I can not reproduce this, if you will find a simple way - please tell me.\n\ncentrifugo 1.4.1 there is a better compability with older browser\n\nIt was built using older version of Go - so yeah, something could change. It's still possible to build Centrifugo using Go 1.5 : GO15VENDOREXPERIMENT=1 go1.5 build. But it's just to try maybe, that go version anyway already deprecated.\n\nOn my other golang http server, this error will be catched by the logging package\n\nYeah, I think we can redirect those messages in our log, but what do you think is the appropriate level for them - debug, info, error? Semantically those messages are always errors so we can redirect into ERROR log. But will this save you from log spaming?\n. What could be helpful in this situation is understanding what cipher suites client sends when such error happens. But without adding more logging into go std lib or using wireshark/tcpdump I don't see how to see this information.. > With this i can reach about 250k Clients (or more), with a proxy in front the maximum client amount will be the half..\nJust out of curiosity. This looks like a very huge number for a single server. Have you already tried this with Centrifugo? And have you already experimented with proxy in front?. Ah! I now remembered that issue, interesting - that was so long ago, happy that you are still using Centrifuge/Centrifugo. Thanks for sharing details - this looks incredible.\nStill question about log level you prefer I redirect errors coming from Go std lib? We can make them info so error Centrifugo log level will suppress them.. @ramon-ga made std lib logs go to INFO in this commit https://github.com/centrifugal/centrifugo/commit/ee82b1ae884cc8de2cf4e4cde0f4f7cb8468e380. > Interesting is on this part, the cipher list on ssllabs did not change after i change this\nThis is really interesting, maybe ssllabs caches results for a while?. @ramon-ga just found this topic - looks like old Chrome on XP uses RC4 suites which considered insecure. See this line of Go source code: RC4 suites disabled by default. As far as I can see you tried with TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 but not with TLS_ECDHE_ECDSA_WITH_RC4_128_SHA, TLS_ECDHE_RSA_WITH_RC4_128_SHA, TLS_RSA_WITH_RC4_128_SHA.. @ramon-ga investigated a bit with SSLLabs and real domain, here are results of simulated handshake from Chrome 49 on win XP SP3:\n```\nSupported: []uint16{0xc02f, 0xcca8, 0xcc13, 0xc014, 0xc013, 0x9c, 0x35, 0x2f, 0xa}\nPreference: []uint16{0x5600, 0xc02f, 0xc02b, 0xc030, 0xc02c, 0xc011, 0xc007, 0xc013, 0xc009, 0xc014, 0xc00a, 0x9c, 0x9d, 0x5, 0x2f, 0x35, 0xc012, 0xa}\nStart setting: 0xc02f for version 0x303 \n!rsaSignOk\nStart setting: 0xc013 for version 0x303 \n!rsaSignOk\nStart setting: 0xc014 for version 0x303 \n!rsaSignOk\nStart setting: 0x9c for version 0x303 \n!rsaDecryptOk\nStart setting: 0x2f for version 0x303 \n!rsaDecryptOk\nStart setting: 0x35 for version 0x303 \n!rsaDecryptOk\nStart setting: 0xa for version 0x303\n!rsaDecryptOk\n```\nAs you can see there are actually lots of matching cipher suites but none of them set by setCipherSuite function.  You can see reasons of why continue in that function was called in log above - i.e. all of the rejected by logic described here. . @ramon-ga I don't see any solution at moment. Using Nginx can help - but maybe not if there is a real problems with client TLS. Maybe the error is deeply inside Go - but I am no qualified enough in this area at moment to say exactly. Actually we can try to use SSLLabs to test TLS with Nginx in front - I have not tried this when experimenting with Chrome 49 XP SP3 handshake.. @ramon-ga just run ssllabs over our demo https://centrifugo.herokuapp.com - it uses Heroku proxy for TLS - there is no problem with Chrome 49 XP SP3. Only IE6 on XP failed during handshake. So yes - Nginx can help. The reason here is Go tls module - but hard to say is this bug or not.. @ramon-ga I posted question to golang-nuts - hopefully someone strong in TLS can explain this behaviour.. @ramon-ga I\u2018ve just tried running Go TLS server with trial certificate issued by Comodo - and it works on Chrome 49 XP SP3. So seems that the reason here is in certificates issued by Lets Encrypt. Dont think we can do much in this situation - consider dropping support for old clients like this or using another certificate authority.. @ramon-ga wow, you did brilliant research! \ud83d\udc4d  Of course we can add both changes.\nI think ForceRSA (autocert_force_rsa) must be configurable and off by default to mimic std lib behaviour and to preserve our backwards compatibility. And sth like ssl_server_name for sni problem as looks like we also have to add it to our non Let's Encrypt https server here. @ramon-ga thanks for your work here! see release notes for v1.6.5. @ramon-ga this looks like Go issue as panic happens inside HTTP/2 implementation.\nSee https://github.com/golang/go/issues/17868 - this commit most probably solves panic - but it have not been included into recent 1.7.5 for some reason.... @ramon-ga commit 329fe3533f039729695a377321ea9e17b9661cd0 should fix it. @ramon-ga could we wait for a couple of days until Go 1.8 out to make new release? It will contain fixes for this panic so no need to use x/net/http2 lib. @ramon-ga released v1.6.4 using Go 1.7.5, new release must fix this issue - feel free to reopen in case it does not.. For uptime seconds it makes sense. Regarding detailed channel information - there could be tons of channels actually, maybe in your case you have tens of them, but some have thousands, another reason agains is that channel is a dynamic ephemeral thing that could be created on the fly. Due to these reasons we can't add this type of info to metrics.. @joshdvir hello, do you mean timestamp in connect client to server message? It's not needed in insecure mode. Or you mean timestamp in every broadcasted message - if yes it's not related to security - it's a Centrifugo server time when every message was created.. Actually this was added in Centrifuge (written in Python) after feature request in issue, so it was migrated into Go server version to preserve backwards compatibility. I've never used it myself so I'd be happy to remove it. If someone needs timestamp - it can be added into message payload.\nBut this is a breaking change for those who rely on it somehow. So at least we should wait with this for a while to collect opinions against removing it, then deprecate it in release notes and then remove. I'll change title of this issue to be more precise and let's wait.. @banks thanks for looking, will try to write test for this scenario before merging.. Hi @arleincho \nCPU usage is a one time snapshot - it can be less during the minute. Look at top command to see how it behaves.\nI suggest you to disable join_leave option and see the difference first.\nNext step is showing output of stats command from actions tab. \nAnd finally you can start Centrifugo in debug mode:\ncentrifugo -c config.json --debug\nAnd then get cpu and memory profiles to get an exact understanding what is the reason of high CPU usage (it will take 30 sec):\ncurl http://your_centrifugo_address:8080/debug/pprof/profile > /tmp/cpu_profile\nAnd memory:\ncurl http://your_centrifugo_address:8080/debug/pprof/heap > /tmp/heap_profile\nThen send resulting files to me (as file attachments) and I'll look at them.\n. Let's continue our discussion on Gitter - at moment this looks like abnormal Centrifugo usage with storm of heavy presence requests. Will reopen if we find that the problem is in Centrifugo itself.. @mkevac thanks for report! That's because web interface tries to show those endpoints based on browser url - before adding different ports for different handlers options (--admin_port and --api_port) it worked pretty good, but now we have to find a new way to deal with it.. Looks like the best solution will be just remove those lines from web interface as they can be confusing sometimes and better document those endpoint addresses. \nEven if rely on configuration options coming from Centrifugo we won't be able to show correct endpoints as depending on proxy/load balancer setup connection/api domain addresses can differ from admin web interface address. Also we can't say exactly should we use ports from config in these lines or omit them because Centrifugo behind Nginx for example.\n. Added more docs about endpoints and port configuration.. @mkevac just released v1.6.5 with changes - there are no connection endpoints shown anymore.. @arden hello! \njoin and leave events (messages) generated automatically when someone subscribes (join message emitted) to channel or unsubscribes (leave message emitted) from channel.  You don't need to do this manually. You need to turn join_leave configuration option for channel namespace where you want it to be sent.\nI can't help with iOS client a lot as I am not Swift programmer, but I opened an issue and asked client author about how to set join and leave handlers.  . @arden not at moment, because Redis Pub/Sub does not scale in cluster which is critical for Centrifugo as we are pub/sub system. We support client side Redis sharding by key though as written in docs. . @phouverneyuff thanks for suggestion.\nI am not enthusiastic in this idea. IOT world needs reliable delivery for many tasks. How do you plan to build this on top of at most once transport like Centrifugo?\nMQTT for example has three QOS levels - at most once, at least once, exactly once - we already support at most once and our internal protocol is actually very similar to MQTT. Other QOS-levels can't be built on top of Redis PUB/SUB without additional logic in Centrifugo code and fully in-memory model. Do you have any concrete proposal on how to solve this? Personally I don't see such a way.. If you take over on this and come up with proof of concept then it will be worth considering. Until that moment my opinion is that you should not try to use Centrifugo for areas where more suitable solutions exist. I can be wrong and there is an elegant way to build such engine that will solve your needs somehow (btw you have not even described what properties you want from Centrifugo here - maybe you already can start using Centrifugo for your task) - but without concrete proposal and how it will fit current design, detailed description of benefits this is not what I want to promote to Centrifugo at moment.. Yes, it's possible to create channel that can only be used by 2 users (points). I suppose your question is about security of channel between 2 points. There are several ways to achieve it:\n\nuse private channel (starting with $) - every time user will try to subscribe on it your backend should provide sign to confirm that subscription request. More in docs\nnext is user limited channels (with #) - you can create channel with name like dialog#42,567 to limit subscribers only to user with id 42 and user with ID 567\nfinally you can create hard to guess channel name (based on some secret key and user IDs or just generate and save this long unique name into your main app database) so other users won't know this channel to subscribe on it.\n. Also added this to our FAQ. @arden yep, thats right. Btw please read our FAQ in docs - there is a description that publishing directly from client is not an idiomatic Centrifugo usage. But if you still need to publish from client then yes - you should subscribe first. And also publish option for channel namespace must be enabled.. @visrs hello, as far as I can tell this happens when we are trying to send messages to already closed connection. So these messages are not actually errors. Maybe we should make them debug level in next release (I will investigate what can we do). Use log level error to avoid such messages in logs for now. Btw - is it raw websocket or SockJS connections?. Have you increased open file descriptors limit?. Looks ok. As I said above these lines are not errors and do not indicate that sth wrong - in new releases we moved them to debug level so you won't see them by default. What makes you think that your instance can't support more than 1200 connections?. Looks like network problem, maybe with proxy before Centrifugo - could you describe your setup in detail in our gitter chat ? I need as many detail as you can provide to help.. > how many connections one centrifugo process max support\uff0ci want to know\n\nSee FAQ. @visrs any update on this? I can't help without knowing details.. Personally I've never used jMeter. To emulate many connections in development environment you can use our connections script, it's written in Go so you need Go and some dependencies installed.. @visrs - closing this as this is not a real issue anymore - this looks like chat between two of us, so please ask questions in our gitter chat, it's hard for me to understand what you mean sometimes - please try to write with more explanation to overcome the language barrier:) . The same as #157 . Hmm, looks like you are using old Centrifugo version right?. Closing as duplicate of #157 . I also suggest you to upgrade to latest Centrifugo version.. Duplicate of #116 - use logrotate for this.. Thanks for looking, Paul!. hello @liughost ! What do you mean exactly - what is room monitoring? . @liughost admin interface in pretty primitive, it allows only basic things. For example it's possible to monitor messages in channels with watch option set to true. But if you need to monitor specific channel then admin interface can be not a very suitable thing as it does not support any sort of filtering - you will see messages from all \"watched\" channels. Solution depends on actual task you want to solve - maybe admin capabilities are enough for your case, maybe you should build sth custom on top of Centrifugo.. @liughost hope answers helped you a bit, feel free to reopen issue and ask if you need more explanation - also knowing more context always helps to give a proper answer.. @banks yep, it definitely made performance worse - in case of node reconnect it's the same because batching still used, but normal client subscriptions not batched anymore unfortunately. Maybe it's still possible though but just to quickly fix a problem.. On the other hand we never met problems with this in real life.\nI have not found the exact reason - after several disconnects in a row looks like sth blocks (blocking channel send?) - I experimented with 100k resubscriptions every time on node start, tried to find a problem and fix it but gave up after several attempts and decided to rewrite. I think that we need to handle e.subCh channel overflow situation (so subscribe/unsubscribe will block) - it won't be too visible on practice I suppose but better to handle this - maybe just return error?. @arden hello! yes, it can. @sergunich hello, a very nice question. The answer is not simple. First thing I can say is Centrifugo approach for message recovery is just a best effort, there are no strong guarantees so you can't use this mechanism for critical data. As option you can configure your history_size and history_lifetime out of your message rates - maybe there are acceptable values for these options.\nFor critical messages you can only rely on your application backend as the only authority. I.e. think about mechanism to ask for missing messages from backend every time subscription successfully resubscribed.\nCentrifugo has a field in it's internal protocol which indicates whether Centrifugo think that all messages were recovered after reconnect or not. So theoretically if we make it public it can be a signal that you need to ask your app server for missed messages. You can find how that flag is set looking at this function - second returned value is recovered flag in subscription response I speak about.\nIt can sometimes return true when subscription request contained last message id and we found that id while iterating over history. In cases you described it will return false. Actually relying on this flag can slightly reduce amount of requests that you should do to your backend to get missed messages after each successful resubscribe. But it's impossible to say how strong this reduction will be as it heavily depends on application nature.\n. @sergunich let's clarify API before I'll add it to Javascript client. With exported recovered flag it will be possible to rely on it in this way:\n```javascript\nfunction handleSubscribe(ctx) {\n    // Called every time subscription succeeds - including resubscribe after reconnect.\n    if (ctx.isResubscribe && !ctx.recovered) {\n        console.log(\"you need to restore messages for channel from app backend\");\n    } else {\n        console.log(\"no need to restore state for channel \" + ctx.channel);\n    }\n}\nvar sub = centrifuge.subscribe(channel, handleMessage).on(\"subscribe\", handleSubscribe)\n```\nIs this what you expect?. @sergunich yep as @banks noticed, relying on this still does not guarantee that all messages were perfectly recovered - this can only be a trade-off you can accept assuming that in normal workflow most messages have not been lost somewhere and no race conditions happened. So asking backend is still the most reliable way.. @sergunich I am a bit busy at moment, will try to add this into client before next week. \n@foobargeez  it's a bit difficult to add protocol features into mobile clients as I can't do this myself - but I'll open issues in both as soon as js client will support this. Actually our iOS and Android clients lack some features. They were contributed and now supported by community members. I work on https://github.com/centrifugal/centrifuge-mobile to at least provide generated from Go code Java and Swift full-featured client bindings - this is a work in progress and very experimental but at least I can work on code myself.. @sergunich just released centrifuge-js 1.4.6 - please check it out.. @sergunich looks like you are not using namespace user for which recover option is enabled: your channel is user#2 right? To use namespace it must be sth like: user:user#2. Welcome:) Can we close this then?. @foobargeez hello. I think I don't understand - what is the disadvantage of calling backend explicitly for messages when recovered is false?  You can call backend and then start backfilling messages posting them to client channel like you suggested (but I'd just return all messages in response to backend call). For me this is the same what you suggest but without extra magic message posting into channel and without involving Redis.. I understand that having RPC built into real-time framework is a huge win - you provide a builtin way for users to utilize already setup websocket connection to call backend functions. But this is OK for framework - you can register your backend-side functions leveraging deep integration of real-time framework with your application code. \nBut Centrifugo can't be a framework as it was designed to work with all backend languages. Calling backend function in this case is not just a delivering RPC message from client to Centrifugo but also asking backend over HTTP from Centrifugo side then - I see some disadvantages in this approach:\n\nlonger way for message to travel until we get response - instead of 1 RTT to backend we get 2 hops from client to Centrifugo, then from Centrifugo to backend and then back. Having this feature in Centrifugo looks as making our users using anti-pattern where it's possible to just explicitly call backend for RPC-like information. Especially with HTTP 1.1 connection keep-alive and HTTP/2 this does not look like a huge overhead.\nat moment Centrifugo has no knowledge about application backend at all - even URL address, I think it's a good thing to have this loose coupling and want to keep this this way until possible\nthe fact that you won't deal with timeouts means that Centrifugo will need to deal with them and other HTTP handling stuff - this is additional proxy logic in Centrifugo core I'd like to avoid - I like current one-directional data flow concept from app backend to client through Centrifugo\n\nDoes it make sense?\nAlso have you looked at Pushpin - it looks like real-time proxy that maybe better suits your needs.\n. Closing after discussion here and in Gitter - currently there are no plans to provide reliable message replay from persistent store directly in Centrifugo core. At moment this can theoretically be another system near Centrifugo (to reuse in many apps) or just a specific application backend. Maybe in future we come back to this topic, will see, the idea described in this issue is reasonable but I don't see a straight way to implement it on top of what we have now.. @chelkaz hello! From what you've posted I suppose you actually successfully started Centrifugo but port 8000 not available from outside - maybe it's closed by firewall. Try asking 8000 port from inside the Centos 7 machine:\ncurl http://localhost:8000/connection/info\nOutput should be like:\n{\"websocket\":true,\"cookie_needed\":false,\"origins\":[\"*:*\"],\"entropy\":943439154}. Cool! So depending on your preferences - try to open port 8000, or proxy requests from already open port (maybe port 80 already open) to Centrifugo using reverse proxy like Nginx (we have Nginx configuration example in documentation), or you can just start Centrifugo on port that is already open changing --port flag.. @chelkaz just add port and web related options to Centrifugo JSON config file (/etc/centrifugo/config.json) instead of using command line flags:\njson\n{\n    \"secret\": \"XXX\",\n    \"admin\": true,\n    \"admin_password\": \"XXX\",\n    \"admin_secret\": \"XXX\",\n    \"web\": true,\n    \"port\": \"8000\"\n}. @synw thanks for contributing, good job! I'll look at this tool and create an issue with feedback. And then I think we can add a page in docs with a list of community-driven Centrifugo-related tools and libraries.. @synw just created a new section in documentation - please feel free to add there other projects you built on top of Centrifugo.. There is no subscribe in server API clients - server API clients were created to work on prefork-model framework side, there is no way to handle async subscriptions. And actually in normal flow all messages flow through backend so it have all messages anyway. What is your specific use case?\n\ndoes the client need re-subscription when shortly disconnect? because the mobile network can lose connection and reconnect frequently.\n\nYep, it does - after disconnect Centrifugo node cleans client connection info, and actually client can then reconnect to another node. Do you know a better way?\n. > \"there is no way to handle async subscriptions\", it confuse me.\nI supposed you wanted to subscribe on channel and handle new messages on server side - so I answered on that, now I see that you are speaking about different thing - controlling client subscriptions on server side.\n\n1, client userA -> backend(join groupA)\n2, backend -> userA (join groupA OK, now you should subscribe groupA)\n3, client userA -> centrifugo (subscribe groupA)\n\nDo you mean only private channel subscriptions (because subscribe on normal channel does not require 3 steps now)? Or all subscriptions including non-private channels? I suppose you mean all subs because you said that client can be fully passive.\nSome thoughts about caveats of approach you suggest:\n1) Centrifugo should keep a state of user-channel subs in this case. And this state must be persistent as connection can live forever. So Centrifugo could restore client subscriptions on reconnect - this is what Centrifugo allows to avoid currently - subscriptions are self-managing.\n2) How about recovering missed messages - who will send a last message ID - now it is sent in subscription request\n3) It's not very flexible for big applications where client-side components can now subscribe from various parts of application, with your approach all client subscription logic must be concentrated in one place on backend. You need to maintain subscriptions on server side while now for most use cases this can be done in one line on client centrifuge.subscribe('channel', callback).\n. @roytan883 I think APNS analogy is not very correct because in APNS channel is just an app installed on device (device token is like channel) - so every message sent to APNS with device token will be delivered to app. You can do the same with Centrifugo subscribing on just one private channel.\nI still have a question about how you imagine clients will reconnect. Consider this situation:\n1) You have 10k clients online - all of them subscribed a month ago\n2) They all need to reconnect (reason: network glitch, Centrifugo restart etc)\n3) They reconnect to Centrifugo - but they won't receive messages because backend did not say Centrifugo which channels correspond to clients. Centrifugo does not have this information - because client channels are app specific. So every time clients will reconnect they should anyway send message to your app backend so backend can subscribe them to correct channels sending subscribe request to Centrifugo? If yes - this destroys your arguments about battery usage and traffic - you will have almost the same as we have now. Maybe I miss something?\n. @roytan883 let's summarize, in current scheme you only need a server side call to subscribe client on channels. Because actually Centrifugo should not hook your backend - you can hook your backend from client on connect, reconnect events yourself via backend.getMissedMessages() call you described above.\nEvery client has it's client ID issued by Centrifugo on connect, so call from client to app backend must be backend.getMissedMessages(CLIENT-ID), because subscribe request from server to Centrifugo should look like this:\n{\n  \"method\": \"subscribe\",\n  \"params\": {\n    \"client\": \"CLIENT-ID\",\n    \"channels\": [\"channel_1\", \"channel_2\"]\n  }\n}\nSo Centrifugo could subscribe this particular client to channels. Note that we can't operate with User IDs here - only with Client IDs.\nOn every client reconnect you do the same steps - i.e. calling backend.getMissedMessages(CLIENT-ID) with new Client ID\nIs this what you expect?. See my post above - we can't operate with User IDs here - we must subscribe per client (per tab in browser in other words) - because the same user can see another page in other tab of  browser and not interested in events for another page. For unsubscribe usage of User ID is valid.. > I don't get it. you said the same user, so when user subscription changed, it should sync with user's all client.\nIn general it should not. Imagine a web site where several absolutely different pages exist. On one page (PAGE_1) we show some sort of user schedule (calendar), on another page (PAGE_2) we show comments to some post. On PAGE_1 user must be subscribed only on CHANNEL_SCHEDULE, the same user on PAGE_2 must be subscribed only on CHANNEL_COMMENTS_FOR_SOME_POST. If you subscribe user on all possible events on your site it will receive tons of unnecessary messages that he/she currently does not actually need to handle.   . @roytan883 you asked @manson how client can subscribe on topic-1. You can implement it this way:\n1) Have a channel named topics-USER_ID (client always subscribed on it)\n2) As soon as client have to subscribe on channel topic-1 you should send special type of message to channel topics_USER_ID (client already subscribed on it). This message can look:\n{\n    \"event\": \"new_topic\",\n    \"data\": {\n        \"channel\": \"topic-1\"\n    }\n}\nAnd then you can programatically subscribe on channel \"topic-1\" - this is how client can discover new channels to subscribe.\n\nlike i use Skype , if i joined \"group-family-1\" ,\"group-company-1\", \"group-friends-1\" . If currently i'm at group-family-1's chat page sending or read messages. Meanwhile \"group-company-1\" and \"group-friends-1\" has new messages published, should i receive those new messages?\n\nI have not said that you always need to subscribe on one channel only - subscribe on many! If new chat created you previously not know about - send it to topics_USER_ID channel I described above and subscribe on client side. . @roytan883 This subscribe command won't work for everyone (due to examples me and @manson gave above when client needs a subset of subscriptions at moment, if you don't understand those points think about Reddit with millions of posts - you really don't need to see all messages from every post - this is just impossible) but I understand how it can simplify your case when you want to write less code on client side. Let's experiment with this topic before coming to conclusion.\nOne challenge I see already is adding method to listen for all messages to our client libraries - but this is programming task, not architectural. Some design problems can araise during these experiments - will see.. @roytan883 thinking more, imagine many Centrifugo nodes with 100k clients on each. If they all need to reconnect (Centrifugo restart) they will reconnect almost immediately.\nIn current approach:\n1) If channels are public no requests will be made to server backend at all (and I consider this is a main Centrifugo feature, most use cases are ok with public channels)\n2) If channels are private - 100k requests will be sent to backend requesting channel sign, and then 100k requests will be sent from client to one Centrifugo node to actually subscribe on channel (actually requests will be spread over Centrifugo nodes cluster). \nIn your approach:\n1) After reconnect every client will issue a request to your backend - i.e. 100k requests in any way\n2) Then 100k requests from backend to Centrifugo\n3) Then every subscribe command should be broadcasted to other Centrifugo node because user can be connected to any node - i.e. 100k publish operation in Redis. And then all those messages must be received and processed on every node. I think this is not scalable.\n. @roytan883 I have a strong feeling that in PUB/SUB system client must control what he want to receive. This is how all PUB/SUB systems work. Decoupling publisher and subscriber is what PUB/SUB was invented for. \nI see your points about some savings (traffic and client simplicity benefits) but if we think deeper we will see that every server-side subscribe command must be reliable - we can miss messages, but I think we can't afford a system in non-deterministic subscribe state. This non-deterministic state will appear as soon as we will share subscribe commands across Centrifugo nodes cluster. As this is done via non-reliable Redis PUB/SUB mechanism we can't guarantee clients will be subscribed on channels they must be subscribed to. Subscribe command can be lost somewhere on its way. So in any given moment we can't say exactly what's happening with client subscriptions. This can be an acceptable trade-off for you but once I add this into Centrifugo other people will start using this too and I have to deal with this and with all problems this can introduce - I feel that this can be a wrong step for Centrifugo.. Hi! stats command returns an a aggregation over minute. During minute stats metrics have the same values.\n\nwhy the web stats is not: 500, 50000, 50000 ?\n\nBecause queued and sent include other type of messages - connect response, subscribe response etc\n\nis the stats will be clean interval ?\n\nYep, every minute counters start from zero. There is node command that returns raw metrics from a node - web interface does not have it because it returns only current raw stats on concrete node and can't be used from web interface (as it connects to random node if behind load balancer).  \nYou can try node command from console, first start Centrifugo in --insecure_api mode:\n./centrifugo --insecure_api\nThen\ncurl -s -X POST -H \"Content-Type: application/json\" -d \"[{\\\"method\\\":\\\"node\\\",\\\"params\\\":{}}]\" localhost:8000/api/. It's already possible to do  in one request using array of commands:\njson\n[\n  {\n    \"method\": \"presence\",\n    \"params\": {\n        \"channel\": \"CHANNEL_1\"\n    }\n  },\n  {\n    \"method\": \"presence\",\n    \"params\": {\n        \"channel\": \"CHANNEL_2\"\n    }\n  }\n]\nThis is a bit more verbose than what you suggested of course - but I don't think we need to optimize this until someone will have real problems with it.. @LopatkinEvgeniy hello, thanks:)  I agree with second change, but prefer to avoid using defer when adding a message into queue. Can we leave only loop change here?. I am not an original author of this code - you can see a reference to this post in source code. This is an adapted version of queue described there. Regarding to your question:\n\nWhy you increase size in method resize? I think would be better to increase capacity.\n\nBecause To increase the capacity of a slice one must create a new, larger slice and copy the contents of the original slice into it. - see this post. \nAlso resize works both ways - to increase and decrease size - if we were using slicing when decreasing we still have a reference to an underlying array which can't be garbage collected.\nI don't want to refactor queue implementation until it will be a bottleneck or have any known problems as it's rather important and stable part of Centrifugo.. Cool, thanks \ud83d\udc4d . @libsgh hello, it\u2019s not possible:) actually I never met this requirement before, what is your use case? I suspect that if you need this then you maybe trying to use Centrifugo for a wrong task.. I can't help you much because you have not provided enough details for me to understand your use case. You should rely on your backend to recover missed (offline) messages when client opens a page/app first time. Centrifugo keeps a history in channel for at most history_lifetime period set in namespace config - this lifetime is only for preventing memory leaks when you have tons of channels (as we keep them in memory or Redis process memory) - so you should choose a reasonable time that suits your app. There is no way to set TTL per message and I still don't understand why you need this.. @libsgh please reopen in case of new info or question. Sorry for delay - actually I commented a month ago but have not noticed that I have to push submit review button - and all my comments were invisible for all that time:). @msaranas hello, just started wiki and added page for developers there - should I add some more info?. @msaranas looks like you have a mess in directories at moment. This can be related to Gogland somehow - I never used it yet, so hard to say. You can start from scratch without using Gogland - just in your terminal. Also note that code should be located inside your $GOPATH dir: $GOPATH/src/github.com/centrifugal/centrifugo. @msaranas great, happy coding! \ud83d\udc4d . Thanks for looking! \nI also don't like a lot current server/httpserver packages - there is currently a possibility to run many servers now (and register custom in main file) but I think this was an unnecessary thing... Maybe in future I'll try to get rid of this complexity and leave only one server so we can concentrate only on it.. @msaranas if I understood you right you can do this by serializing message into protobuf using our protobuf schema. But doing so you are hacking into Centrifugo internals - where no backwards compatibility guarantees exist. This way you also lose some channel related Centrifugo features. \nDo you have control over c# application? What about sending directly to Centrifugo from it using native Centrifugo API?\nYou can also create simple proxy to listen to Redis PUB/SUB and redirect received messages to Centrifugo API.. You said that you have no control over c# app - why do you need client implementation then?. Got it, you have 2 options:\n1) Implement C# API client (we have no one yet) - this is not difficult, it's just properly made HTTP POST request with sign - you can look at existing clients to figure out, also it's described in docs. And you can disable sign check using --insecure_api Centrifugo flag (also described in docs) - so it becomes a really simple task (but without signing check your API endpoint must be protected by firewall).\n2) Use Redis client but instead of PUBLISH use RPUSH command and run Centrifugo with Redis engine and --redis_api flag so you can RPUSH messages into Redis queue - description in docs.  . Hello, if I remember right on Ubuntu 16.04 we use systemd to daemonize Centrifugo - here is its config. There is no pidfile used. The script in your link is for previous Ubuntu releases which had no systemd installed.. systemd does not create PID file itself - it's a task for a process it daemonizes (i.e. Centrifugo in this case), this PIDFile option only helps systemd to get a value of main daemon process (see this). So just adding PIDFile=/var/run/centrifugo.pid won't work. With Monit it's possible to monitor process by name I suppose?. > Where is public/ directory located/cached in the filesystem? I need to create root directive for it in Nginx.\nStatic assets embedded into Centrifugo server - you need to proxy directly on Centrifugo, there is an example config in docs\u00a0- it should work. Have you tried that?. > Is there a way to notify user2 about message in channel chat#, if he does not subscribed for this channel on client side yet?\nYou can have extra private channel for each user - personal#<user1_id> - and send personal notifications to it. For example you can send via that personal channel notification about new chat created with user2_id - and then subscribe on channel chat#<user1_id>,<user2_id> on client side. All subscriptions on channels must be initiated by client. New chats created relatively rare - so this workflow should not affect performance a lot. After user refreshes page you send all active dialog channels to him from server.\n\nWill channel be automatically droppped in Centrifugo if history is disabled and both users disconnected?\n\nYes. Even if you enable history channel will be dropped - but history for channel will be kept for history_lifetimeso when it will be created again (user came back) history will still be there.\n. Hi, you can look at current status on Travis Ci, also you can run tests yourself via:\nmake test\nAlso goreportcard. Hi, Centrifugo has built-in support for Let's Encrypt certs and can update Let's Encrypt certificates automatically - maybe you can use it instead?. It will generate new I suppose. If you already have certificate for Nginx then maybe you can just put Centrifugo behind Nginx and let Nginx deal with TLS stuff?. @johndoejdg any feedback? Actually looks like there is a way to handle what you ask here but it seems pretty hacky to me and I'd prefer to not adding this - especially because we already have builtin Let's Encrypt integration.. I think the reason here is port - see this, just use 443 and https://MY_DOMAIN. At moment after this refactoring it's possible to start Centrifugo inside Go app with only raw Websocket endpoint in this way:\n```go\npackage main\nimport (\n    \"net/http\"\n\"github.com/centrifugal/centrifugo/libcentrifugo/channel\"\n\"github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory\"\n\"github.com/centrifugal/centrifugo/libcentrifugo/node\"\n\"github.com/centrifugal/centrifugo/libcentrifugo/server\"\n\n)\nfunc main() {\n    nodeConfig := node.DefaultConfig\n    nodeConfig.Secret = \"secret\"\n    nodeConfig.Namespaces = []channel.Namespace{\n        channel.Namespace{\n            Name: \"public\",\n            Options: channel.Options{\n                Publish:   true,\n                Presence:  true,\n                JoinLeave: true,\n            },\n        },\n    }\n    n := node.New(nodeConfig)\ne, err := enginememory.New(n, &enginememory.Config{})\nif err != nil {\n    panic(err)\n}\n\nif err := n.Run(e); err != nil {\n    panic(err)\n}\n\nserverConfig := &server.Config{}\ns, err := server.New(n, serverConfig)\nif err != nil {\n    panic(err)\n}\n\nopts := server.MuxOptions{\n    Prefix:       \"\",  // can be sth like \"/centrifugo\" in theory\n    HandlerFlags: server.HandlerRawWS,\n}\nmux := server.ServeMux(s, opts)\n\nhttp.Handle(\"/\", mux)\n\nif err := http.ListenAndServe(\":8000\", nil); err != nil {\n    panic(err)\n}\n\n}\n```\nSo theoretically this can be a starting point to use Centrifugo as library - but this is out of scope of this pull request.. @banks Paul - thanks for looking, it was important to hear that you agree with main idea. Then I suppose I'll merge this at some point - but any comment before that can help of course.. @johnsonc hello, this a bunch of non-trivial work behind this documentation request:) While I'd be very curious to see results  - I have no plans to do this myself and include into docs. This will be a biased work anyway. And it's pretty hard to do right and maintain.\nI'd be happy to have benchmark suite for Centrifugo but only to let users estimate what to expect from Centrifugo itself using load they expect in application.\nChannels and Centrifugo are not identical - different languages, different approaches (though both allow to solve similar problems). Centrifugo's model is language agnostic - with its pros and cons (pretty well described by @synw above - I can just add that with channels you are required to use Django/Python while Centrifugo can work with backend written in any language). I am sure you already understand differences well - choose whatever more suitable for your case.\n. Closing, as this is out of scope of Centrifugo. Though as I said I'd be happy to have a proper benchmark suite for Centrifugo itself without intent to compare it to something else - we now have benchmarks inside Go code but those are not very meaningful for users . @synw and @johnsonc - if you are interested in comparing Centrifugo with Channels take a look at Channels test project which has benchmark code for Channels - maybe it's a good place to start.. Wow, this is great, thanks! Do you already have Centrifugo running inside Kubernetes?. Cool, thanks again!. @mkevac hello! What example do you mean? We have clients for several languages, some of them with examples in repo. But I suppose you mean sth different.. Ok, personally I am using Tornado example for debugging and testing but having just index.html is much more simple. There is an example close to that one but not exactly what you want - it uses insecure mode, no channel selection etc. Will try to make it soon.. Started prototype in https://github.com/centrifugal/examples/tree/developer_index/developer branch - @mkevac if you are still interested please look - is this what you asked for? Do you need sth else? It's really only a prototype at moment - sth like python3 -m http.server 3000 will help to serve.. Improved that page a bit and merged into master - though a lot of improvements can be done there looks like it already can be useful. Planning to work on that page more in future.. @a1martin hello! On client side you should subscribe on $test - namespaces allow to use custom channel options but they are part of channel name.. I mean if you subscribed on $test on client side - you should publish to $test, if you are using test namespace then you should subscribe on client side on $test:channel_name and publish into $test:channel_name. Also note that $ sign must be in the beginning of channel name to make it private (not in the middle like in test:$test). This should work if client correctly subscribed on channel. Could you show websocket frames from browser developer tools? Maybe you have not implemented private channel auth endpoint in your backend and client not actually subscribed on that channel?. Cool, welcome!. Hi, here is a chapter about connection check mechanism available in Centrifugo. You can also protect channel access using private channels.. Hi, there is an example Nginx configuration in docs. Your config looks absolutely different. Also you don't have to use SSL in Centrifugo config if you are terminating SSL in Nginx.. @Inpassor thanks for a valuable snippet.\n@delprofile can you proxy requests from Nginx to Centrifugo without Apache involved or something? Actually I have never worked with ISP manager and have no notion about how it works. Maybe you better ask this question in ISP community.. @delprofile as far as I can see problem solved?. @delprofile you can look at results of SSLLabs for your site: https://www.ssllabs.com/ssltest/analyze.html?d=centrifugo.hardcsgo.ru - which is saying:\n\nThis server's certificate chain is incomplete.\n\nI think if you resolve this issue you will get NodeJS client to work properly. \nBtw, I remember that in past I used https://certificatechain.io/ site for problem like this.. Cool! Thanks:)\n@Inpassor many thanks for your help with this issue btw. https://github.com/centrifugal/centrifugo/wiki/Investigating-performance-issues. @skyborn8 hello, many thanks for a report!\nJust pushed a fix in 3c27a7f35be21b083288744ce562080fec1efddc\nThe problem was setting env prefix in incorrect place, until new release a workaround is to set secret key this way:\nSECRET=test centrifugo\n. Just released new version 1.7.6 with fix . @YOxan hi! Unfortunately there is no way to do this at moment. Could you describe your use case for this in detail? Why you need to control channels by backend and how events can help with this. . When user with role A enters a channel you can periodically send request from frontend to your backend indicating its presence in that room - you just update some time field in your main database. Then on backend side you can have a cron job that deletes rooms without activity for some time.\nYou also can ask for presence in room from Centrifugo periodically but I personally don't like this idea - this does not look as efficient and beautiful way.\nRelying on connect/disconnect event stream seems like the most unreliable solution because as soon as you miss one message you will get a room hanging in open state. I.e. you will need some extra mechanism to check it anyway.\nHope I understood your case right. . @YOxan hi, what a status for this - what you finally ended up with?. @cheddarwhizzy hello, I won't accept such pr without full proposal taking into account some moments:\n what to do in case of massive connect/disconnect routine - i.e. Centrifugo node shutdown/restart for example. When thousands of clients can disconnect for a while and then connect.\n what if HTTP request about user disconnect fails - does this mean user will be in online status forever in your app.\nThere could be some other tricky moments, at moment I am not convinced that this must be added into Centrifugo.. As soon as this will be merged it becomes Centrifugo and my problem. So a real proposal with concrete solutions required here.\nYou are right - when node killed there won't be any hooks at all. But on controlled shutdown Centrifugo tries to gracefully disconnect users. Both cases must be handled somehow.\nClient ID issued by Centrifugo for every new session, client state is mostly in process memory. Client can subscribe to another node after reconnect.. @cheddarwhizzy thanks for your work! Your proposal misses some important parts about how application should behave and adopt to this behaviour to reliably work with connections. For example how you are personally going to deal with missed hooks. If you already have a plan and describe it I will really appreciate.\nCurrently I am working on Centrifugo 2 in separate c2 branch. There are some ideas for new version release - one of which is let Go developers use Centrifugo as library. This is not a simple task, but I hope I'll succeed in this. If yes - it will look similar to Melody in some aspects - though different and more difficult because of lots of Centrifugo specific backgrounds and features. This can theoretically give a Go developer possibility to add custom logic to internal events. If you want to participate and help with library API design - we can discuss it further (in some chat, on Gitter for example - just write me a message there).. With Centrifugo v2 release this issue is not fixed. I am still not sure webhooks should be in Centrifugo. There is a possibility to implement system similar to Centrifugo using centrifuge library - building webhooks on top of it looks simple task (at least in a simple MVP form). If someone will come to a nice webhooks design on top of Centrifuge lib we can discuss is it possible to backport it to Centrifugo. This is the best advice I can give at this moment.. Hello @dvrkps ! Thanks for pr!\nOne caveat - Go version in packagecloud Centrifugo package created in Travis should match version in binary release which at moment I create manually and then manually upload into Github releases section. But I think I can be careful when releasing - at least I will try. And this can be an extra reason to automate releasing binaries via Travis too.. Looks like this can be drastically simplified using https://github.com/goreleaser/goreleaser tool. . Closing as this is done for Centrifugo v2 in c2 branch. Thanks @furdarius . Hello!\nThere is an article in wiki that describes how to investigate problems like this. Please create 2 heap profiles on Centrifugo start (when clients already connected) and when memory usage is high. Also output of stats command on start (when clients already connected) and at moment when memory usage is high.. One more note - I see watch: true in your configuration, this is a bit strange to see on top level in high load system. I don't want to say this is a bad practice - maybe you are really using it - just mentioning that maybe you better to turn this option off as it's pretty useless in production when traffic is high and adds extra work.. @amaleev any news?. Please reopen with more info if still actual.. Hello! Sorry - I don't understand your question. Could you explain it in more obvious way?. Got it! You are misusing Centrifugo a bit - you should go with Geo specific database, which allow to make queries like this and optimized for this sort of task. Use Centrifugo as server->client transport. When client sends new positions send them not via Centrifugo but via HTTP call (for example) to your application backend, save coordinates to Geo specific database and then publish to Centrifugo API to show positions in real-time. The client side publish feature of Centrifugo is mostly for demos, presentations, or maybe projects that do not require business logic - this is stated in documentation. Consider Centrifugo only as transport for real-time messages going from server to client.. @foobargeez please reopen in centrifuge-mobile repo.. Hello! Could you describe a problem this solves in more detail? On initial subscribe you can get data from backend.\nIn any case this solution is a bit hacky, will hit performance and not obvious. But hopefully if you provide more details we will find a way.. migrated to #204 . @vladshut thanks, this is much better than previous approach.\nBut I am still waiting for real use case information behind this change. Could you describe it in details?. @damour thanks for detailed explanation, do you need assistance from centrifuge-js side for this to work? Looks like you need this pr to be merged?  . Thanks!. Thank you very much @furdarius ! Added some comments on changes.. Thanks!. @vladshut hello, thanks for report! Could you provide goroutine profile?. @vladshut actually goroutine profile not needed - the fix is very simple. But could you describe the way you found deadlock? Have you used blocking profile? Or maybe some other tools/instruments?. > I attached goroutine profile.\nSorry, I don't see it\n\nI build centrifugo from latest master branch\n\nYou can use v1.7.7 - https://github.com/centrifugal/centrifugo/releases/tag/v1.7.7 - it contains that fix. @vladshut hmm, unfortunate.. could you write me on Gitter to personal messages? . Hello @ingosus ! Thanks for detailed report.\nThe reason is busy cycle in you publishing code which publishes faster then client can handle responses, try this diff (git apply patch.diff):\n```diff\ndiff --git a/Makefile b/Makefile\nindex d3de8db..66666b1 100644\n--- a/Makefile\n+++ b/Makefile\n@@ -7,7 +7,7 @@ npm: ## Run npm (npm arg=args)\n.PHONY: up\n up: ## Start app\n-       docker-compose -f ./infrastructure/docker-compose.yml -p centex up $(arg)\n+       docker-compose -f ./infrastructure/docker-compose.yml -p centex up --build $(arg)\n.PHONY: help\n help:\ndiff --git a/streamer.js b/streamer.js\nindex 0ce51f6..83778ab 100644\n--- a/streamer.js\n+++ b/streamer.js\n@@ -61,8 +61,12 @@ async function pub(cent) {\n     let errCount = 0;\n for (let n = 0; n < 1e6; n++) {\n\n\nsub.publish(msg).then(\nmsg.d = n;\nconsole.error(\"publishing\", msg);\n+\nlet p = sub.publish(msg).then(\n             ack => {\n\nconsole.error(\"success for\", n);\n             },\n             err => {\n                 console.error(\"publish error: %o\", err);\n@@ -73,6 +77,7 @@ async function pub(cent) {\n             throw new Error('publish error count');\n         }\n\n\nawait new Promise(resolve => setTimeout(resolve, 1));\n\n//await new Promise(resolve => setTimeout(resolve, 1));\nawait p;\n     }\n }\n```. @ramon-ga hello!\n\nMaybe related to this - though I can't say exactly at moment.\nDid your setup change in some way from what you had before? Maybe extra proxy providers before your service?. Yes, I'll update dependency. Looks like this also requires HTTP handler that works on port 80 to be registered in server and only solves a task of acme http_01 challenging.\n. @ramon-ga added new boolean option ssl_autocert_http in https://github.com/centrifugal/centrifugo/commit/4920a8f6c7fc529fa1c2faa9896a05a3a22b1c13 - could you try Centrifugo from master branch on your host? You can try without enabling that option first - maybe updating acme library is enough. Otherwise that option will turn on handling http_01 challenges on port 80.. ok, fine \ud83d\udc4d \n\nShould be written in log, that listen on port 80 too\n\nAgree, will add it.\n\nMaybe in that case, admin panel should no be accessible on port 80\n\nCould you write more about admin panel? As far as I understand it must work on main port which is 443 in this case and not on port 80 - or am I wrong?\n\nFor me it's nice that on port 443 and 80 the service is available, but not for everyone\n\nThis is turned on only if ssl_autocert_http turned on and only serves acme challenges on that port redirecting all other plain HTTP requests to HTTPS. What's you suggestion here?. > Correct\nSorry - so do you see any problem with admin interface at moment?. Are you sure it was not a redirect to https admin page? . @ramon-ga added logging in latest commit, so looks like this can be released?. Just released this in 1.7.9. Hello! This was originally made for cases where all configuration set via environment variables. Which difficulties with current approach did you experience?\n. Please reopen if you have more to discuss.. It's possible to scale with Redis engine. You can run many Centrifugo nodes each connecting to Redis. Also you can run many Redis instances and configure Redis sharding - Centrifugo will shard everything by channel. Sentinel can be used to add HA to each Redis instance. All of this written in docs - do you have any specific question?. Hello @tianxia007! Sorry - I don't understand your question. Could you ask with more details?. Messages are being kept in Centrifugo node memory in case of using Memory engine and in Redis (in Redis process memory, there is no much sense to enable disk persistence in Redis for Centrifugo data but you can) in case of using Redis engine. . @hudbrog hello! Thanks for report!\nYes, you are right about reason. Trying to understand how it could happen - are you using connection refresh mechanism?. Yeah, so looks like it's happening because of missed info length check in refresh handler, compare: this vs this. Will try to fix it today.. @hudbrog reproduced on local machine, commit db1a1043e98e363306a98368526f14980fb7d62f contains a fix for this. Will make new Centrifugo release later today or tomorrow.. released 1.7.9 with fix - please check it out.. Try this:\njson\n{\n  \"secret\": \"secret\",\n  \"web\": true,\n  \"admin_password\": \"password\",\n  \"admin_secret\": \"secret\",\n  \"engine\": \"redis\",\n  \"redis_host\": \"ip.top\",\n  \"redis_port\": \"7000\",\n  \"redis_db\": \"3\",\n  \"redis_password\": \"pass1\",\n  \"namespaces\": [\n    {\n      \"name\": \"public\",\n      \"anonymous\": true,\n      \"publish\": true,\n      \"watch\": true,\n      \"presence\": true,\n      \"join_leave\": true,\n      \"history_size\": 10,\n      \"history_lifetime\": 30,\n      \"recover\": true\n    }  \n  ]\n}\nSo you put options in the wrong level and also forgot one comma and used malformed JSON key value separators. @tianxia007 please ask questions like this in our Gitter chat - this is a bit out of scope of issue tracker here.. Unfortunately I can not do this myself, the best I can do is leave this issue open and mark it with help_wanted label.. @xurwxj thanks for your work on this!. @xurwxj I'll add a link to it in Translations chapter of documentation for Centrifugo v1. As you know I am in progress of developing Centrifugo v2 and it will have some breaking changes and differences in docs, it's hard to say when it will be released, but new docs most probably will be based on mkdocs- I have prototype here.. @xurwxj added link to your translation in commit https://github.com/centrifugal/documentation/commit/64b3d5ef8ddf1055a8feeb273beb326a4cfed280\nI did not understand what you mean under integrate Centrifugo's session into redis in v2 \u2013 could you provide more details about your idea?\nClosing this issue as link to translation is now in docs . As stated in centrifuge-android repo description we are looking for maintainer for it, this issue relates to Android client and looks like a bug in it. I can't say when maintainer will be found but as soon as it happen hopefully issues will be fixed. . @kaizer666 also opened an issue in centrifuge-android repo - https://github.com/centrifugal/centrifuge-android/issues/16 - I am very sorry but this is the best I can do at moment.. @Vovan-VE hello, thanks for report, what is your Linux distribution/version?. Pushed a fix in cd3b73979b64032d6d311183f0d53679307cd110. Released in v1.8.0. No - this project is not about video streaming. It's designed for messaging. I could understand you wrong though as you tend to create issues without description - this is a bad practice. . @arrowcircle hi! \nJust wrote a chapter in new docs about API. In short - it's just a POST request with JSON body to /api endpoint and optional API key set via Authorization header. No signing needed anymore. This commit into Python cent library adapts client to be used with new Centrifugo - it can help to understand which changes needed. Also note that token renamed to sign and timestamp renamed to exp and changed semantics (it's now timestamp seconds of connection expiration instead of current timestamp seconds). So helper functions will change a bit too. \nI think most of the things are pretty final though after some feedback still can change a bit.. So just to give some info about v2 status - at moment I am trying to solve two questions:\n1) Does GRPC client transport based on bidirectional streaming has benefits  over Websocket for Centrifugo use cases - my first measurements showed that Websocket is better in all aspects (server CPU, server memory, traffic) for our use cases. There is possibility that GRPC client transport won't be included into release from start and chance that it won't be used at all. \n2) I want to find a better algorithm for message recovery after disconnect. Particularly for the case when there were no active messages in history cache and client reconnects. For this case Centrifugo can't say exactly after reconnect were all messages recovered or not (recovered flag is false in subscription response). The idea is understand that  all messages were recovered if disconnect time was no bigger than history_lifetime and no more than history_size messages appeared in cache .. I removed GRPC bidirectional streaming client transport because:\n\nGRPC requires more memory on server (4x compared to Websocket)\nGRPC generates more traffic via interface than Websocket with protobuf (~20-30% more for Centrifuge protocol)\nGRPC is much more CPU hungry on server side (2x-3x)\n\nIt's still possible to put it back in future if we find its advantages in some scenarios. Note that GRPC for server API is still here.\nAlso improved message recovery - new docs here https://centrifugal.github.io/centrifugo/server/recover/\n. Hello @masterada ! Thanks for a great feedback!\n\nIs there a reason for unexporting the engine methods?\n\nYes, the reason here is that I don't know any other Engine implementations and their requirements so decided to approach this with caution. I.e. my final goal is to make engine interface fully exported and pluggable in Centrifuge lib - but I don't want to export things right now to not break public API later. So if someone interested in having engine exported we can find a proper way and moment to export it. Also see below.\n\nIs there a reason for removing the plugin.go?\n\nAs Centrifugo will now use Centrifuge lib it's not that difficult to plug whatever developer wants. From my point this makes library much more manageable and easier to maintain. Regarding Centrifugo server implementation: adding new plugin using code from plugin.go anyway required rebuilding binary by developer itself. So I think there is no much difference in possibilities but the code is much cleaner now. Also in version 2 I tend to remove some parts that seem hacky to me and not globally useful - this is one of them.\n\nI also realized that the engine interface consists of 3 parts...\n\nI also noticed this and I actually have secret gist regarding to this. The problem with 3 parts is that it generally looks cleaner and more flexible but not justified by reality where we only have 2 main Engines where everything done in memory or in Redis and this separation can be a bit overkill.\nIf you look to my gist you will see that PUB/SUB mechanics combined with channel history in Broker interface. That's because from performance and atomicity perspective it's a great win to save message into history in publish method of PUB/SUB broker - in case of Redis it allows to do this in one RTT to Redis (via lua script). I suppose there is some way to separate engine in parts but still keep this property - but I just had no time and use case to investigate this more to find correct and elegant component design than I already did. But personally I am for this separation - but it's just not that simple.\nBtw, this topic about correct engine separation is one of the reasons I don't want to export Engine interface right now.\n\nIt would be really nice to have a mute client in channel feature in the server API, resulting in that client not getting the messages.\nFree clients join a channel. One of them starts paying. This one client will receive slightly different notifications on that channel.\n\nCould you elaborate more about this - why not using 2 different channels for this?\nActually I thought many times about having server-side Subscribe() method in Centrifuge library (not in Centrifugo for now while there are no hooks to communicate with backend) so backend could subscribe client to channels itself. But I have not found an elegant way yet how to integrate this to protocol and existing client libraries. I see that you have figured out Centrifuge/Centrifugo internals pretty well - so maybe you will have some ideas on this.\n. I'll try to elaborate more on my points above as some of my thoughts were pretty chaotic.\nAs far as I understand you are suggesting to do sth like this:\ngo\ntype Engine interface{\n    Broker\n    HistoryKeeper\n    PresenceKeeper\n}\nBoth Memory and Engine will implement all methods of Engine interface thus will work. And if someone want to switch component it will be possible to call sth like node.SetBroker(BrokerImplementation) and control on PUB/SUB mechanics will be passed to this component.\nIn Node publish we can call:\nnode.historyKeeper.addHistory(...)\nnode.broker.Publish(...)\nInstead of \nnode.engine.Publish(...)\nIf you look at Publish method of Redis engine you will see that it publishes to channel and saves history in one RTT to Redis. This is a property I want to keep for Redis engine. First idea is making addHistory noop in Redis Engine but this means that Redis Engine can't be used as one of history keepers if we swap PUB/SUB broker to sth else. The solution - make it configurable - noop addHistory in one case and addHistory which saves history in another case. This is not very beautiful.\nRegarding to muting and except_clients - your case can be solved subscribing on two different channels - on both even if client have not start paying - you just don't publish new messages into that channel until right moment to start doing this. Maybe there is problem that I just don't see. \nRegarding to server-side subscribe. It's possible to subscribe on server-side but client will not have callback handler set to process messages coming from channel. Also there is a question about message recovery - can't imagine how to fit it into this model - looks like this must be a task for application code in this case.\n. ### Possible solutions\nStill not sure I understand your difficulties right. \n1) You can have 2 channels - one for free events and one for paid events. As soon as user starts paying it subscribes on paid channel stream and receives both free and paid events from 2 streams. And on client side you have the same publication handler for events from both channel subscriptions.\n2) Another option you mentioned in your first post - resubscribing on paid channel as soon as user starts paying. In this case on backend you publish free events to both channels (free channel and paid channel) and paid events only to paid channel. So you have 2 separate streams - one for free users and one for paid users.\nTags\nAt moment Centrifugo assumes identical data for each channel - this is especially important in terms of history/recovery. Though we can still keep full channel history but do server-side filtering based on tags before sending message or history data to client. Also Centrifugo designed in a way that all state required to subscribe comes from client side - so server can be just in-memory message proxy. Do I understand right that when you say about /tag?user=<USER ID>&channel=news you mean AJAX request to backend (similar to what we have with private channels)? \nI suppose yes because If you mean server-side integration of Centrifugo and backend via hooks then this idea fails quickly (for example restart of node with Memory engine - we can afford losing message history but loosing tag information is critical). So the only way to keep tags is always pass them from client on subscription request.\nThis is actually an interesting idea that theoretically can allow to do some interesting channel configurations.\nAdding more frontend-backend integration points (a-la private channel authorization now) will be hard to maintain in client libraries. So maybe this can be included into private channel subscription workflow? At moment we have channels starting with $ - private channels. Every time client want to subscribe on private channel request sent via AJAX (in the case of browser) to backend which provides sign for this subscription request. We can theoretically inject tags on this stage on backend as part of private channel subscription request. Those tags must be included into signing process so client can't cheat on tags. In case of Centrifuge library tags fit pretty well and can be simply set by application backend code inside onSubscribe handler.\nChannel remains the same, Publication will be delivered to all nodes subscribed on channel and server will do extra filtration based on client subscription tags before actually send message to client connection. History for channel will be kept full inside engine - and every time clients ask for history/recovery we can do extra filtration on Centrifuge/Centrifugo side to only provide history that relates to client tags. This is possible at moment because client can only ask history after subscribe request.\nOne caveat: this requires resubscription in case when user subscription tags must be changed (i.e. user becomes paid user and have to receive paid events). At this point this looks similar to point 2 from possible solutions section above. Though at least you can publish new events into one channel (though for me it seems not too bad to publish into 2 different channels).\nIt's difficult to tell at moment that there are no other caveats that can be found when we try to add this in code - it's hard to keep everything in the head. So proof of concept required and also this should not affect performance when tags not used. And of course I need an understanding that tags solve a problem that is hard (or not performant) to solve without them. Or maybe find some other applications for this feature. \nSummary \ud83d\ude00\nIt's pretty hard to discuss this on Github, because I have feeling that I still don't understand your use case right and suggesting unviable solutions:) What is your thoughts on my points here? If you feel that I don't understand you right then maybe we could discuss this in chat on Gitter.. A quick question - from your post I did not understand - is one subscription to private channel is acceptable for you? I. e. 1 Subscription to channel that needs requesting backend for sign and possibly tags (the request to backend will be sent every time user subscribes) ? . Yep, thanks! I considered JWT before - but it seemed hard to support it across languages. Actually Centrifugo was born before JWT gained its popularity. Now looks like there are tons of libs implementing RFC spec, so this looks reasonable. Though still needs a bit investigation as all libs has its own API to generate tokens - hopefully resulting string is spec compliant and Go server can verify and decode it despite of language that was used to generate it :)\nIt seems also that using JWT will allow to simplify integration with Centrifugo where we don't have helper libraries and be more flexible when we want to add features to Centrifugo-specific data (like tags from this discussion) - because at moment we have to add this to all helper libraries.\nBack to tags. Adding more stuff to protocol like updating subscription state seems a very complex solution. It's possible to implement but you are right that it makes things more difficult and hard to debug. Sure there could be a better way. Some ideas:\n\nuse disconnect API command to disconnect user. In this case client will automatically reconnect and thus will have a chance to get actual tags from backend during private channel subscription process. Downside is that it will reconnect with delay but I think it's possible to add new fields to disconnect command like reconnect_delay: true, reconnect_after: 0 to control disconnect behaviour.\nuse unsubscribe API command with a new field that will tell client that it must unsubscribe and then subscribe again (smth like resubscribe: true): so will get actual tags from backend during private channel subscription process.\n\nBoth approaches never guarantee delivery (as Centrifugo is at most once delivery transport) but should work in practice in normal circumstances. And actually your suggested approach updating subscription state has the same guarantees.\nDoes this make sense for you?. BTW this all can be paired with connection check mechanism to ensure valid client state.\nUpdate: no, this is wrong as connection check does not operate with subscriptions. . I investigated JWT a bit - looks like it suits pretty well. Generated token in Python:\npython\njwt.encode({\"user\": \"42\", \"exp\": 121010101010, \"tags\": [\"a\", \"b\"]}, key=\"secret\")\nThen decoded in Go:\n```go\npackage main\nimport (\n    \"fmt\"\n\"github.com/dgrijalva/jwt-go\"\n\n)\ntype ConnClaims struct {\n    User string   json:\"user\"\n    Info string   json:\"info\"\n    Tags []string json:\"tags\"\n    jwt.StandardClaims\n}\nfunc main() {\n    s := \"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyIjoiNDIiLCJleHAiOjEyMTAxMDEwMTAxMCwidGFncyI6WyJhIiwiYiJdfQ.fUoNhGoYgXwJd9D9K_hloFo0MkwUgQyIrDQJDN0Akp8\"\ntoken, err := jwt.ParseWithClaims(s, &ConnClaims{}, func(token *jwt.Token) (interface{}, error) {\n    return []byte(\"secret\"), nil\n})\n\nif claims, ok := token.Claims.(*ConnClaims); ok && token.Valid {\n    fmt.Printf(\"%v %v %v\", claims.User, claims.Tags, claims.StandardClaims.ExpiresAt)\n} else {\n    fmt.Println(err)\n}\n\n}\n```\nAn interesting idea here is adding tags to user connection itself instead of subscription. This will allow to set tags on connect and filter publications based on user tags and not on subscription tags. This is less flexible in general but will allow to not use private subscriptions. The only problem here is updating tags on the fly. This is easy to do during connection check request. But to change tags immediately after they changed on backend some sort of signal required - maybe new API refresh command that will force active user connections to refresh token from backend thus updating tags. Maybe sth else? In this case looks like it can be paired with connection check to ensure valid tag state.. @masterada I've created pull request to https://github.com/centrifugal/centrifuge (#6) with JWT support.\nI had time to think more about tags idea while adding JWT. In general I still like what tags can provide in terms of channel configuration. But our final implementation ideas here not very robust unfortunately.\nImagine situation where tags set via user connection token. Then at some moment tags change. If user is offline at this moment he won't get updated tags and will reconnect with the same token after going online (if token not expired). Not asking for token on reconnect is important in terms of not ddosing application backend with CPU intensive tasks (for example when Centrifugo node restarts). This means that user will have old tags until next token refresh. Maybe we should just provide an option to refresh token on every client reconnect.\nFrom this perspective having tags information in private subscription token is more robust as private subscription token is asked every time client resubscribes. This means that on Centrifugo node restart there will be lots of private subscription requests after every client reconnect. But this is a reasonable compromise that we already had before, people use this and not everyone actually using private subscriptions. But to update tags on the fly some sort of signal required (disconnect/resubscribe maybe) and looks like subscription token refreshing on expiration is also a good idea. But this requires quite a lot work - not sure I can spend time for this at moment. But seems like it's possible to add at any moment later.\nSo I am not sure about best way to add this feature yet.. > If you are looking at jwt, I suggest you check out go-jose instead. It implements all of jws, jwe and jwt (go-jwt only implements jws + jwt), even thought you will probably not need the jwe part. I also found it a bit easier to use. Here is an example of usage (parse+validate).\nIn Centrifuge case we have to handle token expiration in special way to support refresh workflow. I looked at go-jose and have not found a straighforward way to check that the only problem with token is that it's expired.. @masterada ok, feel free to ask any questions on Gitter and via personal messages if you prefer. As you can see I was able to implement subscription expiration - implementation is not ideal but I think it's pretty sufficient for this moment.. Centrifugo v2.0.0-alpha.2 just released - this is first public pre-release, hope someone will give it a try and share feedback.. Centrifugo v2.0.0-beta.1 released. So Centrifugo v2 released - release notes are here. Thanks a lot to everyone who helped during development: @masterada @mogol @Inpassor @furdarius @wlredeye and others.\nThere are still lots of things to do in transition to v2 - update remaining libraries, several examples still use v1, fixing bugs (sure there are some). But the important step just made:). Hello @Sannis , thanks! \nRegarding to CPU usage - Iooks like measuring this inside application itself is hacky, not accurate and not a convenient practice. This was done using ps because it was the simplest cross-platform way I found without using CGO at that moment. Also in today's container world CPU must be measured per-container from outside as there is no such info inside container. CPU usage stats will be removed in v2 (at least until someone knows how to do this right).\nBinary version - this is useful, at moment stats look like this:\n\"body\": {\n    \"data\": {\n        \"nodes\": [\n            {\n                \"uid\": \"8a7cf241-62c3-4ef5-8a20-83fbadb74c6f\",\n                \"name\": \"Alexanders-MacBook-Pro.local_8000\",\n                \"started_at\": 1480764329,\n                \"metrics\": {\n                    \"client_api_15_count\": 0,\n                    ...\n                    \"node_uptime_seconds\": 120\n                }\n            }\n        ],\n        \"metrics_interval\": 60\n    }\n}\nI think the correct way for Centrifugo v1.x will be adding version field on top level of each node info i.e.:\n\"body\": {\n    \"data\": {\n        \"nodes\": [\n            {\n                \"uid\": \"8a7cf241-62c3-4ef5-8a20-83fbadb74c6f\",\n                \"version\": \"1.7.10\",\n                \"name\": \"Alexanders-MacBook-Pro.local_8000\",\n                \"started_at\": 1480764329,\n                \"metrics\": {\n                    \"client_api_15_count\": 0,\n                    ...\n                    \"node_uptime_seconds\": 120\n                }\n            }\n        ],\n        \"metrics_interval\": 60\n    }\n}\nIn version 2 Centrifugo will have different metrics mechanics - Prometheus and automatic Graphite exporter - so this must be ported to v2 in a bit different way - using labels, sth like in Prometheus itself:\nprometheus_build_info{branch=\"HEAD\",goversion=\"go1.9.2\",revision=\"cd5e2fe68741a60ba90b80fbc161d0581be9e8bd\",version=\"2.2.0-rc.1\"} 1\nWhat do you think?\n. @Sannis very sorry for a long reply time - was attending Gophercon EU. Thanks for pointing out how ps behaves. As I said above I think Centrifugo should avoid measuring CPU stats itself so I won't backport this to v2 but we can add this to v1 I suppose. Do you know how this syscall behaves on Windows btw?\n. I always tried to make Centrifugo production ready out of the box. @mkevac @Sannis so you think that porting rusage utime and stime to v2 makes sense right?. @Sannis thanks for improvements! I will try to make new release soon, there are several small changes in master.. Also pushed a fix for Windows in 991fae6c30e91f72b2829b749d20ed738cf77d10 - syscalls not defined:\nlibcentrifugo/node/cpu.go:57:9: undefined: syscall.Getrusage\nlibcentrifugo/node/cpu.go:57:27: undefined: syscall.RUSAGE_SELF\nlibcentrifugo/node/cpu.go:62:9: undefined: syscall.TimevalToNsec\nlibcentrifugo/node/cpu.go:62:37: rusage.Utime undefined (type *syscall.Rusage has no field or method Utime)\nlibcentrifugo/node/cpu.go:62:46: undefined: syscall.TimevalToNsec\nlibcentrifugo/node/cpu.go:62:74: rusage.Stime undefined (type *syscall.Rusage has no field or method Stime). Hello, it's expected - port can not be set via environment at moment. To let config var to be set via environment it must be explicitly used while viper set up, so diff like this will do the work:\n```\ndiff --git a/libcentrifugo/centrifugo/main.go b/libcentrifugo/centrifugo/main.go\nindex 3a9ede7..93efb62 100644\n--- a/libcentrifugo/centrifugo/main.go\n+++ b/libcentrifugo/centrifugo/main.go\n@@ -222,7 +222,7 @@ func ConfigureServer(setter config.Setter) error {\n        }\n    bindEnvs := []string{\n\n\n\"web\",\n\"web\", \"port\",\n        }for _, env := range bindEnvs {\n\n```\n\n\nDo you need this or possibility to set port via command-line is enough for your case?. @grachevko see bf8655914ef94aaa4b2579d943b64fc63e7b9b08\nRegarding to Docker Swarm secrets - I had no enough time to think on it and can't decide at moment whether we should add entrypoint.sh or port recursive directory handling to viper-lite lib (fork of Viper that Centrifugo uses internally).. > entrypoint will require to duplicate handled environments to sh script.\nNot sure I understand this point. I thought it's possible to not duplicate config env names in entrypoint - just look at directory with secrets, then add CENTRIFUGO_ prefix to a name of each file inside dir (or maybe they will already be prefixed correctly) and then set as env var with file content as value. Am I missing something?. As far as I understand (never worked with Swarm though) when giving service permission to secrets only those secrets will be mounted in container.\nPersonally I am more for viper approach too, just because this will allow to keep docker image the same.. Released in v1.8.0. Thanks @Sannis !. Hello! Here is a list of packages we build at moment. If there are no differences in how package should be built for 18.04 then we only need to add a new line here. @bubooon see https://github.com/centrifugal/centrifugo/commit/c2d78ec045793b2bb5b3355fe081ce47dabc2408 - it will be built with next release, unfortunately I have no possibility at moment to test this on Ubuntu 18.04.. Released in v1.8.0. Thanks! Did you experienced wrong result with any API call? Because looks like we already do this right at least in v1. You are right, thanks a lot!. Hello! Thank you! The only thing is statik.go file - it's autogenerated so there is no need to change sth in it, need to change in code generator.. Thanks!. @nmorel yes, you are right - some of the edge cases of this were addressed in Centrifugo v2 which will be released very soon I hope. At least if I understand your concerns right. It's hard to backport changes to v1 as changes affect protocol. In v1 recovered is set to true only when Centrifugo is confident that messages recovered leaving it false otherwise to give application a tip to reload state.\nIs this an option for you to use Centrifugo v2? . @nmorel I can help you with any question about migration - feel free to write me into PM on Gitter. @nmorel I've put more effort to this topic - the approach with away field was not bulletproof in some edge case scenarios. The reliable solution I found is using global incremental sequence in each Publication in channel and keeping top of stream separately (as you suggested in this issue title). Pull request to centrifuge lib is here. I have not update doc yet but will do soon.. Recovery algorithm described here.. Hello! There are no technical barriers \u2013 only skill and time. Unfortunately I personally don't know Dart and Flutter ecosystem. But I know that @mogol which is an author of centrifuge-ios currently develops a lot of things in Flutter and likes it.\nIt's hard to give a forecast on when such client will be implemented. Writing a client is quite a big work. Actually writing a client with basic PUB/SUB functionality is very simple. The complex part is making it compatible with all protocol features.\nFrom my side I can help to everyone who wants to implement client - answering questions and extending protocol documentation, adding missing parts to it.\n. @jonahfang please note that current Android and iOS clients work with Centrifugo v1 while client that @mogol started in Dart will work with Centrifugo v2. We have no Android and iOS native clients for Centrifugo v2 yet.. Guys - thanks for your interest to dart client, the skeleton with basic functionality now exists in https://github.com/centrifugal/centrifuge-dart repo - thanks German! Please contribute and help @mogol to make it fully compatible with Centrifuge/Centrifugo protocol features (see current feature checklist). I am closing this issue - the link to new repo is in docs.. Thanks a lot! Fixed in 9aa3f253f54300d0d0fe8d3a0639bf1d111fe18c. Thanks! I've also pushed a fix for CI to not try login to docker on pull requests in https://github.com/centrifugal/centrifugo/commit/fa01b4bcb18cb023187df2a3b12988075de902cc.  . @chebyrash also I returned several lines you deleted for some reason: e8640245b0603ea6335f6eef790ba29f793cd80e. Yeah, right \u2013 if you have time please send another pr with this fix, if not \u2013 I'll fix it myself soon.. Thanks again:). Yep, currently in business trip, will do very soon. Fix in master, will be in next release . @rampredd hi, which client version are you using - latest version from master branch? Latest code supposed to work with Centrifugo 2.0.0 while you are connecting to 1.8.0. See https://centrifugal.github.io/centrifugo/server/configuration/#channel-options about channel options - you need Publish set to true when publishing from client side. Gocent library have not been updated to work with Centrifugo v2 yet - see https://centrifugal.github.io/centrifugo/libraries/api/ about state of API clients. At moment you can manually integrate with HTTP API using this doc: https://centrifugal.github.io/centrifugo/server/api/. This is pretty simple - just send POST request with Authorization header and JSON command in body.. If you want to use Centrifugo v1 then here you can find a list of compatible libraries: https://centrifugal.github.io/centrifugo/misc/migrate/#centrifugo-v1-repos\nIf you want to use Centrifugo v2 then you should communicate with Centrifugo HTTP API manually implementing request to server. Gocent will be updated to work with Centrifugo v2 eventually. Maybe in a couple of weeks.. Hello, yes - it's still in my roadmap, I was tired and vacationing so failed those deadlines. Let's create new one - will try to come up with updated library until the end of this week. Will appreciate if you help me with reviewing updated code.. @aannuujj just opened pull request with working code: https://github.com/centrifugal/gocent/pull/6 - please look and comment inside pr.. gocent lib for Centrifugo v2 released (gocent v2.0.0). Hello @andthereitgoes \nI don't see client_insecure option in your server config, you need to set it:\nfz@centrifugo: ./centrifugo --client_insecure\n...\n2018-10-18T09:47:28+03:00 |WARN| INSECURE client mode enabled\n...\nDoes it solve a problem? If yes then please share which example/docs you followed - I'll update it with this information. If not - we will try to dive deeper:)\n. @andthereitgoes any news?. Thanks:) . Hello @nanom1t !\nThe option is called admin_insecure in Centrifugo v2, not insecure_admin, see https://centrifugal.github.io/centrifugo/server/admin/\nPlease try it out.. Yes, I suppose the reason is that frontend app sets Authorization header itself thus not allowing browser to set basic auth header. I think we can simply do not send any headers in admin insecure mode. Will you have a chance to test Centrifugo from master branch (go run main.go) after I make changes or you need release to try?. Ok, thanks - I reproduced this locally, seems like fix works but will be really nice if you confirm for your case. . Does this solve a problem for you?. Will try to make it during this week, btw packagecloud.io requires update of GPG key for Centrifugo repository - this means that users will need to re-run repo installation script (https://packagecloud.io/FZambia/centrifugo/install) to update. This is a required step unfortunatelly - I will write about this in release notes.. Thanks!. Cool, thanks again!. Good catch:). The only place where Centrifugo v1.8.0 returns 503 is this one - when node shutdown initiated it stops accepting API requests. This allows load balancers to proxy requests to another Centrifugo node if any. Not sure how this relates to your case though as there is some sort of SSL error involved.\nI am not sure this can be fixed from Centrifugo side as this looks like client issue. Have you tried solutions described here?\n. OK, I suppose it somehow relates to client machine environment, closing for now, if happens again - please try advices from Stackoverflow post . Yes, thanks! Now there is only internal_port option. Really appreciate pr.. fz@centrifugo: go run main.go --internal_port=9000 --admin --prometheus --debug\n2018-10-29T21:15:32+03:00 |INFO| starting Centrifugo dev (go1.11.1)\n2018-10-29T21:15:32+03:00 |INFO| config path: /Users/fz/go/src/github.com/centrifugal/centrifugo/config.json\n2018-10-29T21:15:32+03:00 |INFO| pid: 5034\n2018-10-29T21:15:32+03:00 |INFO| engine: Memory\n2018-10-29T21:15:32+03:00 |INFO| gomaxprocs: 4\n2018-10-29T21:15:32+03:00 |WARN| DEBUG mode enabled, see /debug/pprof\n2018-10-29T21:15:32+03:00 |INFO| serving websocket, SockJS endpoints on :8000\n2018-10-29T21:15:32+03:00 |INFO| serving API, admin, prometheus, debug endpoints on :9000\nWhen internal_port set  the following endpoints will be served using that port: \n\nAPI\nadmin\nprometheus\ndebug endpoints\n\nMaybe in future there will be a need to set custom ports for specific endpoints, we can always add custom ports later. But now all endpoints considered internal configured to use this internal port option.. @vitoordaz fixed by 13aa173042663e37985346fab831aa920a515bf3, if you have sth to add to improve docs please feel free to do it. Thanks for pointing on this.. It was pretty handy with stats before. That allowed to better understand what's going on even without configuring integration with monitoring system (not everyone does this). And it allowed to see more information in admin web interface which is also cool.\nStats mechanism requires synchronization of stats between all running nodes so it's possible to ask full stats from any node. It worked before - so should work now too.\nI am OK to get stats back but not sure how to implement this with Prometheus at moment (before we used custom metrics implementation which was simple to serialize into map[string]int, now we need to serialize Prometheus stats into similar map[string]float64 I suppose). Maybe something like we do in graphite case should move to Centrifuge library and Graphite exporting in Centrifugo should use library method to extract current stats and send them to graphite.. I came up with sth like this in order to convert Prometheus metrics to some generic form that can be used to export automatically to external system from Centrifugo and for admin web interface stats:\njavascript\n{\n    \"metrics\": {\n        \"centrifuge_client_command_duration_seconds\": {\n            \"method.connect.count.delta\": 3,\n            \"method.connect.count.raw\": 30,\n            \"method.connect.quantile.50\": 0.000092533,\n            \"method.connect.quantile.90\": 0.000138654,\n            \"method.connect.quantile.99\": 0.000313045,\n            \"method.connect.sum.delta\": 0.00034440999999999986,\n            \"method.connect.sum.raw\": 0.0033648199999999997,\n            \"method.ping.count.delta\": 2,\n            \"method.ping.count.raw\": 14,\n            \"method.ping.quantile.50\": 0.000013244,\n            \"method.ping.quantile.90\": 0.000019972,\n            \"method.ping.quantile.99\": 0.000036619,\n            \"method.ping.sum.delta\": 0.00002931300000000005,\n            \"method.ping.sum.raw\": 0.0003692980000000001\n        },\n        \"centrifuge_node_action_count\": {\n            \"action.add_client.delta\": 3,\n            \"action.add_client.raw\": 30,\n            \"action.remove_client.delta\": 3,\n            \"action.remove_client.raw\": 29\n        },\n        \"centrifuge_node_build\": {\n            \"version._\": 1\n        },\n        \"centrifuge_node_messages_received_count\": {\n            \"type.control.delta\": 20,\n            \"type.control.raw\": 467\n        },\n        \"centrifuge_node_messages_sent_count\": {\n            \"type.control.delta\": 20,\n            \"type.control.raw\": 467,\n            \"type.join.delta\": 3,\n            \"type.join.raw\": 30,\n            \"type.leave.delta\": 3,\n            \"type.leave.raw\": 29\n        },\n        \"centrifuge_node_num_channels\": {\n            \"\": 1\n        },\n        \"centrifuge_node_num_clients\": {\n            \"\": 1\n        },\n        \"centrifuge_node_num_users\": {\n            \"\": 1\n        }\n}\nUsing this code\nMetrics contain raw values for counters and delta values aggregated inside Go process over configured interval. It's pretty hard to do in generic way because of labels (more labels in Prometheus metric will result in new final metric path), different separators in metric paths in different metric systems. \nThis information will be available at any node as method call. Also it's possible to share this information between Centrifugo nodes to show deltas in admin interface.\nI am not very happy with this result at moment... Format seems pretty odd (for example gauges without labels result in empty string keys \"\" - but it should work as when exporting we will iterate over nested key/values and construct proper path - in case of empty string we just ignore it). But this is sth that we can work with. We can change format as we want - for example add help description to metrics or refactor sth else.\nCurrently we use code taken from Grafana to export Prometheus metrics to Graphite. It has some magic converting namespaces to Graphite paths that I'd like to avoid if we refactor that part. Approach above will result in backwards incompatible paths in Graphite. But I suppose it's an acceptable change.\n@vitoordaz so if it will be possible to extract Prometheus stats in a form above we will be able to implement exporter to Clowdwatch from Centrifugo directly. But I can't estimate is the format of metrics above will allow us to export to Clowdwatch in a nice manner? Need your help with this.\nMaybe it's not very clear what I am planning to do here - I can explain more, just ask me.. Fixed format a bit to be more generic: https://gist.github.com/FZambia/3584bd5ca70254fe4981dcd064489409. > Not neccessarily \u2014 as long as the hostname or something was included in a dimension then cloudwatch will aggregate them correctly if each node self-reports.\nI've meant a case when we ask for metrics in admin interface which was possible in Centrifugo v1, in this case request goes to one random Centrifugo node after load balancer so that node should know current metrics from all running nodes to properly answer. That was pretty useful to have. Currently almost finished this in this pull request.\nFor export to Cloudwatch we don't need this sort of sync  - right.. Starting from v2.1.0 it's not too hard to implement export to Clowdwatch - just like we already do in Graphite case - but I need help with this, I am not a Clowdwatch user so can miss some specific things while implementing. Also don't have possibility to test it out. I think go-kit repo has a good example of how to export to Clowdwatch in general.. Hi, you need to have different values in secret and API key, those are a separate options. Secret is for client JWT authentication, API key is for HTTP API request authorization. Added more clarification about api_key option in this commit: 13aa173042663e37985346fab831aa920a515bf3. No, clients that were adapted to be used with Centrifugo v2 do not use secret at all (see Python client for example). Only api_key. Several API libraries have not been ported for Centrifugo v2 yet (https://centrifugal.github.io/centrifugo/libraries/api/) including phpcent. I will update Go library soon (gocent), but for phpcent, jscent and rubycent we need community help as I cant write code in these languages. This is possible to integrate with Centrifugo v2 without any API client though as this is just a POST request with JSON and Authorization header (docs).. Yes, your backend should now know 2 things: secret and api_key. But HTTP API client only requires api_key. Connection JWT is not supposed to be generated by API library - it's possible to use any JWT library around (docs).\nYou can keep these values the same but I don't see why you want to do this.. Hello, please provide steps to reproduce. . Yes, it can be the reason because both versions use the same channel for control messages but different format. I suppose that using custom redis_prefix in config file can help too. But better to just use different Redis instances. Yep, just fixed in commit 5d7495ebbab942e48464e1deb2fbb044df22c7cc, already updated in docs. Welcome!. This is not supported by command-line arguments - must be set in configuration file. I saw this error during development but I thought it was gulp issue. Are you using builtin web interface without custom admin_web_path?\nAlso could you show this resource request and response headers? . @iamsee unfortunately I can't reproduce this at moment even in development... Let's keep this open for now - at least until https://github.com/centrifugal/web/issues/13 will be closed.. In Centrifugo v2.1.0 I've rewritten web interface using modern JS stack, hopefully the problem will go away. @iamsee please check it out and reopen if the problem still remains in v2.1.0 . Hello, yes, you can. For example you have public namespace then you can use channel name $public:news to use namespace options for that channel. Example which works with config like this. Hello, thanks.\nAt moment Centrifugo has no health probe endpoint, there is also similar request in Centrifuge library which is the core of Centrifugo - https://github.com/centrifugal/centrifuge/issues/27 - with a bit more details.\nCould you tell me which things you expect to be checked when calling this endpoint?. ok, will include health endpoint into next release then if it already has benefits in this state. At work we have services that check external storages in liveness probe. I suppose checking external services has some reasoning in certain scenarios - broken reconnect, possible deadlock in drivers, connectivity lost forever for the whole underlying machine. But this can be an extra functionality added later.. Released with v2.1.0, docs here. Yes, this is reasonable, I've just added support for setting api_key via env var in 683befcbb2386f27c18e5d42dc820124cd8f4300.\nSetting secret already possible with CENTRIFUGO_SECRET.\nHere is a list of options Centrifugo supports setting over env vars: https://github.com/centrifugal/centrifugo/blob/683befcbb2386f27c18e5d42dc820124cd8f4300/main.go#L61\nIf you need some option that is not currently in list we can add it too. Maybe it's a bit hard for namespaces option because it's currently an array but I suppose there could be some workaround.. OK, will add very soon or just send pr :). Hello!\nMany questions here:)\nDo you mean generating certificate in runtime on process start? I.e. the only reason is not to provide key and cert files on disk? Is using separate files is impossible in your environment?\nAlso you will need to turn off verification on client side in this case right? So I suppose you won't use this in browser?. @sj26 do you know any Go lang software that already does this? To be fair I am not 100% sure we have to support things like this as certificate generation has lot's of options and is a better task for separate specialized tool.. Hello, thank you, fixed with https://github.com/centrifugal/centrifugo/commit/73667014da0aeb1f32a0ba632cfc10355a347963. Hello, you need to enable admin web interface in config. See how to do this in this documentation chapter. . Sorry, I don't understand your question, could you ask with more details?. Thanks for suggestion, Centrifugo uses goreleaser for automatic release workflow - looks like goreleaser already supports making snaps. I also found that you opened an issue in goreleaser repo about full integration with Snapcraft. Can we use goreleaser instead of manual integration?\nAlso can you provide any information about using snaps on production servers? I have not heard about this before. For development purposes we have prebuilt binaries for all target systems so it's already simple to install everywhere. So the benefit of extra release step is not obvious to me at moment.. @igorljubuncic thanks for information. I still not convinced that many use snapd on production servers. Closing this for now, at least until goreleaser will have full support and there will be request from Centrifugo users. . @atygaev hello, thanks for positive feedback and pull request!\nThe reason I doubt we should change this is the fact that one request can contain several API commands and thus several replies in one response (example in Go HTTP client).  So there is a chance that one of those commands will contain protocol error, another will be successful. In this perspective having 400 Bad Request code is not semantically great.\nAnother concern is that this can theoretically break existing API clients as HTTP libraries in different languages react on non-20x status codes differently.. Closing as I don't see how to change this without breaking semantics and client libraries.. Hi, are you migrating from Centrifugo v1 to Centrifugo v2? In v2 SockJS info endpoint path is /connection/sockjs/info. You asked for info endpoint so I answered on that question:)\nNow your task is clear - you need to use new SockJS endpoint in your JS:\njavascript\nvar centrifuge = new Centrifuge('https://my.site/connection/sockjs', {\n    sockjs: SockJS\n});\nThis is described in migration docs BTW. Also I suggest you to read new documentation from scratch as Centrifugo v2 has some important and some backwards incompatible changes.. @chelkaz you have two ways:\n1) Manually send AJAX request to you app as soon as client connected, process that event and then publish event to all listeners over Centrifugo API if needed. I suppose this option is more suitable for your case.\n2) Enable JOIN/LEAVE events - but you have to properly estimate cost of this operation, for channels with lots subscribers you have a risk of overwhelming your clients with join/leave events. Those are mostly suitable for channels with reasonable amount of subscribers and cases where you really need to instantly react on client presence.  See join_leave option of channel namespace - https://centrifugal.github.io/centrifugo/server/configuration/. I suppose this way is not what you need as you only have to notify other users on first join to channel.\nConsider not posting questions like this to Github issue tracker, it's mostly for bug reports and well-planned feature proposals. We have chat groups on Gitter and Telegram - see links in README.. Hi, thanks for pointing - a bit unfortunate. So I suppose you can just rename your service? Another possible solution is explicitly set port over command line flag option --port - according to Viper docs Centrifugo will resolve configuration in this order:\n```\nViper uses the following precedence order. Each item takes precedence over the item below it:\nexplicit call to Set\nflag\nenv\nconfig\nkey/value store\ndefault\n```\nAlso a bit odd that env var contains not only port but ip address and protocol parts. . Yep, this is good to know, thanks! . Asking question like this you should be ready than no one can give exact answer on how to architect channel configuration without knowing all corner cases and specifics.\nWhat I can say:\n\nOption 1 simply does not scale, you should avoid arbitrary amount of channels for many reasons.\nIn messaging app you definitely need per user personal channel, actually with Centrifugo you can use user-limited channel (with #) and not necessary use private channels. Though private channels have a characteristic to be confirmed with private subscription token on every subscribe attempt - even on every reconnect. So maybe this is valuable for you.\nOf course broadcasting message to 1000 users will affect latency, but in general new messages not created in a very high rate so there is a chance that you will be fine. Centrifugo can process 1000 messages pretty quickly (look at broadcast API method). But you should measure and estimate how it works for your case.\n\nI'd start with one channel per user.\nI will close this issue as this is not bug report or feature request, but feel free to continue discussion.\n. You can very quickly estimate time locally:\n./centrifugo --api_insecure\nThen run:\n```python\nfrom timeit import default_timer as timer\nfrom cent.core import Client\nclient = Client(\"http://localhost:8000\", \"\")\nnumChannels = 5000\ndef publish_in_loop():\n    start = timer()\n    for i in range(numChannels):\n        client.publish(\"test\" + str(i), {\"input\": \"hello\"})\n    end = timer()\n    print(f\"publish in a loop to {numChannels} channels: {end - start} sec\")\ndef broadcast():\n    start = timer()\n    channels = []\n    for i in range(numChannels):\n        channels.append(\"test\" + str(i))\nclient.broadcast(channels, {\"input\": \"hello\"})\nend = timer()\nprint(f\"broadcast to {numChannels} channels: {end - start} sec\")\n\nif name == \"main\":\n    publish_in_loop()\n    broadcast()\n```\nThis gives me the following output on my machine:\npublish in a loop to 5000 channels: 16.99 sec\nbroadcast to 5000 channels: 0.017 sec\nAs you publish in a synchronous loop it's a very long operation - Centrifugo can handle thousands of requests per second so here you are limited in speed of Python and sequential sending. If you have a possibility to send requests in async way (actually you can start asyncio event loop inside your Django worker and send many requests and then close loop, but it's a bit esoteric). So just using broadcast gives you a great speed up here (17 sec vs 17ms).\nI'd avoid Celery until you really understand it's required.\nAlso note that this test was done with Centrifugo memory engine, history turned of, over localhost and no connections to channels. So numbers could be a bit different in real case but still the difference will be the same. \nOne more property you better to implement is making your messages idempotent - if client received message that it already loaded with state from backend this should not result in extra information on user screen. Though I suppose React gives this for you for free as it has key concept.\nAbout load testing - this is hard topic but in general you can artificially create many connections using our client libraries (for Javascript, Go, Swift, Dart at moment) and experiment in a way you want. Don't forget to make file descriptor limit higher on your machine to handle many connections. If you end up with any results - please share here, this is very interesting.\nWe also have benchmarking script here - but not sure how it suits for you.. 1) You should send request to your app\n2) This should be solved periodically pinging your backend\nSome insights why this limitation exists can be found in #195 \nBoth cases supported by Centrifuge library Centrifugo built on top of. But I don't know scalable solution to make it work properly in Centrifugo case - consider  node restart with many active connections - some events can be lost. I suppose this is the same for Django channels. In normal workflow everything works fine but under heavy reconnect time you can not rely on Django channels at all. Correct me if I wrong. . Or if you just kill Daphne server.. I suppose all events will be missed too in Django channels case. I suppose you can use presence for this. \nFor two users case I think you can use presence and join/leave messages. Have you considered join/leave messages? Maybe I just do not understand problem right.. Got it now.\nTheoretically you can have one more common channel each user will be subscribed to. For this channel you can enable presence and rely on it. But this does not scale well when there are many users... This works fine for isolated groups - like game lobbies maybe or sth... But for messenger app I suppose every user can have many contacts. So presence info can be pretty heavy.\nAt work we develop messenger with pretty big amount of users. We use part of Centrifugo (slightly modified Redis engine) and we solve this problem using separate service which is responsible for online status. It works pretty fine, though it gives small delay when user goes online/offline. But it's robust and very simple - there are no edge cases at all.. @fhalim thanks a lot!. Will update doc site soon - it needs separate command to be published. @Raerten I forgot to mention that using Nats as broker will be optional of course. Redis Engine will work the same way as now without changes.\nThe reason why I think it's useful is because Nats is simple to configure in cluster mode and it's very performant. For applications that only need fast PUB/SUB this can be a nice option.. Don't understand why this happened exactly too, but one of races I posted in comments looks like panic trace - https://gist.github.com/FZambia/88bc50efec3728ea7f85 - so hope this was an actual panic reason\n. I tried to reproduce in various ways, with concurrent API calls, fast snapshot update interval etc - works fine. Only race detector showed lots of race warnings.\n. > Does just changing this to a *Metrics in NodeInfo make the race detector happy?\ngive me a minute to try...\n. no, does not help - another race - https://gist.github.com/FZambia/79941320ec62b40f6c6b (I just made what you suggested in original master branch version)\n. Yep all races that I could produce solved \n. But there is already zremrangebyscore in next line - here we need to clean both hash and set.\n. Btw I also thought about sth like this (but my idea was to change behaviour of publish to return channel so I rejected it as it results in massive refactoring inside other Centrifugo parts, and unfortunately I have not thought about possibility to simply add new method). Thanks, will try to change engine in this way!\n. Agree, just deleted it\n. ok, so something like 60sec as upper limit? And at moment mean POST request time is about 70mks on my old macbook, so 1mks looks as good lower limit.\n. I don't think that seeing at things that took more than 60sec makes sense - because at moment we have sth > 1sec - we are already in trouble\n. Actually I don't fully understand how to implement separate metrics for all these different protocol request types.. because they all can be aggregated in array of commands in one request. Do you mean that we should insert histograms after we already unmarshaled JSON and already iterating over commands in request: for example wrap this call like this:\nstarted := time.Now()\nresp, err = c.connectCmd(&cmd)\nc.app.metrics.histograms.RecordMicroseconds(\"client_connect\", time.Now().Sub(started))\nI think this will take nanoseconds btw. \n. Just measured, 15 histograms:\n10sec -> 1.85mb\n60sec -> 2.08mb\n10min -> 2.58mb\nSo if you agree on 60sec I'd prefer to make 60sec\n. Without profiling tools it would be anyway hard to make optimizations... I think even more correct way would be measuring this all on Nginx level - because small overhead on Go HTTP library etc... But anyway this is better to have out of the box in Centrifugo than nothing. So I consider this as just a monitoring tool and maybe sth that can show performance improvements or regressions when jumping to new version in production (I think most of our users just make separate publish HTTP API requests, actually at work we only do publish and broadcast). \nSo yes, let's push it like this then.\n. Yes, will fix it. Agree, I'll try to write such test. This is mostly for situation when configuration look like this:\ncentrifugo --engine=redis --redis_host=127.0.0.1 --redis_port=6379,6380,6381\nSo 3 shards look like this: 127.0.0.1:6379,  127.0.0.1:6380,  127.0.0.1:6381.\nBut actually this piece relates to my specific concerns you asked. When I wrote it I see how simple it would be to add just one more host or port. But first of all it look ugly internally.\nAnd what if someone will write\ncentrifugo --engine=redis --redis_host=127.0.0.1,127.0.0.2 --redis_port=6379,6380,6381\nI don't think we need to try to guess what user meant, right? So maybe adding extra check here? Like this:\ngo\nif len(hosts) < numShards && len(hosts) == 1 {\n    newHosts := make([]string, numShards)\n    for i := 0; i < numShards; i++ {\n        newHosts[i] = hosts[0]\n    }\n    hosts = newHosts\n} else {\n    FATAL('Wrong sharding configuration!')\n}\nWill write more thoughts about sharding in comment under pull request.. yes, found a way to simplify code. aaa! you mean wrong comment, yep, will fix it. :). The queue implementation itself is unbounded, we check it's length in caller's code before adding message.. We also have tests for this function in another package, I don't think we have to copy that code everywhere, that function is pretty simple. typo here - HEARDBEAT. I don't think it makes much sense to check all possible config fields here - it's enough to check just one for each type. Centrifugo \u2013 real-time messaging server.. let's only create binary releases at moment without deb and rpm packages. We already have separate step for deb and rpm uploaded on packagecloud in Travis CI.. Is it possible to build for exactly same platforms we already have in releases without windows 386? I.e:\n darwin amd64\n freebsd amd64\n linux 386\n linux amd64\n linux arm\n windows amd64\n. We still can add them later if needed . ",
    "thedeadofblackfire": "hi, \nVery good new stuff!\nI'm not familiar with Go language but you mentioned better performance & multi cores ready.\nCan you estimate what should be the best server to host only centrifugo as service (with memory engine) from 2 servers below:\n- 8 CPUs (Intel Atom) with 8 GB RAM (Ubuntu 14.04)\n- 4 CPUs (Intel Xeon) with 12 GB RAM (centOS 6.6)\nSo the battle between more memory vs more cores?\nDo you have an idea of the max connections we can reach with one of this kind of server?\nDid you use the benchmark tool from centrifuge repository ?\nThanks\n. Thanks for your reply. I think more memory is the best deal for now. Yep agree, 10 000 max connections simultaneous is already a solid base. I'm not yet at the beginning of the development phase about a medical chat platform. i like centrifuge & now centrifugo compared to pusher.com (price ^^). I try to make some projections of Use. The production phase will not be for the next months but i will try to use your benchmark on the servers to play with it (monitoring by newrelic).\n. ",
    "yagobski": "Thanks @thedeadofblackfire  for your question i want to ask the same. Iam also not familiar with Go language but if it make performance good why not. \nI want to join the project to develop an Angularjs frontend for Centrifugo with more features. \nCan you confirm us when centrifugo will be stable in production?\n. I confirme that il is working on production without any downtime since 3\nmonths.\nLe jeudi 24 septembre 2015, Alexandr Emelin notifications@github.com a\n\u00e9crit :\n\nSo I think Centrifugo is pretty stable at moment. In our project it works\nwithout any downtime since my last message. If you use Centrifugo please\nwrite me a message here or via email about your use case.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/1#issuecomment-142860249\n.\n. Thanks !\n\nOh it can be good feature if by default centrifugo listen on http and https just by editing the configuration. See this example : https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/auth-reference.html\nI will try to configure nginx.\n. I have many app on same server running on Apache Do you have any configuration to use apache to serve https for centrifugo?\n. Thank you @klauspost @FZambia !  Centrifugo is really awesome. I will wait for your release.\n. How you do to compile from source Centrifugo?\n. Thank u very much !\n. I install the new release all start fine but i can't connect anymore : \nclient will connect to SockJS endpoint\ncentrifuge.js:684 Status disconnected -> connecting\ncentrifuge.js:684 Send Object {method: \"connect\", params: Object, uid: \"1\"}method: \"connect\"params: Objectinfo: \"\"project: \"TEST\"timestamp: \"1435309309\"token: \"440add23d87ed14ed0b94b215bf5c931\"user: \"225\"proto: Objectuid: \"1\"proto: Object\ncentrifuge.js:684 Status connecting -> disconnected\n. even with wss://xxx:8000/connection/websocket it not working\n. No error just for websocket i get 101 Switching Protocols\n[\"{\\\"method\\\":\\\"connect\\\",\\\"params\\\":{\\\"user\\\":\\\"225\\\",\\\"project\\\":\\\"TEST\\\",\\\"info\\\":\\\"\\\",\\\"timestamp\\\":\\\"1435310324\\\",\\\"token\\\":\\\"14f7d5211a2cf388bda172a7456b1b\\\"},\\\"uid\\\":\\\"3\\\"}\"]\n. Sorry i get this error now : :8000/connection/info?t=1435311061415 net::ERR_INSECURE_RESPONSE17.r._start @ sockjs.min.js:2(anonymous function) @ sockjs.min.js:2\n. it is the bundle certificat problem. Any why to add --bundle to complete ssl configuration?\nOn MAC OS if there is no bundle certificate sometime it make this error. but it is not the issue about my problem. Thanks for your help i will try to found on internet and comeback.\n. Sometime when i use safari on mac i have this error : \nWebSocket network error: OSStatus Error -9807: Invalid certificate chain \nI have valid certificat from  Comodo. Works fine most of the time but sometime in safari i get this error on different laptop. \nI resolve this problem for my app using apache by adding the bundle package. But with centrifugo i can't pass the bundle file.\nSSLEngine on\n        SSLCertificateKeyFile /etc/apache2/ssl/private.key\n        SSLCertificateFile /etc/apache2/ssl/xxx.com.crt\n        SSLCertificateChainFile /etc/apache2/ssl/xxx.com.ca-bundle\nI want to pass this param SSLCertificateChainFile to centrifugo.\nThanks in advance\n. Yes it works thanks\n2015-07-06 18:21 GMT+02:00 Alexandr Emelin notifications@github.com:\n\nI am not an expert in tls configuration - but maybe that chain file can be\nconcatenated into cert file which Centrifugo accepts - see last messages in\nthis thread\nhttps://groups.google.com/forum/m/#!topic/golang-nuts/TnwfKyotEIY -\nsounds similar, can it help?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/27#issuecomment-118915885\n.\n. Sure. It is very easy I just create new centrifugo.crt file and i have put\nthe original crt content + bundle content in the same file.\nI call it like this :\n\n--ssl --ssl_cert=/etc/apache2/ssl/centrifugo.crt\n--ssl_key=/etc/apache2/ssl/private.key\n2015-07-06 19:01 GMT+02:00 Alexandr Emelin notifications@github.com:\n\nNice! You are welcome, I will appreciate if you write full receipt how to\nbuild such certificate here - can be useful for someone in future\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/27#issuecomment-118925052\n.\n. \n",
    "klauspost": "Sorry, that was a bit unclear. I meant a struct or something similar.\nI tracked back the \"presence\", which is (as you know)\nGo\n    info := map[string]interface{}{\n        \"user\":         c.user,\n        \"client\":       c.uid,\n        \"default_info\": c.info,\n        \"channel_info\": channelInfo,\n    }\nWhere channel_info is  set by\nGo\n            err := json.Unmarshal([]byte(cmd.Info), &info)\n            if err == nil {\n                c.channelInfo[channel] = info\n            }\nTo me it would make sense to do that as\nGo\ntype ChannelInfo struct{\n        User string `json:\"user\"`\n        Client string `json:\"client\"`\n        DefaultInfo *json.RawMessage  `json:\"default_info\"` // Marshalled JSON - do we ever need the content of this? \n        ChannelInfo *json.RawMessage `json:\"channel_info\"` // Marshalled JSON? \n}\n. Yes, it doesn't seem like there is any real reason to do so. json.RawMessage will just store the JSON as bytes, and when it is Marhalled it is re-inserted. \nIt will still be syntax validated when it is parsed, so you will not begin passing around invalid JSON. This will probably be a good speedup for the server.\n. In general, every time you use a interface{}\", and even some map[string]interface{} ask yourself if it really is arbitrary data.\nTo a long time gopher it hurts to see:\nGo\n        resp.Body = map[string]interface{}{\n            \"project\": p.Name,\n            \"message\": message,\n        }\nIf you have fields you don't want returned, use the \"omitempty\" json tag.\n. Sorry - forgot your question ;)\n\nOne question - will this result in double encoded JSON in the response output for default_info and channel_info or json.RawMessage must be unmarshalled manually later when building a final response?\n\njson.RawMessage is special. When you insert it, the content of the tag will be stored as raw json; a []byte slice containing the encoded JSON. When the struct is marshalled, it simply re-inserts the content of the slice as the value of the tag.\nThat also means that you can decode it later, as shown in #5 - because you can simply cast it to a byte array, which will contain the content of the tag.\n. Awesome!\n. There are a lot of similar 'race', where the same operation will return different results based on random timing. The practice of just returning ErrInternalServerError could perhaps be improved.\n. Yes - maybe it isn't possible (I cannot really say 100%).\n. Yes, I think that is the only safe way to do so, since it no longer holds the lock to the data once it returns. With the latter, you copy it before you return it, and you are safe.\n. (you can of course still return a pointer, but since I assume it cannot be nil, there isn't much point)\n// getChannelOptions returns channel options for channel using structure\nfunc (app *application) getChannelOptions(projectKey, channel string) *ChannelOptions {\n    app.RLock()\n    defer app.RUnlock()\n    namespaceName := app.extractNamespaceName(channel)\n    b := *app.structure.getChannelOptions(projectKey, namespaceName)\n    return &b\n}\n. sure :)\n. I would, if possible, avoid (and even remove) the toJson() function. However, it made the error conversion much simpler.  \nI am in the process of moving my stuff to a new computer. In an hour I should have it set up, so I can compile stuff. I think we should be able to do this in a simply and easy to understand way, I just need to be able to test it :)\n. (then I can also send pull-requests)\n. Continued in #7 \n. Hold a little longer, I think it can be made even better.\n. Small change response.Err() now returns a bool, so it can be used for checks as well.\nSo it can be used like this:\nGo\n    if resp.Err(someFunction()) {\n        return resp\n    }\nInstead of:\nGo\n    err = someFunction()\n    if err != nil {\n        resp.Err(err)\n        return resp\n    }\nIn cases where the function returns an error we want to pass on.\n. Nah - only about an hour and a half of work with gorename. \nYour comments all make sense. I will adjust the PR.\n. Changed most.\n\nI'd try to change c.Info in some way as info() returns ClientInfo full of different fields while c.Info is just default []byte client info.\n\nI actually investigated this quite a bit. Would it be more precise if it was infoCache, or what does it actually contain?\n- Made it ConnLifetime to be in line with the common abbreviations.\n- Made it channelNamespace, since namespaceName is a bit weird :)\n. Changed\n. The good thing it you don't need to care about what it is, but the compiler will make sure you never mess up and use the wrong one.\nGo\ntype (\n    namespaceID string // Namespace ID\n    projectID  string // Project ID\n    channelID string // Channel ID\n    userID  string // User ID\n)\nThis is the big difference in a type-safe language. You use types to convey information, not variable names. That way the compiler will immediately tell you if you when you mix stuff up. The call would usually look like this addPresence(pid projectID, cid channelID, uid userID, info ClientInfo).\nThe great things is that map[projectID]map[channelID]*channel without any work works the same as map[string]map[string]*channel, except there is no way for you to use the wrong key for a given level.\n. I added a conversion of these 4 types as #13 - the actual name can be changed in 1 minute. \n. > Could you also change ChannelID to just Channel? I don't like ID suffix when it's not an ID actually - channel can be the same in different projects.\nDone. Also found a rather easy way to change function parameter names, so I changed a lot of channel Channel to ch Channel.\n. The reason I personally prefer ChannelID is because the content of the type is not the channel \"itself\", but rather an ID to find it. But the way it is structured not, it makes ok sense.\n. Too late #15  :D\n. I must say, I am extremely impressed that this hasn't shown any existing errors. I had expected at least one, maybe up to three minor mistakes to show up from this change.\nBut I guess that is the advantage of using existing, tested code as a base. \n. Shortly I will be away (as in email only) until Sunday. \nI don't have any more changes right now, but when I get back I might want to look at writing benchmarks, so we maybe could see how things perform. This will also likely be able to act as a race detector.\n. Cool :)\n. ok. fair enough. Maybe is should just be added as a constant?\n. Same here. Sleep well!\n. Continued in #26 \n. client.send() blocking shouldn't be an issue, since sendMessages will always pull messages from c.messageChan.\nBut if c.sess.Send(msg) doesn't return, m will keep growing. What do you think would be the optimal solution?  A 10 second (configurable) timeout on c.sess.Send(msg)?\n. We could wrap message sending in a function:\nGo\nfunc (c *client) sendTimeout(msg string) error {\n  to := time.After(time.Second)\n  sent := make(chan error)\n  go func() {\n      sent <- c.sess.Send(msg)\n  }()\n  select {\n     case err := <- sent:\n        return err\n     case <- to:\n        return ErrSendTimeout\n  }\n  panic(\"unreachable\")\n  return nil\n}\nThe timeout length could be added to the client.\nThe thing that I don't really like about this solution is that we are spawning 2 goroutines to send a single message. Not a huge deal - goroutines are cheap, and it does seem like it is required.\nI will make a PR proposal. It is a bit easier to discuss.\n. I made a proposal in #23. After a few rewrites I think it is fairly unobtrusive, light on resources and rather easy to follow (except perhaps the ring queue implementation).\n. git crap. I will resubmit.\n. Very interesting. I think the main difference comes from the send timeout. What are the numbers if you change the function to:\nGo\nfunc (c *client) sendMsgTimeout(msg string) error {\n    return c.sess.Send(msg)\n}\nI think this would make it just as fast as the \"old\" code, but clients will no longer time out on send.\n. The buffer and separate goroutine can now also be removed from websocket. See commit 3bc068d - should speed up websocket quite a bit.\nSo the question is, do we want:\n- Timeouts on client connections?\n- A fixed limit on queue size?\n. In client.go, change this function to avoid errors:\nGo\nfunc (c *client) send(message string) error {\n    c.messageChan <- message\n    return nil\n}\n. I only have two issues:\n- [x] Add 'shutdown' package to godep. I haven't used it. Maybe you could help me?\n- [ ] Tests, but I want to make sure that this is the right way to go.\nI don't know if there are other things that should be done on shutdown? Should we do something with Redis?\n. > We also need to not accept new API requests in apiHandler - but what will application do in this case.\nIt will return at once with a http.StatusServiceUnavailable (503) shutdown is initiated. This should be enough for nginx to choose another node for instance.\n\nAnd then stop a node. Sending remaining messages suppose high message rate - in this case client will lose new messages anyway while reconnecting\n\nYes, and in case of a redis engine, any incoming messages will still be processed and sent to other clients, as well as be in history.\n\nUnsubscribing from channels is a nice new feature because we get actual presence info in Redis.\n\nYes.\n. > clients already technically already unsubscribed from all channels and should not receive those messages.\n\nMessages already queued up in 'client' doesn't care if you are still subscribed. If they have been routed to the client they will be sent.\n\nBut in stage 1, we unsubscribe, so no additional messages can be sent. In stage 2 we flush any that may have been queued up.\nSo\npre shutdown: Finish processing any commands that hasn't finished processing.\nstage 1: Unsubscribe users.\nstage 2: flush any messages still left in the client.messages queue.\nWe could consider sending a \"shutting down, please reconnect\" message to users. But that is easy to put in later.\nI think in all cases it is preferable to send what is queued up if possible.\nRegarding Redis, I think we should add a shutdown check here: https://github.com/centrifugal/centrifugo/blob/master/libcentrifugo/engineredis.go#L200 - when shutdown has started we shouldn't process more incoming messages. Agree?\n. > [...]One of Centrifugo nodes is under heavy load [...]\nAh - I think I found out why we see things differently. When discussing shutdowns, I don't see server re-balancing as a something that should be solved that way.  \nIn my eyes that should be handled by a separate function you can message with a command, like \"disconnect 50% of all connections\" or something similar. That would be much more gentle, and will not load the other servers. In my experience shutting down a server on overload is much more likely to create a cascade effect, that can bring down your entire cluster.\n. Whatever you want. I will keep the code, and you can add it later. I don't want to waste more time on it, and now it seems like there is a tons of conflicts to be resolved, which I don't have the time for.\n. In general I would put centrifugo behind a reverse proxy, like nginx for instance - that allows you greater flexibility, so you can host other things on the same server, and use the standard SSL port.\nThat said, I can send in a PR with TLS support, so you can use your certificate for centrifugo.\n. Maybe this helps:\nhttp://stackoverflow.com/questions/18637730/how-to-use-secure-websockets-with-sock-js\n. Anything in the \"network\" tab in Chrome that could help?\n. ",
    "dchest": "Yes, it would be fine to reject tokens with bad lengths early on.\n. ",
    "jancel": "That's too funny. I will report this to their support. It was working last\nweek!\nOn Friday, May 29, 2015, Alexandr Emelin notifications@github.com wrote:\n\nAlso their official button tutorial repo also throws an error (\nhttps://github.com/heroku/node-js-sample). So I think this problem must\ngo away soon.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/14#issuecomment-106706887\n.\n\n\nJeff Ancel\n(314) 703-8829 - Main\nwww.jeffancel.com\n. Did you do anything above and beyond to fix it or ah ha moment? I'm going\nto be hitting it tonight. Thanks.\nOn Friday, May 29, 2015, Alexandr Emelin notifications@github.com wrote:\n\n@jancel https://github.com/jancel it works now!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/14#issuecomment-106925380\n.\n\n\nJeff Ancel\n(314) 703-8829 - Main\nwww.jeffancel.com\n. ",
    "palazzem": "Hi @FZambia,\ndocker user here :)\nI've integrated your (amazing) service within our docker infrastructure and I've seen this \"issue\" related to a missing official image published in Docker Hub repositories. If you want to take a look to our Dockerfile, this is a link to our repository.\nWhile we're using some customization for our infrastructure purposes (e.g.: using our evonove/scratch as a base image and exposing port 8080 instead of your default 8000), maybe something could be useful. As you can see, during the build process, we're creating a non-privileged Linux user like other official images do (e.g.: Redis Dockerfile).\nWhat do you think? I can even help with a PR if you want to integrate something to your Dockerfile. Furthermore, it could be useful for you to activate an automatic build hook based on your tag releases, so that you can provide your images easily and without efforts.\nLet me know if I can help you or if you think that my advice are not suitable / useful for your project.\nCheers.\n. Hi again!\nAbout your points:\n1) The only things I will change, is adding the MAINTAINER and the VERSION keys just to easily point out what this build is about (nothing so strictly mandatory, just a personal opinion). We usually provide a docker-entrypoint.sh in which we launch the service using gosu or any other \"default operations\". Anyway, gosu isn't shipped with centos:6 or centos:7 images and this is why we use our base image. Without something like gosu or any other Linux command to obtain the same effect, your service may run as a root user, which is not so \"dangerous\" within a container. Anyway, as you can notice in the Docker security section (conclusions), they suggest to:\nDocker containers are, by default, quite secure; especially if you take care of running your processes inside the containers as non-privileged users (i.e., non-root)\nIf your compiled application doesn't make anything particular and the CMD [\"centrifugo\"] runs as a root user, probably it's better to use something like gosu to run your service within the container as non-privileged user.\n2) Didn't notice that you're already creating centrifugo user and group! In this case, user/group creation through Dockerfile is not required.\n3) In our case, we're just exposing a custom folder in /centrifugo path (like other official images do). When we start the container using docker-compose or simply docker, we use:\ndocker run -v /home/foo/bar:/centrifugo -t centrifugo --config=config.json --port=8080\nconfig.json is found because in our Dockerfile /centrifugo is the default working dir.\nAbout our logs, we don't expose that folder because we're investigating if we could provide all centrifugo logs in the container stdout. In this way, we can use logstash to collect and organize containers stdout as a log for the entire application infrastructure. In your case, I think it's really important to expose the logs folder otherwise docker newcomers may lost their logs.\n4) If you can already pull your container (seeing this issue I thought that an automatic build isn't available) you're good enough. The only requirement is the automate build and the Docker service in your GitHub repository.\nHope it helps! :)\n. Exactly, in this way the config.json could be saved within the application repository or it could be provided in a folder without versioning.\n. You're welcome! :)\nI see your points about rpm building and I totally agree. Services are not useful inside docker (there is no systemd or anything like this in base images and, in this case, CentOS 7 team removes the useless systemd package in favor of a fakesystemd just for dependency resolution).\nFurthermore, like you said, building from a zip file is really more explicit. Now that we both agree, I will include your changes in our custom Dockerfile.\nAbout the web interface, if you need to add the extras/web folder executing the update.sh script, I could suggest to create another container that extends from this one (e.g.: FROM fzambia/centrifugo:whatever). Don't know if this is a wise choice but in this way you're providing a container with only the centrifugo service while another one contains the centrifugo together with the web interface (without duping the Dockerfile).\nIn this way users may choose if use your container with the web interface or not. In this case, I suggest some instructions in the README file explaining the difference between fzambia/centrifugo and (hypothetically) ``fzambia/centrifugo-web.\nAnother choice is to provide an all-in container with both service and web interface. If you think that the use of the web interface is a usual choice for developers, you could go straight on with this way.\nWhat do you think about?\n\nAlso I set USER directive - I ran container built from this Dockerfile and it seems to work fine but I am not sure that USER is a replacement for gosu?\n\nUSER directive provides the execution of all consecutive commands (RUN, CMD and ENTRYPOINT) through the chosen user. Because you don't need any further customization neither an entrypoint script, it's totally fine to use USER. Just to be \"consistent\" I will place it before the CMD [\"centrifugo\"] even if it's not required to run centrifugo command as a centrifugo user.\n. Ah, obviously, I'm glad to help you with a PR if it's needed (probably you're busy with more interesting issues / features :) ).\n. OK, I've missed that you could launch independently your web interface using the --web option. In this case I think that the most suitable choice is to provide an all-in-one container that contains the right web version. In this way, users can launch their container using the option --web=/container/path/web/app.\nIn this way, developers don't need to configure a second data volume to provide the web interface code. Bearing in mind that \"developers are lazy\", an example to launch the container in two different ways without downloading / configuring the web interface is good enough for an all-in-one container.\nThe data volume option is still OK but I think that it involves a major number of steps for the purpose of a docker container. I think it's better to use them just for data (databases or anything that changes according to users' actions) or custom configuration files. If these files are static, I think it's better to include them in the docker build process.\n. You're welcome! :))\nYes, it's perfect and works as expected. I think that you can close this issue because this Dockerfile solves the presence of a working container in your Docker hub repository.\nHope to contribute again to your project (maybe with some code) :)\n. Currently, you should add the tag version build manually in your docker repository configuration. An automatic tag discovery isn't available at the moment but the Docker team already track this issue / feature request in their internal tracking system.\nI don't know when this feature will be implemented (don't see anything about it) but it's really a waste of time especially if a developer provides a lot of monthly release.\n. ",
    "khamaileon": "OK! Thanks for the reply and keep up the good work :)\n. ",
    "freeformz": "@FZambia Thanks!\n. ",
    "averrin": "Thanks, but you can add this command to readme ;)\n. Yeah. It wasnt critical for me, but i prefered to notify you.\n. ",
    "andremendonca": "@FZambia no problem at all. I read about the environment variable, thanks for the explanation. I didn't send a fix myself because I've just started with Go Lang but I'm glad I could still help :)\nI will update my project binary\n. ",
    "aleksraiden": "Yea, init.d scripts awesome! Thanks!\n. Maybe only for Redis lpush publish interface (without any responce)?   If data payload has some size, and number of channels  - we have very high overhead to data transfer (and we need more logic at publish script too) for publish. \nSecond idea - redis has binary-safe string, gzip/deflate data for publish?\n. Yeah, good idea! Broadcast command sounds good! \n. ",
    "sl4mmer": "@aleksraiden if you use Debian/Ubuntu here is init script\n```\nvagrant@ubuntu-14:/var/www/centrifugo$ cat /etc/init.d/centrifugo\nCENTRIFUGO=centrifugo\nCENTRIFUGO_ARGS=\"--config=/etc/centrifugo/config.json --log_file=/var/log/centrifugo.log\"\nPIDFILE=/var/run/centrifugo.pid\ncase \"$1\" in\n  start)\n    echo -n \"Starting Centrifugo\"\n    start-stop-daemon --start --quiet --pidfile $PIDFILE --make-pidfile --background --exec $CENTRIFUGO -- $CENTRIFUGO_ARGS\n    echo \".\"\n    ;;\n  stop)\n    echo -n \"Stopping Centrifugo\"\n    start-stop-daemon --stop --quiet --pidfile $PIDFILE\n    echo \".\"\n    ;;\n  restart)\n    $0 stop\n    $0 start\n    ;;\n  *)\n        echo \"Usage: /etc/init.d/centrifugo {start|stop|restart}\"\n        exit 1\nesac\nexit 0\n```\n.  Then maybe let's just add a notice to JsClient documentation ?\n. For Android - take a look at  WebsocketClientEndpoint from java.net\n. ",
    "flc": "Thanks for the info! Have you ever used the JS client from an Ionic / Cordova context? I can't see any reason why it shouldn't work, just curious. \nBut unfortunately I'm in a situation where a native iOS client has to connect to centrifugo. :(\nKeep up the great work btw!\n. Thanks @SammyVimes that's great news!\nA usage example would be nice.\nWe are considering to create an ios client, we'll see how it goes.\n. ",
    "SammyVimes": "@flc \nI got a repo with android client for centrifugo\nhttps://github.com/SammyVimes/ACentrifugo\n. @flc \nExample is here: https://github.com/SammyVimes/VersionMonitorAndroid\nYou should take a look at PushReceiver.java, Manifest and App.java classes\n. @FZambia of course, I want to implement full-functional client. \nBtw, is there any way for client to get undelivered messages? (e.g. I sent a message for user, who just left the channel, and I want him to get this message when he comes back)\n. I suppose this issue is not relevant anymore:\niOS client\nandroid client\n. ",
    "ghost": "Another approach worth thinking about:\nusing gomobile, you can cross compile the centrifugo go client  code to IOS and android, and use it from a Android(java) or IOS (objective-c) application.\nSome examples here:\nhttps://github.com/golang/mobile/tree/master/example\nThere are 3 options:\n1. Pure opengl clients GUI. Write all of the client in golang\n2. Native Android and IOS GUI, communicating directly with underlying go code\n3. Hybrid Web app, communicating directly with underlying go code. Use Cordova to help \nIts really easy to integrate with android studio and XCode IDE too.\nSlides / Concepts:\nhttp://www.slideshare.net/SeongJaePark1/hello-androidgo\nhttp://www.codingvelocity.com/2015/07/23/go-mobile-intro.html\nThis means that its write once, publish anywhere.\n. @FZambia \nWell i was also feeling that way.\nBut getting a basic android and xcode client, just for testing was remarkably easy in the end.\nI am a backend guy too.\nIt does not have to look good, but just demonstrate the idea.\nRegardign types. Yes your right that there are some restrictions.\nBut the go team are working through those and are aiming to have it resolved.\nThe other thing i am planning is to use flat buffers (or protocol buffers) between the Client GUI and the Client middle tier. This gets around some binding issues, because there are libraries for Protocol buffer for Android and IOS. Just an idea - i have not had a chance to try that out on a project yet.\nThe advantage is that it means that you can use the exact same code on the server as on the client. No RPC changes :)\n. that really clears up some confusion for me.\nThe use case is a small load application.\nwe have rooms, and users subscribe to them, but only certain users see certain messages (role based i guess).\nall clients are web browsers (chrome)\nI also need server to server web socket communication.\nagain small load\non the db level i am using rethinkdb.\nrethink can also be used like a message queue , because it support queries that are called \"changefeeds\". this means that is any data that the query represents is changes, rethinkdb fires an event to the middle tier. there you need a goroutine listening, and then you fire it up to the browser using web sockets. \nRethinkDB is pretty cool in this regards.\n. OK - cheers\n. ",
    "joeblew99": "Yeah its a pain at the moment.\nOther option is to communication as if it was a client and server.\nYou have 3 options:\nAvro\nGoogle buffer\nFlat buffers.\nAll of them want a IDL. Then it code generates both sides.\nA pain again because you already have codevthat represents an IDL I know\n. @FZambia \nBTW for go1.6 allot of this will be fixed.\nyou can make shared libs, and do dynamic or non dyanmic linking.\nThere is a good doc about it from the golang mobile team.\nHave a google !!! Its loosk freaking awesome\n. I think I see what you at saying.\nWhat I do is make things like presence a library, with use the mq layer to interact with it.\nA message queue like nats can go all the way to the client.\nBut I can see the contradiction.\nAt the end of the day the real issue is the protocol of the message queue and binary compat.\nThis is why some devs like http based microservices, because htyp is the one true binary compatible interoperable approach.\nMhh makes me wonder about using the new HTTP/2 push mechanisms as a message queue :)\n. Found one :)\nhttps://code.google.com/p/httpsqs/\n. At the moment you can use NSQ and mango to talk web sockets. Not sure about NATS.\nIt's not sure HTTP/2  push but good enough for now\n. Hey again,\nIt's nice that your interested in this.\nI see your point.\nIt all comes down to who is the message queue.\nI don't think, but am guessing a little that rethink can be the message queue itself. So I 100% agree with you.\nSo then all that has to happen is for the application to use rethinkdb for normal durable data storage.\nFrom my various experienced with lots of different databases I very much think you and others will find it an awesome dB.\nSuper easy to manage and scale in a single data centre and multiple data centres. I am using it this way now and its very impressive how easy it is , and yet still performance is great. \nWriting queries is also very easy.\n. Ah I see your using redis for durable storage. Sorry I forgot.\nSo yes you can either make another data adapter for rethink, so people can use rethink OR redis.\nI might add that the configurabikity of rethink is similar to redis. For example in rethink you can configure a table to use \" soft\" durability. It will hold it is memery and fkush to disk every few seconds. The perf is then about 20 times higher I recall.\nAnd rethink clusters like butter on toast. It just works\n. My main issue with using centrifogo is that it uses redis.\nThere is nothing wrong with redis.\nIt's more that thinkdb offers what redis has, but I get something that can scale horizontally a across data centres from day one with zero devops hassle.\n. I would say its possible.\nI use changefeeds for projects and so allow a table to act as a queue.\nPoint 3 is just middle tier logic\nOn Sun, 27 Dec 2015, 12:47 Alexandr Emelin notifications@github.com wrote:\n\nI see your point, but at moment I don't think it would be easy to\nimplement all Centrifugo engine needs on top of rethinkdb.\nLet's look at our requirements and what rethinkdb currently has:\n- storage to keep data (history, presence) - yes\n- PUB/SUB mechanism - maybe, it seems this can be implemented of top\n  of changefeeds feature -\n  https://www.rethinkdb.com/docs/publish-subscribe/javascript/.\n- expiration mechanism (history and presence data should expire) - not\n  yet rethinkdb/rethinkdb#746\n  https://github.com/rethinkdb/rethinkdb/issues/746\nAs rethinkdb user please correct me - maybe I am missing something. We can\nbe on the alert though.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/45#issuecomment-167403069\n.\n. Yes I see your point.\nRedis is pretty efficient.\nHere's some tips:\nBut with rethink and the sharing the efficiency can be handled due to its inherent sharing. \nAlso check out \"soft\" transactions in rethinkdb.\n\nI think you will find it can really scale and be managed much easier.\nI use rethink as a queue, with simple coroutine's listening and then firing up to clients over web sockets.\nCheckout the to do example:\nhttps://github.com/frankdugan3/GoRethink_TodoDemo\n. I am 100% biased in that I prefer a golang based storage layer. Just want\nto be frank. Maybe boltdb is a good solution ?\nOn Wed, 10 Feb 2016, 22:32 Alexandr Emelin notifications@github.com wrote:\n\nLet's summarise what we have in this discussion at this moment.\nNot so many databases can offer everything to support all Centrifugo\nfeatures out of the box. Redis is perfect in this.\nNATS and NSQ are more messaging systems. It would be possible though\nimplement PUB/SUB on top of them and other features on top of other\ndatabases. Also it could be possible to implement only PUB/SUB for example\nand let other features like history and presence as not implemented. But in\nthis case with those features left we also loose something that makes\nCentrifugo unique. So I think it would be possible only if in future we\nfind a way to make engines pluggable. And keep such engines out of core.\nIf we consider databases capable to support all our features - at moment I\nsee 2 real candidates here: RethinkDB and Tarantool. Tarantool don't have\ntruly PUB/SUB at moment (but something can be implemented on top of lua).\nTarantool is fast and flexible, has master-master replication, not so\npopular in the world yet unfortunately. RethinkDB don't have TTL yet and a\nbit different in terms what is this and how it works. But both look\npromising in some aspects. RethinkDB is quite popular (btw I see a lot of\nhype about Rethink but I don't really know is it used widely now?) and can\nbe a good companion for Centrifugo - as both positioned as tools for\nreal-time web. Also it seems it scales well.\nBut we need a real use case scenario and users that need alternative\nengine implementation to promote this further - otherwise we will grow wide\nbut stay at the same place.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/45#issuecomment-182590169\n.\n. Vanadium does the distributed store and encryption.\nIt's on github. Have a look.\n\nOn Thu, 11 Feb 2016, 03:21 Paul Banks notifications@github.com wrote:\n\nI see only very limited value in building engines that store data on the\ncentrifugo node.\nCentrifugo's entire scaling design really relies on external storage so\nthat you can easily scale number of front end servers. Even if you can\neasily serve all your load from one node, I don't consider single node to\nbe a viable option for production as it is a single point of failure.\nThe current in-memory engine is really only there for testing without\nredis dependency. I don't see any real cases where you would want to use\nthat in production unless you literally don't care about availability of\nthe system. There's no real value having another persistent engine for\ntesting either.\nOf course it would be possible to build an engine with BoltDB (say) that\nmanaged replication and communication between Centrifugo instances, but\nthen you are effectively building a custom distributed database inside\nCentrifugo which is almost certainly not a good idea. If you really have\na need for that you should probably focus on building a great distributed\nDB and add a WebSocket API directly...\nNow if there was a pure-go embedded distributed storage and communication\nlibrary that has already done all the hard distributed systems stuff then\nthat could be interesting, but I don't know of one. Closest would be\nsomething like Serf which solves communication and membership but not\nstorage or replication (and is eventually consistent so takes some extra\nreasoning about).\nFor now I don't see mileage in building custom engines that are so\nimpractical for production. Something like RethinkDB makes sense if people\nare already using Rethink for their app.\nPerhaps if there is demand for niche engine implementations then we should\njust make them pluggable so people can build their own exotic ones without\nus distributing them in core Centrifugo binary.\n\nOn 10 Feb 2016, at 23:01, jow blew notifications@github.com wrote:\nI am 100% biased in that I prefer a golang based storage layer. Just want\nto be frank. Maybe boltdb is a good solution ?\nOn Wed, 10 Feb 2016, 22:32 Alexandr Emelin notifications@github.com\nwrote:\n\nLet's summarise what we have in this discussion at this moment.\nNot so many databases can offer everything to support all Centrifugo\nfeatures out of the box. Redis is perfect in this.\nNATS and NSQ are more messaging systems. It would be possible though\nimplement PUB/SUB on top of them and other features on top of other\ndatabases. Also it could be possible to implement only PUB/SUB for\nexample\nand let other features like history and presence as not implemented.\nBut in\nthis case with those features left we also loose something that makes\nCentrifugo unique. So I think it would be possible only if in future we\nfind a way to make engines pluggable. And keep such engines out of\ncore.\nIf we consider databases capable to support all our features - at\nmoment I\nsee 2 real candidates here: RethinkDB and Tarantool. Tarantool don't\nhave\ntruly PUB/SUB at moment (but something can be implemented on top of\nlua).\nTarantool is fast and flexible, has master-master replication, not so\npopular in the world yet unfortunately. RethinkDB don't have TTL yet\nand a\nbit different in terms what is this and how it works. But both look\npromising in some aspects. RethinkDB is quite popular (btw I see a lot\nof\nhype about Rethink but I don't really know is it used widely now?) and\ncan\nbe a good companion for Centrifugo - as both positioned as tools for\nreal-time web. Also it seems it scales well.\nBut we need a real use case scenario and users that need alternative\nengine implementation to promote this further - otherwise we will grow\nwide\nbut stay at the same place.\n\u2014\nReply to this email directly or view it on GitHub\n<\nhttps://github.com/centrifugal/centrifugo/issues/45#issuecomment-182590169\n.\n\u2014\nReply to this email directly or view it on GitHub.\n\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/45#issuecomment-182674305\n.\n. I don't like redis only because its not golang. Really I am not joking. I\ntypically deploy golang code to mobile, embedded and servers. I don't use\nopenssh even, but instead a golang equivalent. It's makes everything much\nsmoother\n\nOn Thu, 11 Feb 2016, 16:48 Paul Banks notifications@github.com wrote:\n\nVanadium is an interesting project. Didn't have time to look in detail yet.\nBut what makes you actually think it would be a good alternative? Seems\nit's primary focus is on security in distributed systems where they are not\nall in the datacenter - i.e. mobile apps and multiple different services in\ndifferent locations. It seems more like an RPC toolkit with some storage\nfeatures. It's \"peer-peer synchronised storage\" is more like offline/online\nsync between intermittently connected devices not really a real-time\nreplicated data store from what I can see.\nMaybe we should flip this conversation around: can you describe what you\nactually need, and why Redis doesn't meet that need? Then we can find good\ntechnical solutions that do. Speculating on random technologies that sound\nfun and could possibly be pressed into working is really not the way to\nbuild a system.\nIt seems your only criteria so far in the things you suggested were that\nthey are written in Go which seems a very odd constraint considering that\nsome have been external binaries anyway (i.e. you don't need to care about\nthe code). Can you elaborate on why?\nFWIW I totally see possible use-cases for all sorts of backends - maybe\neven Vanadium - but unless we have real people trying to solve real\nproblems that require those solutions, it's really not sensible to try to\ndesign them!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/45#issuecomment-182925928\n.\n. :) well depends hat your building.\n\nAnyway. Lets close this issue. Its been hacked to death....\nOn Thu, Feb 11, 2016 at 6:31 PM Paul Banks notifications@github.com wrote:\n\nWith respect that is a pretty niche rationale. Redis is way more widely\nsupported in package managers, PaaS, tutorials etc. as well as being battle\ntested etc.\nBuilding a custom distributed database just because you'd rather deploy Go\ndoesn't sound like a recipe for a good system design!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/45#issuecomment-182968105\n.\n. \n",
    "yurtaev": "The minimal working example: https://dl.dropboxusercontent.com/u/714800/cent_mini.zip\nbash\n$ docker-compose build\n$ docker-compose up\n. 1. The latest docker supports setting ulimits through the command line and the API \n   - https://blog.docker.com/2015/04/docker-release-1-6/\n   - https://github.com/docker/docker/pull/9437\ndocker run --ulimit nofile=40000:40000 -v /your/host/dir/containing/config/file:/centrifugo -p 8000:8000 fzambia/centrifugo centrifugo -c config.json\n2. For example https://hub.docker.com/_/docker/ https://github.com/docker-library/docker/blob/e33e7226872e53dfa88bee09f153704a66fc103d/1.9/Dockerfile\n. ",
    "banks": "Thanks for the reply!\nI realise you can disable web but like I said we would need a way to bypass login like you said so we could run it on separate instance.\n\nCould you configure access on location level?\nis it possible in your case to just restrict access to API endpoint /api/?\n\nCould do that but in our case we will probably have an AWS ELB right in front of centrifugo doing TCP load balancing so it can't know anything about http request path or routing... Adding whole extra proxy layer just to secure it is possible but it would be much nicer just to not have the api exposed at all (or only on a separate listening port we can control separately).\nIf you are unsure it's useful to anyone else, I can implement in a fork but it would be great to not be running custom version!\nI think my prefered option would be:\n- allow web_secret to be empty (or maybe false to make it explicit) and if it is skip the login\n- add config web_port and api_port which by default are just the same as port\n- if web and/or api have different ports configured, add their handlers to a separate http.ServeMux and serve them with a separate call to ListenAndServe. This allows you to have same instances used for internal API calls and web UI and public websockets, but gives flexibility to lock down access to api/web ports to only internal machines and/or separate proxy with different authentication layer etc.\nThe simpler option is:\n- allow web_secret to be empty (or maybe false to make it explicit) and if it is skip the login\n- make an option disable_api which just removes the API handler for being registered at all.\n- fix it so that /auth/, /info/ and /action/ APIs are only enabled if web is also enabled...\n. Sounds good. If you don't post here I might have a go at this soon but probably not for this week at least so if you want to that will be awesome :)\n. Commented on commits - looks awesome thanks. I'll give the branch a try really soon - hopefully next day or two.\n. @joeblew99 yeah http2 push is a confusing thing - it's NOT arbitrary 2 way messaging with browser. See \n\nHTTP 2.0 server push is not a replacement for technologies such as Server-Sent Events (SSE) or WebSocket. Resources delivered via HTTP 2.0 server push are processed by the browser but do not bubble up to the application code - there is no JavaScript API to get notifications for these events.\n\nFrom https://www.igvita.com/2013/06/12/innovating-with-http-2.0-server-push/\nWhat is even more confusing is that http2 is used in grpc.io and there it supports \"streaming\" requests where client makes request to server and then gets a long lived stream of replies back.\nThat is something http supports at a protocol level, but only because the grpc client is choosing to use it that way, In regular web browser that supports http2 they don't have those client features - they only accept push from server to mean \"you might also want to load this other http resource\".\nYou could possibly hack that to force loading a javascript \"file\" with a jsonp style function call in the body to deliver a payload to your app, but I'm not sure that is a good idea really - that is just trying to turn another transport into a websocket when it was never designed for it. Clients don't guarantee to hold http2 connections open for example or reconnect on failure and I'm not sure your app could control the transport enough to do that yourself either. In other words http2 push is not at all the same as websockets and shouldn't be used as such.\nFWIW I love the design of both NSQ and NATS and considered building something like centrifugo on top of them. It could work, but it would really need to be a websocket API that mirrors the underlying API of those messaging systems since they are opinionated and don't really fit the way centrifugo is designed.\nNSQ would also support history while NATS wouldn't without some other central (i.e. shared by all centrifugo frontends) storage of the history. The obvious choice there is redis and that is essentially what centrifugo is already - just would need an adapter to publish direct from an NATS consumer (which is about 50 lines of go - I just did it for Scribe ;) ).\nNSQ could support history too but you'd have to have a separate NSQ consumer queue for every active user session connected to centrifugo which would mean as number of users connected increases, the memory needed in NSQ grows a lot - current redis design doesn't have that issue with memory only growing with number of //channels// that are active. Plus centrifugo design for storing message ids and syncing last ID seen etc would all not work and you'd have to rely on NSQ consumer protocol to handle that for you.\nI'm not sure NSQ is really designed for having tens of thousands of consumers - it's more designed for inter-service communication where it's assumed that each consumer is a service and hence having a separate queue for it is not a big scaling issue.\nWhat I'm saying is, what you ask for makes a bunch of sense and I'd personally be interested to see what you come up with - but it's essentially a websocket interface for those queue's protocols. And centrifugo is really a different thing to that right now.\nWhat is your use case by the way?\n. Yeah I looked at RethinkDB recently.\nIt would be possible I think to make an engine for it. But I'm not sure if that is quite what you want...\nAn engine for rethinkdb would just be same centrifugo pub sub features - what you want it seems is to integrate notifications from rethinkdb and publish them to centrifugo for delivery.\ni.e. you want a custom PUBLISHER that gets messages from rethinkdb and publishes to centrifugo, not an engine which is expected to support the full pub/sub/storage/presence etc. features of centrifugo.\nYou could make that an engine that just didn't support most features and converted subscribe requests for channels into rethinkdb queries, then published the results...\nBut seems you probably just want to build a custom app that talks to rethink and then published the results to a stock centrifugo with one of the existing engines.\nMake sense? Would be interested to hear if you have other ideas and where you go with this.\n. Point 3 (expiring keys/garbage collection( can be implemented in the engine, but it significantly complicates the design to have your app managing garbage collection in a scalable, fault-tolerant and distributed way. Failure to do it right could easily result in consistency issues, memory leaks or poor performance one number of channels scales up regardless of how scalable rethink is. \nBut yes I think you could build an engine on rethink now if that was a goal. The thing that isn't obvious to me with limited rethinkdb experience is whether it would be efficient to implement centrifugo's current model which is really based closely on assumptions about what is efficient in redis.\nIn general, I could imagine another model which is much closer to rethinkdb's internal model/design which would be a better fit (I.e. a possibly simplified rethinkdb API exposed over websocket) than building a centrifugo engine. I'd guess such a thing has been built already elsewhere...)\nIn other words, centrifugo is a fairly generic pubsub message broker application, rethinkdb is a full database with change feeds feature. You can model simple generic pubsub in rethink if that is your goal, but that's not the same as centrifugo being a good fit as a front end to your existing data model/change feeds your app might have in rethinkdb. Does that make sense?\nWould love to hear your thoughts though - if I have time I will look more into rethinkdb features to see how well it could model this. \n\nOn 27 Dec 2015, at 13:08, joeblew99 notifications@github.com wrote:\nI would say its possible.\nI use changefeeds for projects and so allow a table to act as a queue.\nPoint 3 is just middle tier logic\nOn Sun, 27 Dec 2015, 12:47 Alexandr Emelin notifications@github.com wrote:\n\nI see your point, but at moment I don't think it would be easy to\nimplement all Centrifugo engine needs on top of rethinkdb.\nLet's look at our requirements and what rethinkdb currently has:\n- storage to keep data (history, presence) - yes\n- PUB/SUB mechanism - maybe, it seems this can be implemented of top\n  of changefeeds feature -\n  https://www.rethinkdb.com/docs/publish-subscribe/javascript/.\n- expiration mechanism (history and presence data should expire) - not\n  yet rethinkdb/rethinkdb#746\n  https://github.com/rethinkdb/rethinkdb/issues/746\nAs rethinkdb user please correct me - maybe I am missing something. We can\nbe on the alert though.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/45#issuecomment-167403069\n.\n\u2014\nReply to this email directly or view it on GitHub.\n. I see only very limited value in building engines that store data on the centrifugo node.\n\n\nCentrifugo's entire scaling design really relies on external storage so that you can easily scale number of front end servers. Even if you can easily serve all your load from one node, I don't consider single node to be a viable option for production as it is a single point of failure. \nThe current in-memory engine is really only there for testing without redis dependency. I don't see any real cases where you would want to use that in production unless you literally don't care about availability of the system. There's no real value having another persistent engine for testing either. \nOf course it would be possible to build an engine with BoltDB (say) that managed replication and communication between Centrifugo instances, but then you are effectively building a custom distributed database inside Centrifugo which is almost certainly not a good idea. If you really have a need for that you should probably focus on building a great distributed DB and add a WebSocket API directly...\nNow if there was a pure-go embedded distributed storage and communication library that has already done all the hard distributed systems stuff then that could be interesting, but I don't know of one. Closest would be something like Serf which solves communication and membership but not storage or replication (and is eventually consistent so takes some extra reasoning about).\nFor now I don't see mileage in building custom engines that are so impractical for production. Something like RethinkDB makes sense if people are already using Rethink for their app.\nPerhaps if there is demand for niche engine implementations then we should just make them pluggable so people can build their own exotic ones without us distributing them in core Centrifugo binary.\n\nOn 10 Feb 2016, at 23:01, jow blew notifications@github.com wrote:\nI am 100% biased in that I prefer a golang based storage layer. Just want\nto be frank. Maybe boltdb is a good solution ?\nOn Wed, 10 Feb 2016, 22:32 Alexandr Emelin notifications@github.com wrote:\n\nLet's summarise what we have in this discussion at this moment.\nNot so many databases can offer everything to support all Centrifugo\nfeatures out of the box. Redis is perfect in this.\nNATS and NSQ are more messaging systems. It would be possible though\nimplement PUB/SUB on top of them and other features on top of other\ndatabases. Also it could be possible to implement only PUB/SUB for example\nand let other features like history and presence as not implemented. But in\nthis case with those features left we also loose something that makes\nCentrifugo unique. So I think it would be possible only if in future we\nfind a way to make engines pluggable. And keep such engines out of core.\nIf we consider databases capable to support all our features - at moment I\nsee 2 real candidates here: RethinkDB and Tarantool. Tarantool don't have\ntruly PUB/SUB at moment (but something can be implemented on top of lua).\nTarantool is fast and flexible, has master-master replication, not so\npopular in the world yet unfortunately. RethinkDB don't have TTL yet and a\nbit different in terms what is this and how it works. But both look\npromising in some aspects. RethinkDB is quite popular (btw I see a lot of\nhype about Rethink but I don't really know is it used widely now?) and can\nbe a good companion for Centrifugo - as both positioned as tools for\nreal-time web. Also it seems it scales well.\nBut we need a real use case scenario and users that need alternative\nengine implementation to promote this further - otherwise we will grow wide\nbut stay at the same place.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/centrifugal/centrifugo/issues/45#issuecomment-182590169\n.\n\u2014\nReply to this email directly or view it on GitHub.\n. Vanadium is an interesting project. Didn't have time to look in detail yet.\n\n\nBut what makes you actually think it would be a good alternative? Seems it's primary focus is on security in distributed systems where they are not all in the datacenter - i.e. mobile apps and multiple different services in different locations. It seems more like an RPC toolkit with some storage features. It's \"peer-peer synchronised storage\" is more like offline/online sync between intermittently connected devices not really a real-time replicated data store from what I can see.\nMaybe we should flip this conversation around: can you describe what you actually need, and why Redis doesn't meet that need? Then we can find good technical solutions that do. Speculating on random technologies that sound fun and could possibly be pressed into working is really not the way to build a system.\nIt seems your only criteria so far in the things you suggested were that they are written in Go which seems a very odd constraint considering that some have been external binaries anyway (i.e. you don't need to care about the code). Can you elaborate on why?\nFWIW I totally see possible use-cases for all sorts of backends - maybe even Vanadium - but unless we have real people trying to solve real problems that require those solutions, it's really not sensible to try to design them!\n. With respect that is a pretty niche rationale. Redis is way more widely supported in package managers, PaaS, tutorials etc. as well as being battle tested etc.\nBuilding a custom distributed database just because you'd rather deploy Go doesn't sound like a recipe for a good system design!\n. > I think we will need some extra code that will allow to connect Centrifugo nodes into cluster to communicate with one another without any third-party provider.\nI think we'd need to consider that very carefully. Implementing a distributed message bus inside centrifugo sounds like a big step and one we might quickly regret. The simple thing of full mesh and broadcast to all peers doesn't scale as connections and messages grow quadratic ally with cluster size. It also leaves you with complicated partial failure cases and great difficulty in describing the actual reliability guarantees that are provided. \nI'd actually suggest if we were to consider that, that we should make pubsub part a separate engine from storage part so you could write custom providers for that but. For example NATS.io, NSQ, RabbitMQ or Kafka for pubsub with DB X for storage of history etc. \n\nOn 3 Oct 2016, at 08:48, Alexandr Emelin notifications@github.com wrote:\n@CodingNemesis no unfortunately. There is a work in issue #100 to decouple Centrifugo packages so it would be possible to write custom engines. As LedisDB has no PUB/SUB support then it will be impossible to implement scaling Centrifugo to several machines on top of it. I think we will need some extra code that will allow to connect Centrifugo nodes into cluster to communicate with one another without any third-party provider. And use this code inside custom engine implementation. Then choosing database to keep temporary data would be much easier.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Didn't test this yet but the changes look good to me from reading through.\n\nAre you happy enough to land it or should I test this first with real load to verify?\n. I think @roytan883 means: if every channel has a Redis key containing a \"last activity\" timestamp then there is no need to use the current \"try to publish and see if anyone gets it, try to save if history exists\" technique. \nBut I'm not sure it's an optimisation - currently we can do it all in one round trip with a redis script anyway so cost is extremely low, the only real saving would be that if you did check first you could possibly avoid serialisation etc if message entirely but then the active case would require two round trips, one to check if publish needs and one to do it which is almost certainly much worse performing than now. \nI think we should forget about this suggestion being an optimisation - it's either not or is likely insignificant - and just consider it on the basis of less surprising behaviour. \nOne alternative that occurs to me would be that we could publish \"null\" messages to a channel on client subscribe or unsubscribe. They could consume almost no memory and would get the desired behaviour without changing either the publish/history logic or adding new keys into redis. \n@FZambia how easy would it be to introduce a null message that is just ignored by engine code that handles subscribed messages but is enough to keep a history channel alive for the activity TTL? Seems easy and less hacks than alternatives. Especially if we only publish them in the case that the channel IS inactive at the time (that might be harder though). . I was thinking actually publish a \"messsage\" which is just a 0x0 Byte or something so it uses same code paths etc and just drop messages like that when reading history back (before delivering to client). \nBut yeah could probably be done with a \"touch\" of the history key without inserting message if that's cleaner. \nEither way should be transparent to clients. \n\nOn 31 Jan 2017, at 08:11, Alexandr Emelin notifications@github.com wrote:\n@banks it's an interesting idea - I have not thought about this from a side that we can just create history key with TTL or prolong existing on TTL.\nLet me clarify - you mean \"null\" messages that will be published in Redis and not actually added into history and won't be published into channel right? The goal is just to touch history.\nMaybe we should do this as separate routine without mixing publish logic with such history touch. It's an implementation detail of course but could be semantically cleaner and not exposed to public API anyway. Also need to think about mass resubscription case after reconnect to Redis and how this will affect existing metrics.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. This works for me - now broadcasting average of 5k messages a second for several days with peaks of over 20k a second and queue lengths rarely go above the single item that was just pushed.\n. My client code is rand.Intn(numShards) since I'm broadcasting to many channels and already have no ordering guarantees thanks to Scribe and multiple instances. \nOn 22 Dec 2015, at 17:59, Alexandr Emelin notifications@github.com wrote:\nThanks a lot @banks ! Will see at pull request as soon as possible.\nI don't have strict strategy how to update docs, but usually I am writing and updating docs at the same day when releasing. We can create chapter in docs now in separate branch and make pull request that just merge later.\nYes, tests needs some improvements here:(\nBtw what's your client code to determine queue to which you put message? Something like crc16 mod N?\n\u2014\nReply to this email directly or view it on GitHub.\n. Yeah so this is not as simple as I thought - I assumed disconnect already sent message back to client.\n\nSo let me re-state what I actually want rather than just suggest we change this existing feature.\nWhat would be useful in some cases would be te ability to put a whole centrifguo cluster into \"load shedding\" mode where they:\n- deny incoming requests with a permanent error\n- close all existing connections with a reconnect: false message\nThe motivation is that in real-world we see clients still connected weeks after stopping a load test of centrifugo. For example, I ran a load test which had about 50k users connected and I still see about 100 users connected now - over a week since I stopped including JS on the page that makes the connections! For first 24 hours after load test it's in the thousands.\nOne way to achieve this would be to have some application property that is checked on each request (like config properties are) and then just make and admin API to toggle it with enough warnings about how destructive it is.\nHonestly not sure if it's worth it though if it's relatively hard to do. There are other ways to acheive same thing - alter HMAC secret and restart for a while so that all the reconnects are failed permenantly due to bad auth for example. (not tried that but I assume it would work).\n. I meant that for it to be useful, batching must be exposed right through to the client API. Even if we only choose to expose it via redis API, right now that just makes internal calls to API commands. I think we should support it on http API too though as it will make that much more powerful for medium to high throughput cases. \nI don't think backward incompatible changes are the best way though, I was just pointing out the options. \nMy vote would be to make a new API command called 'publish_batch'. Internally we can just make existing publish and broadcast commands use the internal batch publish method. \nMake sense. Apologies I wasn't clear. \n\nOn 30 Dec 2015, at 22:45, Alexandr Emelin notifications@github.com wrote:\nCould you explain what you mean under:\nthe application itself will need to support batch publish API requests (should we make new API call? Or breaking change to current API params?\nI supposed that this must be transparent for applications i.e. apps just send the same requests but they batched in Centrifugo before publishing. Seems I miss something?\n\u2014\nReply to this email directly or view it on GitHub.\n. There is another option which I think is best. \n\nWhy can't we just make whole engine async internally? I.e.:\n- engine interface methods just build request object with a reply channel (like we do already for subscribe)\n- they build object push it to pending chan\n- one goroutine runs in a loop reading from that chan and writing to redis pipeline, then reading from pipeline and sending result on the next in-flight request object\n- interface method then just waits on response chan and returns the result or error\nThis keeps the external synchronous interface but allows full use of pipelining with  no extra config nor any trade off between latency and throughput. \nIf for some reason we don't want to do that then we should at least use dynamic batching rather than fixed interval. I was going to write an article about this technique as its so simple and yet is about the only design choice in IO handling space that optimises both latency and throughput at same time: http://mechanical-sympathy.blogspot.co.uk/2011/10/smart-batching.html?m=1 \n\nOn 15 Mar 2016, at 08:13, Alexandr Emelin notifications@github.com wrote:\nPart two. Yesterday I made proof of concept showing that we can actually batch publish requests to Redis over pipeline and this makes things more performant as we save time on RTT to Redis. But the hardest part is how to seamlessly add batching support to existing API.\n1) Option 1. Make redis_batch_* options - to batch all published messages in time interval (or configured amount reached).\n2) Option 2. Add batch option to internal API, so only use it when needed - for example we don't really need batching when single messages come to HTTP API - because they will use different connections to Redis from pool. But we need batching when lots of messages to publish come in one HTTP request.\nAlso we should keep the behaviour in which call to history after publish always return correct history containing messages just published. So we can't just publish asynchronously - we need a way to only return response to API client when publish has been done.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/centrifugal/centrifugo/issues/59#issuecomment-196711021\n. Didn't think too hard about it yet but I don't see why we wouldn't use the same mechanism for everything if we built it. \nOn 15 Mar 2016, at 10:27, Alexandr Emelin notifications@github.com wrote:\nActually I thought about this option (I meant this as solution if choose option 1). But I thought to do this just for publish operation \u2013 do you mean that we should try to do all engine operations over pipeline - i.e. including history, presence etc?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/centrifugal/centrifugo/issues/59#issuecomment-196757416\n. Looks good to me @FZambia \n. After I clarified with the authors on the mailinglist (resulting in w3c/push-api#179) it is apprent that Web Push will NOT be a suitable replacement for WebSockets or other transports in Centrifugo.\n\nBut I still think there is a lot of value in considering supporting it as an additional feature such that Centrifugo remains a complete solution for both in-page and out of page updates. We'd also be one of the first open source implementations I guess which might be a useful thing for profile of the project.\nOne downside is that it requires HTTP/2 push promises and go1.6 http integration does not yet support push.\nIt is certainly possible to implement push - the http2 lib in golang has the necessary protocol support, just the net/http integration does not expose it. I'm considering opening an issue on golang to see if it will be considered for support.\n. I'm not sure about it being approved soon, but the standard is worthwhile even if Firefox and Google have centralised services. The fact they are all a standard and interoperable is important. \nIn practice we already have every major site implementing their own push stuff - for \"online\" messaging, that is the reason Centrifugo exists after all. And even if Google and FF have free centralised services there will always be people who have use cases that don't fit or need more control.\nMy understanding (might be out of date) is that Google has an existing non-compliant service which is experimental but FF and other browsers are pushing for this standard exactly so they don't have to run their own proprietary service to be feature compatible with chrome - let publishers bear the cost of service infra but still have feature parity with Google/chrome who can afford to run huge services for free. \nI think the standard is interesting regardless, but I agree it's still too early for this to be essential. The biggest opportunity I see would be if we are one of a very few open source implementations available if/when it does become a more widely used tech it would be cool. \nI also saw movement on some of the blocking issues in golang recently so it might be feasible soon. I think it would be possible now actually just with more customisation needed to http2 handler. \n\nOn 3 Jun 2016, at 08:30, Alexandr Emelin notifications@github.com wrote:\n@banks @jeberly I have doubts that draft promoting specification for web push server will be approved in near future - I don't understand the motivation behind this - allowing any server to be web push server means that every site will create separate connection to separate domains in Service Workers. Is this reasonable to have? When Firefox and Chrome have its own web push servers (GCM or Mozilla\u2019s Web Push service) it's reasonable because this could be single connection for all sites.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Not sure if the status of this draft but I\u2019ve not seen anyone asking for or excited about this protocol so let\u2019s close unless someone has a really strong motivating case where an alternative isn\u2019t a simpler option. . Without checking code, I expect that means that some value passed to Centrifugo via rest API, redis API or WebSocket API was invalid JSON. \n\nCan you reproduce?\n\nOn 16 Jan 2016, at 17:19, MadHamza notifications@github.com wrote:\nHi,\nI had this error message on my heroku logs and could figure out what's about\njson: error calling MarshalJSON for type *jsonRawMessage: invalid character '\\'' looking for beginning of object key string\nThanks for getting a look on\n\u2014\nReply to this email directly or view it on GitHub.\n. Hmm I don't see the point of this change as it is now.\n\nIt just adds latency and more moving parts as it is - there is still only single goroutine doing the \"hard\" work of delivering messages to client queues so the extra buffer is just another place for things to queue up if it really is over worked. and rest of time it's pure overhead.\nThe only argument I see for this change is if we have multiple goroutines pulling from the buffer channel to parallelise the \"hard\" work.\nPerhaps I misread the code though?\nEither way, as a performance optimisation, this should really be accompanied by benchmark results that show it actually helps!\n. > send metrics directly to Graphite\nInteresting, how does that work - I haven't seen options to configure output to graphite in the code?\nKeeping optional time-based counters seems reasonable - I did originally suggest that but my ticket got too long so I simplified ;)\n. Hm I see go-metrics supports graphite output but I don't see any code that configures that, plus if you did it at go-metrics level it wouldn't use the existing metrics interval stuff anyway...\n. Yeah that is equivalent to what Diamond does although diamond already supports remembering the last value of a counter and only submitting the differnce each 10 seconds (or however often it runs).\nIn your setup, sync between when celery job runs and when Centrifugo aggregates could cause races where same values get submitted fro 2 minutes and one real minute get lost.\nThis is why plain counters are more general and the external tool should manage figuring out rate of change base don when it actually executes.\n. Anyway we can keep the 1 min summaries if you want - it does save you from keeping persistent state elsewhere in your setup.\n. From gitter discussion:\nFirst option would be to just keep single stats method with no params and satisfy the requirements here by:\n- keeping aggregated counts\n- also have raw counts\n- include a top level key local_node_name or UUID such that consumer can easily filter to just local node without more options or relying on coordinated config.\nBut this has one unpleasant drawback: raw counts from non-local nodes will be subtly different semantically from the local node since they will only update once every ping interval. It's also generally quite messy.\nThe alternative which I think is cleaner and I prefer is to add a new method stats_raw or similar which has following semantics: \n- Only for local node\n- Outputs raw counter values (plus the other things like num cpus/goroutines etc.)\nEither way we should also:\n- remove timers (keep them with 0 value in stats output for now to not upset any code relying on them)\n- remove go-metrics and just store struct of uint64 for counters with atomic increments and loads\n  - metrics struct will need to keep separate set of counters for aggregation (i.e. remember the total value last interval as well as the value we return)\n  - each interval we simply atomic.LoadUint64(&counter) the raw counter and store the difference between that and the count we saved last update, then save the new raw value\n  - then when we generate stats response we return only the difference\n. @FZambia now it's node :)\nAlso note: I removed go-metrics from Godep file by hand because I'm actually running go1.6rc and didn't want to save that in Godep file.\nI noticed though that there are a couple of other packages in Godep file that godep diff seems to think are no longer used in the code - in a separate PR/branch would be good to clean those up at some point.\n. Seems good although I never understood what the 1 second sleeps achieve. \nClosing a socket already ensures any data already written to kernel buffer is sent before FIN, unless client has already gone away. \nThere are some exotic cases talked about here http://stackoverflow.com/questions/8874021/close-socket-directly-after-send-unsafe with big files where a more elaborate dance is described, but I don't think it applies, and at any rate arbitrary 1 second wait doesn't really guarantee anything since kernel or client might be slower than that anyway. \n. > 1) Messages for client first go to client's queue\nAh OK. Well it's fine then, it does kinda assume that we can always clear the queue in 1 second so it's still a bit hacky but not so bad. Would be a lot of work to rewrite disconnect so that it actually waits fo queue to drain I suppose?\n\n2) Just don't give a simple way for malformed clients spam server with lots of malformed messages.\n\nI don't understand how it helps there... If it's a malicious attack, the attacker can close connection their end as soon as packets are sent - they don't need to wait for us to. If you mean a bug in our client and the 1 second sleep limits how fast they will reconnect then that assumes we don't disconnect explicitly in client on receiving error packet, and at any rate throttling to connecting once per second is not very effective - a bug in client at scale will still DDOS you if they are all reconnecting every second...\nBut yeah OK I missed the fact we have additional queueing on top of the socket.\n. Thanks for the report. Has this happened regularly for you or just once?\nCan you reproduce reliably? Does it happen right after startup or at some \"random\" time after it's be working fine for a while?\nLooks like something racey in the metrics updating which we added recently. If it's a common occurrence and affecting your service availability, you can downgrade to 1.3.3 - the only major change was in metrics so unless you are relying on new metrics gathering it won't even be noticeable.\n@FZambia Not sure when I'll have time to look at this as I have a few other priorities. I'll admit I didn't run race detector though.\n. Seems good for now. Having seen this I think my metrics design was probably not the cleanest - I was optimising more for not having to hard code every metrics field in many places and have many different stir ts all holding different counts for same named metric. You're PR seems to please race detector and the traces seem to match the issue here so it's a reasonable assumption you fixed this. We can review cleansing up the metros further elsewhere. \n. @odin3 Your  original panic shows asm_386.s which shows you were using the i386 (i.e. 32 bit) binary. So even if your actual hardware is 64 bit AND your OS version is 64 bit (you can run 32 bit linux distros on modern processors and some do for example on small VPS to save memory on pointers), if you were using the i386 binary by mistake it still would have crashed due to this bug.\nThat's because the assembly code in sync/atomic explicitly causes that crash for unaligned access on i386 builds.\nBut in general, if you are running 64 bit OS on 64 bit machine you should be downloading the amd64 builds - they will perform better as all the low-level stuff like mutexes and atomics, can take advantage of full 64 bit instructions, as well as the compiler being able to use all the full width of registers etc.\n. And thanks for the report - we wouldn't have found that for some time without it even if it was only accidental that you used wrong binary :)!\n. Seems OK, what was the race reported out of interest?\n. In general this is a lot better and what I should have done. I was really trying to limit how many places copy-pasted the big list of counter fields but that's a dumb think to complicate code for and still didn't hug my goal of just one definition. \nSee online though. Unless I'm missing something (which is quite likely - it's nearly 3am and I'm on my phone while pacifying a baby) this doesn't fix the issue of unaligned atomic 64 ops on the counters due to mutex. \nIncidentally did you try to run 1.4.0 i386 to see if you could duplicate? Not sure where to get hold of a real 32 bit machine to try on but it might be enough to use 32-bit OS in a vm on your Mac or on Digital Ocean etc. \n. From sync docs: \n\n\u261e On x86-32, the 64-bit functions use instructions unavailable before the Pentium MMX. On non-Linux ARM, the 64-bit functions use instructions unavailable before the ARMv6k core. On both ARM and x86-32, it is the caller's responsibility to arrange for 64-bit alignment of 64-bit words accessed atomically. The first word in a global variable or in an allocated struct or slice can be relied upon to be 64-bit aligned.\n\nSo same bug would happen on any ARM processor too it seems. You could probably reproduce on http://www.scaleway.com server for a few cents if no luck getting an i386 vm to fail. \n. > That struct does not contain int64 values we access in atomic way\nYes it does since the metricCounter fields are not pointers. That means that each field of the metricCounter is laid out continuously in memory inside the MetricsRegisty and so will be offset by the mutex. \nIt's the same as before - the bool was at the end so it wasn't causing align issues with the counters in the same metricCounter, but rather causing all the subsequent ones in the Metrics struct to be offset by one byte each time. \nIf this works now in 32 bit then it means that sync.Mutex just happens to be 64 bits on your architecture. But that is not a good thing to rely on - on a genuinene 32 bit processor it would almost certainly be 32 bits (guess though).\nAt any rate the documentation from sync/atomic is very clear: the only layout guarantees you can rely on (without using unsafe.SizeOf or similar) are that structs are allocated 8-byte aligned. \nThere are two options I see:\n- move the mutex to the end\n- change all the fields to *metricCounter/Gauge so they are all allocated separately and thus all guaranteed to individually align.\nAnd we should comment as I mentioned so we don't accidentally reintroduce align errors if we change this in future. \n. Turns out I'm not 100% accurate with my assumptions\nsync.Mutex is defined in current implementation like this:\ngo\ntype Mutex struct {\n    state int32\n    sema  uint32\n}\nWhich means it's size will not be architecture dependent and we can rely on this PR working for the current sync.Mutex implementation.\nSo it's not a bug right now, but is a potential future bug since we are implicitly relying on the sync.Mutex implementation to never changed in a future go version.\ntl;dr this is fine for now and fixes issues. We should change it though so that we are not relying on undocumented implementation details of mutex to be correct. I'll make a separate PR.\n. Download the binary (https://github.com/centrifugal/centrifugo/releases/download/v1.4.1/centrifugo-1.4.1-darwin-amd64.zip) and run it!\nThere is getting started and config info in the documentation - should work just the same on OS X as anywhere else. \nSee https://fzambia.gitbooks.io/centrifugal/content/\n\nOn 15 Mar 2016, at 19:50, Nick Tabolich notifications@github.com wrote:\nHi there!\nHow can I use the Centrifugo on OSX?\nThank you\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\n. Didn't look in great detail but overall it seems good.\n. Great!\n\nWill look at code again tomorrow but that just didn't look very efficient!\nThanks\n\nOn 22 Mar 2016, at 21:27, Alexandr Emelin notifications@github.com wrote:\nActually that was not so simple because we don't call engine method directly from broadcastCmd - we call application's publish method which contains lot of helper logic.\nBut anyway I think I changed it in a way you suggested - not adding new engine method though but returning error channel from existing and added helper method to publish synchronously to Application.\nResult is wonderful: broadcast now 2 times faster for 10000 messages than version with goroutines.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. This looks great to me :+1: \n\nIf I get a chance, I'll try it out, but don't wait if you are happy.\n. I should note that this was centrifugo 1.4.1 on debian amd64. But I'm pretty sure that will happen everywhere and be easy to reproduce :).\n. Nice work!\n. I can go either way on this. \nOn one hand I expect anyone who uses this in production to have turned logs down to ERROR so we are not \"production ready\" by default there. \nOn other hand it's nice for new users just playing to start up in foreground with default config and get feedback about what's going on for each request. \nIn either case turning log level up or down is not so horrible. \nThat said your suggestion of minutely summaries sounds cool but it's a bunch of work and some overhead and I'm not sure how useful it would be in production in practice given that user should already have metrics setup telling them that graphically in better resolution etc. \nI think I sway towards leave it like it is and just document somewhere that we expect production deployments to tune it down...\n. In that case maybe make spammy stuff DEBUG. \nCould even make that be the default if we like it being loud for first run users with default conf with recommendation in docks to turn it down \n\nOn 28 Jul 2016, at 15:40, Alexandr Emelin notifications@github.com wrote:\nAlso thought about the same things...There are some caveats with other INFO messages, like logging when SIGHUP received for example - it would be nice to see such messages when error level set. This whole levelled logging concept looks broken a bit:(\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Calling stuff that is not an \"error\" condition \"error\" or even \"warning\" seems kinda hacky to me...\n\nDEBUG for verbose per-request logging seems more sane...\n. LGTM :) great job.\n. LGTM\n. While this may be a reasonable feature, if be pretty wary of claiming/assuming it could help in legal disputes. \nEven if you have a log, it's no guarantee that the users client ever received the message sent nor that your app displayed it correctly and even if it did all that, still no evidence the user actually missed it while refreshing the page etc. \nThis kind of audit trail really needs to be in your primary data store - I.e if you have messages that are this important then they should be stored in your primary store and marked as read by your app separately from centrifugo. \nCentrifugo is a best-effort message transport and should not be relied on as the source of truth for any data at all including a record of \"what happened\" in your app. \nIt might be interesting to have this feature but I think it's dangerous to assume it's useful beyond debugging and certainly not as your primary audit trail of app messages sent.\n. @sandeep-sidhu please explain why you need this. \nEven if we add this, the data really shouldn't be used for anything more than debugging or large scale aggregate analytics. We just can't provide strong enough guarantees for it to be useful for anything else and I worry that even if you know that, the presence of the feature in general will be misunderstood by others and used inappropriately.\nPhilosophically I dislike this because centrifugo is a best-effort message transport. Any truth about history or state should come from your app and be stored somewhere appropriate with well controlled semantics that match your requirements. Centrifugo should never be a source of truth for anything that happened. Think of it more like using Apple Push Notification Service - you wouldn't request that they add logging for your app's source of truth about messages sent, you'd do it in your app. Centrifugo should be treated with the same expectations with respect to its role in your architecture. \nIt does have some state but that is only enough to ride out temporary disconnections in a \"best effort\" sense - just like other transport systems. It's important not to confuse that with being source of truth about what was delivered etc. \nThe one thing here I see as a possibly useful thing would be logging of messages published and sent in the same way a web server logs - these could be used for analytics or debugging or security, but with the same understanding that they are not primary source of truth for your app. I'd push for doing this via some standard logging protocol like syslogd which can be consumed by almost any log aggregation tool. \nHope this helps. \n. One additional disconnect in this discussion - I'm assuming you don't use centrifugo clients to publish although that seems to be the original post's use case. I know this is a feature offered but it's one we seriously considered removing as it has all sorts of issue like this for any real application. Even for high-velocity chat apps posting new messages should really go back through your app rather than just relayed through centrifugo.\nSo when I say it's just a transport, I'm really implying that IMO you should not be publishing from clients at all and it should be a ONE WAY push transport with all messages flowing through your app first. \nIf you really need two way websockets for your app (a very small minority of real time apps do) then it's likely centrifugo is not a good fit for exactly this reason - no clean way to hook those client-published messages back into all the normal functions of your app like persistence, analytics etc. You will likely end up building a custom stateful websocket server in that case and we shouldn't add features to centrifugo to support a use case it's not really a good answer to anyway. \n. One thing to bear in mind Alexandr is that Prometheus' push gateway is kind of a hack. \nPrometheus' whole system model assumes that when it scrapes an endpoint it's getting metric values that are valid right now - I.e the endpoint is actually \"measuring\" and returning the current thing.\nThe push gateway subverts that. In general it can work OK in simple cases but it quickly breaks down if you have metrics which change cardinality often for example - if you replace metrics into the push gateway you can end up loosing data when the push and scrape intervals don't perfectly align which can happen a lot in practice due timing fluctuations. If you don't replace then metrics never go away and you end up scraping and storing stale and static metrics in Prometheus for systems that are long gone which is wasteful and confusing. \nI've run into all these issues recently and was part of helping to find a solution for Telegraf that properly handled these cases in as-close-as-possible way to matching a push system with Prometheus' system model. \nI'm not sure these specific issues are a big deal for Centrifugo, but you'd need to write custom code to support push gateway anyway since we don't export stats in any of the currently supported output formats IIRC. Or perhaps we do with graphite you mentioned? But graphite doesn't support histograms for timing so we'd loose all the usefulness of that data that way. (Prometheus clients support exporting histograms that can preserve that data properly). \nI see three reasonable options:\n\nDon't support Prometheus- leave users to build something with push gateway and graphite collector and figure out the gotchas and subtleties of all the different system assumptions themselves\nUse the Prometheus client library in Centrifugo and integrate with current metrics by implementing Prometheus' Collector interface in our metrics object. Their library will add the endpoint etc. for you and should be just a few lines of code. \nWrite an external \"centrifugo collector\" daemon for Prometheus that uses the Prometheus client and then executes a stats call to Prometheus on each scrape and returns the metrics scraped to Prometheus via the client. (This is the same as 2 except the code lives in a separate daemon and needs an RPC to centrifugo to scrape rather than reading from memory.)\n\nI don't have a strong opinion, but considering how popular Prometheus is becoming, I'd suggest one of the second two options leaves us in a better place for adoption.\n\nOn 21 Dec 2016, at 09:50, Alexandr Emelin notifications@github.com wrote:\nI started to implement this recently and the more I think about this the more I feel that this should not be in scope of Centrifugo core functionality - this is a new HTTP endpoint with its own auth. We already provide a way to aggregate stats over time interval and raw node stats. And API to export them - stats (aggregated info) and node (per-node non-aggregated info) commands.\nI see how this can simplify life for Prometheus users though. Python version of Centrifugo (Centrifuge) had a possibility to periodically export metrics into Graphite. Prometheus also has Pushgateway (https://prometheus.io/docs/instrumenting/pushing/). Maybe we should support pushing metrics instead of introducing new endpoints. On the other side having too much functionality in core for all cases does not seem like a good idea - more code to support, more dependencies. So another solution here - build a tool that can grab Centrifugo metrics and export them into desired destination.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @deepanchor\n\nJust as an FYI as we seem to not communicate this well: centrifugo is not really designed to be a \"general purpose websocket server\" - websockets are actually an implementation detail is personally prefer we didn't support as there are alternative ways to do server to client push that are as good and with fewer downsides. \nCentrifugo really has no good support for pushing data from client to server - it can be done and will be rebroadcast among other subscribers but for almost any real world app this is not sufficient - there is really no good way to get that data back into your app where it belongs. \nEven for chat apps where you don't care about persistence at all (rare) we had people hit walls with needing analytics info or audit logging and the answer to all of these is: push data from client to your regular app with HTTP and so what you need for persistence etc. and just use centrifugo as a server to web client \"push\" transport. If rather people saw it as analogous to apple or google push service for web than a general websocket solution. \nIf your game really needs two way comma then centrifugo is not a fit for you. \nAll that said, this issue is not irrelevant - there might be plausible use-cases for alternative serialisation with only server push semantics, but unless I misunderstood your use-case ids probably not a good fit anyway. \n. I think you mean like logrotate does. \nIMO this is a solved problem outside of Centrifugo. Nginx might do it itself but almost every other daemon on Linux at least just writes to a log file and lets a daemon manager like runit or systemd or just logrotate itself manage rotating and compressing and/or shipping log files. \nI'd vote no change - use standard tools. \n\nOn 9 Nov 2016, at 09:14, Alexandr Emelin notifications@github.com wrote:\nHi! Don't understand what you mean, sorry - need examples:)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. This is already possible. \n\nNot specifically by channel but by prefix. You can architect you app around channel namespaces where shared namespace prefixed channels have same configuration. \nIf you really want you could configure hundreds of namespaces which are actually contain only one channel if you really want per-channel semantics but the current namespace behaviour is sufficient I think. \nIf it's not suitable for you, please let us know your use-case in more detail. \nSee https://fzambia.gitbooks.io/centrifugal/content/server/configuration.html\n\nOn 17 Nov 2016, at 07:49, John Doe notifications@github.com wrote:\nIn my application some channels must recover all items from history but another just need able recover only very last message.\nCould you consider add history_size option by channel. Channel history_size will override global option.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Yeah, having host andnport still separate is unpleasant when you come to sharding...\n\nI'd suggest we leave the current flags for simple setups but change the sharding Ines like you suggest. \nMy preference would be something like: --redis_shards=host1:port1[,host2:port2,...] notnsurenif there are other things to configure per-shard but I'd be wary of exposing too much more since shards really ought to be uniform otherwise confusing issues would occur. \nAs for sentinel... I'm not really sure what the best plan is there. Certainly some people would likely run one sentinel group monitoring all the shards but I can think of a few setups where people might have different sentinels. \nMaybe for now leave it assuming just one set of sentinels and that they are same for all shards and document that? We can see if anyone has a real need for separate ones?. Ah yeah URLs are better - I forgot about DB numbers and it's quite possible to want to have different shards on different dbs on a single instance to make growing/balancing easier. So stick with that!\n\nOn 11 Dec 2016, at 18:57, Alexandr Emelin notifications@github.com wrote:\nSo my specific concerns about sharding as it currently implemented.\nI am not sure I found the best way to configure it. What do you think about current sharding configuration format? It's rather simple and intuitive format I think:\ncentrifugo --engine=redis --redis_host=127.0.0.1 --redis_port=6379,6380,6381\nOr\ncentrifugo --engine=redis --redis_host=127.0.0.1,127.0.0.2 --redis_port=6379,6380\nDo you see better ways?\nMaybe this must be more explicit option redis_sharding which is an array of objects each relating to shard config? We can add this later though and start with this simple format.\nAlso current option parsing relies on fact that application will use the same Sentinel addresses for all Redis shard instances - as Sentinel adresses already separated by comma. If this will be a problem then explicit array of objects for sharding config could help in future. Or we can add some other separator for various Sentinel configuration if someone will have problems with it.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Ah yeah. Worth noting that in the sharding docs then. \n\nFor future, I wonder if the cleanest fix for that would be to have one admin/control channel per shard suffixed with shard number. It makes presumably sharding stuff already has to handle the case where admin and control are split across multiple separate redis instances so I assume it would be no different but would just force the case of multiple shards on different DNA of one instance to work the same as different instances? Or am I wrong and we also hash admin/control channels so they are only in one \"shard\"? If we do that, I think this suggestion could help as each shard listener will only be listening to the control/admin channel in its shard and so which ever shard they get assigned them will do the work alone. \n\nOn 13 Dec 2016, at 09:19, Alexandr Emelin notifications@github.com wrote:\nIt will not work with different dbs currently due to how Redis works with PUB/SUB - unlike keyspace operations PUB/SUB messages propagate to all dbs so centrifugo.control and centrifugo.admin will propagate to all shards and will be handled several times.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Now it would indeed copy the message 10k times (or however many channels have storage enabled and/or active clients.\n\nThat said, centrifugo is not really designed for sending large messages. If your messages are more than a few hundred bytes things you should consider a different architecture. \nMost push systems like Apple APNS and GCM have the same design and suggest you push the bare minimum data needed to show that there is something new to a slider and then only pull down the detail in the client probably only if the user taps/clicks the simple notification for more. \nIn this case the design of storing a reference to a message and separate message (with reference counting) adds a lot of code complexity and possibly performance loss for not so much gain. \nIf you have small messages and still measure significant inefficiencies in memory due to the copying, could you paste some numbers you see? It could be nice to enable reference as an option but it's a lot of work and might be detrimental to the more common case so unless it's requested a lot and shown to be a significant cost saving I'm not convinced it's worth it. \nUsually careful design can allow small messages as well as always using history_drop_inactive (i.e. not using centrifugo as a general message store but doing that in your app DB). \n\nOn 10 Dec 2016, at 04:44, roytan883 notifications@github.com wrote:\nFor example:\n{\n    \"method\": \"broadcast\",\n    \"params\": {\n        \"channels\": [\"CHANNEL_1\", \"CHANNEL_2\", \"CHANNEL_3\"],\n        \"data\": {\n            \"input\": {...size about 4KB ...}\n        }\n    }\n}\nso centrifugo will use 4KB or 12KB to save the input message?\nIn this scenario:\nI need broadcast an announcement to many channels (10K channels).\nThose channels have different setting: some of them are public, some are private, some have different history_size and history_lifetime, some are history_drop_inactive.\nIf the message is saved by shared reference, the memory cost is cheap. But if the message is saved isolated to each channel, then it may use GB memory for just one announcement.\nIt is important factor for my current project if i change to use centrifugo, because i need channels to support organization with tree like structure. I need push announcement from top to bottom of the organization tree.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. You can also for cases like this rearchitect so that everyone subscribes to a public \"general announcements\" channel as well as anything else your app needs and the just publish announcements to that one. \n\nI'd still recommend messages are minimal though - just enough info to display a notification to user and/or allow you app to go fetch the full content via your regular API if needed. \n\nOn 10 Dec 2016, at 04:44, roytan883 notifications@github.com wrote:\nFor example:\n{\n    \"method\": \"broadcast\",\n    \"params\": {\n        \"channels\": [\"CHANNEL_1\", \"CHANNEL_2\", \"CHANNEL_3\"],\n        \"data\": {\n            \"input\": {...size about 4KB ...}\n        }\n    }\n}\nso centrifugo will use 4KB or 12KB to save the input message?\nIn this scenario:\nI need broadcast an announcement to many channels (10K channels).\nThose channels have different setting: some of them are public, some are private, some have different history_size and history_lifetime, some are history_drop_inactive.\nIf the message is saved by shared reference, the memory cost is cheap. But if the message is saved isolated to each channel, then it may use GB memory for just one announcement.\nIt is important factor for my current project if i change to use centrifugo, because i need channels to support organization with tree like structure. I need push announcement from top to bottom of the organization tree.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thanks for the info! This sounds like an interesting use-case which I've not had time to think deeply about but some immediate remarks:\n\n\n\nIn theory having 5million users all subscribed to one channel is no more expensive/unscalable than having the same number of subscriptions spread across tens of thousands of channels. It's much more efficient in terms of history storage. In practice I've not tried it so you may hit new and interesting bottlenecks which we can tackle. \n\n\nSupposing you do hot some limit with a single global channel, you could potentially shard it and have N channels and have each user subscribe to one based on hash of their user ID. Now you can trade off N copies of message cost against how many users per channel before you see issues. \n\n\n\"we still need guarantee when user online they can get missed messages from its organization\" this is not a guarantee centrifugo can provide. It's strictly a \"best effort\" transport mechanism designed (for example) to deliver updates that occurred since a web page was loaded. It's an anti-pattern and strongly discouraged to use the history feature as a source of truth or even for \"reliable delivery\" where users might be disconnected for more than a few minutes at a time. If you need that it really needs to be built into your app with your app's DB as the source of truth for catching up on stuff missed while offline.\n\n\nI don't think message references and deduplication is a terrible idea, but it's an optimisation for a use-case that is really outside of the core design goals IMO. \nHope this helps. \n\nOn 10 Dec 2016, at 07:43, roytan883 notifications@github.com wrote:s \nA We have 110K organization now, 5 million users (onlines are few based on total users, but we still need guarantee when user online they can get missed messages from its organization). And actually in our nodejs server, we save message in shared reference way to reduce memory usage.\neach organization have different users 10 ~ 5000. The biggest root organization has children about 70K sub-organization struct in tree.\nFor the bottom organization , it may has about 1~20 upper organization parents. Each parent organization can publish announcements. Parent may only publish to its own layer, or self and direct children organization layer , or include all children organization layer.\nThat means there are two options to design the push rule:\n1: As your suggestion, children organization users subscribe all parents organization channel. That will quickly increase channel users. The root organization channel may have 3 million users need subscribe . And the second layer organization channel may have 2.99 million users need subscribe. But the message only need push to one channel once. The message memory is small ,but maybe the channel will have pressure with such huge users subscription.\n2: Broadcast the message to those channels which need to be notified. This means each organization channel only have its own user subscription, but need publish the message to many channels.\nSeem both options are not good ......\n4KB just a sample to question the issue. In fact, most our message is less than 1KB. But still it is a big problem to save those message which need send down to child organization.\nIn our old nodejs server, all real message save in a big hash map with max TTL, each channel or topic only store the message IDs, only when push to client or client request the message, than get its real body from the message map.\nFor centrifugo , maybe we can do the save thing. First analyze the longest TTL time of \"channels\": [\"CHANNEL_1\", \"CHANNEL_2\", \"CHANNEL_3\"] when broadcast. Then save real message body in one big hash TTL map. Each channel only save the hash message id.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Nevermind, engine.go was collapsed in my diff view for some reason.... I like the new tests. Looks good. \n\nI notice you didn't actually assert on the shardFraction only on the resharding was that because it failed too often? I'd suggest assert with generous bounds (0.07 < shardFraction < 0.13) and if it still fails too often try increasing the number of items hashed to a million or something to increase the probability of uniformity.\nIf it's still too flaky for CI but it's only failing one time in a hundred or so it's probably best just to disable it in CI run and only run it with a special test tag and. Just keep it as a manual sanity check. . Not sure where 1 week came from - is that the default for the client lib you used? \nAll the clients I've seen renew with a month to go so they renew every 2 months.\nI don't think it's a big deal but one reason it might be worth increasing the time in a future release: I've seen lets encrypt rate limits kick in which are reasonably generous but not that hard to hit if you are systematically generating SSL certs (in our case we hit them despite negotiating an increase over the default limit partly due to a bug on their side, and despite this relationship, their engineers were unable to lift the block early and we had to wait a week...). When they do you are effectively blocked for a week from any new certificates being generated or renewed (actually I'm not sure about the renewed part but IIRC renewal is the same API call as initial generation anyway so I guess it's true).\n\nOn 3 Jan 2017, at 04:49, Alexandr Emelin notifications@github.com wrote:\n@manson yes, they should (1 week before expiration)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Do we need to make it clear if exposing this that, while it might be useful, it doesn't hangs Centrifugo's \"best effort\" guarantee and that solutions relying on perfectly reliable or in-order message delivery still need to do more work to verify state with app rather than rely on Centrifugo transport?\nOn 8 Mar 2017, at 08:35, Alexandr Emelin notifications@github.com wrote:\n@sergunich let's clarify API before I'll add it to Javascript client. With exported recovered flag it will be possible to rely on it in this way:\nfunction handleSubscribe(ctx) {\n    // Called every time subscription succeeds - including resubscribe after reconnect.\n    if (ctx.isResubscribe && !ctx.recovered) {\n        drawText(\"you need to restore messages from app backend\");\n    } else {\n        drawText(\"no need to restore state\");\n    }\n}\nvar sub = centrifuge.subscribe(channel, handleMessage).on(\"subscribe\", handleSubscribe)\nIs this what you expect?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thanks for the ticket. \n\nI can see having some basics on this would make the project more friendly for potential contributors. \nCan I ask if you found any specific areas confusing here?\nIt's been a while since I worked on Centrifugo but I recall it follows all the go practices and almost all of the points you mentioned would be more or less identical to any other Golang project. \nIf you ran into specific issues that would help guide the task. If it was just general Golang project familiarity we could maybe link to more general resources?\n\nOn 16 May 2017, at 04:33, Saravanakumar Mariappan notifications@github.com wrote:\nCreate Developer documentation about setup workspace , dependency packages installation for beginner , customise the code , build and run debug.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Sorry wrote that earlier before your reply. \n\nThat is useful context thanks!\n\nOn 16 May 2017, at 08:38, Saravanakumar Mariappan notifications@github.com wrote:\ni tried go build , got errors, I am using Gogland EAP IDE , go 1.8 version Please refer screenshot attached \n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Having actual message payload in the \"options\" configuration seems odd to me. As it's also separate param to publish as expected. Is this left over from an aborted refactor?\n\n\nEdit: ah I see from below history message is for some reason serialised separately from the one published.\nIs there a good reason for that? It's quite unpleasant interface to pass the raw bytes as an argument and then a struct with same data in as an option...\n. Perhaps add a comment here explaining what parameters are expected to mean? i.e. what are KEYS[1|2] and ARGV[1..4]?\nThis is all kinda magical and hard to read on it's own without that context.\n. Hmm NewScript call above specified 3 key arguments but we only pass 1 here.\nI think you are mixing and matching \"keys\" and \"args\" to the script which is not ideal. Redis docs say the \"KEYS\" arguments should \"represent Redis key names.\"\nWe should be stricter, I suggest:\n- KEYS[1] is the channel's history list key \n- ARGS[1] is the channel id for PUBLISH\n- ARGS[2] is the message payload\n- ARGS[3] is the HistorySize (0 means don't save history)\n- ARGS[4] is the HistoryLifetime\n- ARGS[5] is the HistoryDropInactive (0 or 1)\nThen we can call it like this:\n``` go\n// Initialize script with NewScript(1)\nif  opts == nil {\n    e.pubScript.Do(conn, e.getHistoryKey(chID), chID, message, 0, 0, 0);\n} else {\n    e.pubScript.Do(conn, e.getHistoryKey(chID), chID, message, opts.HistorySize, opts.HistoryLifetime, opts.HistoryDropInactive);\n}\n```\nThen the script itself becomes:\nlua\nlocal histSize = tonumber(ARGV[3])\nlocal histLifetime = tonumber(ARGV[4])\nlocal histDropInactive = ARGV[5]\nlocal n = redis.call(\"publish\", ARGV[1], ARGV[2])\nif histSize > 0 then\n  local m = 0\n  if histDropInactive == \"1\" and n == 0 then\n    m = redis.call(\"lpushx\", KEYS[1], ARGV[2])\n  else\n    m = redis.call(\"lpush\", KEYS[1], ARGV[2])\n  end\n  if m > 0 then\n    redis.call(\"ltrim\", KEYS[1], 0, histSize)\n    redis.call(\"expire\", KEYS[1], histLifetime)\n  end\nend\nreturn n\n. Huh so the history message is somehow different from the published payload? I guess I missed that. Is that necessary?\n\nedit: just checked above and it's not even different :) this just duplicates the json encode already done on the caller - the []byte is already the same as messageJSON currently.\nWhat was rationale for wanting to separate the two version of message?\n. Ah I see so just taking the current value and copying it causes non-atomic reads of the counters which races with atomic increments...\nI still don't understand why that would actually cause a nil pointer or invalid memory reference as in the original report...\n. Ah I guess I made mistake here - I thought about it as if this was a pointer to Metrics not a Metrics copy.\nI think just making it a pointer probably solves the race since there would be no read of the counter values here.\nThen when it comes to marshal the JSON, the Metrics marshalling code takes care of only reading the non-atomic stuff here.\nBy adding GetSnapshot, we are kind of doing the copy twice, both under lock.\nDoes just changing this to a *Metrics in NodeInfo make the race detector happy?\n. Huh ok well go with this for now. Does it solve all races reported?\nSorry I didn't think to check this. \n. Why atomic load? Before all reads and writes to delta were done only under lock. But I may be missing something on my phone!\n. This unaligns all the counters below. You said \"no need to align\" but I don't see why not - as long as you are still dong atomic ops on the ints in the struct a below they will still need to be aligned. \nPerhaps a murex happens to be 8 bytes? Even if so (and my gut feeling is it isn't) that is a platform/implementation detail I don't think is guaranteed so we shouldn't rely on it. \nI think since the bool is gone we can just move this to the end. \nWe probably need to include in comments on both these structs reminders not to unaligns them again. \n. Can't you use zremrangebyscore to do that in one command?\nIt has to do loop inside but much lower overhead for lua calls etc. Probably insignificant for common case when there will be only very short list of expired entries though\n. Sigh. \nYep sorry ignore me! Apparently I need more sleep. \n. Hmm, this works but it feels off to me...\nIt's intentionally creating overhead and contention on the publish channel etc as well as spawning maybe thousands of goroutines. Perhaps that's not too bad in practice, but in theory it would be possible to do this much more efficiently if we had a real async API in our engine interface.\nMaybe something for the future?\n. How about this very simple change to engine interface:\n- Make another method publishAsync which has same args but which returns <-error instead of error.\n- publish implementation then becomes:\ngo\nfunc (e *RedisEngine) publish(chID ChannelID, message []byte, opts *publishOpts) error {\n    return <-e.publishAsync(chID, message, opts)\n}\n- Cases like broadcastCmd above are now way more efficient and can just do something like:\n``` go\nerrs := make([]<-error, len(channels))\nfor i, channel := range channels {\n    errs[i] = engine.publishAsync(channel, ...)\n}\nfor _, err := range errs {\n    if err != nil {\n        // decide how to handle partial errors - just log?\n    }\n}\n```\nI think that makes broadcast case much simpler without affecting backward compatibility of engine interface, not complicating the engine implementations much (it's just a few lines more code).\n. Nitpick but that name is a little bit confusing. It's real purpose is a synchronous helper so maybe publishSync would be cleaner name?\nNot a big deal if you disagree though.\n. I suggest larger max value - a thing over 10 seconds is bad but if you have heavily loaded server for a few mins and all you can see is that 50% of requests took more than 10s it's hard to know if that's a bit bad (they all took 11 seconds for the peak) or awful (they all hung and took 5 mins before client timed out). HDR histograms are pretty space efficient so going up to 10 mins should be negligible. if space is a big deal then you can reduce low resolution - nothing is likely t be faster than a few hundred microseconds so you could start at 10 or 100.\n. This is a good start. Would be great to have separate late view at least for the important things like publish/connect/subscribe etc. Not sure how much work that is though and danger of bloating the stats output I guess although more is better in my book - people can just not look. \n. 60 would be ok but I'd still prefer more - it's relatively cheap and the cases where it gets high are probably exactly the times you need to know details. \nFor example Elasticache redis can take up to a minute to failover. I'd like to know if the requests took that long because they were waiting for failover and then completed or if they all hung because they queued up and overloaded new redis when it came up for example. \nIt's quite contrived and more than a minute probably you would get clients timing out too, just saying in general is tend to keep as much data as possible about extremes and I think it's not that expensive to do it with hdr histogram... If 60s is significantly cheaper than 10mins fair enough but my vote is for more where possible - who know what you might cat h and what insight you might have never had when you throw data away...\n. Actually, I guess we have lower timeout on redis connect and return error to client rather than waiting... so maybe this is moot. The principle stands but 60s probably is good enough for this case.\n. I didn't think too hard.\nI was most interested in whether we can expose the difference between say publishing stuff and fetching history/messages etc.\nIt's not crucial though.\nOne option I was considering (ignoring the aggregated part still) would be that we start a timer before JSON unmarshall, but then don't record the value until the end of the request (we do that here already with defer...) and then by the time we record it, we know the command(s) issues and can record them like http_publish. If JSON fails we can record it as http_error or something?\nThe alternative would be to measure individual commands like you said as well as overall requests like now - that way you get some insight into which operations are fast/slow but also what general overhead of Marshalling is?\nI dunno now I'm thinking about it it's harder to see the value. I was hoping that this would be detailed enough that anyone could do performance testing without instrumenting - e.g. you'd be able to do next round of optimisations of publish path just using these metrics rather than external measurements or additional logging in the code.\nBut maybe that much detail is not generally useful.\nThis PR is a great enhancement at any rate Maybe lets push it like this and we can see if additional detail is useful to anyone later?\n. Nitpick but this line added at start of comment makes it fil the test of Go standard docs - it no longer begins with the Function name... Would be picked up by go linter for example. You could add a probabilistic test of the hashing here, it might not be a good candidate for CI as it would be not be reproducible, but it's hard to have confidence in implementation of something like a hash function unless there are code tests that at least sanity check that for some example(s) it produces roughly the expected distributions.\nIn the past I've written them where I've picked generous bounds like hash 1000 random keys into 5 buckets and assert that each bucket has between 150 - 250 items.\nYou could also assert that adding a bucket doesn't move more than 20% keys (plus some margin for error/random chance so say 30%). If you make it tolerant enough it's unlikely to fail while still sanity checking there is no dumb typo introduced in the algorithm that will badly skew it's performance in practice.\nI've seen this before where someone didn't test probabilistic code because it was no-deterministic like this but then when I analysed it, they had an off-by-one error that had skewed group assignment in A/B tests for years by enough that it basically invalidated all the conclusions drawn from several years of running A/B tests :(. FWIW I can't see a defect in the implementation compared with the paper other than the redundant hash as noted. But I'm never confident of code that I can't at least see passing basic sanity checks!. I assume go does the right thing and interprets that literal as an int64 here especially given the multiplication with an int64 but did you verify that? truncating that number accidentally would destroy the properties of this hash.. This seems like an odd decisions, I'd just fail or try to distribute shards evenly between the hosts rather than put all the remaining shards on the first host.... There are no no-op requests any more are there?. Comment is wrong now ;). Unbounded? Isn't the whole point that it is bounded and this is needed to enforce total length bound?. ",
    "CodingNemesis": "Can Centrifugo work with LedisDB (http://ledisdb.com/)? Most Redis clients can apparently connect to it.\n. ",
    "criloz": "@FZambia  love the nats PUB/SUB engine in nats, I will use it,  the db  part should be implemented in redis at  the moment, but I am thinking in experiment other alternatives  like  serf and raft in centrifuge for my use case, . ",
    "rtsisyk": "You can take our RPM/DEB specs as an example:\nhttps://github.com/tarantool/modulekit/\n. ",
    "Sulverus": "@rtsisyk, probably we need to add go language support in docker images\n. ",
    "roytan883": "about the Edge Case:\nCan you treat channel is active when at least one user online(SUB) in TTL of history_lifetime once.\nconsider the following:\n\nClient connects and subscribes to foo (which history_lifetime is 1 hour)\nNo messages are published before client loses connection (phone goes into tunnel for example)\nWhile client is offline, message A is published into foo\nAlthough there are no active subscribers (dropped connection pubsub state cleaned up) AND no existing history.  But foo has client subscribed in history_lifetime TTL(1 hour). So foo is active. Then the message saved in memory or redis for channel foo.\nClient reconnects within history_lifetime with recover option. And client get A.\n\nI think this is somehow solve the Edge Case. If one channel has no subscription in TTL time, then it is inactive, otherwise it is active. For those channel with no subscription in a long time, it always inactive, no memory cost.\nAnd to implement this is also simple, just one field lastClientSubTime compare TTL can do the job.\n. @FZambia lastClientSubTime is not replacement of your current history_drop_inactive logic. It just an additional logic which should add to history_drop_inactive logic. \nFor this scenario:\n\nAs client connection can live days and subscription could be created a week ago for example. \n\nlastClientSubTime will treat this channel as inactive. But your rule:\n\ncheck if engine.publish() actually delivered to anyone\n\nshould work, mark this channel is active, because the channel has subscriber.\nSo the active conditions should be any one of the three:\n- check if any subscription or unsubscription happened in history_lifetime TTL (from now-TTL to now)\n- check if engine.publish() actually delivered to anyone\n- check if history already exists (i.e. something was listening in the last history_lifetime) \nAlso I think the first rule can optimize the history_drop_inactive performance in real world. Just save lastClientSubTime in memory or redis for each channel. For most active channels which have users online and offline frequently, most of their lastClientSubTime will be in TTL. So in most scenarios no need do the engine.publish() and history already exists inspection which may much slower than TTL check.\nlastClientSubTime maybe named wrong, perhaps lastClientSubOrUnsubTime will be better. Both subscription and unsubscription in TTL should be treat as active event.. Can customize websocket_compression_min_size ? for small message no need do the compression. Currently we use 2KB as the boundary.. We have 110K organization now, 5 million users (onlines are few based on total users, but we still need guarantee when user online they can get missed messages from its organization). And actually in our nodejs server, we save message in shared reference way to reduce memory usage.\neach organization have different users 10 ~ 5000. The biggest root organization has children about 70K sub-organization struct in tree.\nFor the bottom organization , it may has about 1~20 upper organization parents. Each parent organization can publish announcements. Parent  may only publish to its own layer, or self and direct children organization layer , or include all children organization layer. \nThat means there are two options to design the push rule:\n1: As your suggestion, children organization users subscribe all parents organization  channel. That will quickly increase channel users. The root organization  channel may have 3 million  users need subscribe . And the second layer organization  channel may have 2.99 million  users need subscribe. But the message only need push to one channel once. The message memory is small ,but maybe the channel will have pressure with such huge users subscription.\n2: Broadcast the message to those channels which need to be notified. This means each organization  channel only have its own user subscription, but need publish the message to many channels. \nSeem both options  are not good ......\n4KB just a sample to question the issue. In fact, most our message is less than 1KB. But still it is a big problem to save those message which need send down to child organization.\nIn our old nodejs server, all real message save in a big hash map with max TTL, each channel or topic only store the message IDs, only when push to client or client request the message, than get its real body from the message map.\nFor centrifugo , maybe we can do the save thing. First analyze the longest TTL time of \"channels\": [\"CHANNEL_1\", \"CHANNEL_2\", \"CHANNEL_3\"] when broadcast. Then save real message body in one big hash TTL map. Each channel only save the hash message id.\n. I rethink this problem today. I guess the \"TREE\" structure organizations should not put in centrifugo. And also the announcement should not send down in the \"TREE\" structure. \nBecause the upper and lower organizations can remove the relation, save announcement  in each organizations is not a good idea. If the relation changed, or announcement  itself was modified, then need sync many organization's  announcement, it is lots of work.\nI should only use centrifugo for real-time chat message PUSH of One2One and organization itself. \nOther group multi-layer sending messages should use QUERY sync mechanism, because most of those kinds of messages no need real-time.. Today i read the source code. I think it already use message reference. \n```\nbyteMessage, err := resp.Marshal()\nn.clients.Broadcast(ch, byteMessage)\n...\nfunc (h *clientHub) Broadcast(ch string, message []byte) error {\n...\n        msg := NewQueuedMessage(message, true)\nfor uid := range channelSubscriptions {\n    c, ok := h.conns[uid]\n    if !ok {\n        continue\n    }\n    c.Send(msg)\n}\n\n```\nIt use slice []byte for QueuedMessage's Payload. So no matter how many queue used, the payload use the same slice []byte.\n@banks @FZambia \n\n\"Now it would indeed copy the message 10k times\" \n\nSeems it is not using deep copy depend on those source code. . Seems it is not using deep copy depend on those source code ?. I guess i'm wrong. \nIt use message payload reference for clients, but create different new messages for channels.\nAt channels level, it use deep copy.\n```\nfor i, ch := range channels {\n    if string(ch) == \"\" {\n        resp.SetErr(proto.ResponseError{proto.ErrInvalidMessage, proto.ErrorAdviceFix})\n        return resp, nil\n    }\n\n    chOpts, err := n.ChannelOpts(ch)\n    if err != nil {\n        resp.SetErr(proto.ResponseError{err, proto.ErrorAdviceFix})\n        return resp, nil\n    }\n\n    message := proto.NewMessage(ch, data, client, nil)\n    if chOpts.Watch {\n        byteMessage, err := json.Marshal(message)\n        if err != nil {\n            logger.ERROR.Println(err)\n        } else {\n            n.PublishAdmin(proto.NewAdminMessage(\"message\", byteMessage))\n        }\n    }\n\n    errs[i] = n.Publish(message, &chOpts)\n}\n\n```. thanks, i got it.. by the way, does the client need re-subscription when shortly disconnect? because the mobile network can lose connection and reconnect frequently.. @FZambia \nAbout \"subscribe \" command :\nFor example:\nIf userA want join groupA on backend server. \ncurrently, userA need subscribe channel \"public:groupA\" by itself. it works like this:\n1, client userA -> backend(join groupA)\n2, backend -> userA (join groupA OK, now you should subscribe groupA)\n3, client userA -> centrifugo (subscribe groupA)\nThe point is step 3, can be:\n3, backend -> centrifugo (userA subscribe groupA)\nThat means the client should be fully passive. client no need subscribe any channel by itself . All subscription can be done by backend call centrifugo's Server API, backend server tell centrifugo which channels user want to subscribe.\nIt can simplify client logic, client no need concern which channel it should be subscription.  \ncurrent sync subscription status need \n1\uff0cclient<-----> backend \n2\uff0cclient<-----> centrifugo\nit can be simplify to :\n1\uff0cclient <-----> backend \n2\uff0cclient <----- centrifugo. @FZambia \n\"there is no way to handle async subscriptions\", it confuse me. \nwhy \"unsubscribe\" can be call by backend, but \"subscribe\" can not ?\nYou mean the client can only do subscription once at beginning , then it can not subscribe any new channels at runtime?. The whole point is:\n\nMake the client simplify, just call connect, then handle OnMessage, that's all. \nThe subscription logic can be done by server side between backend and centrifugo. . 1\uff0cI want backend manage all subscriptions, backend server like a babysitter for all clients. clients no need worry about sync subscriptions status. It is still subscriptions are self-managing for Centrifugo's view, but managed by backend server. \n\n\nexample 1\uff1a user join a temporary chat group , currently the client need subscribe a new channel, then when user leave , client need unsubscribe. If use my suggestion , client no need do any thing with centrifugo, it all handled by backend server. If the backend is intelligent, backend can delay the subscription when there have real new message in that temporary chat group, so if one user just fast join and leave temporary chat group in 3 seconds, then no thing happened.\nexample 2\uff1a mobile network can lose connection and reconnect frequently, if one client has 50 subscribed channels , then each time reconnect, client need send 50 subscriptions command , it waste more phone battery and network traffic. If all of that can be done by backend, client only need connect to Centrifugo. This somehow solve the reconnect frequently issue.\n\n2\uff0crecovering missed messages can be handled by backend, backend can provide a API \"getMissedMessages\" for client. And it will be much faster then client call each channel history by WAN network, because in most case, backend and centrifugo are running in the same LAN network. clients just post all channels last message ID to \"getMissedMessages\". Especially when the client has a lots subscription channels , faster and efficient by one API call for all channels.\n3\uff0cI think in most case there is no real client subscription, that client subscribe a new channel but backend don't know that, it is horrible. Especially on business layer , i provide service , but i don't know who use it. I think the common logic should be :\n\n\nclientX -> backend (hi, i want subscribe channel \"topic-A\");  \nbackend (check clientX authority, user role, channel \"topic-A\" settings ..... if all OK);  \nbackend -> centrifugo (make clientX subscribe channel \"topic-A\")\nbackend -> client (OK, your subscription was made, just wait new message from \"topic-A\") \n\n\nI think for sync client subscriptions it will be much easier and effective by backend -> centrifugo then backend -> client -> centrifugo, because backend should know client's all subscription channels. . No matter which use case it is , but on Server API layer, centrifugo Server API command already has \"unsubscribe\", which give the ability to backend server side controlling user unsubscribe channels . Corresponding, there should have \"subscribe\" command for backend server side controlling user subscribe channels. \nIf no \"subscribe\" coupled \"unsubscribe\", on Server API layer, it doesn't make sense.. @manson \nif topic-A administrator want kick clientX, how to do that ? \nbackend -> clientX: you should unsubscribe \"topic-A-xxxx\" ?  what if client has something wrong or not unsubscribe or even not received this message, what happened ? \nIn this case, the only thing backend server can do is calling Centrifugo's Server API \"unsubscribe\" which force clientX to unsubscribe \"topic-A-xxxx\". But if you do that , here comes question : why backend can server side call \"unsubscribe\" but can not server side call \"subscribe\"???. @manson in your opinion , I think Centrifugo should remove the Server API \"unsubscribe\". Otherwise it doesn't make sense that only has \"unsubscribe\" but NO \"subscribe\".\n\nunsubscribe allows to unsubscribe user from channel. params is an objects with two keys: channel and user (user ID you want to unsubscribe)\n{\n    \"method\": \"unsubscribe\",\n    \"params\": {\n        \"channel\": \"CHANNEL NAME\",\n        \"user\": \"USER ID\"\n    }\n}. @manson \nIf you're about security, make private channels to users or random for every user. And then just dont send data into this channel client listening to stop him receiving data. Anyway in a public or commonly used channels (for groups) you cannot rule security strictly. And as of this did user unsubscribed or not is not important\n\nTo implement a chat room and its administrator, is that hard? need create lots of private channels for every user, just to implement one simple feature request \"kick user\" ?. @manson I think the big difference opinion between you and me is : \n\nin pub/sub system, who make the subscription ? I think your are insist on that subscription can be only made by client. But my opinion is both the client and backend server can make subscription. \n\nwe just want use pub/sub system to implement a push service , like Apple's APNS. I don't think APNS all subscription are maintained by client. If you have  experience on iOS development , the only things need is \"DeviceToken\" from client to APP backend, then no matter how many channels or groups inside that APP, client no need call APNS subscribe on any channels .. @manson \n\nOh? its all about chat? Ok lets see. First of all ......\n\nI get you point , and your suggestion  is good. \nThe things is, all your saying is based on one rule: Client is the only one can make subscription. But why? Does there have any specification about pub/sub system that rule ? what the bad effect if backend can server side full control user subscription ? . @manson \ntake a look at the Centrifugo Document :\n\nCentrifugo server easily integrates with your existing application \u2013 no need to change your project architecture and philosophy to get real-time events.\n\nbased on this, I don't think client handle subscription is a good idea. client should not concern which and when to subscribe or unsubscribe channels. The seamless integrate Centrifugo is only doing \"connect\" and \"onMessage\" on client side, thats all. \nAll complex stuff should be handled by backend server. For example, you know that modify own server is much much faster than Apple's App store review and wait user to upgrade their client version.\nMake the client simple and clean , let the backend do the complex and heavy stuff , that is my current prefered APP architecture.. @FZambia @manson \nOK, maybe on big picture APNS is not a good example. My point is like this:\nfor client side code, it should be clean and simple. like use APNS, client side code only need 3 step:\n1\uff0cregister which APNS get DeviceToke; 2 send tokens to backend ; 3, wait new message , you see, at least, at source code level, there  is no code about get channels, subscribe, unsubscribe ......\nwhat i want my client to integrate with centrifugo is the same . I want my client side code is like this:\n1\uff0cget centrifugo host address from backend api ; 2\uff0c connect to centrifugo ; 3\uff0c wait new messages, that's all. what the bad effect if i implement my client code like this ?. @FZambia \n\nCentrifugo does not have this information - because client channels are app specific. So every time clients will reconnect they should anyway send message to your app backend so backend can subscribe them to correct channels sending subscribe request to Centrifugo? If yes - this destroys your arguments about battery usage and traffic - you will have almost the same as we have now. Maybe I miss something?\n\nIt comes to the question again, Why subscription only handled by client side? In my plan, backend know all client's subscriptions. So this is simple, when client reconnect to Centrifugo, backend hooked it from Centrifugo, then backend call \"subscribe\" for that client user (server side recover client's subscriptions). During the reconnection, the client is fully passive. \nThe problem is how to recover missed history , as my suggestion , backend can provide one API \"getMissedMessages\". when reconnect,  client need at least call one API to receive missed messages, I think this is common case for APP development.\nfor example , one client have 50 channel subscriptions. currently , when reconnect , client need send 50 subscribe command to Centrifugo, because subscription must handled by client. In my suggestion , client don't need send any thing except call \"getMissedMessages\".. @manson \nIn modern chat app, I don't think it still use join and leave rule, only one channel active rule. It is more like join group and stay, like Skype. If i join 10 groups, and my Skype is at background, when new messages comes from any group, should a notify shown. \nFor you example , user may subscribe lots for topic or channels , like 1000 channels. Does that mean the client should maintain the 1000 subscription ? join,leave, kick, subscribe ,unsubscribe at least those source code need to be implement in client side, and additional code to sync those subscription with backend server when user may operate it at PC or web. So what benifit we get from \"only client handled subscription\" ?. @manson if use your suggestion to implement a cross-platform APP: ios, Android , PC, web. At least, the synchronization of subscription information on each platform  is complex, because \"only client handled subscription\"\nfor example : \n1\uff0cuser-A use Android client subscribe \"topic-A\"\n2\uff0cbackend notify user-A's: ios client, PC client , web webscoket page client;\n3\uff0cthose client subscribe \"topic-A\"\nwhy can't we let backend handle step 2 and 3 ? \nI think to make one backend server code right is much easier, compare to make 4 different platform and 4 different develop languages synchronize subscriptions code right .. @manson \n\nCentrifugo server easily integrates with your existing application \u2013 no need to change your project architecture and philosophy to get real-time events.\n\nI don't know how do you understand upper sentence.\nWith my plan, it may only 10 line code at client side\nconn = Centrifugo.init(host)\nconn.setAutoReconnect()\nconn.onMessage(centrifugo.Message msg) {\n   oldMessageHandler(msg.data)\n}\nconn.onReconnect() {\n   backend.getMissedMessages()\n}\nconn.start()\nI don't how many lines you need to implement those feature subscribe , unsubscribe , sync others platform client subscription. I guess there will be lots of code like this:\nbackend.joinGroup(\"groupA\", callbackFunction(err, groupInfo){\n     if (err)\n        centrifugo.subscribe(groupInfo.channelId)\n }\n)\n......\nbackend.onSubscriptionChanged(groupInfo){\n   ..... check if this client has subscribe or unsubscribe \n   ..... do subscribe or unsubscribe \n}\nI think this is what we called intrusive code. Then read this sentence again:\n\nCentrifugo server easily integrates with your existing application \u2013 no need to change your project architecture and philosophy to get real-time events.. @manson \nI dont get you. You make all the same client subscriptions from all platforms. Server doesn care from where you made subscription. Dont make server complex. All client will make the same steps on connect: make some queries (get latest messages) and subscribe to new one. From the serverside you of course may store linsk clientId->userId (clientId - unique client connection, userId - user id from db) to send info to all platforms in case of private channel. But if this is public channel you dont have to do anything at all on server side. Just push message to channel and forget\n\nOK, The simple use case:\n\n1, user-A login on iPhone client , Android client , PC client , web client, simultaneously\n2, user-A use iPhone client joined a new private channel \"topic-123\": this \"topic-123\" already has few user: user-B, user-C ...., and they may send new messages.\n3, what next ? I want the user-A's other client(Android client , PC client , web client) also can get new message from \"topic-123\"\n\nI don't how you implement step 3. \nBut in my solution, client side code on step 3 is none , because all stuff are handled by backend server\n. @FZambia \nThat's right. corresponding current \"unsubscribe\", it may like this:\n{\n    \"method\": \"subscribe\",\n    \"params\": {\n        \"channel\": \"CHANNEL NAME\",\n        \"user\": \"USER ID\"\n    }\n}\nfor performance , also provide \"mSubscribe\" will be nice:\n{\n    \"method\": \"mSubscribe\",\n    \"params\": {\n        \"channels\": [\"channel_1\", \"channel_2\"],\n        \"user\": \"USER ID\"\n    }\n}. @FZambia \n\nSee my updated post above - we can't operate with User IDs here - we must subscribe per client (per tab in browser in other words) - because the same user can see another page in other tab of browser and not interested in events for another page.\n\nI don't get it. you said the same user, so when user subscription changed, it should sync with user's all client. \nlike currently the github page's right upper corner, the notification, when new message comes, all github browser tab show that blue point notification. \nfor example, i opened an old github browser tab, then open a new github browser tab, subscribe new repository , when the new repository has notification , my old github tab also get new blue point notification.. @manson \n\nIn common solution you dont have to to something special on step 3. This is all the same - you enters from another platform, does the same as if you enters from android. \n\nyou mean user need manually open Android client , subscribe \"topic-123\" or re-login, by hand ??? manually ??? \nI don't get it , how you implement step 3, how to make Android client automatically receive new messages from \"topic-123\". . @FZambia @manson \nI think you are talking about traditional web page. But currently , web are more turn to SPA(single page web application), like angular or react, redux. web is more like a web client , not web page, especially APP area. \nYou are worry about tons of message and network traffic, I think that's problem about what kind of message should be publish to channels. If only realtime message like chat message, i don't think it a problem. That depend on how APP's message architecture, can have some channel for user like  @xxx @forceALL @forceTopicA. Also APP can limit user's join channels (100?), no limit subscription is not support.  By the way, in real world, simultaneously real time messages in one user's different  channel is very very few. . @manson \n\nOk. Make this simple steps:\n.\nsubscribe to topic-1 from android \nsubscribe to topic-1 fom web\n\nhow to implement it? how  Android know that should subscribe topic-1 ? \nneed user manually awake his Android phone and open client APP, then manually click subscribe \"topic-1\" ? \nor need somehow server send notification to Android client, then android client automatically subscribe to topic-1? show me the code.. @FZambia \nlike i use Skype , if i joined \"group-family-1\" ,\"group-company-1\", \"group-friends-1\" . If currently i'm at group-family-1's chat page sending or read messages.  Meanwhile \"group-company-1\" and \"group-friends-1\" has new messages published, should i receive those new messages? \nI think the answer is YES. we are develop service for user, we are not technology decide which message should or not send to user. Its upto user. If the user is a salesman, he join lots of group , he want receive all messages , that is value for him. For normal user, if he joined too many group , those group messages already bother him, then it should be his responsibility to choose which group message need filter or leave that group, when he do it , our backend server just simplify unsubscribe that group's channel for him. Normally , we develop a chat APP, we provide user a setting options on every group, which are: \"receive all notification\", \"receive All notification but not notify(ring)\", \"do not receive manually read\".. @manson \n\nBut you suggest exactly this. You want to realtime load all the new messages from all channels and filter it on client side. Even those messages you might even wont need (you wont go to all those channels).\n\nyou are not reading my comments, filter not runned on client side.\n\nit should be his responsibility to choose which group message need filter or leave that group, when he do it , our backend server just simplify unsubscribe that group's channel for him. \nNormally , we develop a chat APP, we provide user a setting options on every group, which are: \"receive all notification\", \"receive All notification but not notify(ring)\", \"do not receive manually read\".\n\n\n@manson @FZambia \nOk, the manual channels subscription synchronization way is not our choice , no one like that in today cloud everywhere. \nThe solution is like server -> client (message: you should subscribe topic-1), client -> centrifugo (i want subscribe topic-1), no matter it is implement by private channel or other push system or sync plan. like i said need somehow server notify android client, then android do subscription .\nThe question is Why client need handled those kind of notification to know that it should subscribe topic-x ?  Why my client developer need write those source code to react channels subscription synchronization ?  \nCentrifugo claim that it can seamless integrate with existing system. What i provide is a simple and clean integrate plan, Why you insist on invade client code to handle all sub-unsub. This is big question i'm confused. If i can provide client developer with 10 line code to use Centrifugo , Why you insist on write more code on client side? . @manson \n\nOh, I think I got you. It looks like your solution should be like this: ..............\n\nNo, its not like that. If user-A joined group 1~100\uff0c then it subscribe \"group-1\" ~ \"group-100\", they are 100 subscriptions. \nyour misunderstanding me is : \nwho do the subscription command ? \n\nThe result is the same : user-A's client subscribed 100 channels on Centrifugo. \nThe method is different: you use client do the subscription , i use backend do the subscription (as @FZambia named it: server side user subscription controlling).\n\nanother difference is : At client side, my solution only need 10 lines code, yours i don't know. I already answered, the channels filter is handled by server side, so the network traffic is the same , or my solution is less, because my solution do not send any sub-unsub command to Centrifugo.. @manson \n\nmanually, automatically - whats the difference?\n\n\n\nmanually, it botherthe USER. \n\nautomatically, my solution is only bother backend server developer. Your solution is bother both the client developer and backend server developer. . @manson \nThere is no miracles. In development bothers both sides. In a good product\n\n\n\nNo, in a good product, is let server handle those dynamic frequently changed logic, let client be dumb just do basic logic and show. Currently , most successful APP on iPhone and Android , is hybrid APP, half native haft web page. If a application logic can be handled by server then no need chagne the client. \nlike our argument, if the subscription can be handled by server , why bother client ?. @FZambia although i don't get why can't \"subscribe\" by User_ID, but i think if you provide \n{\n  \"method\": \"subscribe\",\n  \"params\": {\n    \"client\": \"CLIENT-ID\",\n    \"channels\": [\"channel_1\", \"channel_2\"]\n  }\n}\nthen my backend can call it multiple time to implement server side controlling user subscription for all that user's client. \n@FZambia by the way, does Centrifugo provide method to get USER_ID's all CLIENT_ID ? . @FZambia \nYes, this is a good example. \nIn current approach:\n\nIf channels are public no requests will be made to server backend at all (and I consider this is a main Centrifugo feature, most use cases are ok with public channels)\n\nbut the client still need send subscribe to public channels to Centrifugo after reconnect ? right? as your answer Yep, it does - after disconnect Centrifugo node cleans client connection info. Because  the client don't know the reconnection is caused by network problem or server problem. so every client will subscribe its channels again , then lots of subscription command are made to Centrifugo , must be more than 100K.\nSo in current approach, its not cheap when Centrifugo restart .\n\nIn my approach:\n\n\nAfter reconnect every client will issue a request to your backend - i.e. 100k requests in any way\nThen 100k requests from backend to Centrifugo\n\n\nbackend can have request limitation when very large requests post simultaneously for this performance concerned API.  for example , limit to 100/s, so it is 6k/min, for 100K, only need 16 minutes. We are talking about Centrifugo restart, this shouldn't happen frequently. If it really happen , then need 16 minutes, I think its a reasonable time cost. For those deny request , backend  API will return a specified error to client , let it retry in a random 30~60 seconds. \nIn real world, when server restart, client reconnect , those thing happened in background, most our client is in sleeping background mode, only user are currently using our APP at front, then user will notice that connection lose.  And in real world, server performance is much better than 100/s, it will be recovered quickly, even the user have not noticed connection lose.\nI think its a common issue about requests limitation , like nginx or other server , can config a reasonable limitation.\nfor centrifugo, can do the same thing to limit connection rate. If centrifugo do those limitation , then backend no need limitation :) because step 2 is triggered by step 1's succeed reconnect. Anyway , backend API server should have basic requests limitation for all APIs. No matter how powerful Centrifugo, or nginx , or our backend server , there always need requests limitation setting. \nIn your example , 100K clients, if each client need subscribe 10 channels . Lets do the math, how many network traffic need: 100K connect command , 1000K subscribe command . You see , in my solution , the 1000K subscribe command were saved, it running in server side LAN network. . Thanks, I got it. @FZambia Thanks\narray of commands works for me. ",
    "jeberly": "\nan additional feature such that Centrifugo remains a complete solution for both in-page and out of page updates\n\nIt would be ideal for our use case.  Single solution for all in/out of page updates.  SSE might be a consideration too, but I don't want to add more feature bloat. :)\n. ",
    "Garito": "+1\n. ",
    "MadHamza": "Thank you Paul for the hint.\nIndeed, I've checked the info parameter I'm passing to the authEndpoint function and found out that's not a genuine json.\n. @FZambia  No more questions. Thank you!! Sure you can close it. \n. ",
    "x1unix": "@banks it happens after every API request to centrifugo. I use Centrifugo PHP api. I've downgraded to 1.3.3 and that's was a single solution at the moment.\n. @FZambia I'm using 64-bit architecture (x86_64) on CentOS:\nCPU: Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz\nOS: CentOS Linux release 7.2.1511 (Core)  (x86_64)\n. @FZambia looks like v1.4.1 is working without crash, I'll test it now.\n. @banks Thanks :)\n. ",
    "oddurmagg": "There seems to be a workaround in #21 \n. It makes me have to jump through hoops in the dockerfile where I need to pass the environment variable to the command line. And the docker CMD does not do enviroment variable expansion by default, so I need to invoke sh and through that invoke the actual binary. \nsee: https://docs.docker.com/engine/reference/builder/#cmd\nReading it in like all the other environment variables is much cleaner and I would prefer that. \n. Awesome ! Thanks\n. Either that or expose the already collected metrics in the format that Prometheus scrapes it in, which is a trivial text format. \nI\u00b4m gonna take a look at how metrics are collected atm in centrifugo to see how much work it would be to pipe them to the golang prometheus library. \n. ",
    "mediatec": "Thank you!\n. ",
    "AlexeySoshin": "In my opinion, constants will also make your code refactoring easier, instead of find&replace.\nAnd you don't produce GC this way.\nBut it's your choice, of course.\n. No problem, those are only suggestions.\nAnd if you'll use arrays for configurations, that will be fine by me.\n. ",
    "korvinko": "I know about presence method. But it not good often send request on server. Please consider include system event when someone connect and disconnect in channel\n. Answer found. Found that it possible by any official centrifugo client. But anyway, maybe you can consider include events functionality in server? \n. Ok, thank you for clarification.\n. Yes, thanks for explanation. Logrotate will solves my problem.\n. Thank you. I will try it now and will response about results.\n. Does not help me. I updated version centrifugo js client to 1.3.8 but after some time same user caught in reconnect loop.\nCentrifugo server did not restart after update client.\n. Log before starting this issue on server side:\n```\n[I]: 2016/11/14 12:21:36 Admin session completed in 59.181994736s, uid ad5d8bfc-cd61-415e-852b-053b3214ec01\n[I]: 2016/11/14 12:21:36 GET /socket from 178.126.77.39:49864 completed in 59.182772723s\n[I]: 2016/11/14 12:21:57 POST /api/ from 185.5.249.166:54984 completed in 996.691\u00b5s\n[I]: 2016/11/14 12:22:04 GET /connection/websocket from 178.126.77.39:49632 completed in 36m27.326398467s\n[I]: 2016/11/14 12:22:05 New raw Websocket session established with uid 1bfa3041-c8fb-4849-97d4-26b6f1528d56\n[I]: 2016/11/14 12:22:54 POST /api/ from 185.5.249.166:55478 completed in 280.485\u00b5s\n[I]: 2016/11/14 12:22:55 POST /api/ from 185.5.249.166:55486 completed in 218.081\u00b5s\n[I]: 2016/11/14 12:23:21 POST /api/ from 185.5.249.166:55534 completed in 743.715273ms\n[I]: 2016/11/14 12:23:24 GET /connection/websocket from 178.213.225.4:50587 completed in 1h7m57.896224078s\n[I]: 2016/11/14 12:23:24 error sending to 7a7757df-a747-43c2-89eb-697afdbb00e5 write tcp 185.5.249.166:8000->178.213.225.4:50587: use of closed network connection\n[I]: 2016/11/14 12:23:26 New raw Websocket session established with uid 64ee3960-1c6c-486d-84e3-494bfe96c1cc\n[I]: 2016/11/14 12:23:29 POST /api/ from 185.5.249.166:55546 completed in 244.01\u00b5s\n[I]: 2016/11/14 12:23:29 POST /api/ from 185.5.249.166:55550 completed in 710.461\u00b5s\n[I]: 2016/11/14 12:23:30 POST /api/ from 185.5.249.166:55558 completed in 271.787\u00b5s\n[I]: 2016/11/14 12:23:30 POST /api/ from 185.5.249.166:55560 completed in 184.173\u00b5s\n[I]: 2016/11/14 12:23:30 GET /connection/websocket from 178.213.225.4:62689 completed in 56m42.87719791s\n[I]: 2016/11/14 12:23:30 error sending to 8646a149-d047-454d-8ae5-1062115fe097 write tcp 185.5.249.166:8000->178.213.225.4:62689: use of closed network connection\n[I]: 2016/11/14 12:23:31 POST /api/ from 185.5.249.166:55582 completed in 704.033\u00b5s\n[I]: 2016/11/14 12:23:31 POST /api/ from 185.5.249.166:55596 completed in 806.088\u00b5s\n[I]: 2016/11/14 12:23:32 POST /api/ from 185.5.249.166:55598 completed in 819.393536ms\n[I]: 2016/11/14 12:23:33 New raw Websocket session established with uid 4dbf85dc-3919-4fcf-87d1-19486297226f\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n[E]: 2016/11/14 12:23:34 client is closed\n```\nWe can see follow error in this log before start problem:\nerror sending to 7a7757df-a747-43c2-89eb-697afdbb00e5 write tcp 185.5.249.166:8000->178.213.225.4:50587: use of closed network connection\n. Our backend combine and minimize js assets and generate unique filename. It can not be cache and that user refreshed page. I sow it in centrifugo log.  I sure that he has last centrifugo js version - 1.3.8.\n. Router traffic in that time:\n\nInternet channel: 10 megabytes (not bytes)\n. One user still in reconnect loop by we do not sure that he restart page. We will check how it works with update today, maybe, you was right that not each user refresh page.\n. Yes, it is good ideas.\nAnd I want to ask consider another one option. I need have ability to prevent getting old history for first connection.\nIn my application user after refresh page always have valid state of data and I do not want after refresh page for same user token getting old history. Could you please consider adding option to prevent getting old history on first user connection? Is it clear for you? Am I need create new issue for that?\n. Ok, good.\nProblem with reconnect not solved. It is 1.38 centrifugo js. Client try reconnect every second. Please see follow pictures.\n\n\n\n\n. Log in console:\nea36716\u2026.js:2109 reconnect after 1421 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1487 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1841 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1377 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1305 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1983 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1041 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1703 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1163 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1413 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1057 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1074 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1625 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1957 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1128 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1215 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1664 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1857 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1972 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1498 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1700 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1893 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1825 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Array[1]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send Array[15]h @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Objecth @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1074 millisecondsh @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"leave\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1036 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1946 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1756 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1460 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1402 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1174 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1537 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1268 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1136 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1243 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1530 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._resetRetry @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._addMessage @ ea36716\u2026.js:2109_transport.onopen @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received [Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connecting -> connectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.mango-api-notification_15h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.multiple-user-mode--servicesh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--clients.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.clientsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.visitsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.tasksh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.occupancyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.sync--services.occupancy-per-weekh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--services.workloadh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.updated--services.staffsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.saleh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 no last uid found for channel production.sync--sales.sale-historyh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 last uid found and sent for channel production.system-eventsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._getLastID @ ea36716\u2026.js:2109v._subscribe @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Send [Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object, Object]h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._send @ ea36716\u2026.js:2109v._flush @ ea36716\u2026.js:2109v.flush @ ea36716\u2026.js:2109v.stopBatching @ ea36716\u2026.js:2109v._connectResponse @ ea36716\u2026.js:2109v._dispatchMessage @ ea36716\u2026.js:2109v._receive @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Received Object {method: \"join\", body: Object}h @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onmessage @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reason is a plain string slowh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 disconnected: slow trueh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status connected -> disconnectedh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reconnect after 1538 millisecondsh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._disconnect @ ea36716\u2026.js:2109_transport.onclose @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 start connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 Status disconnected -> connectingh @ ea36716\u2026.js:2109v._debug @ ea36716\u2026.js:2109v._setStatus @ ea36716\u2026.js:2109v._connect @ ea36716\u2026.js:2109(anonymous function) @ ea36716\u2026.js:2109\nea36716\u2026.js:2109 reset retries count to 0h @ ea36716\u2026.js:2109v._debug @\n. Each user subscribe to multiple channels for isolation separate logic. I subscribe to each possible channel after \"connected\" event.\nWe have a SPA application and I can disconnect and connect to specific group event on separate view if you think it can be possible bottleneck here.\n. Can I up client size queue manually?\n. I need join_leave event to correctly work application. We need unlock all locked items after leaving client from application to allow other users work with that items. I would happy to disable it but it need for us.\nWe do not have so much users - about 10 users in centrifugo. Usually they work all day without refresh page. And we have totally about 25 channels in centrifugo. Each user can be subscribed about 13-16 channels.\nI think, it theoretically can be that user can get 60 messages. But I not sow it.\n. I can reduce number of channels for one user and so each user will have no more 2 channels in one moment. One for global events and second for specific view events. \nWill it help?\n. Message not so big. Max size messages should have similar size:\n{\n  \"user\": {\n    \"id\": 59,\n    \"first_name\": \"asdasdasd\",\n    \"last_name\": \"asdasdasd\"\n  },\n  \"task\": {\n    \"id\": \"452\",\n    \"text\": \"asdfasdfasdf aasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfasdfasdfasdf asdfsdf;\",\n    \"date\": null,\n    \"creator_id\": \"61\",\n    \"created_at\": \"1479018954\",\n    \"updated_at\": \"1479128489\",\n    \"distributed_at\": \"1479128486\",\n    \"status\": null,\n    \"lock_by_user_id\": null,\n    \"viewed\": null,\n    \"creator\": {\n      \"id\": \"61\",\n      \"first_name\": \"asdasdasd\",\n      \"last_name\": \"dasdasdasd\"\n    },\n    \"taskFFFFFClients\": [\n      {\n        \"id\": \"338\",\n        \"task_id\": \"452\",\n        \"client_id\": \"226\"\n      }\n    ],\n    \"clients\": [\n      {\n        \"id\": \"226\"\n      }\n    ],\n    \"taskFFFFObjects\": [\n      {\n        \"id\": \"307\",\n        \"task_id\": \"452\",\n        \"object_id\": \"249\"\n      }\n    ],\n    \"objects\": [\n      {\n        \"id\": \"249\",\n        \"address\": \"\u041c\u043e\u0441\u043a\u043e\u0432\u0441\u043a\u0430\u044f \u043e\u0431\u043b, dfsdfsdfsdfsdf\",\n        \"boiler_id\": \"4\",\n        \"client_id\": \"226\",\n        \"boiler\": {\n          \"title\": \"sdfsdfsdfsdfsdf\",\n          \"id\": \"4\"\n        }\n      }\n    ],\n    \"files\": [],\n    \"taskEnbsvVisits\": [\n      {\n        \"id\": \"186\",\n        \"task_id\": \"452\",\n        \"visit_id\": \"2075\"\n      }\n    ],\n    \"visits\": [\n      {\n        \"id\": \"2075\",\n        \"date\": \"2016-11-11\",\n        \"time\": \"00:00\",\n        \"time_end\": \"00:45\",\n        \"staff_id\": \"0\",\n        \"staff\": {\n          \"id\": \"61\",\n          \"first_name\": \"sdfsdf\n          \"last_name\": \"dfsdfsdf\n        }\n      }\n    ],\n    \"emails\": [],\n    \"phones\": [\n      {\n        \"id\": \"193\",\n        \"task_id\": \"452\",\n        \"phone\": \"asdfasdfasdf\",\n        \"contact_id\": \"342\",\n        \"full_name\": null,\n        \"contact\": {\n          \"id\": \"342\",\n          \"phone\": \"asdfasdfasdf\",\n          \"full_name\": \"asdfasdf asdfasdf\",\n          \"object_id\": \"249\"\n        }\n      }\n    ],\n    \"lockedByUser\": null,\n    \"executors\": [\n      {\n        \"user_id\": \"59\",\n        \"status\": \"1\",\n        \"task_id\": \"452\",\n        \"first_name\": \"asdfasdfasdf\",\n        \"last_name\": \"asdfasdfasdf\",\n        \"user\": {\n          \"id\": \"59\"\n        }\n      }\n    ]\n  },\n  \"type\": \"sync\",\n  \"id\": \"452\"\n}\nIn 10 minutes can be max 30 messages like this.\nCurrent centrifugo state:\n\nStats:\n\n. \"history_size\": 999999\n. History call execute very long time\n. Php client return exception for me.\n\nVersion php-client:\n            \"name\": \"sl4mmer/phpcent\",\n            \"version\": \"dev-master\",\n            \"source\": {\n                \"type\": \"git\",\n                \"url\": \"https://github.com/centrifugal/phpcent.git\",\n                \"reference\": \"a1148a7b3549bab355a5e9fff44416b76b02401f\"\n            }\n. No, we use in Memory engine (default option)\n. Ok, done. Will inform you about results.\n. After restart all clients works correctly. But history API from php client still return same exception.\n. Looks strange that web UI show me 110 queued \n\nWhen I set  history_size = 100 \n\n. Now it is ok, look like it work with delay.\n\n. Unfortunately,  some clients still goes in reconnect loop.  History_size does not help.\nCurrent stats:\n\n. I am not sure, but look like we found problem. I reproduced problem with reconnect loop after log in and some hours timeout.  Look like application loss TCP connection.\nWe added ping methods to client to prevent it. Will check tomorrow how it works.\n. Half day works good. Was only same problem for user on GPRS but it is ok.\nWe did not disable join_leave. Look like our problem was in TCP connection.\n. I cut some subscriptions but save code with ping:\n$rootScope.centrifuge = new Centrifuge({\n            debug: CrmSettings.centrifugoDebug,\n            url: CrmSettings.centrifugoUrl + '/connection/websocket',\n            user: CrmSettings.centrifugo_token.userId.toString(),\n            timestamp: CrmSettings.centrifugo_token.timestamp.toString(),\n            token: CrmSettings.centrifugo_token.token\n        });\n        $rootScope.centrifuge.connect();\n        $rootScope.centrifuge.on('connect', function () {\n            $rootScope.centrifugePingInterval = setInterval(function() {\n                $rootScope.centrifuge.ping();\n            }, 30000);\n            $rootScope.subscription = {};\n            $rootScope.centrifuge.subscribe($rootScope.buildCentrifugoEventName('sync--clients.clients'), function (message) {\n                $rootScope.$broadcast('sync--clients.clients', message.data);\n            });\n            $rootScope.centrifuge.subscribe($rootScope.buildCentrifugoEventName('sync--clients.tasks'), function (message) {\n                $rootScope.$broadcast('sync--clients.tasks', message.data);\n            });\n        $rootScope.centrifuge.on('disconnect', function () {\n            if ($rootScope.centrifugePingInterval !== null) {\n                clearInterval($rootScope.centrifugePingInterval);\n                $rootScope.centrifugePingInterval = null;\n            }\n        });\n. Thank you. I guess, it can be closed.\n. And one moment, when client disconnected by server please show more information.\nEntry like this is not informative:\n\n[E]: 2016/11/14 17:28:40 client is closed\n\nI need enable client logs to get more details. Whould be great to see in server logs userId and reason for disconnect.\nThank you again for you help.\n. Still meet same problem - disconnect slow and reconnect loop.\nIn logs found strange lines with very long connection time:\n[I]: 2016/11/16 10:20:18 POST /api/ from 185.5.249.166:39440 completed in 288.114\u00b5s\n[I]: 2016/11/16 10:20:18 GET /connection/websocket from 178.213.225.4:49955 completed in 1h20m2.920555422s\n[I]: 2016/11/16 10:20:18 error sending to 1bf295f2-922c-4159-ac88-47733d577edf write tcp 185.5.249.166:8000->178.213.225.4:49955: use of closed network connection\n[I]: 2016/11/16 10:20:19 POST /api/ from 185.5.249.166:39458 completed in 710.111\u00b5s\n. Join and leave event data not so big: just object with two fields:\n\nI have multiple channels for each user (about 8-13) so for each channel centrifugo send me leave and join event. For me one event enough but it not possible in this architecture of application and need refactor it.\nI no more can reproduce it by myself. When problem appear I see userId in webInterface that connect and disconnect each second. After that I know how is it and remotely connect to this computer to get logs. \n. Ok\n. Problem was on my side.\nMy application accidently sent bigger serialized array of objects (about 1900 items with nested objects) in one message. Size of message was about 6 megabytes. So, when multiple users worked with application their default limit 10 megabytes of client queue quickly overflowed. \nIn same time I found some useful practices for myself:\n1. Unsubscribing from channels when no more need listen.\n2. Using namespace to override default channels settings.\n3. Using only one channel with join_leave.\nAll of these helped me solve problem with overflow client queue and up effectivity of network.\nThank you, @FZambia for help. . Thank you for explanation. I want reduce join_leave events in channels. This is fit for me. \n. Same for 1.6.2. Yes, ping: false solved problem.\nOn client side centrifugo-js: 1.4.1 without sockjs. . Mistaked by repo. I will open issue in centrifugo-go. Hi. I already have certificate generated by certbot for nginx. Will it option generate new certificate for centrifugo or it could found already generated for specified domain?. Will builtin integration with lets encrypt upgrade SSL certificate without loose connection to prevent miss sensitive information during upgrade?. Something wrong with builtin integration. I tried start second centrifugo process on 9000 port for testing lets encrypt but it does not work. \nSecond config centrifugo\n{\n  \"ssl_autocert\": true,\n  \"ssl_autocert_host_whitelist\": \"MY_DOMAIN\",\n  \"ssl_autocert_cache_dir\": \"/tmp/certs\",\n  \"ssl_autocert_email\": \"my_email@gmail.com\",\n  \"secret\": \"my_secret\",\n  \"admin_password\": \"my_pass,\n  \"admin_secret\": \"my_admin_secret\",\n  \"port\": \"9000\",\n  \"join_leave\": false,\n  \"anonymous\": false,\n  \"publish\": true,\n  \"watch\": true,\n  \"presence\": true,\n  \"history_size\": 100,\n  \"history_lifetime\": 1800,\n  \"recover\": true,\n  \"history_drop_inactive\": true,\n  \"namespaces\": [\n    {\n      \"name\": \"system\",\n      \"publish\": true,\n      \"anonymous\": true,\n      \"watch\": true,\n      \"presence\": true,\n      \"join_leave\": true,\n      \"history_size\": 0,\n      \"history_lifetime\": 0,\n      \"history_drop_inactive\": false\n    }\n  ]\n}\nLogs centrifugo process:\n[I]: 2017/06/22 12:58:01 Config path: /root/test_centrifugo/config.json\n[I]: 2017/06/22 12:58:01 Centrifugo version: 1.7.3\n[I]: 2017/06/22 12:58:01 Process PID: 10960\n[I]: 2017/06/22 12:58:01 Engine: In memory \u2013 single node only\n[I]: 2017/06/22 12:58:01 GOMAXPROCS: 2\n[I]: 2017/06/22 12:58:01 Starting http server\n[I]: 2017/06/22 12:58:01 SockJS url: //cdn.jsdelivr.net/sockjs/1.1/sockjs.min.js\n[I]: 2017/06/22 12:58:01 Start serving raw websocket, SockJS, API endpoints on :9000\n[I]: 2017/06/22 12:58:14 http: TLS handshake error from MY_IP:41876: acme: identifier authorization failed\nWhen I open https://MY_DOMAIN:9000 in browser I see:\n[I]: 2017/06/22 12:58:14 http: TLS handshake error from MY_IP:41876: acme: identifier authorization failed. Thank you for feedback, we decide create hack for ourself. We will compare actual certificate in certbot path with loaded by each service like nginx, centrifigo and so on and will inform about mismatching.  . ",
    "lmj0011": "The default, Memory.\nIt's reproduced everytime.\n. > Just tried to run on Centos 6 \u2013 works well... Could you also show the output of these 2 commands from machine where Centrifugo running (maybe you are using wrong build for your architecture)?\n\nuname -a\nand\ncat /proc/cpuinfo\n\n```\nforge@forge-virtual-machine:~/www/client1/BGateway$ uname -a\nLinux forge-virtual-machine 3.19.0-49-generic #55-Ubuntu SMP Fri Jan 22 02:10:24 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nforge@forge-virtual-machine:~/www/client1/BGateway$ cat /proc/cpuinfo\nprocessor   : 0\nvendor_id   : GenuineIntel\ncpu family  : 6\nmodel       : 26\nmodel name  : Intel(R) Xeon(R) CPU           W3565  @ 3.20GHz\nstepping    : 5\nmicrocode   : 0x19\ncpu MHz     : 3200.000\ncache size  : 8192 KB\nphysical id : 0\nsiblings    : 1\ncore id     : 0\ncpu cores   : 1\napicid      : 0\ninitial apicid  : 0\nfpu     : yes\nfpu_exception   : yes\ncpuid level : 11\nwp      : yes\nflags       : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc aperfmperf pni ssse3 cx16 sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer hypervisor lahf_lm ida dtherm tsc_adjust\nbugs        :\nbogomips    : 6400.00\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 42 bits physical, 48 bits virtual\npower management:\nprocessor   : 1\nvendor_id   : GenuineIntel\ncpu family  : 6\nmodel       : 26\nmodel name  : Intel(R) Xeon(R) CPU           W3565  @ 3.20GHz\nstepping    : 5\nmicrocode   : 0x19\ncpu MHz     : 3200.000\ncache size  : 8192 KB\nphysical id : 2\nsiblings    : 1\ncore id     : 0\ncpu cores   : 1\napicid      : 2\ninitial apicid  : 2\nfpu     : yes\nfpu_exception   : yes\ncpuid level : 11\nwp      : yes\nflags       : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts nopl xtopology tsc_reliable nonstop_tsc aperfmperf pni ssse3 cx16 sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer hypervisor lahf_lm ida dtherm tsc_adjust\nbugs        :\nbogomips    : 6400.00\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 42 bits physical, 48 bits virtual\npower management:\n```\n\n(maybe you are using wrong build for your architecture)?\n\nI'm using the same build I used for v1.4.5\n. > Hm.. Can't find what can cause this bug, and can not reproduce it. Could you post all websocket messages from chrome network console (Network -> WS)?\nNothing shows in the Network section of Chrome Web Console for this\n. this is the data I'm sending in new Centrifuge({})\nlet data = '{\"user_data\":'+ JSON.stringify(this.app.whoiami) +'}';\nthis.app.whoiami is just an object with some user properties, just like in the original post^^\n. Give me until the end of the week to update this with more code. Sorry I've been quite busy. This Sunday at the latest.\n. \ud83d\udc4d\ud83d\ude00 that's great. Now I don't have to upload my confusing code\n. Just tested it, was not able to reproduce the error.\n:+1: \n. the use case is I want to send some data to the refresh endpoint that has some user info (username, id, etc) attached to it. I don't want this info in the url for security reasons.\n. > Why do you want this?\nIn my app, I'm passing the request for the refresh endpoint through middleware that verifies if the user is still logged into the app. If they are not, I need to be able to read the response and alert them that their chat session has ended \nnote: I do not have my server set up to intercept messages from the client, so it's client <--> centrifugo <--> client communications\n. > I mean should client try to reconnect or not after this, should it continue to refresh credentials or not. What is your thoughts about this - what you expect to happen with such client after its credentials expired (I mean after that window to rescue passed and Centrifugo finally disconnected client)?\nI think that the disconnect event should fire after the refresh endpoint fails, and it shouldn't try to refresh until the client establishes a new connection. But this method would not be beneficial for all, so maybe there should be an refresh_attempts option. Where after a set number of refreshes centrifugo cuts off connection to the client and fires some event to signify that.\n. > could you test it?\nyea, I will post feedback when done\n. verified after 1 failed refreshAttempt, the refreshFailed callback was called and no more refresh attempts were made after that. :+1: \n``` javascript\nlet centrifuge = new Centrifuge({\n       //[...]\n        refreshAttempts: 1,\n        refreshFailed: function() {\n            bootbox.alert(\"Your chat session has expired, please refresh your page\");\n        }\n    });\n\n```\n\n\n\n\n. yes, being able to write plugins would be nice.\n. > This kind of audit trail really needs to be in your primary data store\nin comes Redux\n. I don't think this is really necessary for JSON data, is there an option to disable proto buf encoding?\n. I'm trying to implementing this https://github.com/centrifugal/centrifugo/issues/102\nBy subscribing to the message.history channel using laravel, and storing messages to disk as they're published to Redis.\n. > But as soon as you already have Laravel backend why not to just save messages just before publish them to Centrifugo API? \nI'm doing that with Express now\n\nAlso what is message.history channel? \n\nThis is the channel I was meaning to refer to centrifugo.history.list.centrifugo.message\n. no this issue is good to close.\n. I'm not going to hack internals. Just trying to understand everything since I will be using this framework for a while.\nI will just ignore centrifugo.* all together within the handler then. \n. Alright, This should be good enough for me to go off of.\n. Hi, this is strange. Could you try to use ttl Redis command to see what happens with time?\n127.0.0.1:6379> ttl centrifugo.history.list.centrifugo.message.$dev+user3\n(integer) 598962\nmaybe you have memory limit in Redis and some eviction strategy? \nI have nothing set in my redis.conf\n. > Maybe sth happens with Redis itself? After loosing history try to run Redis INFO command in redis-cli. It can show some useful info - uptime_in_seconds, used_memory, evicted_keys etc\nI recently changed my history_lifetime to 604800 and restarted centrifugo. Message history looks to be retained, even after I restarted my machine.\nSo this leads my to think there is a max amount of seconds that centrifugo will take for the history_lifetime. This should be documented if so.\n. I going to try to use this number 7889231, 3 months in seconds, for history_lifetime. That number shouldn't be a problem, right?\nThis may not even be an issue, because in my config file I discovered the history_lifetime was set for 1800, 30 minutes, which would explain why it was disappearing so quickly. \n. Yes that's correct. I think it's safe to close this issue\n. ",
    "vector090": "Wish commands, auth algorithm etc. allows extension.\n. What a surprise! Thanks for the hard work! I'll look into it as soon as  I can.\n------------------ Original ------------------\nFrom: \"Alexandr Emelin\"notifications@github.com\nDate: Wed, Oct 26, 2016 10:40 PM\nTo: \"centrifugal/centrifugo\"centrifugo@noreply.github.com;\nCc: \"vector090\"fuyicong@gmail.com;\"Comment\"comment@noreply.github.com;\nSubject: Re: [centrifugal/centrifugo] Modular design, separating componentsfrom libcentrifugo to its own packages (#100)\nI almost finished splitting everything on packages - there is pull #112 . I can't say that I achieved all goals during this refactoring but at least Centrifugo got several important improvements I described in pr. Will continue to work on it - hopefully till the middle of November I am planning to make release that contains this work.\nAs this is Go - it's hard to create easy to use plugin system yet. But at least now Centrifugo will have possibility for extending in some way without needing to support separate code base in fork.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. #112 looks good to me. If I understand correctly, in order to support my own customized client commands, I need to do it in my own client connection struct, is it?\n. ",
    "sandeep-sidhu": "not sure about legal reasons but we definitely need a feature where  you can point centrifugal to some backend database and it saves keeps room's message history.\n. hmmm.. okay.  First of all thanks for the responses, really appreciate the quick and details responses.\nAs @banks assumed I'm actually using https://github.com/centrifugal/centrifuge-js currently and publishing messages from clients.. well it started initially as poc to see if I can centrifigual to build my chat application and also the page here made no reference for me to avoid going down that route..  https://fzambia.gitbooks.io/centrifugal/content/clients/javascript.html but anyway.. I'm right now facing the problem of having no history of the chat rooms.\nI was hoping the clients do the authentication with my App which issues auth tokens to user depending on if they can publish to a room or not and then everything gets offloaded to centrifugo and all connected clients can keep chatting to each other without my application doing any message handling.\nBut I see that this is not going to be the solution for now, so I'll look into publishing messages back to my app and.  Just additional work for me now I guess.  Anways thanks for the responses, I'll hit the gitter room in case I run into any other things.\n. ",
    "nordicdyno": "I'm voting for option 2 (integration with Prometheus out the box). Any plans on this? Probably I can implement this feature if you help me a bit.\n@FZambia . I've written PoC of Centrifugo exporter: https://github.com/nordicdyno/centrifugo_exporter.\nMetrics subset proxied from JSON endpoint is described in code here: https://github.com/nordicdyno/centrifugo_exporter/blob/master/main.go#L61 It's easy to add others if anybody wants \u2013 PRs are appreciated.\nThe main problem now, current JSON endpoint exports metrics from all nodes. This is not how Prometheus exporters supposed to work. Exporters should be work for every node, for \"up\" checks and metrics availability. I think better solutions is to add Prometheus /metrics endpoint support, probably on its own port without any auth logic. Alternative is to add query parameter for current JSON metrics endpoint like only-this-node=true and write \"official\" exporter for centrifugo. Thank you for pointing on /node method. I missed it, unfortunately. Soon I've modified my exporter with support of this method. Also, I've found there is no Node() method in gocent lib like Stat(), so I implemented it on my own.. ",
    "synw": "To advocate for solution 3 the \"centrifugo collector\" daemon sounds nice. If it could be extendable to distribute Centrifugo stats not only to Prometheus but to other systems as well it would be great. User case: I need to monitor what happens on some specific channels and distribute this info to third-party apps. A flexible external worker would be a good fit for the job.\nThe approach 3 looks very interesting if it could be extendable.. @nanom1t : the terminal client has a stats command : it is useful to keep an eye on a number but not for serious monitoring. Do you have some ready to use django-channels code? We could start comparing it to django-instant which uses Centrifugo. About the ease of use and stuff I made a little +/- vs channels here. @johnsonc sorry for the delay as well. As this request is about Django I opened an issue in the django-instant repository so that we can discuss this in the details and start something. . ",
    "nanom1t": "Which tools can I use to monitor metrics for Centrifugo (for example, number of opened connections, requests per second, graphics and so on) on my server? Here https://fzambia.gitbooks.io/centrifugal/content/server/stats.html I've found stats API command, but it returns only JSON. Is statistic only available in web admin panel? Thanks.. Thanks for your responses. I will try to check Graphite and Grafana.. Thanks for your response. Yes, you are right. You can also create pid file in systemd using next example:\n'PIDFile=/var/run/centrifugo.pid'. it is useful for process monitoring (for example with Monit).. Yes, it is possible to monitor process by name. Now I'm using next configuration for Monit and it is working. \ncheck process centrifugo\n    matching \"centrifugo\"\n    start program = \"/usr/sbin/service centrifugo start\"\n    stop program = \"/usr/sbin/service centrifugo stop\"\n    if failed host 127.0.0.1 port {{ centrifugo_port }} then restart\n    if cpu > 60% for 2 cycles then alert\n    if cpu > 85% for 5 cycles then restart\n    if children > 255 for 5 cycles then stop\n    if 5 restarts within 5 cycles then timeout\nHowever the traditional way for Monit is to use something like this:\ncheck process redis with pidfile \"/var/run/redis/redis-server.pid\"\nI'm not sure how it will beheive if there will be runnning few processes of Centrifugo with same name.\nThanks. I have a little question. In my Nginx configuration file I have next lines for static resources caching:\n```\n    location ~ .(ico|jpg|jpeg|gif|png|wav|ogg|m4a|mp3|swf|flv|zip|rar|xml|txt)$ {\n        root /var/www/public_html/{{ host_domain }}/www/;\n        access_log off;\n    # cache static\n    add_header Cache-Control public;\n    expires 30d;\n}\n\n``\nAlso I've enabled Centrifugo web panel. It works, but I have issues with loading static resources from centrifugo admin panel:GET http://domain.net/centrifugo/public/images/bg.png 404 (Not Found)Where ispublic/` directory located/cached in the filesystem? I need to create root directive for it in Nginx.\nThank you.. @FZambia Thank you for the response.\nI've change insecure_admin to 'admin_insecure' and now centifugo does not require password to login into admin panel. But the nginx still requires authorization again and again as shown on screenshot\n\nIt looks like something wrong with nginx config and I'm not authorized to execute POST requests to https://node1.site.com/centrifugo/admin/api (401 Unauthorized).\n. It looks like I've found the issue. Nginx send Authorization header with each request if basic auth is enabled:\nAuthorization: Basic bW9uaXRvcxNDMzMDdzJA==\nCentrifugo overrite this header and send it with each API request to https://node1.site.com/centrifugo/admin/api:\nAuthorization: token insecure\nIs this a reason why I get 401 Unauthorized error from Nginx?\nP.S: There is no this problem in version 1.8.0.. I will try to test on VM.. @FZambia I've cloned repo from master branch and built it with go build. It works on my VM  in insecure mode and does not send Authorization header. In secure mode it still overwrites Authorization header. Thanks. Yes, thanks.. When will be next release for Ubuntu on packagecloud.io?. Ok, thank you.. ",
    "derkan": "Hi,\nThanks. I didn't mean to persist data. It will be done as it is done in current presence data. When user disconnects, channel users data will be also gone with presence data. \nWhat I want is adding users to a channel by ID when creating the channel and later able to add or remove users from that channel by API. It will be actually a presence data but, centrifugal should be filtering messages on a channel by also checking its defined users by this api proposal. By this way client will send message to a channel easily  without defining target user channels. \nFor single signed(token)  microservices, there are services on different platforms which is bound to a single user login/session. For per-project centrifugal installations, web browser client should connect to all these microservice servers and developer will be developing a service for private channels for each of installation of centrifugo. But, by using this api proposal, cenrifugal will not need to connect a backend for validating a client and this will be nicer for performance.\nIf this proposal doesn't fit for current project goals, than there is nothing to do :-) thanks for evaluating my api proposal.\n. OK, thanks.\n. ",
    "DeepAnchor": "I'm evaluating Centrifugo for a realtime multiplayer mobile game that will communicate game state with the back end using a binary protocol. \nI could probably just roll my own using a less feature-full websocket library, but Centrifugo provides some quite nice features out of the box like presence information, channel authorization, etc., built right in.\nHaving a pluggable serialization format would allow Centrifigo to be a much more general purpose websocket server and open up a lot of applications, I think.  But I can understand that it would require a lot of work. Perhaps it can be put on a future wishlist!\n. @banks interesting, thanks for the clarification. I can what you mean now when you say that  Centrifugo fits more into the push service space -the diagram with the one way arrows make a lot more sense now.\n@FZambia you're probably right :) No idea about gRPC stuff, but it seems to be taking over the world right now. Making RPC calls from browsers though... that's something i'd like to see!\n. ",
    "narup": "Thanks, even with this approach I can see out of sync issues happening. I see publish response has  error field, will it send any specific error response if it cannot deliver the message?\n. Thanks, I got that part. But, I am thinking more in terms of group messaging. It seems bit too much of work to check message acknowledgement for each users within a group. I am not saying it's hard or not doable, but feels like should be handled by the centrifugo. It would be nice if centrifugo has some kinds of plugin handler or hook which can be used by developers to customize behaviors like these.\n. I know what you mean, It's just that I am not very comfortable with maintaining status for each message on a group to each user of a group, at least for my use case. By hook, I mean some kind of callback URL that centrifugo can call on app's backend side for different events that could be interesting for app logic. User not in session is one event but there could be others. But, it means definitely more work for centrifugo :) But, for now I will try to go with your above solution you suggested. Thanks much for all the help.\n. Yeah sounds good. \n. ",
    "joshdvir": "Hi @FZambia, \nI've just installed the server and everything is running fine except for the compression, I just don't see the headers stating the permessage-deflate is working, the server is not returning them.\nI've added the websocket_compression to the config file and also set websocket_compression_min_size to 1 but still no change.\nCan you assist ?\nThank you.. @FZambia sorry got it now, I was connected to the server SockJS endpoint, when I connected to the websocket endpoint it started working.\nThank you.\nbtw why is the SockJS endpoint not working with permessage deflate ?\n. I might give it a go also.\nAnother question, I'm now POC'ing centrifugo and planning to use it on a rather big application with 200K concurrent users with billions of messages, any recommendation on your side? \nThank you.\n. Redis engine is a must and already implemented and working properly, I'm not going to use anything else except websockets for now since there is no permessage deflate and the last time I tried working without the deflate option I got around of 100TB of data transfer so it's not an option.\nI'm just looking at the code of \"igm/sockjs-go\" and you are right it's pretty straight forward adding the deflate option to him, I might give it a go try to find the time.\nI'm actually transferring from Slanger which I encounter some issues with clients subscribing to channel with him, which I'm sure won't happen here since you subscribe to 2K every time and not 100K at once which killed Redis for me, and it's hard killing Redis.\nI'm going to test it in the upcoming week so I'd be happy to update on progress \ud83d\ude04 . @FZambia yes I meant the timestamp send in every broadcasted message, does Centrifugo server use it?\nFrom going over the code I didn't see the client using it, if removed it can save traffic.\nDon't you think that any application has it's own logic about when messages are created and they use that? why does the server needs to send when messages where created ?\nThanks. \ud83d\udc4d great, thanks a lot.. ",
    "siddharthlatest": "@FZambia To clarify, the API Backend --> Centrifugo interactions are fine.\nOn the Centrifugo --> Client side is where HTTP Chunked Transfer aka Streaming can be used for pushing out channel updates. \nThe primary use-case is the gained accessibility as one can then simply cURL the realtime API endpoints and even do a GET in browser. Let's say the app backend was exposing a REST API, this eliminates the need of exposing separate endpoints for the websockets based realtime API.\nThe client protocol part (i.e. Client --> Centrifugo --> Client) for connect, authorization and managing channel subscription events can be made over an HTTP API while allowing the server to client interactions to be done via HTTP Streaming.\nAn example scenario: Client#1 is subscribed to Channel Foo. A new Client#2 connects and then also joins Foo. \nClient#2 --connect--> Centrifugo Server  via HTTP POST\nClient#2 -subscribe-> Centrifugo Server  via HTTP POST\nCentrifugo ---join---> Client#1 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0via HTTP Streaming. I think we're getting closer. Let me share a use-case we have so that it helps better clarify on how Centrifugo implementing the HTTP Streaming transport helps.\nWe expose a database namespace via REST endpoints like this:  https://api.appbase.io/app12/location/1 ,\nand map the streaming endpoints to look like this:\nhttps://api.appbase.io/app12/location/1?streaming=true.\nSince these endpoints are used by devs who use our APIs to create end-user apps (similar to the Firebase or Horizon use-case), it's important that the endpoints themselves abstract out the details of how the namespace maps to channels in our implementation.\nSo while SockJS provides support for Websockets and HTTP Streaming as a fallback, it would be a very different looking endpoint.\n\nLooking at the implementation side: The idea is that we provide everything needed to establish a subscription but in an invisible fashion so an API creator can blend it directly within their API structure.\nFor this to happen, the subscribe endpoint should be POSTed by the app backend to the Centrifugo server.\nHere's how that interaction might look: Client wants to connect to a streaming endpoint and uses an abstract endpoint like:\nhttps://example.centrifugo.com/location/1?streaming=true\nThe client makes a GET request, Centrifugo server proxies this request to the app backend which then POSTs a subscribe method to Centrifugo server with the connection parameters:\njson\n{\n    \"method\": \"subscribe\",\n    \"params\": {\n        \"channel\": \"CHANNEL NAME\",\n        \"user\": \"USER ID\"\n    }\n}\nThe Centrifugo server then keeps an open connection with the original client and whenever the app backend publishes a message to a channel, it streams the message to the subscribers of that channel.\n\nPotential benefits of implementing this are:\n\nGained accessibility: cURL supports HTTP Streaming without any vodoo, a GET endpoint can be streamed directly in a browser. I wish more streaming API providers used this over websockets (although WS have some key advantages in the browser environment).  \nAn invisible client API: This is our use-case, but it allows for any esoteric namespace <> channel mappings as the app backend is now responsible for that logic.  \nNo state management overhead on Centrifugo server side: scales better horizontally than websockets would have.  \nSince using this way makes websockets client library dependency optional, it simplifies client side debugging. Most modern frameworks and languages have support for handling chunked HTTP responses.  \n\nAs a reference, pushpin.org does this very well.. @FZambia Agree on your analysis, and it won't be a trivial addition.\nPushpin works well for our use-case and we use it in production. We have a new use-case for a project that will be written in golang and was recommended to Centrifugo. Upon reading, the design decisions that went into building Centrifugo made sense and the docs were really easy on the eyes :-).  \nThere haven't been noticeable scenarios where this has happened, I don't know what Pushpin does to solve for this. . ",
    "chavenor": "Got it.  My largest question was about the reliability but I can code that into my apps backed so we should be good to go.  I look forward to getting those performance gains. . Sorry about that.  From a in/out messaging system I expect you to beat my current setups performance.. The current system I'm using to handle real-time messages is likely much slower than Centrifugo.   Thus your (Centrifugo) should be much faster and overall perform better. . Me too!  :) . ",
    "phouverneyuff": "I would like to see this feature. This's will help me on deploy em dev and stage when I need clean all data.. @FZambia , I use different Centrifugo instances. In dev I have centrifugo with Redis engine. I spend some time to delete the history in Dev. If I don't use with Redis is very easy to do it, but with Redis .... @fzambia, yes. I don't know why, but if I shutdown Centrifugo, clean Redis with FLUSHDB and start again Centrifugo, all data are publish in Redis again. I don't know why. I kill all, flushDB in Redis and restart machine to clean all. I remove the Redis data file too.\ndocker run  --name centrifugo -d --ulimit nofile=65536:65536 -v $HOME/centrifugo:/centrifugo -p 8000:8000  centrifugo/centrifugo centrifugo -c config.json  --admin --web --engine=redis --redis_host=172.17.0.1 --redis_port=6379. @FZambia , I'm studing use centrifuge with IoT. Maybe we need create use another engine #45 with this logic.. ",
    "QuackMartins": "@FZambia thks for clarifying \nClosing this one o/\n. Here is my docker-compose config\nyaml\ncentrifugo:\n  image: centrifugo/centrifugo:1.6.0\n  environment:\n  - CENTRIFUGO_SECRET=secret\n  - CENTRIFUGO_WEB=1\n  - CENTRIFUGO_ADMIN=1\n  - CENTRIFUGO_ADMIN_PASSWORD=password\n  - CENTRIFUGO_ADMIN_SECRET=secret\n  ports:\n    - \"8569:8000\". \u0f3c\u1557\u0e88\u0644\u035c\u0e88\u0f3d\u1557 I think it worked\nThis is my first time using centrifugo, then I was first trying to access the admin page\nI think that maybe viper is not getting boolean variables, but we can workaround it with --flags. Here are my changes\nyaml\ncentrifugo:\n  image: centrifugo/centrifugo:1.6.0\n  environment:\n  - CENTRIFUGO_SECRET=potato\n  - CENTRIFUGO_ADMIN_PASSWORD=potato\n  - CENTRIFUGO_ADMIN_SECRET=potato\n  command: centrifugo --web --admin\n  ports:\n    - \"8569:8000\"\nThks @FZambia \n...\u1555( \u141b )\u1557. ",
    "ramon-ga": "Hi, awesome! Thank you!\nIf you need a tester, i can do that.... Hi, wow you're very fast! I had some time set it up on a test server and can confirm it's working!\nThe first call on the server is a little bit slow, but after that it works like a charm!\nThank you very much for your work!\n\nSome Details about the test:\nServer: Ubuntu 16.04 / go version go1.6.2 linux/amd64\nJavascript Client: sockjs-client v1.0.3 / centrifuge.min.js v?\nPHP API Client: phpcent 1.0.4 / php 5.5.9-1ubuntu4.20\n(with php 5.6.2 on mac osx not working: tls: no cipher suite supported by both client and server)\nBuild centrifugo:\napt-get install golang\ngit clone https://github.com/centrifugal/centrifugo.git\ncd centrifugo/\ngit checkout autocert\nexport GOPATH=$HOME/go\ngo get ./...\ngo build\nmkdir /root/certs-test\nConfig updated with:\n{\n  ...  \n  \"ssl_autocert\": true,\n  \"ssl_autocert_host_whitelist\": \"ws-autocert-test.xxxx.xx,ws2-autocert-test.xxxx.xx\",\n  \"ssl_autocert_cache_dir\": \"/root/certs-test\"\n}\n1. Test Run\nroot@centrifugo-test-letsencrypt-cert:~/centrifugo# ./centrifugo -p 443 --ssl\n[I]: 2016/12/23 10:37:30 Config path: /root/centrifugo/config.json\n[I]: 2016/12/23 10:37:30 Centrifugo version: \n[I]: 2016/12/23 10:37:30 Process PID: 9640\n[I]: 2016/12/23 10:37:30 Engine: In memory \u2013 single node only\n[I]: 2016/12/23 10:37:30 GOMAXPROCS: 2\n[I]: 2016/12/23 10:37:30 Starting http server\n[I]: 2016/12/23 10:37:30 SockJS url: //cdn.jsdelivr.net/sockjs/1.1/sockjs.min.js\n[I]: 2016/12/23 10:37:30 Start serving raw websocket, SockJS, API, admin endpoints on :443\n[F]: 2016/12/23 10:37:30 ListenAndServe: open : no such file or directory\n2. Test Run after update code\n```\nupdate package downloaded from github\ncp libcentrifugo/server/httpserver/config.go $GOPATH/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/config.go\ncp libcentrifugo/server/httpserver/handlers.go $GOPATH/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go\ngo build -a\n\nroot@centrifugo-test-letsencrypt-cert:~/centrifugo# ./centrifugo -p 443 -d\n[I]: 2016/12/23 11:17:28 Config path: /root/centrifugo/config.json\n[I]: 2016/12/23 11:17:28 Centrifugo version: \n[I]: 2016/12/23 11:17:28 Process PID: 14591\n[I]: 2016/12/23 11:17:28 Engine: In memory \u2013 single node only\n[I]: 2016/12/23 11:17:28 GOMAXPROCS: 2\n[W]: 2016/12/23 11:17:28 Running in DEBUG mode\n[I]: 2016/12/23 11:17:28 Starting http server\n[I]: 2016/12/23 11:17:28 SockJS url: //cdn.jsdelivr.net/sockjs/1.1/sockjs.min.js\n[I]: 2016/12/23 11:17:28 Start serving raw websocket, SockJS, API, admin, debug endpoints on :443\n```\n. Great! As soon as the release is done, i'm setup it up on the production server.\nThanks again \ud83d\udc4d . Thanks for investigate this shortly.\nAfter your explanations it's sure not the same as a \"normal\" http server with short living connections, and not that easy to implement.\nWith the SIGTERM handling, i think a good alternative already implemented, and this issue can be closed.. Because it cannot run the websocket server with non-ssl and ssl without an additional Script, that starts ex. the ssl server.\nIf i can start the server and both ports 80 & 443 it's easier to setup.\nservice centrifugo start starts just one of the servers . You're right, thank you for this hint! I don't think on that, issue solved ;). Ok, thank you. So there isn't a solution for older systems out of the box.\nI'm going to investigate this a little bit to find a solution..\nI was using 1.6.1 and now updated to 1.6.3, but the syslog (/var/log/syslog) is still flooded by the entries.\nThis error is maybe a direct output of the tls library?\nBecause centrifugo log entries are not the same format:\n```\ncentrifugo log entry (--log_file=/var/log/centrifugo/centrifugo.log):\n[I]: 2017/01/23 13:56:31 Starting http server\n[E]: 2017/01/23 13:56:40 connect error: client already authenticated\nError in the syslog (/var/log/syslog):\nJan 23 14:19:01 ws centrifugo[5790]: 2017/01/23 14:19:01 http: TLS handshake error from xx.xx.xx.xx:4900: tls: no cipher suite supported by both client and server\n```\n. Hi, thanks for your tips.\ni've done some tests, but no test has worked for the problem.\nTest i've done:\nDisabled HTTP/2\nwith GODEBUG=\"http2server=0\" and directly in the code:\nserver := &http.Server{\n     TLSNextProto: make(map[string]func(*http.Server, *tls.Conn, http.Handler), 0), // disable HTTP/2\n}\nSet the cipher suites manually\n~~Interesting is on this part, the cipher list on ssllabs did not change after i change this..~~\nInteresting here is, not all ciphers i enabled are listed on ssllabs.\nWith enabling the cipher TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 i try to fix the failing  handshake simulation  for Chrome 49 / XP SP3, but it isn't working.\nserver := &http.Server{\n    TLSConfig: &tls.Config{\n          PreferServerCipherSuites: true,\n          CipherSuites: []uint16{\n        tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n                ...\n    }\n}\nTest with direct certificate\nRun centrifugo without lets's encrypt (--ssl --ssl_cert test.crt --ssl_key test.key)\nI run ssl test with ssllabs (https://www.ssllabs.com), and with no configuration i get it working.\nMaybe interesting, with centrifugo 1.4.1 there is a better compability with older browser.\nCipher Suites centrifugo 1.4.1:\n\nCipher Suites centrifugo 1.6.3:\n\nAt the moment i'm going to live with that, but later i dive in this again.\nThe same problem exists on our other golang https server, so i try to find a solution on this.\nPutting a proxy like nginx in front would be solve the problem, but at the moment i'm using a single server. With this i can reach about 250k Clients (or more), with a proxy in front the maximum client amount will be the half.. \nMy target is to run golang standalone servers without a proxy.\nOn my other golang http server, this error will be catched by the logging package (https://gist.github.com/Tantas/1fc00c5eb7c291e2a34b)\n2017-01-24T13:00:03.094Z [DEBUG] http: TLS handshake error from xx.xx.xx.xx:9323: tls: no cipher suite supported by both client and server. Thanks for your answers, old browser compatibility is always important for servers. But in this case i think most of the client browsers are ok with this. The problem ist just with old browsers/systems like ChromeChrome 49.0.2623.112, Windows XP, and these are just a few. I will make a workaround in our code, to disable the connection or reconnect without ssl. \nIf i need that i will do it with a proxy/lb in front.\n. > Just out of curiosity. This looks like a very huge number for a single server. Have you already tried this with Centrifugo? \nYes this amount of clients i reached with centrifugo 1.6.1, i need to boot multiple client test servers to reach that. Because per client server the maximum connection count is around 64'500 tcp connections. \n\n(Server: 8 Dedicated x86 64bit Cores, 32GB memory)\nOn the client servers i run your connections script: https://github.com/centrifugal/centrifugo/blob/master/extras/scripts/connections/connections.go\n(With a workaround to not close all connections if one has an error: \nsed -i -e \"s/log.Fatal(err)/log.Print(err)/\" $connectionsScript)\nTo test a \"real live\" scenario, i send multiple messages to all ~258k clients, with this i'm getting a load around of 8 on the server. \nAt the moment the maximum of real clients we reached is about 40k and normally about ~10k (On old server with 4 core processor, 8GB memory), but we want to be prepared for about 80k - 120k clients, we need this probably in future projects.\n\nAnd have you already experimented with proxy in front?\n\nWith the old centrifuge (Python) we had an autoscaling setup with a load balancer in front.\nBut we had some problems with that, so the decision was to deploy it as single server.\nAs Load Balancer we used tengine (fork of nginx, http://tengine.taobao.org/), because with a module it's possible to update the upstream-list without reloading Nginx.\n(Details you will find here: https://github.com/centrifugal/centrifuge/issues/47 ;). I've have to say thank you for this super simple stable websocket server! :1st_place_medal: \nFor me it would be nice if all output is written to the specified log file, so i have the option to save it to another device. So it's not possible that the system fs is out of space because the log is huge.... > This is really interesting, maybe ssllabs caches results for a while?\nI'm sorry this was wrong, i've corrected the text (https://github.com/centrifugal/centrifugo/issues/144#issuecomment-274803378). \nAnd no, the have a link Clear cache so nothing should be cached.\n. I tried alreasy to enable all ciphers i found in the go source code, i tested it with:\nTLSConfig: &tls.Config{\n                GetCertificate:           certManager.GetCertificate,\n                //MinVersion:               tls.VersionTLS12,\n                //CurvePreferences:         []tls.CurveID{tls.CurveP521, tls.CurveP384, tls.CurveP256},\n                PreferServerCipherSuites: true,\n                CipherSuites: []uint16{\n                    tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n                    tls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\n                    tls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\n                    tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\n                    tls.TLS_ECDHE_RSA_WITH_RC4_128_SHA,\n                    tls.TLS_ECDHE_ECDSA_WITH_RC4_128_SHA,\n                    tls.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,\n                    tls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,\n                    tls.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,\n                    tls.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,\n                    tls.TLS_RSA_WITH_AES_128_GCM_SHA256,\n                    tls.TLS_RSA_WITH_AES_256_GCM_SHA384,\n                    tls.TLS_RSA_WITH_RC4_128_SHA,\n                    tls.TLS_RSA_WITH_AES_128_CBC_SHA,\n                    tls.TLS_RSA_WITH_AES_256_CBC_SHA,\n                    tls.TLS_ECDHE_RSA_WITH_3DES_EDE_CBC_SHA,\n                    tls.TLS_RSA_WITH_3DES_EDE_CBC_SHA,\n                },\n            },\n            TLSNextProto: make(map[string]func(*http.Server, *tls.Conn, http.Handler), 0), // disable HTTP/2. Thank you for investigating this so deeply!\nAs i understand this, It confirms that with old browsers there's no simple way to get it working.\nThe only way is a proxy like nginx in frontend to solve this right? So we can close this issue.... Thank you for your hint that this just occur with lets encrypt certs, now i had again some time to dive into it.\nOn a other host we have lets encrypt certs too, and there isn't a problem, so i compared it.\nThe main difference is the key EC 256 bits (golang autocert) and RSA 2048 bits (e 65537) (Other lets encrypt host).\nSo i searched and found a new flag for autocert ForceRSA, with this the server key will be RSA 2048 and the ssllabs client Chrome 49 XP SP3 is able to connect.\nhttps://godoc.org/golang.org/x/crypto/acme/autocert#Manager\nhttps://github.com/golang/crypto/blob/master/acme/autocert/autocert.go#L148\nIt's possible to add this line to the http handler (or make it configurable)?\nForceRSA:   true,\nhttps://github.com/centrifugal/centrifugo/blob/master/libcentrifugo/server/httpserver/handlers.go#L196\nThen the next thing is, that browsers without sni support didn't get a certificate (ex. IE 8 / XP: Server sent fatal alert: internal_error).\nWith a small change (call own function) to the GetCertificate function, we will able to set the default hostname to get the certificate.\nIs it possible to implement this too?\nGetCertificate := func(hello *tls.ClientHelloInfo) (*tls.Certificate, error) {\n            name := hello.ServerName\n            if name == \"\" {\n                hello.ServerName = \"xx.myhostname.ch\"\n            }\n            return certManager.GetCertificate(hello)\n        }\nhttps://github.com/centrifugal/centrifugo/blob/master/libcentrifugo/server/httpserver/handlers.go#L210\n. Perfect, thank you. With this centrifugo should be fully backwards compatible with older browsers.\n. Yes, because of that i disabled the http2 temporary with GODEBUG=\"http2server=0\" now.\nTo add this the simple way, add it to /etc/default/centrifugo.\nHopefully with this it did not crash anymore.\nRunning now for 45min without crashing.\nActive: active (running) since Sun 2017-01-29 13:24:38 CET; 45min ago\n. Wow, you're fast!\nFrom my side this is ok. With disabling the http2 server we're up since 21h, so we have a temporary workaround for the problem.\n. I'm happy with the uptime field. \nI didn't keep this in mind, you're right! In our case i would be not a problem, and i can get this information out by the presence command.. Hi @FZambia \nquite possible this is related to that issue.\nI briefly read it, and i think they released an update for crypto/acme\nhttps://github.com/golang/go/issues/21890#issuecomment-357986015\nIt's possible that you check if the dependency is up to date?\nElse i'll find time next week to build it and test it...\nThe setup is as before on the old server, and there's no proxy in front.\n. @FZambia thanks for your effort on this! I tried it, see below.\nWith ssl_autocert_http:false:\n[I]: 2018/04/09 07:21:01 Start serving raw websocket, SockJS, API, admin, web endpoints on :443\n[I]: 2018/04/09 07:21:25 http: TLS handshake error from 212.51.141.47:53095: acme/autocert: unable to authorize \"****.****.**\"; tried [\"tls-sni-02\" \"tls-sni-01\"]\n[I]: 2018/04/09 07:21:26 http: TLS handshake error from 212.51.141.47:53096: acme/autocert: missing certificate\nWith ssl_autocert_http:true it's working fine.\nPoints to consider:\n- Should be written in log, that listen on port 80 too\n- Maybe in that case, admin panel should no be accessible on port 80\n- For me it's nice that on port 443 and 80 the service is available, but not for everyone?\n. > As far as I understand it must work on main port which is 443 in this case and not on port 80\nCorrect\n\nThis is turned on only if ssl_autocert_http turned on and only serves acme challenges on that port redirecting all other plain HTTP requests to HTTPS. What's you suggestion here?\n\nPerfect, redirecting all other plain HTTP requests to HTTPS is a perfect solution \n. No i don't see any problem for me this works fine.\nI'm thinking just about that maybe someone don't like to see that the admin interface is accessible over unencrypted http. But for me it's fine.\nNow if ssl_autocert_http is enabled, the admin interface is accessible through http too.. > Are you sure it was not a redirect to https admin page?\nI started the new version again, and you're right it's a redirect.\nThe last time the url wasn't changed to https (i'm pretty sure), now after a forced reload the url changed too and the redirect stays. Maybe this was a caching problem on my side.\nSorry for the misinformation.. All this works like a charm, thank you for your effort!\nTasks done:\n- [x] pull latest commit\n- [x] build\n- [x] delete existing certificates\n- [x] run with new config flag ssl_autocert_http: true\n- [x] open web with http for both domains\n- [x] will redirect to https\n- [x] certs Let's Encrypt Authority X3 received\n- [x] admin interface with wss connected\nLog:\n[I]: 2018/04/13 07:15:33 Redis: 127.0.0.1:6379/0, pool: 256, using password: no, API enabled: no\n[I]: 2018/04/13 07:15:33 Config path: /etc/centrifugo/config.json\n[I]: 2018/04/13 07:15:33 Version: \n[I]: 2018/04/13 07:15:33 PID: 20774\n[I]: 2018/04/13 07:15:33 Engine: Redis\n[I]: 2018/04/13 07:15:33 GOMAXPROCS: 8\n[I]: 2018/04/13 07:15:33 SockJS url: //cdn.jsdelivr.net/sockjs/1.1/sockjs.min.js\n[I]: 2018/04/13 07:15:33 Start serving raw websocket, SockJS, API, admin, web endpoints on :443\n[I]: 2018/04/13 07:15:33 Serving ACME http_01 challenge on :80\n. ",
    "manson": "Will Let's Encrypt automatic certificates renew when they are about to expire?. Should it be jscent serverside library updated to work with https?  Currently I've managed to run centrifugo with lets encrypt certificates, admin UI works fine (except it complains on unsecured fonts downloading) but my serverside code cannot connect to centrifugo with exception:\n{ [RequestError: Request failed with an error]\nname: 'RequestError',\nmessage: 'Request failed with an error',\nurl: 'https://mysite:8000/api/',\nerror: [Error: UNABLE_TO_VERIFY_LEAF_SIGNATURE],\nstatusCode: null,\nbody: null }\nWhat have I missed?. @FZambia Thats great you have no problem connecting jscent node library to your server, but I cannot check it out because of my node library unable to connect to your site without secret key. I want to remind that from browser and my browser application part I manage to connect to my centrifugo instance in ssl mode. Just node unable to connect. \nI've checked links you supplied. Both are related to switching off security so I dont get it what in this case is ssl, sertificates and so on for? Or I dont get something?\nAlso I see 8000 port in your request url - is it ok? - what is wrong with this? I've started centrifugo standalone instance with lets encrypt certificates. It started at the same default ports. Is something wrong with it? Althow I started it on production server (just because of certificates bound to servers domain), currently I use it just to test it how I can use it. And cannot get it work in this mode. Without ssl it works fine - I even rewrote subscriptions engine for Meteor.js using centrifugo to reduse memory consumption and rise concurrent connections (meteor subscriptions are too memory greedy)\nas for fonts. This what I see in browser console when opening centrifugo admin UI:\n`Mixed Content: The page at 'https://mysite:8000/#/' was loaded over HTTPS, but requested an insecure font 'http://themes.googleusercontent.com/static/fonts/rosarivo/v1/OGdIq-p0tOtBN2VMVvO9W_esZW2xOQ-xsNqO47m55DA.woff'. This request has been blocked; the content must be served over HTTPS.\nbundle.js:2121Mixed Content: The page at 'https://mysite:8000/#/' was loaded over HTTPS, but requested an insecure font 'http://themes.googleusercontent.com/static/fonts/inconsolata/v5/BjAYBlHtW3CJxDcjzrnZCIbN6UDyHWBl620a-IRfuBk.woff'. This request has been blocked; the content must be served over HTTPS.. @FZambia Ok. I managed to connect to your instance with secret key. At least now I had no exceptions on my serverside code. Although my browser client right after connection gets disconnected, I assume it ok at least for this issue. Will try with ports playing but if this is the case its not very well bc I plan to use the webserver ssl processing. I.e. 433 port will be my webserver port, so they may conflict... I'm getting into a mess with all this. Separatelly I understand how it should work but not in common, under the one server roof.So please try this, I think it's worth adding strictSSL option anyway for self-signed certificate cases in development for example.` - I've gotten letsencrypt certificates and want to make them to work but will check it anyway, thanks\nThanks for font warning: this is a bit strange - hmmm... maybe this is some kind of chrome plugin plays a dirty game :-) Cannot check right now. Anyway thank you!\n. @FZambia Excuse me, I have another question but dont know where to ask it. Its not an issue just a question. Why dont you want to do a serverside subscription? I mean in jscent library? I have a usecases where clients may directly communicate each other but server intercepts messages (bc its subscribed to channel) and sometimes it may log info or make some actions according to data in channel. Usefull for some kind of pseudo-distributed applications. At least the lack of this is a bit uncomfortable....\nFor updated  jscent- thanks a lot! Will try. @FZambia I see. Thank you! Centrifugo is a great tool! :-). > the client can be fully passive.\n\nclients no need worry about sync subscriptions status.\nI think in most case there is no real client subscription, that client subscribe a new channel but backend don't know that, it is horrible\n\nIt all sounds stupid. If you dont want client to initiate subscription you should'n use any kind of pub/sub server except its a very simple app - i.e. any client will receive all messages. If client want to get a data from a channel it just subscribes it. In one code string. Almost all apps workflows is where the client desides what data to receive/consume and what not. Be it a web page or a desktop app. And backend only rules the permitions, filtering data and maybe some data processing. And of cause the delivery data user subscribed.  If its not - it looks like the app architecture is built wrong.\nThe other thing is that it lacks of server-side funcs to subscribe to channels as a client - in some situations it is very usefull, but its not hard to make it different way and is out of centrifugo conception as author wrote before...\nAs for your situation (backend desides should user subscribe or not) you may just use private channels and randomly generated channel names on backend:\nAs an example:\n1) On app startup backend randomly generates channel names for topics\n2) client->backend (hi, I want to subscribe to 'topic-A)\n3) backend (check clientX authority, user role, channel \"topic-A\" settings ..... if all OK) - returns the real channel name for this topic\n4) client subscribes to channel\n. @roytan883 \n\nif topic-A administrator want kick clientX, how to do that ?\n\nIf you're about security, make private channels to users or random for every user. And then just dont send data into this channel client listening to stop him receiving data. Anyway in a public or commonly used channels (for groups) you cannot rule security strictly. And as of this did user unsubscribed or not is not important\n. @roytan883 \n\nI think Centrifugo should remove the Server API \"unsubscribe\". \n\nWhy? This is right your situation.  User subscribed to a channel (you can hook the channel entered user on server side and make some authentication or other checks) and server may kick him out at any time...or leave.... @roytan883 \n\nTo implement a chat room and its administrator, is that hard? need create lots of private channels for every user, just to implement one simple feature request \"kick user\" ?\n\nOh? its all about chat? Ok lets see.\nFirst of all we have the serverside function to unsubscribe user from any channel (client unsubscribe from serverside). Right? So we already can kick user form channel. So the only thing left to do - auth user to a channel. Right? I think you're afraid that someone who is out of you app can connect to channel, right? Ok. From an app level we can simply auth user and manage his connection or disconnection from channel in a usual app workflow (client might unsubscribe itself if server said that). As for a foreign user - first he must connect with the same credentians than centrifugo server expose. He cannot just connect to any channel not being aware where to get connection parameters from. But ok, he did it and connected. And tries to connect to a channel. In this situation we can track the user connection from serverside (join_leave parameter in config). I didnt try it to know how it works in reality but it should give at least user id. You can check its availability in some serverside internal auth dictionaries and kick off the user if its not in.\n. @roytan883 \n\nhe only things need is \"DeviceToken\" from client to APP backend, then no matter how many channels or groups inside that APP\nClient is the only one can make subscription. But why?\n\nLoosely speaking ios app is always subscribed to a one channel (in terms of our pub/sub). And by that device token it is the private channel created for a device. And all the info goes to a user in this channel. And if you remember in your mobile app when you \"subscribe\" to a notification along with this device token you supply the application name wich is a message filter for your app. If you wish to have something similar, nobody prevents you to subscribe user to a single private channel to which server will send all the user related data. You just filter it by a topics. And this is will be the same as IOS app you consider as a pattern.. @roytan883 \n\nclient should not concern which and when to subscribe or unsubscribe channels.\n\nI think this is totally wrong. In chat application there might be hundreds channels client usually read info but currently he just wish to get the info from a single channel user swiched onto. Usually user just subscribes to a channel and unsubscribes from previous. In your model you will have to send all the data from all channels and let user filter data iteself (huge data amount) or if somehow server will know that you changed to a different channel (your client must say it to server) - in this case there is no difference how you gonna do it - remote methos call or resubscribe. Anyway you'll have to make server do something for client...\n. @roytan883 \n\nwhat the bad effect if i implement my client code like this \n\nIts not for chat app if you want to see posts not only to a user but all from a chat room. As I sayed user may have hundreds of channells he subscribed and if you will send him all the data from them - you will have traffic overload and user disturbtion. But you can do it with clientside filtering and single subscription - its up to you how to get your users.... @roytan883 \n\nWhy subscription only handled by client side?\n\nBecause this is the common client-server use case. With a large amount of users the more effective balanced server is a stateless server. Users gets the minimum info from server and server dosen't care how user ask him and where from. The data sent to user is small enaugh as from server processing logic and from client simplisity. Client is simple not when it process all the info came from server as you think, but when it has only currently needfull information. In your situation you'll have to filter and manage info in client side all the time and its obvious for me not your \"simple client\". As for me your app arcitecture is totally wrong in this point of view.. @roytan883 \n\nFor you example , user may subscribe lots for topic or channels , like 1000 channels. Does that mean the client should maintain the 1000 subscription ? \n\nOf course not. When user selects one chat room - it subscribes to this chat room. When selects different - unsubscribes from previous and subscribes to current. There could be additional always subscribed to service channel where user can get common info - how many messages is on other channels, new and so, but not that currently unnessesary messages from other channels...\nThere no difficults to manage subscriptions this way. \n\nat least those source code need to be implement in client side, and additional code to sync those subscription with backend server when user may operate it at PC or web\n\nI dont get what the problems is here for you. Just get the latest messages when entering the channel and subscribe to new. That it. 2 simple steps. . @roytan883 \n\nwhy can't we let backend handle step 2 and 3 ?\n\nI dont get you. You make all the same client subscriptions from all platforms. Server doesn care from where you made subscription. Dont make server complex. All client will make the same steps on connect: make some queries (get latest messages) and subscribe to new one. From the serverside you of course may store linsk clientId->userId (clientId - unique client connection, userId - user id from db) to send info to all platforms in case of private channel. But if this is public channel you dont have to do anything at all on server side. Just push message to channel and forget. @roytan883 \n\n3, what next ? I want the user-A's other client(Android client , PC client , web client) also can get new message from \"topic-123\"\nI don't how you implement step 3.\nBut in my solution, client side code on step 3 is none , because all stuff are handled by backend server\n\nIn common solution you dont have to to something special on step 3. This is all the same - you enters from another platform, does the same as if you enters from android. If this is common channel thats it. Centrifugo will send info to all connected clients of this channel. It doesnt care of your user id, every connected client is unique for centrifugo. Every client has its clientId. You can have multiple clientId's with one userId - its up to you how to link userId->clientId's. But this is nesessary only if you have to sent messages to specific userId clients. In this case as I said previously you have to store clientId->userId links on you backend. Maybe in redis, maybe in memory. In other situations its not nesessary.\n. @roytan883 \n\nI don't get it. you said the same user, so when user subscription changed, it should sync with user's all client.\n\nThe \"same\" logic user, but not the same user application instance. In your example in github you see common notifications for this user (you) but you dont see info (dont subscribe) on other your pages. I.e. dont have all the info opened in all pages in every page. Right? You see only those info you asked for current page, not more. The same in subscriptions. Some of them you subscribe according to your page, some globaly. And in this case (github) you should remember on server side how many clients (their ids) you have up for your userId. @roytan883 \n\nI don't get it , how you implement step 3, how to make Android client automatically receive new messages from \"topic-123\".\n\nOk. Make this simple steps:\n1) subscribe to topic-1 from android\n2) subscribe to topic-1 fom web\n3) push message to topic-1 from backend\nYou'll get that message as on android and on web because both subscribed to a same topic\n. @roytan883 \n\nI think you are talking about traditional web page. But currently , web are more turn to SPA(single page web application), like angular or react, redux. web is more like a web client , not web page, especially APP area.\n\nIt doesnt matter. Actually I'm more in SPA. And I tryes to subscribe to channels that need at this moment. All this data store in browsers memory and in a intensive data exchange it might bring to browser's allocated for you app memory. Besides its like in database area normalization method - split data to tables and query only needing parts of info. You dont load all the data from database to your client but if yes - you have a very bad architecture.\n\nBy the way, in real world, simultaneously real time messages in one user's different channel is very very few.\n\nBut you suggest exactly this. You want to realtime load all the new messages from all channels and filter it on client side. Even those messages you might even wont need (you wont go to all those channels).\n\nAlso APP can limit user's join channels (100?), no limit subscription is not support\n\nAha! you allready limiting you users. Just because of architecture! But in our case you dont.\n\nhow Android know that should subscribe topic-1 ?\n\nHow do I know you have to go home or to sleep? How do you know you want to read a book? You just know. The same is here. If I want to read a Topic-1 - I subscribe to this topic.\n\nneed user manually awake his Android phone and open client APP, then manually click subscribe \"topic-1\" \n\nmanually, automatically - whats the difference? Its up to you as a developer how your user will subscribe to topic - automaticcaly or manually. I really don't get you. If you wish make a subscrition on app start or when user enters the chat room or else...\n\nor need somehow server send notification to Android client, then android client automatically subscribe to topic-1? show me the code.\n\nI dont get you. If you want to send to clients some common statistic, you can subscribe to a separate channel where you will send common info to a specific user. I dont understand why you should automattically subscribe to some channel according to a server event. You just do subscribe(\"channel\") when you need according to you app workflow and thats it.\n. @roytan883 \n\nI think the answer is YES. we are develop service for user, we are not technology decide which message should or not send to user.\n\nOh, I think I got you. It looks like your solution should be like this:\n1) For every user you have a separate channel. Just for this user. Just one channel.\n2) When user logins he subscribes to this channel. From all devices. This channel might be named by userId.\n3) Its up to  you (your backend) to find out that specific user has a new message and server just publish it to a channel userId. All user devices will get this messages as they subscribed to a same user channel.\n4) Every message has a property \"room\" by this you deside what to do in client side. I.e. you filters it. Say if you in a chat room \"topic-1\" - and this message has the same - you add it to a messages list. If this is a different chat room message - you popup it.\n5) Message may have some special properties (service, system) for other purposes\n6) thats it.\nThe same with sending messages. From any room you call the same server method, you just have to set the current room id property in message to which it belongs. \nThis is very simple as I see and right what you want... I guess...\n. @roytan883 \n\nNo, its not like that. If user-A joined group 1~100\uff0c then it subscribe \"group-1\" ~ \"group-100\", they are 100 subscriptions.\n\nIn my suggestion doesnt matter how many subscriptions user has. When he \"vurtually\" joined and subscribes to \"group-1-100\" backend just knows that user will accept messages from all this subscriptions. Anyway your backend is a main ruler so let him do this job. New message arrived - it looks for all the users who can accept this message (subscribed to a group message belongs) and send them. Here client is totally passive except the initial subscription to his channel.\nI just want to say that centrifugo in not the concept you want to use it. @roytan883 \n\nYour solution is bother both the client developer and backend server developer.\n\nThere is no miracles. In development bothers both sides. In a good product. @roytan883 \n\nIf a application logic can be handled by server then no need chagne the client.\n\nAccording to my experience I would give some reasonable logic to client to make my server breath. Let users processors work instead of my server. Thats why SPA has a growing interest - because its client-rendered. But of course it should be balanced. My main tool is Meteor.js and it has the similar websocket subscriptions engine. But because of node.js (serverside of meteor) not very good with sockets - a couple hundred of users make it die and even several users over ssh make it use 100% of processor I had to rewrite subscribtion engine using centrifugo. On my users count centrifugo almost always sleeps - I event cannot detect when it use some resources. And works fine. \nSo SPA is not dumb clients.. @roytan883 \n\nYou see , in my solution , the 1000K subscribe command were saved, it running in server side LAN network.\n\nIf you dont use your app you'll save 2000K commands, he-he :smile: \n. ",
    "williambao": "Hi @FZambia ,\nCould you update the Android SDK for this?\nAndroid SDK crashed when receive message from server, because the message json no timestamp property...\n\n. ",
    "arleincho": "i attach the two files\nArchivo comprimido.zip\n. ",
    "mogol": "@arden hey\nCentrifugeChannelDelegate has methods\nswift\n    func client(_ client: CentrifugeClient, didReceiveJoinInChannel channel: String, message: CentrifugeServerMessage)\n    func client(_ client: CentrifugeClient, didReceiveLeaveInChannel channel: String, message: CentrifugeServerMessage)\nThey should work after subscribing to channels.. I have already started implementation. Let me build skeleton, then it will be worth to push. . I have added very basic api.  It's definitely not ready for production. \nBut you could try and provide feedback if any. \nhttps://github.com/centrifugal/centrifuge-dart. ",
    "visrs": "when one channel online user above 1200\uff0cthis message will show\uff0cbut i want support more users. ulimit -a|grep open\nopen files                      (-n) 51200\n. when connections above 1200 \uff0clog will show and then all connections will lost connec. how many  connections  one centrifugo process   max  support\uff0ci want to know. proxy before Centrifugo is nginx. I just think how to do 50-100k clients?\nNow, i use jmeter for test. good tools.\nI found online  client num will be affected with config \"join_leave\": true. Yes\uff0c1.5.1. ",
    "DylanVolz": "I think he is building a chat room service using centrifugo that people can join and chat in, and is asking how to implement a way to passively watch the chat.\n@liughost if that is the case, you could either monitor the channel via the admin app after setting the watch option to true (https://fzambia.gitbooks.io/centrifugal/content/web/index.html) or implement a subscriber to the channel that had no write capability. . ",
    "liughost": "thanks! I study admin interface.. ",
    "sergunich": "@FZambia thanks for fast answer!\n\nCentrifugo has a field in it's internal protocol which indicates whether Centrifugo think that all messages were recovered after reconnect or not. So theoretically if we make it public it can be a signal that you need to ask your app server for missed messages.\n\nThat would be awesome. Seems like valuable feature.\n\nActually relying on this flag can slightly reduce amount of requests that you should do to your backend to get missed messages after each successful resubscribe.\n\nYes, that was exactly my plan :)\nFor now I will stick with \"re-request all data after disconnect\" approach. > Is this what you expect?\nYes\n\nrelying on this still does not guarantee that all messages were perfectly recovered\n\nThat's fine. I am aware of this.. @FZambia I don't know why but recovery doesn't work.\nCentrifugo server config:\n\nCentrifguge client config:\n\nMessages that I sent:\n\nTo emulate disconnection I use redir.\nClient -> redir -> centrifugo.\nTo disconnect client: just kill redir process.\nTo reconnect client: start redir again.\nSteps:\n- send several messages (through centrifugo admin)\n- disconnect(kill redir)\n- send several messages (through centrifugo admin)\n- reconnect(start redir)\nResult:\n\n. Wow! I somehow missed it...\nNow with correct namespace it works.\nThanks @FZambia !. ",
    "foobargeez": "+1 for this.  In need of this for Android and iOS clients too -- it helps to know when to request the backend app for more data (or not call backend explicitly at all if https://github.com/centrifugal/centrifugo/issues/166 accepted).. Thanks @FZambia.  centrifuge-mobile is exciting.. I was thinking/hoping to leverage centrifugo as a broker to communicate with our backend which then helps me to just deal with centrifugo and not call the backend explicitly (and deal with timeouts/failures/all the fun that comes with handling REST endpoints).\nIf not a magic message post to redis, something like supporting a RPC call too would work akin to deepstream's RPC.  I think RPC route is more generic and scalable.\nLet me know if we are on the same page.  If not, I am happy to jump into gitter and see if I can convince you :-). Thanks for your thoughts.  The issue really for me is that Centrifugo doesn't support historical message replays in a given channel and that the mobile app needs to have a plan B to circumvent that (it can be good or bad depending on how one sees it).  My preference at the moment is to rely on one thing (thing being a black box for now) and let that handle delivering recent messages quickly and historical messages albeit slowly (relatively).\nI understand that Centrifugo uses redis for storing messages (and storing tons of data in RAM isn't exactly free/a great idea) but having support for more than redis to replay historical data really helps.  If Centrifugo supports historical message replays, redis, will assume a cache role, to deliver recent messages (and quickly) and beyond that for historical data, Centrifugo queries an external database, be it Tarantool or Elasticsearch or simply external files based or whatever connectors you/community comes up with.  If you were to add support for an external database for historical data, I can't see how this can be a uni-directional data flow, as the client needs to listen for \"requesting more data\" and has to be passed to the server somehow as sending \"all\" data is sometimes be expensive and the client may not just want it or can't handle it.\nIf you were to stick with uni-directional data flow though, then may be, your idea of supporting external database could just be to replace redis but not necessarily in conjunction with redis and at least not for historical data.\nThe alternative to supporting external database for historical data is to support ability to just call REST endpoints with RPC support, although at the expense of uni-direction data flow, which you want to avoid, so not getting into it.\nI agree with your note about two hops, but I didn't think that would be a big deal (as far as elapsed time from user's perspective) if the client were to proactively read ahead data, so by the time the user wants historical data, it's ready for him.\nI came across pushpin in the past and it's on my list to things to look into, especially if Centrifugo doesn't support historical message replays.  I am not a big fan of too many moving parts/technologies -- hurts reliability at some point and pretty badly -- although I understand that sometimes you can't avoid that.\nIf you were to say that replaying historical messages is not on your priority list though/doesn't align with Centrifugo's goals, I will understand and will look around for other complimentary solutions to see if there is something that meets my requirements.  Appreciate your time and discussion!. Thinking more ... historical message replay is more likely a requirement by a particular client at a given time (or multiple clients at the same time for different date/time duration criteria) and having the historical messages being pushed to the same channel that all clients are connected isn't probably efficient, as we end up pushing more data to clients that don't really care for it (I don't really know if there is a way for the client to discard the data that it is not expecting though, so to not have any additional overhead of processing the data that it doesn't want).\nGiven the above concerns, I don't think on-demand data pushing for a single client to a channel where all clients are connected to, is efficient.  I would ideally prefer Tarantool/Elasticsearch (given their cluster abilities) for storing all the data (both new and historical) and have Centrifugo deliver messages in a streamed fashion (akin to NATS streaming).  This way, the client will connect to Centrifugo for all it's messaging needs and be (mostly) done.\nSupporting Tarantool/Elasticsearch as external storage will give me more flexibility as I can independently push data to those stores i.e., outside Centrifugo (Centrifugo reads from it, as it does from redis right now).\nNATS streaming is the closest to my requirements but I am not a big fan of file based stores, so supporting Tarantool/Elasticsearch/some DB that has cluster ability (and HA) will be a huge benefit.  Also, NATS lacks presence information and leave/join events that Centrifugo has.  So, I am looking for what Centrifugo does but replace Redis with an external DB (for data storage at least) and support streaming data.\nThanks for the discussion -- I am now more clear on what I am looking for :-)\nBTW, if you agree with the above (even not fully) and are willing to put in hours and I will certainly consider swallowing some of the development costs (do let me know your email and we shall discuss further).\nLet me know if something is unclear and I am happy to elaborate.. I was going through https://github.com/centrifugal/centrifugo/issues/45 and came across this by @banks:\n\nI'd actually suggest if we were to consider that, that we should make pubsub part a separate engine from storage part so you could write custom providers for that but. For example NATS.io, NSQ, RabbitMQ or Kafka for pubsub with DB X for storage of history etc.\n\nThe above is very close to what I was proposing above -- Redis (or some other provider) for pub-sub and an external DB for channel data (current and/or historical) along with a streaming client for channel data.. ",
    "chelkaz": "\u041e\u043d!!! Thank you! You're right! From CURL console OK!\n{\"websocket\":true,\"cookie_needed\":false,\"origins\":[\":\"],\"entropy\":565761875}. You opened my eyes! Thanks, I read a lot of documentation and searched for examples, but my little experience makes it difficult for me to understand.. HI! I use Nginx configuration for my domain and SSL https://centrifugal.github.io/centrifugo/deploy/nginx/\nAdmin page work http://mydomain.site:8000/#/ OK\ndefault NGINX 8000\nbot console command - curl http://localhost:8000/connection/info\n404 page not found \nHELP Please(. > Hi, are you migrating from Centrifugo v1 to Centrifugo v2? In v2 SockJS info endpoint path is /connection/sockjs/info\nNo, i quick install new https://packagecloud.io/FZambia/centrifugo/install#bash-rpm\nI did not have other versions\nIF now CURL curl http://localhost:8000/connection/sockjs/info return\n{\"websocket\":true,\"cookie_needed\":false,\"origins\":[\":\"],\"entropy\":243875689}\nIf site page browser\n/connection/sockjs/info failed: Error during WebSocket handshake: Unexpected response code: 404\nMy JS return /connection/sockjs/info/info?t=1549740207915 404\nimport Centrifuge from 'centrifuge'\nimport SockJS from 'sockjs-client'\nvar centrifuge = new Centrifuge('https://my.site/connection/sockjs/info', {\n    sockjs: SockJS\n});\ncentrifuge.subscribe(\"news\", function(message) {\n    console.log(message);\n});\ncentrifuge.connect();. ",
    "systimanx-itsol": "I]: 2018/04/05 17:54:11 Start serving raw websocket, SockJS, API, admin, web endpoints on :8000\n[F]: 2018/04/05 17:54:11 ListenAndServe: listen tcp :8000: bind: address already in use\ncurl http://localhost:8000/connection/info\n{\"websocket\":true,\"cookie_needed\":false,\"origins\":[\":\"],\"entropy\":170012351}\nand my config\n{\n  \"secret\": \"admin\",\n    \"connection_lifetime\": 0,\n    \"anonymous\": true,\n    \"publish\": true,\n    \"watch\": true,\n    \"presence\": true,\n    \"join_leave\": true,\n    \"history_size\": 10,\n    \"history_lifetime\": 30,\n    \"recover\": true,\n    \"admin_password\": \"admin\",\n    \"admin_secret\": \"admin\",\n    \"port\":\"8000\"\n}\nhow to solve this issue?. systimanx_itsol@centrifugal-instance:~$ lsof -i:8000\nsystimanx_itsol@centrifugal-instance:~$ curl http://localhost:8000/connection/info\n{\"websocket\":true,\"cookie_needed\":false,\"origins\":[\":\"],\"entropy\":1387084916}\nsystimanx_itsol@centrifugal-instance:~$ sudo centrifugo --config=config.json --admin --web\n[W]: 2018/04/06 02:26:33 No config file found\n[I]: 2018/04/06 02:26:33 Config path: /home/systimanx_itsol/config.json\n[I]: 2018/04/06 02:26:33 Version: 1.7.8\n[I]: 2018/04/06 02:26:33 PID: 5633\n[I]: 2018/04/06 02:26:33 Engine: In memory \u2013 single node only\n[I]: 2018/04/06 02:26:33 GOMAXPROCS: 1\n[I]: 2018/04/06 02:26:33 SockJS url: //cdn.jsdelivr.net/sockjs/1.1/sockjs.min.js\n[I]: 2018/04/06 02:26:33 Start serving raw websocket, SockJS, API, admin, web endpoints on :8000\n[F]: 2018/04/06 02:26:33 ListenAndServe: listen tcp :8000: bind: address already in use. systimanx_itsol@centrifugal-instance:~$ sudo lsof -i:8000\nCOMMAND    PID       USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\ncentrifug 5697 centrifugo    3u  IPv6  49023      0t0  TCP *:8000 (LISTEN)\n. After kill -15  i am able to stop all process and able to run it. ",
    "Sarga": "@systimanx-itsol show me please the result of command\nlsof -i :8000 . ",
    "LopatkinEvgeniy": "Yes of course\n. Why you increase size in method resize? I think would be better to increase capacity. In this way there will be no need in fields tail and ctn.\nq.tail == len(q.nodes) \nq.ctn == len(q.nodes[q.head:]). Ok, i'll roll back the changes. I deleted this. fixed. ok. ",
    "libsgh": "@FZambia When a client connects the client first, from history to find news, in order to receive offline messages, but these messages are the expiration time, but can not control the expiration time of each message, the message is stored in the redis, can not be achieved by way of TTL?. ",
    "msaranas": "i tried go build , got errors, I am using Gogland EAP IDE , go 1.8 version Please refer screenshot attached \n. Log FYI,\n/usr/local/Cellar/go/1.8.1/libexec/bin/go run /Users/admin/GoglandProjects/centrifugo/main.go\ngithub.com/centrifugal/centrifugo/libcentrifugo/centrifugo\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/centrifugo/main.go:208: cannot use nod (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node in argument to engineFactory\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/centrifugo/main.go:221: cannot use nod (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node in argument to fn\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/centrifugo/main.go:248: cannot use servers (type map[string]\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/server\".Server) as type map[string]\"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/server\".Server in field value\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/centrifugo/main.go:269: cannot use \"github.com/centrifugal/centrifugo/vendor/github.com/FZambia/viper-lite\".GetViper() (type \"github.com/centrifugal/centrifugo/vendor/github.com/FZambia/viper-lite\".Viper) as type \"vendor/github.com/centrifugal/centrifugo/vendor/github.com/FZambia/viper-lite\".Viper in argument to \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/config\".NewViperConfigSetter\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/centrifugo/main.go:269: cannot use rootCmd.Flags() (type \"github.com/centrifugal/centrifugo/vendor/github.com/spf13/pflag\".FlagSet) as type \"vendor/github.com/centrifugal/centrifugo/vendor/github.com/spf13/pflag\".FlagSet in argument to \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/config\".NewViperConfigSetter\ngithub.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory/engine.go:19: cannot use Plugin (type func(\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node, \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/config\".Getter) (\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/engine\".Engine, error)) as type plugin.EngineFactory in argument to plugin.RegisterEngine\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory/engine.go:24: cannot use MemoryEngine as type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/engine\".Engine in return argument:\n    MemoryEngine does not implement \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/engine\".Engine (wrong type for AddPresence method)\n        have AddPresence(string, string, \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ClientInfo, int) error\n        want AddPresence(string, string, \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ClientInfo, int) error\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory/engine.go:83: cannot use message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".Message) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".Message in argument to e.node.ClientMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory/engine.go:90: cannot use message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".JoinMessage) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".JoinMessage in argument to e.node.JoinMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory/engine.go:97: cannot use message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".LeaveMessage) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".LeaveMessage in argument to e.node.LeaveMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory/engine.go:104: cannot use message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ControlMessage) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ControlMessage in argument to e.node.ControlMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory/engine.go:111: cannot use message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".AdminMessage) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".AdminMessage in argument to e.node.AdminMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/enginememory/engine.go:124: cannot use &chOpts (type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ChannelOptions) as type *\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ChannelOptions in argument to e.historyHub.touch\ngithub.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:26: cannot use Plugin (type func(\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node, \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/config\".Getter) (\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/engine\".Engine, error)) as type plugin.EngineFactory in argument to plugin.RegisterEngine\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:27: cannot use Configure (type func(\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/config\".Setter) error) as type plugin.Configurator in argument to plugin.RegisterConfigurator\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:513: cannot use RedisEngine as type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/engine\".Engine in return argument:\n    RedisEngine does not implement \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/engine\".Engine (wrong type for AddPresence method)\n        have AddPresence(string, string, \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ClientInfo, int) error\n        want AddPresence(string, string, \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ClientInfo, int) error\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:1009: cannot use &message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ControlMessage) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".ControlMessage in argument to e.node.ControlMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:1017: cannot use &message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".AdminMessage) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".AdminMessage in argument to e.node.AdminMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:1093: cannot use &message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".Message) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".Message in argument to e.node.ClientMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:1100: cannot use &message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".JoinMessage) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".JoinMessage in argument to e.node.JoinMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:1107: cannot use &message (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".LeaveMessage) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".LeaveMessage in argument to e.node.LeaveMsg\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:1697: cannot use cmd (type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".APICommand) as type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/proto\".APICommand in argument to apiCmd\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:1714: cannot use n (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node) as type *\"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node in argument to apiv1.PublishCmdAsync\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/engine/engineredis/engine.go:1714: too many errors\ngithub.com/centrifugal/centrifugo/libcentrifugo/server/httpserver\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go:309: cannot use s.node (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node in argument to clientconn.New\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go:309: cannot use newSockjsSession(sess) (type sockjsSession) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".Session in argument to clientconn.New:\n    sockjsSession does not implement \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".Session (wrong type for Close method)\n        have Close(\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice) error\n        want Close(\"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice) error\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go:380: cannot use s.node (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node in argument to clientconn.New\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go:380: cannot use newWSSession(ws, pingInterval, writeTimeout, wsCompressionMinSize) (type wsSession) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".Session in argument to clientconn.New:\n    wsSession does not implement \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".Session (wrong type for Close method)\n        have Close(\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice) error\n        want Close(\"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice) error\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go:470: cannot use s.node (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node in argument to apiv1.ProcessAPIData\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go:592: cannot use s.node (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node in argument to adminconn.New\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go:592: cannot use sess (type wsSession) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".Session in argument to adminconn.New:\n    wsSession does not implement \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".Session (wrong type for Close method)\n        have Close(\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice) error\n        want Close(\"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice) error\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/handlers.go:612: cannot use \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice literal (type \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice) as type \"vendor/vendor/github.com/centrifugal/centrifugo/libcentrifugo/conns\".DisconnectAdvice in argument to c.Close\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/server.go:14: cannot use HTTPServerPlugin (type func(*\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/node\".Node, \"vendor/github.com/centrifugal/centrifugo/libcentrifugo/config\".Getter) (\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/server\".Server, error)) as type plugin.ServerFactory in argument to plugin.RegisterServer\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/server.go:15: cannot use HTTPServerConfigure (type func(\"vendor/github.com/centrifugal/centrifugo/libcentrifugo/config\".Setter) error) as type plugin.Configurator in argument to plugin.RegisterConfigurator\n../../go/src/github.com/centrifugal/centrifugo/libcentrifugo/server/httpserver/server.go:15: too many errors\nProcess finished with exit code 2. @FZambia @banks Thank you for your support, yes issue related to directory and  vendor directory.\nNow able to build ,run and debug using Gogland.\n\n. C# connect redis and publish messages in to channels, no control, Able to receive message but error occured invalid wire type because of json protobuf marshal unmarshal.,solution need on pubsub handle message override unmarshall.\nIn alternative Is there any client for centrifugo in c#?. I can propose that C# team to take and use centrifugo client instead direct redis publish. ",
    "Inpassor": "\ncentrofigo\n\nROFL. Here's the config that I use (removed some extra lines):\n```\nserver {\n    server_name {{SERVER_NAME}};\n    listen 80;\n    error_log off;\n    access_log off;\n    add_header X-Frame-Options DENY;\n    add_header X-Content-Type-Options nosniff;\n    add_header X-XSS-Protection \"1; mode=block\";\nif ($http_user_agent ~* (nmap|nikto|wikto|sf|sqlmap|bsqlbf|w3af|acunetix|havij|appscan)) {\n    return 403;\n}\n\nlocation / {\n    return 301 https://$host:443$request_uri;\n}\n\n}\nupstream centrifugo {\n    server 127.0.0.1:8000;\n}\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\nserver {\n    server_name {{SERVER_NAME}};\n    listen 443 ssl http2;\nerror_log /var/log/nginx/msg.{{DOMAIN}}.error.log;\naccess_log /var/log/nginx/msg.{{DOMAIN}}.access.log;\n\nadd_header X-Frame-Options DENY;\nadd_header X-Content-Type-Options nosniff;\nadd_header X-XSS-Protection \"1; mode=block\";\nadd_header Strict-Transport-Security \"max-age=31536000;\";\nadd_header 'Access-Control-Allow-Origin' \"$http_origin\";\n\nif ($http_user_agent ~* (nmap|nikto|wikto|sf|sqlmap|bsqlbf|w3af|acunetix|havij|appscan)) {\n    return 403;\n}\n\nset $root_path /var/www/msg.{{DOMAIN}};\nroot $root_path;\ndisable_symlinks if_not_owner from=$root_path;\ncharset utf-8;\nautoindex off;\n\nssi on;\nssl on;\nssl_certificate \"/etc/letsencrypt/live/{{DOMAIN}}/fullchain.pem\";\nssl_certificate_key \"/etc/letsencrypt/live/{{DOMAIN}}/privkey.pem\";\nssl_trusted_certificate \"/etc/letsencrypt/live/{{DOMAIN}}/chain.pem\";\nssl_ciphers AES256+EECDH:AES256+EDH;\nssl_prefer_server_ciphers on;\nssl_protocols TLSv1.2;\nssl_ecdh_curve secp384r1;\nssl_stapling on;\nssl_stapling_verify on;\nssl_session_timeout 24h;\nssl_session_cache shared:SSL:24m;\nssl_buffer_size 1400;\n\nsendfile on;\ntcp_nopush on;\ntcp_nodelay on;\ninclude /etc/nginx/mime.types;\ndefault_type application/octet-stream;\nproxy_next_upstream error;\nlocation /connection {\n    proxy_pass http://centrifugo;\n    proxy_buffering off;\n    keepalive_timeout 65;\n    proxy_read_timeout 60s;\n    proxy_http_version 1.1;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Scheme $scheme;\n    proxy_set_header Host $http_host;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n}\nlocation /socket {\n    proxy_pass http://centrifugo;\n    proxy_buffering off;\n    keepalive_timeout 65;\n    proxy_read_timeout 60s;\n    proxy_http_version 1.1;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Scheme $scheme;\n    proxy_set_header Host $http_host;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n}\nlocation / {\n    proxy_pass http://centrifugo;\n    proxy_buffering off;\n    keepalive_timeout 65;\n    proxy_read_timeout 60s;\n    proxy_http_version 1.1;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Scheme $scheme;\n    proxy_set_header Host $http_host;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n}\n\n}\n```\nInstead of {{...}} insert what you need, the ssl settings should be changed according to your needs. Change paths to files and directories to your own.. @delprofile try this:\n\nRemove everything related to centrifugo from the config vhosts domain.conf\nCreate a new file /etc/nginx/vhosts/{{YOUR_HOST}}/centrifugo.conf\nCopypaste my config example.\nMake sure that server_name in the centrifugo.conf point to a SUBDOMAIN, e.g. centrifugo.yourdomain.com\nDon't forget to add centrifugo.yourdomain.com to your SSL sertificate (the sertificate should be one for all your domains on the same IP address).\nConnect to centrifugo by the url\nwss://centrifugo.yourdomain.com. @delprofile by the way, did you try to connect by the url wss://yourdomain.com/centrifugo ?. Try to add the root certificate at the top of your certificate chain.. @FZambia , Alexandr, you were allowed!. @delprofile , is this a complete listing of your config? This will not work.. @FZambia , no problem, you're welcome!. \n",
    "johnsonc": "@synw Hey! Sorry about the delay. I do have django-channels implementations lying around :) \nThere are a couple over the web. Let me know what we can measure against and we can try it out?\n@FZambia Thanks for the reply! Yes! Am absolutely aware that it will take some non-trivial work and here's why I believe it will be beneficial: \n1. Benchmarks and documentation drive adoption. \n2. Your knowledge of the application is what is paramount to \n  a) Squeeze the juice out of it, that other devs cannot. \n  b) If you slap in into a build process (which as the author of this beautiful piece of work), you don't need to touch it too many times :) \n   => run_benchmarks.go or something and you're sorted! \n3.) Django-channels has a lot of concepts, very little production usage or metrics. But code for code, there are thousands of more repos just testing out channels which is a pure python implementation as opposed to centrifugo, which I believe owing to the stack, will be much more performant. \n . ",
    "oleh-ozimok": "Yes, but now only in dev environment, staging and production envs at the implementation stage.. ",
    "mkevac": "I mean something like example index.html that uses centrifugo.js, connects to centrifugo and just prints all messages received for a selected channel in text area.\nOne can use such an example as an example :-) and for debugging.. > Do you know how this syscall behaves on Windows btw?\nIt does not work on Windows AFAIK. But ps does not work either...\n\nAs I said above I think Centrifugo should avoid measuring CPU stats itself\nAlso in today's container world CPU must be measured per-container from outside as there is no such info inside container.\n\nThis is very limiting.\nEven if we were using containers for centrifugo, we would have to put only centrifugo inside and we would need separate tools for measuring CPU usage. It makes whole infrastucture more complex.\nMaybe it's not important for centrifugo and Go, but imagine some service uses several processes or forks periodically. Measuring CPU usage from outside would not be precise enough. It would be per container, not per process. I don't even mention that sometimes it could be useful to measure CPU usage per thread (not for Go though).\n. Adding this code in v1 makes sense. I see no reason not to. It is useful and @Sannis is prepared to support it.\nPorting this code to v2 is not so useful, because you don't need it and we at Badoo don't use it. It would be a dead code. I would wait until someone asks for it or @Sannis makes a patch :-). ",
    "iamsee": "thank u,that help me. yep, not use custom admin_web_path , just the builtin. ",
    "a1martin": "Are the namespaces required then? \nIf I have the conf like that:\n{ \"secret\": \"key\", \n\"admin_password\": \"admin_psw\", \n\"admin_secret\": \"key\", \n\"insecure_api\":true, \n\"api_port\":7777 }\nand subscribe to channel $test: centrifuge.subscribe(\"$test\", function(message) { console.log(message); });\nand send to HTTP API: \n{\n    \"method\": \"publish\",\n    \"params\": {\n        \"channel\": \"$test\",\n        \"data\": {\n            \"input\": \"hello\"\n        }\n    }\n}\nthen the centrifugo console shows POST /api/ from [::1]:50295 completed in 0s but nothing shows up in browser.. Case solved! The problem was malformed response. Signature was on JSON field \"token\" but had to be \"sign\". Thanks for help!. ",
    "delprofile": "\u042f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b \u043a\u043e\u043d\u0444\u0438\u0433 \u0438\u0437 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432, \u0442\u043e\u043b\u043a\u0443 0\n```\nupstream centrifugo {\n    ip_hash;\n    server 127.0.0.1:8000;\n}\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    ''      close;\n}\nserver {\n    server_name *.ru www.*.ru;\n    ssl on;\n    ssl_certificate \"/var/www/httpd-cert/*/*.ru.crtca\";\n    ssl_certificate_key \"/var/www/httpd-cert/*/*.ru.key\";\n    ssl_ciphers EECDH:+AES256:-3DES:RSA+AES:RSA+3DES:!NULL:!RC4:!RSA+3DES;\n    ssl_prefer_server_ciphers on;\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    add_header Strict-Transport-Security \"max-age=31536000;\";\n    ssl_dhparam /etc/ssl/certs/dhparam4096.pem;\n    charset off;\n    index index.html index.php;\n    disable_symlinks if_not_owner from=$root_path;\n    include /etc/nginx/vhosts-includes/.conf;\n    include /etc/nginx/vhosts-resources/*.ru/.conf;\n    access_log /var/www/httpd-logs/*.ru.access.log;\n    error_log /var/www/httpd-logs/*.ru.error.log notice;\n    ssi on;\n    set $root_path /var/www/*/data/www/*.ru/public;\n    gzip on;\n    gzip_comp_level 5;\n    gzip_disable \"msie6\";\n    gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript;\n    location / {\n        location ~ [^/].ph(p\\d|tml)$ {\n            try_files /does_not_exists @fallback;\n        }\n        location ~ ^.+.(jpg|jpeg|gif|png|svg|js|css|mp3|ogg|mpe?g|avi|zip|gz|bz2?|rar|swf)$ {\n            expires 7d;\n            try_files $uri $uri/ @fallback;\n        }\n        location / {\n            try_files /does_not_exists @fallback;\n        }\n    }\n    location @fallback {\n        proxy_pass http://127.0.0.1:8080;\n        proxy_redirect http://127.0.0.1:8080 /;\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Forwarded-Port $server_port;\n        access_log off;\n    }\nlocation /centrifugo/ {\n        rewrite ^/centrifugo/(.*)        /$1 break;\n        proxy_pass_header Server;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Scheme $scheme;\n        proxy_pass http://centrifugo;\n    }\nlocation /centrifugo/socket {\n    rewrite ^/centrifugo(.*)        $1 break;\n\n    proxy_next_upstream error;\n    proxy_buffering off;\n    keepalive_timeout 65;\n    proxy_pass http://centrifugo;\n    proxy_read_timeout 60s;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Scheme $scheme;\n    proxy_set_header Host $http_host;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n}\n\nlocation /centrifugo/connection {\n    rewrite ^/centrifugo(.*)        $1 break;\n\n    proxy_next_upstream error;\n    gzip on;\n    gzip_min_length 1000;\n    gzip_proxied any;\n    proxy_buffering off;\n    keepalive_timeout 65;\n    proxy_pass http://centrifugo;\n    proxy_read_timeout 60s;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Scheme $scheme;\n    proxy_set_header Host $http_host;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n}\nroot $root_path;\nlisten 185.87.49.66:443;\nlisten [2a02:f680:1:1100::3985]:443;\n\n}\n```\n\u041a\u0430\u043a \u0436\u0435 \u043c\u043d\u0435 \u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c ssl \u0435\u0441\u043b\u0438 \u0443 \u043c\u0435\u043d\u044f \u0445\u043e\u0441\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442 ssl?\n\u0423 \u043c\u0435\u043d\u044f \u0432\u0435\u0431 \u0441\u0435\u0440\u0432\u0435\u0440\u043e\u043c \u0443\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u0442 isp manager. \u041d\u0435 \u043f\u0440\u043e\u043a\u0430\u0442\u0438\u0442, \u043f\u043e \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u043f\u0440\u0438\u0447\u0438\u043d\u0435 \u0443 \u0432\u0430\u0441 \u0441\u0442\u043e\u0438\u0442 \u0447\u0438\u0441\u0442\u044b\u0439 nginx \u0443 \u043c\u0435\u043d\u044f \u0436\u0435 \u0441\u0442\u043e\u0438\u0442 nginx+apache. I asked, ISP support dont help.\nisp manager cfg\n```\nuser www-data;\nworker_processes  1;\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\nevents {\n    worker_connections 40000;\n}\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\nlog_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                  '$status $body_bytes_sent \"$http_referer\" '\n                  '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\naccess_log  /var/log/nginx/access.log  main;\n\nsendfile        on;\n#tcp_nopush     on;\n\nkeepalive_timeout  65;\n\n#gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\ninclude /etc/nginx/vhosts/*/*.conf;\nclient_max_body_size 128m;\nserver {\n    server_name localhost;\n    disable_symlinks if_not_owner;\n    listen 80;\n    include /etc/nginx/vhosts-includes/*.conf;\n    location @fallback {\n        error_log /dev/null crit;\n        proxy_pass http://127.0.0.1:8080;\n        proxy_redirect http://127.0.0.1:8080 /;\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        access_log off ;\n    }\n}\n\n}\n```\nconf.d - # disabled by ISPmanager\nvhosts domain.conf\n```\nupstream centrifugo {\n    server 127.0.0.1:8000;\n}\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    ''      close;\n}\nserver {\n    server_name *.ru www.*.ru;\n    ssl on;\n    ssl_certificate \"/var/www/httpd-cert/*/*.ru.crtca\";\n    ssl_certificate_key \"/var/www/httpd-cert/*/*.ru.key\";\n    ssl_ciphers EECDH:+AES256:-3DES:RSA+AES:RSA+3DES:!NULL:!RC4:!RSA+3DES;\n    ssl_prefer_server_ciphers on;\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    add_header Strict-Transport-Security \"max-age=31536000;\";\n    ssl_dhparam /etc/ssl/certs/dhparam4096.pem;\n    charset off;\n    index index.html index.php;\n    disable_symlinks if_not_owner from=$root_path;\n    include /etc/nginx/vhosts-includes/.conf;\n    include /etc/nginx/vhosts-resources/*.ru/.conf;\n    access_log /var/www/httpd-logs/*.ru.access.log;\n    error_log /var/www/httpd-logs/*.ru.error.log notice;\n    ssi on;\n    set $root_path /var/www/*/data/www/*.ru/public;\n    gzip on;\n    gzip_comp_level 5;\n    gzip_disable \"msie6\";\n    gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript;\n    location / {\n        location ~ [^/].ph(p\\d|tml)$ {\n            try_files /does_not_exists @fallback;\n        }\n        location ~ ^.+.(jpg|jpeg|gif|png|svg|js|css|mp3|ogg|mpe?g|avi|zip|gz|bz2?|rar|swf)$ {\n            expires 7d;\n            try_files $uri $uri/ @fallback;\n        }\n        location / {\n            try_files /does_not_exists @fallback;\n        }\n    }\n    location @fallback {\n        proxy_pass http://127.0.0.1:8080;\n        proxy_redirect http://127.0.0.1:8080 /;\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Forwarded-Port $server_port;\n        access_log off;\n    }\n    location /centrifugo/connection {\n        proxy_pass http://centrifugo;\n        proxy_buffering off;\n        keepalive_timeout 65;\n        proxy_read_timeout 60s;\n        proxy_http_version 1.1;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Scheme $scheme;\n        proxy_set_header Host $http_host;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n    }\n    location /centrifugo/socket {\n        proxy_pass http://centrifugo;\n        proxy_buffering off;\n        keepalive_timeout 65;\n        proxy_read_timeout 60s;\n        proxy_http_version 1.1;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Scheme $scheme;\n        proxy_set_header Host $http_host;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n    }\n    location /centrifugo/ {\n        proxy_pass http://centrifugo;\n        proxy_buffering off;\n        keepalive_timeout 65;\n        proxy_read_timeout 60s;\n        proxy_http_version 1.1;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Scheme $scheme;\n        proxy_set_header Host $http_host;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n    }\n    root $root_path;\n    listen 185.87.49.66:443;\n    listen [2a02:f680:1:1100::3985]:443;\n}\n```\nBut not worked. Try! not worked... I'll try your version in the evening. work, but jscent \nvar cent_conf = {\n    url: \"https://centrifugo.*****.ru/api/\",\n    secret: \"secret\",\n    strictSSL: \"true\"\n}\nurl: 'https://centrifugo.*****.ru/api/',\n  error: { Error: unable to verify the first certificate\n. @FZambia sorry, no problem steel on jscent. i changed certificate bot don't work\nerror: { Error: unable to verify the first certificate\nAnd you may add this config to your readme for nginx+apache+isp manager 5+Let's Encrypt\n```\nupstream centrifugo {\n    server 127.0.0.1:8000;\n}\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\nserver {\n    server_name centrifugo.{{ YOURDOMAIN }} www.centrifugo.{{ YOURDOMAIN }};\n    listen xxx.xxx.xxx.xxx:443;\nssl on;\nssl_certificate \"/var/www/httpd-cert/hardcsgo/centrifugo.{{ YOURDOMAIN }}.crt\";\nssl_certificate_key \"/var/www/httpd-cert/hardcsgo/centrifugo.{{ YOURDOMAIN }}.key\";\nssl_ciphers EECDH:+AES256:-3DES:RSA+AES:RSA+3DES:!NULL:!RC4:!RSA+3DES;\nssl_prefer_server_ciphers on;\nssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n\nerror_log /var/www/httpd-logs/centrifugo.{{ YOURDOMAIN }}.error.log;\naccess_log off;\n\ninclude /etc/nginx/vhosts-includes/*.conf;\n\nlocation / {\n    proxy_pass http://centrifugo;\n    proxy_buffering off;\n    keepalive_timeout 65;\n    proxy_read_timeout 60s;\n    proxy_http_version 1.1;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Scheme $scheme;\n    proxy_set_header Host $http_host;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n}\n\n}\n. @Inpassor , working (=\nupstream centrifugo {\n    server 127.0.0.1:8000;\n}\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\nserver {\n    server_name centrifugo.{{ YOURDOMAIN }} www.centrifugo.{{ YOURDOMAIN }};\nssl on;\nssl_certificate \"/var/www/httpd-cert/{{ YOURISPUSER }}/centrifugo.{{ YOURDOMAIN }}.crt\";\nssl_certificate_key \"/var/www/httpd-cert//{{ YOURISPUSER }}/centrifugo.{{ YOURDOMAIN }}.key\";\nssl_ciphers EECDH:+AES256:-3DES:RSA+AES:RSA+3DES:!NULL:!RC4:!RSA+3DES;\nssl_prefer_server_ciphers on;\nssl_protocols TLSv1 TLSv1.1 TLSv1.2;\nssl_dhparam /etc/ssl/certs/dhparam4096.pem;\n\naccess_log off;\nerror_log /var/www/httpd-logs/centrifugo.{{ YOURDOMAIN }}.error.log;\n\ninclude /etc/nginx/vhosts-includes/*.conf;\n\nlocation / {\n    proxy_pass http://centrifugo;\n    proxy_buffering off;\n    keepalive_timeout 65;\n    proxy_read_timeout 60s;\n    proxy_http_version 1.1;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Scheme $scheme;\n    proxy_set_header Host $http_host;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n}\n\nlisten xxx.xxx.xxx.xxx:443;\n\n}\n``\nmay check \n- https://centrifugo.hardcsgo.ru/\n- https://centrifugo.hardcsgo.ru/api/\n- https://centrifugo.hardcsgo.ru/connection/\n- https://centrifugo.hardcsgo.ru/connection/websocket\n- wss://centrifugo.hardcsgo.ru/. @FZambia dont i generate chain, isp manager generate this. @FZambia isp manager generate 4 file\ncrt ca key and crtca\ni changedssl_certificate \"/var/www/httpd-cert/{{ YOURISPUSER }}/centrifugo.{{ YOURDOMAIN }}.crt\";tossl_certificate \"/var/www/httpd-cert/{{ YOURISPUSER }}/centrifugo.{{ YOURDOMAIN }}.crtca\";`\nand test js work fine, fucking ispmanager (=\nsolution \nssl_certificate \"/var/www/httpd-cert/{{ YOURISPUSER }}/centrifugo.{{ YOURDOMAIN }}.crt\";\nssl_certificate_key \"/var/www/httpd-cert//{{ YOURISPUSER }}/centrifugo.{{ YOURDOMAIN }}.key\";\nto\nssl_certificate \"/var/www/httpd-cert/{{ YOURISPUSER }}/centrifugo.{{ YOURDOMAIN }}.crtca\";\nssl_certificate_key \"/var/www/httpd-cert//{{ YOURISPUSER }}/centrifugo.{{ YOURDOMAIN }}.key\";. THX ALL FOR HELP AND MOST RESPECT FOR CENTRIFUGO!!!!!!!!!!. ",
    "skyborn8": "@FZambia awesome, thanks!. ",
    "YOxan": "@FZambia thank you for your reply! We wanted to utilize it to make some intercommunication between participants of room. The channels will be bound to an inner room model. There are two roles of participant of the room: roleA and roleB. We need to track events of connection/disconnection of users with such roles to collect them for the further analysis and to close the room if participant with roleA will absent in room (on channel) more than 1 minute for example. Maybe you know some way how we could deal with that? Thank you! . Ok, I see. That's an option, I just thought there is some predefined mechanism to notify third-party service from Centrifugo. Thank you.. Hello! We have found that we can't go without events from the message exchange part, so it's reasonable to look for something else or develop our own bicycle) Thank you! . ",
    "cheddarwhizzy": "I have a use case where I'd like to know on the backend if a user has connected or disconnected. Right here https://github.com/centrifugal/centrifugo/blob/80db50873c1b5478aac3eaf5dc012b1389c808c3/libcentrifugo/server/handlers.go#L166 is where I'd like to trigger a webhook when the client disconnects. I could also add a webhook when the client connects as well. \nI'll get a PR going if this is something we can get into master. Otherwise I'll probably end up building a custom solution.\nI'm basically using a single connection per client, and broadcasting the messages to connected clients. If a user has either lost connection or closed the app, I'd like my backend to be aware so I can take necessary actions (send notifications of new messages to that user, set user status to \"away\" or \"online\", etc..) . In regards to a failing centrifugo node, wouldn't the node fail and not trigger any handlers? Therefore no webhooks would be triggered. As for the massive reconnect after a failure, if there a \"state\" for each client stored somewhere (redis?), then centrifugo technically could disregard this reconnect if the client ID hasn't changed. But if the outage was for even 5 seconds, that's potential for lots of lost messages. So triggering the reconnect webhooks could be a good thing depending on the application. \nAs far as the webhook not being received and handled in my application properly without error I don't see being a concern for centrifugo. Just like if my Jenkins is down when a dev commits to Github, not Github's problem :) \nIs this something we can enable via config option(s)? . Thanks for the feedback. Here is my attempt at a proposal. I used the golang proposal template. Hopefully this covers what you're looking for :)\nAbstract\nImplement webhooks on configured Centrifugo events, enabling other server-side services to react accordingly.\nBackground\nCurrently, Centrifugo is in it's own bubble. Whatever happens in Centrifugo, stays in Centrifugo. This can be an issue if you have a real-time application that needs to know when users connect/disconnect, publish messages, . For example, if a user connects, change his/her status to \"online\" and send all relevant data from the backend to the user via websocket connection. If a user disconnects, send relevant data via push notification, email, etc and set user to \"offline\". Another example would be if a user publishes a message directly to the Centrifugo API rather than POST to your API and push to Centrifugo, you may want to relay that message to a data warehouse for machine learning or other purpose.\nProposal\nAdd a \"hooks\" or \"webhooks\" package and add it to the relevant handlers. . Config to enable this functionality could be \n\"webhooks\": true,\n  \"webhook_url\": \"https://some-service.domain.com/webhook\",\n  \"enabled_webhooks\": [\"SockJsConnect\", \"SockJsDisconnect\", \"RawWsConnect\", \"RawWsDisconnect\", \"PublishMessage\", \"BroadcastMessage\", \"Unsubscribe\", \"Subscribe\"]\nHaving separate webhook URL's per event is another option for higher performance. Omitting \"url\" could default to a single endpoint\ndefault_webhook_url: \"https://default-webhook-service.domain.com/webhook\",\nwebhooks: [\n  {\n    enabled: true,\n    name: \"SockJsConnect\",\n    url: \"https://connect-webhook-service.domain.com\"\n  },\n  {\n    enabled: false,\n    name: \"BroadcastMessage\",\n    url: \"https://message-webhook-service.domain.com\"  \n  },\n  {\n  enabled: true,\n  name: \"Subscribe\"\n  }\n]\nWhen decommissioning a node gracefully, the webhooks for connect/disconnect should be ignored because they will be reconnected to another available node. \nWhen a node drops out due to being unresponsive, the clients would reconnect to a new node also ignoring the connect webhook since it was previously connected. The client has \"isResubscribe\" for this. If the app is using raw websocket, this will have to be handled by the webhook service or via connection parameters such as wss://centrifugo.domain.com/connection/websocket?notifyConnect=false\nRationale\nI can't think of any alternate approaches to this problem other than to write a custom websocket service that has this functionality. A proxy service that sits in front of Centrifugo for handling direct publishes/broadcasts could work, but is not ideal. Having a 2nd websocket connection to another service for handling online/offline status, but then you might as well go custom solution. There aren't really any disadvantages to having this webhook functionality as a feature of Centrifugo that I can think of. \nCompatibility\nThis change should not affect existing functionality. This means any users currently using Centrifugo should be able to upgrade to this version using their existing config without running into any issues. Webhooks would be configurable via the config.json file\nImplementation\nI could begin this after the MVP release of the app I'm working on as this isn't a make or break feature. Development would begin about the start of Feb 2018. \n. After doing a bit more research, I came across a project called Melody which has functions for each of these events so it seems to be way less work to create a custom web socket api using Melody vs diving into Centrifugo code. If you like the proposal and think this would be a good feature for Centrifugo, I\u2019d be happy to contribute cuz I really like this project. If not feel free to close this issue and thank you for your time :) cheers!. I actually wasn't considering a failure mechanism in Centrifugo for the failed POST request to the webhook endpoint. I'd imagine if the webhook endpoint went down, there could be tons of failed requests and data that would need to be queued for retry and that'd be a bit overkill for what I was thinking. Having a HA webhook endpoint that processes the data could handle retries by sending data straight to a bus (kafka, rabbitmq, or nsq) and processing the message accordingly using workers/consumers. With that said, webhooks was more of a quick and dirty way of getting data across services written in any language that speak HTTP. And I was piggy-backing off this issue hehe.\nThe library idea would probably perform better. I'd imagine another websocket connection straight to the Centrifugo server subscribing to all or selected events, or a grpc implementation. The only downside to the library is that it'll need libs for all languages. Using any websocket client (from say a nodejs service) or having a RPC server to receive events is what immediately comes to mind, but I'm sure you've thought about it a lot more and have some solid ideas. . ",
    "furdarius": "I'll take it.. @FZambia glad to help you!\nAll review notes fixed.. Fixed. Commented. No problem! Done!. ",
    "vadimkozak": "Geo based system, so I have 100 users with mobile app which send their locations every 2 seconds to centrifugo. Each user have an their own channel called user_{id}. In Admin panel I need to get all users in some X radius on api call, on my opinion would be best way to get all latest messages of each channel (for example from user_1 to user_100), and then calculate which users in radius (on my side).. thanks for response, centrifugo Is a great service, I want to try it as a transport from client to server bcz http will slow down my server) . ",
    "damour": "Useful for restoring messages at the initial subscribe.\nFor example, updating message box counter after page rendering (we know last published message id at that moment).. Hi @FZambia ! Thanks for prompt response. Some background. At our site in header user can see his  message counter (in internal mail). Frontend is classic web application (not single-page application) so after some actions page reloads. After page loading/reloading user see his message counter. Then we subscribe to user notification channel and update message counter.\nBackend - microservices that communicates via async messages.\nProblem: user can missing some messages.\nRegistration use case:\n- user click \"register\" button, controller in user service push welcome message to user notification channel, sends async UserRegistered message to message bus and return response to user.\n- page loaded, user see 1 message.\n... at this moment background workers sends another messages to user\n- we subscribe to user channel.\nResult: user see 1 message.\nExpected result: user see 2 messages in message box.\nProposed solution: when page rendering we store last message uid with counter. Then in subscribe command we provide last id:  {channel: \"notifications\", last: lastMessageUId, recover: true}. So centrifugo restore messages and user see actual info.. We use centrifugo beyond api gateway:\nclient (graphql subscription) -> api gateway(nodejs websocket client) -> centrifugo.\nTherefore, for us it is not mandatory, but for other users it will definitely be useful. Thanks!. ",
    "vladshut": "@FZambia \nThis functionality allows to push notification with specified uid to centrifugo. Also server can send notifications directly (without centrifugo) to client with specified uid and client can fetch notifications from centrifugo started from specified uid by server.. @FZambia Hi! I attached goroutine profile.\nFor debugging I created some wrapper for sync.rwmutex. Here it is: https://github.com/vladshut/rwmutex_debug_logger/blob/master/rwmutex_debug_wrapper.go\nI tried to fix it in the same way: https://github.com/centrifugal/centrifugo/commit/688c290f0cb05161f19e27ca90c8b87b7aa105cd\nBut, unfortunately, it didnt fix this issue.\nSo, I  build  centrifugo from latest master branch (with this fix: https://github.com/centrifugal/centrifugo/commit/688c290f0cb05161f19e27ca90c8b87b7aa105cd) and now we use it in production to test this fix again. I will comment about results.\n. Sory, here it is: goroutine.txt\nUnfortunately, that fix does not help. \n. @FZambia I wrote you message on Gitter.. ",
    "ingosus": "Hi @FZambia ! Thanks for your help. My bad ;). ",
    "tianxia007": "thanks. after network disconnect,the messages stored to where... thanks. wrong:2018/04/13 18:06:30 Error parsing configuration: While parsing config: invalid character '\"' after object key:value pair\n{\n  \"watch\": true,\n  \"publish\": true,\n  \"secret\": \"\",\n  \"web\": true,\n  \"admin_password\": \"password\",\n  \"admin_secret\": \"secret\"\n  \"namespaces\": [\n    {\n      \"name\": \"public\",\n      \"anonymous\": true,\n      \"publish\": true,\n      \"watch\": true,\n      \"presence\": true,\n      \"join_leave\": true,\n      \"history_size\": 10,\n      \"history_lifetime\": 30,\n      \"recover\": true,\n        \"engine\": \"redis\",\n        \"redis_host\"= \"ip.top\",\n        \"redis_port\"= \"7000\",\n        \"redis_db\"= \"3\",\n        \"redis_password\"= \"pass1\"\n    }\n  ]\n}. thanks!. ",
    "hudbrog": "Yes, we are using refresh. Even more, it would seems that most of the errors are from users who has left the page(and ws connection) open for quite some time. . Got to say - it's not a seldom occasion too. I have tens of thousands of these errors in the last couple of weeks. . Thanks, been running it for 24h now, seems to be ok!. ",
    "xurwxj": "@FZambia i can do this\nhttps://github.com/xurwxj/centrifugal_cn_doc\nI'll do as much as possible to translate 1~2 markdown files a week\n. finish start and configuration translation, change gitbook to v3\nnow u can run gitbook serve directly in your local env after pull the doc repo of mine. @FZambia u can merge into your docs repo when i finish translation.. @FZambia That's ok. I can follow up v2 after i have an in-depth understanding and practice of Centrifugo when translate v1's doc to Chinese.. @FZambia I propose to integrate Centrifugo's session into redis in v2. ",
    "kaizer666": "We have asked in https://github.com/centrifugal/centrifuge-android/issues/14, but we have no answer. \u0422\u0440\u0435\u0439\u0441 \u043f\u0440\u0438 \u043a\u043e\u043d\u043d\u0435\u043a\u0442\u0435 \u043a \u0434\u043e\u043c\u0435\u043d\u0443 (\u0447\u0435\u0440\u0435\u0437 Nginx) - https://pastebin.com/HyuGkTPu\n\u0422\u0440\u0435\u0439\u0441 \u043f\u0440\u0438 \u043a\u043e\u043d\u043d\u0435\u043a\u0442\u0435 \u043a Ceentrifugo (\u043d\u0430\u043f\u0440\u044f\u043c\u0443\u044e) - https://pastebin.com/yC3Cd0Xx. @FZambia And many people need to fix https://github.com/centrifugal/centrifugo/issues/147\nA timestamp is not sent from centrifugo.. I get the same error when updating. ",
    "Vovan-VE": "Ubuntu 16.04. ",
    "arrowcircle": "Hey! Great news!\nWhere I can find the protocol changes to make ruby lib compatible?. ",
    "masterada": "Hello,\nGreat work. After browsing through the code I have some thoughts (I have never used centrifugo before, I'm just know checking the project to see if it fits my use case).\nI see that the Engine is no longer pluggable.\n\nIs there a reason for unexporting the engine methods?\nIs there a reason for removing the plugin.go? I understand it doesn't make much sense in the library code, but I think it could still be included in the server project. Registering a new plugin and using it from config is much cleaner in my point of view than forking the server project to change 1 line for using a different engine.\nI also realized that the engine interface consists of 3 parts: PUB/SUB mechanics, channel history and presence information. I think it could be separated into 3 different interfaces, with minimal effort (histroy saving would need to be moved to a dedicated addHistory method, which could be called from Node.publish method). RedisEngine could still implement all 3 interfaces, but pub/sub, history and presence handling could be swapped out independently.\n\nMy use case:\nI need to write a special presence handling. In v1 I could write a custom engine that has an embedded RedisEngine struct with the presence methods overriden. Now with the Engine interface methods being unexported it's no longer possible.\nAn another note:\nIt would be really nice to have a mute client in channel feature in the server API, resulting in that client not getting the messages.\nMy use case:\nFree clients join a channel. One of them starts paying. This one client will receive slightly different notifications on that channel. I know it's possible to leave that channel and join another for the paying session, but it would need to be initiated on frontend, and it would be really nice to be able to solve this on backend only. An alternate solution could be to be able to add \"except_clients\" id list to publish/broadcast messages.. Thanks for the detailed explanation. I completely understand you reasons for not wanting to sacrifice performance for a feature that's might not even needed (separating broker from history).\nAbout subscribing clients on server side\nLet's assume a js client subscribed to a public:news channel. He is handling \"news\" type messages. It might not even make sense to subscribe him to a public:groceries channel, because the client would need to handle these new types of messages, so we might as well just instruct the client to subscribe to public:groceries channels by itself. \nOn the other hand, it might make sense to subscribe the client to a gossips:news channel. It has the same kind of messages, the client already handles them, the only difference is that now the client will get more messages of the same kind. However it would still be confusing, the client subscribed to public:news, and suddenly it starts getting messages from gossips:news. I don't see a good, non-confusing way of implementing this, so let me suggest a different approach.\nMessage tagging\nDuring publishing a message, there is an optional tag parameter. Each subscription (user-channel combination) has it's own tags. When forwarding a message to a user, only forward it if the subscription has a tag matching the message's tag. Configuration could contain default tags (for namespaces) that are automatically added to each new subscriptions. Tags could be managed on either client side or server side (with the option to disable client side tag management).\nSo instead of:\n1. client subscribes to public:news\n2. if client has access to gossips, he subscribes to gossips:news as well (with proper authentication)\nYou could do:\n1. client subscribes to news (and the subscription gets the default public tag)\n2. if client wants to read gossips as well, client tags the subscription with gossips\nOr:\n1. client subscribes to news (and the subscription gets the default public tag)\n2. backend tags the subscription with gossips tag (calling something like /tag?user=<USER ID>&channel=news)\nIt would solve my use case as well:\n1. client connects to channel, gets notifications  (and the subscription gets the default free tag)\n2. backend removes the free tag and adds the paying tag\nIt's not the same as subscribing the client from backend, but I think this could be easier to use than  using multiple subscription from the client to get public and access restricted messages of the same type.\nRegarding your case can be solved subscribing on two different channels...: it does not work if there can be more than 1 clients on the same paying channel (it's doable with user restricted channels but a bit more complecated). Also it's problematic for me to get the free messages as well while the user is in paying status (can be solved by filtering on frontend, but again, more complex).\nOf course all this is just a suggestion. If you like it, I can help with the implementation. If you don't, it will still be a great project :D. You are right, I didn't think about the issue of persisting tag information.\nI will try to clarify my circumstances:\n   1. We are developing a platform, and want to keep the usage of this platform as simple as possible. That means as simple frontend code as possible.\n   2. Change between paid and free status is not always initiated by client. It might come from a backend event (eg user runs out of money).\nThe 2. means the only viable workflow is the following:\n   1. client subscribes to a user restricted operation channel (so we can notify it to join/leave paid/free channels)\n   2. user joins free channel\n   3. when backend event needs to trigger subscription change, it send a message on operation channel (either sending the sign here that the client can use to join the paid channel, or instructing the client to request a sign and then join the channel)\n(This is very similar to your suggestions. ) \nIn order to keep this simple, everything more than a one time subscription to 1 or more channels is unexceptable.\nI can of course solve this issue by providing my own library that wraps the centrifuge js client and adds the above mentioned functionality, hiding these details from the users of our platform (and by users i mean frontend developers). \nSo to summarize:\n  - If backend side subscription works, but it requires extra effort from frontend developers, it's a no-go for me. \n  - If tags work, but it requires extra effort from frontend developers, it's a no-go for me.\n  - Temporary unsubscription (aka muting) could work (if there is no client side logic associated with it), but I now see it has the same issue as tags (the need to persist muted state)\nWith tags the following workflow could be implemented in the centrifuge server and client:\n1. backend sets tag via the server api (it's not an add/delete, backend must specify the new tags exactly) \n2. server notifies client to request a tag change, providing it with a sign to do so (a sign thats based on all newly active tags) \n3. client library updates tags seemlesly\n4. client library saves the new tag sign for the channel, so it can use it for reconnect\nCould even hide tags feature from client library, by sending client an updated subscription data + sign (with tag info that the client doesn't need to know about), which it used to upgrade it's existing subscription (and for later reconnect if needed).\nBut this complex client side logic might not be worth the feature. It's always a tough call to draw the line between features and simplicity :) \nOne more thing that popped into my mind during writing this: have you considered using JWT? It's a standardized solution that encapsulates data and it's signature, basically used for the same purpose as you use the signs for. . Yes, if it's a one time thing (eg: during site load on traditional websites, or opening a page in a single page application). What's not ok is handling the free/paid status change in the 3rd party code in any way. In other words: if the developer who uses our platform needs to write any code that reacts to the paid/free status change, that's not ok.\nI want to completly hide the fact from the platform's users that there is even a free/paid status. I want them to subscribe to one channel and keep processing the messages without caring about whether they are free or paid. If in the backend it's solved by 2 channels I don't care, I just want to hide this implementation detail completly. . I read the centrifuge js lib code, and had the exact same tought - using refresh to update the tags, and an option to force client refresh from server api. I don't think it's an issue to have user scoped tags instead of subscription tags - it's still possible to prefix the tag name with the channel name if needed. It might be a good idea though to make guest tags configurable (a static list of tags that apply to guests).\nIf you are looking at jwt, I suggest you check out go-jose instead. It implements all of jws, jwe and jwt (go-jwt only implements jws + jwt), even thought you will probably not need the jwe part. I also found it a bit easier to use. Here is an example of usage (parse+validate).\nWe use jwt in php, go and nodejs, so far the only difficulty we ran into is that some libraries accept the key in base64 format (eg: php), while others use it as-is (eg: go). It caused us some headache :) \n. I see your point about tags and refresh. Still, tags could be a private channel only feature.\nI decided I will use the centrifuge library in a new project, because I will need to change private channel subscriptions very often, and I think the short refresh interval I would need to do this with token style is more of a performance overhead than using backend webhooks from centrifuge server for authentication. I will try to include the minimal code to be able to support tags with the library, and create a pull request. But before that I need to dig in some more :). Only checked it in v2. Set history size to 1, published 3 events on the channel from admin interfance, then checked the history and there were two items in it. . ",
    "Sannis": "\nRegarding to CPU usage - Iooks like measuring this inside application itself is hacky, not accurate and not a convenient practice. This was done using ps because it was the simplest cross-platform way I found without using CGO at that moment. Also in today's container world CPU must be measured per-container from outside as there is no such info inside container. CPU usage stats will be removed in v2 (at least until someone knows how to do this right).\n\nThe problem with ps described in man:\n\nCPU usage is currently expressed as the percentage of time spent\nrunning during the entire lifetime of a process.  This is not ideal,\nand it does not conform to the standards that ps otherwise conforms\nto.  CPU usage is unlikely to add up to exactly 100%.\n\nSo actually I don't know how this metric can be used for real-time monitoring.\nThis is how ps aux cpu usage percent matches getrusage utime/stime derivative:\n\n\n\n. @FZambia thanks!\n\nI always tried to make Centrifugo production ready out of the box. @mkevac @Sannis so you think that porting rusage utime and stime to v2 makes sense right?\n\nThere is gopsutil package that provide such stats not only for *nix systems, if you need it.. @FZambia thanks!. ",
    "grachevko": "Our infrastructure build on Docker and Docker swarm, and we have 4 different usage of centrifugo: local, test, rc and prod. \nI built centrifugo docker image for solve this issue https://github.com/centrifugal/centrifugo-docker/issues/4, and wanted to use one point to configure some default options like port. But it's not a big problem, just not much convenient.\nIt will be great if we can use official centrifugo image for all cases out of the box without extending it.. @FZambia thanks. \nIn my opinion handle *_FILE on viper will more convenient than entypoint, because entrypoint will require to duplicate handled environments to sh script.. 1. I never see implementation like that\n2. What if not all secrets related to centrifugo and one of secrets will have collision with centrifugo envs?\n3. You restrict developer in naming of secret files.\nSo the way if <env> not found try check <env>_FILE and get from it more flexible.. Do not limit the flexibility of loading secrets from files only for Docker swarm needs.  . ",
    "bubooon": "@FZambia thx, so much! . ",
    "recoilme": "oh sorry, this issue for centrifuge library\nmust i reopen it here? https://github.com/centrifugal/centrifuge. ",
    "chebyrash": "Yep, those spelling errors are probably from a js library. @FZambia sorry, I deleted the wrong lines. I wanted to fix it like below\nGolint shows that code from e864024\ngo\nif err = addExtensionConventionForRollups(buf, mf, m); err != nil {\n        return err\n    }\nreturn nil\nCan be rewritten because if ...; err != nil check, just return error instead.\ngo\nreturn addExtensionConventionForRollups(buf, mf, m);\n. ",
    "nmorel": "I read the new documentation about recovery here : https://centrifugal.github.io/centrifugo/server/recover/\nThe away property should do the trick.\nI'll check if we can migrate to v2, thanks!. Thanks for your work!\nI will try v2 asap. ",
    "jonahfang": "I will try to read source code of Centrifugo andriod library and convert it to dart. But I am new to the dart-lang, and may fail in this process.\n. @mogol Thanks! I am looking forward to your implementation. . @mogol Thanks, I will test it soon.. ",
    "rampredd": "Thanks for quick response.\nNow I got it working with latest centrifugo linux tar.gz got from downloads page.\nNow I can run jwt example from centeifuge_go examples.\nThis example has connect and subscribe to channel. That is private.go file.\nI tried add publish to that subscription in private.go file.\nBut server is not permitted.\nPlease explain.. Am using centrifugo v2.0.0 and centrifuge,centrifuge-go and gocent libraries are checkedout from git.\nI did (go get centrifug****) to get these libraries.\nWith this version if I connect to server http client api like this\ncFugoApiCli = gocent.NewClient(\"http://localhost:8000\", \"secret\", 5*time.Second)\nBut it gives error:\nCFUGO PUBLISH ERROR:  :  wrong status code: 404 Not Found\ncentrifugo is run with following config\n{\n  \"secret\": \"secret\",\n  \"namespaces\": [\n    {\n      \"name\": \"chat\"\n    }\n  ],\n  \"pubish\": true,\n  \"anonymous\": true,\n  \"insecure\":true\n}\n. Thank you.\nPlease tell me any other version that can work gocent and also client side connection.\nI wanted to bring server API and client connect to same centrifugo server.\nPlease let me know the version that works from both sides.. Thank you. I will check. ",
    "aannuujj": "@FZambia Wow, end of this week will be perfect. I would be more than happy to report any issues and review the updated code as I work through using the client.\nIf by any chance you can make the changes by Friday or Saturday morning, I can set aside this weekend on to work on them and report back with any review . @FZambia Top effort. Thanks for the quick response on this. Will set aside time to work on this, this weekend and get back to you.. ",
    "Bedotech": "I've tried this configuration and with --client_insecure is working.. ",
    "applecat": "@FZambia, thank you for help! But for now the problem is solved itself in some way. I'll back to this if it appears again.. ",
    "vitoordaz": "@FZambia Thank you for updating docs.. ",
    "sj26": "This would be ace! Although I'd like to be playing with prometheus, we're still using cloudwatch and datadog.\n\nStats mechanism requires synchronization of stats between all running nodes so it's possible to ask full stats from any node. It worked before - so should work now too.\n\nNot neccessarily \u2014\u00a0as long as the hostname or something was included in a dimension then cloudwatch will aggregate them correctly if each node self-reports.. Imho, a fixed \"200 OK\" response would be sufficient. It should exercise that the application is available to service requests. Generally health checks should not check upstream services (i.e. redis).. That's true, Kubernetes has two different probes which differentiate \"this service is alive\" versus \"this service is healthy and all upstreams are okay\"\nhttps://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/. Thanks!. That's wonderful, thank you!\nIt would be great to be able to configure ports and tls through env as well.. \ud83d\ude47 . > Do you mean generating certificate in runtime on process start? I.e. the only reason is not to provide key and cert files on disk?\nYes!\n\nIs using separate files is impossible in your environment?\n\nNo, but\u00a0\u2014\u00a0using the official Docker image on Fargate \u2014 I would have to generate some in an entrypoint, or create a layer that does so, or something. For the moment I'm creating my own centrifugo docker image based on ubuntu and installing ssl-cert which generates a \"snakeoil\" self-signed cert at /etc/ssl/private/ssl-cert-snakeoil.key and /etc/ssl/certs/ssl-cert-snakeoil.pem. But these are created at docker build time and shared amongst all instances.\nInstead, I'd ideally like --tls without --tls_key/--tls_cert to generate a self-signed keypair to use for HTTPS.\n\nAlso you will need to turn off verification on client side in this case right? So I suppose you won't use this in browser?\n\nAbsolutely. But in our case the browsers are connected to a load balancer with verified certs, then the load balancer connects to centrifugo running in containers. I'd like that backhaul connection to be https, not plain text. But verification isn't important, it's just about securing the transport layer.. No, looking around I can't find a good example of this. Perhaps everybody uses sidecar containers to translate https, or fancy service meshes, or finds ways to inject certificate files into pre-built containers. \ud83e\udd37\u200d\u2642\ufe0f. ",
    "chamaeleon-nitr": "Thank's. This is important information for all backend libraries such as phpcent, php-centrifugo. Because, also, these libraries generate a JWT-token for centrifugo-js. \n\nyou need to have different values in secret and API key, those are a separate options.\n\nSo we need to specify both options for them. For example,\n$centrifugo = new Centrifugo('http://example.com/api/', 'secret', 'api key', new HttpClient());\nIs that what it's supposed to be?. I'm catching on. I mean, now the backend needs to know both the \"secret key\" and \"api key\".\nWhich confused me, because it might actually be one of the \"secret\" or \"api_key\" options. Or separated for security purposes?\nI was just trying to adapt php* to v2, but to make as few changes to the \"main code\" as possible. \nAll v1 libraries genereted SignToken for the frontend, for example:\n\nYou can use phpcent to create frontend token:\n$token = $client->setSecret($pSecret)->generateClientToken($user, $timestamp);\n\nAnd now, the backend must know the \"secret\" options to generate a JWT-token and \"api key\" to use HTTP API.\nI may have misunderstood, but \"centrifuge-js\" (frontend) requires a JWT-token, that needs a \" secret\" key. Brrr... :). ",
    "hetao29": "Thanks very much , I guess may be the reason is both v1.8 and v2.1 use the same redis config.\nI change v2.1's redis config to the another , the errro disappeared.. Sorry, I cant find the redis_prefix description in the document.. Thanks very much!. Error: unknown flag: --redis_prefix\n~~~. Ok, I got, Thanks.. ",
    "thanhps42": "Thanks. ",
    "cpanato": "thanks, sounds great. please let me know if need help or where can i help :). thanks, I've updated the helm charts to use that. ",
    "Gadgetroch": "Add this permit to have web interface for write in chat ?. ",
    "igorljubuncic": "It's only reasonable that you don't change your integration flows. So goreleaser sounds like a better solution, and I believe the dev will include additional options so that everything works smoothly. You can test with manual integration for the time being.\nProduction servers:\nIf you have the snapd service installed (default in ubuntu), then you can install snaps. The big advantages are granular isolation and automatic updates. Isolation means that your snaps will run even if there are problems in libraries in the system and vice versa, if you introduce a problem other applications won't be affected.\nFor example, say your app dynamically links /lib64/foo.so and this is provided by a different package called baz.deb. If there's a bug in this library, centrifugo will be affected even if you yourself made no change to your code.\nWith snaps, you ship foo.so inside the snap filesystem (maybe even a newer or a different version from the system one), so you don't depend on the system changes. Then, automatic updates mean your entire user base gets updates roughly at the same time, so you have fewer leftovers and old versions lingering about.\nThen, interfaces - snaps can be confined, so they can't access resources, like x11, audio, home, etc. You can give control to these resources on individual basis, make your snap access home and network but not be able to access camera or bluetooth, etc. This gives you the ability to make for a very tight and controlled app footprint.\nHopefully, I made sense.. ",
    "zigmund": "As workaround if you need to set exact same service name - overwrite env var in deployment:\nyaml\n      - env:\n        - name: CENTRIFUGO_PORT\n          value: \"\". @FZambia sure we can rename service or set flag. So it's not critical issue or not an issue at all, just a rare case. :)\nJust for history if someone else will catch this. Thanks.. ",
    "KakarN": "Hi @FZambia ! Thank you for your insight. \nI have not quite grasped the concept of # of Centrifugo's channel design, but I will certainly look into it more.\nIt would be great if you could help me clear some of my doubts:\n\nWhen sending (publishing) messages from the server API, is it in a non block fashion? \nBecause if not, suppose a group has 5000 members\nPublishing a single msg to 5000 private channels of each user of a single group.\nWont the process of the sender's request will block until the message is published to all of the individual use's channel. Or should I be using something like to Celery.\nA very simple example using python (Cent and Django): \n\n\n\ndata = request.data\nmembers = thread.members.all()\nfor member in members:\n    channel = member.private_channel\n    client.publish(channel, data) # without celery\n    celery_function_to_publish.delay(channel, data) # with celery\n2. And yes, you are absolutely right, that messages are not created in a very high rate. As you mentioned that \n\nCentrifugo can process 1000 messages pretty quickly (look at broadcast API method).\n\nI was not familiar with the broadcast command, but now looking at the broadcast command, it seems the right choice for the job! I can pass all the user's private single channel to the channels list in the broadcast command. However, could you please tell me whether the performance will be improved by using the broadcast command as opposed to looping (for loop) through all the channels as described in the above example?\n\n\nCan you please tell how do you go about load testing the Centrifugo server's connection, because there are many authentication mechanisms to handle before actually connecting to the Centrifugo server?. @FZambia Thank you so much! Your insights were really very helpful! And I will be sure to share my results with you.. @FZambia So, I have set up the required architecture, on the client and backend server. However, I have stumbled across some issues:\n\n\nIs there any way to know in the backend server (Django) when the client is connected?\n\nI need this so that I can send the remaining messages (message sent by other users on the thread when the user was offline) to the client when the client is online, and also to set the user active status to true in the database.\nTo solve this I can make a request on the backend server, to get the remaining messages on the client, and set the active status to true.\nIn Django-channels, it was possible to send data back after the connection is established, without any request from the client. It would be great to know that we can do this with Centrifugo too.\n\n\n\nSimilar to connection event, after the user disconnects, is there any way to know in the backend server (Django) that the user has unsubscribed or disconnected?\n\nI need this to update the user active status to false, and also to update last seen feature. So that other users may know that the user is offline, and if the user is offline show the datetime when the user was active.\nI cannot think of any better way to solve this problem. The only solution I can think is making a ping request by the backend server on the client. But I am not familiar with how to start with this.\nIt would be great to know that this is possible using Centrifugo out of the box.\n\n\n\nBoth, the online and offline matter is stated in the highlights of Centrifugo readme, but I guess this highlight is only related to the client side.\nYour insights on this matter would be great!. Yes, you have a point. \nI think for the last seen feature, there's no best option than to solve this issue on the client side, by making a ping request every 5 or maybe 30 seconds in the backend server. \nFor the user's active status, could you tell me if the presence method will suffice to know if the user is online? Since, every user will have its own private channel (e.g.: $user-8), and the user will subscribed to that channel on the client side. So using cent library, if len(client.presence(\"$user-8\")) is greater than 0, means the user is online, else the user is offline. \nAlthough even if the presence method will work on first request, suppose userA and userB is chatting, and after some time userB is offline, I think there is no way to inform userA, that userB is offline. The only solution again would be if userA ask the server every x seconds whether userB is online or not.. Please consider this scenario:\n\nuserA opens the app, and is connected (authenticated and subscribed to its private channel) to the Centrifugo server.\nuserA selects a user (userB). \nAnd it is navigated to the next screen, which is the thread (messages) between userA and userB.\nSince, userB is offline, so the last seen will be displayed on the user-detail on the top header of userA.\nLater, userB opens the app. (Here, userB does not select userA, but may open a different thread or is doing nothing.)\nBack on the userA's app, which is still on the thread between userA and userB screen, the server notifies, that the userB is online.\nAfter a while, userB closes the app. \nBack, on userA's app, which is still on the thread (messages) between userA and userB screen, the server notifies, that userB is offline, and the last seen is displayed again.\n\nAs you have told me, I also think join/leave events are the best approach for this case. But I am not sure how to emit the join/leave events to both the clients (userA and userB), since each user is only subscribed to its own private channel (eq. userA is subscribed to channel $user-A, and userB is subscribed to $user-B)? Could you please elaborate if possible how can I utilize the join/leave events to both the user?. Okay! I will try to solve the issue. Thank you for your helpful insights!. ",
    "Raerten": "what are the pros and cons using NATS?\nIs NATS a dedicated service? Redis itself is widely spread and likely already used in projects, so NATS can complicate infrastructure.. "
}