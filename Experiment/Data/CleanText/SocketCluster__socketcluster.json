{
    "jondubois": "That's a good idea. Note that the json/ module that's in there is not a standard npm module - It removes cyclical references from JSON (to avoid potential errors) that's why I left it there... I guess we could use a library like https://www.npmjs.org/package/cycle instead to do the decyling and just use the native JavaScript JSON to stringify/parse.\n. EDITED Nov 2014.\nYou can achieve horizontal scalability (across multiple remote machines) using a distributed message queue like RabbitMQ (the code would go inside your storeController file). SocketCluster handles the vertical aspect automatically but doesn't prevent you from scaling horizontally. I'm hoping that the kind of vertical scalability that SocketCluster offers would allow companies to have single large servers to handle the users of an entire state or country (based on geolocation for example).\nSocketCluster was designed in response to trends in microprocessor design - CPU makers are increasingly focusing on adding more cores as opposed to getting more raw speed our of each core. Hopefully as CPUs get more cores, SocketCluster will help make a scale-up-and-out hybrid strategy more appealing.\n. I never cared much for the tabs vs spaces debate but it does look like most similar projects on GitHub are using double spaces so I'm OK with that change if you feel passionate enough about it :)\nI'll have to test it before I merge (hopefully later today).\nAlso, that means we'll have to make the change for SocketCluster's related submodules.\nThe ones which are close enough to warrant that consistency are:\n- https://github.com/topcloud/socketcluster-client\n- https://github.com/topcloud/socketcluster-server\nThere's also:\n- https://github.com/topcloud/loadbalancer\n- https://github.com/topcloud/iocluster\n- https://github.com/topcloud/ndata\n  But the coupling with these ones is looser so it's not as urgent.\nRegarding JSLint, I find it to be a little too opinionated. For example, I've used double equals == throughout the code. From memory JSLint doesn't like it and wants us to use ===. Unfortunately, it's not a straight forward conversion.\nI think == are OK but you should know when they are safe to use and when they're not.\n. It definitely sounds like a good idea - So long as JSLint doesn't force us to make a lot of quick-fix logic changes to the code (with hard to predict consequences) then I'm happy with that.\n. This is a security feature of SocketCluster designed to prevent malicious clients from hogging up unlimited connections (and DOS-ing your server).\nIf you want to get rid of the limit, set the addressSocketLimit start option to 0.\nI.e:\nnew SocketCluster({\n...,\naddressSocketLimit: 0\n}).\nIt's probably best to have a limit set when running your server in production though. This is a gotcha of using the stateful WebSocket protocol.\nIf you have a good firewall (that handles WebSockets properly) or you've written some protective code in your balancerController file then it might be safe to set addressSocketLimit to 0. The addressSocketLimit option is just SocketCluster's default way of handling the problem.\n. Yes, a single session will be shared between all open tabs in a browser.\nYou can still emit events to individual sockets by using:\njs\nsocket.emit('myevent', eventData, callback);\ninstead of 'socket.session.emit(...)'\nRegarding your issue with separating clients into different rooms - You can do that really easily:\nFor example, assume you have separate chat rooms: 'roomA', 'roomB', 'roomC'...\nTo allow a client socket to receive all events from roomA, all you have to do is call:\njs\nsocket.on('roomA', function (event) {\n  console.log('Received message: \"' + event.message + '\" from user \"' + event.user + '\"');\n});\nSocketCluster will automatically subscribe that client to the 'roomA' channel on the backend.\nIf you want another client to send a message to that channel, you just need to call:\njs\nsocket.emit('roomA', {user: 'username2', message: 'Hello people in roomA!'});\nAny client socket which is listening to the 'roomA' event will receive that message.\nUnlike Socket.io, SocketCluster only sends particular events to clients that are actually listening to them - No waste - Events on the frontend are represented as pub/sub channels on the backend - This allows events to be treated like pub/sub channels in the browser.\nYou could make 'roomA' private by adding an event middleware function on the backend to handle auth (the code should go inside your workerController worker.js by default):\njs\nwsServer.addMiddleware(wsServer.MIDDLEWARE_EVENT, function (socket, event, data, next) {\n  if (event == 'subscribe') {\n    var channelName = data; // channelName could be 'roomA', for example\n    // Check if channelName is in the session's allowedchannels list\n    socket.session.get(['allowedchannels', channelName], function (err, hasChannelToken) {\n      if (hasChannelToken) {\n        // If so, let SC handle the event\n        next();\n      } else {\n        // Otherwise block the subscription by passing back an error\n        next(new Error('Session ' + socket.session.id + ' is not allowed to listen to ' + channelName + ' channel'));\n      }\n    });\n  } else {\n    next();\n  }\n});\nAs you can see from the code above, when a client socket registers to an event using socket.on(event, listener), a 'subscribe' event will be automatically sent to the server. This subscribe event passes through the event middleware which can choose to block it if the user is not authorized.\nI hope that answers some of your questions or at least gives you some ideas of what you can do. Please let me know if you have other questions.\n. Also, if you want users to send events to each other in a targeted way, one thing you can do is make each user listen for an event that has their username in it:\nBrowser code:\njs\nsocket.on('events-username123', function (data) {\n  if (data.action == 'invite') {\n    console.log('Another user \"' + data.fromUser + '\" has invited you to room \"' + data.room + '\"');\n    // ...\n  }\n});\nThe room invitation could look like this:\njs\n// Here we assume that we know the username of the user that we want to invite to our chat room\n// fromUser should be the username of the current user\nsocket.emit('events-username123', {action: 'invite', fromUser: 'username999', room: 'aprivateroom'});\nThere are many ways to do this though, this is just off the top of my head.\nEDIT\nWhen you emit an event on a client socket, that event is only emitted locally on that session on the server side. So to complete the example above (in order to relay the event globally to all subscribed clients), you would have to add this code on the server:\njs\nsocket.session.on('events-username123', function (eventData) {\n  socket.global.publish('events-username123', eventData);\n})\n. That's right, you don't need to store all socket/user IDs in a global database to allow them to communicate with one another - In fact, that would be a huge hassle to manage. SocketCluster is built around the Publish/Subscribe pattern ( http://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern ). Most pub/sub systems (such as Redis) work only on the server-side - SocketCluster's pub/sub extends all the way to the browser.\nWhat that means is that when you call this on the server:\njs\nwsServer.global.publish('foo', 'This is a message');\nThe event will only be sent to sockets which are actually subscribed/listening to the 'foo' event. You can use the event middleware (as shown in previous post) to allow only authorized clients to subscribe to particular events - So others will NOT get that event.\nEvent channels get distributed evenly between your store processes. An event channel is assigned to a particular store based on its name (hash). So if you had 10000 clients emitting and listening to the exact same channel, then yes, that could overload one of your stores.\nIf you needed to have a large room with 100000 users, then you could have multiple versions of the same event: 'foo1', 'foo2', 'foo3'... Giving them different names will assign them to different stores (spreading the load). Then on the backend you could make them share all events with one another.\nIf you need to use a global store. you can use:\njs\nwsServer.global\nThe global object is a clustered nData client which means that you can use any of the nData client methods: https://github.com/TopCloud/ndata\n. The storeController can be used for achieving horizontal scalability (sharing data/events between multiple remote SocketCluster instances).\nIt basically lets you interact with the nData store directly (without going through the client).\nNote that the store is responsible for both data and events in SocketCluster.\nYou can see the store object's methods here (line 110): https://github.com/TopCloud/ndata/blob/cb19fc8b56e038c817f33150544160491a332c19/server.js\nIt also emits some useful events:\n'subscribe': Which gets triggered when a socket subscribes to an event on the store.\n'unsubscribe': When a socket unsubscribes from an event.\n'publish': Whenever a socket publishes an even to this store.\nNote that the data format of the store is different from what you would deal with in SocketCluster - Because here we are in fact dealing with a raw nData store object and so you get access to all the low-level metadata and structures used by SocketCluster.\nYou can use store.getAll() during testing to see all the data - This should give you an insight into how SC uses nData to store its session and global data.\nIf you want to synchronize nData with other stores/databases, you can use the get, set, add, etc... methods to directly modify the data however you like, but try to understand the structure used by SocketCluster to make sure that everything goes in the right place!\n. A single socket can handle different types of data so it might be best to use a single one if possible - It's more efficient - You can use different event naming conventions to signify what kind of data the event is carrying. SocketCluster does not have explicit namespaces - You should decide on an event-naming convention to use within your system to represent namespaces.\nFor example, if your system supports two kinds of events; \"important\" and \"unimportant\" messages, you could name important messages using this convention; \"important.myeventname\" and other messages could have the format; \"unimportant.myeventname\" - Here we are using a dot as the delimiter for the namespace. This is just an example; you can separate events into any categories and you do not have to use dots as delimiters if you do not want.\nThere are no restrictions as to how you create namespaces. SC lets you setup your own conventions.\n. Then you can name all binary events in the format \"binary.someeventname\".\nYou can pass an ArrayBuffer as the data argument when emitting the event - Or you can even mix binary data with textual data:\njs\nsocket.emit(\"binary.foo\", {\n  message: \"This message conains some binary data\",\n  binary: myArrayBuffer\n});\nYou can also publish binary data in the same way using (here we are sending only the binary buffer):\njs\nsocket.publish(\"binary.foo\", myArrayBuffer);\nWhen you emit binary data (on its own or inside an object as shown above), SC will convert all ArryBuffers to Base64 objects:\njs\n{\n  base64: true,\n  data: \"keJr7z9=\"\n}\nThis is done because Base64 is more flexible (easier to work with) and is compatible with more database engines than raw binary and it makes it easier to handle mixed objects as shown above.\nIf you want to get a Node.js Buffer on the server side, you can do this easily in Node.js:\njs\nvar buff = new Buffer(myBase64String, \"base64\");\nIf you really want to use raw binary for efficiency reasons, you can do this using:\njs\nsocket.send(myArrayBuffer);\nand listening to the \"raw\" event on the server side:\njs\nsocket.on(\"raw\", function (data) {\n// data is a raw Buffer object\n});\n. @joinfok I have written 5 new 'developer guides' which will be published sometime near the end of this month on http://socketcluster.io so hopefully this will fill all the gaps in documentation. It's a bit tricky to cram all this information on a single GitHub page. I have also put together a FAQs page which will also go up at around the same time.\nsocket.emit() lets a client socket send events (and data) to a server socket; and vice versa.\nSo: \n1 client socket => 1 server socket\njs\n// In browser\nsocket.emit('foo', 123)\nOR\n1 server socket => 1 client socket\njs\n// On server\nsocket.emit('foo', 123)\nsocket.send is like emit (between 1 client and 1 server socket) but it just sends raw data (not events) so it's difficult to manage (you need to come up with your own protocol) - You shouldn't have to use this method unless you really need top efficiency and you know what you're doing. You can catch raw data by listening to the 'raw' event on the client or server socket:\njs\nsocket.on('raw', function (data) {\n  // ...\n});\nsocket.publish lets you share data with multiple (n) client sockets (whoever is listening to that event)\nSo:\n1 client socket => n client sockets\njs\n// In browser\nsocket.publish('foo', 123);\nOR you can publish from the server using the Global object:\nGlobal => n client sockets\njs\n// On the server\nscServer.global.publish('foo', 123);\n. Did you update the socketcluster-client as well?\n. I tried serving my HTML page from a different port as socketcluster but it worked fine - I didn't get this error. Also, when updating, make sure you run 'npm cache clean' just in case.\n. Yes SC supports pub/sub channels which you can use as rooms. There're a bit different from Socket.io rooms but you should be able to achieve the same result.\nI wrote a blog article about it recently, it should give you a lot of the information you need: http://ncombo.wordpress.com/2014/08/22/full-stack-pubsub-with-socketcluster/\nIn SC, events are treated like pub/sub channels - So when you call socket.publish(event, data) (in the browser) or wsServer.global.publish(event, data) (on the server) - Only client sockets which are listening to that event will be notified. Effectively, the event itself is a pub/sub channel.\nUsers could even use their username as an event (which only they will be allowed to listen to - See section on middleware in blog post for sub/sub authorization) - You would just go: \njs\nsocket.on('user123', function (data) {\n    // ...\n});\nThen any user who wants to send a message to user123 would just have to go:\njs\nsocket.publish('user123', {from: 'user456', message: 'Hi!'});\nAgain, you could use the publish middleware to make sure that only authorized users can publish the 'user123' event.\n. Also, if you get to that stage, SC lets you scale horizontally across multiple machines. You can specify a storeController file which you can use to hook multiple remote SC servers together. (You can hook your host pub/sub channels to remote message queues like RabbitMQ or a third-party service).\nSo you can easily scale without limits.\n. Regarding your first question - You don't have to do anything. The socketcluster-client will automatically resubscribe to the appropriate channels when it reconnects (also automatic).\nYou should see the (re)subscribe requests go through the MIDDLEWARE_SUBSCRIBE middleware when the client reconnects.\nRegarding the cookie - Yes, you are right, that is definitely important!\nI looked at your code. You should change this line (285):\njs\nvar cookie = headers.cookie || req.headers.cookie || {};\nto:\njs\nvar cookie = headers.cookie || {};\n^ Remove duplicate logic - headers.cookie and req.headers.cookie will always be the same (see line 267)\nIf you make that change and do a pull request, I will accept it and make a quick release :)\n. I accepted your changes. I made a few code style changes afterwards (for consistency). Also, I added an extra check in case a malicious user tries to pass an invalid cookie string. E.g. 'a=;b=;'.\n. Nice find! This is not the right place for the fix though. It should go in the master process (index.js) - The master process already does some sanitization of keys/certs (lines 170 to 190) but obviously the pfx option wasn't sanitized correctly. Having it in the load balancer as a synchronous (blocking) operation could cause issues if you have multiple load balancers.\nThe self.options.protocolOptions object in index.js (master) gets passed to the loadbalancer - So if you make changes to it, these will affect the loadbalancer, worker and store processes.\nGetting passwords from the command line (for encrypted certs/keys) can be tricky with SC - It should be all done on the master process (or at least throw an error so the user can try to provide it in an alternative format) - The master process handles all bootstrapping and configuration tasks - Otherwise you will get strange behaviours like getting prompted multiple times for the same password (depending on how many processes you have).\n. What other errors did you encounter? Did you try to supply a private key and public cert instead?\n. Ok, this has been fixed in version 0.9.72. Your observation about the buffer not getting passed properly to the balancer was correct. I put your username in the release title to acknowledge your contribution https://github.com/TopCloud/socketcluster/releases/tag/0.9.72\nIf you find any other issues, don't hesitate to report them. Pull requests are welcome too if you can find the time :)\nRegarding your upcoming work - It sounds interesting and I would be happy to offer advice if you need any.\nJust one piece of advice for now; when doing benchmarks make sure you set the addressSocketLimit option to 0 (unlimited) - This option is a security feature to prevent malicious clients from hogging up too many connections (which could cause DoS by hogging up all your memory).\n. Not right now.\nBut we should definitely try to get SC to work with as many frameworks as possible.\nThe problem is that SC sits just below the framework layer so it needs access to the raw Node.js http server.\nIt might be worthwhile to try to convince the maintainers of some of these frameworks (like Hapi) to tweak their code to optionally accept an existing http server object instead of a port as argument. It should be fairly easy for them to do that in most cases.\nConsidering this line in of Hapi:\nhttps://github.com/hapijs/hapi/blob/master/lib/server.js#L229\nIf the first argument was a server object, it might just be a simple case of running:\njs\nthis.listener = server;\nthis.listener.on('request', this._dispatch());\nInstead of creating a new server from scratch.\nAnother solution might be possible; there might also be a way to allow SC to use an existing server object - Exposed by the framework (or maybe some kind of generic server-adaptor/wrapper) instead of creating its own - I will have to think about this - But if you have suggestions, I would be happy to hear them.\n. I did more research - Unfortunately, it seems that there is not much we can do on the SC side of things to allow Hapi to run on top of SC. The problem is that Hapi is tightly bound to the http server object (it creates and manages the server internally).\nSC-compatible alternatives that you could use right now include KrakenJS (https://github.com/krakenjs/kraken-js) or Koa (https://github.com/koajs/koa).\n. I thought a bit more about this. Making SC use an existing server is tricky because SC has to be able to set the SocketPath on which that server should be bound (using the server.listen() method). Hapi already invokes the server.listen method on a port, so we will have to override that listen call if possible.\n. Note that if you use newer versions of SC you can now use any framework so long as it exposes an HTTP server object (or one that has a compatible API and events).\nSC uses the Node.js HTTP or HTTPS module internally by default but you can provide a custom HTTP/HTTPS server module. Search for httpServerModule option here: https://socketcluster.io/#!/docs/api-socketcluster\nYou need to make sure that your module exports a createServer(protocolOptions) function which returns a Node.js-compatible HTTP(S) server. At the very least, this server needs to support the following events:\n\n'request'\n'upgrade'\n'error' (Make sure your custom server emits errors when it fails)\n\nAlso your custom HTTP(S) server needs to expose the following methods:\n\nlisten(sourcePort, [host, tcpSynBacklog])\nclose([callback]). Yes, you can do handshake authentication or you can also authenticate events individually. You should read the section on Authentication on the main GitHub page for details.\n\nBinary transport should be supported but an ArrayBuffer sent from the client should arrive as a base64 string on the server and a Buffer sent from the server should arrive as a base64 string on the client. This is partly because a lot of browsers still don't support ArrayBuffer and I felt that it's better to have a consistent interface than have to do browser checking.\nEDIT Actually, ideally, they should arrive as a Buffer on the server.\nIt sounds like you might have found a bug because you definitely shouldn't be getting an empty response. I will check this later today.\n. Yes, MIDDLEWARE_HANDSHAKE runs before the connection event (the callback receives a HTTP req object not a socket).\nAll socket objects have the session object attached to them, this should also be true for every HTTP requests (I.E. req.session) - But it appears to not be the case - This is a pretty urgent issue - I should be able to have this fixed by tomorrow.\nTo clarify things: To do handshake auth, you would have to authenticate the user over HTTP first and then you would check the session within MIDDLEWARE_HANDSHAKE (using req.session). - It's basically useful for preventing someone from establishing a persistent connection with the server (It's more for efficiency purposes - You still need to use EMIT, PUBLISH and SUBSCRIBE middleware for more control - See link at bottom).\nSo basically until I fix this bug, you can't effectively prevent sockets from establishing a connection (because you don't have access to the req.session object which you need to set auth tokens).\nOnce the connection is established though, you can still block connected sockets from listening, emitting and publishing certain events. I will have to update the documentation on this, but in the meantime, you should look at this blog post I wrote a while ago:\nhttp://ncombo.wordpress.com/2014/08/22/full-stack-pubsub-with-socketcluster/\n. I fixed the first issue with the req.session being undefined. With the latest SC version on npm, you should be able to store/manipulate session data through HTTP requests before the realtime connection is established.\nThe ArrayBuffer issue is the next priority. You should expect a fix within the next few days.\nRight now, you can send buffers to the backend by running this on the client: \njs\nsocket.send(buffer);\nand you will receive it as a 'raw' event on the server: \njs\nsocket.on('raw', function (data) {\n    console.log('RAW DATA:', data);\n});\nNote that whenever you call send() on the client, you will receive the data from a 'raw' event on the server (you can send raw strings too). Unfortunately, this isn't always ideal since we are just sending raw data - It would be nice to be able to emit the buffer as part of an event and within an object like this:\njs\nsocket.emit('someevent', {\n    message: 'This message contains a buffer',\n    buffer: ArrayBuffer\n});\nThat will be my focus in the next few days.\n. Ok, the bug with not receiving ArrayBuffer has been fixed.\nBinary is now supported but note that when emitted as part of an event, ArrayBuffers will be converted to base64 objects of this form:\njs\n{\n  base64: true,\n  data: \"YWFhYWFhYWFhYQ==\"\n}\nThis is different (and slightly less efficient) than Socket.io where binary buffers gets passed raw as 'attachments' along with the event data. There are two reasons why the cast-to-base64 approach was chosen:\n1. You get a consistent object (containing the base64 string) regardless of browser (whether or not it supports ArrayLists or Blobs or neither).\n2. It's much simpler to handle base64 strings on the backend especially when it comes to scalability. Raw binary attachments would add a level of complexity - Developers will have to figure out how to transfer this mixed binary/string data across multiple remote machines - It would require a new protocol. Also, having it as base64 makes it compatible with more database engines.\nI'm not opposed to moving to using raw binary attachments in the future, I just feel that the added complexity is not worth the performance advantage right now (at least until browser and NoSQL support for binary types improves). It mostly depends on consensus and common use cases so I will keep an eye on this.\n. Stores are mostly used internally by SC - You generally don't need to think about these very much (unless you decide to scale your system horizontally across multiple machines). SC uses stores to allow sharing events between client sockets which are bound to different workers.\nWhen you run:\njs\nscServer.global.publish('foo', 'This is some data');\nSC is using a store process in the background to efficiently distribute the event to all subscribed workers which in turn will distribute the event to all subscribed client sockets (subscribed to the 'foo' event in the case above). If you have multiple stores, the publish event will be mapped to only one of the stores based on the event name.\nWhen you call:\njs\nsocket.session.set('someKey', 'some value');\nSC keeps that data in a store under the current socket's session key - That way when a session gets destroyed, that session's data will be destroyed along with it.\nYou can also save global data in the store using:\njs\nscServer.global.set('someKey', 'some value');\nThat data doesn't automatically get cleaned up so you will need to be careful.\nBy default, a store process is basically just an nData server: https://github.com/topcloud/ndata\nThe socket.session and scServer.global objects are essentially nData clients - You can call any of the nData methods on them to manipulate their internal state.\nThe big advantage of having stores as separate processes from workers is that pub/sub channel subscriptions, session data and global data will not be lost if your worker crashes - This makes worker crashes invisible to users. This is a key principle of 'Crash only software'.\nSC also exposes the raw store object through the storeController file (see the store.js file which comes with the sample SC app). You generally don't need to access the raw store object unless you:\n- Want to hook SC's pub/sub system with another external pub/sub system or message queue\n- Want to add your own backup mechanism for persisting session data\n- Want to synchronize store data with an external engine like Redis\n(I will try to write more on the specifics later)\nSC is designed so that you can use a custom store engine (but there is no documentation yet on how to do this and it's tricky). The default one is called iocluster (just a cluster of nData servers). I'm hoping that we'll be able to add a Redis module in the future so you could use Redis directly - Once this happens, you will be able to use socket.session and scServer.global as if they were Redis clients.\nRegarding your second question, you might want to read this post:\nhttp://ncombo.wordpress.com/2014/08/22/full-stack-pubsub-with-socketcluster/\nThe optimal ratio of balancers:workers:stores depends on your app's specific workloads. If you're using HTTPS, then you might need more balancers (because balancers handle the encryption/decryption). If you have a lot of events happening then you might need more stores. If you do a lot of processing in your workers, then you will need more workers. If you were to use SC as a plain HTTP server (no realtime stuff and no session data storage), then 1 store process will be more than enough. It's more of an art than a science.\nThe most important thing to consider is that the sum of all your balancers + workers + stores should be about the same as your CPU core count. If you spawn too many processes, you will waste performance because of context switching. Also, note that the operating system you use could affect how well the load is distributed between processes - You will have to test to find out.\nIt will be nice to automate the process type distribution in the future, but that feature probably won't be there for a while.\nLet me know if you have any other questions or if you encounter any issues.\n. To answer your question directly. You can publish events from three places:\n- A worker (workerController file) - E.g. wsServer.global.publish('foo', 123)\n- The client (a browser) - E.g. socket.publish('foo', 123)\n- The store (storeController file) - E.g. store.publish('foo', 123)\nJust to make sure we are on the same page. Here's an overview:\nSC is made up of four different kinds of processes:\n- The master process\n- Load balancers\n- Workers\n- Stores\nMaster:\nThe master process is were everything gets initialized - You shouldn't put much code in there. It's a good place to spawn daemon processes and perform various build/config steps which your app needs before it gets launched.\nLoad balancers:\nLoad balancers are responsible for distributing traffic evenly between your workers, the are also responsible for encrypting/decrypting requests/messages if you are running over HTTPS.\nLoad balancer instances get boostrapped in the balancerController file if specified.\nWorkers:\nAll worker processes are bootstrapped in the workerController file (you get a reference to the worker object as argument) - It is the entry point for all your request-handling logic - Pretty much all of your backend code should be linked from this file.\nStores:\nStores are responsible for keeping track of realtime connections and efficiently sharing pub/sub events between workers. If you have multiple SC servers running on different machines (scale-out approach), you can hook them up together by sharing their pub/sub events with each other. Stores are bootstrapped in the storeController file. Usually you only need to touch this file when you are ready to scale-out - It is a bit more advanced and requires a good understanding of SC's architecture in order to use properly. The run() function of the storeController file receives a store instance as first argument - You can use the store instance to listen to incoming 'subscribe' or 'publish' events (coming from workers) and to publish events directly to it (to automatically share between all subscribed workers and their subscribed clients).\nEach process gets 'bootstrapped' through a controller file (as you can see from above, you can specify a controller file for each kind of process). Controller files allow you to set up middleware and initialize your logic for each process type.\n. Also note that with version 0.9.80 of SC, you can communicate to individual worker processes from the master process. To get a reference to a worker process when it spawns (in master process >> server.js), you can use:\njs\nsocketCluster.on('worker', function (worker) {\n  console.log('Worker ID:', worker.id);\n  worker.send('This is a message');\n});\nThen inside the workerController, you can use:\njs\nprocess.on('message', function (m) {\n  console.log('Message:', m);\n});\nYou can send messages to specific workers, for example, based on the worker's ID.\nNote that if the worker dies, it will be replaced by another worker with the same id.\n. SC workers are behind a local load balancer layer (proxies) so you want to get the originating IP address (not the address of the proxy):\njs\nsocket.request.headers['x-forwarded-for']\nIn a simple setup, this will give you the plain IP address of the client. If you have a large distributed setup with multiple hosts and multiple levels of load balancers, then the value of this header could be a string with multiple IP addresses (do a search for the x-forwarded-for header - The format has been somewhat standardized - Basically you could have multiple values separated by commas depending on how many proxies the request had to go through).\nUsing socket.request.connection.remoteAddress in a standard Node.js server can be dangerous if you put your app behind a proxy so it's best to avoid - Although it is really widely used in the Node.js community.\nThe reason why socket.request.connection.remoteAddress is undefined is because SC uses UNIX sockets (or named pipes in Windows) instead of TCP sockets between balancers and workers for efficiency reasons so the load balancers do not have an IP address from the worker's point of view.\nI will add an easier way to access the user's source IP in the near future (maybe directly from the socket).\n. Ok, as of version 0.9.81 - You can access the client's IP address from:\njs\nsocket.clientAddress\nor\njs\nreq.clientAddress\nThis will always report the client's correct IP address regardless of how many proxies are in front of your host.\n. I also got rid of the 'socket hang up' errors completely in v0.9.81. I looked into it and came to the conclusion that it really shouldn't be an exception at all - By definition, exceptions should only be raised as a result of unexpected behavior - Basically when the browser aborts a request, it causes the node-http-proxy to also abort the request, but for some reason, Node.js decides that it should throw an error at that point (even though the abort() was fully intended in this case and carries no side effects at all).\n. @zalmoxisus To get the IP of the machine on the other side of the connection, you have to use the socket.remoteAddress property. Note that if you are running the SC server behind a proxy, the remoteAddress will point to the IP address of your proxy (and not the end-client).\nIf you're running behind a proxy, you won't be able to see the end-client's IP directly and so you have no choice but to read their address from socket.request.headers['x-forwarded-for'] - It is a convention for most proxies to put the end-client's IP inside the x-forwarded-for header.\n. What you pointed out is correct, each worker has its own scope and cannot access each other's variables directly as you suggested.\nAlso, note that you should treat workers as though they are disposable and can crash at any time - This is a central idea of the 12-factor app (http://12factor.net/disposability).\nIn SC, you can share events/data between workers using the global nData object (accessible through property of worker object):\njs\nworker.global\nThe global object is an nData client (https://github.com/topcloud/ndata) which you can use to store/retrieve data asynchronously in a central place to share between all workers. It's basically a lightweight version of Redis which runs entirely in Node.js.\nNote that in SocketCluster, a client will always be sent to the same worker (this applies to every HTTP request and WebSocket connection made during that session). If a user has multiple tabs open in the browser (multiple sockets), they will all be sent to the same worker as well.\nThere are a few general rules for using variables inside workers:\n- These variables should only store data which concerns a user/session/socket which is bound to the current worker, and;\n- The data that you store inside these variables shouldn't be operation-critical - Basically, you shouldn't store data in a variable if that data is necessary for your system to continue to operate normally after a worker crash. (You should assume that your workers are disposable)\nAll this said, when designing a distributed system, you shouldn't try to store individual clients as you are trying to do. This works against the principles of the Publish/Subscribe pattern (http://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern).\nYou should try to resist the urge of having all your workers 'know' about all of your clients (this approach is simply not scalable). Instead, you should design your system in such a way that you do not have to keep track of them at all (yes it's possible) - You will find this MUCH easier to deal with and it will scale seamlessly.\nYour clients should listen for events that they are interested in - In your workers, you can use the SUBSCRIBE middleware to authorize/block them from doing so. Once your client is subscribed to a channel, they will receive all events that you publish to it. You don't have to know which clients are subscribed to that channel in order to send messages to them.\nFor example, you could have an event channel for a user ('Bob') and another user ('Alice') could send messages to that channel by emitting to it.\nFor example, assume this client-side code (for Bob):\njs\nsocket.on('Bob', function (data) {\n    console.log('Received message from ' + data.from + ': ' + data.message);\n});\nThen assume this client-side code (for Alice):\njs\nsocket.publish('Bob', {\n    from: 'Alice',\n    message: 'Hi Bob!'\n});\nHere Alice is sending a message to Bob's event channel. Only clients which are subscribed to the 'Bob' event will receive the message (in this case just Bob, no one else). As mentioned before, you can control who can subscribe to a channel using middleware - You can control access by authenticating the user. See this post for more details: http://ncombo.wordpress.com/2014/08/22/full-stack-pubsub-with-socketcluster/\n. Your approach to handling events sounds good.\nWith regard to middleware, you're almost there.\nNote that you should always call next() eventually (for every publish message).\nIf you call next() with no arguments then it means allow, if you call next with a a string as argument like:\njs\nnext('You are not allowed to publish to this channel...')\nthen that means fail.\nIf you never call next() (as would happen in some cases in the example you showed) then it will timeout and throw a timeout error on the client (which doesn't give much information to the browser) - It's better to call next() with an explicit error to let the browser know exactly why they are not allowed to publish to that channel.\nAlso, I feel that you don't need middleware to do what you're trying to do. If you don't want a specific client socket to receive an event - All you have to do is not listen to that event.\nSocketCluster is really efficient at making sure that only client sockets which are listening to an event will receive that event.\nYou generally don't need to block a user/socket from publishing an event to their own channel since there is no security issue with that. The publish middleware is mostly used for preventing other users from publishing events to a channel which they shouldn't have access to.\nDocumentation on middleware is lacking at the moment, so I'll do my best to provide an explanation:\nFollowing from the example I gave earlier.\nIf you have a channel for 'Bob', you might want to setup a SUBSCRIBE middleware function which will make sure that only the sockets which belong to the user Bob will be allowed to listen to that event. On the publish side, you might want to add middleware to make sure that only friends of Bob are allowed to post messages to his channel.\nTo make good use of middleware, you need some way to associate sockets (or a session) with a particular user's identify. You can do this in a number of ways (you can make use of tools like Redis or other database engines to keep track of session IDs and authentication tokens). Note that you can get the session id from:\njs\nsocket.session.id\nHowever, probably the easiest way is to use SC's socket.session (also accessible over HTTP using req.session) object directly to set/get auth tokens, you can perform authentication over either HTTP or over a realtime connection (whatever works best for you):\nExample (server) code:\n``` js\nscServer.on('connection', function (socket) {\n  socket.on('login', function (data) {\n    // Get user's actualPassword from a database then compare it with \n    // the provided data.password to check if the user is who they claim to be\n    // Here we are using MySQL (see https://github.com/felixge/node-mysql/)\n    connection.query('SELECT * from user WHERE username = ?', [data.username], \n      function (err, rows) {\n        var actualPassword = rows[0].password;\n    if (data.password == actualPassword) {\n      // Password matches so set a token to associate this session with the username\n      socket.session.set('username', data.username);\n    }\n  }\n);\n\n});\n});\n```\nThen the subscribe middleware could look like this (Note that this is highly simplified):\njs\nscServer.addMiddleware(scServer.MIDDLEWARE_SUBSCRIBE, function (socket, event, next) {\n  socket.session.get('username', function (err, username) {\n    if (event.indexOf(username) == 0) {\n      // If the event begins with the session's username token,\n      // then allow it to subscribe to that event\n      next();\n    } else {\n      // Otherwise block with appropriate error message\n      next(\"ERROR - You cannot subscribe to other users' channels\");\n    }\n  });\n});\n. With only 2 cores, you will not get much performance benefit (maybe a little bit faster than single-process engine.io). You should be able to see a clear performance benefit with 4 cores though.\nIn any case, you will still benefit from SC's pub/sub architecture and also the auto-respawn of dead workers in case of error. Also, if your system gets enough traffic down the track, it will be easy to scale up (just get a bigger machine with more cores - No code changes necessary). Also, if you get even more traffic, SC will make it easy to scale across multiple machines.\n. We can try to decycle/retrocycle objects but there is a performance tradeoff there.\nI used the json2.js decycle/retrocycle functions briefly in the past and found them to be inefficient with large objects because of this: https://github.com/douglascrockford/JSON-js/blob/master/cycle.js#L63-65\nBy adding a decycle/retrocycle step, we are adding processing overhead for every single object that is sent to the server from all client sockets - Regardless of whether this object actually contains a circular reference or not.\nI'm really torn on this issue. Last time I dealt with it, I decided that throwing an error was best because developers shouldn't assume that the object will always be exactly the same on the other side (For example when sending a complex object <which is not JSON-compatible> from the client to the server). Only JSON-compatible objects should be passed as argument. For example, functions get removed from an object's properties when passed to JSON.stringify() (no way around it) so maybe cyclic references should also be considered incompatible?\nI'm happy to revisit the issue though. Maybe we should remove the cyclic reference and log a notice  on the server (not error) so it doesn't cause the server to reboot? Or maybe there is a more efficient way to decycle/retrocycle than using the cycle.js library? Not sure. I'm happy to listen to options.\n. Yes, the problem lies with express-session middleware (not with passport.js itself).\nSocketCluster sets its own req.session property so as you pointed out it's likely that it's overwriting the one provided by express' session middleware.\nI'll try to come up a way to get SC's session engine to work with the one provided by express. I'll have a look later today. Feel free to tinker with SC in the meantime and see if you can find a solution or maybe even make a pull request if you feel confident enough (but that part of the code could be tricky because it affects a lot of things).\nYou can use Redis with SC but it has to work alongside the default nData solution (which is used internally to do all the pub/sub magic). There are plans to bring better SC-Redis integration in the future (by making a special wrapper to allow Redis to handle all of SC's internal pub/sub and session storage needs) - That way it would optionally replace the default nData solution, but for now it should be used alongside the default nData engine (not a full replacement). They should work well alongside each other. If you were to start a fresh project though, it would definitely be simpler to just use the default solution (it's just a bit easier - and scaling will be easier down the track).\n. @MegaGM - Thanks for sharing your workaround. For convenience, I added a new option to prevent the default session object from being added to HTTP requests so that you don't need to add the middleware explicitly.\nIn version 0.9.84, you can now set the addSessionToHTTPRequest option to false if you don't want to attach SC's session object to HTTP requests (this lets you use a separate session object such as the one provided by express).\nserver.js:\njs\nvar socketCluster = new SocketCluster({\n  // ...\n  addSessionToHTTPRequest: false\n});\nNote that this property is true by default because it's nice to be able to share the same session data across two different protocols. For the sake of migrating existing apps, though, it may be easier to keep them separate.\nIf you're starting a project from scratch though, it's better to leave it as true and use the default SC session object (instead of using the express-session middleware) - That way the same session object will be used for HTTP and Realtime (WebSocket) protocols - This allows you to share the same authorization tokens and permissions across both protocols.\nAs mentioned earlier, I intend to make a Redis-backed version of this session object (instead of nData) due to popular demand. SC's architecture is already in place to support using alternate session storage engines - We just need to create the wrapper.\n. As @MegaGM pointed out, if you provide a callback to emit(), you need to send the ack response yourself from the other side - This feature allows events to return a value to back to the sender and is also a good way to check if the event was received successfully.\nRegarding timeout, the default one is 10 seconds. You can change it by adding an ackTimeout option when you initialize SocketCluster:\njs\nvar socketCluster = new SocketCluster({\n  ...\n  ackTimeout: 20 // Set a 20 second ack timeout for realtime events\n});\n. @joinfok are you doing something like this?\njs\nalert();\nres.end();\nIf so, you may want to change it to:\njs\nres.end();\nalert();\nalert() blocks the thread of execution so it's possible to timeout while the alert is up.\nThe ack response feature is mainly used to check if the event was received successfully by the other side so you generally shouldn't make your timeout too long (but there are always cases where it's appropriate).\nSometimes it's better to just emit a new event instead of using the ACK.\n. The arguments to the callback appear to be incorrect, it should be:\njs\nsocket.on(,,function (data, res) {\n  res.end();\n  ... more code hier\n});\nIn case that's not the problem, which version of SC are you using?\n. You could try upgrading and see if that fixes the problem. I couldn't reproduce the issue on latest version.\n. @joinfok I made a major update to SC today: v0.9.91.\nI think it might fix your problem.\nNote that this update will require minor code changes:\nTo receive published events, you now have to subscribe to them explicitly using:\n``` js\n// This is new\nsocket.subscribe(['foo', 'room-a', 'bla'], function (err) {\n  // Check if subscribe was successful\n});\n// Same as before\nsocket.on('foo', function (data) {\n  // This function will handle published 'foo' events\n});\nsocket.on('room-a', function (data) {\n  // This function will handle published 'room-a' events\n});\n...\n```\nThis new way is a bit closer to how standard pub/sub is done. Before, SC used to do the subscribe automatically. The new way gives developers more control over whether or not a client can receive published 'channel events' (this is an important security consideration since events may come from other clients). The socketcluster.io website has been updated with the new information.\nYou don't need to call socket.subscribe() in order to receive events emitted by the server - Only published events.\n. Sorry I didn't understand the first question.\nFor the second question:\nI would recommend that each user listens to one or more channels under their username.\nFor example, the user 'bob123' could have something like this:\n``` js\n// Client side\nsocket.on('bob123', function (message) {\n  if (message.action == 'kickout') {\n    alert('You have been kicked out from room ' + message.data.room);\n  }\n});\n```\nOn the backend:\n``` js\n// Server side\nscServer.global.publish('bob123', {\n  action: 'kickout',\n  data: {\n    room: 'roomA'\n  }\n});\n```\nYou should use your database (or scServer.global nData client) to store the fact that bob123 is no longer allowed to access roomA.\nThen in your subscribe middleware you could add logic to check the database to see if bob123 is allowed to subscribe to the event 'roomA' since you banned him, he will not be allowed to subscribe to it.\n. The master process in SC is a process manager itself (the master process takes care of respawning workers and other child processes and error logging). So adding another process manager in front is generally redundant - Unless you put code in the master process which runs periodically and is prone to errors (which should be avoided).\n@willeponken Does raise a very important point though (I will need to mention it in the docs). You should only use the master process to bootstrap SC, you shouldn't use it to spawn new threads or execute new logic after the initial boot phase. If you want to have some daemon processes running in the background, then you can spawn them from master at startup time and let them be independent afterwards. If you keep your master process lightweight, then it shouldn't be any more likely to crash than a forever or PM2 process.\nThe socketcluster.io website has been running on SC for about 1 year now and the master process has never crashed (except when the EC2 instance itself crashed on on a couple of occasions).\n. All that said. I'd like to know how users of SC feel about adding runtime logic to the master process. Maybe this is actually a desired feature?\nIf you absoutely must, then I would suggest you should launch it using forever. PM2 feels really overkill for this purpose.\nMaybe we should think about adding a lightweight respawn process in front master by default (the only thing it would do is watch and respawn master - And maybe log any crash to a socketcluster.log file with timestamps)?\nWe could achieve this by adding some logic to the existing socketcluster command-line tool, maybe instead of launching with node, we could launch it using:\njs\nsocketcluster run server.js -p 8000\n^ Any arguments should be passed to the master process\n\nIf someone wants to contribute to SC then that would be a really nice task to do (since you don't really need too much preexisting knowledge of SC). I will gladly accept pull requests.\nThe code for the command line tool is in this file: https://github.com/TopCloud/socketcluster/blob/master/bin/cli.js\nYou'd have to add a 'run' command which should launch a 'master watcher' process (making sure to pass on any arguments to the master process). The master watcher process should be really lightweight and the only thing it should do is respawn master when it crashes (and it should do this in a crash-proof way - I.e. make sure any errors are caught (and logged to a socketcluster.log file) - The only possible errors here would be if the process crashes or if it fails to fork). I feel that using forever as a dependency would be overkill (we don't need most of it).\n. I'm working on this right now.\n. As of SC v1.0.9, you can run your master in a way that will allow it to auto-respawn if it crashes. It also logs everything in a socketcluster.out file (which will be created in your current working directory). The command is:\nbash\nsocketcluster run server.js\nYou can also pass arguments to your node script as normal:\nbash\nsocketcluster run server.js -w 2 -b 2\nNote that it only works in Linux right now (probably iOS as well). It uses the forever-monitor module behind the scenes so it should be quite robust.\n. One way to handle this is to setup a plain Node.js server to redirect all HTTP traffic your HTTPS SC instance.\nIf you really want to have the two running side-by-side then you will need to split server.js into two files - One for HTTP and one for HTTPS. So maybe instead of server.js, you can have server-http.js and server-https.js. You will need to launch both of these separately.\nNote that they will still share the same code (only the bootstrapping logic from server.js will be different - One will have key and cert info and the other will not).\n. Yes, it sounds feasible at first glance. It it plays nice with the load balancers then that could be pretty straight forward to implement. It could be specified by setting the 'protocol' option of SC to be 'spdy'.\nIt's not high on my TODO list right now but if you need this feature in a hurry, feel free to play around and make pull requests.\n. @ghost I think we should forget SPDY and focus on HTTP2 instead.\n. You can add middleware to intercept (or authorize) publish, subscribe and emit actions.\nMiddleware functions are useful to filter inbound communications.\nI.e. Client => server\nYou can read up on the different kinds of middleware lines here: http://socketcluster.io/#!/docs/middleware-and-authorization\nFor example, for subscribe (to control who can see what channels), the client-side code might look like this:\n``` js\n// Client\nsocket.subscribe('foo');\n```\nThe middleware might be:\n``` js\n// Server (worker.js)\nwsServer.addMiddleware(wsServer.MIDDLEWARE_SUBSCRIBE,\n  function (socket, channel, next) {\n   // Get the list of channels which this session/socket is allowed to access\n   // Alternatively, this could come from a database instead of socket.session\n   socket.session.get('allowedChannels', function (err, channelPermissions) {\n     if (channelPermissions[channel]) {\n       // Allow the socket to subscribe to this channel - After calling next(), you don't need to\n       // do anything else - SC will handle the rest\n       next();\n     } else {\n       // Here we block every other channel which is not in that session's channelPermissions object\n       // By passing an error to next(err), we are blocking the subscription\n       next(socket.id + ' is not allowed to subscribe to event ' + event);\n    }\n   });\n  }\n);\n```\n. @joinfok You found a bug in socketcluster-server (the session object wasn't being added to the request). It's been fixed in v0.9.43 (https://www.npmjs.org/package/socketcluster-server). Thanks!\nOne way to fix it is by reinstalling socketcluster using npm.\nbash\nnpm remove -g socketcluster\nThen make sure you run:\nbash\nnpm cache clean\nbefore you install again. This should fetch the latest version of socketcluster-server which has the fix.\n. Yes, I can upgrade engine.io. I'm planning to push a big SC update this weekend so I might take the opportunity to also upgrade engine.io.\n. Ok, this has been delayed a bit (been busy). I'll try to do it THIS weekend.\n. Upgrade done in v1.0.6\n. First of all, to handle 200k connections, you may need a really big machine/instance. It depends on how often each client sends a message to the server.\nThe most basic tools to use are the 'top' and 'perf' commands which are available on most Linux distros by default.\n. I did tests on various EC2 instances (4-cores, 8-cores and 16-cores). For performance monitoring, I just used top and perf commands. The 16-core instance I used was c3.4xlarge. I can share with you the EC2 AMI (machine image) that I used if you like?\nThere is an academic paper about performance testing SocketCluster (see download link on the right): http://arxiv.org/abs/1409.3367\nIt might give you an idea of how to test (what tools to use). This paper was written a while ago so hopefully performance has improved since then. The author had encountered some issues with running on 32 CPU cores. Also, you have to be careful of what OS you use - Some OSes are much better with CPU scheduling than others at high concurrency.\n. @nhatduong In SC, everytime you call:\njs\nvar socket = socketCluster.connect(options);\nIt will create a new socket connection - There is no need for a 'force new connection' option. So if you want to simulate two 'clients' then you just create two sockets... Careful though because you will find that client sockets use much more CPU than sockets on the server. You have to make sure that client processes don't get too close to 100% otherwise they will start lagging and it will mess with your results.\n@3rd-Eden Yes, that's a good point to keep in mind. Real systems are usually much more complex and there are a lot of variables to consider. I feel that benchmarks don't really yield much information on their own - They can be useful to make comparisons between different solutions but even then there are a lot of variables :)\nSometimes the operating system or even the choice of CPU can affect the results. Some OSes aren't very good at context-switching between processes cough Windows cough - That can also mess with results if the product being tested uses process-based vs thread-based concurrency.\n. I wasn't able to reproduce your issue. The session ids are the same for me. I'm using the absolute latest pre-release version so it may have been fixed since but I haven't encountered this issue before so I'm not sure. I might try with an older version to see if I can reproduce tomorrow.\nNote that socket ID and session ID are two different concepts:\njs\n// Client code\nconsole.log(socket.id); // socket id\nconsole.log(socket.ssid); // session id\njs\n// Server code\nconsole.log(socket.id); // socket id\nconsole.log(socket.session.id); // session id\nRegarding losing session data - When a SC worker crashes, you should not lose any session data. It should be unnoticeable to the user - SC will reconnect everything as though nothing ever happened.\nIf however, a store crashes, then yes, the session data hosted by that store will be lost (unless you have implemented a backup mechanism). Note that store crashes should be MUCH less common than worker crashes since the logic that runs on the nData server is typically pretty lightweight and predictable.\n. You should try to upgrade to socketcluster 1.0.1 and see if that fixes the problem.\nThere are some API changes on the client-side though.\n. Try upgrading to socketcluster v 1.0.1. I will need to look into this over the weekend. I haven't had much time.\n. Note that if you emit an event with a callback, you are telling SC to expect a response to that event - So you HAVE to call req.end() on the other side to let the other side know that the event has been handled. This is normal behaviour.\nIn the future, if you want to share a really long log like this (I deleted it from your post as it was taking too much space), send it to my email instead of posting it on GitHub. You can find my email from my GitHub profile.\nAlso, if you want to share some code, you can send the .js files to my email that way I can test it.\nThanks.\n. Sorry about that, I forgot to mention this in API changes.\nres is no longer an object but a function. I will update the docs and API changes section.\nTo send back an error:\njs\nres('This is an error message')\n// OR if you prefer, you can make the first argument an error code\n// and set a message separately\nres(1234, 'This is an error message')\nTo send back a regular response (not error) message:\njs\nres(null, 'This is a response message')\nThis is closer to the standard node.js style and it encourages developers to think about error cases but it does make sending back a normal non-error response slightly awkward.\nHow do you feel about this new style compared to old way?\n. @MegaGM I would hope so :)\nPersonally, I feel that overall it's better because most of the time when the developer provides a callback to the emit() method, they do it because they want to check if an error occurred so it's the most common use case.\n. What is your OS and which signal are you sending? What command are you using?\n. Nvm, I was able to reproduce this on Linux with kill command on master. I will look into it.\n. Ok, this has been fixed in v1.0.5 - Also the overall shutdown process should now be more graceful (it will now allow the server to finish what it was doing). You can specify a processTermTimeout (in seconds) option to SocketCluster to set a maximum amount of time a process should take to terminate. Defaults to 10 seconds.\nSo by default it may take up to 10 seconds for processes to die if they're busy.\n. @sdejean28 Thanks for reporting this. To gracefully shutdown when using forever, you have to start it using this command:\njs\nforever start --killSignal=SIGTERM server.js\nthen to stop is as normal (example using 0 as index):\njs\nforever stop 0\nThe example on the website is incorrect - I will update it today :)\n. There are many ways to do this. One way is to create a basic Node.js server (HTTP or raw unix domain sockets if PHP allows) on one of your workers (inside worker.js) and make it (in the case of HTTP) listen to '/publish' POST requests from outside. Whenever you get such a request (which may come from your PHP script), you can call this inside your worker.js:\njs\n// You can use the payload of the POST request to make up arguments\nscServer.global.publish(...);\nYou might want to make sure that only one of your workers is watching for external publish messages (that way you won't get duplicates). The worker object passed to your worker.js file's run() function has an id property (worker.id) which lets you uniquely identify the worker in which your code is currently running. The id is actually an index - So you will always have exactly one worker with id 0 (the leader).\nAnother way would be to use a Node module like chokidar to watch a text file and to publish an event whenever that file is modified (the file could contain the channel name and JSON data to publish) and you could clear that file each time.\nYou could also create the publish HTTP server directly inside your store.js and publish directly on the store object. I can't remember if stores have a unique id which you can use to avoid duplicate (I added this to my TODOs). If you only have one store then that won't be a problem (for now) but you shouldn't work on that assumption.\nAnother solution could involve Unix signals... If you can find a sensible one to use. You'll probably need to share the relevant process PID with your PHP script which may be more complicated than HTTP solution.\nI might consider creating a plugin to make this easier (or maybe integrate directly into SC) because you're not the first person to ask about this feature.\nThe advantage of the HTTP solution is that you could allow any external (authorized) client to call a REST endpoint to publish to SC (from anywhere on the network). There are security considerations to this though.\n. By default, SC respawns workers automatically when they die (on Linux this typically takes less than 1 second).\nIf you have your TCP server running directly in a worker process (worker.js), then it will automatically be restarted when your worker dies (you don't have to do anything). If your pub/sub handling TCP server is in its own process (forked from a worker) then that process will be respawned too but you have to make sure that the previous process is killed along with the parent worker by adding some logic like:\njs\nworker.on('SIGTERM', function () {\n  myChildProcess.kill();\n});\nWhether or not you need a separate process for the server depends on how many messages get published (you don't want to make worker 0 process too busy handling publish requests).\nSo fork()ing a new process is a better solution.\nYou can talk to your worker using Node's built-in IPC mechanism:\n``` js\nvar fork = require('child_process').fork;\nvar myChildProcess = fork(__dirname + '/pubserverfilename.js', ['arg1', 'arg2']);\nmyChildProcess.on('message', function (message) {\n  if (message.action == 'publish') {\n    scServer.global.publish(message.channel, message.data);\n  }\n});\n```\nThen inside 'pubserverfilename.js':\njs\nprocess.send({\n  action: 'publish',\n  channel: 'somechannel',\n  data: 'This is some data'\n})\nNote that 'data' here could also be an object since SC lets you publish any JSON-compatible JavaScript object as second argument to scServer.global.publish()\n. I will be working to make this task easier in the near future but for now you have to handle these external publish requests yourself.\n. Maybe try:\njs\nworker.on('exit', function () {\n //..\n});\nInstead.\n. I thought just listening to 'exit' would suffice (across all platforms).\nBut if it works, then that's fine. It may depend on your specific OS.\nAlso, I would try logging to a file instead of using console.log().\nIt could just be that stdout closes just before the event is triggered (so you never actually see the output even though the code would run properly) - It's probably not the case but it's worth considering.\n. I'm closing this issue. This problem will be solved by a Redis plugin. See https://github.com/TopCloud/socketcluster/issues/38\n. Not sure if that's any use but anyway: Regarding your question on mongo's req.user-object object:\nYou can access the socket's HTTP handshake request object using socket.request... So if you're using express with HTTP middleware which adds the user-object, in theory you should be able to access it using socket.request['user-object']. I haven't tested this, but I'm confident it would work.\nNonetheless, I think using the default SC session store may be easier because it handles distribution across multiple store processes for you and it integrates nicely with SC.\nYou don't need to add any middleware to express in order to use SC's session store - It's there by default. You can access it through either the socket or HTTP req object (socket.session or req.session).\nThe session object is effectively an nData client (https://github.com/TopCloud/ndata) which is scoped to a particular session ID. You can use all he methods exposed by the nData client (except the ones related to pub/sub - See link above for API).\nSo in your example where you use passport.authenticate(), if you have a reference to either a socket object or a HTTP req object, you can just use something like:\njs\nreq.session.set('user', req.user, function (err) {\n  // This is an optional callback to check if data was set successfully on local nData store process\n});\nThen later, if you need to get the data out of this session:\njs\nreq.session.get('user', function (err, data) {\n  // ... If data is undefined then you know that the request's current session was never authenticated\n});\nHopefully that answers your questions. Don't hesitate to ask more questions if you run into any issue. Also suggestions are welcome.\nIf anyone is interested; The clustering engine (which provides the session object) is a modular component of SC (can be swapped out), the default one (and currently the only one) is called IOCluster: https://github.com/TopCloud/iocluster. Ideally, it would be nice to make alternatives with different popular storage engines like Redis and Mongo.\n. I can't recommend any specific tools at this stage... New Relic and Keymetrics are two tools off the top of my head for general-purpose CPU monitoring. StrongLoop has some nice tools for identifying runtime issues while in deployment.\n. @mlmarius Yes, I like the idea of having special channels for the system status.\nRight now if you wanted to get the client count, you would have to make your own channel and publish the updated client count to it manually (and you also have to keep track of the client count which is extra work).\n. What problem would this solve?\nIt's usually better if the development and production environments are the exactly same (or as close as possible) to avoid bad surprises in production. Maybe there is something we can do to SC itself to make it easier to debug? I'm happy to hear suggestions/criticism.\nIf this is about cross-domain issues, I think it's a somewhat unusual case so I don't think we should add an extra script file just for this one case - I think the developer should come up with a solution on their own fr how to test it :)\n. There is always a risk when debugging anything within a production environment.\nYou make a good point that the worker reboot behaviour can be a bit scary when debugging (in the case where a worker keeps dying as soon as it's launched because of a error during startup).\nWhen debugging, you might want to set rebootWorkerOnCrash to false in your config - You can read argv while in server.js to decide whether it should be true or false.\nI will change the sample/boilerplate app to look for the --debug argument and when it's there, it will set rebootWorkerOnCrash to false automatically.\nWill this help a bit?\n. Can you add write some small snippets of code (server and client) so that I can reproduce the issue?\n. I think I followed the steps you mentioned. It appears to be behaving correctly.\nHere's some code I used:\n``` js\n// Server\nsocket.on('disconnect', function () {\n // With no arguments, it will kick out from ALL channels\n  socket.session.kickOut();\n});\n```\n``` js\n// Client\nsocket.on('dropOut', function () {\n  console.log('dropOut:', arguments);\n});\n```\nHere's what happened:\n1. I opened two clients in the same browser (in two different tabs) - Both subscribed to 'pong' channel.\n2. I closed one of the tabs - This triggered the disconnect event on the server.\n3. Because the remaining client (in the first tab) is in the same session as the other one (which we just closed), it got a 'kickOut' event (now it's no longer subscribed to any channels so it's not getting any more published messages from any channel).\n4. I opened a new tab and connected a new client to it (this client joined the same session of the first one as expected).\n5. Then I emitted a message to 'pong' channel from new client.\n6. The new client received its own message but the old client did NOT (which is expected since the old tab is no longer subscribed to any channel).\n7. If you close the new tab/client, the first one will not get 'kickOut' again because it was already unsubscribed from all channels when the old tab closed the first time.\nIs this the kind of behavior you encountered?\nIf so, this is expected behavior.\nNote that it's generally not a good idea to use socket.session.kickOut() when a single client disconnects - This will kick out all sibling clients open in other tabs. Also there is no point calling socket.kickOut() either because whenever a socket disconnects, it will already lose all subscriptions automatically.\nLet me know if this answers your query.\n. Actually, I just realized, I forgot to add API documentation for socket.kickOut() on website.\n. 1)\nIt should be similar - You can write your own adaptor to sync pub/sub channels between store processes on multiple SocketCluster instances. Pub/Sub in SC is very similar to how it works in Redis so it should be seamless to integrate. You need to add the code inside your store.js file - You can listen to events on the store object and publish data to channels on that store in order to get stores on different hosts to sync with each other. I will write a tutorial about how to do this in more detail (hopefully will be up by the end of January - I've been busy).\nRegarding load balancing - You may not need an external load balancer (depends on what you want) - If you have a Geo-based DNS service, you could send users directly to the nearest host. Because SC can scale vertically (and it has its own internal process-level load balancers), you could have really large servers (for example with 16 cores) in high-usage geographical areas and smaller servers in areas where usage is lower. If you really need to use an external load balancer, you should be able to use HAProxy to balance between SC instances.\n2)\nNo, you wouldn't need any special settings - These settings only apply to the current instance and are only needed for scaling vertically on a single machine (to use multiple CPUs/cores).\nBy default, an SC instance will launch with 1 load balancer, 1 worker and 1 store but you can change this using command line arguments when you run SC, for example:\nbash\n// Launches with 2 balancers, 3 workers and 2 stores\nnode server -b 2 -w 3 -s 2\n3)\nSC uses the cluster module internally for load balancing - You don't have to think about this at all - It's all automated. You just put your code inside your workerController (worker.js) and the rest is automatic.\nTo test - Add this code inside the run() function of your worker.js file:\njs\nconsole.log('This is a worker with PID: ' + process.pid);\nThen run SC with 3 workers (using command node server -w 3).\nYou should see the log message 3 times (once for each worker showing each worker's PID).\nSC automatically handles the load balancing between workers and the sharing of pub/sub channel data between them.\n. Documenting this aspect is my next priority - I will try to have the tutorials up as soon as possible.\n. I also got a couple of emails asking for this. The pressure is on :p\nThe API page for the Store object is almost done - It might be enough to get started (it should give a fairly good idea of how to hook up SC stores to external Pub/Sub systems to achieve scalability across multiple machines). I should be able to put the new API page up on the website tomorrow.\nHopefully the full tutorial will follow soon after that.\n. I added the API for the store object (http://socketcluster.io/#!/docs/api-store) - Hopefully it's enough to get a basic idea of how to implement horizontal scalability. I will add a tutorial soon for more details.\n. @pressla Thanks for the feedback :)\nI'm going to release a more detailed tutorial soon - But yes the basic idea is that you scale by synchronizing channels between the stores of multiple SC instances/machines.\n. Here is a guide to scaling SC across multiple machines: http://socketcluster.io/#!/docs/scaling-horizontally\nIt doesn't discuss how to setup a distributed message queue, but hopefully it covers the SocketCluster side of things.\nRight now I'm collaborating with a startup to introduce an MQTT channel synchronization service to make this a easier. If anyone is interested, feel free to contact me (email is on my GitHub profile).\n. A Redis adapter has been released. It's not suitable to scale horizontally - Since it only deals with a single server, but it's useful to get an idea of how it all works. Also, it's away to allow third-party systems to interact with internal SC channels.\n. @MegaGM - What is mean by client-to-client communication is that one client can publish messages to another client without having to add any special server-side logic to connect the two.\nAll SC pub/sub messages do go through your SC instance on the backend server so you can watch them pass through your MIDDLEWARE_PUBLISH middleware (you can also bock messages or even modify them before they are shared with all other clients).\nFor example, if you had a channel called 'censored_channel' and a client did this:\njs\n// Client code\nsocket.publish('censored_channel', {message: 'I cannot get this damn thing to work!'});\nYou could have this middleware:\njs\n// Server code (worker)\nwsServer.addMiddleware(wsServer.MIDDLEWARE_PUBLISH, function (socket, channel, data, next) {\n    if (channel == 'censored_channel') {\n        data.message = data.message.replace(/damn/g, '****');\n    }\n    next();\n});\nThat way, all clients would receive the message as:\n{message: 'I cannot get this **** thing to work!'}\nA unique feature of SC is that it lets you watch and even transform pub/sub messages in realtime so you can do some really cool stuff. You could use AI to analyse messages or transform them in clever ways.\n@1manStartup - You are on the right track regarding multiple machine scalability. You can also make is so that you receive events from MQTT (that way all SC channels will sync with MQTT ones in realtime).\nYou should have a look at the sc-redis example here: http://github.com/topcloud/sc-redis\nYou can listen to 'subscribe' events on store to subscribe to the matching channel the external service.\n. The reason why you can't publish events directly from the SocketCluster master is because it is an anti-pattern - We should avoid putting any runtime logic in master - The master process isn't as resilient as worker processes so it's better to keep it lightweight (mostly good for configuration/bootstrap logic).\nThe best place to publish to an SC channel from outside is in the worker (worker.js) - The worker object which is passed inside the run() method has an id property which is the index of the current worker - There will always be at least one worker with id 0. So inside worker.js, you can have this code:\njs\n// By checking worker.id we can make sure that only one worker is handling a particular event\n// So we don't get duplicates\nif (worker.id == 0) {\n  // ... Here we can do anything we want like listen for events from outside Node.js\n  // For example, we can use the Node.js redis client https://github.com/mranney/node_redis \n  // to subscribe to specific channels from redis and publish data to \n  // SocketCluster channels by calling worker.global.publish('myChannel', dataFromRedis);\n}\nIf you have a LOT of external data coming in from many different Redis channels (too much for a single worker process to handle), you could split responsibilities between multiple workers and make it so that each worker handles a specific subset of all Redis channels - This approach is more scalable.\n. EDIT I edited the post above since the information provided earlier about publishing from stores is not ideal - You should actually publish from workers - That way channel data will automatically get routed to the appropriate store which is responsible for that channel.\nNote that in SC, if you have multiple store processes, each store will only be responsible for some of the channels - That way they share the work evenly.\n. I just started working on a Redis adapter which will allow hooking SC into Redis automatically to share channels.\n. I'm closing this issue. The optimal solution will be the Redis adapter - I opened a separate issue for it here: https://github.com/TopCloud/socketcluster/issues/38\nIn the meantime, the best way to interact with SC from external systems is by passing data to workers. You can use IDs to uniquely identify them.\n. @slidenerd \n\nif I do worker.exchange.publish() from worker 0 and if a client is connected to worker 1 will they still get this data?\n\nYes, channels in SC are global so they are shared between all processes. If you use SCC, channels are also shared between all machines so it doesn't matter what process or machine the client is connected to.. Redis plugin has been released:\nhttps://github.com/topcloud/sc-redis\n. No, not at the moment.\nThere are platforms like Apache Cordova which allow you to use JavaScript to make native apps. The SocketCluster client should work with these.\n. @hopewise Some community members have been building a native Android client which implements the basic features. I haven't tested it personally though but worth trying: See https://github.com/abpopov/SocketCluster-android-client\n. To answer your question as directly as possible:\nOff the top of my head, to get the 'connection' event to trigger on the server, you will have to send this JSON immediately after your SocketRocket clients becomes connected\njson\n{\"event\": \"ready\", \"cid\": 2}\nThe cid is actually a unique id (index) assigned to each message (so you may not want to hard code it like that in production - Your client should count each JSON message it sends and use that as the cid).\nAs for the bigger picture behind your question:\nSocketCluster client has its own (simple JSON) protocol on top of the engine.io protocol.\nIt looks like it might be compatible with the SocketRocket client (based on the info you provided), but you might have to create a wrapper class around SocketRocket to expose the same methods as socketcluster-client.\nFor example, when you call socket.emit('somevent', 'This is a message') on the socketcluster-client, that translates to this JSON string being sent over the WebSocket connection (example):\njson\n{\"event\": \"somevent\", \"data\": \"This is a message\", \"cid\": 2}\nIf you want to do this properly and write your own fully-compatible client on top of SocketRocket, you will have to implement the methods and trigger the events described here: http://socketcluster.io/#!/docs/api-scsocket-client\nYou may want to read the source code for the JavaScript client to try to follow: https://github.com/topcloud/socketcluster-client\nThe current client does some fancy stuff - For example, it buffers emit() events before actually sending them (that way it handles bad connections better). But you don't need all this fancy stuff to get your client working.\nAlso, if you do get it working (with your own client wrapper), that would be an awesome open source project. People have asked for native clients for SC before so this would be useful.\n. @victorjussiani Full-featured SocketCluster native iOS client is ready: https://github.com/topcloud/socketcluster-client-ios\n. You can listen to the 'error' event on pretty much every object in SC. This includes the client socket, server socket, worker, SCServer, When you listen to the error event on an object, it will prevent errors coming from that object from being uncaught.\nTo listen to errors on the SocketCluster object, you should listen to the 'fail' event - The fail event could carry any uncaught error from any worker, store or loadbalancer object.\n. @maxime-crunding \nYou can restart all workers by sending a SIGUSR2 signal to the master process (master PID is logged when you start SC) or you can use the SocketCluster instances' killWorkers() method (on master) if you want to do it programmatically. The new workers will use the fresh code.\nWorkers typically take less than a second to restart - Not long enough for HTTP requests to timeout - So except from the fact that all active realtime connections are destroyed (and will have to reconnect), it might feel close to zero downtime. SC clients will automatically try to reconnect - So in effect, clients will miss a few seconds of realtime messages between the time they lose the connection and the time the 'connect' event triggers again.\nMissing a few realtime messages isn't a huge deal if you're storing the messages in a database anyway (which is usually the case for most apps unless we want truly ethereal messaging) you can make your clients refetch the latest data when socket.on('connect', ...) triggers - That way they won't actually miss anything - This reduces the problem down to only to a slight delay.\nTrue zero downtime deploy is difficult to achieve with realtime WebSocket connections because each client is attached to a single server. We could come up with a strategy to keep the old workers up (the ones that have active connections) and spawn some new ones (which use the new code) to handle all new connections and the old workers will be killed only when they have 0 clients left attached to them - But then what if we do several deploys in a row - We might end up with a LOT of workers using different versions of the code and it would get confusing when errors happen. So this approach is probably not worthwhile.\n. I should probably add it to the docs... It's quite important :)\n. You can implement an adapter to sync SC channels with external channels from a pub/sub or message queuing service.\nThere is a partially completed one for Redis:\nhttps://github.com/topcloud/sc-redis\nIt doesn't let you add password yes, but feel free to modify the source code to get it working for you. Also pull requests are welcome.\nAt this stage, it's more to show how it works.\n. @seme1 Yes your idea sounds really good. You can also use a third-party message queue 'as a service' and hook up your socketcluster instances to it if you're lazy.\nThe service would only handle synchronization aspect and you can take care of your own storage/data.\n. @seme1 You should never try to make each worker share data with all other workers... You don't want to be in a situation where each worker knows about the state of the entire system - That kills scalability. Also you shouldn't store important state in your workers.\nYou can use something like Redis, MongoDB, Cassandra or SC's own scServer.global object (http://socketcluster.io/#!/docs/api-global) to share data between your workers - The solution you choose depends on how critical that data is. For temporary data like the list of activeUsers, it should be OK to use the scServer.global object. You can specify a mapping function (using global.setMapper()) in case you want to spread your data evenly across multiple stores (for scalability) - Read the docs carefully if you want to understand how this works (it's tricky). More docs coming soon.\nWith pub/sub, it's important to note that you often don't need to know about who is interested in some data in order to deliver that data to them. Channels can make things much easier.\nYou can create channels for any kind of data - You could let each user have a unique channel to represent his 'online_friends' for example... Whenever one of his friends comes online, you can publish data to his channel to let the user know - In this scenario, the backend only has to track friends online status on a user-by-user basis - So no need to keep one massive array of all users who are online.\n@MegaGM You can subscribe to pub/sub channels on the server (see scServer.global http://socketcluster.io/#!/docs/api-global) - To keep the channel private, you need to add a MIDDLEWARE_SUBSCRIBE middleware to block all clients from subscribing to these private channels - That way only server-side processes will be able to subscribe to them. See addMiddleware method in API docs: http://socketcluster.io/#!/docs/api-scserver\nMaybe this is something that needs to be simplified? I'm happy to hear suggestions.\nShould private server-only channels become a new concept? Or maybe this usage pattern (using middleware) should be explained better in the docs? - I think Middleware should be a central part of SC (just as they are in Express).\nI'm putting this in my TODOs list. You shouldn't have to use Redis to share private data between workers :p Thanks for pointing this out.\n. @MegaGM Lol. Thanks for the LONG, enthusiastic response! Record breaking! That's what this community is all about :)))\nYou really nailed the root of the issue with the 'Right way' vs 'Wrong way' - Can I use this idea for a new documentation page to add to the website?\nThe only thing I would add is that you don't necessarily need to use Redis's pub/sub feature to talk between workers (for private channels) (see my post above) - SC already shares channels between workers automatically and you can use middleware to make sure that they are not accessible by clients. Of course SC has no strict rules - It really depends on your specific environment and what's easier for you :)\nYou do need a database of sorts if you want to store persistent data. But since SC can do all the pub/sub stuff on its own, you are not limited to just Redis - MongoDB, Cassandra, or even plain old MySQL or PostgreSQL is fine!\n. @seme1 Yes, I think what you're described in your last post is the best flow!\nYou shouldn't try to make an effort to store all this activeUsers information to map usernames to session ids - It's a lot of work to maintain this array across multiple workers.\nRegarding sockets from the same session going to different workers - That is currently not possible (v1.2.5) - SC does sticky balancing which forces all sockets opened in the same browser (across multiple tabs for example) to be bound to the same worker.\nThat said, I feel that since pub/sub channels were introduced in SocketCluster v1, the idea of a session has become somewhat redundant and people are often tempted to 'keep track of them' which is probably more of an anti-pattern.\nI am working on SocketCluster v2 right now and we are getting rid of the session object in favor of just using channels based on user names because it's so much more powerful.\nOne of the things which SC emphasizes is that if your code doesn't scale across multiple processes (vertically), it also won't scale horizontally across multiple machines either (assuming your product gets to that stage). Conversely, you will find that if your code can scale linearly across multiple processes on a single, big machine using SC (and is capable of recovering from worker crashes), that same code should also be able to scale across multiple machines without requiring any major changes. The two types of scalability require the same programming design patterns so SC encourages you to think about these things early in the project.\n. You need a database (or use the nData memory Store in SC) to keep track of users. Auth tokens should make this easier, but you can't avoid using a data store of sorts (and the solution you choose would depends on you specific needs).\n. When initializing the client, you can use:\njs\nvar socket = socketCluster.connect({\n  // ...\n    autoReconnect: false,\n  // ...\n});\n^ This option is missing from the Docs ( http://socketcluster.io/#!/docs/api-scsocket-client )... Will fix soon.\nThen you can call socket.connect() manually when you're ready to reconnect.\nYou can listen for 'disconnect' event on the socket.\nRegarding the flexibility of the reconnect: If autoReconnect is true (default).\nYou can also specify an object in the connect() method to control how it happens:\njs\nautoReconnectOptions: {\n  delay: 4000, // fixed delay in milliseconds\n  randomness: 1000 // randomness to add on top in milliseconds\n}\n\nThere might be other ways to do the same thing without having to re-authenticate (maybe using cookies to store the token on the client and check for that cookie when the client tries to subscribe to a channel ). I will think about this and get back to you.\n. Authentication is now implemented - It's designed to work seamlessly with the autoReconnect option and also middleware. You can still disable autoReconnect if you like. See website docs: http://socketcluster.io/#!/docs/authentication\n. @MegaGM Thanks for putting this up. I made a post detailing the current plan: https://github.com/TopCloud/socketcluster/issues/49\nAlso, thanks for all the suggestions, I will think about each one.\nNote that v2 will be released alongside v1 so I will put in a lot of effort to make sure that they stay compatible.\nIf anyone else has suggestions, I will be reading through this issue for ideas :)\n. @MegaGM \nI really like these ideas:\n- Server-side channel entity\n- Banning users who belong to a channel (kickOut)\nI like this one, but we need to think about it more:\n- A simple way to find out which users are subscribed to what channel.\n^ This can be tricky because no single worker knows about every socket - Also, what if you're scaling SC horizontally across multiple machines - The socket might be on a different machine (not just different worker)... I will try to see how other pub/sub services do this.\nMaybe we need a separate 'presence channels' concept to make this easier.\nI'm not sure about this one:\n- Combining res.end() and res.error(err) to callback(err)\n^ I like the idea, but sometimes we need to send back a message/data on success too (not just error).\njs\n// Maybe we want to send back a token in response to an event (not just an error)\nres.end({token: 'abc123'});\n. @jmny I would like there to be a native client for both iOS and Android so I think publishing the protocol would be a first step to take - Then maybe others can implement it :p\nI plan to write a base protocol (just to cover the basic emit, pub/sub aspect) - That should be fairly simple and easy to implement... And then I might write an optional 'extension' part to the protocol to cover reconnect behavior and other 'nice to haves'.\nThe protocol will assume WebSocket support (it won't go into things like message framing which belong in the WebSocket layer). On the iOS side, I know some people have been playing around with SC and SocketRocket and it looks promising as a base to handle the WebSocket layer: https://github.com/square/SocketRocket\n. Feel free to open new standalone issues if you have new suggestions.\n. SC v2 will be ready for release in maybe 1 or 2 weeks, but I think it could be a long time before v2 can replace v1 (maybe 1 or more years) - It will depend completely on how users feel about it and also how many users are using v2 compared to v1... Maybe we will have a vote or something.\nv2 will be available for those users who don't care about old browsers but v1 will still be the 'main/official' version...\nExamples where v2 might be preferred:\n- Online multiplayer games where all your users NEED to have the latest browser to get the best experience possible (for a variety of reasons beside WebSocket support; for example 3D capabilities, need for LocalStorage, etc...).\n- Financial trading systems where users won't mind to upgrade browsers (especially if this is an app that they will use on a daily basis as part of their job) :)\n- Some types of enterprise apps where users tend to use cutting-edge browsers anyway and upgrading the browser is possible.\n- Other cutting-edge enterprise-oriented application where fast realtime collaboration is critical (and is a central feature of the app/system).\n- IoT devices that run JavaScript (Node.js) and so the user has control over the client runtime (so they can guarantee that WebSockets are available).\nIn almost all other cases, v1 is the right choice!\nI'm thinking maybe we shouldn't call it SocketCluster v2 for now... Maybe it should be called SocketCluster VX or SocketCluster WS, ...?\nWe can then use it as v2 when the time comes and we are ready to replace v1.\nIt's only a matter of time before all realtime apps and frameworks switch to raw WebSockets, I want SC to prepared for the change - I prefer to be 1 year early than 1 month late!\nAnother benefit of using a simpler WebSocket-only protocol is that it makes it easier to implement clients in other languages (for example to supporting IoT devices which cannot run JS).\n. @pressla Thanks for your feedback. Yea, V2 is much leaner on both the client and server. I definitely want to keep the client small and lightweight. I think the features which are there now in v2 are pretty much as far as I intend to push - The future will be mostly about optimization. I think any new major features could be made into separate plugins or libraries on top of SC.\n. You can run the socketcluster-client on node.js on the server too. you just have to:\n``` js\nvar scClient = require('socketcluster-client');\n// Pass in options object - Same as regular client in browser\nvar socket = scClient.connect(options);\n// Then you can use socket object as you would in the browser\n```\n. I don't know if passport.socketcluster will work with the latest version of SC. I should probably get in touch with the author to check. You could make a pull request if it's not :)\nThe req object in the handshake middleware is a regular Node.js HTTP request object https://nodejs.org/api/http.html#http_http_incomingmessage.\nThe handshake middleware function gets called just before the WebSocket is created, so the WebSocket doesn't exist yet at that point. You can use the req object to do stuff like read headers, cookies (auth tokens) etc... to decide whether or not to allow the client to establish a persistent WebSocket/polling connection with the server. This lets you do stuff like allow the user to connect over WebSocket only after they have logged in with HTTP first... (It prevents unauthorized clients from hogging up connections on your server).\n...You may not necessarily need this feature; another approach would be to allow any client to create a websocket connection with your server (without special authentication) but then you do the access control at the 'publish', 'emit', 'subscribe' stages (using the appropriate middleware).\nWith the second approach, you effectively let anyone connect to your server, but if they want to interact with channels or send events, then they will need to have the right auth token to do that.\nNote that there have been significant changes in how auth works in SC since v1.3.0. Now it's following the JWT (token) specification (https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32) which is the foundation for OAuth. The new JWT engine should play nice with third-party OAuth providers like Facebook... although I haven't yet tried this feature yet ;(\nSo yeah, in summary, you don't have to use the handshake middleware if you don't want to unless you are really worried about denial of service attacks and you're too lazy to monitor your system :p\n. @JasonPaulos Also, the req.socket object refers to the TCP socket (not WebSocket).\nThe purpose of the auth token in SC is to keep the user logged in if their connection crashes or if they revisit the page at a later time - setAuthToken() is something you do after the login has taken place (successfully) by that point your user should already have access to your WebSocket connection.\n. @JasonPaulos The SCSocket object has a request property. So you don't necessarily have to change SC's code. You could use:\njs\nsocket.request.profile\nThe request property holds the handshake HTTP request which was used to initiate the persistent connection (the one you can see from the handshake middleware).\nThis property is not mentioned in the documentation... I will fix that soon.\n. I'm closing this and opening a separate issue regarding passport - The title of this issue is no longer relevant enough. https://github.com/TopCloud/socketcluster/issues/71\n. If anyone wants more info on authentication over HTTP, you may want to check out this thread; https://github.com/SocketCluster/socketcluster/issues/233#issuecomment-254871963. Thanks for the feedback.\nYes, all subscribers will receive the message including the publisher (if the publisher is subscribed to the channel). This is a minor efficiency issue in most cases but if it really matters:\nOne current solution around this is to have named channels for each user which contain the username like 'bob123_test', 'alice3_test', etc... and then on the server, you can use the Global object to subscribe to the generic 'test' channel and watch() for incoming data (let clients publish directly to the 'test' channel) - Then whenever you get new data on that generic 'test' channel on the server, you can re-publish to the appropriate channel of each user who is interested in 'test' (excluding the publisher). You will have to include the publisher's username as part of the data to determine who not to publish to - It does mean you will have to do a database/datastore lookup which is less than ideal. Also it can get more complicated if you have many channels to manage on the server (creating subscriptions on the server adds management complexity because you have to remember to destroy them).\nThe current solution is too complicated, so I'm thinking of maybe splitting the MIDDLEWARE_PUBLISH line on the server into two: MIDDLEWARE_PUBLISH_IN and MIDDLEWARE_PUBLISH_OUT for filtering both inbound and outbound published messages. Right now the MIDDLEWARE_PUBLISH line only deals with inbound publish requests so you can filter out inbound messages before they reach the message broker (store) but not on the way out to individual sockets.\nI will post here when this feature has been implemented and released (hopefully this week). It feels pretty important.\n. @bamoo456 Yes, it will be applied to both.\nIt's already out in the latest version of sc2 (v2.1.3).\nThe changes will be back-ported to v1.3+ - Hopefully by the end of the week.\n. @bamoo456 It's on this page: http://socketcluster.io/#!/docs/middleware-and-authorization\nBut I haven't updated the API pages yet.\nThis weekend hopefully.\n. @mailmevenkat Yes it should also work in SC1.\n. @hedgepigdaniel I can't reproduce - Does it do this for every client? If so, you should try to remove the whole sc2/ directory then:\njs\nnpm cache clean\nthen do a fresh install:\njs\nnpm install sc2\nI made some changes to dependencies but npm may be using the old dependencies from cache instead of getting the latest one when you updated sc2.\nNote that in production, it would be normal to get a few of these notices occasionally if a client has a really bad connection (or one which isn't closed properly) - The ping timeout (60 seconds by default) will kill the socket if that's the case, but in the meantime, the socket could miss some messages.\nIn 2.1.4, SC will by default retry to deliver the failed messages to clients who didn't receive it due to a poor connection - This is to achieve 'guaranteed' exactly-once quality of service.\nHaving 'exactly once guarantee' by default is a bit extreme for most scenarios so in the next version, I'm going to revert the default back to 'at most once' (this is what it was before), you will be able to specify which Quality of Service level in the publish(channel, data, QoS) method. There will be three levels:\n0 - 'at most once'\n1 - 'exactly once guaranteed'\n2 - 'exactly once, in-order guaranteed'\n. @hedgepigdaniel Strange. Note that some proxies could block WebSocket traffic when used over plain HTTP. Using it over HTTPS/WSS should fix the issue.\n. @hedgepigdaniel Actually, I ended up changing the QoS levels idea. Instead there are just two levels: 'at most once' (default) and 'exactly-once-in-order'. I felt that level 1 was redundant when it ended up providing no performance advantage over level 2.\nSo for 'at most once' (same as before):\njs\n// callback is optional\nsocket.publish('channel', data, callback);\nFor 'exactly once in order':\njs\n// boolean and callback are optional\nsocket.publish('channel', data, true, callback);\nIf you intentionally block messages using middleware functions, they will be counted as delivered. If you forget to call next() in your middleware, it will retry until it times out (2 minutes). There is an exponential backoff happening so it doesn't kill the server if lots of deliveries fail.\nI have a lot of documentation updates to do on the website... Arghh.\n. The best way to allow multiple remote SC instances to share channel messages with each other is to hook up your stores (store.js) to a a distributed message queue engine like RabbitMQ or MQTT. See this guide: http://socketcluster.io/#!/docs/scaling-horizontally - Note that if you're using SC2, you don't need sticky load balancing anymore; regular TCP load balancing will do (will update docs soon to mention this).\nYou CAN run the socketcluster-client on Node.js (on the server side) and there are use cases when this might be OK, but if you end up having to maintain a lot of these server-side clients, it can get messy so be careful.\n. You will need to get your SC instance integrated with an external message queue like Redis or RabbitMQ. See http://github.com/topcloud/sc-redis\n. @mnami I'm not sure what your specific use case is but you generally shouldn't try to reference individual sockets - It's not a scalable approach - What if you have multiple servers and the socket you want is hosted on a different machine? It would be physically impossible to get a reference to it from the current machine.\n^ These kinds of issues happen when you try to 'tightly couple' two specific client sockets together.\nSockets should always stay loosely coupled from each other and communicate through channels instead.\nAs a rule of thumb - Any kind of user-to-user communication should be done through pub/sub methods like publish() and subscribe() and watch() (you can call all of these from the client).\nemit() and on() should only be used when you want user-to-server or server-to-user communication. For example, if the user wants to request a particular piece of data from the server, it could emit an event and the server would emit back the response containing the data.\n. @mnami Why do you want to add a proxy? You no longer have to add a local proxy to do load balancing between worker processes in SC2 thanks to its pure WebSocket implementation.\nWebSockets never close the connection at any time so a client will stay bound to the same process on the same server (so you don't need session stickiness anymore - That was the whole point of having load balancers in SC1).\nI don't know why you're getting EADDRINUSE, I can't reproduce this. It means that another process is using this port. Are you using --debug, --debug-workers or --debug-stores on CLI?\n. @mnami It was a convenient side effect of SC1 that HTTP requests from one user always ended up in the same process (HTTP session stickiness).\nHTTP session stickiness is something SC2 tries to move away from because of these reasons:\n- It's very expensive to do HTTP session stickiness - Based on some tests I did, SC2 is more than 10 times faster than SC1 when it comes to handling new connections (this is in part because the extra layer of proxies/loadbalancers required in SC1 is very expensive).\n- HTTP is designed to be stateless. Trying to force it to be stateful (using session stickiness) introduces scalability/security challenges. For example, it's better if you don't allow clients to choose which host/process will handle their request (which is a requirement for stickiness) - Otherwise a malicious user might be able to target a specific process and launch a Denial of Service attack against that process. As soon as you remove HTTP session affinity/stickiness, this problem goes away.\n- WebSocket is naturally stateful and is not prone to denial of service attacks like with sticky-session HTTP. When you need to handle stateful, sequential interactions between a client and a server, you should be using WebSockets (and not HTTP).\nSo in summary, you shouldn't rely on stickiness for HTTP because it's not the most secure approach at scale. I'm not sure what your use case is, but can you find a way to not rely on stickiness for HTTP - Maybe by storing data in a database (or using the scServer.global object)?\n. @MichaelJCole Yes sure, I'll try to add something along those lines in the main README. It's not a hard rule, but it's a good pattern to follow if you want your system to scale easily if/when the time comes.\n. On EC2, most ports are blocked by default - You need to configure your security group to allow them.\n. Is your redis server running on a different machine or same machine? If on different machine, it uses port 6379 by default.\nWhich version of SC are you using?\nHow are you calling watch()?\nOn which object? Are you calling it on the client side or server side?\n. Try to reinstall SocketCluser - Use the latest version of SC1 v1.3.7 or SC2 v2.1.11. There was an issue with one of the SC1 dependencies not too long ago so that could be the issue.\nDo (sc2 example):\nbash\nnpm remove -g sc2\nnpm cache clean\nnpm install -g sc2\nsc2 create myApp\n. Not right now - You have to keep track of it manually. But you don't need to use Redis, since each server-side server socket is only available in the current worker process. You could add your own activeSubscriptions property to the socket object on the server to keep track (for now).\nA subscriptions([includePending]) method on the server-side SCSocket might make sense (right now it's only supported on the client). I'm considering adding all the pub/sub methods from the client-side of the socket onto the server-side of socket so that they'll be available on both sides.\nAlso, I plan to add a way to make it easier to track when sockets join or leave a channel on the server.\n. @mailmevenkat I have added a socket.subscriptions() and a socket.isSubscribed(channelName) method to the server-side SCSocket object: http://socketcluster.io/#!/docs/api-scsocket-server\nThe change was done in iocluster (a dependency of SC) so you will need to 'npm cache clean' before you reinstall SC - Or you can navigate to your sc2 or socketcluster's node_modules/ directory and manually upgrade the iocluster module to the latest version.\n. Can't reproduce. Can you check the version of ioCluster in its package.json file? It should be 2.2.9.\nWhen you're in your project directory try:\nbash\nnpm remove sc2\nnpm cache clean\nnpm install sc2\n. @mailmevenkat Ok, now you can do this safely:\njs\n// Server code\nsocket.on('subscribe', subscribeHandler);\nsocket.on('unsubscribe', unsubscribeHandler);\nThe handlers in both cases receive a channelName string as argument.\nNote that now, the unsubscribe will trigger whenever a socket becomes unsubscribed from a channel (this includes unsubscribe triggered by a disconnect/lost connection so you don't have to handle the disconnect event separately for the purpose of checking which subscriptions were lost).\nI will update the docs on the website soon.\nAlso, I decided NOT to implement all of the pub/sub methods from the client SCSocket onto the server SCSocket - The reason is that you don't want the client and server side of the socket to fight over when to subscribe/unsubscribe/publish, etc... It could be a maintainability nightmare, especially when you consider the latency between them.\nThe control has to be given either to the server or to the client (but not both). The client-side is a much better place for this control in my opinion (it's more readable and explicit). The server's job is to decide whether or not to allow or block various client actions using middleware - The client is still in charge of how the data that flows in and out of the browser - The server effectively just enforces permissions.\n. This will be backported to SC1 soon but right now these changes only affect SC2.\n. @nelsonzheng Really well chosen quote! I don't want to implement a quote rotator, because whatever other quote comes up won't be as good as this one :p\nI merged this in manually and made minor changes:\n- I got the links working (I temporarily removed the demo one until we actually have demos to show)\n- I changed the title from SocketCluster.io to just SocketCluster\n- I added a GitHub star button\n- I added log messages back to console to encourage people to play with SC\n. @nelsonzheng Yes the smiley face thing was cheesy.\n. @woubuc What is your version of SC2 client and server?\nNote that you cannot use the SC2 server with the SC1 client (socketcluster-client). You need to make sure that the client inside node_modules/ is sc2-client (the two versions are not compatible with each other's servers).\nSome notes:\n- Unlike SC1, SC2 is always WebSocket - So you don't need to specify the transports option at all (both client and server).\n- SC2 doesn't use LoadBalancers - The workers take turns to pickup connections directly from the port (this is possible thanks to the pure WebSocket approach) - So you don't need to specify the 'balancers' option.\nYou should probably specify the workerController path like this:\njs\nworkerController: __dirname + '/server.js'\nOtherwise, if you run your instance from a different directory, the path will be incorrect. Using __dirname ensures that it is relative to the current file's directory.\nI don't think any of these things explain the issue you're getting though. Is this parser error being shown on the client or server? Is there any stack trace?\n. @woubuc The other thing is that I haven't tested the server-side with CoffeeScript before, but I don't see why that would be a problem. Does the sample app work for you as is?\n. @woubuc The sc2-client is here: https://www.npmjs.com/package/sc2-client\nWhen you run\nYou shouldn't have to think about it though if you run:\njs\nnpm install -g sc2\nsc2 create myproject\n^ The 'sc2 create' command automatically bundles sc2/ and sc2-client/ inside your node_module/ directory so you don't have to install them separately.\nI'm thinking of making SC2 the official version of SC because the vast majority of people seem to be using it instead of SC1. There has been issues with other people mixing up the clients/server versions, so this is definitely a big problem.\n. @woubuc showing the version number in the console is a good idea!\n. Done\n. Did you install SC using npm?\nWhen you install using:\nbash\nnpm install -g sc2\nsc2 create myproject\n^ SC will setup everything for you (it will take the socketcluster.js client and put it inside your sample app folder for you). If you setup by cloning the Git repo or if you don't install with the -g flag, then you will have to get the client and server separately and the sample app won't work by default - You will have to get the client from https://www.npmjs.com/package/sc2-client and put it inside the sample/public/ directory.\nI didn't want to put the client script inside the server/sample/ directory because it's annoying to have to update whenever the client changes.\n. The --debug-brk=<port> command line argument is not yet supported, but it's definitely a feature I would like to add. As you suggested, we will have to make sure we pass on the flag to spawned workers.\nI will look into this tomorrow.\n. Feel free to post your findings (or pull request) if you decide to investigate this yourself.\n. @delaneyj Are you using node-inspector? I will try to get node-inspector working this week.\nFor my own testing, I have been using node-webkit-agent https://github.com/c4milo/node-webkit-agent to check for memory leaks - It doesn't require you to set the --debug-brk flag (it's easy to get working with SC - You just have to require the module in your worker/workers) but it's mostly for checking memory leaks and CPU utilization - It doesn't let you do step-by-step debugging like node-inspector.\n. @delaneyj In the latest releases of socketcluster (both v1 and v2), children now inherit all command line arguments from the master process - So all workers should now receive the --debug or --debug-brk flags.\nNot sure how that will play with Webstorm's debugger. Let me know.\n. ... Hmm actually I didn't think this through properly. The --debug-brk flag carries a port number with it - So it will have to be unique for each worker.\nMaybe in this case I will need to add a new option like debugPorts inside server.js where you can define the default debug ports for each worker (based on worker id).\nMaybe it should also log the debug port for each worker in the console when master is launched using the --debug-brk option to make it extra clear.\n. @delaneyj Yes. The incremental approach might be the best and easiest one to implement.\n. @delaneyj @IngwiePhoenix - SocketCluster 2.2.13 (https://www.npmjs.com/package/socketcluster) now supports debugging using node-inspector (https://github.com/node-inspector/node-inspector) and probably others.\nFirst, make sure that you are using Node.js v0.11.0+ (preferably the latest stable version).\nMake sure node-inspector is installed:\nbash\nnpm install -g node-inspector\nThen run it in a console window using:\nbash\nnode-inspector\n^ You have to keep this one running in its own console (or in the background).\nTo debug, you need to have a fresh console open. You can now pass a --debug-workers or --debug-stores argument when you run your server.js file using node. Make sure you add the new flags after the server file name or else it won't work.\nE.g.\nbash\nnode server --debug-workers\nor\nbash\nnode server --debug-stores\nThe default debug port for the first worker is 5858, the second worker is 5859, ... (it increments by one) - You should see a debug message get printed to the console telling you which debug ports are open.\nTo open the debug console for the first worker, you need to type this address in your Chrome browser (debug port 5858):\nhttp://127.0.0.1:8080/debug?ws=127.0.0.1:8080&port=5858\nYou can also provide a custom starting port for the first worker (subsequent workers will +1 increment):\nbash\nnode server --debug-workers=5999\nThis applies to stores too:\nbash\nnode server --debug-stores=5999\nIf you want to debug your master process (server.js), it's the normal\nbash\nnode --debug-brk server\nNote that the order matters in this case too (this time --debug-brk needs to go before the server argument)!\nWhen you're debugging a worker, you may want to make it break on a particular line or else it will go to the end (idle). To do this you need to add a debugger; statement in your worker.js code where you want it to stop - There is no --debug-brk-worker option (node.js doesn't appear to support debug-brk with the cluster module) so you have to use debugger statements if you want it to stop in a particular place.\nNote that if you're in a worker, you will have access to a global worker object so you can interact with your server and do things like worker.global.publish('pong', 'This is a message for the pong channel') to interact with your clients directly from your worker. (You don't need to add debugger statements in your code to access this feature - The worker variable is exposed globally so you can access it from any scope).\nIn the same way, when you're debugging a store process, you will have access to a store object and you can also interact with the store directly through the debugger just like the worker.\n. This will be backported to SC1 this weekend or sometime next week.\n. @IngwiePhoenix I will investigate more later - Part of the problem is the way Socket.io and SocketCluster handle 'acknowledgements' differently. That is:\njs\n// Client code\nsocket.emit('myevent', myData, callbackToHandleEventResponse);\nIn SC, the callback is in the form:\njs\ncallbackToHandleEventResponse(err, data)\nin Socket.io, it is:\njs\ncallbackToHandleEventResponse(data)\nIn SC, if you pass a callback (optional), it means that the server has to explicitly send back something or else it will timeout and pass an err object as the first argument to the callback. In Socket.io - It doesn't timeout and the first argument is just the data (not sure what the implications of  the socket.io approach are - Either it leaks memory holding on to that callback forever or it quietly disposes of the callback after a timeout).\nSee http://socketcluster.io/#!/docs/handling-failure\nvs\nhttp://socket.io/docs/#sending-and-getting-data-(acknowledgements)\n. @IngwiePhoenix EADDRINUSE happens when another process is already using a port. Make sure no other SC instances are running at the same time.\nI will check the host issue later today.\n. @IngwiePhoenix There was no way to specify the host in listen() - In the next release, you will be able to specify a host property when you instantiate SC using new SocketCluster({host: 'myhost.com'}).\nAre you running the app with the --debug flag? This could explain the EADDRINUSE.\nI'm currently working on improving the debugging experience in SC - Right now it's a bit tricky dealing with multiple processes - They're all trying to bind to the same debug port.\nI should have all this fixed in the next day or two.\n. @IngwiePhoenix v2.2.13 should fix the EADDRINUSE issue.\n. You should look at how SC-Redis does it (This file should have all the logic you need: https://github.com/TopCloud/sc-redis/blob/master/index.js). SC handles a lot of the complexity there.\nWhen you're hooking SC to an external Message Queue, you shouldn't think about end-clients at all. You should focus purely on satisfying the needs of your workers. Your workers are responsible for figuring out how to deliver messages to clients and your code is only responsible for delivering messages to workers.\nNote that the store.on('subscribe', ...) event triggers when a worker process itself asks to subscribe to the channel on the store (this event is independent from an end-user/client subscribing to a spcific channel).\nFor example, let's say you have two clients; ClientA and ClientB and both of them are connected to Worker1 and let's say you have one store Store1 which manages all channels within your system.\nAssume that ClientA asks Worker1 to subscribe to the channel 'foo'.\nWorker1 handles this and decides that it needs to subscribe itself to 'foo' on Store1 in order to start relaying the messages from that channel back to ClientA. To do this, it creates a new subscription to 'foo' on the store - The store.on('subscribe', ...) handler is triggered.\nNow ClientA will start receiving messages on 'foo' from Worker1 which is itself getting them from Store1.\nThen assume that ClientB also asks Worker1 to subscribe to the channel 'foo'.\nWorker1 handles this and notices that it is already subscribed to 'foo' on Store1 - Therefore it doesn't need to subscribe again :) So the store.on('subscribe', ...) handler does NOT run this time.\nSo basically events on the store are based on the worker's needs (not the end-client's).\nSame with 'unsubscribe'; the 'unsubscribe' event on the store will only trigger when the worker itself doesn't need that subscription anymore (this will only happen if ALL of its end-clients unsubscribe from that channel - Or they become disconnected).\nThe way the 'subscribe' and 'unsubscribe' events occur on the store is efficient in that a worker will only subscribe/unsubscribe to/from events which they actually need to - There is no wasted bandwidth/CPU.\nWhen you add more stores, what happens gets a little bit more complex (although this shouldn't affect your Message Queue 'hook' code in any way). When you have more than one store - Each store handles a subset of all channels. So basically if you have 2 stores; one of them will handle half of all the channels in your system and the other one will handle the other half - Basically each store has no idea about what the other half of channels are (it can't even publish to such a channel - Each store can only publish to their own channel).\n. You can interact with a store from the worker using the Global client object (it behaves mostly like a normal client socket except that it exists on the server: http://socketcluster.io/#!/docs/api-global). The Global client can be accessed from your SCServer object in your worker.js file (scServer.global property).\nFor most cases though, when you want to hook up SC to an external MQ, it's better to put that logic inside store.js - It's the most efficient place and requires no round trips.\nAre you hooking it up to RabbitMQ to scale SC across multiple machines or you just want to integrate with another system on the backend (synchronizing with channels from RabbitMQ)?\n. @mlmarius First of all, don't feel bad if this seems difficult (distributed message queue integration is about as difficult as it can possibly get).\nFirstly, this code:\njs\n var rabbitChan = scServer.global.subscribe('testchan');\n    rabbitChan.watch(function(data){\n                console.log('worker received testchan data');\n    });\nshould be moved outside of the 'connection' handler block (just above it is fine) - Otherwise it will keep adding new watchers every time a new user/client connects to your server (this is probably not what you want - And if you do decide to go down that path, you need to remember to unwatch them afterwards when each client disconnect - But I would advise against this approach - It always better to just deal with the Global client independently) - Also when your second user/client will connect, your global client will already be subscribed to that channel, so there is no point subscribing to it again.\n^ This issue above is probably not the root of the problem though (it should still work in theory, but you would end up getting duplicate messages after multiple clients have connected to your server).\nYour store.js code is not ideal from an efficiency point of view, but at first glance it looks like it should still work (theoretically, you should be able to see messages from RabbitMQ inside your worker.js). To try to figure out why it doesn't work, try to put a console.log(...) inside your RabbitMQ callback just above var topic = msg.fields.routingKey; to make sure that the message is in fact being received from RabbitMQ - Hopefully that is the issue.\nThe reason why your store.js code is not ideal (efficiency-wise) is because it pretends that there is a single store process. \nIf you had 5 store processes, it would create 5 RabbitMQ clients, each of which would subscribe to the same RabbitMQ channel. In reality you only need one of your stores to be subscribed to that RabbitMQ channel (not all 5 - It's wasteful since only one of your stores will be responsible for the 'testchan' channel - The other stores will ignore it). \nTry to change your store.js code to this (this is kind of rough but it's much more efficient):\n``` javascript\nvar rabbitCon = require('./rabbitCon');\nmodule.exports.run = function (store) {\n  console.log('   >> Store PID:', process.pid);\n//callback when rabbit has messages for us\n  var cb = function(msg){\n            var topic = msg.fields.routingKey;\n            topic = topic.substring(topic.indexOf('.')+1);\n            var msgString = msg.content.toString();\n            console.log('publishing topic: '+topic+' | '+msgString);\n            store.publish('testchan', msgString);\n    }\nstore.on('subscribe', function (channel) {\n    // This if block will only run on the store process which is responsible for the 'testchan' channel.\n    // the other store process will never receive this subscription - SC automatically decides\n    // which store process should handle which channel (based on hash of the channel name).\n    if (channel == 'testchan') {\n      var rql =  new rabbitCon('amqp://bunnyuser:bunnypass@localhost:5672','topic1', 'socketcluster.*', 'socketcluster');\n      rql.connect().then(function(rabbitConnObj){\n            //console.log('rabbit conn now complete');\n            rabbitConnObj.setCb(cb);\n      });\n    }\n  });\n};\n```\n. @IngwiePhoenix Yes, good idea. I will look into it this weekend.\n. @IngwiePhoenix I would prefer to wait a bit longer before allowing HTTP2 support in SC.\nI spent some time reading discussions in Node.js issues section and it seems that it's still undecided how and when HTTP2 will be integrated into core.\nI think we could in theory add support for HTTP2 before it becomes part of Node.js core, but looking through the issues list: https://github.com/molnarg/node-http2/issues - It seems like the http2 module is still in its early stages. I will keep an eye on the project and when it looks like it's stable enough for production use, we can allow people to use it instead of the regular http1.1 - Probably by setting the prototocol option of SC to 'http2'.\nWe can leave this issue open as a reminder to check up on it from time to time - It might not be too far off.\n. At first glance, it looks like it may be possible to make a small change to SC to allow providing a custom server object (this could be a HTTP2 server or SPDY server or whatever).\nI will try to look into this sometime next week.\n. When instantiating the main SocketCluster instance (in server.js), you can now pass an optional 'httpServerModule' - It should be a string (module name/path). So if you want to use the http2 module, you can set it to 'http2'. You can specify any module but it has to conform to the standard Node.js http API (which http2 does).\nNote that http2 doesn't appear to work with express yet though, so if your SC worker uses express then it will throw a weird error. See https://github.com/molnarg/node-http2/issues/100\nUse at your own risk :p\n. @mastayoda That sounds interesting.\nYes, right now SC has its own process manager - It's all integrated in SC since there needs to be some coordination when launching and re-spawning various processes.\nYou can monitor using OS commands. Here are some of the most popular ones for Linux: http://www.tecmint.com/command-line-tools-to-monitor-linux-performance/\nSocketCluster gives you the PID for all worker and store processes on startup, so you can watch for these when using a command like top.\nAlso, there may be node.js modules that you can bind to your worker processes from inside your actual code and will let you track various metrics.\nThere may be plans to integrate with PM2 in the future but don't count on it yet.\n. If you're running SCC on Kubernetes, this will be supported automatically. https://github.com/SocketCluster/socketcluster/tree/master/kubernetes\nI've done some tests using Rancher and the Rancher control panel lets you see how much CPU any Docker container is using. I will add more docs about this in the future.\n. @mnami Nice find. Fixed.\nIt happened when you used the default socket path/URL '/socketcluster/'.\nNote that I took the opportunity to rename the method to worker.getSocketPath() instead of getSocketURL() - URL kind of implies that it's a full URL, but in fact it's just a relative path.\ngetSocketURL() still works but it has been deprecated and will be removed at some point in the future.\n. It's next on my TODO list.\n. I'm currently making some changes to authentication (making it localStorage-based instead of cookie-based, also it will be fully customizable on both the client and server) so I need to finish that before moving on to passport... Sometime this week hopefully :(\n. @rrNuvoPoint Thanks for mentioning this!\nSatellizer looks like a very good solution to this problem.\n@MegaGM @vnistor \nNote that you can do Authentication either over HTTP or over WebSockets.\nAssuming I understood satellizer correcrly, a typical HTTP auth flow could be:\n1. Use satellizer to open a new Facebook OAuth window and let the user sign in\n2. Let satellizer send the resulting authorization code to the server at a specific URL (HTTP request)\n3. The server can then check that auth code with Facebook\n4. If the auth code is valid, then you can generate a new JWT auth token on the server and send it as a cookie to the client by setting the 'Set-Cookie' HTTP response header (for example).\n5. Do socketCluster.connect(...)\n6. After the socket connects, you will be able to access the JWT token from socket.request.headers.cookie (WebSockets)\n^ Alternatively, you could pass the JWT token as a query parameter (in the URL) if you don't want to use cookies. But note that there are some drawbacks to this approach. See related article: https://facundoolano.wordpress.com/2014/10/11/better-authentication-for-socket-io-no-query-strings/\nA typical WebSocket flow could be:\n1. Call socketCluster.connect(...)\n2. Use satellizer to open a new Facebook OAuth window and let the user sign in\n3. Get the auth code back directly on the client-side (don't send directly to server via HTTP)\n4. You can then send the code to the server over WebSockets using something like socket.emit('authFacebook', facebookAuthCode)\n5. Then on the server you can do socket.on('authFacebook', handlerFunction)\n6. Inside handlerFunction, you can check the auth code with Facebook and if it's valid, you can provide the client with a new JWT token - SC provides a method to make this easy (example) socket.setAuthToken({username: 'bob123'}) \n7. Any time after this (usually inside middleware functions), you can check if the client has a token by calling socket.getAuthToken()\n8. If your token has a short expiry, remember to send the client a fresh one from time to time while they are still connected (renew the token). You can call socket.setAuthToken(...) as often as you like - Each time it will send the client a fresh token and reset the expiry\nThe second flow (WebSocket based) is currently the easiest way to do OAuth since SC manages the JWT tokens for you (you don't need to know anything about JWT to use it). If you choose the HTTP approach, you have to generate, sign, parse and validate the JWT token yourself which is more work.\nI will try to make it easier to generate the JWT token as part of the HTTP flow too so that should make the first flow easier.\nThen once that's done I will think about how to integrate with PassportJS.\n. Since SC v2.2.35, you can access the default AuthEngine, from worker.auth inside your workerController. This allows you to sign (create) tokens and also verify tokens provided by clients: https://github.com/SocketCluster/socketcluster/blob/master/lib/auth.js - This may be useful if you want to do custom authentication over HTTP but don't want to write your own token signing/verification engine.\n. I think satellizer seems like the best solution since SC is designed to work with JWT tokens.\n. @mnami A socket cannot subscribe to a channel before it is connected to the server otherwise it would make authorization impossible to do via middleware (you can't authorize a subscription request from a socket which doesn't exist yet - Middleware functions always require a socket as argument).\nWhat is your use case?\n. @fanweixiao Yes, that was caused by some old code carried over from SC1 - As you suggested, it was overwriting the DEBUG env variable in the code which is bad.\nIt's been fixed in v2.2.22.\nThanks for reporting!\n. @orecus The doc was out of date - It's been fixed: http://socketcluster.io/#!/docs/handling-failure\n. @orecus Sorry about the confusion and thanks for raising this issue.\n. @madwill There are many ways to do this.\nAlso note that the store (nData) isn't the only way to store data, you can also use a database of your choice or Redis (may depend on your scalability needs). If you want to scale SC across multiple hosts, then you need to store that data in a scalable database like MongoDB, Cassandra or perhaps an SQL one - Stores aren't yet automatically scalable across multiple hosts (although you can certainly do your own replication if you like).\nIf you want users to listen to shared channels then you shouldn't have the username be part of the channel name. Only if it relates to that user specifically (maybe that's your case?).\nIf you want to keep track of logs, you should do it from the server side.\nThere are several ways to do this.\nHere is some server code to give you ideas (note that I haven't tested this code) - In this example, we have a chat room about 'cats':\n``` js\n// Server code\nwsServer.on('connection', function (socket) {\n  // ...\n  socket.on('POST cats', function (message, res) {\n    // Append the message to a room_cats array inside the store\n    // The array will be created automatically if it doesn't already exist.\n    // Note that the res callback is in the form res([err, data]) which happens\n    // to match the signature required by the nData add method:\n    // callback([err]) https://github.com/topcloud/ndata#add\n    wsServer.global.add('room_cats', message, res);\n// Publish the message globally to the cats channel so that\n// all client subscribers will receive it\nwsServer.global.publish('cats', message);\n\n});\n// In case client wants to get the whole list from scratch\n  socket.on('GET cats', function (message, res) {\n    wsServer.global.get('room_cats', res);\n  });\n  // ...\n});\n```\nSo then on the client side you can have:\n``` js\n// Client code\nvar catsChannel = socket.subscribe('cats');\ncatsChannel.watch(function (message) {\n  // Display any new messages published to 'cats'\n});\n// The 'status' event gets triggered directly after the socket \n// connects (including reconnects due to failed connections)\n// so it's a good place to request entire lists from scratch.\n// It's also a good way to make sure that you haven't missed any messages\n// while your connection was cut.\nsocket.on('status', function () {\n  socket.emit('GET cats', function (err, messageList) {\n    // ... render the list of all messages\n  });\n});\n// ... This would probably run from an event handler of sorts\n// Send a new message to cats channel\nsocket.emit('POST cats', 'I like cats!', function (err) {\n  if (err) {\n    alert('Failed to post message about cats because of this error: ' + err);\n  }\n});\n// ...\n```\nYou will probably need a way to clean-up/manage the cats list in the store so that it doesn't get too long.\nAlso, you don't need to use the 'GET', 'POST' convention if you don't want - There are no formal conventions for doing this yet but hopefully it illustrates the point).\n. @madwill socket.io-ndata is an old project. fent/clusterhub is also kind of old - Both of these are meant to work with the old version of Socket.io and none of them are scalable.\n. @bicho The problem is not load balancers. They do not have to be sticky.\nThe problem is that you want to share channels between multiple remote SC instances.\nTo do this, you need to hook them up to a backend pub/sub system or message queue like Redis or RabbitMQ. See Redis example: https://github.com/socketcluster/sc-redis\nCheck out the guide: http://socketcluster.io/#!/docs/scaling-horizontally\n. @gabrielbiga socket.request.headers.cookie works for me.\nYou need to make sure that the cookie is set before the client socket starts connecting. In SC2, there is just one HTTP request at the start so you need to make all your cookies are set on the client by the time that request is made. Note that cookies are no longer used as part of authentication so it wouldn't show up there. Let me know if you find a solution or a way to reproduce.\n@MegaGM The socket.cookie shortcut was removed in SC2 - I think it's better if the user gets it from the socket.request.headers.cookie and does their own parsing if they need to - This keeps SC lightweight.\n. The docs are valid for both v1 and v2 - The general pattern hasn't changed. I should probably update that page to make it sound more current.\nYou can setup a channel for each user and also have group channels shared between multiple users. So you could have a channel called 'web_developers' and all users who are web developers could subscribe to it. I expect that the vast majority of apps will have more than one channel per client, in fact SC lets you have up to 1000 simultaneous channels per client by default (you can configure this to be even higher if you need).\nSC is efficient about how messages are delivered so you don't have to worry about using too many channels.\n. @bamoo456 You can have any number of channels you like :) \nSC has a default upper limit of 1000 per socket which should be plenty. You can change the upper limit using the socketChannelLimit boot options here: http://socketcluster.io/#!/docs/api-socketcluster\nYou can subscribe to channels at any time (even if the socket has gone offline) - In this case, the channels will be put in a 'pending' state.\nAs soon the socket reconnects, any channel which was 'pending' will automatically be subscribed to the server and once this is done, their states will change to 'subscribed'.\nRegarding efficiency, SC will use 1 WebSocket frame for each subscription. WebSocket frames are very lightweight so even if you did try to establish 1000 subscriptions at the same time, a single worker process should be able to handle that without too much trouble (provided that you don't have too many sockets subscribing to all 1000 channels at the exact same time - That's part of the reason why the reconnect delay is randomized with exponential backoff).\nYou probably don't want to have 1000 subscriptions per socket though, for security reasons, you may want to make the socketChannelLimit lower and try to unsubscribe to old channels that you no longer need. The client will emit an error if you exceed the socketChannelLimit.\nOne useful thing to do is to have one channel for each 'REST' endpoint in your app - So you can update your front-end views whenever your backend data changes. You can checkout the sample app I'm building to see how this can be done (still work in progress, but it's close to ready): https://github.com/socketcluster/sc-sample-inventory\nSo yes, SC is designed for having many channels per client. It's also part of the reason why SC2 has moved away from engine.io and HTTP polling fallbacks - In such case, each subscription could take up to 1 HTTP request each (and 1000 HTTP requests is a lot for one worker to process in a short time).\nI will try to publish the Polymer <sc-socket> and <sc-model> components independently when this is finished (along with a backend 'realtime REST' plugin to match). Polymer components are really cool because when you remove an sc-model tag from the DOM, the related SC channel will automatically be unsubscribed.\n. @IngwiePhoenix They actually act as both 'stores' and 'message brokers' - I've considered renaming them to brokers, but it's not completely accurate either because you can in fact store data inside them. Feel free to use that feature.\nRedis is often referred to as a 'store' even though it also provides pub/sub features - Because of this, I decided to keep the word 'store' - You can think of them as 'stores for holding and managing channel subscriptions' but you can also use them to store other kinds of data.\nSC stores are nData servers: https://github.com/socketcluster/ndata - nData is heavily inspired by Redis but it runs entirely in Node.js (the other main difference is that it lets you store deep, hierarchical/document data).\nThe downside with nData is that it doesn't currently allow you to easily persist data to disk - So it's only meant for volatile in-memory data - It's perfectly OK to use Redis (or any other Database) alongside nData. You can access the nData stores though the scServer.global object (see http://socketcluster.io/#!/docs/api-global) - The Global object actually represents a cluster or nData clients so you can interact with multiple stores at once.\n. @IngwiePhoenix Thanks for the feedback. I renamed 'store' to 'broker' throughout SC as you suggested. Hopefully it makes more sense - Hopefully developers won't feel weird about using their own databases/datastores with SC anymore because we want to encourage that.\nBrokers are useful for routing messages between SC workers and also for storing data in-memory (to allow sharing between multiple workers) - So the word 'broker' seems ideal.\n. There is a small one with text from the website: http://socketcluster.io/assets/img/logo.png\nOr you can get the logo on its own:\nhttps://camo.githubusercontent.com/1e6a52dbf401b60f5979aec6416967a42aab8e53/68747470733a2f2f7261772e6769746875622e636f6d2f536f636b6574436c75737465722f736f636b6574636c75737465722f6d61737465722f6173736574732f6c6f676f2e706e67\n. @mscdex Yes, that's actually completely useless. Thanks for spotting this. Fixed.\n. @Llorx the general pattern which I follow with SC (when dealing with data instead of messages) is that immediately after connecting (or reconnecting), I use pub/sub to subscribe to changes in the data and then load a fresh snapshot of the data - This works with data because I keep it stored in a database so getting that fresh copy of it is possible.\nYou could use the same approach by storing messages in an external database (even if only for a minute, or only for servers which are about to be shut down).\nThe other approach is to open a second socket (concurrently) from the client while the the first one is being shutdown but it seems like a bit of a hack.\nEDIT I made a change in my answer: Upon reconnecting, you need to establish a subscription before you request the snapshot of the data or else you would lose any message which was sent while the snapshot was in the middle of being retrieved.\n. @leedium On the server side, you have to use the Global client scServer.global see http://socketcluster.io/#!/docs/api-exchange - It behaves similarily to the socket on the client side. You can just go var myChannel = scServer.global.subscribe('myChannelName');\n. @leedium The client will not try to subscribe to a channel which is it already subscribed to so it won't even hit the server in this case (so your middleware wouldn't run in this case - And so your if condition will never be false).\nYou shouldn't need to call socket.global.subscribe() or socket.global.unsubscribe() inside your middleware - SC already handles the subcribe/unsubscribe logic for you. Middleware is just there to allow you to accept/request particular events.\nYou still shouldn't get duplicate messages though (unless of course you have two watchers on the same channel) - I will check if this is an issue.\n. @leedium I couldn't reproduce your issue. Maybe it's something somewhere else your code (maybe in your worker.js)?\nAlso, calling socket.global.unsubscribe() does nothing - The first channelName argument is required - Right now SC tries to unsubscribe from a channel with the name: undefined (so it does nothing). I should change this to throw an error instead.\nThere is no quick way to unsubscribe from all channels in SC - This feature was too dangerous. If you want to do this, you can get a list of channels and use a for loop to unsubscribe from each one.\n. About your question regarding whether socket.global.subscribe(), global.publish(), etc... will pass through middleware - The answer is no - Any code which is running on the server has full access privileges so it shouldn't have to pass through middleware.\nMiddleware only sits between clients and the server.\nLet me know if you managed to resolve this issue. Thanks for raising an issue :)\n. @seiyria The global API was renamed to Exchange. http://socketcluster.io/#!/docs/api-exchange\n. I decided not to fix this for now due to consistency reasons - SC methods tend to handle cases like null/undefined parameters quietly without throwing errors (provided that doing so doesn't carry any negative side-effects).\nBasically if you unsubscribe() without any arguments - Right now SC tries to unsubscribe from the undefined channel which doesn't exist. I'd prefer not to treat this case as an error because unsubscribing from an undefined channel name doesn't cause any negative side-effects.\n. @mastayoda SC doesn't currently support horizontal elastic scaling, but of course it does support elastic vertical scaling. It should be fairly easy to implement elastic scaling for the number of workers, but it will be tricky to implement elastic scaling for store processes.\nEach store process holds a somewhat equal portion of all channels used throughout SC, the Global server-side client (responsible for interacting with the cluster of stores) uses a hash function of the channel name to decide which specific store should handle what channel. If you change the number of stores at runtime (and they already hold some subscriptions internally) - Then the hash function will need to be updated and that will cause existing mappings to be wrong. We would have to come up with a strategy to either redistribute the channels according to the new mapping or do some kind of redirection (I think redirection is the approach Redis uses).\nIt would be nice to implement it at some point. That said, as far as I know, the number of CPU cores on an instance cannot change at runtime, so having a fixed number of processes shouldn't be too much of a problem.\n. We now have released Kubernetes config files so you can now run and scale SC horizontally on any Kubernetes infrastructure. See https://github.com/SocketCluster/socketcluster/tree/master/kubernetes\nI plan to release documentation about this in the near future.\n. Ok done - socketcluster v2.3.1\n. This is an issue with the client so I'm closing this issue in favor of this one: https://github.com/SocketCluster/socketcluster-client/issues/13\n. @mlmarius I just made an update to SC v2.3.4 which makes communicating between workers and master much easier. See sendToMaster() method here: http://socketcluster.io/#!/docs/api-scworker\n. Generally though, it's better if each worker sends stats individually to your New Relic (or to whatever other monitoring service you might be using). Adding runtime logic to your master process can be dangerous (unless you're running your whole SC instance a process manager like Forever or PM2).\n. @1manStartup It is by design. If you publish a message to a channel which doesn't have any subscribers, that message will still reach the broker process but it won't go any further.\nThere should still be some load on the worker and broker processes but it should be less than if you published to a channel which did have subscribers.\nIf you have multiple brokers and you publish to a particular channel from a worker, the message will be sent to one of your brokers (chosen based on a hash of the channel name) that way each broker only handles a subset of all possible channel names (to spread the load evenly between them).\nEvery message published has to go to a broker (the broker then decides which workers to route it to based on their active subscriptions). In practice, if you only have a single worker, we shouldn't really need to go through the broker at all (since there is only one possible worker to route back to) but right now it will go through it anyway (I haven't optimized for this case) keeping the behavior consistent regardless of the number of workers is nice, but I guess if we added a special setting like disableBrokers: true then we could optimize for the single-worker case, but I don't know whether or not it's worthwhile.\nBroker and worker processes communicate using Unix domain sockets on POSIX systems or named pipes on Windows so it should be more efficient than TCP.\n. @batazor What do yo mean by that?\n. The idea of workers is that they share the same code so if you only want one worker to do something, u should check worker.id inside worker.js. The first worker's id will always be 0, the second one will be 1, then 2, etc... depending on how many workers you have.\n. @KCypher13 Thanks for the positive feedback :)\nYes, modifying published data inside your middleware function is supported. After the publish action is processed by the SC server, all subscribers should be able to see the id there.\n. @vnistor Whoops. Fixed in v2.3.9\n. @waltergms In SC, watchers are functions which handle data which was published to a particular channel. Watchers are not users although I understand how the wording might be confusing.\nIf you're trying to implement user presence. SC doesn't expose any methods for finding out who is listening to a particular channel - This is because there is no single correct way to implement this.\nYou will need to keep track of which users are subscribed to which channels by storing the channel => username mappings in a database/datastore of your choice.\nYou can use JWT tokens to keep track of a user's sockets and channel subscriptions. You can also create special channels to notify clients when a new user joins or leaves a specific channel (or a particular group of channels...). There are many different ways to implement this depending on your requirements (each with its own pros and cons) so SC doesn't want to constrain you to any specific technique.\n. I'm hoping that in the future, there will be open source plugins for SC which will implement various user presence strategies on the backend (e.g. maybe supporting different kinds of databases) and developers will be able to just install the one which make sense for their project instead of having to implement one from scratch.\n. Yes, you should store that data in a database/data store - Otherwise your solution won't scale across multiple workers and that means it also won't scale across multiple hosts.\nA nice side effect of using SC is that if you can get your code working using multiple workers, it will generally also work using multiple hosts without having to change any code (mostly just changes to configs).\nIf your code scales across multiple processes and later you want to scale it horizontally across multiple hosts, it's usually just a matter of moving your database to its own machine or maybe sharding it but your code itself won't have to change.\nSC tries to encourage developers to think of their system as a distributed one from the beginning in order to avoid nasty surprises in the future when the time comes to scale out (if it comes to that).\n. @kaviproject This works fine for me. Maybe try console.log(socket.remoteAddress) instead of console.log(self.socket.remoteAddress)?\n. You should be running node-inspector in the other window instead of node-debug worker.js.\nWhen you run SC with node server --debug-workers - node-inspector will give you a URL which you can use to debug from Chrome.\nSee this guide: http://socketcluster.io/#!/docs/debugging\n. @kaviproject You should try to follow all the steps here exactly: http://socketcluster.io/#!/docs/debugging\nYou need to run the node-inspector command in a separate console window or in the background. It needs to stay running throughout the entire debugging session.\n. Reopen if this is a legitimate issue (using node-inspector can be tricky).\n. @waltergms Did this issue happen in production?\nNotices like the first one can happen in production if a client's computer goes to sleep for example (their connection could timeout without closing the connection properly) - In this case this is normal and you should expect some of these while running in production if you have lots of users. If this issue happened during testing, I would like to know what steps you used so that I can reproduce it.\nThe second one (Error) means that you are trying to write to a socket (which you have a reference to) after it has been disconnected. If you listen to socket.on('disconnect', handler) and make sure that you don't try to write to the socket again after this then you shouldn't get the error - If you do then that's a bug that needs to be fixed.\nIf you want to be really safe, you can check if (socket.state == socket.OPEN) before emitting events to a socket.\nLet me know if this helps.\n. @waltergms Yes, you can keep track of socketIds and users (e.g. keep track of them using an Object), but this approach is likely to become a problem as soon as you have to add a second worker or host - I would generally recommend against it but it depends on the use case.\nYou're not using socket.emit() from the server side at all?\nIf not then I will investigate socket.global.publish to try to identify if there is an issue there.\n. Interesting. In theory it may be possible that a client could disconnect just before the server sends a response to the event from the client.\n. @waltergms I tried different things like turning off my connection (and intentionally causing pong timeout) before doing a publish and also just before responding to a client event but I wasn't able to reproduce the second error.\nIf you're getting the second error in production, it shouldn't affect your users - Basically, what is happening is that the SC server is trying to send a message to a socket which has already been closed.\nIf this error is triggered by SC internally (for example by global.publish(...)), then that's something I would like to fix - Can you find a way to reproduce this issue in a simple environment or it only happens in production?\nAlso, what is your client socketCluster.version? And your server version?\n. Do you have any code running in the broker.js file?\n. Did you change the pingInterval or pingTimeout options?\n. That looks OK\n. You don't have to ping explicitly - SC handles the pinging for you.\n. So long as the pingInterval is less than half of the pingTimeout it should be fine.\n. I noticed in your original error that it's coming from a broker process... Also it looks like it's causing the worker to restart - I think this is different than the issue I was thinking about.\n. What did you do?\n. Maybe a socket was trying to reconnect while you were restarting it in your test env... Not sure.\n. Regarding the original issue (in production) - You should check CPU and memory consumption of all processes to see if maybe there is a memory leak or another issue which is causing the OS to kill a process.\n. I need to go now. Let me know if you can reproduce it or if you find the cause.\n. @waltergms How many broker processes do you have and how busy are they? Can you see using the top command? You should try to keep them below 60% CPU usage in case of spikes.\nThat looks like something which might happen if a broker gets so busy that it can't keep up relaying channel data between your workers.\nYour app seems to make heavy use of channels so you should try to boost the number of brokers. When you launch your instance, you can pass the -b flag: E.g. node server -b 2 (this will launch 2 brokers) - The more brokers you have, the less work each one will have to do.\n. I will try to simulate a similar scenario (with lots of channels) later today to see if I can reproduce the issue.\n. @waltergms Ok, I was able to reproduce the exact same errors by blocking the nData server (broker process) for 10 seconds using a while loop while a client is trying to unsubscribe. This suggests that it's probably due to a broker maxing out on CPU usage.\n. @welberty You need to provide a special --expose-gc command line argument to worker processes in order to be able to invoke global.gc().\nThis wasn't possible before so I fixed this in version 2.3.13. I created a new issue in case anyone else is wondering about the same thing: https://github.com/SocketCluster/socketcluster/issues/105\nWorkers and brokers will now inherit any CLI execArgv from the master process so you can also have --nouse-idle-notification and/or --harmony flags or any other valid flag.\nThanks for reporting this issue.\n. @welberty This error is normal and you should expect it to happen fairly often if your system has lots of users - It's a socket error so it won't crash the worker (just log it, but don't worry too much about it unless you get a really massive number of these - Then it might mean that the internet connection between your server and your clients is bad for example).\nIt just means that a socket was closed suddenly without  first sending a close control frame (maybe the user's computer/browser/internet crashed/froze suddenly). You should still get a 'disconnect' event on the server's socket object though.\nTo reproduce the 'Socket hung up' error, I have the client running in Node.js in the command line and I connect it to a SC server. Then I just kill the client abruptly using Ctrl+C - This triggers a 'Socket hung up' error on the server as expected because the client did not send a close packet. In my case, I did get a 'disconnect' event on the server socket object.\nCan you find out what is triggering this error in your case and double check that the 'disconnect' event is not triggered on the socket object on the server?\nNote that sometimes, if the hung up is due to a bad internet connection, the 'disconnect' event might trigger only after a ping timeout (20 seconds) is reached but the hung-up event should appear at the same time on the server.\n. @safiresh Try to use a client and server with the same version number.\n. Fixed https://github.com/SocketCluster/socketcluster/commit/20b83ed1efe422a917a5a872c1d5aaa5ffc16a32\n. @bamoo456 If that data is temporary as you suggest (related to the life of the socket) and it's only relevant for that specific socket (doesn't need to be accessed by other sockets) then yes, it's OK to store data on the socket object on the server.\n. @ryanpager Your solution seems pretty good.\n@IngwiePhoenix Yes, it would be nice to have a simpler way to add custom preprocessors to handle compile-to-javascript languages like coffeescript. Not sure how we could implement this - The child_process.fork() method requires a JavaScript file ultimately.\n. Hopefully the new initController feature solves this: https://github.com/SocketCluster/socketcluster/issues/116\n. @KCypher13 Ah yes, that looks like an issue specific to SC1 which uses cookies to store and transmit the JWT token. I guess that's an issue if the script is loaded from a different host from origin?\nThis is one of the few areas where SC1 diverges from SC2 - This is low priority though, I have a lot do do. Feel free to submit a pull request if you can fix the issue.\n. Since v2.3.13, worker and broker processes inherit execArgv from the master process. So to expose gc throughout SC, you just need to add the --expose-gc CLI argument before your script's name.\nE.g:\nnode --expose-gc server\nNote that the order is important, you must provide the --expose-gc before the script (server.js).\n. Note that if you disable the default gc using --nouse-idle-notification, you may also want to set the killWorkerMemoryThreshold when initiating your SocketCluster class in server.js. See the killWorkerMemoryThreshold option from the constructor method here: http://socketcluster.io/#!/docs/api-socketcluster\n. @McFarts You should check the client and server versions to make sure that they are compatible.\nThe latest server is 2.3.14 and the client is 2.3.13.\nTo find out your current client version, just enter socketCluster.version in the dev console. The server version comes up in the console when you launch the SC server.\n. @ccravens SC adds its own protocol layer on top of the WebSocket protocol so you can't really use the plain WebSocket API to connect to it unless you're prepared to re-implement part of the SC protocol.\nFor example, SC adds a handshake step which it uses to perform JWT token authentication and set up channel subscriptions.\nIn theory, you could make a more lightweight version of the SC client which only implements the basic features required but such client doesn't currently exist.\nOut of interest, why can't you use the current client?\n. Sounds like an SC1 issue.\n. @tilleps Nice catch. Fixed in v2.3.17.\n. Note that I was not able to reproduce this issue myself. I think it may depend on the specific environment.\n. I haven't been able to reproduce this. It may have been fixed in newer versions of SC. Feel free to reopen if anyone encounters such problems while using new versions of SC.\n. @ribalba That is a tricky case, I think one safe solution would be to set an expiry on all temporary socket data - You can keep extending the expiry for each socket's data so long as that socket is connected - You can keep refreshing the expiry at an interval of your choice.\nIf the server dies, the data will naturally expire without having to clean it up explicitly.\nYou can listen for a 'SIGINT' in the worker like you sugest but you cannot guarantee that a SIGINT will always happen - If the SC server loses all power suddenly and the socket data is sitting on a different machine, there will be no way to clean it up (your server suddenly without receiving any signals).\nThere is no way to easily check which sockets/users are in a particular channel - This is tricky because subscribers of a single channel could be hosted on different processes or machines - It would require an external (potentially, distributed) storage solution to allow multiple machines to share that data between all machines. This task is better left to developers as there are many ways to implement this and can be done using many different engines.\n. Fixed in v2.3.16\n. @robborden Thanks for reporting this! That led me directly to the problem. SC didn't do a very good job at handling worker errors which didn't have a stack trace (this is unusual, but can happen with low-level V8 errors such as a call stack overflow). This was fixed in v2.3.18.\n. @ccravens SC needs to take control of the creation and management of underlying HTTP servers in order to coordinate them across multiple processes.\nExpress can be setup in two ways; \n- In the example you provided, express is creating the HTTP server internally/implicitly and then you wrap your WS server around express without having to deal with the plain HTTP server directly.\n- The other way to achieve the same result is to create the plain HTTP server explicitly and then attach express to it along with your WS server.\nE.g. (second approach)\n``` js\n  // How to use express with SC\n  var app = require('express')();\n// worker.httpServer is a plain Node.js HTTP server\n  // which was created by SC.\n  var httpServer = worker.httpServer;\n  var scServer = worker.scServer;\n// Add middleware to express\n  app.use(serveStatic(path.resolve(__dirname, 'public')));\n// Here we are passing express to the HTTP server's request\n  // handler - So express will handle all incoming HTTP requests.\n  httpServer.on('request', app);\n```\nBecause SC needs to take control of the HTTP server creation step, it favors the second approach - It works well with modular frameworks likes express but it clashes with other frameworks (e.g. https://github.com/hapijs/hapi) which also take control of the http server creation.\nYou CAN get it SC to work with any framework in theory (including Hapi), but this isn't currently documented. Basically you can provide a custom HTTP server module and SC will use it as its internal HTTP server instead of creating its own - I will try like to get that documentation up soon.\n. If a user navigates away from the page before their client responds to an event, then you could miss some acknowledgements but 40% sounds extremely high.\nAnother possible scenario:\n- An error is being thrown on the client-side (not necessarily related to SC) which is preventing the SC client from sending the acknowledgement to the server (even though they did receive the message).\nIt's also possible (if your site/app has lots of mobile users), that if their mobile device goes to sleep while they are looking at your website/app, that SC may not realize that they are offline until the ping timeout happens and they could miss some messages from the server (though 40% missed messages still sounds really high in this case).\nThe SC client will automatically disconnect if the user navigates away from the current page but sleeps are a bit trickier to detect but the connections should 'ping timeout' and disconnect on their own in this case - The ping timeout could take a few seconds to kick in though.\n. Closing this... Feel free to open a new issue if something else comes up.\n. @waltergms No you shouldn't have to change any of your code.\nYou can fork/copy the code from this repo: https://github.com/SocketCluster/sc-redis and then modify it to suit your specific needs (if necessary). You can modify it to relay subscriptions/messages to any pub/sub or distributed message queue you like without having to chnge any of your code in SC.\nSome people used sc-redis as-is, others used NSQ and ioredis with a Redis cluster.\n. @waltergms You can have as many brokers as you like and you shouldn't have to change any code.\nSC shards channels evenly between your brokers so it should just work.\n. @waltergms Nice!! It sounds like there were some issues with your previous loadbalancing solution. \nLoadBalancer,js is pretty lightweight (and easy to use), if you ever need something more advanced in the future, feel free to use nginx or HAProxy (just make sure you use a new version which supports WebSockets)... They should work as well.\nOr feel free to contribute to LoadBalancer.js too if you want to add more features. That's good too :p\n. Sounds like this has been resolved.\n. I'll have to look into the calling next() twice issue - That's a separate thing.\nSocket hung up errors/notices can happen often for a lot of different reasons (they're not a big deal and you don't usually have to do anything - Unless you get a really massive number of them).\nIt just means that the client socket closed without first sending a close control frame.\nMaybe the user is on a mobile device and it just went to sleep (probably the most common reason). Maybe the user's machine just crashed/froze abruptly for an unrelated reason.\n. As of v2.3.25, if you call next() twice, it will emit a notice but will ignore the second call.\n. @IngwiePhoenix Yes, I think the second approach makes the most sense.\nI think what you're describing is a kind of middleware function which does stuff/modifies the environment for all children scripts before they get executed.\nWe should try to follow existing conventions relating to middleware functions: See the addMiddleware() method: http://socketcluster.io/#!/docs/api-scserver - We could add a new addMiddleware(...) function on the SocketCluster master instance: http://socketcluster.io/#!/docs/api-socketcluster and the middleware type could be MIDDLEWARE_EXEC 'exec' or MIDDLEWARE_RUN 'run'.\nThis would be a nice feature. Would you feel comfortable forking SC and implementing this? I will accept a pull request.\nYou can see how SC implements middleware, here: https://github.com/SocketCluster/socketcluster/blob/master/lib/scworker.js#L168-L170 and https://github.com/SocketCluster/socketcluster/blob/master/lib/scworker.js#L195-L203\n. I guess this logic will have to run before workerController and brokerController scripts get required.\nSee https://github.com/SocketCluster/socketcluster/blob/master/lib/scworker.js#L222-L223\nThe brokerController logic is actually not directly part of SC (although it follows the same conventions). It's part of nData; see: https://github.com/SocketCluster/ndata/blob/master/server.js#L169-L173\nThe hard part is figuring out how the options from master get shared between the master, workers and nData (broker) processes.\n. Or maybe this shouldn't be a normal middleware (since passing the function across different processes will be difficult). Maybe it can be an option to the SocketCluster master instance (as you suggested) - Maybe the user should provide the path to the module which is responsible for preprocessing/prerun. I like the idea of this module calling a next() method when it has finished preprocessing (as you suggested in your second example).\n. @IngwiePhoenix Haha, well trying is what counts :p It sounds like we figured out a good solution. I can always make minor changes afterwards to ensure consistency so don't worry about it too much.\nI don't have much time right now so even if you have a partial solution, that would help get things started.\n. That's the hardest part. The iocluster module is only responsible for launching a cluster of nData servers and figuring out how to exchange data between them (basically its only purpose is to manage multiple nData servers efficiently - It's the most complex part of SC but it's independent from all other components so hopefully you don't need to change/understand it).\nIt's easier to just look at an nData server directly.\nThis part here is were the nData server receives the brokerController file path: https://github.com/SocketCluster/ndata/blob/master/server.js#L12\nThen later, it gets used here: https://github.com/SocketCluster/ndata/blob/master/server.js#L171\nThe BROKER_OPTIONS here: https://github.com/SocketCluster/ndata/blob/master/server.js#L15 is the same as the initial options object (configs) which you pass to the master SocketCluster instance when initializing - Not sure if you'll need this.\n. Yes, I guess\n. Merged.\n. @tbashor Does running SC as root user fix the issue?\n. Or try deleting the /tmp/socketcluster/ directory.\n. What are your configs for the SocketCluster() instance in server.js?\n. @tbashor You shouldn't have to run as root. I just wanted to check what the problem was.\nSC creates a /tmp/socketcluster/ directory to store unix domain socket file descriptors.\nMaybe you had existing socket fds from an earlier time that you ran SC as root? Then when you try to run it as non-root, it tries to access the fds under the same directory but it can't because it doesn't have the privilege. Does deleting the /tmp/socketcluster directory allow you to run as non-root?\nI may have to make this case more obvious in the error message because it's confusing (assuming that the issue is what I just described).\n. @tbashor What OS were you using?\n. @SomeKittens @tbashor It's difficult for me to debug this issue because I'm running Linux.\nYou could try logging the output of self._getBrokerSocketPaths() in the SocketCluster code here: https://github.com/SocketCluster/socketcluster/blob/master/index.js#L552\nWhen running with 2 brokers, you should expect to get an array like:\njs\n[ '/tmp/socketcluster/350a68c6-b1ec-411b-a916-eb0cd6e067d2_c6d951f854/b0',\n  '/tmp/socketcluster/350a68c6-b1ec-411b-a916-eb0cd6e067d2_c6d951f854/b1' ]\nThe important part is that you should have on ending with /b0 and the other one ending with /b1.\nIf that looks normal for you, you can have a look inside the iocluster submodule of SocketCluster on this line: https://github.com/SocketCluster/iocluster/blob/master/index.js#L308\n^ That line should run twice (once for each broker) and socketPath should be a diferent path each time.\nThen finally, if that still looks normal, you can dive deeper in the ndata submodule (of iocluster).\nYou can log the SOCKET_PATH here: https://github.com/SocketCluster/ndata/blob/master/server.js#L480\nThis is where the broker server actually tries to bind itself to the UNIX domain socket and likely where the error happens.\n. @SomeKittens Often, one broker is enough, but it depends on how heavily you use channels within your system - Every use case is different. Number of brokers is often proportional to number of worker processes though.\nThe main purpose of brokers to allow multiple workers to share channel data between one another (when each broker is running on a different CPU core) - They do this automatically. You can also add logic to sync them across multiple machines.\n. This has been fixed so that it now works with multiple brokers on OSX without having to use sudo. The fix is in socketcluster v5.0.2 .\n. Done v2.3.18.\n. It should be\nhttpServer.on('request', app);\nOn 'req' is the old way.\n. Where did you find this snippet?\n. @pandafinity Ok, I looked into this more deeply.\nMIDDLEWARE_HANDSHAKE middleware is invoked by the WS module, so it occurs at the WebSocket protocol level. Basically, this is outside of the control of SC.\nIt looks like the WebSocket procotol does not offer a way to capture the reason why the connection handshake was rejected. See this issue (on a different project) https://github.com/theturtle32/WebSocket-Node/issues/46.\nThat said, it turns out that the 1006 status code is not so useless. If you intentionally abort the connection like this:\njs\nvar socket = socketCluster.connect(...);\nsocket.disconnect();\nThe connectAbort event on the client will pass error code 1000 - But if the connection abort was caused because of a blocked handshake, then the error code will be 1006.\nSo basically 1006 means that the connection was refused - This could be either because the handshake was intentionally blocked by the server, that there was a network failure which prevented the connection from being established or that the the client was not allowed to connect because it did not meet origin requirements.\nSo basically there is nothing we can do about it...\nYou just have to try to work with the fact that there can only be two states; 1000 (intentional client-initiated abort) or 1006 (non-intentional abort).\n. Note that the 'connect' event on the client will only trigger once the handshake has been accepted.\n. As discussed, there is a limitation of the WebSocket API/protocol itself, hopefully this discussion cleared up things a bit.\n. @IngwiePhoenix I'm on holiday this week but I read through it and it looks good.\nI will merge it once I've had time to test it. Feel free to make the PR for nData in the meantime - That way I could test everything together.\nNice work!\n. @IngwiePhoenix Testing and merging this is top of my TODO list for when I get back from my holiday in a few days ;p\n. @IngwiePhoenix Great work. All merged. SC v2.3.22.\n. @IngwiePhoenix I ended up removing the init controller boilerplate from the sample app in v2.3.24 - This is because it's a more advanced feature and we don't want to overwhelm new users with too much stuff up front (also the initController is optional). We'll have to mention the initController in the docs on the website though.\nFeel free to make PR for that too (I will do it if you don't have the time though). The page on the website is here https://github.com/SocketCluster/socketcluster-website/blob/master/public/app/views/docs/api-socketcluster.html\n. @ab4drinkadvisor If you use channels, you can send a message \"directly\" between clients (the message will pass through the server but you don't have to write any serverside code to handle this).\nTo subscribe to a new channel:\njs\n// Client-side code\n// Assume the current user's username is bob123\nvar userChannel = socket.subscribe('channel_of_bob123');\nuserChannel.watch(function (data) {\n// Handle the data published to the 'channel_of_bob13' channel by other users\n});\nThen if another user wants to send a message to bob, they can just call:\njs\n// Client-side code\n// Note that the second argument can be any valid JSON object/type\n// you don't need to have a from or message field...\nsocket.publish('channel_of_bob123', {from: 'alice456', message: 'Hi bob!'});\nYou can name channels anything you like - You don't have to have the username as part of the channel name. You could have public channels like 'cats' - And all people who like cats could subscribe/publish to this channel...\n. @ab4drinkadvisor SC is quite efficient at dealing with channels. It's OK to have hundreds of channels per client.\n. You can use middleware to restrict which users are allowed to subscribe to what channels (for access control). See section on middleware at the bottom of this page: http://socketcluster.io/#!/docs/api-scserver\n. @Anaphase The documentation needs to be fixed. This feature only exists for the publishOut middleware because publishOut tends to get called often and you sometimes want to make it quiet.\nNote that if you don't want to see notices at all, you can lower the logLevel setting in the main SocketCluster config.\nIt would be nice to implement the same feature for other middleware in the near future.\n. @Anaphase As of v 2.3.25, if the next() callback is called with true as first argument, it will quiety block the action (without emitting any notices on the server or logging to the console). Be careful with this feature though - Notices are a nice way to keep track of what's happening in your system.\n. @tbashor There is no hard client limit per server. You can always add more CPU cores to your server and handle more clients. According to this page http://socketcluster.io/#!/performance, on an 8 core machine, it was still only using less than half the total available CPU with 42K connections. So on an 8 core it could probably handle at least 84K in reality.\nIn the stress test, the limit wasn't caused by the client code itself, it was the machine which was used to simulate the clients that wasn't powerful enough. The clients were being created by a single 32 CPU core machine and ALL 32 of these cores were being used at 100% capacity so it couldn't create any new clients. This was a limit of the testing environment, not of the SC server.\nSC has its own protocol on top of WebSocket - So you would have to follow it if you wanted to build your own client for it.\n. @abhi86813 You need to increase file limits. On Linux there multiple commands that need to be run to increase the limits. Also you need to increase the limits on both the client and server machines (if you're doing a stress test).\nhttps://www.tecmint.com/increase-set-open-file-limits-in-linux/\n. You need to use middleware for access control. See addMiddleware method here: http://socketcluster.io/#!/docs/api-scserver\nThere is a MIDDLEWARE_SUBSCRIBE middleware which you can use to block certain users from subscribing to certain channels and a MIDDLEWARE_PUBLISH_IN line for preventing them from publishing to channels.\nIf you're sure that you never want to allow clients to publish to channels (only the server), then you can set the allowClientPublish config option to false. See http://socketcluster.io/#!/docs/api-socketcluster\n. To publish from the server, you can call worker.scServer.global.publish(eventName, data, cb); anywhere inside your workers (worker.js).\n. @roblav96 Yes, the client can 'spoof' the isAuthenticated property but that won't change the reality that it doesn't have a token which was signed and encrypted by the server (and the server knows this because it doesn't have a valid token associated with that socket). The isAuthenticated property is the server's way of telling the client that it has received a valid token (which was signed by the server itself). It's JWT token-based authentication.\nThe security lies in the fact that the client cannot sign and encrypt a fake token because it doesn't know what the authKey is. If the client tries to send a token which they signed/encrypted themselves using the wrong key, the server wouldn't be able to decrypt it and therefore, the server would know that this is not a valid token.\nFrom the server-side, if the socket is authenticated (with a valid token), when you call socket.getAuthToken(), it will give you the content of the token in plaintext. If the user tries to provide an invalid token, the getAuthToken() method will return null (to indicate that there is no valid token associated with the socket).\nOn the backend, you can use middleware along with the getAuthToken() method to determine whether or not a socket is authenticated and block/allow specific actions based on the existence of the token or based on the content of the token.\nNote that you can store any data you like in the token since it's encrypted and the client cannot see the plaintext (it's good to store permissions data to tell the server what resources the user is allowed to read/update).\n. @robborden Fixed in ndata v2.9.7 - You'll have to update the ndata dependency inside node_modules/socketcluster/node_modules/iocluster/node_modules/ndata.\nBasically, the problem was that the string $1 was interpreted as a placeholder as part of a call to string.replace() when nData 'compiled' the query before sending to the the nData server.\n. The android client is still in work in progress... Closing this for now.\n. Looks like you may have mixed up socket.emit(...)/socket.on(...) with pub/sub actions socket.subscribe(...) and socket.publish(...).\nUsing emit and on allows your to do simple client/server communication, pub/sub channels are separate from this (a higher level of abstraction).\n. @roblav96 It works for me. What is your client and server version? Do socketCluster.version on the client to see the client version.\n. As @IngwiePhoenix you can hook SC into Redis or another message queue and SC will automatically sync its channels with Redis. https://github.com/SocketCluster/sc-redis\n. The Exchange object is a cluster of nData clients and has the same methods as a regular nData client: https://github.com/SocketCluster/ndata\n. What you're talking about here is a channel presence service - This is outside of the immediate scope of SC because there are too many ways to implement this (no one-size fits all).\nWhat if you have multiple SC instances/servers? Then where should you store the the list of socket IDs? You will need to store it in an external service which all your SC instances/servers can share (so the implementation of this feature would be different).\nThis specific case (for a single-server scenario) might make a good server-side plugin though...\nEDIT - Maybe the plugin should think of 'subscribers' in terms of 'users' and not 'sockets/socket IDs' - The problem with referring to individual sockets is that it doesn't scale well. If you refer to users based on username instead, then you can just publish stuff to a 'bob123_chat' channel (for example) and you don't have to worry if the socket(s) which belong to the user bob123 is/are on a different process or server.\nSee https://github.com/SocketCluster/plugins for current guidelines for plugins.\n. I think storing channel permissions in the JWT upon successful login is actually a good strategy for reducing hits on the database - You just establish all channel permissions up front. Then in the subscribe middleware, you could just check the JWT token (socket.getAuthToken()) and if the channel name matches one of the entries in the token, then you can allow the user, otherwise you block them.\n. Making a database call in the middleware is good if you need down-to-the-millisecond accuracy regarding the user's access rights. Storing it in the token theoretically gives the user access to the channel so long as the token is not expired.\n. I was thinking that the error passed to the 'subscribeError' handler on the client would always be of type 'MiddlewareBlockedError' (or similar).\nThe token-expiry error would have its own 'authenticateError' event (and be separate from the authorization/access-control logic).\nSo if a token expires during a subscribe request, the authentication middleware on the server would notice this and remove the token and emit an 'authenticateError' on the client and then the subscribe middleware might notice that the token is no longer present and therefore block the request and emit a 'subscribeError' on the client immediately after.\nBut even in this scenario, you raise a fair point.\nDo we prefer this:\n``` js\nsocket.on('authenticateError', function (err) {\n  console.log(err.message); // -> 'The JWT token has expired'\n  // Here we can redirect the user to the login screen.\n  // ...\n});\nsocket.on('subscribeError', function (err) {\n  // err.message is whatever error was provided to the next(error) call in the middleware on the server\n  console.log(err.message); // -> 'Socket is not allowed to subscribe to the foo channel because the socket did not have a valid token'\n  console.log(err.channel); // -> 'foo'\n  // We can notify all relevant components that they are not\n  // authorized to subscribe to the 'foo' channel while they are not logged in.\n  // ...\n});\nsocket.on('publishError', function (err) {\n  // ...\n});\nsocket.on('emitError', function (err) {\n  // ...\n});\n```\nOr this:\njs\nsocket.on('error', function (err) {\n  if (err.name == 'AuthenticateError') {\n    console.log(err.message); // -> 'The JWT token has expired'\n    // Here we can redirect the user to the login screen.\n    // ...\n  } else if (err.name == 'SubscribeError') {\n    console.log(err.message); // -> 'Socket is not allowed to subscribe to the foo channel because the socket did not have a valid token'\n    console.log(err.channel); // -> 'foo'\n    // We can notify all relevant components that they are not\n    // authorized to subscribe to the 'foo' channel while they are not logged in.\n    // ...\n  } else if (err.name == 'PublishError') {\n    // ...\n  } else if (err.name == 'EmitError') {\n    // ...\n  } else {\n    // ...\n  }\n});\n. So my idea at the moment is to trigger both the 'authenticateError' and the 'subscribeError' independently (this approach considers the authentication problem as being completely independent from the authorization problem).\nI think one of the earlier ideas thrown around was that if the middleware blocked the request, it would trigger a single error event on the client and that error would be either an authentication error or an authorization error but not both.\nThe second approach is a bit like HTTP status 401 (not authenticated) vs 403 (forbidden). Each HTTP request can only have a single response so it can only be 401 or 403 but not both.\nI feel that the first approach offers better decoupling, but at the same time, I'm not decided on which one is more practical.\n. @mattkrick Ok, I made more changes to the specs based on new feedback. I also added a 'deauthenticate' event which will be triggered on the clientside (initiated by the AUTHORIZATION/TOKEN_EXPIRY middleware). Note that this is not an error event. We have an 'authenticate' event, so we should also have a 'deauthenticate'/'unauthenticate' event too.\n. Errors will have a name which indicate specifically what kind of error it is. E.g. 'SubscribeError' and optionally also a type which tells us what kind of error this is. E.g. 'AuthenticationError'.\nThe user can also add custom properties to the error object (whatever they feel necessary to help them handle the errors effectively on the client-side)... They could add a 'code' property if they wanted to assign error codes to their errors.\n. I'm not sure what we should do with the removeAuthToken event if we add a deauthenticate event... Should we remove it?\nMaybe we could provide an argument to the 'deauthenticate' handler which tells it whether the token exired or was removed intentionally by the server... Not sure.\nRegarding middleware errors - I think the user should be able to pass either a plain object, an Error object (or derived class) or a string (for backwards compatibility). If a string is provided, SC will construct an Error object with a default name and type depending on the middleware (E.g. name: 'SubscribeError', type: 'UnauthorizedError').\nHere's a potential variation to the table of errors you posted earlier ():\n| Error Name          | Error Type          | Source                                           |\n|---------------------|---------------------|--------------------------------------------------|\n| ConnectionError     | ConnectionError     | Can't connect due to [code] or unknown           |\n| ConnectionError     | HeartbeatError      | Ack timeout                                      |\n| ConnectionError     | HandshakeError      | Handshake failed (include middleware?)           |\n| ConnectionError     | ...                 | ...                                              |\n| AuthenticationError | AuthTokenInvalid    | Provided token was invalid                       |\n| AuthenticationError | AuthTokenExpired    | Provided token was expired                       |\n| SubscribeError      | [userDefined]       | subscribe middleware                             |\n| PublishError        | [userDefined]       | publish_in or publish_out (separate?) middleware |\n| ...                 | ...                 | ...                                              |\nIf the error has type ConnectionError, the err object should have a code property containing the status code. A lot of generic socket error types can fall under the error name 'ConnectionError'.\nI'm leaning more towards all errors going through a single 'error' event - It's nice to have all core error-handling logic in a central place.\n. @mattkrick I'm happy with your suggestions for the deauth flow - In this case, I would add that maybe we should rename socket.removeAuthToken() to socket.deauthenticate() since it will now do a bit more than just removing the token.\nAlso, I'm thinking that maybe we shouldn't have an error 'type' property because it seems confusing (especially since we also have a name property which shows a different error type).\nAlso what would happen if the token had expired and we called next(req.authTokenError); inside the subscribe middleware?\nThe req.authTokenError would look like this:\njs\n{\n  name: 'AuthTokenExpiredError',\n  message: 'The JWT auth token has expired'\n}\nSo when the client would receive this error inside the error handler, we wouldn't know that it is a SubscribeError (which happened inside the subscribe middleware) because the name AuthTokenExpiredError would have overwritten the default SubscribeError (even though it comes from the subscribe middleware.\nWe could make it so that next(err) ignores the name of the error provided and just copies the other properties (and keeps the name as 'SubscribeError') but that seems too magical and confusing for a new developer.\nMaybe instead, we should add an action property (or maybe there is a better name??) to whatever error object is passed to the next(myErrorObject). For example; for the subscribe middleware, the value of the action property would be subscribe. For the publishIn middleware, the value would be publish, etc...\nSo then to handle the different error cases on the client, we could do:\njs\nsocket.on('error', function (err) {\n  if (err.action == 'subscribe') {\n    // ... Error while performing 'subscribe' action\n  } else if (err.action == 'publish') {\n    // ... Error while performing 'publish' action\n  } else {\n    // ... Other kinds of errors.\n  }\n});\n... Or maybe there is a better way. Would it be a problem if some err objects don't have an 'action' property (for example, errors which are not related to middleware)? Maybe it's not a big deal - I guess some errors will have additional properties anyway.\n. @mattkrick The reason why I would like to to add a type/action property to the error object is because a single action (E.g. socket.publish(...)) could fail from a number of different causes. A 'middleware blockage' is just one of two ways a publish action could fail - The other way is a timeout - If the connection is bad.\nOften, the developer just wants to track if a specific action failed (they might not want to know about all the different kinds of errors which could cause that action to fail). It would be nice to have a way to group multiple errors so that the developer can easily check if an action failed without having to add multiple if (error.name == 'PublishBlockedError' || error.name == 'PublishTimeoutError' || ...) - If there was a single shared action property, the user could just go if (error.action == 'publish') and all errors related to that action could be handled in the same place.\nOr maybe there is a better way to handle this? It seems like a potential problem especially if a single middleware could emit a lot of different user defined error - Should we have a common property to group them by?\nNote that it doesn't matter in the case of subscribe because subscribe actions can never timeout... This is because SC manages retry behavior behind the scenes - So the user-defined middleware error is the only possible error in this case, but the publish or emit actions are examples of actions which might each fail from two different causes (userDefined middleware error and connection timeout error).\n. @mattkrick I guess grouping errors based on action is not that important. I think the benefits of having a lot of different error types outweighs the inconvenience of having to know about them - So long as they are documented.\nIf a user wants to know if a specific action failed (for any reason), they can just provide a callback to whatever method they're using. E.g. socket.publish('channelName', data, callback) - All errors would be passed to that callback (regardless of the error type).\nEffectively, the 'error' handler will be useful for adding generic error-handling logic (based on error types), while the callback will be useful for handling failures related to specific actions (without regard for error types). So actually this setup is quite flexible.\nWe could lump together publish and emit timeout errors under the same 'AckTimeoutError', but this is different from the heartbeat/ping timeout.\nThe ping timeout might happen beacause of a poor/lost connection. The ackTimeout is separate and it can be caused by two things:\n- Poor/lost connection\n- The server is taking too long to process the action (even though the connection itself is fine)\nWe could have a single 'AckTimeoutError' or have separate timeout errors for each type of action: 'PublishTimeoutError', 'EmitTimeoutError'. Maybe the second case is better; these are two different error cases and will often require different handling.\n. @mattkrick thanks for all the help with this - I'm going to update the specs tomorrow with the stuff about errors and other stuff from our discussions. I think this is getting close to ready (It all seems to fit together really nicely so far).\nLet me know if you want to get involved with implementation too. I will add more bullet points to the list at the top and you can just pick the ones you want to do. (If you want... No pressure).\n. The flow I had in mind for deauthentication is (example):\n1. socket.isAuthenticated is false initially\n2. The socket connects, then authenticates itself via the handshake (which will provide a JWT token to the server if one exists)\n3. Once the handshake completes sucessfully (assuming there was a valid token), the client-side 'connect' event will trigger and the socket.isAuthenticated property will be set to true\nClient-initiated deauth:\n4. Some time later, the frontend calls socket.deauthenticate()\n5. The socket.isAuthenticated status is immediately set to false on the client, then a #deauthenticate event is emitted to the server.\n6. Once the socket on the server-side receives the #deauthenticate event, it will remove the token from the socket (so, from now onwards, calling socket.getAuthToken() will now return null/undefined)\nServer-initiated deauth:\n4. Some time later, the backend calls socket.deauthenticate() - The token will immediately be removed from the server-side socket.\n5. A #deauthenticate event is emitted to the client\n6. When the client receives this event, socket.isAuthenticated will be set to false.\n* 5.5. For server-initiated deauth, before the client receives the #deauthenticate event from the server (and before the client changes its isAuthenticated state to false) - For a brief moment, the client will wrongly believe that the socket is still authenticated (socket.isAuthenticated will be true on the client even though the token was already removed from the server).\nIf the client tries to perform an action (e.g. socket.publish(...)) which requires authentication during this short period, the relevant (e.g. publish) middleware on the server will send back an appropriate user-defined error (e.g. UnauthenticatedPublishError) to the client.\nIf we go down this path, we don't need to do client-side token expiry. We can let the jwt-expiry middleware on the server handle this. Basically it means that the token expiry won't happen in realtime (it will only happen as a result of a client-server interaction - Which might fail as a result). I think that's fine because we can never guarantee that the server and client are in sync anyway - That's OK, so long as we send the client an appropriate error and allow it to correct its state.\nI don't like the idea of trying to synchronize expiry times on different machines - This sounds easy at first but it's actually impossible to do with perfect accuracy. In part because you can never accurately predict the latency between the server and client (the clocks will almost always be a few milliseconds out of sync as a result) - And if the client tries to perform an action during that small millisecond gap, it would be out of sync with the server's authenticated state.\nSo we would end up adding a lot of complexity and end up with a solution which will be perfect 99.9% of the time but when it will eventually fail (and it will), the error will be confusing (and it will be impossible to reproduce under test conditions because it happens so rarely).\nAlso there is the unusual case that the client might change their computer's time while they're using the app... Or maybe they're using it when daylight savings kicks in (and the time on their computer immediately increments by one hour) then the client will wrongly believe that the token has expired.\n. @mattkrick Yes, I forgot to mention that, it will remove the token from the client at step 5.\nI think at this stage token renewal should be handled by the server - This offers the most flexibility (and there is an infinite number of ways to do this). It's just a matter of the user calling socket.setAuthToken(...) from the server.\nYes it's true that the solution I proposed has the same problem as yours ultimately. Also, it's true that a setInterval solution probably wouldn't be affected by a user changing time on his machine (I guess it depends on how it's implemented). I guess I like the approach I described more because the behaviour is more predictable and I prefer to keep the client lightweight.\n. @mattkrick I meant it should be handled by the server (not client) :p I used the wrong word.\nAs you mentioned, the approach so far has been for the developer to write a setInterval() on each socket on the server after they login which keeps renewing the token.\nI don't know if we should automate this. I need to think about it more.\n. I decided to remove the waitForAuth option for the emit() function (but keep with for the subscribe() function).\nThere can only ever be one pending subscription per channel (this is managed internally by SC). For emit, however, you could have as many pending emit events as you like (however many times the frontend calls socket.emit())... This could cause the 'waitForAuth' queue to become massive and freeze the app when the socket finally becomes authenticated. It's too dangerous - It's better if the developer checks themselves whether or not the socket is authenticated - There will be a new property on the socket object which will make this easier.\n. @mattkrick They can't really flood the buffer because emitted messages would timeout (and thus remove themselves from the buffer). With waitForAuth, I'm not sure having a timeout would be appropriate. I will think about the LIFO cap; that might be a solution - I think this should be considered for a later release. Maybe 4.1.\n. I removed the point about \"removing the subscribeFail event and emitting it as an 'error' event instead\" - I think we should keep 'subscribeFail' because:\n- Subscription failure is not a socket error - It is an application-level error which is not related to SC itself.\n- This approach is consistent with changes introduced in v4; I.e. socket.emit('eventName', callback) no longer emits an 'error' event on the socket when the emit operation fails; the callback is the only place where the error will be handled - That is because it is now considered an application error.\n- Pusher.com has a 'subscription_succeeded' and a 'subscription_error' event so this approach is already commonly used in the industry - So this would be equivalent to SC's 'subscribe' and 'subscribeFail'.\n. @mattkrick \n- 'pending' generally means that the authState is not yet known but will be known soon. Channels also have the concept of 'pending' and 'subscribe'.\n- Yes you can send back any error to the client - They will be dehydrated on the server and rehydrated on the client. If the error is related to SC (not user-defined), then it will be one of these types: https://github.com/SocketCluster/sc-errors/blob/master/index.js (I will make a list of them on the website at some point).\n- You can already access those as static properties on the class itself. E.g. socketCluster.SCSocket.CONNECTING - This should be documented better on the website maybe. We could export the connection state directly. I don't have a preference for either using the constants or the string form 'connecting' - These are very unlikely to change anytime soon... If ever.\n. I guess the bulk of v4 is complete so I'm closing this. Anything new from now on can be raised as a separate issue for a minor release.\n. @ibrahim9 Presence is outside of the immediate scope of SC but you can get a module for it: https://github.com/coinigy/sc-presence\nThis is a single-database solution. If you need to scale beyond a certain point, you may need a different solution.\n. Unlike Socket.io, SC doesn't need sticky load balancing between workers. The reason is that Socket.io starts with a HTTP polling-based handshake (which involves multiple HTTP requests) and the sticky-session module is necessary to ensure that multiple requests get routed to the same worker process.\nSC doesn't use long polling, it's just pure WebSockets, so a single connection is naturally bound to a single process (for the entire life of the connection) - Each WebSocket connection is stateful by default so you don't need session stickiness. The only reason Socket.io needs sticky-session is because it's trying to simulate a stateful protocol (WebSockets) using a stateless protocol (HTTP).\nIn SC, brokers are there to allow workers to efficiently exchange channel messages with each other (for doing pub/sub - Which is one of the most important features of SC). They can also be hooked into remote message queues so that multiple SC instances can share the same data channels across multiple distributed instances.\nBrokers are launched and managed by SC automatically. You can have multiple brokers running as part of a single SC instance.\nEach broker manages (handles message passing for) a subset of all pub/sub channels used in your system. So for example, if you have 100 channels and 5 brokers in your system, then each broker will manage 20 channels - So each broker will have less work to do.\nEach broker process is independent from one another so they don't share any work with each other (sharded according to a hashing function and based on the channel name) - Each broker manages their own subset of channels - And each of them can hook into a remote MQ and sync their own channels.\nSo you can scale indefinitely vertically and/or horizontally.\n. @hustcer It probably depends on your use case. Based on one of the benchmarks I've seen, nginx was only about 5% faster than Node.js' cluster module - This is not statistically significant.\nYou may want to use nginx or HAProxy if you want to spread the load across multiple physical hosts but you don't really need if you're running a single host.\n. It's recommended to run it over https. In addition to preventing eavesdroppers from seeing your data (including the content of your JWT token), an important case to consider is that some old corporate proxies may block plain WebSocket traffic.\nBasically this might affect some users who are accessing the internet from inside a school or corporate network.\nIf delivered over SSL/TLS, this generally doesn't happen because the proxy won't be able to tell the difference between WSS or HTTPS traffic (since it's all encrypted).\n. Which version of Node.js are you using?\nNew versions should be ES6.\n. Is the SC/WebSocket connection over plain HTTP/WS (not HTTPS/WSS)?\nSome proxies are known to kill/block long-lived raw WebSocket connections. Users who are connected to the internet through some corporate networks may encounter such issues.\nConnecting to SC via HTTPS usually fixes this.\nThe other thing to consider is that some old browsers don't support WebSocket.\nI know China is really weird when it comes to browsers; they have a lot of people still using old versions of IE.\n. @ryanpager You can increase the pingTimeout and pingInterval options.\nhttp://socketcluster.io/#!/docs/api-socketcluster\n. It depends on your scaling strategy and the following factors:\n- How difficult it will be for you to scale horizontally (adding more dynos/instances)?\n- Messaging patterns in your system; does your system tend to have a lot of one-to-many messaging (I.e. a message from one user might be sent out to hundreds of other users - Reddit style interactions) or are the communications generally one-to-one?\nSystems which have one-to-many messaging could be orders of magnitude more efficient when run on a few large machines versus lots of small machines because it reduces bandwidth consumption.\nFor example, assume a scenario where you have 100 small instances vs 10 big instances and you want to broadcast a single message to everyone across all your instances. In the first case, 100 copies of that message will have to go across the network while in the second case, only 10 will go across the network (it requires only 1/10th of the bandwidth).\n. Obviously I used Node.js/SC on the server.\nAs for the clients, I spawned many thousands of 'virtual users' using a large Amazon EC2 instance with 32 CPU cores. To create virtual users - I just ran socketcluster-client inside Node.js and spawned 32 concurrent Node.js processes - Each hammering the SC server with as many connections as they could (and keeping virtual users connected throughout the whole test and each sending a message roughly once every 5 seconds - With some randomness to make sure that all messages don't all come at once exactly).\nI used the Node.js cluster module for spawning the 32 processes but you could also do it with the child_process module. A 32-core machine shouldn't be sufficient to DoS an 8-core SC machine.\nI used the top command for monitoring on both the server and the client (you have to make sure that the client doesn't exceed 100% on any process - Or otherwise your results could be scewed if your virtual clients starts to struggle).\nBasically I had lots of shells open and just SSH'd into the machines.\nSo I didn't use anything fancy but it was pretty easy to put together with just Node.js and a bit of custom code. There are probably better tools which can draw nice graphs and such.\n. Note that I did some new tests recently with SC v4 and interestingly, I found distribution tended to be uneven between workers when using default settings (it may be related to the way I did the test though) - This is in part because SC doesn't use the same default as Node.js for loadbalancing. You can make the distribution more even by changing the schedulingPolicy setting to 'rr' here: http://socketcluster.io/#!/docs/api-socketcluster\nThe default schedulingPolicy which SC uses lets the OS decide how to allocate new connections across multiple worker processes (and the default scheduling algorithm for Linux cares more about raw efficiency than making sure all processes are even). I suspect it's because spreading the load evenly between all processes might not be as efficient (in terms of CPU cache usage) as concentrating the work on as few cores as possible... Just a guess. Maybe it's related to the fact that I was sending exactly the same message string over and over to the server during the test (and so the OS tried to use the CPU cache more?)... Maybe I should send a string of random numbers instead?\nThe reason why SC uses the OS scheduler by default is because it has no theoretical scalability limits, however, using the Node.js scheduler (using 'rr' schedulingPolicy) does - This is because when you use 'rr', a single process will be responsible for accepting ALL new connections (so that process may become a bottleneck is you have like 16 workers or more...). Some people prefer to have even processes in any case for peace of mind - So using 'rr' might be the best solution - You should try both and see which one you feel more comfortable with.\nWith the default OS-based schedulingPolicy, I got to a point where one worker was close to 100% (while others where like 50% and some were close to 0%). It looks like some workers were almost idle and only started picking up the slack when one of the workers approached 100% - Interestingly enough, I noticed that the process which was close to 100% eventually stopped accepting any new connections - So basically, even though the distribution was uneven, it looked like all clients were getting good service (including the ones attached to the busiest process).\nIt would be interesting to swap out the default Linux scheduler for another one which puts more value on evenness across all cores (as opposed to raw overall efficiency).\n. @drojas You may want to do npm cache clean and then reinstall SC from scratch - There was a bug in the sc-errors module which caused an issue like this (this has been fixed). You may want to get the latest sc client as well - v4 is a bit unstable right now.\nI will push another update of SC today to address a few other minor issues which were introduced in v4.\n. @mattkrick I haven't encountered this problem. sc-simple-broker 1.2.0 is published: https://www.npmjs.com/package/sc-simple-broker\nDoes doing npm cache clean fix the issue?\n. SC already launches ndata behind the scenes - You don't need to launch the server yourself.\nAlso, you might want to read through this issue https://github.com/SocketCluster/socketcluster/issues/44 which is similar.\n. The socket.exchange http://socketcluster.io/#!/docs/api-exchange on the server has all of these methods: https://github.com/SocketCluster/sc-broker#client-methods\nYou could just go socket.exchange.set('myCustomValueToShare', 123, callback) from any worker\nThen once set, you could just go:\nsocket.exchange.get('myCustomValueToShare', function (err, data) {\n  console.log(data); // 123\n});\n. @hyatt03 This object isn't very large. SC should be able to handle JSON objects with a few hundreds of thousands of properties.\nI tested with that exact object using the latest version of SC (and client) and the object arrived on the client almost instantly. Are you sure that you're not accidentally sending more than this?\nThe error you mentioned might in fact happen if an object is too large - Or it could be caused by your client/browser or server being frozen.\nWhich version of SC are you using (client and server).\nThe server version shows up when you launch SC and to get the client version, you can just run socketCluster.version the browser console.\n. Maybe can you update the submodule node_modules/socketcluster/node_modules/socketcluster-server to  v4.1.4 and the client in node_modules/socketcluster-client to 4.1.3 - Just to be sure? These versions are a bit more stable though I don't think it would explain the issue.\n. Are you doing synchronous IO operations on the server (like reading a file synchornously)?\n. If you keep removing some properties from the object, does it work eventually?\n. The exact object you provided works fine for me on Ubuntu. What OS are you using?\n. The way I'm doing it is I put your JSON object in a separate bigdata.js file then I have this code on the server:\njs\nvar bigData = require('./bigdata');\nsocket.on('getBigData', function () {\n  socket.emit('bigData', bigData);\n});\nThen from the client I listen to the 'bigData' event using socket.on('bigData', function (data) {console.log('BIG DATA:', data);}) then when I do socket.emit('getBigData'), then I can see the whole object in the browser console.\n. @jfsimon Make sure that your pingTimeout is more than 2 times as big as your pingInterval.\nSo if your pingInterval is 1 minute, your pingTimeout should be like 2.5 minutes or higher.\nBasically, you want to allow your pings to miss a beat (or arrive late) once in a while - You need a margin of error. Let me know if that fixes the problem.\n. @jfsimon What if you set your pingInterval to 10000 (every 10 seconds)? 2 minutes is a long time. I don't think that's the problem though.\nNote that timeouts are normal for most applications - This can happen if the user closes their laptop suddenly, or their connection drops out, or if accessing over a mobile device and it goes to sleep suddenly.\nYou shouldn't be too worried if you get timeouts; it's important to log them anyway, so if you see that more connections timeout than 'normal' that could indicate something.\nAre you able to reproduce the issue under controlled conditions or is this issue happening in production only? If so, I suspect it's completely normal; you might want to not log these warnings individually and instead keep track of the count over time maybe?\nTo reduce the number of timeouts, you could try to to detect when a mobile device is about to go to sleep (for example) and do socket.disconnect() to close the socket properly. It's not a huge deal if you don't though.\n. @jfsimon The ping/pong is necessary and allows the socket to know when the connection has dropped out suddenly (without sending proper close control frames). This is so that a disconnect event can be triggered in those cases. All current implementations of WS have some form of ping/pong.\nI can't think of a reason why it's not working on Windows.\n. Is this user behind a corporate proxy or a firewall? Maybe there is a proxy/firewall which blocks messages sent over WebSockets. Using wss:// instead of ws:// would fix this issue; You'll have to get an SSL certificate if that's the problem.\n. @efkan I'm not currently aware of any good Android client. We have an 'unofficial' iOS client https://github.com/abpopov/SocketCluster-ios-client.\nI believe that @abpopov is (or at least was) working on an Android (Java) client too (not sure about progress). You can chat with him on Gitter: https://gitter.im/abpopov\n. I started writing the official SC protocol guide here in case anyone is interested: https://github.com/SocketCluster/socketcluster/blob/master/socketcluster-protocol.md\n. @poppahorse Which version of SC are you using on the server? Version 1.x.x?\n. Closing. Dropping support for version 1 of SC.\n. @till Yes, the tests right now are extremely primitive. It would be nice to use something like mocha and have them run using the npm test command. Right now, you run the tests by running the index.js files using node. E.g. node test/external/index.js. They are just integration tests - On directory has tests for checking the external behavior of SC and the other one checks internal logic like making sure objects are cleaned up internally... I think the internal stuff is pretty basic, but it would be nice to add more 'external' integration tests to validate the behavior of SC.\nFeel free to restructure this as you see fit.\nYou can look at how we did tests for sc-broker if you need ideas (it is for the broker process in SC): https://github.com/SocketCluster/sc-broker/tree/master/test \n. I can't reproduce your issue though, it works for me. It looks like your socketcluster-client module might be missing though, maybe it didn't get installed properly for some reason.\nAlso, yes getting TravisCI setup would be awesome.\n. I can think of only three things which SC does which could add overhead to the express/HTTP server:\n- The Node.js cluster module (https://nodejs.org/api/cluster.html) which distributes requests between processes\n- The WS module (https://github.com/websockets/ws) which interfaces with the HTTP server\n- Then there is this code which adds some custom SC properties to the req object: https://github.com/SocketCluster/socketcluster/blob/master/lib/scworker.js#L266-L290\nMaybe the Node.js cluster module is responsible for the extra latency? I wouldn't be too worried about this just yet; a 6x increase in latency doesn't necessarily mean a 6x increase in CPU load (especially since these are still all quite small numbers) - If it does increase CPU load, then that's definitely something that needs to be investigated and fixed. I wouldn't expect there to be any significant increase in CPU load with SC.\nI haven't noticed any performance issues with SC based on the stress testing I did, but then those tests were mostly focused on WebSocket connections/data and not HTTP.\nI will see if I can reproduce this issue.\n. The other thing to consider is that the default SC boilerplate uses the serve-static module  with express - If you use a different module, you may get different results.\n. I did a test serving a simple .js file over HTTP and I'm getting the same latency for Express with SC and for plain Express without SC. I did notice that there is a huge difference between the first time the file is loaded vs subsequent times - It took 6x to 10x as long on subsequent calls (sometimes more). This is related to caching.\nCaching happens in both the browser and on the server. Even if you disable browser caching, it will still be faster the second time you fetch a particular file because of server-side caching. If you restart the server, it will clear the server-side cache.\nNote that if you use SC with 4 workers, each worker needs to get its own copy of the cached file so that means that after starting up the server, the cache could miss up to 4 times if the request ends up on a different worker each time. On a plain single-process express server, the cache will miss once at most.\n. I can't reproduce this issue - Cross origin connections work fine for me on the latest version of SC. Could you give more details? What client and server versions are you using?\n. I'm closing this since this appears to  relate to a very specific use case. Feel free to reopen if you would like to pursue this issue further.\n. @leedium This is normal, you probably have an old JWT token lying around in your localStorage from a previous session. Each time you restart SC, a new random authKey will be generated (unless you specify a custom one as an option to SocketCluster). When an SC client socket reconnects, it will automatically try to reauthenticate itself with any existing tokens it has - In this case the token is signed using a different authKey. These 'warnings' can be ignored - It just means that your socket wasn't able to authenticate itself using its existing token.\n. Warnings in SC are typically not important and can be ignored most of the time. You can even turn them off by decreasing the logLevel config option of SC but that is not recommended - Warnings can tell you useful information about your users and your system.\n. @leedium Ah thanks! I should share the credit with @mattkrick though - He had most of the ideas for the error-handling changes in v4 and helped a lot with the planning.\n. There was a change in that area which resolves the issue. Now if there is an invalid token, the client will clear it so the error won't show up every time the socket connects - Only the first time it realizes that the token is not valid.\n. @Kequc Yes, the underling transport is WebSocket/TCP - So you get guaranteed exactly-once, in-order delivery over the life of the connection.\n. @leedium SC now has its own Docker image https://github.com/SocketCluster/socketcluster#docker-and-socketcluster - It can even run and scale automatically on Kubernetes. We will add more docs about running it on Kubernetes at some point in the near future.\n. SC recovers from lost connections automatically and it automatically re-establishes channel subscriptions when they are lost so it sounds good for your use case. (You can optionally disable this behaviour of course).\nRegarding your second question; if you call socketCluster.connect(options) multiple times (to the same host, port, etc...), by default it will reuse the connection. You can optionally turn this off by adding a multiplex: false option when you call socketCluster.connect(options). See http://socketcluster.io/#!/docs/api-socketcluster-client\n. @stewartcelani Yes, you can force disconnect and reconnect in SC whenever you like. The autoreconnect kicks in if the connection is lost due to network failure.\nIf you call connect multiple times in SC, by default it will reuse the existing connection so it won't leak sockets. \nRegarding your question about events - SC tries to keep it as simple as possible when it comes to channels. If you want to add events within your channels, you can use the if statement approach which you described (if you don't have too many different types of events) or a good approach would be to have an object which maps event names to functions (in this case you can declare as many handlers as you like).\nE.g.\n```\nvar eventHandlers = {\n  foo: function (eventData) {\n    // This is the foo event handler\n  },\n  test: function (eventData) {\n    // This is the test event handler\n  },\n  // ... Add as many handlers as you like\n};\nsomeChannel.watch(function (data) {\n  var handler = eventHandlers[data.event];\n  if (handler) {\n    handler(data.eventData);\n  }\n})\n```\n. @seiyria Which version are you using on the server? There was a problem like this in the past (not so long ago) when SC occasionally tried to serialize error objects that had error domains attached to them (and the domain objects had a circular structure).\nThis could also happen if you try add an object which has a circular reference as a property to an Error object.\n. Do you think if we switched the serializer to https://www.npmjs.com/package/json-stringify-safe it would solve the problem?\n. @seiyria Did the error look like this?\nchild_process.js:479\n    var string = JSON.stringify(message) + '\\n';\n                      ^\nTypeError: Converting circular structure to JSON\n    at Object.stringify (native)\n    at process.target._send (child_process.js:479:23)\n    at process.target.send (child_process.js:416:12)\n    at handleError (/projects/sc/node_modules/socketcluster/lib/workercluster.js:133:13)\n    at EventEmitter.emit (events.js:107:17)\n    at EventEmitter.SCWorker.errorHandler (/projects/sc/node_modules/socketcluster/lib/scworker.js:348:8)\n    at Domain.<anonymous> (/projects/sc/node_modules/socketcluster/lib/scworker.js:33:23)\n    at Domain.emit (events.js:107:17)\n    at emitError (domain.js:83:24)\n    at Domain.errorHandler [as _errorHandler] (domain.js:122:16)\n. @seiyria I think the problem in your case might be that your stack trace isn't long enough to show the root of the error inside your code. Try running with node --stack-trace-limit=1000 server.js.\n. What node version are you using? When I add --stack-trace-limit=1000, I get a really long stack trace.\n. Can you provide a simple/short code snippet I could copy-paste to reproduce the error on my machine?\n. You could also try https://www.npmjs.com/package/longjohn\n. Thanks for reporting this. Let me know how things go.\nThe --stack-trace-limit flag definitely works for me in Node v4.2.0.\nIt's weird that the stack trace doesn't go further than Emitter.SCSocket.emit - Something definitely must have called it but it's not showing. Maybe it is related to async await.\nI did fix another potential issue related to circular structure in Error objects a few minutes ago but this is not related to your problem.\n. We have now moved away from the Node.js domain module which was responsible for cyclic errors so hopefully this should no longer a problem.\n. @ryanpager When you say 5k people in a meeting - You mean that some of your pub/sub channels have over 5k concurrent subscribers? How often does the average user send a message to the channel? (On the frontend, does text just stream by really quickly?)\nDid you find out what was using up the CPU? Was it Node.js (SocketCluster) or Redis?\nAlso, do all these 5K subscribers come on all at the same time? Does it always happen or only sometimes?\nBased on the last benchmark I did, SC was able to handle 10K concurrent users per CPU core (therefore per channel since each channel can only use a single CPU core) - Each user was sending a message every 5 seconds on average (with some randomization because you don't want all messages to arrive at the same time).\nNote that a common problem that might arise when you have a lot of concurrent users is what happens when you restart the server. When you restart the SC server, all clients will be disconnected and they will try to reconnect automatically - If too many clients try to reconnect at the same time, you could get a massive amount of (re)subscribe requests and this could crash the server.\nIf you look at the autoReconnect options here: http://socketcluster.io/#!/docs/api-socketcluster-client you can specify the randomness in milliseconds (you can make it multiple minutes if you need to).\n. @ryanpager Do you find that one worker process is doing much more work than the others? Uneven distribution?\nThere were two big performance optimizations that I can think of since v2.3.x:\n- A 5x to 10x boost in handling new channel subscriptions (When clients try to establish a new subscription).\n- More even distribution of load across worker processes (changed the default schedulingPolicy to 'rr').\nSince you have a lot of cores on each machine, you may benefit from an upgrade (particularly the second point above). But note that there are a few breaking changes since then and you will need to upgrade the client too.\nNote that if you have some very large channels with 5000+ concurrent users, you might want to do more advanced stuff like \"sharding\" your channels by appending an index number at the end of the channel name (for example). So for example if you have a channel \"myGroup\", you could split it into two channels \"myGroup1\" and \"myGroup2\"... Then you can add some randomness on the frontend such that half the time, it will publish the message to myGroup1 and half the time to myGroup2... (You can add a wrapper on the frontend to abstract this).\nAn SC channel is bound to a single process/CPU-core so if you get too many messages on a single channel, it's possible that one CPU core will reach 100% while the others will stay relatively low. SC is better at handling many small/medium channels than a few very large channels. So if you have some really big channels, you may want to split them up into multiple smaller channels.\n. @seiyria Only if your bottleneck is bandwidth. Compression/decompression uses extra computational resources. It might be useful maybe if you need to deliver a small number of very popular (and large filesize) resources in realtime - Then you could store the compressed versions of these resources in a cache for example (that way you only compress once).\nThis could make sense if you have a scenario involving very low frequency channels each publishing very large JSON or binary objects to millions of subscribers.\nIt's always important to factor-in the added management complexity when making these decisions though. Stay away if possible.\n... That said, yes, you CAN do that with middleware.\n. @rohittailor You could provide a domain name (or subdomain) instead of an IP address for your Redis instances - Then you can setup a load balancer on that subdomain and loadbalance between the two Redis instances (the load balancer could detect if a Redis instance is down and stop sending traffic to that instance).\nYou could try setting up Redis cluster - But I haven't tried it myself so I can't really help much with that.\n. @alphashuro Thanks for pointing this out, that was a pretty massive gap in the documentation!\nThe code snippet should be a bit more clear now. Also, I added links to more docs.\nhttp://socketcluster.io/#!/docs/getting-started\nAs for answering the question. You need to call var socket = socketCluster.connect(options); to create new sockets. The options argument is optional - See http://socketcluster.io/#!/docs/api-socketcluster-client\n. @alphashuro If you install the full framework using the CLI socketcluster create myapp command, it will install the client for you automatically.\nBut you can install the server and client separately too if you like... Or sometimes you may want to update the client without updating the server, that's fine too.\n. Thanks for the feedback.\nYou install the socketcluster cli through npm using npm install -g socketcluster then you can generate the project using socketcluster create myprojectdir.\nBut yes, I agree we should add more instructions to make this clearer and to give the user options.\nThe website http://socketcluster.io/#!/ is open source https://github.com/socketcluster/socketcluster-website so feel free to contribute if you have any ideas (pull requests welcome).\nI've been involved with SC for a while now so it's hard to me to notice all the gaps in the docs like a fresh pair of eyes :p\n. The actual website docs in are in the repo here: https://github.com/SocketCluster/socketcluster-website/tree/master/public/app/views/docs\n. Yeah I should probably encourage everyone to contribute to the docs more. Especially now that the API has become pretty stable.\n. Yeah sure :)\n. @mattkrick I like the idea of passing custom data to the options object. So the signature would still be:\nsocket.subscribe(channelName[, options]) but the options object could be like (example with waitForAuth set to true):\n{\n  data: someData,\n  waitForAuth: true\n}\nTo keep backwards compatibility.\n. Ok, this was implemented in socketcluster-server v4.1.11 and socketcluster-client v4.3.14 - You'll have to do an npm update to get the the latest changes.\nIt works as described above; you can add a data option to the subscribe call.\nInside SUBSCRIBE middleware, there will be a new req.data property (might be null if no data was provided). Also, the 'subscribe' event on both the client and server will now have a subcriptionOptions object as the second argument to the event handler - The data property will be in there and contain whatever data was passed.\nLet me know if this is suitable or if we can improve it in any way.\n. Yes that's on my TODO list :)\n. That's been done... There is now a new warning that comes up related to node-fs-extra... We will upgrade at some point but it's not really a problem anymore.\n. The instructions are here http://socketcluster.io/#!/docs/debugging\nThis error means that you already have a process running on that debug port. You should check what it is using fuser 5858/tcp and then kill theprocesspid. Then run SC again.\n. @costa974 Yeah the visual studio debugger doesn't work very well with SC.\nBecause SC runs as multiple processes, you have to tell it which processes you want to debug. See http://socketcluster.io/#!/docs/debugging\nIf you use Node.js v6.4.0 or higher, you can launch Node.js using the command line with an --inspect-workers flag - Then you will be able to debug from inside your Chrome browser.\nYou just have to add debugger; statements in your code where you want the debugger to pause.\n. Ok fixed in SC 4.3.5 - If it still doesn't work you may need to do npm update from inside your project directory to get the latest socketcluster-server dependency https://www.npmjs.com/package/socketcluster-server to version 4.1.12.\n. @hopewise Which version of Node.js are you using? Did you try to npm install -g ... as as root?\n. @hopewise Yes adding storage would consume extra CPU and memory. There is a CRUD plugin which allows storing data in RethinkDB using CRUD operations from the frontend (with realtime updates) - You can achieve the same results as data sync except without native conflict resolution support.\nData sync with automatic conflict resolution can be really clumsy, we prefer to let the frontend know that the connection has been lost and let the frontend decide how they want to recover from a period of lost connection (and let the developer decide if (or how) they want to do their own conflict-resolution or just show the user an error and tell them that their connection is bad).\nYou can have a look at this boilerplate if you want to see a sample app (all data is updated in realtime with pagination): https://github.com/socketcluster/sc-sample-inventory - We also made some Polymer components to bind to the data in realtime (See README).\n. @jayesh-sapkale Yes that works but be careful though because if you add a second worker process to SC, you may find that the client you're looking for is connected to a different worker than your current one...\nOften it's better to use pub/sub channels and let clients choose what channels they want to subscribe to instead of trying to target specific clients from the server-side.\n. @jayesh-sapkale SC also has a socket.request object on the server-side to access the express session. It should be the same.\n. uWS already did a pretty good job with this.\n. @jfsimon You can't subscribe on behalf of client sockets from the server directly - It encourages bad habbits and creates overlapping concerns between the client and the server (which can get messy and become prone to race conditions).\nYou can do the approach as you described but the best way is to use the MIDDLEWARE_SUBSCRIBE middleware to block the subscribe request before it is even processed by the SC server. See http://socketcluster.io/#!/docs/api-scserver\n. @jfsimon next() (no args) to pass next(errorObject) to block. You SHOULD call next in any case (eventually) otherwise SC will just hang on to the connection until it times out (which works but isn't ideal).\n. @frank-dspeed Looks good, thanks!\n. @jayesh-sapkale Sorry for the long delay to respond... There is no 'session' object in SocketCluster. But you can set a JWT token using socket.setAuthToken({username: 'foo123'}) then later, you can access that token from both the client and the server using socket.authToken - You can store any information inside the token but don't store any private data like passwords.\nSee http://socketcluster.io/#!/docs/api-scsocket-server\n. @ansarizafar It works fine in Firefox for me. Which version are you using for the client and the server?\n. @ansarizafar What options are you using on the server (SocketCluster constructor) and client?\nAlso is your device behind a firewall/corporate network?\n. @ansarizafar It's difficult to say but these types of issues are usually caused by a mismatch between the client and server settings. Maybe the port numbers don't match, or maybe the hostname is incorrect...\nThe best way to check is to use the simplest settings possible, check that it works and then gradually add more options.\n. When I visit that link using Chrome, I'm also getting SocketProtocolError: Socket hung up (same as Firefox).\nAlso, you shouldn't specify the protocol option on the client.\n. I'm on Ubuntu with Chrome 48.0.2564.109 (64-bit). Did you clear the browser cache?\n. I'm getting\n```\nWebSocket connection to 'ws://server-hlynjegodp.now.sh/socketcluster/' failed: Error during WebSocket handshake: Unexpected response code: 301\nEXCEPTION: SocketProtocolError: Socket hung up\n``\n. Maybe we can chat here instead: https://gitter.im/SocketCluster/socketcluster\n. WHen I look at the ws:// request (in Chrome still), it says 301 Moved Permanently\n. ![screenshot from 2016-05-26 00-07-56](https://cloud.githubusercontent.com/assets/1187447/15542934/2d19605a-22d6-11e6-85d6-a54c39790be8.png)\n. Something is sending back a301 moved permanentlyresponse code.\n. Is it possible to invoke a global socketCluster.connect from the console somehow (for me to test)?\n. This is very unlikely (though I'll admit, not impossible) to be a problem with SC itself - Otherwise others would have noticed the issue too. Plenty of people/companies are using SC with various frameworks including ionic and React native in production right now so there must be something else happening.\n. Are you running this behind a proxy/load balancer?\n. I keep getting status code301which is not something the SC server would ever send back.\n. Maybe try reinstalling socketcluster client and server from scratch. Inside your project directory:npm remove socketcluster && npm remove socketcluster-client`\nthen\nnpm cache clean\nthen\nnpm install socketcluster && npm install socketcluster-client\nor you can also try:\nnpm update\n. What's your Node.js version?\n. Node.js v5.4.0 and 6.1.0 both work for me so that can't be the problem.\nAlso, does setting wsEngine: 'ws' fix it?\nTry to setup a completely new project from scratch:\nsudo npm remove -g socketcluster\nthen\nsudo npm cache clean\nthen\nsudo npm install -g socketcluster\nthen\nsocketcluster create newproject\nthen cd inside newproject\nthen node server\nthen visit in browser http://localhost:8000\nIf that doesn't work then there must be something strange happening - Maybe you have a Firewall on your machine which is blocking WebSocket connections?\n. It works for me in every browser locally and deployed remotely and it seems to also work for the hundreds of developers who downloaded and used SC today (many of who have surely tested it in every modern browser including Chrome, Firefox, Safari, Opera and others).\nI believe 100% that it's not working for you.\nBut I suspect that there is something unusual about your machine which is causing the problem. Sorry I cannot be much help there. Your best chance is to try a fresh setup from scratch - And try getting THAT to work locally before trying anything else.\nYour issue is probably not straight forward.\n. @sandyplace Does it work in Firefox for you?\n. @efkan What kind of clients are you using? I can't reproduce. Are you using the JavaScript socketcluster-client or the client for Android? Also, what is your version of socketcluster?\n. @efkan This error means that the  client socket is disconnecting incorrectly - Without sending a close control frame. I cannot reproduce this issue so far.\nIs there something in your code which could be blocking a close message? E.g. Are you using middleware? The SC client should send a '#disconnect' event before it disconnects itself (maybe the server doesn't receive this message for some reason?).\n. @efkan The SocketProtocolError: Socket hung up warning shouldn't cause problems and is generally safe to ignore.\nYou can change the logLevel option on the server to 1 and that should hide 'warnings'.\nOr you could even set the logLevel to 0 and log all the errors and warnings yourself using the SocketCluster master object's error and warning events (so you can be more selective about which ones to show).\n. @aamirmsw check:\n- That the client is pointing to the correct host and port\n- That you are using matching security level on the client and server I.e. ws:// vs wss://\nCan you paste you socketCluster.connect(options) call here? What does your options object look like?\n. @aamirmsw Is your server running on port 8000?\nWhat version of Node.js and socketcluster and socketcluster-client are you using?\n. The client option to connect should be hostname: '127.0.0.1' instead of host: '127.0.0.1'.\n. @493326889 ^\n. @493326889 That's because SC will reuse connections by default. To turn this off, you can set the multiplex option to false here: http://socketcluster.io/#!/docs/api-socketcluster-client\n. @facundoolano Thanks. Fixed. http://socketcluster.io/#!/docs/authentication\n. @micyee - As @MegaGM mentioned, a client socket in SocketCluster is still alive even when it is disconnected - By default it will reconnect itself when the internet connection can be reestablished. It doesn't make sense for the handlers to be removed just because the socket is currently disconnected.\n. @naelt Why do you need to do that?\nTo answer your question directly: Yes you can. That is pretty advanced usage though, so be careful.\nSC lets you define your own mapping function: see setMapper(mapper) here http://socketcluster.io/#!/docs/api-exchange (accessible as scServer.exchange.setMapper(function (key, method, clientIds) {...});) - Make sure you invoke it when your instance launches and not at runtime (or else existing channels would get lost - SC does not do runtime rebalancing of the shards).\nThe mapping function takes a key, a method and an array of all available broker clientIds as arguments and returns the index of the broker/client which the action should be routed to.\nSC's default mapper can be seen here (feel free to copy and then modify for your own purposes): https://github.com/SocketCluster/sc-broker-cluster/blob/master/index.js#L447-L478\nAlso, you may want to use/copy this hashing function here too: https://github.com/SocketCluster/sc-broker-cluster/blob/master/index.js#L412-438\nYou need to be careful though when you change the mapping/hashing functions - The default ones have been tested and are optimized so that load is distributed evenly between brokers (based on channel names), if you write your own mapper function, it's possible that channel names (for example) will not be evenly distributed.\nThe best strategy is probably to copy the default mapper and hash functions from https://github.com/SocketCluster/sc-broker-cluster/blob/master/index.js#L412-438 and then customize them to add a few edge cases if necessary. Try to keep the mapping function generic so that you don't have too many edge cases or else you probably won't get even distribution.\n. @trzyrazyzero Yes, you can setup a global channel like 'some-global-channel' and make all your client sockets subscribe to it using\nsocket.subscribe('some-global-channel').watch(function (data) {\n  console.log('GLOBAL', data);\n});\nThen, whenever you want to broadcast a message to EVERY client, you just do socket.publish('some-global-channel', {foo: 'bar'});\n. No but it's the most scalable way. With this approach, your system can scale infinitely to any number of users. Another approach is to iterate over all scServer.clients and call emit(...) on each socket individually but this doesn't scale as easily and will require a lot more work.\n. @seiyria Yes you can set the logLevel option to 2.\n. @seiyria Sorry I mean logLevel 1 - See http://socketcluster.io/#!/docs/api-socketcluster\n. @trzyrazyzero You could have each client subscribe to their own channel, for example:\nsocket.subscribe('test_alice').watch(function (data) {\n  abc(data);\n});\nand then when you want to send a message to the user 'alice', you would go:\nscServer.exchange.publish('test_alice', 'some string');\nThe trick is to incorporate a username or userid as part of the channel name itself. SC is really good at handling LOTS of unique channels.\n. @MegaGM ??\n. @picitujeromanov If you do npm cache clean and then install again, it should fix it. Let me know if you still get issues. Make sure you get the latest https://www.npmjs.com/package/socketcluster-server dependency.\n. @efkan Make sure you do npm cache clean before you install. You need to make sure you have the latest socketcluster-server dependency https://www.npmjs.com/package/socketcluster-server\n. SC also has cross-browser and cross-device support. Older corporate firewalls can block raw ws:// traffic. In this case you will find that using wss:// should fix the problem (firewalls don't typically block SSL traffic). You just have to provide a key and certificate to the main SocketCluster constructor.\n. What do your configs look like? Are you using uws or the default ws module as the WebSocket engine?\n. @tephro SC is currently using uws version 0.6.3 - You could try upgrading the dependency to uws v 0.7.0 and see if that fixes the problem?\nIf not, does switching to plain ws fix the problem?\n. @tephro Cool, I will update the default uws version to 0.7.0. Let me know if you run into new issues.\n. SC shards data between multiple workers, it doesn't synchronize the data - You'd have to do it yourself. SC always tries to use the most scalable approach and synchronization is not scalable beyond a certain point.\n. @vicneanschi as @jrylan mentioned, you can use channels. SC is designed to handle lots of concurrent channels. Each SC worker can handle over 20K channel subscriptions per second if you're using the uWS engine.\nOther than that, SC doesn't have explicit namespaces - All events and channel names are plain strings but you can have your own conventions. You can implement a URL-like scheme when emitting events like 'service-1/event-name'.\nBut yeah, I highly recommend trying out channels.\n. @mirague What version of Node.js are you using? Do you run node with the --use_strict flag?\nI can't reproduce it on the latest Node.js v.6.1.0 - This is quite strange since '\\033[0m' is not an octal literal - It is a string. Maybe it's an issue with Node.js?\n. @mirague Nevermind OK, I can reproduce.\n. @mirague Ok, this has been fixed in socketcluster v4.6.3. Note that you will also need to update the dependency sc-broker-cluster to 2.0.3 since there was an issue with the async module in strict mode.\n. @mirague done. If you upgrade the socketcluster-server dependency to v4.2.9, it will have the latest uWS installed.\n. @mattkrick It sounds great but I would like to have all these changes as v6 and v7.\nI would like to use version 5 to release two important features:\n- SCC (SocketCluster for Kubernetes)\n- Make uWS the default WebSocket engine\nThey are not 'breaking changes' but I would like to dedicate a major version to them because they're a pretty significant step forward.\nI think it would be good to maintain backwards compatibility for these two features because some existing users of SC could benefit from them.\nI can probably release v5 next week so it's very close. But yeah, we can get started with v6 pretty much straight away.\nI think simplifying/breaking the API for v6 is fine.\n. Also maybe for v6, we should consider changing how users handle internal SC events (coming from the same side of the connection) versus custom transmitted events (coming from the opposite side of the connection). See https://github.com/SocketCluster/socketcluster-client/issues/58\n. Regarding the doubled nested data; I agree that's confusing - The best way I can explain it is that the outermost data property holds the entire event data (at the most basic protocol layer in SC). In the case of a publish action (for example), this data property will contain a nested data property which holds sub-protocol data (related specifically to the publish action).\nHaving nested property names like this isn't uncommon when trying to represent nested levels of resources (or actions in this case). Kubernetes for example, has a nested spec property (see http://kubernetes.io/docs/user-guide/deployments/) this is confusing at first but the top level spec is the specification for the deployment whilst the nested one is for the pod template (which is a lower-level concept).\nMaybe using a different (but also short) name than 'data' (maybe 'payload' or 'body') might be nice but I'm very careful about breaking backwards compatibility at the protocol level (but breaking backwards compatibility at the API level is fine).\nThere are quite a few unofficial SC clients which rely on the current protocol and they would all break (and won't get fixed for a long time) if we change the protocol in a non-backwards-compatible way.\nRegarding combining socketcluster with socketcluster-server; that's tricky because some people are using the socketcluster-server as a standalone when they need extra flexibility. Using socketcluster (as a whole framework) adds a level of process management and other complexity which is good for most cases but some people don't like it because their tooling (or IDEs) doesn't play nice with it or other reasons. I also want to keep them separate for now because it might be useful for integrating SC with Docker more closely in the future.\n. @happilymarrieddad Something along these lines would be good.. Now I'm thinking that async/await is the next step.\nNode.js v10 now has support for async generators so we could implement async streams which could behave similarly to Observables.. @Charuru It's usually not a problem, it just means that some of your clients are disconnecting abruptly without closing the connection with a handshake. Maybe they closed their browser without warning or their machine went to sleep. There are a several normal scenarios that can cause this.\nIf you get a HUGE number of these (compared to how many total users use your system) then maybe you should investigate why that is but it is not abnormal to get those warnings and you can usually ignore them.\nIf it was a network issue, you would typically get ping timeout errors too.\n. @Charuru To not log warnings, you can set the logLevel option to 1 when instantiating SocketCluster on the server. See http://socketcluster.io/#!/docs/api-socketcluster - You can still listen to the warnings without necessarily logging them by listening to the 'warning' even on the SocketCluster master instance.\nBut it's generally not a problem to just log the warnings even if you don't use them.\n. @cometta @mattkrick Ok I implemented the fix in v5.0.9. Note that if you use the --inspect flag like node --inspect server; that will debug the master process (server.js).\nIf you want to debug workers, you need to add an --inspect-workers flag AFTER the server argument like this: \nnode server --inspect-workers\nYou can also debug broker processes using --inspect-brokers like this: \nnode server --inspect-brokers\nI've updated the docs here http://socketcluster.io/#!/docs/debugging with info about the --inspect flag.\nNote that there is currently a minor 'bug' in Node.js which prevents you from setting custom debug ports for the workers when using the --inspect-workers=${startingPort} flag. This is should not be a problem if you are happy to use the default ports.\nI raised an issue on the Node.js repo: https://github.com/nodejs/node/issues/8201\n. @mattkrick You need to update dependencies too:\n- sc-broker v2.2.2\n- sc-broker-cluster v2.1.4\n. Note that recently there was a similar issue related to using the top-level --inspect flag to debug the master process. This has been fixed in socketcluster v9.3.3.. @deoqc Running two instances side by side works for me (but I don't use the concurrently command). Could you check:\n- Both your dev and test instances use the same code base?\n- Which version of sc-broker-cluster https://www.npmjs.com/package/sc-broker-cluster are you using? (anything 2.1.1 or higher should be fine) \n- Which version of sc-broker https://www.npmjs.com/package/sc-broker are you using? (2.2.0 or higher should be fine)\n- Which version of Node.js are you using?\n. @deoqc I checked with concurrently, it works for me. Let me know if you find the solution or if you have more details.\n. @deoqc if you create a brand new project from scratch using socketcluster create my-new-project and then run to instances of it with concurrently does it still have the problem? I have everything the same as you described but it works.\nWhat OS are you using?\n. @deoqc Are you changing environment variables inside your code at runtime?\n. @deoqc I made an update to socketcluster - Now v5.0.2 - It fixes a separate issue with OSX (which caused issues when running multiple brokers in a single instance). Maybe it will also fix your issue? Let me know. I am not able to test on OSX right now.\nAlso, if you run with sudo, does it solve the issue?\n. @deoqc Try:\n- Removing the appName from your options - Let SC generate it for you.\n- If that doesn't work, make is so that the two instances have a different appName (maybe add random numbers at the end?)\n. @ivan1986 You can modify the data object by adding, removing and modifying properties - You currently cannot replace it though.\nSo you can do this:\nscServer.addMiddleware(scServer.MIDDLEWARE_PUBLISH_IN, function (req, next) {\n  req.data.foo = Math.round(Math.random() * 1000);\n  next();\n});\nThen if a client publishes like this:\nsocket.publish('sample', {hello: 'world'});\nIf you are subscribed to the 'sample' channel, you will receive a message like:\n{\n  \"hello\": \"world\",\n  \"foo\": 658 // The middleware added a random foo property\n}\nA few versions ago, this didn't work for the MIDDLEWARE_PUBLISH_OUT middleware, but if you use a newish version, it should definitely work too. (So this approach should work with every middleware type including MIDDLEWARE_EMIT).\nOf course the current approach forces you to publish objects as messages - You can't modify raw strings or numbers directly by reference for example. This is because SC doesn't currently offer an API to replace the default data.\n. It looks like the behaviour of various middleware is inconsistent when it comes to REPLACING the req.data object - The MIDDLEWARE_PUBLISH_IN middleware allows it but not the others.\nI will see if I can change this to always allow replacing the object.\n. @ivan1986 If you upgrade to socketcluster v5.0.4 - You can now replace the entire req.data object inside all realtime middleware so you can now replace the entire message it no longer has to be an object.\n. @sacOO7 I started writing up the protocol here: https://github.com/SocketCluster/socketcluster/blob/master/socketcluster-protocol.md\n. @ayZagen There is for Swift (iOS), Objective-C (iOS) and Java (Android) https://github.com/socketcluster/client-drivers#list-of-clients. @chegewara if you want to run SC as multi-machine cluster, you need Node.js version 6. I will add this in the README.\n. @chegewara What do you pass as the clusterStateServerHost option in server.js? Make sure it's null.\n. @amekkawi Yep, that was out of date. I fixed it now. Thanks.\n. @amekkawi There is a 'workerExit' event which you can listen to in the master process server.js (on the main SocketCluster instance) - It wasn't in the documentation though so I updated it ;) http://socketcluster.io/#!/docs/api-socketcluster\n. Oh I see. Yes, that's not ideal.\nIdeally all child processes should be shut down if there is an error in server.js.\nI guess the solution for now is to add something like this to server.js:\n```\nprocess.on('uncaughtException', function (err) {\n  console.error(err);\n  socketCluster.killWorkers(); // This will kill the workercluster master too\n  socketCluster.killBrokers();\nprocess.exit();\n});\n```\nI'll make a patch to make this behavior the default.\n. @amekkawi Ah yes, using the 'disconnect' event inside the child processes sounds like the best approach - I did some quick testing and it looks like it's going to work :)\n. @amekkawi Ok, I fixed it using the 'disconnect' technique you described. It was a good opportunity to cleanup some old code in there which was needlessly complicated; your feedback is much appreciated. I published to npm v5.0.7. Note that if you upgrade, you will need to make sure you have the sc-broker v2.2.1 dependency since I had to change the shutdown logic there too (as you assumed).\nLet me know if there are any issues.\nAlso feel free to submit PRs if you like. Raising issues like this is always a good way to contribute though.\n. SC uses plain WebSockets as the protocol (which offers the same in-order delivery guarantees offered by TCP). Because of this, delivery is guaranteed during the course of a single SocketCluster connection. \nIf however, the connection is lost (and the 'disconnect' event triggers), then the delivery is no longer guaranteed and you (the developer) are responsible for retransmitting that message - You can add a callback to your socket.emit('eventName', data, callback) to check. But note that you will have to manage this yourself or use a library. You may be able to adapt your SC socket object to work with socketgd - It looks like it uses a 'reconnect' event - SC only has a 'connect' event (including for reconnects) but you can check yourself whether this is the first connection or not and emit the 'reconnect' event yourelf on the socket.\nSee http://socketcluster.io/#!/docs/handling-failure for more details about acknowledgements.\n. @luozan You can't subscribe a client to a channel from the server side directly, but you can emit an event from the server socket.emit('askClientToSubscribe') then on the client:\n(example)\nsocket.on('askClientToSubscribe`, function () {\n  soket.subscribe('someChannelName').watch(function (data) {\n    // ...\n  });\n});\nSubscribing on behalf of the client from the server side is generally considered to be a pub/sub anti-pattern.\nWhat is your use case?\n. See https://socketcluster.io/#!/docs/running-in-production. @py09mb Well spotted!\n. @wtgtybhertgeghgtwtg Ah yep, this is now in the sc-auth module. Thanks.\n. @mkgn If you pass a callback to the socket.emit(eventName, [data, callback]) function, the socket will expect a response to the event from the server and if it doesn't get a response, you will get a timeout error.\nSee emit function here: http://socketcluster.io/#!/docs/api-scsocket-client\nTo respond to the event from the server, you can just have:\nsocket.on('myEventName', function (data, respond) {\n  // ...\n  respond(); // Respond without anding back any data.\n  // or... respond(new Error('This is a custom error'));\n  // or... respond(null, {data: 'Sending back an object...'})\n});\nThe same applies if you emit from the server side; in this case, the client would need to respond.\nOr alternatively, you can choose NOT to provide a callback to the emit function and then you don't need to respond. The existence of the callback tells the socket that you're expecting a response to this event.\n. @hustcer How long does it take for the promise returned by the getCapitalFlowOfDay call to resolve?\nThe main thing I can think of is that SC has a default maximum timeout for responding to events - It's 10 seconds by default but you can change it by specifying it as an option on the server side. Search for ackTimeout here: http://socketcluster.io/#!/docs/api-socketcluster\nI think this is partially a documentation problem; looking at the docs, the timeout isn't mentioned enough. Also maybe we should increase the default ackTimeout from 10 seconds to 15 seconds?\n. @hustcer Hmm yes that sounds weird. Maybe one of the SC dependencies was out of date (incompatible with the SC version) and was breaking stuff.\nWhenever I've had really weird issues, using npm cache clean and then reinstalling all of SC from scratch (including all dependencies) usually fixes the problem. npm cache can be pretty aggressive.\n. @CoveTechnologyAus SC should be able to pick up and verify your JWT token automatically if it has the same authKey as the one which you used to sign the JWT token. Search for authKey here: http://socketcluster.io/#!/docs/api-socketcluster\nSC client socket will automatically pick up the JWT token from localStorage and pass it to the server during the handshake phase. By default, the client will look for the key socketCluster.authToken inside localStorage to get the token.\nYou can specify a custom localStorage key using the authTokenName option when you create the client socket. See http://socketcluster.io/#!/docs/api-socketcluster-client\nYou can also provide a custom authEngine if you want more control over how tokens get loaded into your SC client. you could change the default authEngine to load from a cookie if you like but this is a more advanced use case.\n. If you want to provide your own authEngine to the client, it must be an object which exposes the following functions:\n- saveToken(name, token, options, callback)\n- removeToken(name, callback)\n- loadToken(name, callback)\nThe default authEngine is here: https://github.com/SocketCluster/socketcluster-client/blob/master/lib/auth.js\n. Check https://socketcluster.io/#!/docs/authentication and https://socketcluster.io/#!/docs/middleware-and-authorization. @mkgn Inside the MIDDLEWARE_HANDSHAKE middleware, the query string will be part of the URL req.url or on a socket, you can use socket.request.url you can use the native Node.js module url.parse(req.url, true) to parse it into an object.\n. I'm not sure what you're trying to do here... There might be more than one thing wrong with this code; maybe you should try to think through it a bit more.\nBased on what you provided, this looks wrong:\nscServer.on('handshake', function (socket) {\n    accesscontrol.attach(scServer, socket); \n});\nThis will add new middleware for EVERY new connection - You should only attach it once and you don't need to pass a socket as the second argument.\n. Maybe you mean to use https://github.com/SocketCluster/sc-sample-inventory/blob/master/sc_modules/authentication.js instead of https://github.com/SocketCluster/sc-sample-inventory/blob/master/sc_modules/access-control.js\nAuthentication and access control are different concepts.\nAuthentication is about verifying that the user is who they claim to be (checking their identity based on a token or password).\nAccess Control is about verifying that this person (based on their authentication credentials) is allowed to perform specific actions.\n. I guess there isn't much point in answering this question now.. @ubaidseth I'm not sure what you're trying to do here. socket.exchange.destroy() doesn't accept any arguments - It's an undocumented function and its purpose is to destroy the entire pub/sub exchange (which will basically shut down pub/sub message brokering for the entire worker) - You shouldn't use this function - It's only for internal use. Be careful when using undocumented functions.\nTo answer your question, on the server-side, you don't have to cleanup channels which were subscribed to by a client socket - A channel which was created on the client is ephemeral on the server and will automatically get cleaned up and garbage collected once it no longer has any subscribers.\nOn the client side, channels are created manually so if you want to completely remove a channel from memory, you need to explicitly call socket.destroyChannel(channelName) - See http://socketcluster.io/#!/docs/api-scsocket-client\nIn SC, the frontend is responsible for explicitly creating and managing channels - The backend logic for handling channel subscriptions and unsubscriptions is automatic.\nNote that channels use very little memory though so you generally don't need to destroy them unless your app has lots of dynamically-generated channel names which keep piling up. If you unsubscribe from a channel on the client and there are no other subscribers to that channel, then the server will automatically cleanup the channel on the backend (you don't have to destroy the channel from the client for it to get cleaned up on the server).\n. @ubaidseth When a client disconnects, all its channels attached to that client will be automatically unsubscribed from (and cleaned up) on the server-side; on the client side, the channels will show up in a 'pending' state (because we did not unsubscribe from them explicitly).\nIf the client reconnects, then all pending channels will be automatically re-subscribed to.\n. Are you using the functions correctly?\nTo emit (event 'arr'):\nsocket.emit('arr', ['This', 'is', 'an', 'array', 123, 456])\nTo publish (the 'arr' channel):\nscServer.exchange.publish('arr', ['This', 'is', 'an', 'array', 123, 456])\nI just tested it and it works fine.\nIf it still doesn't work, what's your SC client and server version?\n. @willypuzzle What are you emitting exactly?\n. @willypuzzle How is it not working? Do you receive an events on the other side?\nDo you use socket.on('eventName', function (data) {/*...*/}) on the client?\n. Or you get nothing at all?\nDoes it throw an error?\n. Are you using a reserved event name? https://github.com/SocketCluster/socketcluster-client/blob/416982105e86494e4f6b12f0244b67b702618588/lib/scsocket.js#L56-L71\n. Can you paste a simplified version of your code so that I can reproduce the problem on my machine?\nSending an array is an extremely common use case, so I need to understand what is different about your case which makes it not work.\n. Also, did you add any custom SC middleware? Check that you're not blocking anything inside your middleware.\n. @willypuzzle Are you sure you are emitting a raw object and not a function/class? Maybe Mongo returns a special Model instance (not a raw JSON-compatible object)?\nI think Mongo offers a way to convert to JSON objects.\n. @willypuzzle That's strange because SC essentially just calls JSON.stringify on the object, sends it over the wire and then passes the string to JSON.parse so you shouldn't have to do it again - It just uses up extra CPU for no good reason.\nSC also converts binary Buffer/ArrayBuffer objects to base64 strings before calling JSON.stringify on the object. See https://github.com/SocketCluster/sc-formatter/blob/825137d765eaa43b14b275a1196b20974cfd803e/index.js#L86 but this shouldn't affect anything in this case.\nCan you reproduce the issue without using MongoDB? Can you create a dummy hard-coded object or array that doesn't work?\n. @willypuzzle Ok, I made a change to the sc-formatter module which should make SC better at dealing with complex objects such as Mongoose model instances... Make sure you npm update the sc-formatter dependency to the latest version. You may also want to update the socketcluster-client to v 5.0.13.\n. @willypuzzle If you call JSON.stringify on the MongoDB model, how does the ObjectId get stringified? Does it also become \"1\" or \"0\"?\n. @willypuzzle I tested SC with the latest sc-formatter and sent a mongoose model to a client socket (I tried both publish and emit) and the _id field (of type ObjectID) got stringified correctly (in the format \"546fa534f65f5d0200855501\"). Are you sure you have the latest sc-formatter v2.0.2 dependency?\nI cannot reproduce this issue. Do you have any SC middleware defined which might be messing with the _id field in the output?\n. @willypuzzle No time was wasted. I made a small improvement to sc-formatter as a result of this discussion so it was useful.\nSometimes it's hard to tell where the root of the problem is... Feel free to reopen this issue later if it turns out to be SC-related.\n. @hustcer @happilymarrieddad Sorry. My fault. I renamed a function to encode instead of stringify and forgot to update it in sc-broker-cluster.\nIf you npm update sc-broker-cluster to version 2.1.5 that should fix it.\n. @happilymarrieddad Arghh, yep I'm on it now...\n. @happilymarrieddad ;p\nOk, I fixed it for real this time (and tested) you have to update socketcluster to v5.0.16 and make sure you have all the latest dependencies including sc-broker-cluster v2.1.7 \n. @happilymarrieddad I don't think npm allows this for security reasons.\n. I just have to be more careful. Maybe I should wait till the weekend to publish risky changes. Even well established projects will occasionally release a buggy version.\nI really should write more tests and think of adding CI to prevent these kinds of issues.\n. @happilymarrieddad Haha. Let me assure you that the specific individual(s) responsible for this issue have been swiftly reprimanded. It won't happen again.\n. @happilymarrieddad Can you tell me the version numbers of the following dependencies for your staging env and also your production env (to make sure that they're the same):\n- socketcluster-server\n- sc-broker\n- sc-broker-cluster\nAre you setting a custom secretKey or changing it at any point during runtime? (you might want to search through your code for references to secretKey - This shouldn't change at runtime - To change it, you should restart your entire SocketCluster instances (all processes).\nBasically it means that your worker process has a different secretKey from your broker process. The secret key is passed from the master process to all children processes (both workers and brokers) during initialization phase.\nI sounds like it's caused by either:\n- The options.secretKey (in either master, worker or broker) gets changed in your code somewhere during runtime - And this causes the mismatch. Or;\n- For some reason the worker and broker processes have different parent master processes... Maybe a child broker process was left over from a previous deployment and somehow SC thinks it belongs to the current instance.\nI will try to reproduce on my end.\n. @happilymarrieddad A good test to do would be to add a console.log('SC SECRET KEYS:', command.secretKey, scBroker.secretKey) on line 187 of sc-broker/server.js just above the line result.error = 'Invalid password was supplied to the broker'; - You should log it when everything is working fine, then wait a few days for the error to show up and check if any of the secretKey values have changed since last time (they should never change unless you restart the SC master process).\nIf one of them did change, it would tell us whether it's the broker or the worker which has he wrong key.\n. @happilymarrieddad how did you terminate SC though? Maybe there is an issue there... It shouldn't leave behind old processes.\n. @wmertens There is!\nYou can run the server directly https://github.com/socketcluster/socketcluster-server - The client-side API will be 100% the same. On the server side the API is also the same except that there is no scServer.exchange object. You just have to add a bit of extra code to attach the server to a Node.js http server object but yeah, it runs in one process.\n. In theory, assuming that you don't use the scServer.exchange object; you could run socketcluster-server for development and use the full socketcluster framework (with multiple processes) in production only depending on your deployment setup.\nThere are also ways to use hot reload with the full socketcluster framework but I haven't looked into Webpack's hot reload feature specifically.\n. @ivopc Ok I've fixed this in socketcluster-server v5.1.3.\nThat's a pretty important issue actually. Thanks for digging in.\n. @bicho Thanks :)\n. @ivopc You're not wrong, SC will automatically pass channel messages across multiple workers on a single host.\n. @ivopc To scale across multiple hosts, you need to synchronize your brokers using a different system like Redis.\nSince recently, we've also introduced a number of components to make it much easier to scale SC horizontally. We call these components SCC; see https://github.com/SocketCluster/socketcluster/blob/master/scc-guide.md\n. @ivopc I tried passing a number and an ArrayBuffer as query (in the socketCluster.connect({ query: new NotAJsonData }) function) instead of NotAJsonData but could not reproduce. What version of SC are you using? What are you passing as NotAJsonData?\n. I've made a change in SC v5.0.18 which makes it handle bad errors/warnings such as null so that should stop workers crashing. It's still strange because errors/warnings should never be null... So I'm not sure what's happening there. Make sure that your sc-errors dependency is updated to v 1.0.6.\n. Let me know how I can reproduce the error you had though (what should I make NotAJsonData)?\n. @ivopc Maybe there isn't something else happening in your code which is causing this issue? It would be interesting to know what is happening here. I can't reproduce it.\nThanks for helping out with this.\n. The lack of follow-up seems to indicate that it all worked out in the end?. @carlmathisen Yep, the MIT license in the main SocketCluster repo covers all sc-related dependencies. Feel free to make PRs.\n. It's all MIT.. On the client side, you can pass custom query parameters:\nsocketCluster.connect({query: {someKey: someValue, anotherKey: anotherValue}});\n^ You can pass the result of a previous HTTP get request as query parameters.\nthen, from the server-side, you can access those inside the 'connection' handler using something like:\n```\nvar url = require('url'); // The Node.js core url module\n// ... then inside the 'connection' handler:\nvar urlParts = url.parse(socket.request.url, true);\nconsole.log(urlParts.query);\n```\nYou can also do a similar thing using cookies.\n. @trzyrazyzero \nThe best (and also simplest) way to do authentication in SC over HTTP is by creating and signing a new JWT token from express and sending it to the client-side (as a string in the response); then, once you get that token on the client side, you just need to add it to localStorage under the key 'socketCluster.authToken' (this is the default JWT localStorage key). SC will automatically pick it up from local storage when a new connection is created.\nWhen you create and sign the JWT token inside your express route, you need to make sure that you use the same key as specified inauthKey when instantiating SocketCluster. Scroll down to the authKey option here for details: http://socketcluster.io/#!/docs/api-socketcluster (you can get it inside your worker.js using worker.options.authKey).\nYou can also change the default auth engine which SC uses on the client side if you have more advanced requirements (e.g. if you want to store and load the JWT from cookies instead of localStorage) but localStorage is the simplest approach and works the best on all modern devices.\nAlso, see this guide for more details: http://socketcluster.io/#!/docs/authentication\n. @trzyrazyzero Good question.\nYou can create the JWT token however you like (so long as it meets JWT specifications). In Node.js, you can use the jsonwebtoken module directly: https://www.npmjs.com/package/jsonwebtoken\nor for convenience you can also use SC's internal worker.auth.signToken(...) function like this:\n``` javascript\n// Sample token data, don't store any sensitive/secret data here\n// it will be signed but not encrypted.\n  var myTokenData = {\n    username: 'bob',\n    language: 'English',\n    company: 'Google',\n    groups: ['engineering', 'science', 'mathematics']\n  };\n// worker.options.authKey below is the key which SC uses internally to verify the token.\nworker.auth.signToken(myTokenData, worker.options.authKey, null, function (err, token) {\n    // The token variable is the signed JWT token; you can send this to your frontend\n    // however you like (e.g. in HTTP response). Once it reaches the frontend, you should\n    // add it to localStorage under the key 'socketCluster.authToken'- By doing this, SC\n    // will automatically pick up the JWT token when doing its handshake/connecting.\n    console.log('JWT token:', token);\n  });\n``\n. @trzyrazyzero You can send the token to your frontend however you like... If you're creating the JWT from inside an express GET route, then you probably want to send it back as part of the HTTP response body - But then make sure that you handle the response on your frontend and add your token to localStorage using JavaScriptlocalStorage.setItem('socketCluster.authToken', token)`.\nOnce the JWT token is added to localStorage under the socketCluster.authToken key, the rest is all handled automatically by SC. You will be able to get the token data from your SC socket on either the client or server by using socket.authToken (or the old way: socket.getAuthToken()).\n. Note that worker.auth in the code sample above is just an instance of SC's server side auth engine - The default being https://github.com/SocketCluster/sc-auth/blob/master/index.js\nIn SC, you can swap out both the client side and server side auth engines with your own engines if you want but generally this isn't necessary.\nTo change the default server auth engine, you can use worker.setAuthEngine(myCustomServerAuthEngine) http://socketcluster.io/#!/docs/api-scworker\nTo change the default client auth engine, you need to pass a custom authEngine option when creating the socket on the client. E.g. socketCluster.connect({authEngine: myCustomClientAuthEngine})\nNote that the server auth engine and the client auth engine are different (and serve different purposes).\nThe server auth engine needs to implement a signToken and a verifyToken function.\nSee default server auth engine here (as mentioned above): https://github.com/SocketCluster/sc-auth/blob/master/index.js\nThe client auth engine needs to implement a saveToken, removeToken and a loadToken function.\nSee default client auth engine here: https://github.com/SocketCluster/socketcluster-client/blob/master/lib/auth.js\n. I've updated the authentication page on the socketcluster.io website to link back to this discussion. See http://socketcluster.io/#!/docs/authentication\n. @vaskevich You can bypass it entirely.\nBecause HTTP-only cookies cannot be explicitly accessed (saved/loaded) on the client-side, they don't fit into SC's standard authentication flow but you can still authenticate sockets at a lower level during the handshake phase. This ensures that sockets are authenticated before they are connected. It's slightly less flexible but very widely used and suitable for most cases.\nWhen using HTTP-based authentication using cookies, you can read the cookie from the HTTP request that is associated with the WebSocket object on the server-side.\nYou can use the scServer.MIDDLEWARE_HANDSHAKE_WS to access the HTTP upgrade request (and read any attached cookies) to determine the authentication state of the socket; from that middleware you can either block the connection or attach custom properties to the req object (which you will be able to access later using the socket.request object); so you can do the authentication yourself without relying on SC's JWT authentication mechanism. The main downside to this approach is that the socket's authentication state cannot change throughout the life of a single socket connection; but that limitation is inherent to HTTP cookies - You can just reconnect the socket if you want to use a new cookie.\nAlternatively you can use the scServer.MIDDLEWARE_HANDSHAKE_SC middleware; this is the SC-protocol handshake which happens after the native WebSocket (WS) handshake; after the socket has been created; it gives you a bit more flexibility when it comes to sending back things like custom errors.\nAlso, some apps authenticate by passing a token using a ?token=... querystring as part of the HTTP upgrade request URL; this follows the same principle as the cookie approach; and has the same downside that the authentication state cannot change throughout the lifetime of a single socket connection.. @vaskevich If you don't explicitly create a JWT with socket.setAuthToken() or manually add a JWT token inside the default localStorage location in socketCluster.authToken - Then it's not going to send anything. The JWT is only sent as part of the handshake it it exists and the SC server doesn't care at all if there is never any JWT.\nHypothetically you could swap out auth engines (on both client and server) to handle any kind of token from the client (except those set using HTTP-only cookies because they are intentionally not exposed to the client code).. @deoqc Publishing to a channel which is named after the username/userid as you described is actually a very good and scalable approach. Channels in SC are cheap so you should use them.. @deoqc Thanks. I've updated the docs http://socketcluster.io/#!/docs/api-scsocket-client and http://socketcluster.io/#!/docs/api-scchannel-client - See the subscribe method.\n. @deoqc That is not practical to implement - It won't scale across multiple workers - There is no guarantee that the publish action will be processed by the same worker (or server) than the one which processed the subscribe action. You can use the data in the published message itself to filter out messages. And you can use req.socket.authToken to verify credentials in any middleware.\n. Sorry for the delay in response. This was a good question.\nYou may want to check out https://socketcluster.io/#!/docs/authentication and https://socketcluster.io/#!/docs/middleware-and-authorization. @wtgtybhertgeghgtwtg In the latest versions of SC, you can use Node.js v0.12.x if you comment out some of the default optional code in server.js and broker.js.\nIdeally we recommend Node.js v4.x.x.\n. Hopefully the passing of time has resolved this issue for us.. @artooroff If you're having problems with that client, there is another native client: https://github.com/socketcluster/client-drivers#list-of-clients\n. @sacOO7 Is in charge of all the native client stuff. See https://github.com/sacOO7/socketcluster-client-java and https://github.com/sacOO7/socketcluster-client-swift. I've updated async to v2.0.0 in socketcluster-server v5.1.6 so that it matches the one in sc-broker-cluster.\nWe could switch to using Promises instead of the async module but as @wtgtybhertgeghgtwtg mentioned, it would be a fair bit of work (but mostly, we risk breaking things). Particularly the async.applyEachSeries function which is used for running middleware in series asynchronously.\nWe could revisit this at some point in the future, but I don't want to take any big risks since a lot of people are using SC now and it's extremely easy to break stuff.\n. I think the word 'rewrite' is confusing (and scary lol) - I don't think SC will ever be 'rewritten'. But small parts might be refactored slowly over time yes (as is the case for any software tool).\nI think refactoring SC to use Promises instead of async is currently very low priority (unless someone finds an actual bug with it).\nIn either case, we're at a stage that we probably shouldn't change anything unless we have tests around it (so we can make sure that we don't break stuff).\n. I just tested on OSX (SC v5.0.18) with both ws and uws and couldn't reproduce the issue. Do you have a proxy (I.e. a firewall) running on your localhost which might be blocking WS connections? If serving over HTTPS fixes the issue, then there is a chance that it's a proxy issue.\n. @Charuru \n. @Charuru I was able to reproduce this on React Native when using the ws module on the backend. I fixed it with socketcluster-client v5.0.18.\n. @zalmoxisus Based on the testing I just did, this issue only seemed to affect ws (not the default uws). But there is a small chance it could affect uws too depending on RN versions and Node.js versions used (but I haven't reproduce that issue myself)...\nI haven't noticed any issues with uws and large message sizes but if you can give me some sample messages with which I can reproduce the issue, I'd be happy to test and fix it.\nI tried sending a large object with 100K randomly generated keys and didn't have any issues.\n. @Charuru Yes that is a big file - I'll test later. I'll check with Alex (author of uWS) to see if he can think of something.\nSo you're saying that this only happens with uws (not ws) and that even if you break the data up into smaller pieces but send them all at once (in quick succession), it causes the socket to hang up? Do you get any server-side errors?\n. @Charuru I tested with the 1.7m log file and it was no problem. It took a fraction of a second to send and receive the entire thing on my machine. Does the issue only happen on your localhost? So it's not going over the network?\nIf you serve over https on your localhost (with a self-signed key & cert, does it solve the problem for you)?\n. @Charuru Could you please post a series of exact steps which I can follow (and code I can copy/paste) to reproduce the issue on my machine?\nI'd like to understand what happened in case anyone else runs into the same problem in the future.\nAlso, one more thing you can try to get it to work with uws is checking that you have the latest uws version as a dependency. It should be v0.11.0 or higher - Sometimes npm can keep old dependencies in cache when you upgrade modules.\n. We could create a plugin which does that and then add it to the sample/boilerplate by default here somewhere https://github.com/SocketCluster/socketcluster/blob/master/sample/server.js - We still want to allow the user to remove it in case they want to use a custom hot module loader (and/or transpiler) like babel instead.\nIt's not as simple as just watching the worker.js file though; we have to watch all dependencies too.\n. @wtgtybhertgeghgtwtg Ah thanks, I forgot that one.\n. @wtgtybhertgeghgtwtg It looks like a lot of those dependencies are pretty lightweight, so inquirer downloads pretty quickly but I don't like the way they've specified their dependencies with ^ in front of the version numbers https://github.com/SBoudrias/Inquirer.js/blob/master/package.json#L22-L56\nI also think they've used way too many dependencies for such a simple tool.\nI've raised an issue on their repo about this https://github.com/SBoudrias/Inquirer.js/issues/460\nI think we can consider creating a new create-socketcluster or similar npm module... The other possibility is to just find something simpler than inquirer.\n. I think that this project already has a lot of different repos/packages to manage so I'm happy to keep it as it for now.. @ivopc That sounds great. Yes, I think this would be perfect as a module (or wrapper?) for SC client.\nI guess you could pass a client SCSocket object to it as an argument when creating a new peer-to-peer connection and you could save the username/user id inside an SC token somehow.\n. Here are long answers (I will link it this on the website) because I get asked similar questions from time to time.\n1. If you have 2 workers, it will register 2 middleware functions in total; 1 middleware function in each worker. Each worker is a separate process and doesn't share anything with each other (not even variables) - So think of them as being completely isolated (embarassingly parallel). I think the best way to understand how it works is to play with it (I.e. use console.log() and watch how messages pass through the middleware).\n2. The worker is a good place to put your MQ consumers; it's not the absolute most optimal solution but it's simple and it scales well (linearly, without theoretical limits) - You consume messages from your workers and when you get a new message from your external MQ, you just do worker.exchange.publish('myChannelName', ...) (that's it; the brokers will figure out how to deliver them to the correct workers and subscribed users). To avoid duplication of messages from your MQ, you can use a hash function to hash topic names into a numeric index and use this to decide which worker should handle which topics (or which subset of messages) - You can get the total number of workers from SC using worker.options.workers. Also each worker has an id which you can get using worker.id. Note that you can use any hash function you like - It doesn't matter which worker ends up consuming which topics so long as it's approximately even between all workers - The  worker.exchange.publish('myChannelName', ...) will figure out how to route it to the right clients. Note that if your message queue supports exactly-once delivery to a single consumer per message, then you don't need to do any special sharding in SC; you can let each worker consume from the MQ and whoever gets the message can publish within SC using the exchange object.\n3. In this case, each client will be bound to one of the workers; SC uses the Node.js cluster module which will do the round-robin load balancing which will pass the connection socket to one of the workers. Once a client is connected, it will stay connected to that worker for the life of the connection. If the connection is lost and re-established, it's possible that the user will end up on a different worker than the first time. Storing session data inside a JWT token using socket.setAuthToken(data) is a good way to keep track of clients across multiple workers in the event of lost connections. Storing the username in the token is the most common pattern but you can store other stuff as well (don't store passwords or private/sensitive data though).\nworker.exchange just represents the cluster of brokers. When you publish to the exchange with a channel name, it will pass the message to a specific broker (based on the channel name) and that broker will then pass the message back to any interested workers which will then pass it back to all their subscribers.\nYou can require custom Node.js modules using var myModule = require('./someModule.js') inside worker.js so you can spread out your logic over multiple files. You can look at the worker controller for this sample app for ideas: https://github.com/SocketCluster/sc-sample-inventory/blob/master/worker.js\n^ I could probably have moved even more code to a separate file...\nSpawning other processes from worker.js is fine but it can make some things tedious (I guess it depends on your use case).\nRegarding point 2, you can also put the MQ consumers inside a broker controller (typically a broker.js file) - But this is more difficult because each broker (assuming you have more than one) only knows about a subset of all channels, so if you try to publish to a channel which a specific broker is not aware of, it will just ignore it; so how you shard your MQ topics has to match how SC brokers themselves are sharded which is more tricky to coordinate. You can always switch to this approach later though. Also it's only 'slightly' more efficient (about 50% more efficient; so not even double) than than the approach I recommended above so it's not really worth it in most scenarios.\n. Note that in the latest version of SC, you can use SC's default hashing function by requiring it with\nvar hash = require('sc-hasher').hash.\nThe hash function is in the form hash(key, modulo) where key is typically a string (e.g. a channel name or MQ topic name) and modulo is the number of available targets (number of brokers). It will return an index which indicates the broker ID that the key maps to.\nFrom inside the worker controller (worker.js), you can do: \nhash('someChannel', worker.options.brokers)\nFrom inside the broker controller (broker.js), you can do:\nhash('someChannel', broker.options.brokers)\n^ In both cases *.options.brokers represents the number of brokers which your SC instance is currently using.\nNote that inside broker.js, you can compare the value returned by the hash function with thebroker.id to decide if the channel/topic belongs to the current broker.\nSo you could do something like this inside broker.js:\n```\nvar hash = require('sc-hasher').hash;\nvar targetId = hash('someChannel', broker.options.brokers);\nif (targetId === broker.id) {\n  // The channel belongs to the current broker so we can do some action here\n  // E.g. we can relay messages between an external message queue and SC.\n}\n// else the channel does not map to the current broker so we should do nothing\n// and let another broker handle it.\n```\nIf it cannot find the 'sc-hasher' module automatically, you may need to npm cache clean and reinstall socketcluster - It should be bundled with SC.\n. @jsynowiec Well technically if a worker dies, a new worker will take its place and that worker will take the dead worker's ID... So I guess the answer to your question is yes - The IDs are reused - They are in fact indexes; the first worker is always id 0, second worker is id 1, etc...\nThe worker object has an isLeader property (boolean) which tells you if the current worker is the leader (worker with ID 0 will always be the leader).\nIf you have just one queue and throughput is reasonable, then it's fine to make the leader always handle it.\nYou don't have to sync state between workers; in fact I would recommend that you don't unless you absolutely have to. Whenever you try to sync data between all workers, you automatically reduce scalability because there is only so much data that you can share around before workers get overloaded - The more workers you add, the more CPU and memory will be spent on synchronizing them; it's just not worth it.\nTo make an effective distributed system, you have to accept that not all workers need to have all the information at any given time (it's just not possible at scale). Data that needs to be accessed globally should be put in an external database and each worker should load what it needs and only when it needs it.\n. @iMoses Is this happening when you do npm install?\nIt works fine on my Ubuntu 15.10 machine with Node 6.4.0. It sounds like it doesn't like your compiler for some reason... @alexhultman do you know what the issue could be?\nWorst case, you can try running SC inside Docker (if you have Docker installed)... See https://blog.baasil.io/framework-in-a-container-6105d3275d61#.nrqmc559j - See the last part\n. Alex said that it can happen if you have an unusual setup like maybe 32-bit machine instead of 64-bit or maybe you have an old compiler - Or something happened to it... I'm trying to find a workaround now.\n. It's weird that you can't just use ws.\n. @iMoses When I delete the uws module and set the wsEngine to ws (http://socketcluster.io/#!/docs/api-socketcluster), it still works for me - Maybe try deleting uws from node_modules directory.\n. Did you try doing npm cache clean before reinstalling?\n. @iMoses What is your uname -a?\n. Did you use npm link to link SC into your project? I noticed it wouldn't update modules correctly on some occasions for me. I just tested it and it definitely lets me switch; maybe it's not actually running the code you think it is.\n. @naelt No, there is no limit. How many brokers do you have? Note that you should avoid putting any code inside broker.js (You can get a 50% performance boost in some use cases, but it's usually much simpler to just have all code running only in worker.js) and publish using scSocket.exchange.publish(channel, message) to publish from the backend.\nIf you have two brokers (for example), then each broker will only know about half of all channels which exist in your system. So if you call broker.publish('somechannel', data) on a broker but the somechannel channel is handled by a different broker (not the current one), then it will do nothing.\nThe code inside broker.js will be run for each of your brokers. You can use broker.id to check which broker your code is running on.\nIf you really want to run code inside broker.js, you might want to get sc-hasher https://www.npmjs.com/package/sc-hasher - This is the hashing algorithm which SC uses to distribute channel names between different brokers. So, inside broker.js can add logic such as (example):\nvar scHasher = require('sc-hasher');\nvar targetBrokerId = scHasher.hash(channelName, broker.options.brokers);\nif (targetBrokerId == broker.id) {\n  // Here we know that this channel belongs to this broker, so we can publish from here.\n}. @happilymarrieddad It depends on how many pub/sub messages you send - If it represents a large part of your workload (like each user is sending one message every second at least), then a 50/50 ratio of workers to brokers might suit. So on a 16 core machine, you could have 8 workers and 8 brokers. But often, I found that you can have fewer brokers than workers (so maybe 10 workers, 6 brokers). You'd have to try it out to see - If your broker processes are maxed out on CPU, then it means you need more.\nYou can have 16 workers and 16 brokers (that way you don't have to think about the ratio) but you tend to lose efficiency when you have brokers and workers sharing the same CPU cores.. @happilymarrieddad In new versions of SCC, there is now an option to customise the connection pool size so it shouldn't matter as much how many workers/brokers there are. Increasing the clusterClientPoolSize (https://github.com/SocketCluster/socketcluster/blob/master/sample/server.js#L38) to be greater than the number processes per node should help even out distribution across all processes in the scc-broker instances.. @heiba Did you try https://github.com/sacOO7/socketcluster-client-java? It's the latest one from the list. Maybe you can have a chat with @sacOO7 (https://gitter.im/sacOO7) - I believe he is currently refining it.. @heiba - @sacOO7 has built (and is building) a number of clients for SC, so I'll probably be working with him more closely soon. It's possible that it might become the official client down the track. Feedback is welcome - Feel free to raise an issue on the client's repo.\nI've reopened this because it's pretty important.. @heiba a lot of people use the official JavaScript client with React Native on Android and iOS - So that may be an option worth considering as well.. @heiba It takes a while to perfect things. It's been a while so hopefully it's better now :). @MrP Looks good thanks.. @ranhsd There is nothing wrong with having the SocketCluster server separate from your HTTP server and to do publish like you suggest; I guess that's the microservices approach.\nAnother approach is to move your HTTP logic inside SocketCluster - As you can see here: https://github.com/SocketCluster/socketcluster/blob/master/sample/worker.js#L13 - The SocketCluster server can be used to service HTTP requests (since WebSockets piggy backs on top of HTTP).\nAnother approach is to not use a POST request for sending messages; instead, you can send the message to SocketCluster directly using socket.emit('addMessage', message), then on the server in worker.js, you can use socket.on('addMessage', function (message) {});.\nInside the 'addMessage' handler, you can use a mongodb client to add the message to MongoDB and once it's successfully inserted, you can call worker.exchange.publish('newMessage', message) (or whatever channel is relevant.. @webeindustry It takes too much effort to click on the 'close' button ;p. @liuqimin323 What is your Node.js version? What is your SocketCluster server version (npm ls socketcluster-server)? What is your uws version (npm ls uws)?\nMaybe try upgrading everything to the latest version.. @prashcr Thanks!. @trzyrazyzero Communication between the various SC processes is private but you can use pub/sub channels on the backend and have the clients subscribe to those same channels if you want to share.. @FantomHD You should be able to do authentication however you like over HTTP on the server - From there you can create a token, send it back to the client (E.g. in the HTTP response) and then on the client, you add it to localStorage. The full instructions are here: https://github.com/SocketCluster/socketcluster/issues/233#issuecomment-254871963\nEDIT - I Found this answer which may be helpful for steam specifically: http://stackoverflow.com/questions/32844596/combining-a-passport-openid-stategy-with-jwt\n^ Basically with SC, instead of\n```\nvar token = jwt.sign(payload, \"thisisnotthesecretiactuallyuse\", {expiresIn : 606024});\nres.cookie('token', token); \nres.redirect('/'); \n```\nYou could do:\n```\nworker.auth.signToken(myTokenData, worker.options.authKey, null, function (err, token) {\n  res.cookie('token', token); \nres.redirect('/'); \n});\n```\nThen to do authorization (which is different from authentication) on WebSockets, you should look into http://socketcluster.io/#!/docs/middleware-and-authorization\nThe JWT token is basically a just special certificate which the server gives clients (upon successful login/authentication on the server-side) and which allows clients to prove their identities in the future without having to show a password.\nSo for example,  if a client loses the connection and then reconnects to a new server/process which has never seen that client/user before, the server can still verify their identity by looking at their token - That's why this approach is scalable.\nIn SC, whenever the socket.authToken property exists on the server, it means that the client has a valid auth token.\n. @FantomHD Ah, you should remove the { httpOnly: true /* TODO: Set secure: true */ } option when setting the cookie from the server - Setting it as httpOnly prevents you from accessing it and editing it in your JS client-side code.\nIf you remove the httpOnly stuff from the server, on the client side, you should be able to copy the token from the cookie and put it inside the localStorage (at key socketCluster.authToken), then, when that's done, you can call socketCluster.connect(...) and the socket will be authenticated.\nMaybe steam also offers other ways to send the JWT token to your front end... I'm not familiar with it. In any case, it doesn't matter how you provide the JWT token to the front end; so long as you manage to create the token on the server and pass it to the client (and store it in the appropriate localStorage key) before it connects, the SC authentication will be automatic.. @FantomHD It's safe. You don't need to secure the cookie. The token which is in the cookie is signed and therefore cannot be tempered with by the user (doing so would invalidate the token and SC would discard it).\nThe reason for using httpOnly when setting a cookie is to prevent it being stolen as part of XSS attacks (if an attacker manages to sneak an unauthorized script into your site/app).\nI wouldn't worry about this. If your website/app has been compromised by an XSS attack, the attacker could already do some serious damage without having access to the token - Having access to the token doesn't provide much additional value to an attacker who already has his code running on all your users' browsers.\nIn case of an XSS attack, remove the offending script tags/iframe (or whatever the offending component is) from your site/app and then make sure you change the authKey option provided to SocketCluster on the server side (and reboot) to invalidate all previously granted tokens.. @FantomHD Yes you should setup a channel to send events to all users. To prevent clients from publishing to that channel, you can either:\n\nSet the main server-side allowClientPublish option to false. See http://socketcluster.io/#!/docs/api-socketcluster - This will prevent clients from publishing to any channel - Only the server will be able to publish to channels.\nAdd a MIDDLEWARE_PUBLISH_IN middleware function to block all inbound messages to a specific channel (based on the channel name). See http://socketcluster.io/#!/docs/middleware-and-authorization\n\nMiddleware functions are only applied to messages which come from outside (I.e. from clients). So you will still be able to publish from the server-side using worker.exchange.publish('some-channel', 123).\nTo send stuff to specific users, you can just setup a unique channel for each user. E.g. 'bob-channel' - Then you can publish to that channel from the server-side. One advantage of this approach is that even if the user has multiple tabs open, they will get the message on all tabs that are subscribed - So it's not coupled to a single socketId.\nIf you want to make sure that a user has received a message, on the server-side, you can create temporary response channels which users can publish to (assuming that allowClientPublish is not false). SC is very efficient at creating and destoroying channels. It's OK to have 100 channels per user for example.. I don't know enough about passport's cookie format to give you specific advice. If the passport cookie is a JWT (which I think is not the case), then you could reuse the same token for both passport/HTTP AND SC - You would just have to make sure that the same authKey is used for both HTTP/passport and WebSockets/SC and both would be able to read the same token.\nIf the passport cookie is a session ID and only passport knows about this session, then you can't really combine the two approaches into one - You'll just have to handle them separately - Or change passport for another JWT-based solution. For AngularJS (v1) there is Satellizer - Maybe there are better ones now for other frameworks (or standalone)... I haven't kept track.\nUnfortunately, whenever you offload responsibility for tracking authentication to a single process on a single server (which seems to be the passport approach), then it makes scalability difficult - You end up having to store temporary session credentials in a DB/memory store (and you have to remember to clean it up when the user logs out or loses the connection; things get messy/complicated).\nJWT is nice because you just sign it once and give it to the client and you don't have to manage it on the backend. It's like an access card - If the user has the card, they can get into the building and enter whatever rooms (open whatever doors) the card allows.\nThe passport approach is like making every door in a building a smart door with its own WiFi - The user gives the door their personal pin number and then the door has to talk to a central server and check if that user has access to that room. If you have a building with a lot of doors and a lot of users, it becomes really messy (and slows down the network).. @FantomHD If you have clients who are subscribed to the same channel but connected to different workers, and you publish a message to that channel; all clients (on all workers) will receive the message. \nThat's what broker processes do; they broker messages between pub/sub channels sitting on different workers. If you use SCC (Kubernetes), then pub/sub channels will even span multiple hosts/machines.\nYou can test it yourself, just use the -w 2 flag (or higher) when launching SC, and in worker.js, inside the 'connection' handler, you can do a console.log('Client connected to PID:', process.pid) to make sure that the clients are hosted on different processes (just refresh one of the browser tabs/windows if they're not).\nThe limitation of SC (and, in fact, all distributed systems) is that you cannot have ALL your user data in one place at the same time. You have to learn to deal with partial data - Pub/sub channels are a really good way to deal with this limitation of distributed systems because it allows machines and users to easily communicate with one another across process and host boundaries - Even if they exist in completely different environments.\nUsing channels, you never have to think about where your users are (I.e. which hosts/processes they're connected to or what their socket IDs are) - You can just blindly publish data to channels and let SC deliver the data to the appropriate users (wherever they are).. By setting it up correctly.. @FantomHD Yes you can communicate between workers using channels. You should use the worker.exchange property (not worker.global - That's deprecated).\nThe Exchange object is here: http://socketcluster.io/#!/docs/api-exchange\nSharing data between workers via channels is the cleanest way. Just make sure that you don't end up sharing TOO much between too many workers or it will affect scalability. Also, try to group data together (e.g. in an array) when publishing it - It's more efficient to publish one long message with lots of data than many small ones.. @FantomHD That's because passport isn't designed to scale across multiple processes/servers by default.\nI can think of two options:\n- Use a JWT solution instead of passport for authentication over HTTP - Maybe implement the Steam authentication yourself from scratch (it can't be that hard).\n- Store the passport session data in an external process (e.g. Redis) instead of storing it in memory.\nEach worker process has independent memory so if you store data in one worker, it will not show up in the other worker - Data that you need to share between multiple workers needs to be stored in a database/datastore.\nOr maybe there is a way to make passport work better with JWT.\nThis articles says that you can set the session feature to false: https://blog.hyphe.me/token-based-authentication-with-node/\nI found this article about storing passport sessions in Redis: https://blog.risingstack.com/node-hero-node-js-authentication-passport-js/\nThe ideal way would be to not store any session data on the backend (just use the signed JWT token for all your authentication needs) - That is the simplest and most scalable approach by far - But if passport doesn't allow you to use that approach, then you may have to use Redis. Or maybe you can find another way to do steam authentication without using passport at all (just handle it yourself inside express and create the JWT token yourself).\n. Yep, or you can also use worker.auth.verifyToken(signedToken, key, options, callback) if you want to be consistent. https://github.com/SocketCluster/sc-auth/blob/master/index.js#L9. @pataiadam I ran your test on a Linux machine and uws was like 4500 messages per second and ws showed less than 1000 messages per second.\nBut note that these numbers are not accurate because you shouldn't run both the client and the server on the same machine when doing benchmarks. Client sockets use up much more CPU than server sockets so the client will be the bottleneck (which will skew results). The client never changes - We always use the client provided by the ws library - Only the WebSocket server is changed when you switch from uws to ws.\nI was able to get over 20K messages per second (with responses) with uws last time I tested and only 10K m/s with ws. Things may have changed since then, but if anything, uws should be even faster now than it was before because the author has kept optimizing it.\nThere may be other issues in your code though because uws should be always be faster regardless.. @trakout You need to use worker.exchange.subscribe('channelName').watch(handlerFunction) to subscribe to and consume the channel messages from inside worker.js. The Exchange object is basically a special client which you can use to publish and subscribe to channels from the back end (the API is similar to the client socket on the front end).\nEvery channel in an SC instance is automatically available across all of its worker processes - This is because SC broker processes route and relay channel messages between different workers.\nThe broker controller (broker.js) allows you to take that concept further and relay channel messages across remote hosts too. So if you hook your local SC brokers (broker.js) to Redis or another remote broker, then you end up with two layers of brokers; one local layer (your SC brokers) which shares messages between worker processes on the same host and one remote one (e.g. Redis) which shares messages between different hosts.\nThis 2-layer approach minimizes the number of messages that need to pass through the network.\nInstead of each worker process consuming messages directly from Redis over the network (potentially with a lot of duplicate messages); it just receives each unique message once from Redis and then shares it across all interested workers on that host only. So the brokers act like a message cache for the host.\nThe end result is that if you publish a message to any channel from anywhere inside SC, it will reach not only all workers on the current host, but also all workers on all remote hosts which are hooked to Redis  (and all their subscribed end-clients too).\nWith SC, you never have to manage channels; they get created and cleaned up automatically based on usage. SC can create and destroy channels really quickly (it can handle 10K to 20K unique channel subscriptions per second per worker).\n. Which version of SC are you using? How are you logging this?\nTry to catch the 'error' event on the socket and check err.name property.\nThere should be more information.. You may need to npm update socketcluster-server or socketcluster itself.. There should be a message that tells you what went wrong - It looks like your logger is not showing that information.\nCheck err.code and err.message.\nYou can see what all the codes mean here:\nhttps://github.com/SocketCluster/sc-errors/blob/master/index.js#L206-L225\nAll codes in the 1000 to 1999 range are native WebSocket protocol errors (not related specifically to SC - See the WebSockets RFC) and those in the range 4000+ are SocketCluster errors.. @mattkrick Thanks for looking into this. Having flexible versions for all sc-related dependencies was convenient for a while but I agree that the time has come to lock all of them down.\nIt's not fair to assume that developers will keep updating to the latest SC version every time anymore.\nI  propose using the recommended npm format '~1.2.3' and to get more strict with semantic versioning when bumping up dependency version numbers (so basically only force update in case of urgent patches where it's guaranteed backwards-compatibility).\nI'll start doing this from the next release v5.3.0.\n. Did you find which version of sc-auth introduced the problem? https://github.com/SocketCluster/sc-auth/commits/master. @mattkrick I think the issue might be with this commit: https://github.com/SocketCluster/sc-auth/commit/24afe2e227f4a96c99674360db67a2d7be45e26b - I upgraded jsonwebtoken and started using the async version of the sign function.\nYou can either downgrade all sc-auth dependencies to v3.0.0 (it should be referenced twice; in socketcluster and also in socketcluster-server) OR upgrade socketcluster to v5.2.2 (make sure that socketcluster-server is v5.4.4). There haven't been any breaking API changes to SC in a long time so upgrading should be straight forward (but you have to update every dependency). Let me know if there are any issues.\nThe socket.setAuthToken(authToken); is working for me when I use the latest version of SC with latest dependencies.. @mattkrick Ok, I published the updated socketcluster & socketcluster-server v5.2.3 & v5.4.5 as you proposed (pointing to the old sc-auth 3.0.0 and fixed deps).\n. I published v5.2.5 and v5.4.6 with the newest sc-auth and with the fix in socketcluster-server.. Hopefully this is all better now with the package-lock.json file.. @nguyenhaian You need a newer Node.js version which supports the 'inspect' flag - Node.js v6.5.0 or later works for me on OSX.. @nguyenhaian Publish actions don't have callbacks but you can subscribe to a new channel on the server to handle acknowledgements from users.\nSo for example, for a user 'bob123', you could do:\n```\n// Capture acknowledgements (ack) sent from client when they \n// have received the message, the ack should contain the mid\n// from the message.\nscServer.exchange.subscribe('bob123-messages-ack').watch(function (data) {\n  // You can use data.mid to match against the original message\n});\n// Then later...\nscServer.exchange.publish('bob123-messages', {\n  mid: 'someuniquemessageid', // Maybe incrementing integer or uuid\n  message: 'some data'\n});\n```\nIn SC, you can create as many channels as you like - They're extremely inexpensive so feel free to create lots of them.\nAlso note that in your code, it should be scServer.exchange.publish not socket.exchange.publish.. @nguyenhaian Oh I misunderstood the question. You can check the auth token inside the MIDDLEWARE_AUTHENTICATE middleware using req.socket.authToken - See http://socketcluster.io/#!/docs/authentication - The auth middleware runs after the token has been verified/attached and before the connection is triggered - Note that it only runs if the token exists and is valid.. Done.. @JCMais Yes that's fine of course; just make sure you don't overwrite any existing properties of the socket object.. It would be a lot of work since WebSocket connections start with a HTTP request and a lot of properties that exist with WebSockets would not be present with TCP.. Done.. @ddolheguy As you suggest, these are exceptions more than errors so they are bound to happen from time to time because of bad connections.\nDo you mean error handling on the client side or the server side?\nOn the client side, you just need to attach a socket.on('error', function() {/*handle error here*/}); handler to prevent the error from being uncaught (and crashing the app).\nOn the server-side, you shouldn't have to handle it explicitly (unless you want to do something in response) - Socket errors are scoped to the socket and so should not crash the server.\nYou shouldn't explicitly have to reconnect since SC will try to auto-reconnect by default.. This has been fixed. https://github.com/SocketCluster/socketcluster-server/issues/17. @BojDom @JGreenberger Sorry for not making a comment sooner, this feature is already supported! Has been since version 8 so make sure that you use the latest socketcluster and socketcluster-client versions.\nTo use it, all you have to do is pass a batch: true option when subscribing to a channel.\nE.g:\nlet myChannel1 = socket.subscribe('myChannel1', {batch: true});\nlet myChannel2 = socket.subscribe('myChannel2', {batch: true});\n...\nWhat that means is that the subscribe actions will only occur on the next tick as a batch instead of immediately. You can subscribe to a large number of channels in a for loop and all the subscriptions will be sent as a single websocket frame.\n. @BojDom Regarding your suggestion with wildcards, there are no plans for this at the moment because pattern matching adds complexity and isn't great for performance.\nYou can implement it yourself in SC though if you feel that it's important (it shouldn't be too difficult) but my initial thought about it was that I didn't want to encourage this use case too much because of performance costs and also because there are often more efficient ways to achieve the same goals without using pattern matching.. @Charuru The unsubscribe event should fire when a socket disconnects.\nThe problem which this approach is that if your SC worker crashes suddenly (e.g. because of a fatal uncaught error), you may lose track of your presence sessions (in your database or redis...) so you have to figure out a way to clean them up later.. @Charuru You can just destroy the socket if you're certain that you don't want to reuse it again. Also you can pass the multiplex: false option when creating the client socket to make sure that sockets are never reused (in case you call create/connect multiple times for the same target host/URL).. @luozan There are many ways to do this, for example you can unsubscribe the channel with socket.unsubscribe('channelName') when the socket 'close' event triggers... Or you can destroy the whole socket as @happilymarrieddad suggested (and this will also delete any attached channels).. @ArmorHerO Pretty much what @happilymarrieddad said: the relationship between scc-state and scc-broker is 1 to many.\nThe relationship between scc-state and socketcluster instances is also 1 to many.\nThe relationship between socketcluster instances and scc-broker is many to many - This means that you can keep adding as many socketcluster and scc-broker instances as you like and everything will scale linearly/automatically.\nscc-broker instances allow socketcluster instances to automatically share pub/sub channels with each other across multiple machines/hosts. So if you have the same channel name on two different socketcluster instances/hosts, scc-brokers will combine them into a single channel that spans multiple machines.\nscc-state just coordinates how the socketcluster instances connect to the back end scc-brokers (like checking when new scc-brokers or socketcluster instances come online or go offline and resharding channels across them accordingly).. @nagamanojv What node.js version are you using?. @nagamanojv When I connect to a socketcluster server from a socketcluster-client running inside Node.js (v7.10.0), on the server socket.remoteAddress is ::ffff:127.0.0.1 which is fine.\nIt would be interesting to know why it says undefined in your case.\nI used this code as the client and I run this with the node command:\n```\nvar socketCluster = require('socketcluster-client');\nvar socket = socketCluster.connect({\n  hostname: 'localhost',\n  port: 8000\n});\nsocket.on('connect', function () {\n  console.log('CONNECT', arguments);\n});\n``. @nagamanojv @joyson-17 There was an issue which meant that remoteAddress was not being set sometimes when usinguwsas the engine. I fixed this in socketclusterv5.11.0`.. @dotob Yes actually the part about launching the socketcluster instance was misleading. I've updated the guide. Let me know if it makes more sense now: https://github.com/SocketCluster/socketcluster/blob/master/scc-guide.md. @rachlies Are you using channels? If so, are the published messages being read/consumed by every client? If so then 100 msg/second * 50 clients is 5000 inbound messages per second in total... Now If you have 50 clients each consuming 5000 messages per second then that's 250K outbound messages which have to be sent out to clients every second.\nYou can tell SC to batch messages together at an interval by setting a pubSubBatchDuration option (see http://socketcluster.io/#!/docs/api-socketcluster); this can give a significant speedup in certain scenarios like described above.\nThe memory consumption looks very high. I'm not sure what the cause is. I did not experience this issue on Amazon EC2.. @toredash Sorry for delay in response. Yes your assumption about pubSubBatchDuration is correct -\n It should have some impact if your system is busy processing lots of concurrent pub/sub messages.. Done. socketcluster@6.0.1. See http://socketcluster.io/#!/docs/api-scserver for documentation on the new events.. Try removing all modules from your node_modules directory and run npm cache clean and then npm install from scratch. . If you upgrade to a newer SC version, it uses the latest uws version which should solve this problem.. Note that SC now maintains its own JavaScript binding for uws so you can try using the latest sc-uws or if you want to stick to plain uws, you can bump uws to the latest version to see if that resolves the issue.. I'm closing this issue since now SC uses ws as the default for maximum compatibility. Using uws/sc-uws is an optional performance optimisation so hopefully fewer people should encounter this issue now.. @heiba I pushed a new Docker image v5.15.0 - But this is Node.js v7.10.0.\nUnfortunately, the base images for Node.js v8.x.x-xxx fail to compile uWS so I raised an issue here: https://github.com/uNetworking/uWebSockets/issues/630\nIt seems more like an issue on the Node.js side than uWS though. The upgrade to Docker image for Node.js v8 will have to wait until this issue is resolved.. Ok the latest docker image runs Node.js v8.. Maybe some sort of optionsController which allows you to customize/transform the options object and runs BEFORE the SocketCluster object is instantiated. Right now there is a masterController but it runs AFTER the SocketCluster object has been instantiated. See https://github.com/SocketCluster/socketcluster/blob/master/sample/server.js#L55. Ok since socketcluster v5.15.0 you can specify the path to an options controller module as an environment variable SOCKETCLUSTER_OPTIONS_CONTROLLER=/path/to/file.js (this is optional of course).\nIf specified, this module needs to be a .js file and must expose a single run function in the format:\nmodule.exports.run = function (options, next) { /* ... */ }\nThe options argument represents the options object as pre-populated by SC (based on standard SC environment variables). From inside the run function, you can modify this options object or create a new options object based on it... But you must pass it to the next callback once you're done populating its properties... E.g. next(options). If you provide an options controller script/module file, you MUST call the next(options) callback at some point or else SC will not boot.\nWith the baasil command, you can use the -e flag to pass in the SOCKETCLUSTER_OPTIONS_CONTROLLER environment variables as you would with the SOCKETCLUSTER_OPTIONS env var as described above.\nWith this approach you can manually read the environment variables from your dotenv file and add them to the options object using JavaScript.. @MatthieuHPP @WwoeSsi Although there are a few similarities, it depends on how heavily you're using the Socket.io API. Usually it will require some code changes as well. No step-by-step guide exists at this stage though it might be worthwhile for me to write one.\nIn the meantime you have to familiarise yourself with the docs: http://socketcluster.io/#!/docs. SocketCluster and Socket.io have some differences; maybe you should raise this issue with the maintainers of the delivery.js module.. Ignore for now.. @Louies89 Neither of these functions should consume much memory and it should get garbage collected as soon as execution finishes. In that case it depends more on the size of the object that you're trying to send.\nWhat uses up the most memory usually are function closures/listener functions which you pass to socket.on('eventName', listener) or channel.watch(listener); in this case you may want to call socket.removeListener('eventName', listener) or channel.unwatch(listener) when you want to remove a watcher.. @Louies89 Channels in SC are very cheap (both in terms of CPU and memory) so you can have as many as you want. SC doesn't keep channel data after it has been published and delivered to subscribers so it the memory gets released very quickly after. You can use middleware like MIDDLEWARE_SUBSCRIBE to make sure that clients don't subscribe to overly long channel names but generally channels.. @renaudguerin Good question.\nSC scales both vertically and horizontally. The vertical aspect (across multiple processes on a single host) is handled internally by SC itself and is static (since each host can only have a fixed number of CPU cores) - That is what SOCKETCLUSTER_WORKERS and SOCKETCLUSTER_BROKERS are about - Basically the number of processes of each type on each host. \nWhen discussing scaling in term of Kubenetes, this is for horizontal scaling; and there is no hard value there. You can just use the kubectl scale --replicas=123 -f socketcluster-deployment.yaml (or whatever) - This doesn't affect the number of worker/broker processes on each host, but it affects the total number of instances that there are (an instance which might be made up for multiple processes).\nThere are actually two kinds of message brokers in SC;\n- sc-broker - Only brokering messages across processes within a single host.\n- scc-broker - Which brokers messages across multiple hosts.\nSee this diagram for more info: https://github.com/SocketCluster/socketcluster/blob/master/scc-guide.md#how-it-works\nThere are performance benefits for having two levels of brokers like this; particularly as modern CPUs are getting more and more cores - It reduces the total number of messages that need to move between different hosts. Also it's convenient because it allows each SC instance (on each host) to attach and detach from the main K8s cluster independently as a whole.\nIf your cluster is made up hosts that have a single CPU core, then I would advise to leave both SOCKETCLUSTER_WORKERS and SOCKETCLUSTER_BROKERS as 1.\nIf each host has 4-core CPUs, then you can play safe and set both SOCKETCLUSTER_WORKERS and SOCKETCLUSTER_BROKERS to 4.\nThat said, it's often better if the sum of SOCKETCLUSTER_WORKERS and SOCKETCLUSTER_BROKERS adds up to the number of cores on each host, so in many cases, you might find that SOCKETCLUSTER_WORKERS = 3 and SOCKETCLUSTER_BROKERS = 1 actually performs better (then the workers/brokers don't need to share CPU cores) but then in some cases you might find that your broker is actually too busy whilst your workers are not busy enough (or vice versa)...\nAs you can guess, it's better if all the hosts in your cluster have the same number of CPU cores.. @renaudguerin Yes 'per pod' is more accurate than 'per host'.\nIn SCC's case though, because K8s automatically avoids port conflicts (and all SCC instances bind to the same port by default), it should never schedule more than one SC instance per host.\nYep, an SC instance runs multiple processes (workers and local brokers) within a single container.\nI know that there have been debates about whether or not it's better to run single process per container when using Docker/K8s, but in this case, it would add a lot of complexity (especially around load balancing) and it would be less efficient.\nI would be happy to revisit the current architecture at some point in the future if it turns out that there are benefits to having one process per container. It would be a lot of work but at least it should be possible to do without affecting the API.. > I don't believe it is true that K8s won't schedule multiple instance., but I might be misunderstand you ? I'm able to schedule multiple socketcluster pods within the same compute node, nothing is limiting me from doing that unless you use podAntiAffinity on the deployment.\nNote that you can have pods from different services sharing the same host in case that's what you were thinking. Based on the tests I did, K8s never assigned more than one pod of the same service to the same host because, for example there is only one port 8000 available on each host (assuming a single public IP per host) and the socketcluster service/deployment specifically reserves port 8000 - See https://github.com/SocketCluster/socketcluster/blob/master/kubernetes/socketcluster-service.yaml#L9 and https://github.com/SocketCluster/socketcluster/blob/master/kubernetes/socketcluster-deployment.yaml#L16\nFrom what I understood, this is because K8s has some implicit affinity rules which prevents Pods which are assigned to the same port from running on the same host. I haven't checked with the latest versions of K8s though so I may be wrong (I know that they've done a fair bit of work around pod affinity and anti-affinity recently).\nMaybe there are new approaches I'm not familiar with... If so, feel free to investigate and share. Maybe some of the SC .yaml files need to be updated for newer versions of K8s?\nUsing ENV variables is the recommended approach to scale up across CPU cores. Let me know if you can confirm for sure that podAntiAffinity rules are required now because I'm pretty sure that this was not a requirement before (can't remember the exact K8s version I tested with).\n\nAlso, if we subscribe to many clients at once(500 per second), the health-check in the socketcluster deployment starts to fail on every pod, causing the whole service to fail. I haven't figured out why, if was terminated on each socketcluster pod I could get it, but SSL is terminated at AWS. Any experience or advice around this ?\n\nHow does CPU usage look on the socketcluster pods? If SC is overloaded (and becomes slow/unresponsive) then it can cause the health check to fail. You may want to do some rate-limiting in SC or in your load balancer.\nI have not experienced the difference between HTTP/HTTPS which you described - Feel free to let me know if you find the problem/solution. The health check is done by K8s using a route which is exposed by SC. See this https://github.com/SocketCluster/socketcluster/blob/master/sample/worker.js#L25  - The module attaches a HTTP/S route to the express app https://github.com/SocketCluster/sc-framework-health-check/blob/master/index.js#L9. @toredash Thanks for the info - I really appreciate this type of feedback. Is it possible to set this no-host-sharing anti-affinity rule in a generic way inside socketcluster-deployment.yaml https://github.com/SocketCluster/socketcluster/blob/master/kubernetes/socketcluster-deployment.yaml?\nIt would be a good default to have... At the same time it's not the end of the world if multiple SC instances end up on the same host; you would only lose some performance due to processes having to share CPU cores (context switching overhead).. @libressence Thanks for the feedback. Do you mean; the documentation exists but it's hard to find?\nYou need to be more specific with your questions. What do you mean by \"recover your data\"? Is it in your database? Inside Redis? Inside your workers? Inside your brokers?. @libressence Data in your workers are in memory and only temporary. If you need to persist your data to disk, you will need to store it in a database instead.\nSC is just for sending messages in real-time, not for storing stuff.\nYes, I speak French.. @trzyrazyzero You should do the rate-limitting per-worker/CPU.\nIf a specific IP address exceeds the maximum number of messages or connections to a specific worker, you can block the IP on that worker and log it in a database/datastore somewhere... Then if you notice that the same IP is being blocked on multiple workers, then you can assume that they are malicious and you can ban them (you can keep a blacklist in the datastore somewhere) then in the future you can block them straight away if they try to connect from any worker... There are a lot of strategies though.. @zmikolaj It depends on what kind of rate limiting you want to do. You can use SocketCluster middleware to do this for different kinds of operations (e.g. MIDDLEWARE_SUBSCRIBE, MIDDLEWARE_PUBLISH, MIDDLEWARE_EMIT...) or you can apply a rate limit based on the number of connections coming from a specific IP address.\nI don't know about any general purpose modules/plugins that are available for SocketCluster at the moment but it should be relatively easy to implement. If you do implement a general-purpose module to do this and want to share with the rest of the community, please feel free to share it.. @LukeXF You should send back a proper Error object instead of a string. Strings don't have error codes.\nSo:\n```\nsocket.on('ping', function (data, res) {\n  // ...\n  var err = new Error('Example error');\n  // Giving each error a name is a convention which SC uses internally, but you don't have to.\n  err.name = 'CustomError';\n  // Preferably, try to use error codes in the range 4100 to 4500 - The WebSocket\n  // protocol and SC leave this range available for custom errors.\n  // You don't necessarily need to use error codes at all though, you can just use err.name.\n  // You can also add custom properties to your error object and they will be available\n  // on the front end.\n  // Note that the err.stack property will not get passed to the front end for\n  // security reasons.\nerr.code = 4123;\n  respond(err);\n});\n```\nNote that the first argument to respond is the error. The second argument is the data.\nIf you have no error but want to pass back some data, you should do respond(null, data);\nThe documentation on the website is confusing because it encourages sending strings (which is possible but not ideal) - Feel free to leave this issue open for now; that way I will fix the documentation.\n. Ok, I updated the docs: http://socketcluster.io/#!/docs/handling-failure\nYou don't really need an error code (unless you want to). You can use err.name to check the error type (since this is an application error and not a WebSocket error).. @ArmorHerO These errors just mean that the connection closed unexpectedly. Maybe the internet dropped out or a proxy killed the connection. The cluster should keep trying to reconnect itself though so these errors are not a big deal. How is your cluster set up? Amazon EC2? Kubernetes? Rancher? KOPS?. @xuejipeng Note that there have been significant improvements in SCC since this issue was raised. I would highly recommend upgrading to the latest versions of scc-broker and scc-state Docker images and also the latest version of scc-broker-client (in the regular/scc-worker SC instance).. @ArmorHerO Are you adding event listeners somewhere in your own code? This can happen if you attach event handlers multiple times with socket.on(...) or similar.... @happilymarrieddad Thanks for that; it's a good start!\nI pulled your changes into this branch: https://github.com/SocketCluster/socketcluster/commits/ipc-message-response and made a few changes and additions on top.\nI'll try to finish it and merge it into master tomorrow. With your changes, workers could respond to messages from master, but for consistency reasons I couldn't merge this feature until master could also respond to messages from workers (it should work both ways or else users will be confused).\nAlso I still need to implement the same functionality for allowing brokers to respond to messages from master and vice versa (will require a change to sc-broker repo). Again for consistency reasons (So the scope of this task has expanded to basically add response support for all IPC communications for all process types)\nFeel free to look through the changes I made. I think your logic was good and in all the right places but there was an extra error case that had to be handled; for example, if the worker response is taking too long (or fails entirely) we don't want to hold onto old event handlers (memory leak) so I added a timeout error which cleans up the pending handlers. Also, emitting random uuids as events on the main SocketCluster object is not ideal (we should keep the main SocketCluster instance clean from unnecessary events).\nAnyway thanks again for this contribution :). Thanks again @happilymarrieddad; I merged your commits manually and squashed them down so I'm closing this PR, you can see here: https://github.com/SocketCluster/socketcluster/commits/master\nThe changes have been published in v6.6.0.\nNote that the first argument to the response callback should be an error object (or null) and the second argument should be the payload. This is the current convention on the client-side and everywhere else in SC. I will update the website.. @happilymarrieddad I can't reproduce this. Could it be related to your specific setup; something is preventing your old workerCluster processes from shutting down properly?\nChild processes in Node.js are terminated when the parent is terminated. workerCluster process should automatically be terminated when your master process stops. I haven't had any issues with the newest version of PM2. What's your version of Node.js and SocketCluster? What PM2 command do you use?. @happilymarrieddad What's your Node.js version? pm2 restart works fine for me.\nI'm using pm2 v2.6.1.. @happilymarrieddad Let me know if you can find the cause because I can't reproduce it. I'm also on Ubuntu, Node.js v8.0.0, PM2 v2.6.1 and SC 6.7.1 and I haven't seen this issue before.\nMaybe it's related to the PM2 version?. @Panoplos That is for HTTP-based authentication. It sounds like your socket object is already connected and making GraphQL requests for public data; in this case, simply setting the localStorage.socketCluster.authToken is not enough; the SC client doesn't watch for changes in localStorage so if the socket is already connected, you need to use socket-based authentication; that means you have to explicitly pass the signed/encoded JWT token to socket.authenticate(myEncodedJWT) on the connected socket.. You could also just watch the localStorage yourself by doing something like this (for example):\nwindow.addEventListener('storage', function (event) {\n  // In case the user logged in from a different tab or if socket is already connected.\n  // Note that socket.options.authTokenName is 'socketCluster.authToken' by default.\n  if (event.key == socket.options.authTokenName) {\n   // self.isAuthenticated here is just some variable in your app logic\n    if (self.isAuthenticated) {\n      if (!event.newValue) {\n        self.isAuthenticated = false;\n      }\n    } else if (event.newValue) {\n      socket.authenticate(event.newValue, function (err, authStatus) {\n        self.isAuthenticated = authStatus.isAuthenticated;\n      });\n    }\n  }\n});. Thanks for pointing out this difficulty. I will see if we can bring that logic into the next version of socketcluster-client so that it watches the localStorage and authenticates automatically (maybe with an option to enable/disable it) - But for now you have to do it yourself.. @FallingSnow do you mean a default catch-all event (in case the server receives an event which has no matching listeners attached)?\nIf so, it's not supported at the moment but feel free to share more details about your use case and why you think it might be useful and we can consider it.. @nardeas Yes, that is what is recommended by Koa here: https://github.com/koajs/koa/blob/master/docs/api/index.md#applisten\nThe app.callback() argument passed to http.createServer(app.callback()) is the handler for the internal 'request' event so doing what you did above is equivalent.\nI think that your approach is the best way for Koa.\nNote that SC now also lets you create the HTTP server yourself but you need to put it in a separate file/module which exports a createServer(protocolOptions) function (which returns a Node.js-compatible HTTP server). You would need to tell SC about this custom module using the httpServerModule option here https://socketcluster.io/#!/docs/api-socketcluster - Then SC will use that function to create its servers internally; note that this is a much more advanced use case and probably not the best for Koa.. @nardeas A writeup would be great! If you write it on medium and send me the link, I could put it on the website somewhere.. @nardeas Nice stuff :). @Nicholi Your solution sounds fine, feel free to make a PR.. @Nicholi Thanks for that. Looks good at first glance. I'll test it out soon and merge it when I get the time.. @Nicholi Thanks for following existing conventions - That made it really easy for me.\nAfter merging your PR, I renamed initWorkerClusterController to just workerClusterController - But it works exactly the same.\nI think that the 'init...' controller should be unique because it's a special convenience controller (mostly for transpiling user logic) which runs on both worker and broker processes. Since this new controller is only run for the workerCluster process, it's OK to just call it workerClusterController.\nI've released this in SC v7.1.0.. Done.. @akshaychand Since SC v9, there is already automatic TypeScript support. Just run the main script (server.ts) with the ts-node command https://www.npmjs.com/package/ts-node instead of the node command - Also make sure that all your controller files (for child processes) have a .ts extension instead of .js. So for example it should be worker.ts instead of worker.js.\nYou will need to also update the path references to these controller files inside server.ts - You'll need to change these lines to point to .ts files instead: https://github.com/SocketCluster/socketcluster/blob/25b3f84f2bb69f92f9f9c404167c23ea27e5e919/sample/server.js#L20-L21\nThen it should just work.. @toredash Thanks!. @toredash I've pushed the latest images to DockerHub.\nNote that I've also just bumped SC to v8 today; this introduces subscription batching which should help provide a performance boost to scc-broker and scc-state but I think we can wait a couple of weeks before upgrading scc-broker and scc-state to v8. Risk management ;p. EDIT It might not affect the API necessarily. Maybe only protocol. Something to think about.. Done since v8.0.0.. @KCypher13 I'm closing this, please reopen this if you're still having the issue.. @PawanWagh It works for me. Note that only inbound messages (client socket -> server socket) will trigger the 'message' event - Not outbound.. @PawanWagh No, the environment should make no difference. Maybe there is something in your code which is different? Lots of people use this functionality.. @PawanWagh This should make no difference. Note that calling socket.exchange.publish(...) will NOT trigger the 'message' event on the socket because that publish is internal (not inbound). Only publish and emit from external client sockets (e.g. running in the browser) will trigger the 'message' event on the server side socket.\nAlso, note that the recommended syntax is scServer.exchange.publish(...) (instead of socket.exchange.publish(...)) you are not actually publishing the message to the socket but to the internal exchange (which will then send the message to all subscribers).. @igorarkhipenko I tested it on the latest react native (for Android) and was able to reproduce this issue. I did not notice it before; maybe it's an issue with new versions of RN. I can't seem to find any info online about window.addEventListener being undefined in React/RN.. I'll push a fix which will only attach the 'beforeunload' event if window.addEventListener exists - The 'beforeunload' event is useful for browsers where a user might navigate to a different website - It's not usually relevant for WebView-based mobile apps so we can just skip that logic in RN. It may be worthwhile to check on RN repo to see if anyone else has encountered a similar issues. It's not the first time that this kind of environment-detection logic has caused us problems with RN.. @igorarkhipenko Fixed in socketcluster-client@7.0.2.. Upgraded scc-broker to v9.. @toredash Great, thanks! I'll test it out over the weekend when I have some time.. @toredash Thanks! It looks like there was an issue with the indentation of the 'affinity' property but I fixed it up and it worked.. I don't think there is a clean solution to this issue until dynamic import() is introduced to Node.js.\nThe spec for dynamic import looks suitable (https://github.com/tc39/proposal-dynamic-import) - Hopefully it will be implemented soon.\nOne hacky solution would be for SC to add a transpilation step to inject the controller import statements into the code itself but that would be an absolute last resort solution.\nI think it's better to wait for now but we can keep this issue open as a reminder.. @mauritslamers Nice looks good! I'll test it out.\nI did something similar for the broker controller but I used the extends keyword and allowed the developer override the run() method with their own https://github.com/SocketCluster/sc-broker/blob/class-based-controllers/test/stubs/broker-controller-stub.mjs#L8-L9\nI see you've used a SCWorker.setup(...) approach https://gist.github.com/mauritslamers/1e5e24207e389dd00373b57b1f0ce359#file-worker-mjs-L19-L20 -\n Can you think of any problems with the extends approach? I like the extends approach a bit more because it reminds me of the Runnable interface which Java uses for running custom code inside threads (which is essentially what we're doing here except using processes instead of threads). http://www.java2novice.com/java_thread_examples/implementing_runnable/\n. @mauritslamers I created a new feature branch for this change on this repo called class-based-controllers https://github.com/SocketCluster/socketcluster/tree/class-based-controllers. If you want your contribution to show up on the GitHub repo, you can do a pull request against that branch. I'll have to do a bit of tweaking later to finalise this feature before we can merge it into master.. > it pretends to be class based, which in essence it is not. The class and extends keywords are syntactical sugar over the prototypal inheritance\nTrue, but maybe this syntactic sugar doesn't hurt in this case? I see an increasing number of projects using classes now and it's already taken for granted in the React community and many other front-end frameworks/projects.\n\nextends creates a new constructor + prototype. It doesn't create an instance\n\nIn that case we can leave the responsibility of instantiating the SCWorker (or SCBroker) to the developer; then the developer can even delay the instantiation if they want and the rest of SC would just wait for it. Here is an example for instantiating a custom broker controller:\nhttps://github.com/SocketCluster/sc-broker/blob/class-based-controllers/test/stubs/broker-controller-stub.mjs#L77\nIt does mean that the developer will need to add one line of extra boilerplate logic (which is a negative) but on the plus side maybe the extra flexibility is worth it.\nWe can make the underlying SCWorker class a singleton if necessary and throw an error if the developer tries to instantiate it twice (or something like that). They don't even need to subclass it, they could just instantiate the SCWorker directly. In that case, SC decides when to run the file (the entry point), but the user decides when to continue (once they've instantiated).\nI understand your point though that maybe instantiation doesn't feel right at a conceptual level. I'll think about this more.\n\nAs described in the comments in the gist: To keep the option of creating a new SCWorker instance you need a reference to the class somehow...\n\nOk. I'll look through your code and see if there are some small adjustments that can be made to solve this problem (to see if it's even possible). I was able to get it to work with the broker controller but it might be different in this case.. @mauritslamers I think that functionally it's perfect.\nBut it's a big change and it should affect all SC-based logic in the future for the rest of eternity. It's not just about functionality and correctness; there is also a convention (aesthetic/marketing) aspect to it.\nDevelopers are attached to conventions; I think that's why they introduced classes to JavaScript (ECMAScript people had to give up eventually); developers just couldn't adopt to the prototype approach fully. It's ridiculous but it's reality.\nSo in terms of functionality, your current approach is a huge improvement (it does everything we need) - but in terms of following existing programming conventions I think we should evaluate it further. Are there any other frameworks using a similar pattern?\nI will consult with some existing SC users to see what they think.. I've raised a proposal for people to vote on https://github.com/SocketCluster/socketcluster/issues/333. @gustojs Yes you can vote for all of them if you don't have a preference; it's good to know. I also think it's close. You can also suggest alternatives if you have other ideas.. This has now been released to npm as socketcluster version 9.0.3 - It's also been pushed to DockerHub.\n@mauritslamers The entry point supports all the formats that were put forward since they all ended up being compatible with almost no added complexity. I did not use any classes behind the scenes except for in the controller scripts themselves as defaults (the user is free to change to whatever approach they prefer).. @toredash Thanks for the feedback!\nBased on the earlier feedback I was given, this issue appears to be related to outbound messages. So if you have 20K subscribers and you publish one message to the channel, then effectively 20K copies of the message will need to be sent out at the same time - That's a lot of messages in a very short time. this can overwhelm the Node.js event loop.\nOne naive solution I can think of would be to add a delay in MIDDLEWARE_PUBLISH_OUT for each message before calling next() but I think it's worthwhile to investigate alternative approaches too - Maybe there is something that can be changed in SC internally to better support this use case.. Notes:\n- Adding random delay before calling next() will cause messages to be delivered out of order.\n- Queuing up the messages in the MIDDLEWARE_PUBLISH_OUT middleware might be a solution (should check that this doesn't use up too much memory).. @toredash It's nice to have some sort of monitoring for SC to track the CPU usage % - If it gets to around 80% on some CPU cores then you should start to expect disruptions to the service during spikes and it might be time to scale up or scale out.\nMy current thinking is to implement some sort of rate limiting/shaping for SC (either directly in SC as an option or as a plugin) which will help deal with large channels (with lots of subscribers) that are susceptible to large sudden spikes in message throughput... This could involve spreading out the messages over a longer period of time instead of trying to send them all at once (which sounds similar to what you're suggesting).\nRegarding your approach of re-fetching the log (snapshotting); that's a very common approach not just with SC but all kinds of projects and frameworks. The optimisation that you're suggesting (to only re-fetch new messages instead of the whole log segment) makes sense for chat as well. You can do this with SC but you'd have to implement that behaviour yourself on top of it... Maybe as a plugin/addon for SC.\nI've built a chat server on top of SC for a company which uses a similar approach (I pass in the date of the last received message and only get the log on or after that date - There can be some overlap so each message has a UUID).\nSC is not just used for chat servers though so it's outside the scope of SC itself (would make a great plugin/addon though),. @happilymarrieddad Yes something like that sounds good. Note that developers could implement something similar right now using MIDDLEWARE_PUBLISH_OUT but it's not that straight forward. Maybe it should be an option passed to SC to use a publish queue like that.. @happilymarrieddad Yes I was thinking of something like this! But I agree it's not very straight forward.\nDid you try this out in production?\nDoes it improve things?. @happilymarrieddad That's great thanks. I didn't get time to test it out. It would be nice to see before and after stats to see how it affects performance for scenarios where there are a lot of subscribers.\nI have some feedback about your plugin code:\n\nIt would be good to use something other than Array.shift() here: https://github.com/happilymarrieddad/sc-publish-out-queue/blob/master/index.js#L20 - When you remove elements from the front of an Array in JS, it has to update the index for ALL elements which come afterwards every time you call shift... So it is inefficient in this case because shift gets called many times (unless there is some special compiler optimisation that I don't know about). Maybe you can access elements using something like array[i] instead and once the loop is finished you can call Array.splice(...) a single time to remove all the elements which were just sent. See https://stackoverflow.com/questions/6501160/why-is-pop-faster-than-shift and https://jsperf.com/popvsshift\nInstead of var handler = function () { here https://github.com/happilymarrieddad/sc-publish-out-queue/blob/master/index.js#L15 you could use var handler = () => { instead. That way you don't have to add an extra closure here: https://github.com/happilymarrieddad/sc-publish-out-queue/blob/master/index.js#L40\n\nWe could consider integrating that logic directly into SC at some point in the future. Maybe using with an option in SC. Depends how popular the use case is and if there are any drawbacks to this approach. But for now it's good as a plugin.. Done.. @ArmorHerO It usually means that a backend scc-broker went down and is no longer reachable by the regular socketcluster instance. If you have multiple scc-broker instances, then the cluster will switch to other available instances.. @happilymarrieddad That sounds good!\nAlso, I'm writing a basic stress testing client for SC which I will use to test these plugins to see how they affect things. https://github.com/SocketCluster/sc-stress-tests. @RubouChen Did you also increase the ulimit? Do ulimit -n on Linux to find out what your limit currently is.. @RubouChen If you shut down the instance and bring it back up later, by default clients should auto reconnect after some time (takes a few seconds by default; but they shouldn't all reconnect at once). See autoReconnect options here: https://socketcluster.io/#!/docs/api-socketcluster-client. Please refer to this issue: https://github.com/SocketCluster/socketcluster/issues/404. @thomasvargiu Thanks for raising this issue. It has now been fixed in socketcluster v9.0.8.. @Panoplos It looks like babel-register ignores node_modules by default but you can set ignore to false. https://www.npmjs.com/package/babel-register#ignores-node_modules-by-default\n[EDIT] If you currently have all your main es6 (babel) logic inside worker.js, you will need to move that logic into a different file and use worker.js only for bootstrapping (e.g. for requiring and configuring babel-register). After you setup babel inside worker.js, then you can require the file which contains your main es6 worker logic (with all the imports).\nIf you use Node.js v8+, you can use es6 module import natively if you pass the --experimental-modules flag.\n. With the new architecture, your worker.js file is executed directly by Node.js with nothing in-between (it's executed directly via cluster.fork()). So you should treat the logic inside worker.js as if it was executed with the command node worker.js from the CLI.. @filipwa Maybe specifying environment variables like this is not supported by your shell on your operating system (Windows Powershell?). You should find a different way to set environment variables.. @debadaz It could either mean that a malicious user is trying to pass fake token data which was signed with an invalid authKey which SC is rejecting or (more likely) it could be that your SC instance's authKey has changed since the token was issued and so it's no longer valid (and so the user should log in again to get a fresh JWT signed with the new authKey).\nNote that by default, if you do not provide an authKey option to SocketCluster (in server.js), then it will generate a random one for you; a side-effect of this is that every time you restart your SC instance; the authKey will be different... So tokens which were issued before the last restart will be automatically invalidated.\nSearch for the authKey property on this page https://socketcluster.io/#!/docs/api-socketcluster for more info.\nYou may want to provide a static authKey string (which doesn't change between restarts) in order to minimize the occurrence of this error (maybe read the authKey from a config file or from an environment variable). That said, you should still try to account for the case where your authKey might change because you may want to change your authKey from time to time for security reasons.. @astutesoftware SC is not a message queue.\nThat said, there are many ways to make sure that clients receive a message after recovering from a lost connection.\nYou can store all messages in a log in the database (e.g. you could do it with MIDDLEWARE_PUBLISH_IN middleware) and when the subscriber client reconnects, they can fetch the latest log (snapshot) - That way they will get any missed messages.\nIf the sender goes offline before the message reached the server, you can make the frontend wait for the connection to come back and then retry sending the message (e.g. you can pass a callback to the publish method to check if the message reached the server)... You could store the unsent message in localStorage in case the user closes the browser before the message is sent while offline.\nYou can setup special channels unique to each user or category to check for read-acknowlegements from other users. Channels in SC are very cheap so you can create as many as you like.\nThere are a lot of scenarios where you simply don't need a message queue and it turns out to be a lot simpler.. @astutesoftware It depends on what your workload looks like. The advantage of using topic channels instead of private user channels is that you only have to check the user permissions once to see if a user is allowed to subscribe to a topic/room (e.g. inside MIDDLEWARE_SUBSCRIBE) and after that you can just keep publishing data to the target channel without having to do database lookups to see which users belongs to (and is allowed to receive data from) which groups/rooms.\nEither way is fine though and allowing each user to have their own private channel is pretty useful for a lot of scenarios and you can actually use both approaches to handle different scenarios within the same system. The best solution for you probably comes down to efficiency and/or code complexity.. This issue was fixed in SC v9.1.4. The time complexity of the algorithm for disconnecting n subscribed sockets was O(n^2). It has now been brought down to O(n).\nNote that this only affected the use case where you have some popular channels with many (e.g. 10K+) subscribers. If you had many small channels with fewer subscribers, then it wouldn't have been an issue.. @toredash Sure, sounds good.. @happilymarrieddad The express session plugin doesn't seem to scale out of the box because it stores the data on the server's memory by default. Maybe there is an option to make it store the session data in an external database instead?\nUnless you need to store sensitive session data, then JWT is usually a much better, simpler and more scalable solution.. @austinkelleher This pattern is not currently supported but it should be easy to add support for it. Please leave this issue open.\nIn the meantime, an alternative to this is to delay instantiation of the broker.\nE.g. You can achieve the same result by moving this line https://github.com/SocketCluster/socketcluster/blob/25b3f84f2bb69f92f9f9c404167c23ea27e5e919/sample/broker.js#L27 into a new async function block and do all your await operations before you instantiate the broker.\nBut yeah since you want to pass the broker to your function in a single call, it's not a perfect solution.\n  . @austinkelleher Ok, this feature should now be available in SC v9.3.0 https://github.com/SocketCluster/socketcluster/releases/tag/v9.3.0. @austinkelleher Great contribution, thank you!. @austinkelleher my mistake, nicely caught! (pun intended).\nAt a glance both of your PRs look very good.\nI'll merge and push/publish the fix later today.. @Rusfighter I've been insanely busy recently but if you want to launch/manage a subproject like this then that would be really great and I'd be happy to help out and answer questions.. The reason for the sc-jsonwebtoken fork has been resolved (https://github.com/auth0/node-jsonwebtoken/pull/446) so we should now switch back to the main node-jsonwebtoken repo.. SC started using the main node-jsonwebtoken dependency again since the missing feature was added.. Thanks. Yes I think a linter would be a good addition provided that it doesn't introduce too many dev dependencies into the project. I like to keep the dev tooling relatively lightweight if possible.\nBut yeah the plan eventually would be to port the current 'integration test scripts' to proper mocha test suites then add linting and CI.\n. :+1: . @masalinas Are you using Kubernetes?\nI would recommend adding a load balancer in front and configuring it to route each new connection to one of the two available instance IPs.\nAlternatively you could to the load balancing at the DNS level (e.g. you can add multiple IP addresses to your A record. See https://en.wikipedia.org/wiki/Round-robin_DNS) but that gives you less flexibility if you decide to add more SC instances later; that's why the load balancer approach is recommended.. SocketCluster/loadbalancer isn't really maintained anymore, it's probably better to use a specialized load balancer like HAProxy or nginx; both of these have pretty good WebSocket support nowadays.. @specialkk this.scServer (which used to be worker.scServer) should always be available inside the worker run() method - The this.scServer 'ready' event is what causes the worker's run() method to execute. Can you post simple code snippets to reproduce the issue?\nNote that you should now use this.scServer inside therun() method instead of worker.scServer but you can do var worker = this; at the start of the run method if you want to maintain consistency with previous SC versions.\nThe boot order is:\n\ncreateHTTPServer()\nrun()\nstartHTTPServer(). @sravia You may want to read the SCC Guide https://github.com/SocketCluster/socketcluster/blob/master/scc-guide.md\n\nIf you use an orchestrator like Docker Swarm or Kubernetes then the load balancing should be handled for you. Otherwise you can add the load balancer(s) yourself - HAProxy or nginx should be fine. Otherwise if you don't have too many nodes, you could even do load balancing using DNS by adding multiple A records which point to different SC instances.. If the page is served over HTTPS then the WebSocket connection from it must also be secure (wss:// instead of ws://).\nThe domain doesn't have to match - Often a subdomain is suitable and yes you may want to get a separate TLS/SSL certificate for the subdomain.. @drew-r That does sound very strange. I haven't encountered this issue. Does it make any difference if you use wsEngine: 'ws' or wsEngine: 'uws' as an option when attaching the socketcluster-server?\nDo you get any errors from the socketcluster-server (e.g. when you listen to the error event)? Is something causing either process to crash?\nCould you provide a simple snippet to reproduce the issue?\nAlso what's your Node.js version?. If you're not passing wsEngine engine option, it will default to uws, you can try to switch to ws explicitly to see if that fixes the issue. It's almost certainly not related to SC because SC itself doesn't interfere with HTTP in any way. It's highly unlikely to be uWS because it's pretty heavily used and I would think someone else would have encountered this issue.\nAre you serving your content over HTTPS? It'd be worth checking if there's some kind of proxy in between the client and server which is messing with things. If that's the case, serving over HTTPS & WSS should solve the issue. You can test with a self-signed certificate.. Note that there was an issue like this related to one of the native client libraries. I believe it's been resolved now. Not sure if it was the cause or not.. @yalint Are you connecting to the SocketCluster instance using a raw WebSocket client?\nIf so, it's not too difficult to make it work but you'll need to send the SocketCluster handshake immediately after connecting your device. You may want to read through the SocketCluster protocol guide here: https://github.com/SocketCluster/socketcluster/blob/master/socketcluster-protocol.md. @fkhateeb Sure that would be one way to do it.. Maybe we should switch to observables or promises or async/await on the socketcluster-client JavaScript client first before changing on the server-side.. This issue is a duplicate of https://github.com/SocketCluster/socketcluster/issues/408. @Hirbod Why can't you have 200K private channels?\nSC doesn't impose any hard limits on the total number of channels that you can have (or even on the rate of creation of new channels). Also the cost of each channel is negligible.. @Hirbod This is normal. It's a warning, not an error. Socket errors show up as warnings on the server.\nIn this case, the problem is probably that the client did not close the socket connection properly and instead killed the connection abruptly. The WebSocket RFC requires that client sockets send a close control frame the server (I.e. socket.disconnect()) before they kill the connection (or shut down the browser/app or put the device to sleep, etc...)\nWhen using SC, warnings are a normal part of day-to-day operations; they don't usually affect the user experience. it's good to be aware of them but you generally don't need to do anything about them. You can try to reduce how often they happen though.. If it says that the worker exited then it is an error. Do you have some other custom code in there that could be causing a fatal error (maybe as a flow-on effect to the first warning)?\nAlso what version of SC are you using?. @Hirbod I cannot reproduce. Which socketcluster version and socketcluster-client version are you using? . Can you reproduce the issue by connecting a client which is running inside Node.js somehow?\nE.g. You can run a client inside Node.js with:\n```\nvar socketCluster = require('socketcluster-client');\nvar options = {\n  port: 8000,\n  path: '/socketcluster/',\n  hostname: '127.0.0.1',\n  multiplex: false\n};\nvar socket = socketCluster.connect(options);\n```\nFor me I only get the warning but no error afterwards.\nNote that if you change a JS file and the worker reboots; that's normal (it's a default feature to help with development).\nIf a client reloads and the worker reboots; that's not normal. A client should never be able to make a worker reboot no matter what. Maybe you are capturing the warning on the server (or capturing the error on the socket) and re-throwing it as an error inside your code somewhere?\nErrors that are thrown directly inside your code will cause an error which will cause the worker to restart. So it's important to catch as many errors as possible.. UnknownError means that an unrecognised uncaught error type was thrown in one of the processes.\nSC should never throw this error type internally. I can reproduce the same error as you if I add this line inside worker.js:\njs\nscServer.on('warning', (err) => {\n  throw err.toString(); // Throwing a string; bad idea.\n});\nThen I open a client in the browser and I hold down the refresh key so that it keeps reloading until I see errors.\nMaybe this is not exactly what's happening but maybe something similar? Also check all your error handlers to make sure you're not re-throwing errors as strings.\nAFAIK, SC never throws strings as errors (it always uses Error objects) so it's more likely to be a problem with your custom application logic. If you do throw strings throughout your code, you should avoid doing that because strings don't have a stack trace. Better to use: throw new Error('Some error');.. @shcheuk Thanks, nice work!. It depends on if you want to automate your infrastructure or not.\nIf you have a very large production system with hundreds of machines then K8s would be very helpful.. You may be able to achieve this by adding an HTTP proxy in front of your SC instance.\nIf SC is down then there is nothing that SC can do about it.\nFor WebSockets though, you can increase the re-connection delay of your clients on the front end.. @happilymarrieddad It's not exactly the same. In the first case soc.publish('1000',packet) is called from inside the 'connect' handler (which is triggered asynchronously). In the second case the this.exchange.publish('1000',packet) is triggered directly inside the run method.\nWhen an instance starts it can take a bit of extra time to join the SCC cluster. If I publish inside a setTimeout it works fine in both cases for me.. @happilymarrieddad I can't reproduce this issue. I don't think any changes have been made to this area.\nMaybe you can try upgrading scc-broker-client https://www.npmjs.com/package/scc-broker-client to v2.2.0. Also I notice that you use scExchange to subscribe but worker.exchange to publish. Is worker pointing to the worker object?. @happilymarrieddad Ok sure sounds good. Thanks.. @happilymarrieddad Also did you update the code inside broker.js to match the new format: \n```\nvar SCBroker = require('socketcluster/scbroker');\nvar scClusterBrokerClient = require('scc-broker-client');\nclass Broker extends SCBroker {\n  run() {\n    console.log('   >> Broker PID:', process.pid);\n// This is defined in server.js (taken from environment variable SC_CLUSTER_STATE_SERVER_HOST).\n// If this property is defined, the broker will try to attach itself to the SC cluster for\n// automatic horizontal scalability.\n// This is mostly intended for the Kubernetes deployment of SocketCluster - In this case,\n// The clustering/sharding all happens automatically.\n\nif (this.options.clusterStateServerHost) {\n  scClusterBrokerClient.attach(this, {\n    stateServerHost: this.options.clusterStateServerHost,\n    stateServerPort: this.options.clusterStateServerPort,\n    authKey: this.options.clusterAuthKey,\n    stateServerConnectTimeout: this.options.clusterStateServerConnectTimeout,\n    stateServerAckTimeout: this.options.clusterStateServerAckTimeout,\n    stateServerReconnectRandomness: this.options.clusterStateServerReconnectRandomness\n  });\n}\n\n}\n}\nnew Broker();\n```\n. @MegaGM this change was intentional. There was an issue that if a regular SC instance would join the cluster in the middle of a sync round then the state of the cluster would get stuck and not sync properly because the new client was 'active' but all the other instances were stuck on a different phase. The client used to wrongly assume that the cluster was always 'active'.\nSo the fix was to make it so that the client would use the last known phase of the cluster that way new instances that join are now always in agreement with all other instances.. @happilymarrieddad Also you may want to upgrade to the latest version of scc-state https://hub.docker.com/r/socketcluster/scc-state/tags/ v1.7.1. > pretty sure this started happening when I upgraded to scc-broker-client 2.2\n@happilymarrieddad can you please confirm this?\nSo if you use the latest scc-state version (v1.7.1) and latest SC version (v10.1.2) but you use the previous version of scc-broker-client (e.g. v2.1.2 or earlier) does that alone fix the problem.\nIt would be great to figure out which of the 3 components is the cause of the issue (scc-state, scc-broker-client or SC itself).. @happilymarrieddad Can you reproduce the issue with a very basic SC instance (with very little custom logic on top)? I have not been able to reproduce it still and I know at least one big company (with tens of thousands of concurrent users and thousands of unique channels) which is using the worker.exchange.publish(...) feature in production right now without any issues. So I'm thinking that it's not so straight forward.\nI'll keep trying to reproduce though. Do you get any errors at all?\nCould it be a network issue between the regular SC instances and the scc-broker instances?\nWhen you publish with the client, does the published message reach both servers? If not then it definitely means that it's a network issue and not related to worker.exchange (if you try this, make sure that both servers have clients which are subscribed to the channel).. @happilymarrieddad Did you check that all dependencies of the regular socketcluster instances are up to date after upgrading to SC10? You can try to delete your project's package-lock.json (if you have one) and and reinstall dependencies from scratch.. @Hirbod MIDDLEWARE_PUBLISH and MIDDLEWARE_EMIT are completely separate lines (or at least they should be). So if you want to block a simple emitted event, you should setup a separate MIDDLEWARE_EMIT. Note that you can use the same function for multiple middlewares since most of them are somewhat compatible (depends what you want to do though).. @Hirbod Have a look at the logLevel option on master process https://socketcluster.io/#!/docs/api-socketcluster. Done since SC v11.3.1.. Done.. @MadGeometer That is definitely supported - It can be different ports on the same host, the same port on different hosts or different ports on different hosts.\nWhat is the log from your scc-state server?. @MadGeometer Make sure that you're using the latest versions of scc-state and scc-broker repos/instances and also the latest version of the scc-broker-client module (which you use on the regular SocketCluster instance inside broker.js).\nThere was one breaking change last month which means that not all versions of the components are compatible.. @hardikamutech You need to increase the number of workers; just change the workers option in server.js to the number of worker processes you like. If you haven't added any stateful socket management logic to your worker process then you won't need to change any code.. @Hirbod ah yes we need to fix documentation. Did you look at https://github.com/SocketCluster/socketcluster/blob/master/scc-guide.md#running-using-nodejs-directly ?. I've trimmed down the stuff on the website a fair bit; see https://socketcluster.io/#!/docs/scaling-horizontally - Hopefully that helps to put more emphasis on the links (where all the real info is).\nHopefully this makes it clearer but documentation is ongoing work.. @abhi86813 If stress testing:\n\n\nDid you increase all the file limits on both the client and server machines?\n\n\nDid you check to see if your client machine is using 100% CPU on all cores when running the tests? You'd need a REALLY good client machine in order to simulate 4K client connections with the socketcluster-client before they start timing out - The client socket is multiple times less performant than the server socket. Also you may need high bandwidth between them if you're sending many (or large) payloads.\n\n\nLast time I did a stress test, I needed multiple 32-core machines to put a single 8-core server under stress.. @abhi86813 it's a lot less than what I would expect, last time I did the test on a single worker process, I was able to get 14K concurrent subscribers on the same channel.\nAlso note that the current test in sc-stress-test is very specific because it tests the ability of the server to process a single message and forward it to all subscribers at the exact same time and it repeats this every second. You can add code in SC middleware to smooth out peaks (e.g. spread out outbound publishes a bit more) so that you can increase the concurrent subscribers multiple times.\nThe number that really matters is how many messages SC can process per second; and that's typically between 10K and 20K per CPU core on a decent machine depending on which wsEngine you use.\nWhen doing tests, you should check CPU usage on the server instance and see if it reaches 100% on all cores; if you run the top command, you should see at least one node process reach 100% CPU. If it never reaches 100%, then you know that there is something else happening (file limit, bandwidth limit or maybe a proxy or firewall?) which is not allowing more connections.. @abhi86813 Maybe a proxy issue; try using a different machine/cloud provider. It looks like your CPU usage % is very low so it's almost definitely not an SC issue.. @happilymarrieddad It's already available on the client (it's false if the socket was destroyed).\nOn the server the socket 'active' property is not as useful because once a server-side socket is disconnected, you can't do anything else with it except throw it away... So active is basically the same as disconnected in that case.. Done v13.1.3.. Implemented in 13.0.0.. @happilymarrieddad I think removing altogether is better or else it just adds more complexity than it's worth.. @JCMais I think it's OK to drop support for node <= 6 for new versions of SC.\nI think we can start now.\nWe may not need to do everything at once but we should make sure that the API remains consistent anyway.\nRight now async/await is already partially supported for some things. With middleware, you can do this:\n```\n  async function wait(timeout) {\n    return new Promise((resolve) => {\n      setTimeout(() => {\n        resolve();\n      }, timeout);\n    });\n  }\nscServer.addMiddleware(scServer.MIDDLEWARE_HANDSHAKE_SC, async (req) => {\n    // Delay handshake by 5 seconds.\n    await wait(5000);\n  });\n```\nor\nscServer.addMiddleware(scServer.MIDDLEWARE_HANDSHAKE_SC, async (req) => {\n    // Block handshake with error.\n    throw new Error('Handshake failure');\n  });\n. @JCMais good point. I also just realized that yesterday and started making changes in socketcluster-server. What do you think about doing something like this:\nasync () => {\n  let err = new Error('Silent middleware error');\n  err.silent = true;\n  throw err;\n};\nthis would also work since this thrown value is not logged anyway:\nthrow {silent: true};\nFor middlewares like MIDDLEWARE_HANDSHAKE_SC, which allow you to close the socket with a custom status code, we could do:\nasync () => {\n  let err = new Error('Handshake failed with custom code');\n  err.statusCode = 4444;\n  throw err;\n};\nDo you have alternative approaches to suggest?. @JCMais sounds good. These could be added to the shared sc-errors module.. For the client, I'm thinking about changing the API to something like this (feedback and suggestions are welcome):\n```\n// Consume response data from emitted event\ntry {\n  let adminUsers = await socket.emit('getUsers', {type: 'admin'});\n  // ...\n} catch (err) {\n  // Failed to fetch users.\n}\n// Consume event data\nasync function consumeErrorEvent() {\n  for await (let error of socket.event('error')) {\n    // ...\n  }\n}\nasync function consumeConnectEvent() {\n  for await (let connectStatus of socket.event('connect')) {\n    // ...\n  }\n}\nasync function consumeCustomEvent() {\n  for await (let data of socket.event('customEvent')) {\n    // ...\n  }\n}\n// Consume channel data\nasync function consumeFooChannel() {\n  for await (let data of socket.channel('foo')) {\n    // ...\n  }\n}\n```\nOn the server side, the worker.exchange object should also follow a similar pattern for consuming channels.. @JCMais the channel object returned from socket.channel('foo') would be an iterable - Implemented as an async generator so you can chain them together in many ways. For example:\n```\n// A filtered stream based on the foo channel stream.\n// It only contains messages published to the 'foo' channel which start\n// with the letter 'A'.\nasync function* filteredFooGenerator() {\n  // socket.channel('foo') is an async generator/iterable exposed by\n  // the socketcluster-client API.\n  for await (let data of socket.channel('foo')) {\n    // This loop will iterate once for each message published to the 'foo' channel.\n    if (data.indexOf('A') === 0) {\n      yield data;\n    }\n  }\n}\nasync function consumeFilteredFooData() {\n  let filteredFooStream = filteredFooGenerator();\n  for await (let data of filteredFooStream) {\n    // Each time a message is published to 'foo' channel which starts with the\n    // letter 'A',\n    // this loop will execute an iteration.\n    // ...\n    // Do something with the message; render it to a VueJS or React template, log it, ...\n  }\n}\nconsumeFilteredFooData();\n```\nThis is based on this approach:\nhttp://2ality.com/2018/04/async-iter-nodejs.html\nI also wrote an article about how this could be implemented:\nhttps://hackernoon.com/using-async-generators-for-data-streams-f2cd2a1f02b3\nIt works similarly to RxJS Observables except it uses generators instead so the code should look a bit cleaner.\n. I think that implementation of the streaming functionality (e.g. using async generators) discussed above could wait a bit though (if the community likes that approach). Async generators are still very new and only implemented in Node.js 10 AFAIK.\nProbably the first thing to do would be to switch to Promises for functions which expect a callback which triggers a single time. That shouldn't be controversial ;p. Also, we should consider separating regular events from events which expect a response (RPCs).\n// Consume regular event\nasync function consumeCustomEvent() {\n  for await (let data of socket.event('customEvent')) {\n    // ...\n  }\n}\n// Consume RPC events\nasync function consumeCustomRPCEvent() {\n  for await (let req of socket.procedure('customRPC')) {\n    // ...\n    console.log(req.data); // req.data is the data passed to the RPC\n    if (...) {\n      req.error(error); // send back an error to the RPC caller\n    } else {\n      req.end(data); // send back data to the RPC caller\n    }\n  }\n}\nOn the opposite side of the socket, the RPC can be invoked like this:\nsocket.invoke('customRPC', data)\n.then((data) => {\n  // ...\n})\n.catch((err) => {\n  // ...\n});\nEvents can be emitted like this:\n// No Promise returned.\nsocket.emit('customEvent', data);\n. I'm thinking of also separating local events (which occur on the same side of the socket) from remote events which are transmitted by the socket on the opposite side of the connection.\n```\n// Handle local events\nfor await (let event of socket.listener('connect')) {\n  // ...\n}\n// Handle remote transmissions from counterparty socket.transmit('myReceiver', ...)\nfor await (let data of socket.receiver('myReceiver')) {\n  // ...\n}\n// Handle RPC requests from counterparty socket.invoke('myProcedure', ...)\nfor await (let request of socket.procedure('myProcedure')) {\n  // ...\n}\n// Handle channel data from counterparty socket.publish('myChannel', ...)\nfor await (let data of socket.channel('myChannel')) {\n  // ...\n}\n```\nFor each kind of stream above, it should be possible to listen only to the first event/message/request like this:\n```\n// For local events\nlet event = await socket.listener('connect').once();\n// For remote transmissions\nlet data = await socket.receiver('myReceiver').once();\n// For RPCs\nlet request = await socket.procedure('myProcedure').once();\n// For channels\nlet data = await socket.channel('myChannel').once();\n```\nIf anyone can think of better method names or a better pattern, feel free to suggest.. @miladr0 It just means that the server sent a ping to a client socket but the client socket did not respond with a pong in time. Either it means that your client was too busy (e.g. maybe stuck in a for loop?) or the internet connection was bad (so the client sent a pong but it did not reach the server in time)... Or maybe you didn't set the pingInterval and pingTimeout options correctly when you created the main SocketCluster instance; the pingInterval should always be smaller than pingTimeout (ideally, the interval should be less than half of the timeout; e.g. you need at least two missed pings/pongs before the socket times out) .. > My first question is (let's assume they did not disconnect and every watcher is working fine)\nIs it possible that a publish won't be delivered to a user? This is a serious question.\nIf you're running SC on a single machine, the only realistic case where this can happen is if one of the processes crashes (e.g. because of an uncaught error) but that should be pretty obvious from the logs.\n\nThe second and much bigger issue is: currently, the user has 10 seconds time to pick an answer...\n\nMaybe the user's socket was disconnected for a few seconds and their answer was sent after a delay (when the connection came back).\nmaybe your server is overloaded since you are running multiple programs on it; what is the CPU % usage on that machine (e.g. with the top command)?\n. How is Redis and MySQL performance?. @MatthewAry it looks like your HTTP requests are slow as well. Is it also slow when you have no users on it? Could it be that your cloud provider is throttling your bandwidth? It looks like you're using a small machine.\nWhat happens if you run a plain Node.js HTTP server next to your SC instance and try to connect to it? Is it also slow? What WebSocket wsEngine are you using? What version? How does it behave if you use ws as the wsEngine?\n. @Hirbod When you say that CPU % is 0.2%, is that at the peak? I suspect that for your use case, you would have very low CPU usage and then a significant peak every 10 second or so (when all the answers are sent from clients at almost the same time).. @Hirbod Many cloud providers throttle CPU and bandwidth on smaller instances; sometimes it doesn't take much to trigger it. Not sure that's the problem but worth trying with a different instance to see if it makes a difference.. > In any case, @happilymarrieddad works down stairs\nHaha good teamwork ;p\n@Hirbod I just did a test on Amazon EC2 with 16K concurrent sockets subscribed to the same channel on an 8 core machine (7 workers, 1 broker). SocketCluster version 13.1.5 (using sc-uws as the wsEngine).\nI published a message to the channel once every 10 seconds:\n\nCPU peaked at 30% (it was for a fraction of a second) and immediately went back down to near 0% - It was 0% throughout most of the test.\nAll 16K copies of the message were received for each round (I watched the channel on each socket and added up the messages).\nLatency varied from 10ms to 600ms max (but I think a lot of this is was because of all the logging I was doing on the client) - I added the timestamp to the channel message just before publishing and then when the socket received the message, I compared it with the current time and logged the results.\n\nThe machine which I used to simulate the clients had 32 cores and was in the same region (US) as the server machine but in a different availability zone.\nYou may want to double-check that you're not accidentally publishing more messages than intended; for example if you publish from inside an event handler which is accidentally attached multiple times.\n. It sounds like this issue could be related to nginx proxy_buffering see https://stackoverflow.com/questions/9612983/socket-io-slow-response-after-using-nginx. @Hirbod I'm pretty sure that a lot of companies use nginx in front of SC, it just seems to be bit more work to configure properly. I have some experience with HAProxy and node-http-proxy and they were pretty easy to setup with SC/WebSockets.\nRunning SC without a load balancer is also good sometimes; one advantage is that it uses less CPU overall but one downside is that you miss out on features that a load balancer might provide in terms of firewall, rate limiting, routing, etc...\nI think that many realtime online games don't use load balancers; often rate limiting is handled explicitly in the backend logic along with other logic to prevent players from cheating. Middleware in SC can be useful for this.. @Hirbod You can't restart other workers directly from a worker, but you can send a message from a worker to the master process using worker.sendToMaster(data, [callback]) and then from the master process (server.js) you can restart all workers with socketCluster.killWorkers().. @marcj If you keep the same socket/exchange object around forever then you should call channel.destroy() when you're no longer using a channel or else it will stay in memory (so if you create a lot of unique channels and never destroy them then yes it will lead to a memory leak).\nYou don't need to destroy the individual channels if you call socket.destroy() on the socket itself; destroying the socket will also destroy all the channels that are attached to it.\nSC will give you back the reference to an existing channel if such a channel already exists on the socket/exchange. Each channel is unique throughout the socket/exchange. So if you destroy a channel, it will affect all watchers for that socket/exchange (shouldn't affect other sockets/exchanges though).\nThe reason why channels are reused is because the SC socket needs to keep track of channels in order to pass data to them from the server so it needs to have a reference to the channel object. Allowing multiple channel objects per socket (for the same channel name) would add overhead and complexity inside SC and would lead to having multiple sources of truths for what is essentially the same resource.\n. @marcj \n\nOh, are you sure about that? Because destroying a channel (channel.destroy()) means all clients currently subscribed to it will automatically unsubscribe as well.\n\nThe channel object is bound to a single client so destroying it only subscribes and destroys it on that client; it doesn't affect other clients. Note that the exchange object is also a client and it's independent from all other sockets in the system; the exchange is basically a socket which can be used on the backend, is always connected and has slightly different behaviour from other kinds of sockets in the system.\nNote that on the front end, if you call let socket = socketCluster.create(...) or  let socket = socketCluster.connect(...), multiple times, by default, if the options are the same (e.g. same target host, port, query parameters, ...) then it will reuse the existing socket instead of creating a completely new one. If you want to force the creation of a new socket every time, then you need to pass a multiplex: false parameter to the create function. Not sure if the current behaviour is the ideal default behaviour anymore so feedback is welcome.\nIf you want to contribute to the website documentation, it's here: https://github.com/SocketCluster/socketcluster-website\n. > So, I assume the SimpleExchange is instantiated per worker. If so we could probably check on each client 'disconnect' event whether a channel has watchers open, if not then automatically delete that channel object to get rid of the memory leak.\nYes I guess there are many ways to do this. Whenever you create channels on the exchange on the backend, you need a strategy like this to manage them.. @marcj Ah yep, it was watching an unsubscribed channel. You need to subscribe the channel to start receiving the messages.\nYou can also do:\nexchange.subscribe('channel');\nexchange.watch('channel', (data) => {\n  // ...\n});\nOr you can call subscribe after as well, it doesn't matter so long as the subscribed is called. So you can turn subscription on/off temporarily without having to detach the handlers.. @dafivius It should definitely log errors from broker.\nWhat version of SC are you using?\nWhat Node.js version?\nWhat do your SocketCluster config options (in server.js) look like?. @happilymarrieddad Hmm yes that is strange - This kind of error should only trigger on the socket object and shouldn't cause the worker process to crash. Maybe something in your code is explicitly calling a process.exit(...) or process.kill(...)? Or maybe some error event handler was removed and so the error became uncaught?\nThe other weird thing is the exit code, did you edit the console output for GitHub or does it actually print Exit code: **** to the console?. @happilymarrieddad Did you try to search for the string **** throughout your project code and/or node_modules dependencies?\nDo you have a custom workerClusterController file? The only way I can reproduce this issue is if I add custom code to the workerClusterController and do something like this.workers[0].emit('exit', '****').\nThat's the only thing I can think of. If it's not that then maybe it's some strange Node.js issue with exit codes that I don't know about. You can try upgrading Node.js version.. @dotbloup Make sure that you are using the latest version for everything including the scc-broker-client library (from your main SC project). https://www.npmjs.com/package/scc-broker-client. @dotbloup The npm packages were out of date. Should be fixed now.. @happilymarrieddad When you get this error, does /usr/bin/nodejs still exist? If it's inside a container then you can try to SSH into the container to check if that path exists.\nWhat happens if you run /usr/bin/nodejs -v in the command line?. @mahmoudsalem That looks more like a Node.js/OS issue than specifically an SC issue. Maybe your system is out of resources? Reached file/socket limit, process limit, memory limit or similar.. These errors seem to indicate that the server could not be reached or it took too long to establish the connection. Maybe there is a load balancer/proxy which is blocking or throttling the connection. You can also get this error if a socket disconnects abruptly without sending a WebSocket close control frame.\nIt's normal to get these 'Socket hung up' messages from time to time in production though.. @tangquoctuan It looks like you may be passing an array as the channel name on the front end (E.g. socket.subscribe(['tuan: 1', 'tuan: 2'])). The channel name needs to be a string.\nNote that to subscribe to multiple channels, you need to call subscribe multiple times.. @DanielRose We should link to it from the project website :)\nDo you intend to do a PR on the main DefinitelyTyped repo?. @DanielRose My current stance is that we shouldn't force developers to use TypeScript in order to use SocketCluster but also we don't want to discourage them from using it either.\nWould having all the type definitions in a folder directly inside this socketcluster repo make them more accessible and easier to maintain (instead of keeping them in the DefinitelyTyped repo)? What is the common practice in the TypeScript community?. @Akuukis the second approach sounds good. I think that if we have the types in the main socketcluster repo, they'll be more likely to be kept up to date with the JS code. Also having a stub with warnings in DefinitelyTyped repo sounds good.. @DanielRose we can go with whatever you think is best ;p\nI guess SC types aren't likely to change too much in the future.\nWe can mention the existence of the typescript definitions on the socketcluster.io website when ready.. @Akuukis I haven'ted used SC with TypeScript yet so I'm not sure what steps are involved so feel free to lead the way if you have something specific in mind. You can make a proposal here or as a new issue and if/when the community is generally happy with the proposal then you can make a PR.. @tarilo It shouldn't be the case. There are several companies running each instance in the SCC cluster on a separate machine in production without issues.\nIt probably means that your scc-worker (regular) instances cannot find the correct IPs of your scc-broker instances. Maybe the port is blocked or the IP address of the machine is not publicly accessible or maybe the container port mapping is wrong or maybe because the scc-broker is running inside a container, it's passing its private container IP instead of the public IP address.\nNote that you can configure the external IP address of the scc-broker instance by passing an SCC_INSTANCE_IP environment variable to the instance/container. See https://github.com/SocketCluster/scc-broker/blob/master/server.js#L9. @tarilo You shouldn't need to pass the IP of the scc-broker to regular instances, you just need to tell the scc-broker its own external IP address when you run it and it will tell the scc-state instance and then the scc-state instance will tell every other instance. But I guess whatever works.. @dkruchinin This is a feature ;p SocketCluster doesn't do delivery guarantees but you can implement your own mechanism on top.\nTelling a client if a message failed to be delivered is tricky because there are multiple scenarios to account for. For example, if a channel has 1000 subscribers and only 999 of them receive the message successfully; should we tell the publisher client that the publish operation was a success or a failure?\nThe publish operation currently only tells you if the message reached the front-facing server; beyond that it doesn't track the delivery to individual subscribers.\nIf you want to track if specific subscribers have received specific messages, then you can create special receipt/acknowledgement channels which subscribers can use to inform publishers whenever they receive certain messages.\nIt would be nice to write a client-side plugin though which could implement this guaranteed pub/sub receipt/ack feature; it shouldn't be too difficult.. @dkruchinin Now, when publishing, you can only verify that the message reached the server that you are directly connected to, beyond that there is no guarantee that the message has successfully propagated through the rest of the cluster.\nThere is some work being done right now which will offer delivery guarantee at the back-end/cluster level (e.g. it will retry failed deliveries which did not reach other nodes on the back end) - That feature could potentially be a couple of months away from completion though.\nIdeally, when this feature is completed, you should be able to configure your SCC nodes to enable or disable delivery guarantees.. @dkruchinin; there is a branch by @BenV which supports adding custom middleware functions to a regular SC instance's broker process; see https://github.com/BenV/sc-broker/commit/43adbe416fb20a1820221b901d49c75a3f4bd9de; this will allow us to do things like delay the completion of a publish operation until it has fully propagated throughout the rest of the cluster (it will allow us to retry publishing multiple times behind the scenes in case an scc-broker instance fails behind the scenes).\nThe changes by @BenV are the first step. Then we'll need to also make changes to https://github.com/SocketCluster/scc-broker-client (this is the client which connects each scc-worker instance to back end scc-brokers) and also to scc-broker https://github.com/SocketCluster/scc-broker - I guess the expected behaviour would be to retry sending a message if it doesn't reach the other instance.\nI think it should be configurable (can be enabled or disabled) because not all systems require delivery guarantees.. @rasmuserik The changelog is here: https://github.com/SocketCluster/socketcluster/releases - The most difficult upgrade is usually from v8 to v9.0.3 so read that one very carefully.\nHow difficult it is depends on the size and complexity of your system.. @tangquoctuan There is no default config option to do rate limiting in SC (if that's what you're asking) but it should be easy to implement it on your own using middleware. See https://socketcluster.io/#!/docs/middleware-and-authorization\nYou can just count the number of messages per minute on a socket and if the number gets too high, you could disconnect the socket with an appropriate error code and reason.. @ShutiMore OK, This error message should be improved in SocketCluster. What it means is that the protocolOptions.key which you passed to the main SocketCluster instance is in the wrong format. It should start with -----BEGIN RSA PRIVATE KEY----- on the first line and finish with -----END RSA PRIVATE KEY----- on the last line.\nPlease leave this issue open so that we can remember to fix this error message.. The error should be more obvious now since socketcluster v14.1.1.. @Aareksio Thanks for pointing out this issue. It's now been fixed in socketcluster-server@13.2.0 so that it  behaves consistently in both cases.. @bebeo92 I haven't tried running PM2 on windows with child processes so I'm not sure what is the expected behavior but this does look strange. Do the blank windows close when you kill the main process with PM2?. @bebeo92 it definitely doesn't do it on Linux (which is the most common production environment). Maybe PM2 is not optimized for Windows.\nSC just uses node.js's cluster and child_process modules to spawn up child processes so it's not doing anything out of the ordinary. Have you tried using a different console in Windows? Maybe Powershell?\nIn any case, it seems to be a PM2 issue: https://github.com/Unitech/pm2/issues/2182. @bebeo92 Maybe try upgrading your PM2 version.. Otherwise, if you think that this issue can be solved inside SC, you can try playing around with the arguments that SC passes to the fork function:\n\nIn main socketcluster module: https://github.com/SocketCluster/socketcluster/blob/master/scworkercluster.js#L167\nIn sc-broker dependency: https://github.com/SocketCluster/sc-broker/blob/master/index.js#L82\n\nThen feel free to make PRs.. Real-time just means that the message is pushed to the user with very little delay. You can build P2P servers using SocketCluster but it's not a WebRTC framework... @eranegozy this repo needs to be cleaned up a bit.\nAlso it needs more tests; now there is only a single one called many-subscribers; it tests a very specific scenario which checks how many clients can subscribe to the same channel (if the channel gets a new message every second).\nFeel free to clean up that logic and add more test scenarios.\nIddeally you need to run node server/server.js on one machine and then you run node client/client.js on a different machine. You can pass the target hostname, port and number of clients using command line arguments. See https://github.com/SocketCluster/sc-stress-tests/blob/master/client/client.js#L8-L10. @dwmcc Yes, by default the socket doesn't need to be authenticated to connect to the server.\n\nbadSocketAuthToken means that the client provided a token as part of the handshake but that token was invalid; if no token was provided, then this event will not trigger.\nMIDDLEWARE_AUTHENTICATE only executes if the socket token was valid; it's useful if you want to add additional authentication steps in addition to SC's JWT validation. Not useful for your use case.\nUsing scServer.on('connection', ...) and socket.on('connect', ...) to check for the token and disconnect if not present are both good approaches.\n\nIf you want to optimize things further, you can also specify a query object when creating the socket on the client side which contains some kind of token. You will then be able to access the token from the query object from the server-side inside the MIDDLEWARE_HANDSHAKE_WS handshake; this is the first middleware which runs before the socket starts connecting; so it's the most efficient place to quickly kill connections. The req object passed to the middleware function in this case is a Node.js HTTP request (IncomingMessage object); so you can parse the query from req.url.\nUsing MIDDLEWARE_HANDSHAKE_WS may be overkill for most use cases.. Thanks, this was useful. I fixed several of the linting issues.\nSome of them were a bit too trivial though so I didn't implement all of them.\nESLint is a useful tool to guide decisions but it should not be a replacement for common sense.. @necccc Thanks for noticing this and for taking the time to make this pull request.. Nice work. Could you provide a bit more detail about using ClusterIP and what this change achieves?\nIf ClusterIP is the default, then it doesn't hurt to be explicit. Please confirm if this PR changes the behavior or not.\nAlso what is your setup/platform which you have you used to test it?. scc-state doesn't use persistent storage; it's all in memory. scc-state is not really a single point of failure because SCC can keep working without scc-state. There will only be partial disruption of the service if both scc-state and an scc-broker fail at the exact same time; and even if this unlikely scenario were to happen, the disruption should only last a few seconds.\nI will update the scc-guide to remove the phrase 'single point of failure' because it sound like it's a problem but it's not; it's intentional. You always need to make a trade-off between consistency or availability and SCC leans slightly more towards consistency but it's still very resilient in terms of availability.\nWe could replicate scc-state but that would add a huge amount of complexity and very little value; and even then, we can never guarantee 100% uptime; you would still get a few milliseconds of downtime after a failure of the scc-state master instance is detected before the cluster switches to the backup scc-state instance.. @happilymarrieddad Your PR looks good now. It might take a bit of time to merge because I want to test it first.. @happilymarrieddad Thanks for this contribution :)\nSorry it took so long; I was busy and didn't get the time to test it until recently.\nAfter testing it on GKE, I changed it to expose the socketcluster (worker) service using NodePort otherwise it doesn't work on GKE. This could also be an issue on other platforms.. @nmhung109 TimeoutError just means that the server did not respond to an event in time. Maybe a database query is taking too long or you forgot to respond to one of the events (to which the client expects a response). The duration can be configured. Check ackTimeout here: https://socketcluster.io/#!/docs/api-socketcluster.. @maxwellhaydn thanks for reporting this.\nFor some reason I cannot reproduce the issue (maybe a settings difference). Also the docker image doesn't seem to be affected.\nThat said, the third argument passed to the cb should in fact be a string; so I agree with your suggestion. We need to account for the possibility that the developer might pass back a string to the next function; so maybe it should be:\njs\nvar errorReason = typeof err === 'string' ? err : err.message;\ncb(false, 401, errorReason);\nAlso, we need to do the same with the other cb(...) below.. @maxwellhaydn Ok, I published the patch in socketcluster-server@14.3.2.. It should be scServer.clients[socket.id] plural.. @JCMais Thanks for pointing this out. I'll investigate this solution.. @JCMais I finally got some time to test your approach on GKE and it worked perfectly and it's definitely much cleaner so I'll try to push with an update soon.. @ayZagen SC has moved away from using sc-uws as the default. It's just too much effort to maintain; each node.js version requires new builds. uWS is an optimization for more advanced users.\nI'd prefer to wait for the ws module to add it. Please let me know if you manage to get SC to work with HTTP2. Feel free to post recommendations here.. Separating channels based on the worker will make things very complex. An alternative approach would be to have multiple workers checking for changes in the database and each one is responsible for consuming a different subset of the data. Then if some data changes, only one of the workers will pick it up and publish to the relevant channel. If you have multiple brokers in SC, channels will automatically shard between them, so it's already scalable on the distribution side. Based on my understanding of the problem, you probably want to focus on the consumption side; how you're consuming changes from the database; you need to spread out consumers across workers.. @maxwellhaydn that sound like a good solution to help organize handlers but I think it's better as a separate module because SC shouldn't be too opinionated about code organization (any more than it already is). If you've published such a module to npm, feel free to share it with the community here.. You can if convenience is important to you and you don't care about horizontal scalability (or you want to implement your own syncing mechanism between different instances). The recommended approach though is to store that data in a database or memory store like Redis.\nThe scServer.exchange instance supports the same methods as the sc-broker object here: https://github.com/SocketCluster/sc-broker#client-methods - It can scale pretty well vertically if you're just storing simple hierarchical data (or just key-value pairs) but it's not designed to scale across multiple machines.\nIt's useful mostly to allow workers to easily/efficiently share data with each other without having to manage a separate database or datastore.. @bodaghialib4 Sorry for the delay in response. Based the logs you provided, I cannot see that the worker is crashing. It's logged as a warning; which shouldn't crash the worker.\nBy default, SC should show the worker PIDs on launch. You can use the command line (e.g. ps -e | grep node) to check if the process PID changes after the error. If the PID is the same, then it means that the worker did not crash. Also you can try adding a console.log at the top of worker.js and see if your message gets logged after the error happens. If your log does not show, then it means that the worker did not restart.. Missing space between the = sign and the number.. Don't commit commented-out code.. Space at the end of the line.. Space at the end of the line.. This shouldn't be removed.. Need space between column and number.. There is a bunch of extra whitespace characters at the end of most lines.. Maybe there should be an option in SC which lets you specify how to kill the workers (which specific signal to use) that way the user can choose.. Makes sense :). Not sure what the scope of this childExitMessage variable is, it doesn't appear to be declared with var.. Won't this always be true?. For consistency, nothing should be logged directly in the workerCluster process (scworkercluster.js); you can pass the warning/error back to the master process to let the master deal with the logging; this is to make sure that the master process is always aware of what's going on across its child processes.\nI think it's probably best to treat this as an error (not just a warning).\nSee how errors are passed back to the master process: https://github.com/shcheuk/socketcluster/blob/08ac2d7f36ffc0a7f17a0b2213f0423cdb615ba8/scworkercluster.js#L20\nhttps://github.com/shcheuk/socketcluster/blob/08ac2d7f36ffc0a7f17a0b2213f0423cdb615ba8/scworkercluster.js#L52\nAlso please be consistent with spacing when concatenating strings together ;p. Maybe call it scc-state-service instead?. Name scc-broker-service would be better.. socketcluster-service. Is this indentation correct?. ",
    "sergiolepore": ":+1: \n. ",
    "gkze": "As an afterthought, it would be cool to have jshint/eslint do this instead. I'd be happy to take that on\n. Sure, I completely understand  :thumbsup:\nI can send PRs for the other modules too if you want, just with the tab => space expansions.\nThere seems to be an option in jshint to allow for ==, but that's completely up to you\n. ",
    "joinfok": "Thanks your fast response! \nMain app is dinamical model. Chatroom created ower php portal, this put the room into browser and client try connect+auth into chatserver. In auth procedure chatserever read all data from redis (room and user info).\nThe socket.on('connect',function(d){\nif auth success->socket.emit(greet..)\nadd sessionStore[current]\nadd socket-to-room.socketStore\nfor(i in room.SocketStore){socket.emit('room.socketStore[i],'X joined into room)}\n})\nThis a event managed response model. I don't like room,user id in connecting procedure=>require create dinamicaly socket event like:\nThis idea is worked?:\nclient:\nsocket.on('connect'){\n  socket.emit('auth',{roomId:roomId,userId:userId,another:...}\n}\nsocke.on('new-message',function(o){ console.log(o});\nserver:\nsocket.on('connection',function(data)){\n    if (auth==1){\n        eval = 'socket.on(data.roomId+'-message,function(d){\n                       socket.emit('new-message',{user:redisData.UserNick,msg:d.msg};\n                  });';\n.......\n}\nHow can communicate single client without storing all socket in global database?\neg.: kick-off one client, send private JSONP...etc.\nOwer this idea require all event grouping and creating one Dedicated-event. If inited 100 room, create roomid-join, roomid-leave, roomid-message,roomid-action...etc at 100 times ca 400-1000 event subscribe to socket. This not owerloading socketCluster?\nAnd if room closed (destroy) how can destroying dinamicaly created socket event?\n. Howto use store?\nThis a store model to workers?\nIf store use inside from worker as global store object, this is good to me, i use this to storing main datas.\n. Thanks!\nHow work the StoreController? In sapmle is empty and I not understand what is this function.\nHow can I integrate ndata, i try using a global membased store?\neg.: ndata initializing in store controller and accessing to each worker or other?\n. Hi!\nI look this legend...  The MD is very minimalistic and have many more feathures in SC than writed hier in docu. Can you publish a API documentation? I help lovely if like You.\nEg.: What a differ on socket.emit / socket.publish / socket.send or global data access model...etc.\n. Thanks!\nI don't refresh cosketcluster-client, only server. Working good after refreshing completed.\n. Try this, not resolve the problem is stable on.\nThis procedure workflow: client socket.emit() send data to server. The receiver is collate control command and generate one socket message. Publish this to redis pub/sub and redis triggering the socket.emit. \nIdea: Redis-SC have incompatibile?\nIf I uncomment redis pub/sub mechanism, the SC is not disconnect.\n. I try... \nThe message wall is working good. Client send message over socket as new-message named event. Put this on server side to redis publish and redis triggering emit to seockets. The sender and all others receive the message, work good.\nThe command event is triggered, freezing the socket. Procedure and functions is eq. the message workflow... I don't understand....wher is a problem.\nAll socket sent event is backlog the client Event response timeout. I testing in loaclhost, common machine.\n. Thanks!\nThis resolve the response-timeout:\nsocket.on('ping', function (data, res) {\n  // This explicitly sends back an ACK to let the client know\n  // that this event has been triggered sucessfully.\n  // You can pass any data back to the client\n  res.end('Success');\n});\n. How mutch the socket event parsing timeout?\nThe testing: Two client in room in different browser. The moderator send kickOut event to channel signed clientId. The client receive this, and JS detect signo, show an JS Alert box -> you kicked out...\nIf I refer this, clicking Ok the alert at fast, the client is stable.\nOther clicking slow (many sec), after clicking, the client is lost socket, leave, destroy session and reconnect.\nThe problem in socket.on(){} parsing time. Howto fixing,controlling this?\n. In client and server send ACK res.end() all event.\nClient:\nsocket.emit('new-action',object,function(err,data){if (err)console.log('SC Error:'+err);} );\nServer:\nsocket.on('new-action',function(data,res){\n                                            res.end('Success');\n                                            try{.... parsing hier, put publish message to redis....\nServer:\nredis publish:  current.socket.emit(channel, message,function(err){if (err)console.log('SCM err:'+err)});\nClient:\nsocket.on('events-'+roomId,function(msg,res){\n        res.end();\n        console.debug('Socket Received:'+msg);\n....... parsing MSG hier...\nThe ACK is good after sending manualy.\nThe socket lost detecting if open many client in one browser(common IP) or separate browser socket.on() function parsing big timeeg.: js alert,confirm dialog.  The ACK is sent before get starting even parse mechanism.\n. The res.end() is always send in first command in function.\nsocket.on(,,function(res){\nres.end();\n... more code hier\n}\n. I use currently SC 0.9.53\n. I try on weekend...\n. I update latest SC and try, problem is stable. \nThis is a reproduce:\nOpen chat as moderator in FF and connect to this in new FF private window as attendee. IP is common, localhost, worker is common w2 (started3 worker,1balancer), sessions is defferent.\nIf moderator client send kick-out (event send all on dedicated pub/sub, parsing localing on client side), the received - and ID eq client is generate js Alert. The SC connection is lost on client on awaiting alert box clicking. In communication schema send common dedicated event to client and use action:message/control field.\nClient code:\nsocket.on('events-'+roomId,function(msg,res){\n        res.end();\n        console.debug('Socket Received:'+msg);\n............\n        switch (action) {\n            case 'message':{....\n target.html(''+ message.msg+''+message.userNick+' '+(new Date()).toDateString(\"HH:mm:ss\")+'');\n            }break;\n            case 'control':{\n                switch(actionSub){\n                     ..............\n                     case 'kickOut':{\n                        if (userId == message.subClientId){\n                            console.log('I kicked out');\n                            alert('You are kicked out from this room!');\n                        }\n                    }break;\n             }\n}\nEvents flow on control:message is working good, not a lost SC.\nIf control on action, the js alert() is stop the js on backend and losing SC.\nIf cut of alert(), SC not losing. \nJs alert() is block any js running? Howto work alert(),confirm() on this problem.... js is asyncron run. The alert is not a blocked function eg.:confirm is blocking running awaiting confirmation return. \nHowto fixing this from Socket? Socket is why lost connection?\n. Ok, awaiting...\nQuestoin: The std. Room feathures is resolve external pub/sub channel, its good. The broadcasting is  selectable only-current-socket/session-sockets(eg. more tab common session)/ROOM-sockets(all worker)/all-sockets(in common worker)/all-socket(all-worker) is available?\nAnd req. a plus feathures: Storing and accessing one globaly Room() object, acces this in all worker, accessing only subscribed Room obj. eg.: room{customClientId:global-socket-id}. Tipycal chat application is require moderated user management eg.: kick-out renitent user. If moderator send kick-out user as customId, on backend find this in Room obj, send kick-out to client and destroy client session+socket and ban IP...etc.\n. \"Sorry I didn't understand the first question.\"\nI becommt response on socket.io, thanks.\n. I try this:\nscServer.addMiddleware(scServer.MIDDLEWARE_HANDSHAKE, function (req, next) {\n req.session.get('isUserAuthorized', function (err, value) {\n    if (value) {\n    next();\n    } else {\n      next('Session ' + req.session.id + ' was not authorized');\n    }\n  });\n });\nscServer.on('connection', function (socket) {\n        // Emit a 'greet' event on the current socket with value 'hello world'\n        socket.emit('greet', 'hello world');\n```\n    /\n        Store that socket's session for later use.\n        We will emit events on it later - Those events will \n        affect all sockets which belong to that session.\n    /\n    activeSessions[socket.session.id] = socket.session;\n    socket.session.set('isUserAuthorized', true, callback);\n});\n```\nreq.session is always undefined.\nThe handshake called before socket.connected. If req.session is set and true, client is authorize the previous connection method, not require authorization again.\nreq.session is unavailable always and I don't understand why.\n. Yes, I use now a simultan authentication handshake on connection->auth->greeting mechanism.\n. Thanks, look and try again today.\nI don't use correctly the socketId and sessionId ... sorry.\nThe documentation is very symple. The SC details depth is not enough. Many small feathure is not publicable.\neg.: client/session side Id-s parsing, or emit callbacks err, res, res.end... socket.functions ...etc.\nI don'know what a functions available on SC specific and socket standards...etc.\nAnd the documentation is pretty inaccurate.\n. Interrest/problem?\nClient connected to SC, ok. If SC is broken/lost data (eg. restarting SC) the client sending event is halt. If SC is available again, client try reconnecting. SC is logging out Handshake, MidEmit parsing->next(). In this point SC is not called .on(connection) and not calling on('connection'){on('auth')}. WHY?\nIn reconnection, the client is receive on('connect') event (server not call on('connection') ) and try emiting emit('auth'),data,function(err,res)) .\nerr: Error: Event response for 'auth' timed out\nI don't understand, if reconnection is ok, detected client, the server is not...\nI try this simulate network error (iptables block/ublock port) the reconnection is good, SC call on(connection) and parsing main auth event. Full good flow, problem detect only SC restarting.\n. I update SC completly latest. Timeout problem source is a client error parsing mechanism.\nIf don't send res.ed the SC manually, client is drop error.\nClient:\nself.socket.emit('ping',self.commObj,function(err){\n                           if (err){\n                               console.log('Emit error:'+err);\n                               if (err.err == 'unauthorizedSession'){\n                                   self.socket     = socketCluster.connect();\n                               }\n                           }\n                       });\nI modify SC to:\nsocket.on('ping', function (data,req) {\n            req.end();\n            count++;\n            log.debug('PING'+JSON.stringify(data));\n            scServer.global.publish('pong', count);\n        });\nAnd req.end() sending is resolve this problem.\nI look upgrade doc, good work, thanks!\n. Thanks, monitoring using monitor plugin, I don't write main.\nAnd how can flow clients as realtime?\nClients is connect several worker,I don't known create simple filtered query, getting clients sum.\nCreate and parse all connect/disconnect event to write a memory data (nData,Redis), or have a listening method (eg: scServer.global.channel(ch).getChannelInfo(function(channelsObject){ for (i in channelObjects) {\n channelObjects[i].SID,channelObjects[i].SSID,channelObjects[i].IP\n}\n}))\n?\n. ",
    "pandafinity": "Hi :)\nI think your module is exactly what I am looking for and I am excited to see how far I can take it. Going to try getting things working before I venture towards Redis in the middle. \nI've got my site up and running with SocketCluster - using Express 4, RequireJS (loading the socketcluster.js file - I think) and Famo.us as the front-end.  \nI wanted to ask you about Namespaces and how I would create them with your approach.  Basically I am looking for a way to distinguish between different 'users' logging in (or guests) and having a 'multi-tenant' approach.  I'm looking for at least 4 separate 'socket' connections per user as I have 4 different types of data I want to send to a user in real-time.\nReally appreciate your thoughts :)\n. Thanks for the tips on making my own naming conventions...\nBut What if I wanted 1 socket to send textual data such as information and status updates and 1 socket to stream binary data?\n. Will try that now - thanks.\nWhat snippet?\n. Thank you that solved - such a little thing annoyed me for hours :) thank you.\nIf by the 'snippet' you mean code, it was something I wrote\n. (with bits of your 'sc-sample-inventory' thrown in as wanted to see how you added modules and data to the server)\nThanks :)\n. Thanks for digging deeper, knowing the states does help.\nI will try and see if I can make an async Handshake function, as I would like all my other SC communication to be done once a valid handshake has been accepted.\n. ",
    "ghost": "+1 for the event naming convention.\n. Perfect!\n. Thanks for the tip for the next method with parameters.\nThe middleware example provided can't be used because in my case 1 username can have multiple events.\nI try to achieve this: sending to all clients except sender:\n// Example from socket.io\n socket.broadcast.emit('message', \"this is a test\");\n. Ok\n. Hello,\nNo it's not related to cross-domain issues.\nMy production server has 2-3 CPU's (tiny).\nIf I run the stage server (with a bug) along side the production server, I'm afraid of the stage server script keep rebooting the workers or worst he crash the production workers...\n. Great :+1: \n. Perfect!\n. ```\n// server.js\nsocketCluster.on('fail', function(error)\n{\n console.log(error);\n});\n// worker.js\nworker.on('error', function(error)\n{\n console.log(error);\n});\n```\n. Sending a SIGUSR2 to the master PID suits me perfectly.\nThanks for digging in.\n. ## - i found solution: \n-  var scServer = socketClusterServer.attach(server);\n-  var clients=scServer.clients;\n-  var specific_client=clients['socket-id'];\n-        specific_client.emit(\"event-name\",{});\n. @jondubois  Thank you for your fast reply.\nBut i have one another problem can you help me there?\nin socket.io express session can easily access by socket.request.session \nbut what syntax for access express session  in socketCluster.\nplease help me on this issue,it is really important for me.\n. @jondubois  :: here is my code :::: \nsession set in express-session already --->  req.session.my_session {hello:'jondubois'};\n/socket cluster code (not working)/\n```\n var socketClusterServer = require('socketcluster-server');\n var io = socketClusterServer.attach(server);\n      io.on('connection', function(socket){\n            /Connect successfully/\n            console.log(socket.request.session);  //undefined where in regular http request it is accessible\n       });\n\n/In socket.io  sessionMiddleware (working)/\nvar session = require('express-session');\nvar RedisStore = require('connect-redis')(session),\nvar sessionMiddleware = session({store: new RedisStore({}),secret: \"jayesh\",db :true}),\nio.use(function(socket, next) {\n          sessionMiddleware(socket.request, socket.request.res, next);\n });\n```\nThis is my only major issue in my framework(based on express).\ni am  familiar with socket.io and novice user of socket cluster\nhow to pass sessionMiddleware in socketCluster like in socket.io above.\nplease help me to uncover bug..\n. @happilymarrieddad @jondubois thank you  guys.\n. @jondubois thank you for information.\n. When you start the worker\nworker.scServer.exchange.subscribe('channel')\nhttp://socketcluster.io/#!/docs/api-scworker\n. Is there any reason this issue remains open? The original question was well answered.. ",
    "samuelngs": "Haha I'm surprised that you wrote me long answer(s) with examples.\nYour answers have been so useful to me. (Socket.io team never answered my question)\nI really appreciated your help! hope you have a great day. :)\n. Hi Jondubois,\nI actually come up with another question. I'm now doing the client side socket subscription. I want to know that do I need to run another socket.on(channel, listenerFn) whenever there is a disconnection between the server and the user.\nHere is an example for this situation:\n1. the client side connected to the server side and subscribe a channel.\n2. the client network was down and disconnected with the server side\n3. the client network was up again and connected to the server side.\n4. ??\nFor the step 4, do I need to run socket.on(eventName, listenerFn) again? Or once I run it, it will reconnect and resubscribe the channel again after disconnection?\nSorry for my bad English. I hope you understand my question :)\nThanks.\n. And actually one thing more, is there a way that I can get cookie inside function\nsocketServer.addMiddleware(sockServer.MIDDLEWARE_SUBSCRIBE, function (socket, event, next) {\n      console.log(socket.request.headers.cookie);\n      // something like that?\n}\nI tried socket.request but it is undefined.\nThanks again.\nps. I just read your code at file scserver.js, I think the only way I can do this is adding \nsocket.cookies = headers.cookie at line 271.\nedit: I actually add code to scserver.js to read cookie. https://github.com/StoryairCommunications/socketcluster-server/blob/master/scserver.js\n. Maybe we can do\nvar cookie = this._parseCookie(headers.cookie);\nsocket.cookie = cookie;\nthen cookie can be read as an object, and I also added\nsocket.request = req;\nso if developer really wants to access the cookie string, he/she can use the socket.request.headers.cookie instead?\nOh yeah! I just did a pull request.\nThanks\n. ",
    "LuukvE": "Hi Jon,\nI knew it wasn't the right solution, but I was just puzzled, because the buffer created in the master process was not equal to the buffer created in the load balancer. The error message coming from Crypto was: \"Headers too long\".\nI have not tried the various other ways the protocolOptions object can be used, because I prefer having one (PFX) file, feels more organized. If no other solution can be found I might switch just for ease of installing the real socketcluster versus my changed version.\nI wish I had time to fix this myself, but I am on the clock and have a product to build. Thanks for creating socketcluster. I originally wanted to go with a distributed server system, with sharded database. And for true scalability I will eventually build it that way. But utilizing one powerful Amazon VM completely is simpler and probably cheaper.\nIn a couple weeks my team and I will be focussing on creating a monitoring system. If you're interested, I might be able to get you some statistics on socketclusters performance. Both in stress tests and production.\n. ",
    "davidchase": "@jondubois  I like the solution of SC using an existing server object, is it not a good idea to allow the server object to be passed in through the options when creating a new SocketCluster ? \n. Hmm, I will give it some thought (maybe using a hapi plugin/pack), I have looked into those alternatives but they are similar to express either built on or by same group and I really like what Hapi has to offer\n. ",
    "tilleps": "Actually, the ArrayBuffer seems to be being replaced by an empty object.  \njavascript\nsocket.send('example', {\n  name: \"test\",\n  data: ArrayBuffer\n});\nturns into:\njavascript\n{\n  name: \"test\",\n  data: {}\n}\nAnd:\njavascript\nsocket.send('example', ArrayBuffer);\nturns into:\njavascript\n{}\nI'm not sure how I missed the authorization section of the readme, but after having gone through it, I am getting an empty req.session in the wsServer.MIDDLEWARE_HANDSHAKE example.\njavascript\nscServer.addMiddleware(scServer.MIDDLEWARE_HANDSHAKE, function (req, next) {\n  req.session.get('isUserAuthorized', function (err, value) {\n    if (value) {\n      next();\n    } else {\n      next('Session ' + req.session.id + ' was not authorized');\n    }\n  });\n});\nIs socket.session.set('isUserAuthorized', true); intended to be placed on the connection event?  Seems that the MIDDLEWARE_HANDSHAKE runs before the connection event.\n. I am able to reproduce this by disabling cookies in the browser (Chrome/Firefox/Safari).\n. Reproduced the problem with SocketCluster version 2.3.14 and cookies disabled.  \nIt seems that the disabling of cookies also disables the usage of localStorage which is causing the interruption.\nOn Firefox, I get this error:\nSecurityError: The operation is insecure.  socketcluster.js line 40\n``` javascript\nAuthEngine.prototype.loadToken = function (name, callback) {\n  var token;\nif (global.localStorage) {\n    token = global.localStorage.getItem(name);\n  } else {\n    token = this._internalStorage[name] || null;\n  }\n  callback(null, token);\n};\n```\n. Here is one situation that can result in \"Socket hung up\":\n``` javascript\nscServer.addMiddleware(scServer.MIDDLEWARE_HANDSHAKE,\n  function (req, next) {\nnext();\n\n// Calling next() again can cause \"Socket hung up\"\nnext();\n\n}\n);\n```\n. ",
    "mafrost": "Thank you so much for the answer! It really helped. Great post as well! We've already started implementing and everything works good so far. Keep up the good work!\n. Oh how did I not see that! Thank you so much. Both of the solutions worked fine but as you said, the latter one (ndata) works just as good and I don't need to use mongo for sessions!\nThanks again, fast response and good explanations!\n. ",
    "soniagaonkar": "thanks a lot for your prompt reply :)\n. ",
    "zalmoxisus": "@jondubois, socket.clientAddress is not available anymore or it was intended to be used with the sticky loadbalancer? It's null while socket.request.headers['x-forwarded-for'] points to the remote IP address. I'm sending x-forwarded-for from nginx.\n. Thank you, @jondubois, for the details! socket.remoteAddress works for me even behind nginx proxy.\n. Just to notice that starting from version 5, socket.remoteAddress doesn't work anymore, but socket.request.headers['x-forwarded-for'] does the trick.\n. Also related: https://github.com/SocketCluster/socketcluster-client/issues/39.\nUsually you don't want to lose offline messages and want the ability to sync different clients (web and mobile app). So, a more universal solution is to use sc-crud-rethink and to insert messages in the database. It is easy to subscribe for new messages (new fields) there, and also can remove / edit messages. I'm still exploring this scenario.\n. @jondubois the fix doesn't affect uws which is by default? Can it be related with https://github.com/jhen0409/remote-redux-devtools-on-debugger/issues/15 and https://github.com/zalmoxisus/remote-redux-devtools/issues/50? The messages are also getting large there and the server is also on https as in the issue.\n. @jondubois, I wish I could reproduce and have more details, but it also works well for me, though I'm not running it much on React Native.\n. @ivopc you could also take a look at janus-gateway, which allows to write custom plugins. Specifically its websockets plugin and text chat pluggin could be rewritten to play nice with socketcluster.\n. ",
    "willeponken": "I think you're right by not decycling, as it wasn't really much work to implement on my part, and it also gives me the power to choose if I want to decycle or not. \nI don't know about the error though. If you're running production and this problem arises it wouldn't really be a problem because the worker will restart anyway, and the developer would probably notice. On the other hand, if you're only running one worker, there would be a problem, but why would you use Socketcluster anyways?\nMy conclusion would be, go with the current solution. :smiley: \n. @MegaGM Your solution worked great.\nThanks @jondubois for such a fast response and fix, going with your solution of course, Socketcluster works great!\n. It's a good idea to use a process manager. \nSocketCluster should take care of the workers and load balancers, but if the master crashes there's nothing that will restart it. \nI'm not a developer of SC, so I could however be wrong about something.\n. ",
    "MegaGM": "@willeponken I don't use PassportJS but after https://github.com/TopCloud/socketcluster/commit/59412c0e977f642cd4ade9455b11a4b9c391b82e v0.9.75 I encountered with same issue. In my case, I didn't wanted to use Socketcluster's sessions in \"Express part\" of my application at all. And I also use Redis for storing sessions.\nSo, I just added a middleware which deletes req.session right before including a session-middleware\nIn the worker.js\n``` javascript\n    / ---------------------------------------------\n    * That's it!\n    * ---------------------------------------------/\n    app.use(function(req, res, next) {\n        delete req.session;\n        next();\n    });\n/* ---------------------------------------------\n* Now req.session doesn't exist, usual Express session-middlewares works as expected\n* ---------------------------------------------*/\nvar sessOptions = config.get('options.sess');\nsessOptions.store = new redisStore({\n    host: config.get('redis.host'),\n    prefix: config.get ..... etc\n});\n\napp.use(sessions(sessOptions));\n\n```\n. @joinfok Apparently you just forgot to add some words in your function\njs\n$('#users-list').on('click','.action>a',function(){\n  event.preventDefault();\n  ...\n. Do you execute res.end('a response data'); in your handler for the 'new-action' event? The handler is probably somewhere inside of\njs\nself.handleConnection(socket);\nres.end() or res.error() it's the right way to pass the data into your callback on the client side from the server side.\n@jondubois wrote me earlier an example, it works just great for me. (btw I'm also using Redis along to SocketCluster, there is no issues with it)\n``` js\n// Client\nsocket.emit('ping', 123, function (err, data) {\n  // Here data will be 'Success' if successful\n});\n```\n``` js\n// Server\nsocket.on('ping', function (data, res) {\n  // This explicitly sends back an ACK to let the client know\n  // that this event has been triggered sucessfully.\n  // You can pass any data back to the client\n  res.end('Success');\n});\n```\n. Maybe it isn't a direct answer.\nMIDDLEWARE_HANDSHAKE is generally used to decide whether or not allow a user to connect to SC, but not for authentication/authorization as such. If I understand all that stuff correctly :smile: \nHowever you can use it as you wish, obviously.\nI hope this small chunk of client-side code makes sense for you\njs\nsocket.on('connect', function () {\n  socket.emit('auth', authData, function (err, data) {\n      if (data.customData) {\n          socket.subscribe...etc\n      }\n  };\n});\n* I assume that all checks are implemented inside MIDDLEWARE_SUBSCRIBE\n. > How do you feel about this new style compared to old way?\nGreat! ^_^\n. I'd also ask @jondubois about client->client emitting. Could you clarify please how it works? Whether any middlewares are effective?\n. Thank you a lot for clarification!\n. When SC was ~0.9.82, I was just using Redis pub/sub. It's straightforward and quite efficient way.\nNow I've planned to make another app with SC power, and I wonder is there a more nifty way to implement such functionality?\nping @jondubois \n. Btw it's fairly popular question, I'm not sure but maybe it will be fine to have an example in docs \n. > how could worker1 know how many other workers are available and still in a \"running\" state in real time ?\n\nhow long should worker1 wait for a response from all other workers before deciding that all other workers have already responded ?\n\nNooo, it's a bad design. Workers should not know about other workers at all.\nEach worker should be totally independent.\nAll workers should handle only data, that they able to reach inside themselves.\nWorkers are your ~~slaves~~ workers! You should never ask them something.\nYou should only give them orders and directions.\n\nRIGHT WAY\nGive directions to workers:\n1. When you encounter a message \"kick all, who under 18 years old\" from the client-side => say to Redis \"kick all under 18\"\n2. When you encounter a message \"kick all under 18\" from Redis => kick all users that you know, that are less than 18 years old\nAnd each worker should check whether inside of it there is such users, then kick them if there is.\n\nWRONG WAY\nGive directions to workers:\n1. If somebody asks you \"are there another users under 18?\" => search such users inside yourself, and give back an answer\n2. When you encounter a message \"kick all, who under 18 years old\" from the client-side => search such users inside yourself, then additionally ask all other workers via Redis, \"are there another users under 18?\", and wait \"SOME TIME\" for answers\n3. Kick all users that you know, that are less than 18 years old, and kick all users that other workers told you\nNope, nope, no. ^^^^^^^^ It's a bad design.\n\nIf in your application there is some type of data that must be available in all workers - go ahead and store it somewhere else, really.\n1. Do you need persistent sessions in your app? Store them in a database (Redis? :3)\n2. Do you need messages in your app? Store them in a database (Redis? :3)\n3. You want to notify users when a new message comes?\n   1. A worker got a message from the client-side, and put it in a database.\n   2. The worker talks a special phrase with necessary data to Redis channel \"hey workers, there is a new message, please notify to all\".\n   3. All workers always are waiting for special phrases and always can handle it. Even if they were born just right now, and they are interacting with no clients yet, it shouldn't matter.\n   4. Last but not least, that \"array of users\"(probably not an array but an object) contains not users, but socket sessions. Of course workers should add them/remove them properly. And if you need more data in future to filter who can receive messages, put the data inside socket session at this step. \n\nLet's say, your client opened 1 or 3 or 30 tabs in a browser. If I remember correct, them all should be attached to the same worker and all that 30 sockets objects should share the same socket session. If another client open another browser then all those tabs also should share another one session, it doesn't matter how many tabs opened there.\nSo, what to do when the special phrase has come into a worker? Loop thru all collected socket session and emit another special phrase \"hey client, a new message has been received\". This message will be delivered to all of those 30 tabs.\nLet's say you want to implement a feature like \"mark as read\". When you hit a button \"mark as read\" 3(i,ii,iii,iv) are repeated.\nOr if you make really big app, each of tabs, when gets a message, has to store info about the message into LocalStorage, and listen to window.addEventListener('storage', ... ), and when you press the button, instead of  31 interactions (1: \"hey server, mark this as read\", 2-31: \"hey client, this was marked as read by you somewhere else\") there will be only 1.\nAnd so on...\nOh, sorry :\\D Now, finally the time to give an answer to your question \n1. Store any data that should be reached in all workers in a database.\n2. Populate often used necessarily data from the database to socket session (on 'connection' event). \n3. If there is necessarily, but rarely used data - query it from the database, when it needs, inside one worker, and pass to Redis for all workers, if you need the data in all workers :) \nI hope you get the point.\n\nAnd last one for today. I didn't work with SC bunch of time, so, maybe now there is a better way to organize workflow ;D\nThank you for reading, but it all needs to be confirmed by @jondubois \n. OMG, the page was opened ~5 hours, while I was working, and when I've come back to this tab, to finish the reply, I didn't noticed Jonathan's message. I'm so ashamed :'(\n. @jondubois wrote:\n\n'Right way' vs 'Wrong way' - Can I use this idea for a new documentation page to add to the website?\n\nOf course! I guess this kind of comparison will help people to understand all better.\n\n@seme1 wrote:\n\nI spent too much time trying to figure out the best strategy for avoiding the problem that may arise when one of the workers crashes.\n\nOkay, I'll try to help you.\nIf I understand you correct, in your application you wanna grant users an ability to be LoggedIn from several devices simultaneously.\nWe have already something like that:\n\nUser entity (entity or model or table in db, doesn't matter how to call it, right?)\nSession entity\nOne-to-many relation between User->Session\nA bunch of pivot tables, because you use MySQL. It's okay.\n\nOkay, now we should create another table, to track sessions' online.\n| online |\n| --- |\n| sessionId |\n| userId |\n| workerPID |\nGo ahead and imagine what our workers should do.\nWhenever a user does \"SignIn\":\n\nChange something in User and Session entities (e.g User.online = 1 etc)\nAdd relation between User and Session\nAdd a new record into online\n\nNow we able to perform queries like get all online users or get all online sessions or even get all online sessions by workerPID. Aha, sounds good but we still have a big problem.\n@seme1 wrote:\n\nthe problem that may arise when one of the workers crashes.\n\nFor finding out a solution, let's imagine what happens whenever a worker does \"oh noo I'm died..\"?\nRight! A new worker is borning. So, it's the right moment to us to clear online table from users, that actually is not online anymore, cuz previous worker has died. What our slave should do?\nWhenever a worker is died and/or a new one is started:\n\nAsk a mysterious Master process \"Hello, my Master! Give me, please, PIDs of all workers\"\nSelect all rows in the online table, that have unknown workerPID. (let's call it dirtyOnline)\nDo some additional logic, you know what you want. Just for instance: for each user in dirtyOnline check whether he has another online sessions, if no then change User.online = 0 etc\nFinally delete all dirtyOnline rows\n\nThis approach will also clear entire online table when you perform cold start your application.\nAnd get all online session where userId X it's probably a good answer to your question:\n\nWhat I'm trying to achieve is to update a backend MySQL database with the number of LIVE socket sessions each user has.\n\nOkay, now it's sounds good. Good enough? Actually no, I never ever tested it, and probably never will.\n\nBut as I see you wanna change your application. And it's good decision. Let's say now we create two SC channels online_users and online_anons.\nWhat's now?\nWhenever a user does \"SignIn\":\n\nUnsubscribe user from online_anons\nSubscribe user for online_users\nPerform additional logic, you know, something like \"Add relation between User and Session\"\n\nWhenever a worker is died and/or a new one is started:\n\nNothing\n\nBut now we have even more questions. And those questions for @jondubois \nI'll make another issue with list of those questions soon. @seme1 some of those will be related to your issue, please be free to add there something.\n. #### Channel entity on the server-side\nIn the examples I assume that we already have executed\nvar channel = something.channels['channel_name'];\nsomething == it might be socket.global or something else.\n\nchannel.getSubscribers()\nServer. Retrieves: an array of sockets.\nAll of us sometimes wanna know, who's subscribed on a specific channel. Sometimes it's even necessarily.\ne.g. As in https://github.com/TopCloud/socketcluster/issues/44 we just have to know who's in 'online_users' channel.\ne.g. Sometimes we just wanna do something with clients that are in specific channel without ping-pong interacting them.\ne.g. In many new apps we wanna show a live list of all clients that are on a page right now.\ne.g. Silently ban all clients that are in channel \"we_hate_nodejs\" \n\nchannel.subscribe(socket object || socket.id || socket.ssid)\nServer. Retrieves: maybe true || false, but I guess it should retrieves nothing.\nForcibly subscribe a socket to a channel on the server-side, avoiding middlewares.\ne.g. When a user is loggedIn, unsubscribe from 'online_anons' then subscribe to 'online_users'.\n\nchannel.unsubscribe(socket object || socket.id || socket.ssid || undefined)\nor possibly\nchannel.kickOut(socket object || socket.id || socket.ssid || undefined)\nbut the former looks better for me personally\nServer. Retrieves: maybe true || false, but I guess it should retrieves nothing.\nForcibly unsubscribe a socket from a channel on the server-side or all sockets if we pass no arguments.\nI know we have socket.kickOut() it's similar but it isn't the same.\ne.g. When a user is loggedIn, unsubscribe from 'online_anons' then subscribe to 'online_users'.\n\nsocket.subscriptions()\nServer and client both.\nTo get all channels the socket is successfully subscribed for. Actually it's really handy-dandy feature.\nOn the client-side if we have, let's say, a chat. List of rooms, in which user is. Via this method it is really simple, thank you!\nFor the client-side this method already exists and has a good description in the docs.\nBut what about server-side?\ne.g. Haha, just imagine that we are addicts and we wanna iterate over the list of channels and find there a channel with name 'uid_' + id \n\nAnd I just wanna say it, just because, that things like\nchannel.publish()\nServer.\nReally is not needed. SocketCluster has such handy-dandy implementation of socket.global.publish() already, I like it! I find it multiple times better than emitting events on channel directly. I hope the rest of people also find it such useful.\n. ### Server-side suggestions\nWhat's now\nsocket.on('ping', function (data, res) {\n  // ...\n  if (success) {\n    res.end('Success'); // Send back success\n  } else {\n    res.error('Error message'); // Send back error\n  }\n});\nWhat's proposed\nCombine res.end() and res.error(err) to callback(err, data).\nsocket.on('ping', function (data, callback) {\n  // ...\n  if (success) {\n    callback(null, 'Success data'); // Send back success\n  } else {\n    callback('Error message'); // Send back error\n  }\n});\n\nClient-side suggestions\nWhat's now\nsocket.on('ping', function (data, res) {\n  // ...\n  if (success) {\n    res.end('Success'); // Send back success\n  } else {\n    res.error('Error message'); // Send back error\n  }\n});\nWhat's proposed\nCombine res.end() and res.error(err) to callback(err, data).\nsocket.on('ping', function (data, callback) {\n  // ...\n  if (success) {\n    callback(null, 'Success data'); // Send back success\n  } else {\n    callback('Error message'); // Send back error\n  }\n});\n\nThis form of callbacks it's exactly that, that most of Node.js/io.js developers are expecting to see, I'm sure. You know, it's a standard de-fakto.\nAlso callback() is the same as callback(null) or callback(undefined)\nI know, Jonathan, you know, but it just for clarify, for all of those who'll read this.\n. >  to send back a message/data on success too\nWe able to send data too? Not just an ack? Great! I've updated the callbacks in the examples.\n. > This can be tricky because no single worker knows about every socket - Also, what if you're scaling SC horizontally across multiple machines - The socket might be on a different machine\nI realized, it's really tricky, and apparently anti-pattern. So, instead of getting all sockets from certain channel and deal with them directly, let's assume that we could setup a listener for an event for the channel, just like on the client-side, but slightly different.\nYou said\n\nno single worker knows about every socket\n\nbut it means each worker knows about sockets that is inside, right?\nBasically what I mean by adding a channel entity on the server side: we need to fire events for all sockets in certain channel but without sending them any data to client-side.\nToday, when I was playing with a cat, I thought we could add a new middleware for 'getting messages', something like MIDDLEWARE_RECIEVE, for filtering listeners, to determine somehow server-side listeners. But now I guess it'll be too much expensive. It'll be better not to iterate over all possibilities, but separate them initially. Omg, English is still so complicated for me >.< Better go ahead and imagine some examples.\nglobal.publish('watsay', {cat: 'meow'})\nAll listeners, that subscribed for 'watsay', across all workers, will get a message, and their .on('watsay') will be triggered, right? But we want to trigger 'watsay' for those sockets, who is subscribed for 'online_users' channel, even if they not subscribed for 'watsay' from client-side. They probably might be subscribed from server-side?\nglobal.channel('online_users').on('watsay', function (sockets, data) { ... })\nWhere sockets will be an array of socket objects that are subscribed for 'online_users' channel and belong to current worker. Inside handler we will be able to iterate thru related sockets and deal them something.\nAnd then emit as usual.\nglobal.channel('online_users').emit('watsay', {cat: 'meow'}, function () { ... })\nWhat do you think about this way?\n. > e.g. Sometimes we just wanna do something with clients that are in specific channel without ping-pong interacting them.\nIt will be possible with proposed approach.\n\ne.g. In many new apps we wanna show a live list of all clients that are on a page right now.\n\nBut it won't :( We need something else.\n. > No WebSocket fallback\nThough only ~85% users are able to use websockets, I'm sure it's a good decision. I do not want to interact with clients who still use IE8 at all. Who those people? I cannot even imagine who it is \n. SocketCluster definitely should have a bridge passport <=> socketcluster, or at least some examples or advices how to make it work with passport.\n. Any news? ^_^\n. I thought in SC2 it also should be the socket.cookie as it was in SC1\nConsider, please, if you're trying to access the socket object inside MIDDLEWARE_HANDSHAKE, there is no socket object yet. So it may contains in req as described here at the section Handshake  ( btw @jondubois, why wouldn't you make those sections' headers as clickable links? It's small but sometimes really useful feature )\nThough, I'm not sure about where exactly they are req.headers.cookie or req.cookie\n. https://github.com/SocketCluster/client-drivers. \"why the socket disconnected ,event handlers still worked\"\nBecause in SocketCluster it's your responsibility to decide whether you still need those handlers or not, I believe. What if a socket will be reconnected soon and you don't want to remove any handlers? There are many scenarios, when you would not want to remove handlers from client sockets just because they were disconnected.\nYour on exit handler on client side with those two socket.off('event'); lines seems correct to me, but FYI, there is another way to remove your handlers on disconnect. Typically it's not a good choise. But in your particular case, maybe it will be the one.\njs\nsocket.on('disconnect', function () {\n  socket.off('res');\n  socket.off('exit');\n});\n\"can not bind the event handler repeatedly\"\nI don't know why would you do that..\nAnyway, why not? Just .off that handler before binding it .on again. Is there any errors when you doing it that way?\nIf something is wrong, in order to get some clue what's going on, you may try to check \njs\nsocket.hasListeners('event'); // true or false\nsocket.listeners('event'); // get array of listeners if there is any or an empty array\np.s. \"socket.io this, socket.io that\" man, don't compare SocketCluster and Socket.io\nSocketCluster is at entirely different level than Socket.io\n\nSocket.IO - Enables real-time bidirectional event-based communication.\nSocketCluster - A scalable framework that is designed to scale both vertically across multiple CPU cores and horizontally across multiple machines/instances.\n\nIf you completely okay with Socket.io and you don't need features of scalability that SocketCluster proposes you, why wouldn't stop to use a sledgehammer to crack a nut?\nI am sorry, I wasn't able not to say this. :sweat_smile: \n. Whaaat? Sad news for me, I'm pretty sure I was not near my PC 3 hours ago. I'll deal with it somehow. \n. I hope it'll help you. If it won't, feel free to ask any questions.\nhttps://github.com/SocketCluster/socketcluster/issues/44\np.s. Instead of using Redis or another external tool, you can create some internal SC channels for server-side only, rest the same as in example with Redis.\np.p.s. The issue was discussed long ago and I haven't re-read it.\n. https://github.com/SocketCluster/socketcluster/issues/150\n. What version of Node.js do you use?\n. Nodemon and the zombie processes. I faced the same problem some time ago.\nAfter I examined code relative to the USERSIG2\nhttps://github.com/SocketCluster/socketcluster/blob/bd70b523fa610206f34f759a8aab7ec19b655b3e/index.js#L466\nI decided to set up the rebootOnSignal: false option. Now there are no zombie processes anymore. \nI consider this way as a workaround, since nodemon reloads all the processes, including master, but on my PC it takes about 500ms so I just don't care.\nThough I'm okay with the workaround, I'd like to know \"the right way\" of doing things anyway. @someone tell us please :3\n. The best option IMO is to get rid of the Async module at all.\nIt should be relatively easy to rewrite some code in the socketcluster-* repositories, since there are just a couple of places, where the Async module is required.\nI'd like to mention this issue in the Wishlist topic https://github.com/SocketCluster/socketcluster/issues/202\n. Above all, stability, I agree.\nNevertheless, one day, for the sake of posterity, all the code will be rewrited in ES2015 or maybe ES2030 :dancer: \nThat day we'll change the Async in favor to Promises or something else anyway.\nI'm patient and I'm looking forward for that day. \n. @happilymarrieddad You are programmer, right? You must know - no one will force you to update SC to a next major version, when it will be rewrited.\nFurthermore, I doubt it will be soon. Not in next two years, I guess. So, don't worry.\n. 1. One socket per connected client. Two opened tabs in a browser == 2 clients. The sockets quantity doesn't correlate with publishing at all.\n2. All channels are being created dynamically, when a first client subscribes to a channel. When the last, subscribed to the channel, client unsubscribes - the channel is being destroyed by SocketCluster automagically.\n3. All clients(sockets) are distributed ~equally between workers. The same goes for channels, they're distributed between brokers. In theory, you can work with 100kk clients simultaneously, if you have enough SocketCluster's clusters in your setup.\nAnyway, @Himansh-Tiwari, this is a bug tracker. So, please, close the issue.\nIf you want to understand SC workflow better, feel free to ask any questions in the SocketCluster's chat room. There are many people who could help you there. https://gitter.im/SocketCluster/socketcluster. @astutesoftware For chat usecase, instead of blocking publishing operations on the server side, you could simply hide the desired messages on the client side.\n1. request from the server and keep a list of ignored userIDs on the client side (store it in JWT)\n2. skip the step in your app logic, which adds a recieved message in Jane's UI. Or you can still add the messages to the chat UI, but wrap them with a \"spoiler tag\", with a title \"Blocked Message\", or so.\nThe complex logic in the middlewares, for finding out if a message should be blocked or not, will cost you much more CPU (and headache), than publishing the message and do with it whatever you want on the client side :wink: . Mr. Shashikant, could you show us the piece of code, via which you send the messages from your server-side app to the client-side app? \nProbably you use scServer.exchange.publish() there. Or socket.emit()\nOr something else?\n\nwhen someone sending me messages, I am receiving it multiple times\n\nIt may be because:\n1. All your workers(instead of 1) try to send the same messages at the same time.\n=to check: put something like \njs\nconsole.log('Worker PID: ' + process.pid + ' sends messages')\nwithin your worker.js file. Place it next to the yours \"sends messages to client\" chunk of code.\n\nYou send the messages somehow wrong.\n=to check: show us the code ^_^. @beingshashi We could continue the conversation in Gitter\nThen, if it's a bug, we'll post here some reports.. The easy way is to send the data from the external app directly to a MQTT or Redis cluster or whatever else brokers of your SocketCluster app are listening to. So, you don't have to connect the external app as a client to your SocketCluster server at all.\nIf the easy way doesn't fit you, feel free to join Gitter. Since you have redis already, you could subscribe sc-app to a channel in redis, then from external app publish to that channel the data.\nBut there is a better solution: https://github.com/SocketCluster/sc-redis\n. Let's find where secure option is being set (the line)\nThen track down all the abstractions until we get VanillaJS code (the line)\nNow we can see that essentially\njs\noptions = {\n  secure: global.location && location.protocol == 'https:'\n  // .....\n}\nSo, there is no default option. It depends. \nUnfortunately, in the docs we indeed have a simple, not entirely correct, explanation.\nsecure: Boolean - Defaults to false\n\n\n\nSomeone, please, be :1st_place_medal: and correct that <3\n@Louies89 what's your site protocol?. @Louies89 \njs\nglobal.location && location.protocol\nglobal in the context is window in a browser. So it's \njs\nwindow.location.protocol. somewhat similar https://github.com/SocketCluster/socketcluster/issues/371\n@HoplaGeiss tldr you can connect to your existing sc app using https://github.com/SocketCluster/client-drivers or even via external queues.. Do you run ALL the stuff on the same T2.Xlarge VPS?\nIf yes, then to get better results you, obviously, have to try to setup a real cluster, so add at least two VPS more, one for scc-broker, another one for your app (and a tiny VPS for scc-state ;) You'll get a big performance boost, probably. If you won't happy with the result, and you have free time, then read a couple of important notices:\n1. SocketCluster works well with unbelievable amount of channels, channels are cheap, but it has some limitations when it comes to high throughput of a single channel. Why? Mostly because of brokers' architecture.\n1. Brokers do shard channels among themself. So if you have 4 broker processes and only one channel to publish in tons of messages, then the only one broker, which is responsible for that particular channel, will work. The other brokers will be idle. If you wonder how SocketCluster determines which broker is responsible for a given channel name, you can check an example of the hashing algorithm at sc-hasher repository.\n1. Once you get tired of looking at hashing functions, you can split your BIG_CHANNEL (f.e: chat:room1377) to, let's say 2 middle_channels, chat:room1377/1 and chat:room1377/2 respectively. So now 2 of 4 brokers will work at the same time on the same VPS. However, it'll require you to change some parts of your app as well. I won't describe possible server-side changes here, but on the client-side you usually can just setup the same watcher for both channels.\n1. Still want more performance? You could try to add intentional delay between publishing/emitting underlying operations. You could setup something like classic setTimeout(func, rand(1-500ms)) in the MIDDLEWARE_PUBLISH_OUT for the purpose. Yes, in theory clients will get a message rand(1-500ms) later. However, in real world, the message might be delivered to all subscribers even faster than if you'd publish it without the intentional delay. And, at the same time, you avoid at least some of cpu spikes of your app. It's like black magic, just try to play with the delay.\n1. Still want better results of the tests? Notice that for stress testing you must have at least x3 more powerfull client-side VPS than server-side VPS. So to test one socketcluster app on 1x8CPU VPS, you need to run at least* 3x8CPU VPS with socketcluster-clients.\n1. Still want MOAR? You can use even custom codec engines for SocketCluster :D\n1. Last but not least, try to improve your app's codebase. JSON array you said? I'd consider it as a bad practice to publish as a payload something else beside Javascript objects. <- Strongly IMO.\nJust in case: don't forget to constantly look at cpu/io/etc of the stuff*, maybe you need more brokers, or scc-broker's, and less workers, or vice-versa. It's up to you to find the best balance for your app.\nthe stuff* - scc-state, scc-broker, your sc-app with many workers and brokers, etc\np.s. I'm looking forward to some improvements in your app, let us know if it'd get better *_*\np.s.s. Since the issue is not an issue of the SocketCluster itself, rather a question, don't you mind closing it and join us in SocketCluster Gitter chat room to continue the conversation?\n. @hardikamutech In the MIDDLEWARE_PUBLISH_OUT as well as in any other SocketCluster middleware, you have to call next() eventually. I was talking, essentially, about delaying the next() call. \nHere it is, a dead simple example \n```js\nfunction rand(from, to) {\n  return 123\n}\nscServer.addMiddleware(scServer.MIDDLEWARE_PUBLISH_OUT, function(req, next) {\n  setTimeout(function() {\n    next()\n  }, rand(1, 500))\n})\n```\nThen you call your scServer.exchange.publish() as usual. The middleware will do its job.. @hardikamutech I've found https://github.com/happilymarrieddad/sc-publish-out-queue/blob/master/index.js it allows you to specify \"how many messages will be published at a time\". Maybe you'll find it useful.\n. js\nSCC_STATE_SERVER_HOST='127.0.0.1' SOCKETCLUSTER_SERVER_PORT='8888' node server\nThe syntax is for *nix terminals(linux, mac). You have to find out how to setup environment variables in the terminal you use and rewrite the command. I guess you use cmd.exe. Fortunately I don't know how to struggle on Windows. So I cannot advice you something Windows-specific.\np.s. After ~1 min of googling, I guess you could use\ncmd\nset SCC_STATE_SERVER_HOST='127.0.0.1' && set SOCKETCLUSTER_SERVER_PORT='8888' && node server.js\nBtw you can see all environment variables via command set with no arguments.. I would advise you to try to avoid including business logic in the master process, where you call new SockeCluster({...}) The better place for your code is workerController. If a worker crashes, the master will respawn it automagically. And it's easier to scale horizontally.\nIf you MUST use Redis, then try to look at https://github.com/SocketCluster/sc-redis\nBasically, it publishes to Redis everything you try to publish from worker. When you socket.exchange.publish('channelName', payload), the broker, which is responsible for that particular channel, will publish the payload to the Redis channel with the channelName. So you can setup a listener for the channel even from a completely another app.\nWith the sc-redis all pubsub channels will be synchronized across all brokers which are connected to the same Redis-cluster. Or even single Redis instance(not recommended for scaling horizontally).\nHowever, that is not the best way to distribute data between hosts. You could simply setup SocketCluster cluster, which contains scc-state and scc-broker and your SocketCluster-based application, which connects to the scc-state via SCC_STATE_SERVER_HOST env variable. This is the recommended way. You can follow the guide https://github.com/SocketCluster/socketcluster/blob/master/scc-guide.md\nOnce you have a cluster, you'll be able to connect to it any SocketCluster-based application. So, in your case, you could put your code(which you wanted to put in a master process) inside the worker of another SocketCluster-based application, just create new. Then connect the new application to the same SCC_STATE_SERVER_HOST. That's it! Both SocketCluster-based applications now share all pubsub channels.\nBtw instead of creating new project, you can create a new workerController.js inside your existing project and switch the workerControllers on some condition like env variable.\nSo the workflow will be like:\n1. Nodes of type1 are performing some calculations, eg cronjobs, and socket.exchange.publish('channelName', payload) the results.\n2. Nodes of type2 are subscribed to the 'channelName' socket.exchange.subscribe('channelName') and get the payload.\nYou can add as much nodes of every type however you want, at any time, simply set the same SCC_STATE_SERVER_HOST variable for them.\n. Yes, it definitely should be fine.\nIf you want to leave you socketcluster-app w/o Redis, and connect to Redis on primary server only - simply require('socketcluster-client') inside all of your workers and connect them to the primary server.\nYou won't even need a cluster to do that. And you don't have to make a fullscale socketcluster application for the primary server. Just a simple socketcluster-server setup will be enough.\n. >  It seemed to me that sc is in a good position to do this\nWell, from my POV, if you get 50x errors from an upstream(SocketCluster), it seems impossible to do something about it on the upstream side, since it's probably is not running (yet or already). But you could intercept such errors in Nginx.\n\nCould you point me to a starting point in the code where something like\nthis could be implemented?\n\n@wmertens Look at the following Nginx directives:\nproxy_intercept_errors\nerror_page\nBy default if Nginx gets an error(non-20x) from an upstream server, it will send the error back to the client.\nUsing the directives you can tell Nginx to intercept, let's say, 50x errors from the upstream and do something about it. \nTo get started, you could read an article about setting up debugging server failover for you upstreams in Nginx config. https://www.nginx.com/blog/capturing-5xx-errors-debug-server/\n. @wmertens Lemme try to answer once again. From scratch.\n\nCan the behavior be changed\n\nYes.\n\nso that when there are no workers available, the request is held for a bit?\n\nNo. SocketCluster doesn't manage http requests in the way you apparently think it does. SC has no built-in load balancer(since socketcluster@2.0.0, iirc). Load balancing now is done by OS by default, or via cluster module if you choose cluster.SCHED_RR as the cluster schedulingPolicy.\nSo currently SC cannot \"hold\" a request while workers are being restarted. Neither can it accept any http requests.\nBecause SC master processes(in this context I mean scworkercluster.js + your server.js) don't listen for client connections at all.\nThe http servers are being instantiated, and the requests are being processed within the worker controllers(SCWorker + your worker.js), which are being restarted atm.\nThe master processes don't know and even should not know anything about the requests, otherwise vertical scaling would be extremely inefficient. So it goes.\n\nCould you point me to a starting point in the code where something like this could be implemented?\nproxy_intercept_errors\nerror_page  \n\nThe run() method in the worker.js. If you're using express, you could setup an error handler for the app.use(), although I doubt you need that.\n\nIt takes 7 seconds for a worker to start, short enough to just hold the request but too long to go unnoticed.\n\nIf you want something like \"zero downtime deployment\", you could just kill a worker per the 7 seconds... ...just kidding :stuck_out_tongue_winking_eye: let's do it ASAP.\nThere are at least two ways of achieving something like ZDD.\nEasy way:\nIn the example below, we won't kill all workers immediatelly(default behavior), but will respawn them one by one in a chain, like if we'd use async.eachSeries().\nCons:\nIf you have 6 workers, it will take 7 * 6 = 42 seconds to complete. It's not a big deal on its own, because for these 42 seconds you still will have running other 5 workers. However, you'll have to always keep in mind, that for those 42 seconds some of workers will be updated already and some not yet. This might be a source for unexpected issues. So if you've changed 50% of worker.js, it could be more safely to kill all workers at the same moment, as socketCluster.killWorkers() does.\nClients will be disconnected-reconnected at least one time. In the worst case amount of workers times, within the 42 seconds. You can decrease reconnection delay for clients(options.autoReconnectOptions), because there always will be some workers alive to connect to.\nPros:\nLess downtime, less non-200 responses. If you have a little cluster with just 2 socketcluster-nodes(aside from nodes with scc-state and scc-broker), you won't have such a big CPU/RAM/SSD/TCP spike because of outage of 50% of cluster. Because most of client will stay on the node which we're doing magic on. So the lag spike will be amount of workers times less.\nAs a bonus, if you messed up with app code, and your updated worker.js throws something, only one of all workers will be affected after sending SIGUSR2. The rest workers won't be restarted, because the first one is unable to start properly.\nserver.js:\n```javascript\nconst options = {\n  rebootOnSignal: false, // disable internal SIGUSR2 handler\n  rebootWorkerOnCrash: true,\n  // other options\n  workers: 6,\n  brokers: 1,\n  // ...\n}\nconst socketCluster = new SocketCluster(options)\n// and setup our own instead\nprocess.on('SIGUSR2', () => {\n  let i = 0\nconst killWorker = workerId => {\n    socketCluster.sendToWorker(workerId, { foo: 'bar' })\n  }\nconst killNext = () => {\n    if (i < options.workers) {\n      killWorker(i++)\n      socketCluster.once('workerStart', killNext)\n    } else\n      i = 0\n  }\n// kill worker with worker.id === 0\n  killWorker(i++)\n  // once worker 0 has been respawned, kill worker 1, etc\n  socketCluster.once('workerStart', killNext)\n})\n```\nworker.js:\n```javascript\nclass Worker extends SCWorker {\n  run() {\nthis.on('masterMessage', payload => {\n  if (payload.foo !== 'bar')\n    return\n\n  this.close(() => {\n    process.exit(0)\n  })\n\n  setTimeout(() => {\n    process.exit(1)\n  }, 10000)\n})\n\n}\n}\n```\nNow the most important. The example hasn't been tested. I run it locally, everything looks fine to me, but I didn't make any \"serious\" tests. So I do not recommend you to use the example on production :slightly_smiling_face:\nHard way:\nFork workerCluster controller.\ncluster shares socket handles among master and childs.\n(Re)spawn any piece of code which will have the handle.\nRewrite lifecycle of workers(not so much).\nDirectly communicate with other workers, and main SC master.\nListen for client connections on the same port which all workers do listen to.\nCons: the major one - you'll have to implement your own cluster.schedulingPolicy\nPros: unlimited possibilities.\nP.S. I still have a feeling like I got you wrong. Could you explain in more detail what exactly do you want to achieve?\n. I've looked at some new code, shouldn't there be 'updatedPubs' instead of 'active' or undefined? https://github.com/SocketCluster/scc-broker-client/blob/0069ea9ead2e119e3f204d0970718b2a6dc339ff/index.js#L165 I'm not sure though, it might be my imagination.. Of course we Shell! :sweat_smile: Don't know when though.. 1st question: it's up to you.\n\n@Tuccinator wrote: Each worker is subscribed to the same event so when it receives the publication, will it relay the information multiple times to each socket? Say there are 4 workers, will it publish to the same channel 4 times?\n\nIf you subscribe to the redis channel via a redis client inside each worker, then each worker will get the message from your non SocketCluster-backend. Then, if you'll scServer.exchange.publish() within listiners for the redis channel inside each of your 4 workers, the frontend clients will get the message 4 times. Although, if you'll loop through clients' sockets manually and call .emit(), the clients will get the message one time only. But, please, don't do that unless you're absolutely positive you must to.\nTo seamlessly integrate SocketCluster with Redis, you could use https://github.com/SocketCluster/sc-redis.\nThe execution flow could look like:\n- a client .emit() a command for a worker to start a job\n- the worker sends the command somehow(as you said via redis) to your non sc-backend, let's say pubClient.publish('myChannelForNonSCBackend', data)\n- the non sc-backend finishes the job and publishes the result in the desired channel (the one, to which the frontend clients are subscribed to) publish channelDesiderByClients 'o:{\"a\":123, \"b\":456}'\n- The message will then be delivered to each frontend client, which is subscribed to the channel, automagically across all workers. And, of course, the message will be sent once\nNotice that, in order to get picked by sc-redis, the message should be in a specific format. You can see some examples in ReadMe and in the source code https://github.com/SocketCluster/sc-redis/blob/master/index.js#L38-L43.\nOr it could also look like:\n- a client .emit() a command for a worker to start a job\n- the worker sends the command somehow to your non sc-backend, including requestedBy: worker.id\n- the non sc-backend finishes the job and publishes the result to a channel all workers are subscribed to. Don't forget to include the same worker.id as the requestedBy\n- the workers are checking if their id is equal to the requestedBy. If yes, then do some additional computations, then scServer.exchange.publish() to the channel desired by frontend clients\n- The message will then be delivered to each frontend client, which is subscribed to the channel, once only\nConsider, please, there might be better ways to resolve your issues, which I just don't know/don't remember.\n2nd question:\nA turnkey solution for the purpose is made already. https://github.com/SocketCluster/sc-stateless-presence\nIt enables you not only to know on both(server and client) sides, how many users are online overall, but how many users are online and subscribed to a specific channels, and more.\nSimpliest way to count overall online is to subscribe all the clients to a channel, with no intent to publish to the channel, just to track the clients online status.\nAnd since sc-stateless-presence is... stateless :) It means if a worker will crush, all the users of the worker will be marked as offline inside other workers as soon as presenceTimeout ms will expire.\n. If the client, which has opened 3 tabs, is authenticated and has username inside its authToken, then all 3 tabs will be counted as one user.\nHowever, on the server side you still can get individual sockets for the given username if you really have to, because all 3 tabs' sockets will be stored under the same username, you could see it at the line https://github.com/SocketCluster/sc-stateless-presence/blob/master/index.js#L88\npresence.workerSubscribers[channelName][username][socket.id] = socket\n\nwithin channels that have fewer than 100 concurrent subscribers\n\n100 - it is not a quite accurate number of subscribers sc-stateless-presence could work well with. TBH I'm not sure if it will be okay for 5k subscribers, but I'd definitely try. Probably you'd like to decrement presenceInterval. Because, by default, the plugin will publish an array of usernames, per each channel you're tracking for, once per 10 000 ms.\nIf you track presence in one channel only, which has 5k authenticated subscribers, then it means each frontend socket will get an array of 5k strings (usernames of clients who are in the channel now) each 10 seconds.\nIt's quite okay to have an array with 5k strings inside each of your workers' memory, but it might not be okay to send so much data so often. The array with 5k strings * 5k sockets, it's 25 000 000 usernames to send over the wires each 10 seconds. Just imagine a common username, let's say it has approximate length of 7 bytes. 25kk * 7 is more that 150MB/10s. That's not quite accurate as well, so irl you'd have to use at least +30MB/s more bandwidth to be able to use the sc-stateless-presence.\nTo reduce the load, you could set presenceInterval to let's say 60 000 ms. However, if a worker will crush, the other workers will identify the clients of the worker as offline only after the presenceTimeout, which is by default presenceInterval * 1.3. So the users of the dead worker will be marked as offline by other workers and frontend clients within 78 seconds time span, or so.\n. I'm just going to leave this here\nhttps://github.com/SocketCluster/sc-stateless-presence/issues/2\nhttps://github.com/SocketCluster/socketcluster/issues/334\nYou could combine sc-stateless-presence with https://github.com/happilymarrieddad/sc-publish-out-queue and with this feature https://github.com/SocketCluster/socketcluster/issues/334#issuecomment-349571106, to get better performance.. > Well I don't need the actual usernames, just the online count.\nNotice, that if you won't use usernames at all, you won't be able even to tell how much sockets are belong to authenticaded users, how much are unauthenticated, how much are actually clients which just have opened multiple tabs. So it's better to track them after all. Otherwise you could simply access scServer.clientsCount, to know how much users are currently connected to the particular worker.\n\nevery 200 milliseconds to 5k subs\n\nI'd advise you to split your BIG_CHANNEL into many little_channels. I'm just speculating, but if you'd split your 1x5k to 5x1k channels or even 10x500, you definitely will see a noticeable improvement in performance.\nI'd suggest you to read some related stuff:\na message and an issue\n\nBack to tracking online clients... Transmitting the big array of usernames each 10 secs - it's the bottleneck of the presence plugin anyway, so you could fork the sc-stateless-presence, or even make a PR :smile_cat:\nBasically you just don't want to send 5k usernames to each socket each 10 seconds. Better send them once instead, when a socket is (re)connecting. So you'd still have pretty much correct data about online/subscribed/authenticated clients. And, at the same time, you'll cut probably 90%+ of sc-stateless-presence's bandwidth usage.\nPlease, look at the important piece of code.\nEssentially you want to remove setInterval(), and execute almost the same code from setInterval's callback, inside a listener for either socket.on('connection') or socket.on('your-custom-event'). And you better use socket.emit() there, instead of .publish(), to send the info to a single socket only.\nYou would like to change presenceTimeout as well. And the way the client part of the plugin marks users as offline via a setInterval as well. And, apparently, something else. I could make the PR myself, but I'm not sure if it will be done soon enough.\njs\nthis.exchange.publish(presenceChannelName, {\n  type: 'ping',\n  timeout: this.presenceTimeout,\n  users: users\n});\nusers: users here is the array of 5k usernames.\n. @wanglong167 Do you want to disable builtin JWT authentication engine and use your own? If that's the case then read the entire #233 issue, and especially this https://github.com/SocketCluster/socketcluster/issues/233#issuecomment-254884626\nIf not, could you join Gitter chat room and clarify your question?\n. @Hirbod Sometimes you don't trust the clients, so you don't want to let them .publish() anything. In such setups the only one trusted publisher is your sc-based app. At the same time you still want to communicate with clients via .emit().\n. :point_up: @matetukacs message in the Gitter room June 5, 2018 6:01 PM\nI guess it's possible your issues are related. It's just an assumption though. I feel like you did try many things to find the culprit of the issue already. The only question that comes in mind - did you try to:\n1. redundantly log somewhere timestamps of every step that message goes through (yourClienSideJS, emit, middlewares, eventListeners, etc)\n2. analize the data, especially of the clients with 10s+ issues\nBetween which components the lag appears?\n. > PM2 shouldn't be used with socketcluster as far as I know.\nIt's totally fine to use SC with PM2. I do like to use PM2 (with SC and not only), because of it's simplistic way to deploy apps to VPS/VDS. Typically, when you use SC with PM2, you just don't use PM2 features for vertical scaling, The rest is good.\nAs well as much more else, it's up to you to decide who'll control the lifecycle of a SC-based app.\nYou're free to replace/remove sc-hot-reload https://github.com/SocketCluster/socketcluster/blob/master/sample/server.js#L76-L79\nConfigurate killMasterOnSignal, rebootOnSignal, and so on. \n\nHow can I listen to \"sendToMaster\" events?\n\nWorker, like if we were inside run() method:\njs\nthis.sendToMaster(payload, callback) // callback is optional\nMaster:\njs\nsocketCluster.on('workerMessage', (payload, callback) => {\n  console.info(`workerMessage: ${payload}`)\n  if (payload === 'banzai') {\n    socketCluster.killWorkers()\n    socketCluster.killBrokers()\n  }\n  callback && callback()\n})\np.s. 1. I didn't test these pieces of code, mb there is a typo or two :slightly_smiling_face:  2. forever is just fine too.. SocketCluster is designed with client-server architecture in mind.\nIt is possible and easy to\n\nmake an app that i can chat with just one friend no everyone that join to group\n\nHowever, when it comes to implementing pure P2P architecture, it is not possible with SC. Well, actually it is possible, but in some quite wretched way. P2P is quite different from client-server architecture after all.. I suggest you to read this article https://blog.baasil.io/socketcluster-design-patterns-for-chat-69e76a4b1966\nDon't forget to read the docs https://socketcluster.io/#!/docs\nThis is issue tracker for bugs. For simple questions, please use Gitter chat room https://gitter.im/SocketCluster/socketcluster. Privet!\n\nWhen im trying to get method of null or exception occurs\n\nCould you, please, elaborate how exactly do you do that?\nDo you have some custom JS code inside the broker process?\nOr do you require('sc-broker').exec(somethingThatProducesAnException)?\nAnd which broker, sc-broker or scc-broker?. I haven't been able to reproduce that.\nHow I tried?\n1. socketcluster create testapp\n2. I've added some code into the run() functions which are inside the broker.js and the worker.js\nBroker\njs\nthis.on('publish', (channel, payload) => {\n  console.info(1)\n  throw new Error('Error from BROKER.onpublish')\n  console.info(2) // this is for the sake of clarity\n})\nWorker\njs\nscServer.exchange.publish('sample', count, (err) => {\n  // err here - is the error we did throw from broker.on('publish', callback)\n  if (err)\n    console.info('3', err)\n})\nWhat did I see in my Terminal?\nsh\n1\n3 Error: Error from BROKER.onpublish\n      # StackTrace goes here, I've omitted it because it's long\n@dafivius How do you .publish()? From client-side? From server-side? Or, maybe, you don't publish explicitly, but use something like Redis adapter?\n. Yes. Essentually sc-uws is just a fork of the uws, with no python bindings and better errors :bowtie:. You get the error because there is indeed no socket with such socketID in the scServer.clients object on SC X. Since the UserB is connected to SC Y, it should be in the scServer.clients on SC Y. Although that is not related much to the information which should help you implement what you need.\nYou said you want to deliver a message from a socketcluster-node-1 to a specific user (client, socket) which is connected to another node, let's say socketcluster-node-2.. ### Essentially you want to deliver a message:\n1. From any part of your application\nserver-side JS, client-side JS, client-side with client written in any other language, external apps like Redis, AMQP, MQTT, etc.\n\nTo a specific user which might have multiple opened tabs, maybe uses a phone, a laptop and a PC at the same time. In other words, the user might be connected to multiple workers on the same node or on multiple nodes simultaneously.\n\nIf that's the case, you could let SocketCluster handle it for you. How?\n\nUser Bob which is connected to node-1, subscribes to a channel, let's say bob-private-channel.\nUser Alice, which is connected to node-2 via her phone, and to node-X via her laptop, subscribes to a channel alice-private-channel.\n\nThat's it! Now you can publish a message to Bob or to Alice from anywhere, where you have .publish() method.\njs\n// in a worker on socketcluster-node-1\nconst payload = {text: 'Hello Alice!'}\nscServer.exchange.publish('alice-private-channel', payload)\nIn this example the payload from a worker on node-1 will be automagically (via scc-broker-client and scc-broker) delivered to node-2 and node-X, and pointed to the exact same workers, which Alice is connected to. Hence her phone and laptop will get the payload accordingly, since they're both subscribed to the alice-private-channel. Just like that:\n```js\nsocket.subscribe('alice-private-channel').watch(handleDirectMessage)\nfunction handleDirectMessage(payload) {\n  console.info(payload.text) // => Hello Alice!\n}\n```\n\nWell, deeply thinking, strictly speaking, the payload won't be \"delivered to workers\". It'll be rather published to a channel and might be consumed by subscribers.\nYou definitely would like to read SocketCluster Design Patterns for Chat\nAnd, of course, the docs https://socketcluster.io/#!/docs\nFeel free to ask any questions in the Gitter chat room\n. > improve, separate emit/broadcast/v.v... as socket.io as done.\nIt's always great to improve SocketCluster! However, I didn't get what exactly did you mean by \"emit/broadcast/v.v\". @tangquoctuan Could you, please, explain a bit more in depth?\n\ndifficult to manage session between those node server\n\nYou could read those comments, I hope they will help you gain more knowledge and make better architecture decisions.\nhttps://github.com/SocketCluster/socketcluster/issues/425#issuecomment-395368250\nhttps://github.com/SocketCluster/socketcluster/issues/165#issue-142854829\n+Feel free to join the chat https://gitter.im/SocketCluster/socketcluster if you have any other questions :slightly_smiling_face:\nEDIT:\nIf you'll emit a message to a socket by the socket.id, and if the user will have multiple opened tabs, the message will arrive to the only one socket, and won't be delivered to the other tabs.\n. @mahdiyousofun This is a bug tracker. For casual questions, please, use the Gitter chat room.\n. @tarilo Long story short, it should be fixed in scc-state@6.1.0\nPlease, try to upgrade.\nP.S. the 6.1.0 has been released just today, and the latest version in npm is still 6.0.3, the 6.1.0 will be pushed sometime soon, please, hang on.. ",
    "nhatduong": "Thank you for the reply.\nI am using server E3 - 1230v3 8GB Ram. And I really did not know how to test the performance of socketclutser. please give me tools that you used to test the performance as published in your performance. If not bother you, the owner of socketcluster please send mail to nhatbg89@gmail.com tools test performance that you use.\nThank you very much, wish I could see myself socketcluster performance and conduct of its use as an official tool.\nSorry for my english .\n. thank you, I will be happy and boost confidence with socketClusterif you share with me what proved to be the performance of socketCluster. The monitoring, tracking specifications on my server, I can do it, but I'm having problems when deploying the emulator user connect to my server. \nexample, socket.io have option 'force new connection': true', to simulate virtual users connect to, and exactly as it is done from client with the following syntax:\nvar socket = io.connect ('http://192.168.1.249:8080', {'force new connection': true});\nPlease, please help me a solution for emulator users connect to socketCluster. I really was halted at this issue with socketCluster.\nThank you!\np/s: Sorry for my english .\n. ",
    "3rd-Eden": "My 2 cents on this issue:\nI'm assuming we're talking about simulating clients that are created in node here.. This is idea is horribly flawed and will give you incorrect numbers. All of those connected clients will upgrade to WebSockets so you're not testing how many users can connect to your server but how many WebSocket connections or upgrades it can handle. You should keep in mind that polling transports such as XHR polling take much resources then WebSockets. Some might be connecting shortly, some might connect longer. Some message more some message less. These are things that have an impact on your cluster. It's like testing a car by only revving the engine ;-)\n. ",
    "vmosyaykin": "For anyone who came here from google:\nIt seems that now you do need to pass a 'force new connection' option, specifically multiplex: false.\nSee here:\nhttps://github.com/SocketCluster/socketcluster-client/blob/master/socketcluster.js#L1171-L1180. ",
    "happilymarrieddad": "@jondubois What are you saying!!!! Windows is the best platform to run everything on. I'm offended by these allegations!!! =) Ah man, windows is terrible lol.\n. @damirci Hey man, our clients all subscribe to their own channel based on their id. You can then query data or whatever on the server and send the data back to them I guess. That being said, you can pass in a callback from any request client-side which is what will be called as the second argument on the server channel being listened to... if that makes sense...\n. You can also use htop which I find to be pretty useful. Another option is to use a small nodejs process to monitor CPU and memory usage using require('os'). If you are careful with how you write it, it will use less resources and you can get better metrics. You can write them to a file also if you need long term monitoring.\n. You can always run a redis server and just dynamically hook up instances as you scale up and down. I made a quick video that explains the connection if you are interested. Here is the link. \nWithout a loadbalancer:\nhttps://www.youtube.com/watch?v=swjwNsEGz9g&list=PLTxFJWe_410zNJJD0o8njNLv7HidG1CHq&index=18\nWith SC-Loadbalancer\nhttps://www.youtube.com/watch?v=zmCdIg7NNUg&list=PLTxFJWe_410zNJJD0o8njNLv7HidG1CHq&index=19\n. Another thing you can do is monitor the cpu usage of the instances using a channel to broadcast the cpu utilization with   require('os').cpus()  for each instance and then use something like hubot to spin up and spin down AWS servers based on load.. you'd have to find a good way to attach them to the load balancer but that shouldn't be too hard.\n. I'm not sure if this helps but one of our production servers has only 1 broker and it is handling a LOT of tasks (4 worker cores and 6 remote socketcluster-clients along with sometimes over 100 users accessing the system). Despite the number of tasks, the cpu never really goes above 2%. 1 broker should be enough I would think for almost any number of tasks. We are using AWS EC2 if that helps at all.\n. Is it possible to have an event that a client can \"publish\" to that will send an event to every other client except for the client the requested the event at the worker level?\n. How large is the object so we can test it? Btw, you can chunk the data or you can increase the timeout.\n. @ryanpager Are you using a database other than redis anywhere? Also, install htop and check what is using the CPU. That will give you the process id and the name of the processes that are eating up your CPU.\n. I've build a redis cluster module if anyone's interested. It's in my repositories.\n. @jayesh-sapkale  One of the things you can do is have each client connect to a channel associated with their id so that you can broadcast on that channel and it will only be intercepted by the client associated with that id. I hope that helps.\nvar socket_channel = socket.subscribe(socket,id)\nsocket_channel.watch(function(data) {\n    // Do something with the data\n})\nNot the best solution but it will at least get you closer.\n. @jfsimon  Hey man use the exchange from the worker. For example:\nvar broadcastChannel = worker.exchange.subscribe('broadcast');\nbroadcastChannel.watch(function(data) { // Do something with data })\n. @trzyrazyzero Hey man, in our app we have a general broadcast channel, a customer channel and a user channel. For example, we have maybe 100 customers with each customer having 100 users. If we need to emit to a specific user, we publish to that user's channel. If we need to publish to all of one customer's users then we publish on their customer channel and if we need a general publish we publish on the broadcast channel. I hope that helps!. Sorry man but that's hilarious lol\n. @jondubois is it possible to get promise support through emit and publish events? I'm not even sure if that is a possibility. I don't know enough about websockets in general. Also, I would love to help with the rewrite if possible. I've been getting into async await and Node 8. \nexample\nvar socket = socketCluster.connect({ promises:true })\nsocket.emit('GETMESOMEDATASERVER').then(data => console.log(data)).catch(err => console.log(err))\nsocket.subscribe('LISTENINGTODATA').watch().then(data => console.log(data)).catch(err => console.log(err))\nOr even better\nsocket.subscribe('LISTENINGTODATA').then(data => console.log(data)).catch(err => console.log(err)). I'm not sure if this helps, but I have an admin channel that all my servers listen to and when they receive a \"reboot\" command it calls the killworkers and killbrokers functions. I think the problem you are facing is those are functions and so they run async and the process.exit() is called right after which means the killing doesn't finish. I'm using redis and the brokers to handle it. I hope that makes sense. Let me know if you need more clarification and/or if this is a solution you are interested in. We have quite a large cluster and it works great for us. Thanks!\n. you can call subscribe from the socket object directly.\n// On some event\nsocket.subscribe('SOME_CHANNEL').watch((data) => {\n  // Handle data\n})\nYou can pass some auth in as well that gets sent down when the app first begins and then when players try to emit they don't have the auth and the request gets rejected. Don't show an error if there is no auth and they won't even know they are missing the auth. You can embed the auth in the app's js before you start with webpack pretty easily. Just make it part of your config before you build the JS and send it to the client.. I just tested as well and it worked great\n. this is the same error I've been getting on our staging server... I updated from 5.0.10 to 5.0.15 is all I've done.\n. @jondubois hey man now I'm getting this error\n\n. Two atoms are talking and one atom says, \"Hey man, I think I lost an electron\". The other atom says, \"Are you positive?\"...\n. That's it.. I quit. I'm rewriting everything in Perl...  =)\n. There are two guys drinking in the bar at the top of the two towers. One guy says, \"Hey man, check this out.\" He goes over to the window, opens it up, jumps out, fly's around, and then comes back inside unharmed. The other guys is blown away. He says, \"How did you do it?\" The first guy says, \"The wind between the towers will hold you up.\" The other guy says, \"I'm going to try it.\" He goes over to the window, opens it up, jumps out, and then falls and dies.\" The bartender looks at the first guy and says, \"Superman, you're a jerk when you're drunk.\"\n. is it possible to remove those few bad versions from NPM? Or at least set them as broken or something?\n. That makes sense. Thanks!!!!\n. Yea, how dare you create the best framework that I've ever encountered and make one mistake.. HOW DARE YOU JOHN! lol no worries man. We have a 3 step deployment process and nothing should ever get to production. Thanks!!!!!!\n. I can confirm it is working great! Thanks!\n. @jondubois hey man I think we can close this one.\n. The one on the left is working great and the one on the right, which by the way is a copy paste from the working one, keeps breaking my staging server lol.\n. well I rebuilt the server and now it works great.. no idea why.. thanks!\n. It's back again. This is a different case though. Now it seems to do it after the server has been running for maybe 3-4 days. I just reset it and it works great for 3-4 days and starts doing it again. It's not really that big of a deal because it's a staging server but it's still kind of annoying. @jondubois do you know why this may be happening? THanks\n. Ok, I'm pretty sure you are right about the leftover deployment. We're good now. Thanks!\n. We have one of our servers running everything except uws on 0.12 and windows server 2008.\n. We are using SC for production and would really appreciate some caution on rewrites lol. Our customers are extremely sensitive and a massive break could cost us a lot of money. Thanks!\n. @alexhultman is it possible to make that 16mb limit a parameter somewhere?\n. ++++ this!!!!\n. I was also thinking it might be nice to add broker and state manager (SCC) to the cli as well so you can easily spin up a clustered system. What do you think about that @jondubois ?. What is the recommended number of brokers... for example if I have 2 16 core machines running together in a cluster how many brokers should each one have? How many brokers in the scc-broker and how many in scc-state?. What about if you switch from redis to SCC?. I had to remove uws and then install uws to fix this on my \"New\" laptop.. @githubfreedcamp Hey man, we are using it in production and have been for over a year. We started on SC2 and are now on SC5 so I think we've had quite a bit of experience with it. It's stable, fast, and efficient. In my opinion, it's the best web framework out there and @jondubois is an awesome guy as well who always answers any questions I have quickly. I can't say enough good things about it. We have quite a few customers. For example, our main database is a 16 core AWS server that's always around 8%-10% load. We have scaling so it depends on the day. I'm not sure if that's the kind of load you are referring to. If it matters, here is our stack.\n1) Nginx\n2) REDIS - sub pub (moving to SCC soon. It wasn't around when we first set up our project.)\n3) Socketcluster for servers (we use socketcluster instances at each customer's site and they communicate data back and with the main instance) (basically we grab data from customers' data warehouses and share the data among customers)\n4) MySQL, MSSQL, Oracle 11.2g and 12.1g, DynamicsGP ... and a ton of other databases..\n5) VueJS for the font-end\n6) Express for the API (it's part of SC). @slidenerd We are using socketcluster-client. \n@githubfreedcamp I've migrated our project to Golang and Vue2. We are no longer using Socketcluster except for sub-pub which will eventually be replaced by Hyperledger's Event System. Thanks!. Hey Man, \nI'm not too sure what you're asking for but here is the documentation on client-side connections including error handling. \nhttp://socketcluster.io/#!/docs/api-scsocket-client\nhttps://github.com/SocketCluster/sc-errors/blob/master/index.js\nI would suggest doing something like\nsocket.on('error',err => {\n  // Do something amazing!\n})\nI hope this helps!. Have you tried listening for errors on the process like\nprocess.on('exit')\nprocess.on('error'). You can use\nsocket.on('disconnect',function() {\n     socket.destroy()\n    // Then call whatever function you want to reconnect and setup subscription\n})\n@jondubois  hey man what you do think about this solution.. if it can be called that?. @jodyhuang Can you please post your js client connection code please?. you need to add \ntarget: 'node',\nto the webpack file. @ArmorHerO Hey man, so the scc-broker is essentially what used to be sc-redis for communication between the servers. It's a 1 to many relationship in reference to scc-state. The scc-state server holds state between the servers and scc-broker handles the communication between the servers. I hope that makes sense.. @ArmorHerO Hey man, thanks so much for participating in the socketcluster community. If your issue is solved can you please close this issue. If not, what can I do to help you fix your issues? Thanks so much!. @shengis \n```\n// Cluster 1\nworker.subscribe('SOME_CHANNEL').watch(data => console.log(data))\n// Cluster 2\nworker.exchange.publish('SOME_CHANNEL',{ id:1 })\n```\nHope that makes sense.. @shengis you can publish from the broker as well. In SC5 the broker really shouldn't be doing anything other than backend sc stuff. Communication requests should be handled by the worker. @jondubois what do you think?. @shengis hey man if this solves your problem can you please close this issue? If not let me know what else I can do to help. Good luck!. @joyson-17 Hey man, that sounds like something you should use the db for. You could store messages in a \"queue\" table or something and then if a user logs in and there are messages in that table pop them off and broadcast them to that user. @jondubois What do you think?. @crazyyi How are you serving static files?. you should be serving the socketcluster.js file in the example. You can just point to it in your html file. As you can see here it's in the public folder. You then reference it in your html file or however you are serving your app. I hope that makes sense.\n\n. We have a lot of clients on our systems and so far we haven't had any memory or CPU usage issues. It could be some rogue code or something causing the issue. Are you sure it's socketcluster and not some async code that you wrote?. I can use this. Thanks!. @dakkafex when I upgraded to Node 8, I had to also reinstall all my global packages. I would suggest also removing the global node_modules folder and reinstall them globally.. Nice!. I had all kinds of problems with this in Node 10 and docker... I just downgraded to Node 8 and all my problems went away. My current application doesn't rely on any of the Node 10 features so for now this is fine. Anyways, I hope this is helpful.. At Fusionware, we have thousands and so far it hasn't hurt anything or caused performance issues. I'm not sure if that helps you but you should be plenty fine with 40.. \n\nHere are two of our application servers. We have thousands of connections and you can see the average CPU and memory usage. SCC handles it pretty well. Our users are pounding our servers constantly and it handles all the messages really well. You should be good to go.. scc-broker-client 3.x.x is very good. Try upgrading to that. We've noticed a difference at Fusionware.. Thanks man!. PM2 - 2.4.3\nSC - 6.7.1\nSCClient - 6.3.0\nI use pm2 start gulp --name=fusion (I know... this app specifically is REALLY old...) and then I use pm2 restart fusion occasionally but other than that I don't really touch the app.\n. I don't write apps like this anymore... it was my first attempt at a large SC app.. I know this has nothing to do with this issue but is there a way to not output the initial startup logs from SC? I want to write my own logging engine and use SC events and process emits to manage what's going on.. @jondubois  8.2.1. I wonder if this has something to do with my startup script. I'm running pm2 startup which will start SC if/when the server crashes or gets restarted.. Ok, I don't know what was causing this... I just restarted the server and it's not happening again... really weird. I'm going to close this.. +1. +1. Are you going to return the channels as an array? How would you attach watchers to them? Thanks!. +1 Alright!!!. @jondubois thanks so much man. Now I can update our broker/state servers.. I would love this!!! Currently, I have a worker class that's a wrapper and this would make things so much easier. +1!!!!. Oh, I use the static create(options = {}) { return new Worker(options) } so I would rather use create instead of new. . @jondubois Hey man, I moved everything over and it makes everything so much easier. Thanks man!! Awesome change!!!. @jondubois what if each worker had a \"publish queue\" and publishing out would just push to this queue. Then there would be some sort of handler that would pop say 100 items from the queue every 5ms or something like that? Would that work? It would keep the messages in order so there shouldn't be any out of order problems. It would also stagnate the messages so the event loop isn't overwhelmed. Is that a viable solution? I've noticed this problem on our servers as we add more clients. Thanks!. @jondubois I know this is kind of dirty and could be handled much better but I was thinking of something like this. What do you think? It seems to work.\n\n\nWorker.js\n```\nlet publishQueueTimeout = 30 * 1000\n  let publishQueue = []\nlet publishOutHandler = function() {\n    console.log('Starting publish out handler',new Date())\n    if (publishQueue.length) {\n      let packet = publishQueue.shift()\n      packet.next(null,packet.data)\n    }\nsetTimeout(() => publishOutHandler(),publishQueueTimeout)\n\n}\npublishOutHandler()\nscServer.addMiddleware(scServer.MIDDLEWARE_PUBLISH_OUT,(req,next) => {\n    let channel = req.channel\n    let socket = req.socket\n    let data = req.data\nconsole.log('WORKER >> SC Server Middleware Publish Out. Storing data to the publish queue',new Date())\n\npublishQueue.push({\n  data:data,\n  next:next\n})\n\n})\nworker.exchange.subscribe('send-data').watch(data => {\n    worker.exchange.publish('receive-data',data)\n  })\n```\nClient\n```\n// Initiate the connection to the server\nvar socket = socketCluster.connect()\nsocket.on('error', function (err) {\n    throw 'Socket error - ' + err\n})\nsocket.on('connect', function () {\n    console.log('CONNECTED')\nsocket.subscribe('receive-data').watch(data => {\n    console.log('receive-data',new Date())\n    console.log(data)\n})\n\nlet packet = {\n    id:1\n}\nconsole.log('Sending packet to server',new Date())\nconsole.log(packet)\nsetTimeout(() => {\n    socket.publish('send-data',packet)\n},5 * 1000)\n\n})\n```\nIt seems to work with multiple workers and brokers as it should.\n\n. @jondubois I'm writing a module to test it in our staging environment. I'll let you know as soon as I test it. Thanks!. @jondubois This is the module I'm going to test.\n```\nvar DEFAULT_TIMEOUT = 50;\nvar DEFAULT_NUM_OF_MESSAGE_PER_PASS = 100;\nmodule.exports = {\n    attach:function(worker,options) {\n    options = options || {};\n\n    var scServer = worker.scServer;\n    var queue = [];\n    var debug = options.debug || false;\n    var timeout = options.timeout || DEFAULT_TIMEOUT;\n    var num_of_messages_per_pass = options.numOfMessagesPerPass || DEFAULT_NUM_OF_MESSAGE_PER_PASS;\n\n    var handler = function() {\n        if (debug) {\n            console.log('Publishing data to clients');\n        }\n\n        var packets = [];\n        for (var i = 0; i < num_of_messages_per_pass; i++) {\n            if (queue.length) packets.push(queue.shift());\n        }\n\n        for (var i = 0,len = packets.length; i < len;i++) {\n            packets[i].next(null,packets[i].data);\n        }\n\n        setTimeout(() => handler(),timeout);\n    }\n    handler();\n\n    scServer.addMiddleware(scServer.MIDDLEWARE_PUBLISH_OUT,function(req,next) => {\n\n        if (debug) {\n            console.log('Storing packet in queue');\n        }\n\n        queue.push({\n            data:req.data,\n            next:next\n        })\n\n    });\n\n}\n\n}\n```. @jondubois Just tested it with SCC, 1 BROKER, 1 STATE, 2 APP servers, 4 CLIENTS, and it only broadcasted 1 to each client. I'm pretty sure we're good to go.\n\n. @jondubois\n@toredash \n https://www.npmjs.com/package/sc-publish-out-queue. Ok, it's on our live production system at the moment. We have somewhere around 200 users who are constantly hitting the system with requests and I haven't seen any issues yet. That being said, it probably isn't tested enough because I've only tested it with my own scripts and our production environment. I will make those changes and push it up. Thanks!. @jondubois I've published 0.2.1 which has those optimizations and an example in the sample folder with somewhat understandable instructions. Thanks!. @toredash no but it will keep the event loop from getting clogged. I'm not really sure how to make it more efficient. When I get a chance, I'll take a look at the publish method and see if there is anything there that could be improved especially in light of V8's updates in Node 8.X.. @jondubois do you want me to write a simple plugin for this kind of like the publish out plugin?. @astutesoftware store an array of \"blocked users\", maybe comma deliminated id's or something, in each user's row in your DB. Then you can simple emit to all clients who's ID is not in that array of blocked users. If there are no \"blocked users\" then it will broadcast to everyone.. @MegaGM That's a really good idea! You can just throw it out if as the client if it's not for you. . @astutesoftware I store every message in a long term log database and then I store the last 7 days in another database that gets cleared every night (any message older than 7 days) to ensure quick queries on recent changes. Then if I really need to go back I can but it doesn't cause major slowdowns on recent queries because 10's of millions of rows is slow to query on lol. This works pretty well for us. Not sure if it helps but it might work for you.. I dirty fixed this by adding ip_hash; to my nginx config but all that does is force users to stay on the same server. I would like to have the ability to move them to whatever server I want without having to deal with any issues. @jondubois Is there a way to save to express sessions from inside the emit middleware instead of using SC session? That would also solve it for at least me. Thanks!. @jondubois\nOk, I stored the data in the DB using the express-session-middleware. Using JWT is great and I would love to do so but I wrote this app a long time ago and switching our login page would be quite complicated... Is there a way to access the express session from the middleware?. ... I just answered my own question... I can store and update the authtoken inside the db store... wow... I'll just do that.. In case anyone else encounters this, all you have to do is update the data object in the db and it works across all systems. They can even login multiple browsers at different IP's and it works. I've been keying off the user_id that I store in the req.session object. Probably not the most performant thing to do but I need accuracy more than performance at this point. I'll do it a better way if I find a better way soon. Thanks!. Hey guys,\nIf you want, you can look through the SC-Client code and see how it works. WebSocket is used client-side by SC-Client to connect so you can just follow that if you want to connect without using SC-Client I guess. Not sure how much help that is but you can do it.\n. @Louies89 what are your connection parameters? Can you post your code?. @Hirbod yea it's killing me lol. Has this been pushed? \n|handler  | 1519765951970 - Origin: Worker (PID 13438)\n1|handler  |    [Error] SocketProtocolError: Server ping timed out\n1|handler  |     at SCSocket._onSCClose (/var/www/handler/node_modules/socketcluster-client/lib/scsocket.js:629:15)\n1|handler  |     at SCTransport. (/var/www/handler/node_modules/socketcluster-client/lib/scsocket.js:280:12)\n1|handler  |     at SCTransport.Emitter.emit (/var/www/handler/node_modules/component-emitter/index.js:133:20)\n1|handler  |     at SCTransport._onClose (/var/www/handler/node_modules/socketcluster-client/lib/sctransport.js:204:28)\n1|handler  |     at Timeout._onTimeout (/var/www/handler/node_modules/socketcluster-client/lib/sctransport.js:269:10)\n1|handler  |     at ontimeout (timers.js:475:11)\n1|handler  |     at tryOnTimeout (timers.js:310:5)\n1|handler  |     at Timer.listOnTimeout (timers.js:270:5)\n1|handler  | 1519765952071 - Worker 0 exited - Exit code: 1\n1|handler  |    >> Worker PID: 13523. Hey man,  yes you can pass it in as a command line arg or you can just edit the server.js file and import it via a config file or something. It forces any node that connects to have the same auth key or else it won't let them connect. I hope this helps!\n```\nvar _ = require('lodash');\nvar argv = require('minimist')(process.argv.slice(2));\nvar http = require('http');\nvar socketCluster = require('socketcluster-server');\nvar url = require('url');\nvar DEFAULT_PORT = 7777;\nvar DEFAULT_CLUSTER_SCALE_DELAY = 5000;\nvar RETRY_DELAY = Number(argv.r) || Number(process.env.SCC_STATE_SERVER_RETRY_DELAY) || 2000;\nvar PORT = Number(argv.p) || Number(process.env.SCC_STATE_SERVER_PORT) || DEFAULT_PORT;\nvar CLUSTER_SCALE_DELAY = Number(argv.d) || Number(process.env.SCC_STATE_SERVER_SCALE_DELAY) || DEFAULT_CLUSTER_SCALE_DELAY;\nvar AUTH_KEY = process.env.SCC_AUTH_KEY || null;\nvar FORWARDED_FOR_HEADER = process.env.FORWARDED_FOR_HEADER || null;\nvar httpServer = http.createServer();\nvar scServer = socketCluster.attach(httpServer);\n. +1 on the sc-publish-out-queue =). @idibidiart We have 7 nodes in our production environment and I never got around to using Kubernetes... I wish I had. I've been meaning to go back and fix this mistake but I haven't got the time to take care of it. I would suggest you start with Kubernetes. I wrote a deploy script that works for now but I'm sure I would have been better off learning Kubernetes from the start.. @wmertens @Hirbod yea I have a delay in my client socket class wrapper as well.. good times.... Going back to 8 fixes it.. I just created a SC client connection to the system in the worker, super dirty I know, and it works like it should. I just replacedworker.exchange.publishwithsoc.publish``` and it works. I hope that makes sense.. hmm the publish is driven by event and isn't called immediately... I guess bad test\nBasically, when a user presses a button it fires an event and other users can get a notification given they match the conditions. When I listen to all events that are published, I don't see it... it's really weird. If I publish from the client it works but not from the worker.exchange.. This is the actual function\n```\n/*\n     * GP Channel Handlers\n     * @type {[type]}\n     /\n    scExchange.subscribe('set-erp-transaction-data').watch(function(data) {\n                console.log('Setting ERP Transaction Data')\n    let chan = data.customer_id ? data.customer_id.toString() : '1000'\n    let packet = {\n        success:1,\n        message:'Here is your erp data',\n        notify:'orders-edit-set-erp-transaction-data',\n        data:data,\n        customer_id:data.customer_id || 1000\n    }\n\n    worker.exchange.publish(chan,packet,(err,ack) => {\n      console.log(packet)\n    })\n})\n\nif I console.log the packet, it logs but a client never gets the message... If I replace the worker.exchange.publish with a client.publish it works.. really weird. Even after the server has been live for a long time. .let scExchange = worker.exchangeis above.. sorry about that. pretty sure this started happening when I upgraded to scc-broker-client 2.2\n. @jondubois I'll create a test network on AWS and give you what you need to connect with a SC client and a SocketCluster app instance so you can connect to the SCC group and see that messages aren't being sent inside the exchange.\n. package.json\n{\n  \"name\": \"socketcluster-sample\",\n  \"description\": \"A sample SocketCluster app\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"prod\": \"NODE_ENV=production gulp\"\n  },\n  \"contributors\": [\n    {\n      \"name\": \"Nick Kotenberg\",\n      \"email\": \"nkotenberg@fusionware.com\"\n    },\n    {\n      \"name\": \"Sam Graham\",\n      \"email\": \"sgraham@fusionware.com\"\n    }\n  ],\n  \"dependencies\": {\n    \"aes256\": \"^1.0.3\",\n    \"async\": \"^2.6.0\",\n    \"base64-stream\": \"^0.1.3\",\n    \"connect\": \"^3.6.6\",\n    \"debug\": \"^3.1.0\",\n    \"express\": \"^4.16.2\",\n    \"ftp\": \"^0.3.10\",\n    \"geocoder\": \"^0.2.2\",\n    \"google-distance\": \"^1.0.1\",\n    \"gulp\": \"^3.9.1\",\n    \"imap\": \"^0.8.17\",\n    \"jquery\": \"^3.3.1\",\n    \"jsdom\": \"9.12.0\",\n    \"minimist\": \"^1.2.0\",\n    \"moment\": \"^2.20.1\",\n    \"mysql\": \"^2.15.0\",\n    \"nightmare\": \"2.10.0\",\n    \"node-env-file\": \"^0.1.8\",\n    \"node-mysql-deadlock-retries\": \"^2.1.0\",\n    \"node-schedule\": \"^1.3.0\",\n    \"nodemailer\": \"^4.6.0\",\n    \"object-sizeof\": \"^1.0.10\",\n    \"promise-mysql\": \"^3.2.1\",\n    \"request\": \"^2.83.0\",\n    \"sc-cluster-broker-client\": \"^1.0.5\",\n    \"sc-redis\": \"^0.2.0\",\n    \"scc-broker-client\": \"^2.1.2\",\n    \"serve-static\": \"^1.13.2\",\n    \"socketcluster\": \"^10.0.1\",\n    \"socketcluster-client\": \"^10.1.1\",\n    \"socketcluster-server\": \"^10.0.1\",\n    \"templatizer\": \"^1.5.4\",\n    \"vo\": \"^4.0.2\",\n    \"xml2js\": \"^0.4.19\",\n    \"xvfb\": \"^0.2.3\"\n  },\n  \"keywords\": [\n    \"websocket\",\n    \"server\",\n    \"realtime\",\n    \"cluster\",\n    \"scalable\"\n  ],\n  \"readmeFilename\": \"README.md\"\n}\n.\nvar config = require('./config.json')\nvar SCBroker = require('socketcluster/scbroker');\nvar scClusterBrokerClient = require('scc-broker-client');\nclass Broker extends SCBroker {\n  run() {\n        let broker = this\n        console.log('   >> Broker PID:', process.pid);\n    // This is defined in server.js (taken from environment variable SC_CLUSTER_STATE_SERVER_HOST).\n    // If this property is defined, the broker will try to attach itself to the SC cluster for\n    // automatic horizontal scalability.\n    // This is mostly intended for the Kubernetes deployment of SocketCluster - In this case,\n    // The clustering/sharding all happens automatically.\n    process.env = config\n    if (broker.options.clusterStateServerHost) {\n        var broker_config = {\n            stateServerHost: broker.options.clusterStateServerHost,\n            stateServerPort: Number(broker.options.clusterStateServerPort),\n            authKey: broker.options.clusterAuthKey,\n            stateServerConnectTimeout: broker.options.clusterStateServerConnectTimeout,\n            stateServerAckTimeout: broker.options.clusterStateServerAckTimeout,\n            stateServerReconnectRandomness: broker.options.clusterStateServerReconnectRandomness\n        }\n        scClusterBrokerClient.attach(broker,broker_config);\n    }\n}\n\n}\nnew Broker();\n```. @jondubois could it be that the client doesn't have an AUTH_KEY set? If I connect to a cluster from a client and broadcast into that system and the client doesn't have an AUTH_KEY but the state and broker servers do? The weird part is the subscribe channel console.log's but the message from that subscribe event doesn't seem to emit anything if that makes sense.\n. @jondubois ok I was able to recreate this. I had to recreate our production env though in order to do it.\nI can give you access to the servers if you wish. Everything is running under PM2 under the Super User. \n1) create a state server on aws\n2) create a broker server on aws\n3) create 2 app servers on aws.\n4) connect it all up\n5) Test emit from app server 1 to client on app server 2.. cluster is live\n6) create a client on my local machine that connects to one of the app servers on the cluster.\n7) have it subscribe to channel '1000' and log any data that comes across that channel.\n8) socketcluster create app (locally) and connect to cluster\n9) have that local server publish a message to channel '1000' and the client will NOT emit the event but if I do the same thing from a SC-Client connection on locally it works.\n\n. Ok, so the client works but the worker does not on \"scc-broker-client\": \"^2.1.2\"\n\n\n\n\n\n. @jondubois on 1.2.2 of scc-broker-client every time I publish to a channel with the worker.exchange it hangs up. On 2.2 it will hang up maybe 10 secs after I publish and the client will never get the message.. it's pretty simple to replicate. You create a cluster,   (state,broker,1 app server, 1 client connected to the app server, then another app server and use the second one's exchange to publish to a channel that the client is subscribed to and the client will NOT get the message). For my test, I spun up 4 AWS micro servers and I used a local app server to publish. The weird part, is if I use the SC-client package INSIDE the second app server the first client gets the message every time.. @jondubois \nsorry man I'm right in the middle of work. I'll create a very simple network of 1 state server, 1 broker, 2 application servers from socketcluster create and two clients each one connected to one of the app servers and then try it.\nI know it's really weird because we are using worker.exchange.publish quite a bit and it's working just fine except for this instance.. when clients publish it works great which is 99.9% of our services but when a app server publishes there are some clients that are not getting the message.. really weird. \nWhen I get another chance I'll create the above simple test and let you know how it goes. For now, I just am using SC-client publish and it's working so our customers are happy...  . @jondubois hey man, no one else seems to be having this issue and with my terrible fix it's working. I'm too busy at the moment to figure out what I'm doing wrong so I'm going to close this issue. Thanks so much for taking the time to reply back and work with me!. +1. @Hirbod \ninitialDelay - is the delay before it connects the first time\nrandomness - is part of the reconnect timeout function for when the socket disconnects and then tries to reconnect\nmultiplier - part of the same equation\nvar initialTimeout = Math.round(reconnectOptions.initialDelay + (reconnectOptions.randomness || 0) * Math.random());\ntimeout = Math.round(initialTimeout * Math.pow(reconnectOptions.multiplier, exponent));\n````\nmaxDelay:\nif (timeout > reconnectOptions.maxDelay) {\n    timeout = reconnectOptions.maxDelay;\n}\n```\nI hope that makes sense.. \n```\nSCSocket.prototype._tryReconnect = function (initialDelay) {\n  var self = this;\nvar exponent = this.connectAttempts++;\n  var reconnectOptions = this.options.autoReconnectOptions;\n  var timeout;\nif (initialDelay == null || exponent > 0) {\n    var initialTimeout = Math.round(reconnectOptions.initialDelay + (reconnectOptions.randomness || 0) * Math.random());\ntimeout = Math.round(initialTimeout * Math.pow(reconnectOptions.multiplier, exponent));\n\n} else {\n    timeout = initialDelay;\n  }\nif (timeout > reconnectOptions.maxDelay) {\n    timeout = reconnectOptions.maxDelay;\n  }\nclearTimeout(this._reconnectTimeoutRef);\nthis.pendingReconnect = true;\n  this.pendingReconnectTimeout = timeout;\n  this._reconnectTimeoutRef = setTimeout(function () {\n    self.connect();\n  }, timeout);\n};\n```. @Hirbod yea exactly. @jondubois -> socketcluster winning!. I could really use the active property. Thanks @jondubois !. +200. @jondubois are you going to do this?\nsomeFunc(data,respond) {\n   return new Promise(async (resolve,reject) => {\n      // Do something\n\n      respond && respond(err,results)\n      return resolve()\n   })\n}\n\nor were you just going to remove callbacks all together?. That's cool. I love promises. I'm pretty excited for this!. We have a guy upstairs who's app is experiencing this exact same thing. I've pointed him to this issue. So far, I haven't heard anything on our app but who knows. We have a lot of traffic but much of the traffic is editing things in the DB and the response time isn't important. . @Hirbod are you guys on google? aws? nginx?. Trying to find the common denominator. . Epic fail... dang it. We have a dedicated loadbalancer (nginx) and everything else in the network is on their own respective instance. We haven't noticed any of these problems. We are also using SCC if that makes a difference. 1 scc-state server and 2 scc-broker servers.. Has this been fixed for everybody?. @toredash I work downstairs from him and I can tell you he's using letsencrypt so SSL is turned on. Our servers are handling a lot of users and we haven't seen this issue. We bought our SSL from comodo but I'm pretty sure he's using a very similar nginx config to me. . @Hirbod kill -SIGUSR2 12345  <--- that's the Master PID\nI use PM2 for server process management so you can easily get the master PID if you're using PM2 with the following command.\ngrep 'aster' ~/.pm2/logs/fusion-out-5.log\nor wherever your log file is at\n. @Hirbod was that on your nginx server?\n. Basically, if there is a data migration process going on on this worker then that process is interrupted and has to restart... sometimes these processes can take hours so a worker crashing is a pretty bad thing. It will get done eventually but sometimes people are waiting on this data. Thanks!. @jondubois I guess my question is why is a socket hanging up an Error... that seems wrong.... @jondubois No, I just copied and pasted from my terminal. It's super weird. . You can assign each user to their own channel (i.e. subscribe(user.id.toString())) and then send emails/messages to that channel. That's essentially what we do for chat messages that are direct messages.\n. v8.11.2\nIt's on an EC2 instance. It's not running inside a container like docker. It's weird and really hard to diagnosis because it's so rare. Next time it happens, I'll check to see if /usr/bin/nodejs still exists. I had to restart the server so I don't know. Thanks!. @tangquoctuan Hey man,\nYou can have each user subscribe to their own channel, for example subscribe to a channel using their user_id. Then, when a person wants to send another person a message, you can publish to the channel matching their ID. Then, you can send messages to everyone or just a specific person. I hope that makes sense and helps!. I had real problems from 8 to 12. Sorry, I don't remember what I did to fix it but I just wanted to let you know that you might experience some issues. . @tangquoctuan You can use the sc-publish-out package and modify it to add a timeout or something to message pushing. I will accept pull requests.. you can pass in ENV with --cssh=localhost --cssp=3300. Good luck!. @jondubois can we close this issue? I believe it has been resolved and no activity for a while.. @jondubois I fixed those changes you asked about. Thanks!. @jondubois hey man I was thinking if the docker images shared the same persistent storage claim could you replicate state servers and remove the single point of failure? You could use ClusterIP to handle the communication. What do you think?. @jondubois no worries. @jondubois cool thanks! Yea, I don't know.. I use kops and AWS for production. I played around a little bit on GKE but it was too much magic for me. Thanks!. I know this doesn't directly answer your question but I had to do build and run on Docker to get it to work. Here is my Dockerfile\n```\nFROM node:8.12.0-onbuild\nRUN apt update -y\nRUN apt install build-essential -y\nWORKDIR /app\nCOPY ./package.json ./\nRUN npm install\nCOPY . .\nRUN npm remove sc-uws --save\nRUN npm install sc-uws --save\nCMD [\"npm\",\"run\",\"start\"]\n```. Very weird that I had to remove it from the package.json and then add it again. That was the only way I could get it to work..... Yea, I need to start using initContainer. I haven't started using it yet. I was going to on my next project. Thanks for the example!. One way I was thinking of handling this is to on startup generate a random string and on connect to the server send that string to the client and have it subscribe to that channel. Then, when a change occurs the server just publishes to it's specific channel... that seems excessive though. I would think that there is just a list of the current clients or some way to already do this.. I guess another way is to just push and pop off clients as they connect and disconnect but it seems to me that there probably already is an array of connected clients somewhere in the worker.. @jondubois Hey John, I wrote a handler that watches a specific table in the database. As the tables grow, the number of containers grows. It seems to work pretty well. Then I use Kubernetes to manage the number of brokers (autoscaling) and everything seems pretty fast. Thanks for your advice!. Are you planning on using socketcluster as an API for the vue-cli? Yes, I've done it. . Yes, it's supposed to be 2 space tabbing on yaml files but it seems to work both ways... to be honest, I'm not 100% sure. In my production yaml files for work I always use 2 space indentation on arrays.. ",
    "MadeinFrance": "In socketcluster@1.3.4\nRes.end throw the following error:\nError: TypeError: Object function (error, data) {\n                response.callback(error, data);\n              } has no method 'end'\nUsed with:\n```\nsocket.on('ping', function (data, res) {\n      res.end({token: 'abc123'});\n});\n```\n. It's suits me very well. Top!\n. ",
    "sdejean28": "HI, i'm beginning in interesting to SocketCluster.\nI've installed it on Ubuntu 14.04 LTS the MyApp sample and it works perfectly, but i wanted to manage the server.js with Forever.\nTo start perfect, but when i try to stop the server, the main process 'server.js' stops, but not child processes. I have to kill them manually.\nI'm using Node.js version 0.10.25 and SocketCluster 1.1.9.\nAny suggestions welcome ...\nthanks\n. perfect !\nthanks all lot i'll keep exploring this technology !\n. ",
    "mlmarius": "Thanks for the reply. I think i will try starting a tcp server from one of the workers but what if that worker dies and is restarted. Will my notification server also die ? Will i have to restart it ? And last ... How can i cleanly shut down my server when socketcluster shuts down ?\n. Thanks !\n. I'm trying to do something on worker shutdown : \nworker.on('SIGTERM', function () {\n  console.log('worker shutting down');\n});\nFrom inside the worker file.\nThen i do node server.js to launch the server into foreground. I then do a CTRL C to shut it down but i don't see the worker loging out that it's shutting down. Am i missing something or maybe it's working as it's supposed to but it's just not able to output to screen anymore when it receives the SIGTERM ?\n. Dosn't seem to fire. Now i'm trying to write to a tmp file but that dosn't happen either \nworker.on('exit', function () {\n    fs.writeFile(\"/tmp/workers_offline\", \"worker offline\");\n});\n. I am now doing this and it seems to work. Not sure if this is the right way:\nprocess.on('SIGINT', function () {\n    console.log('worker got SIGINT ' + process.pid + \"\\n\");\n    process.exit(0);\n});\nprocess.on('exit', function(){\n    console.log('worker ' + process.pid + ' got exit event'+\"\\n\");\n});\n. the connect method takes {host: '', port: '', ...} methods\n. Hi. So is there any way to get some stats from the socketcluster like count of currently connected clients across the entire cluster ? I've been reading this: http://mosquitto.org/man/mosquitto-8.html and i think it is a good sollution. The thing publishes stats to some system topics and you can just listen there for them.\n. Thanks. So from the worker, when someone connects i will subscribe to a store and listen for events on a channel. But how do i access the store and subscribe to it from my worker? I think the logic from the sc-redis repo is for the store.\n. right now i am using rabbitMQ as a messagebus in my network and socketcluster as a consumer but if things pick up i may have multiple socketcluster instances consuming from rabbitMQ.\nUnfortunately i think i still don't clearly get it :). I'll attempt to better describe my setup. This is how my store looks like:\n``` javascript\nvar rabbitCon = require('./rabbitCon');\nmodule.exports.run = function (store) {\n  console.log('   >> Store PID:', process.pid);\n//callback when rabbit has messages for us\n  var cb = function(store){\n        return function(msg){\n                var topic = msg.fields.routingKey;\n                topic = topic.substring(topic.indexOf('.')+1);\n                var msgString = msg.content.toString();\n                console.log('publishing topic: '+topic+' | '+msgString);\n                store.publish('testchan', msgString);\n        }\n  }(store);\nvar rql =  new rabbitCon('amqp://bunnyuser:bunnypass@localhost:5672','topic1', 'socketcluster.*', 'socketcluster');\n  rql.connect().then(function(rabbitConnObj){\n        //console.log('rabbit conn now complete');\n        rabbitConnObj.setCb(cb);\n  });\n};\n```\nNow i'm wondering where in my worker.js should i hook up so that i receive the events published by this store. It's not clear to me wether i should to this inside of the scServer.on('connection',...) block or before that ? \nFrom what i gather i think i am supposed to do something like this maybe ?\n``` javascript\n  /\n    In here we handle our incoming realtime connections and listen for events.\n  /\n  scServer.on('connection', function (socket) {\n//This function returns a Channel object which lets you watch for incoming data on that channel\nvar rabbitChan = scServer.global.subscribe('testchan');\nrabbitChan.watch(function(data){\n            console.log('worker received testchan data');\n});\n// ^ is this OK ? Do i need to bind listeners every time someone connects ? As it is now, It doesn't do anything when the store publishes to testchan.\n\n\nsocket.on('ping', function (data) {\n  count++;\n  console.log('PING', data);\n  scServer.global.publish('pong', count);\n});\n\nvar interval = setInterval(function () {\n  socket.emit('rand', {\n    rand: Math.floor(Math.random() * 5)\n  });\n}, 1000);\n\nsocket.on('disconnect', function () {\n  clearInterval(interval);\n});\n\n});\n```\nThe only missing piece is how to get my worker to react to the event when i do store.publish('testchan', 'test');\nDoes stuff that i publish() from the store end up in the scServer.global object ? Does simply publishing to a channel assert that channel into existence or must the channel be created somehow first ? The scredis extension does show how to publish and check for stuff but unfortunately it's not apparent how to receive the published messages in the worker. Could the fact that i publish from the store and the channel.watch() from my worker doesn't do anything be a bug ?\nDo i need to manually publish to the global object from my store ? if so ... how to get the global object from the store ?\nDo i even need to involve the global object ? I would like to use the most efficient way of doing this.\nThis part i think i didn't get: \n\nWorker1 handles this and decides that it needs to subscribe itself to 'foo' on Store1 in order to start relaying the messages from that channel back to ClientA. To do this, it creates a new subscription to 'foo' on the store - The store.on('subscribe', ...) handler is triggered.\n\nI've read the docs but don't know how to subscribe to a store from my worker.\nAlso i am running socketcluster Version: 2.2.14\n. great post. Thanks!\n. ",
    "pressla": "Hi, I am looking into SC for an M2M scenario. I have 3 level of clusters, propagating upwards. i.e. 100 Level1 servers, 10 Level 2 servers, 5 Level 3 servers. \nLevel 1 servers are source, Level 2+3 are sinks. Clients can connect to any level, depending on the routes, realtime data should be consistent withing reasonable limits.\nLooking forward your description of server-server scenarios.\nThanks\n. wow, many thanks for the extraordinary work here. It is an amazing architecture!\n. This sounds promising.\nI have a large number of embedded clients with very limited memory, so the total footprint of the client side is most critical, and secondly the execution overhead should be lowest possible. \nThese clients are using nodejs, so compatibility is only an issue for mobile clients for me, and I could live even with seperate systems for each solution.\nSo plz keep in mind to stay modular and minimalistic on client side. i.e. many cases exist with outgoing traffic only, and this is super simple case which should not require a large libary.\nI believe a lean approach is king. most libaries suffer from growing big over time.\n. thanks,\nI love socketcluster :)\n. ",
    "acoyfellow": "+1 to the tutorials. Very interested in those.. thanks for the hard work on this\n. ",
    "1manStartup": "Thanks for your explanation and documentation, really helped me out. \n. Also I noticed that SC allows publishing from client to client. Normally when scaling with pubsub I would go from client->server (MQTT/db)->client. But how would we save a client to client event to db? Or is client to client meant for sending non-persistent messages such as 'User123 is online'?\n. @MegaGM the Client API is here(http://socketcluster.io/#!/docs/api-scsocket-client) it works like engine.io-client since that is where it inherits from.\n. Answering Own Question Here, Hopefully this should help others. So when doing publish/subscribe, I noticed two ways to do it. In the examples below, pub/sub can be used for newsfeeds, chat apps, tickers, or even collaboration apps.\nPubSub-Single Machine (Client->Client)\nLets say there are 2 pages with URLs, /RoomA and /RoomB.\nTo allow message message to go from RoomA to RoomB do following:\nHave RoomB subscribe to RoomA: socket.watch('RoomA') on client\nHave RoomA publish to RoomA: socket.publish('RoomA','Hello') on client\nThe above is enough if you don't need to save the data, (collaboration drawing apps, games, or notifications)\nTo save data, on either RoomA or RoomB page, inside your socket.watch('RoomA') event you can POST/emit to db, from client.\nPubSub-Multiple Machines(Client->Server->Server)\nFor Multiple Machines it is more complex. A pubsub system is required (MQTT or Redis).\nWhat I did was have RoomB subscribe and watch to RoomA on client: socket.subscribe('RoomA') and socket.watch('RoomA'), callback inside RoomA. \nAnd on the RoomA client I do socket.publish('RoomA-PubSub,'Hello'). 'RoomB' does not get this event. Instead I make the 'Store.js' file watch for all publish events:\n//store.js on server\nvar mqtt = require('mqtt') //Guide Here: http://bazalabs.com/creating-mqtt-application-end-to-end/\nclient = mqtt.createClient(1883, 'localhost'); //connect to MQTT pubsub \nstore.on('publish',function(room,Message){ //room = RoomA, AND, message= Hello \nclient.subscribe(room);\n client.publish(room, Message);//Put message into pubsub \n client.on('message', function (room, Message) {//when a message is sent\n  store.publish(room,Message)//Publishes messages to all clients listening to RoomA, in our case, RoomB.\n });\n})\nThe above publishes to the desired room, without duplicate messages. And can be scaled across multiple machines.  Would like to hear from @jondubois if this is a 'correct' way to scale across multiple machines. Thanks.\n. ",
    "slidenerd": "@jondubois thank you for the detailed explanation, I have a similar case and a small doubt about the framework which I couldnt find in the documentation.\nMy workers are asymmetric and the way I am currently separating them is by doing what you did above\nif (worker.id === 0){\n//get data from 1st external websocket API\n}\nelse if(worker.id === 1){\n//get data from 2nd external websocket API\n}\nso if worker 0 and worker 1 are getting data from different APis. how do I let all the clients subscribe to this data\nif I do worker.exchange.publish() from worker 0 and if a client is connected to worker 1 will they still get this data? My case happens to be where I want individual workers fetching data from different API sources but connecting clients to be able to get access to whichever data source they want regardless of which worker they are connected with. Interesting, if that is the case, what would be great is if you can add another article in addition to your \"SocketCluster patterns for chat\" that shows a setup involving workers that do different tasks and relay everything to the server which can forward it to all clients, would be a solid usecase. @happilymarrieddad if you dont mind answering, are you using the native js client with vue or are you using some sort of library. Thank god I searched issues :) before posting this, one thing that would be super appreciated is if you can elaborate what socketcluster can do over the cluster module or socketio, you dont have to do it here, a medium post will be helpful too but a comparison would be super appreciated. @amin-mir this node js client you have specified can only connect with another socket cluster server regardless of whether that server is on the same domain or on a different domain, what if you want to connect to a completely third party API that provides data via a websocket stream such as the GDAX API, I am assuming it wont work then. So a highly related question, lets say I have 4 workers running and I have a separate file lets call it api.js that connects to an external websocket api and receives stream, I want to forward this stream data to the connected clients and also to another worker for processing\n\nIf I include the file api.js inside the worker file, obviously it gets called 4 times which is not desirable\nOne way I can fix the issue is to use the worker id and require(\"api.js\") only in a worker with say id 0\nIs there any other way of doing this? and what would be the right way to forward this to another worker. \n",
    "hopewise": "Is there any update?\n. Can you please tell me, what do you mean by basic features? and what would be missing?\n. any update for the android client?\n. I tried to as: \nnpm install -g socketcluster --no-bin-links\nThen I got this error:\nroot@1c35c0f739d0:/app# socketcluster create myapp\nbash: socketcluster: command not found\nWhat would be the full path to socketcluster ? I tried whichbut it didn't return anything..\n. ",
    "abpopov": "This client now in dev state. I hope it will be done in two weeks. At this moment you can connect to server, subscribe to channels, and send messages. Some event are not implemented.\n. We have android client for our project, I hope soon we will make lib for android, which anybody can use.\n. socket cluster 5.5.0\nnode 4.2.4. Update node to 6.10.0 solved problem . ",
    "efkan": "Hello @abpopov ,\nIs there any progress on SocketCluster-android-client?\n. :+1: \n. :+1: \n. Hi @jondubois ,\nI guess this issue can be closed now https://github.com/uWebSockets/uWebSockets/issues/186\n. I get the same message as a warning after the client disconnection at every time.\nclient connected\nclient disconnected\n1468514606780 - Origin: Worker (PID 4268)\n   [Warning] SocketProtocolError: Socket hung up\n    at Emitter.SCSocket._onSCClose (D:\\Work Space\\Projects\\a_web\\node_modules\\socketcluster-server\\scsocket.js:193:17)\n    at WebSocket.<anonymous> (D:\\Work Space\\Projects\\a_web\\node_modules\\socketcluster-server\\scsocket.js:70:10)\n    at emitTwo (events.js:87:13)\n    at WebSocket.emit (events.js:172:7)\n    at WebSocket.cleanupWebsocketResources (D:\\Work Space\\Projects\\a_web\\node_modules\\ws\\lib\\WebSocket.js:927:10)\n    at emitNone (events.js:72:20)\n    at Socket.emit (events.js:166:7)\n    at endReadableNT (_stream_readable.js:905:12)\n    at nextTickCallbackWith2Args (node.js:455:9)\n    at process._tickDomainCallback (node.js:410:17)\n. I try to use an Android app which is developed in react-native.\nYes, I am using JavaScript socketcluster-client (not client for Android) to connect to the server.\nVersions of the server libraries:\nsocketcluster: ^4.6.2\nsocketcluster-client: ^4.3.19\nThe version of the client library:\nsocketcluster-client: ^4.3.19\nNode.js server runs on Windows. And wsEngine option has been set as ws.\nThank you..\nps: The issue is not urgent for me now. I've just let you know.\n. After reading your explanation, the warning message sounds normal to me.\nAn app is an activity in Android. And the activities have some methods that run in different cases. For now, react-native handles only onPause, onResume and onDestroy case methods. [The methods can be used only on the native Java side]\nSo an app created for running on Android, turns to onPause mode when the user opens another app or presses the home button to go to the main screen on the phone. In this case socket connection is still alive. That's good.\nHowever if an app is closed by the user intentionally that means app has been destroyed. Like hard resetting the computer. I get the warning message when destroying the app. Then the SC client cannot send a #disconnect event at all.\nI'd like to know what happens if the SC client doesn't send a #disconnect event at all ?\n(scServer.clients appearances is OK when the destroying the App)\nAnd also I wonder that, can I handle Socket hang up warning/error to shut up that :) I can already handle that error message {name: 'SocketProtocolError', message: 'Socket hang up', code: 1006, domainEmitter...} in socket.on('error') event. Emerging that warning seems not necessary. Is it ?\nThanks for your helps and SocketCluster.\n. It works. A useful option. Knowing that there is no an important issue is good.\nThanks..\n. Hi @jondubois ,\nI wonder that how did you install SocketCluster on Windows despite uws issue?\nI couldn't install the newest version because of uws and windows. Then I installed v4.6.0.\n. Now it works for me too :smile: \nFor some reasons I had tried to clean cache manually.\nThanx!\n. ",
    "seme1": "I am no expert in Redis, but it seems like the SC-Redis plugin require a Redis server to be running. When comparing this to the solution implemented by Ratchet, it looks to me that ZeroMQ is better. \nWouldn't be possible to have one of the workers (or maybe the store ??) listens to ZeroMQ msgs/channels and work as a relay between external apps and SC? On the other end in Php (or any other language), the developer would push/publish/subscribe to the ZeroMQ worker which in return would simply bypass the received msgs to the real workers (which handle the actual subscriptions and channels)?\nThe benefit of the above is that there is no need to run a Redis server (and maybe worry about its scalability later on ??). It would be optimal if the loadbalancer in SC can also balance the load of the ZeroMQ worker and launch new instances (or process) when there is a need to do so (just like it does with normal workers).\n. I've been thinking about the best setup for storing the IDs of all logged in users when having two (or more) worker processes. Perhaps it's best to store a portion of the authenticated users in Worker1 and another portion in Worker2 instead of using a global array shared between both workers that would contain all users IDs.\nIn this case my question is, what is the best way for transferring day from one worker to all the rest of the running workers ?? perhaps a 'private' subscribe/publish scheme can be applied so whenever a new worker is launched, it would subscribe to the 'private' channel. In this case if it requires to check whether is a userID is already registered in one of other workers arrays, it would simply publish a question to the rest of the workers in a specific format ??\n. I am trying to figure out how to implement this with Redis. What I'm trying to achieve is a way for different workers to interchange data that should only be available while the workers up and running. It should also be flexible so that if a worker is added or suddenly removed, a worker should still provide the correct results by communicating with only the other \"running\" workers.\nOne difficulty I'm facing when using the pub/sub model for solving the above problem is how could worker1 know how many other workers are available and still in a \"running\" state in real time ? \nTo clarify this, let's assume that all workers subscribe to a \"private\" channel once they are initiated. Let's say also assume that there are 3 workers : worker1, worker2 and worker3. If worker1 needs to retrieve data from worker2 and worker3, it would have to publish to a request through the \"private\" channel and wait for a response from all available workers. The responses from worker2 and worker3 are expected to be separate but in the same \"private\" channel. The question is : for how long should worker1 wait for a response from all other workers before deciding that all other workers have already responded ? Since worker1 does NOT know how many other workers are still available, I'm guessing this would be very trivial to solve.\n. Thanks to @MegaGM  and @jondubois  for the very informative responses and comments. I learned a lot especially from the examples provided by @MegaGM . Thanks to you all. I also think it will be very useful if the comments provided by @MegaGM are added to the website Documentation secion. \nHowever, I'm still puzzled on how to solve the following problem while still making each worker run independently from the rest of the workers. Here is what I have:\nEach worker has an activeUsers object which basically stores the IDs of the currently logged in users in this worker. It also links each user ID to the session(s) ID of the user. A logged in user may have one or more sessions.\nWhat I'm trying to achieve is to update a backend MySQL database with the number of LIVE socket sessions each user has. Initially, I implemented this via having UserSessionsNumber counter in the database that is initialized to zero for each user. When a user is authenticated via a websocket, a connection is made to MySQL to increase the UserSessionsNumber by 1. When a user session ends because the user either logged out or got disconnected, the UserSessionsNumber counter is decremented by 1.\nThe above solution works nicely and has the advantage of that every worker does NOT need to know or interact with the rest of the workers for computing the number of live sessions a user has/have. HOWEVER, when a worker crashes or suddenly stops, the sessionEnd event for each user is never called. Thus, the UserSessionsNumber is NOT decremented leading to the values stored in the DB to be INCORRECT. \nI spent too much time trying to figure out the best strategy for avoiding the problem that may arise when one of the workers crashes. The only way I could think of for avoiding this problem is by iterating through the activeUsers variable to compute how many active sessions a user has every time he/she signs in or sign out. If there is more than one worker running, then this means that the worker would somehow have to know how many active sessions this user has in the other running workers so that it can update the MySQL database with the correct value.\nI understand now that the above is a bad design. However, if there is any other strategy you suggest for computing the total number of live sessions each user has, please let me know.\n. I just thought about another idea. Perhaps I could have each user session subscribe to a private user Channel, perhaps identified with the user_Id. SocketCluster should (based on my understanding ) span this private channel across all running workers. In this way, when a session is created for a user in worker1 and another session is created for the same user in worker2, both user sessions should subscribe to the channel private_userId. This way, when a worker crashes, all of the subscriptions initiated by this worker would also be deleted.\nThe question I really need an answer for to make the above work is: how to find the total number of subscriptions made to any channel ? \n. Thanks again for your response. The idea of having sessions replaced by usernames (or userIds) is really great. I'm eagerly waiting for it to come out so that I can implement it in my system. Can you give us a hint on its ETA ? I may put my current development on this aspect of the project on hold until it comes out since I'll most probably have to change the design of many things on the client side/server side, especially the authentication part. For me the idea of \"having one session for multiple open tabs\" does not have much value as the app will be cordova-based and will run only once on each device. This also means that the same user may login from different devices. \nMeanwhile, I came across this post which is very similar to the last idea I had for tracking user IDs through pub/sub channels. The question I had is how to get the total number of subscriptions made to any particular channel ? \nAnother way for asking the same question: when examining the following io.socket code (which is taken from the above link):\nvar counter = io.sockets.clients(socket.room).length;\nHow to get the value of counter by using SC instead of io.sockets  ?\n. Thanks a lot for your comments @MegaGM . The approach of having two channels, namely online_anons and online_users is even better, since no master process is needed. It's actually what I almost settled on and I included a link in my last post to somebody who used a similar method with Socket.io. \nFor me, the main remaining part now is how to obtain the number of users that are currently subscribed to a channel from the server side. There are other open issues regarding server side sub/pub but I'll include it in a separate issue. \n. ",
    "jmny": "\"no js\" client and way to implement these clients :\nHave you some plan to publish a kind of protocol ? Or some plan to implement iOS or Java client ?\n. sounds good :)\n. ",
    "franklinjavier": ":beers: \n. ",
    "jasonpaulos": "Thanks for informing me of the details of the req parameter and how authentication works in the current version of SC. I have to agree that auth tokens do seem to be a more elegant solution than sessions, but I had planned my current project around being able to \"soft authenticate\" sockets with their passport session if they had already logged in. And, unfortunately, sending login credentials though sockets isn't an option with the passport strategy I'm using (https://github.com/liamcurry/passport-steam). With passport-steam, login credentials are sent through Steam and then profile information is sent to my app. This information is then stored in sessions, so associating a session with a socket is a key step in my current workflow.\nTo accommodate this necessity, I see no other option than to modify my SC source slightly. I've had to add the line this.profile = req.profile; to the constructor of SCSocket here: https://github.com/TopCloud/socketcluster/blob/master/lib/server/scsocket.js#L65. And in the passportSocketCluster.handshake callback function in my own app, I've set req.profile to an object that contains the required user information from the passport session. This way, I can still associate session data with socket instances without completely reverting to a pre-JWT SocketCluster.\nI'm not very happy about having to modify the SC source, but it's the best way I could think of keeping my current workflow intact.\n. ",
    "bamoo456": "wow, the idea sounds great.\nuse MIDDLEWARE to filter channel data really useful, it keeps application code more\nmaintainable :+1: \ntruly appreciate your quick response and suggestion here. :)\n. Hi, I'm just curious about whether MIDDLEWARE_PUBLISH_OUT will be applied on both sc1 and sc2 when this feature is implemented?\nThanks,\n. useful information, thanks again :)\n. Hi @jondubois \nI just saw that this.MIDDLEWARE_PUBLISH_OUT = 'publishOut' has been added on scserver.js.\nHowever, documents has no related information on it.\nDoes this feature implemented ? or still under cooking ?\nThanks \n. nice work !  Thanks :+1: \n. It's awesome feature and works great.\n. Thanks for your detail response, that's really great on such a lightweight design of subscription request.\nIt truly helps me a lot :)\nThe <sc-socket> and <sc-model> looks interesting, it seems that this new feature can get useful when bind to react.js component. (when componentWillUmount the channel start unsubscribe channel.)\nAwesome works and Thanks again :+1: \n. @jondubois sounds good,\nthanks for your quick reply :+1: \n. ",
    "mailmevenkat": "@bamoo456 On SC2, this feature is working like a charm but on SC1, i don't know.\n. The first solution worked like a charm! I will try with the new one!\n. \nI manually checked iocluster/index.js , it has both Global.prototype.subscriptions and Global.prototype.isSubscribed , i don't think there is any problem in the file.\n. Cool! This is way better for handling subscription! As of now i am using middleware for subcribe and custom channel list (as you suggested before) to handle disconnect. Will test this too. And ofcourse i have been using sc2.\n. ",
    "hedgepigdaniel": "Cleaning the cache didn't fix it, but I can't reproduce the issue anymore. I'll get back to you if I can. Might have been some networking problem on my end.\nGreat to hear about the new QoS levels :)\n. ",
    "damirci": "hi, thanks for your response, According to sc-redis  I cant access to socket object with socket id, and I can to publish message to channels, I need to access socket with socket id\n. i need to implement a http method to send a message to connected client, i know socket and its id saves in stores, your mean is i cant access to socket object with socket id?\n. hi, me again.\ni want to add proxy like load balancer in previous version of sc, but initiate of workers is diffrent in new sc, can you give me a guidance about add proxy to route http request to specific process?\nthanks\n. i must to say, old sc load balancer has this run time error:\nOrigin: Balancer\n[Error] Error: bind EADDRINUSE\nat exports._errnoException (util.js:746:11)\nat cb (net.js:1178:33)\nat shared (cluster.js:586:5)\nat Worker. (cluster.js:561:9)\nat process. (cluster.js:692:8)\nat process.emit (events.js:129:20)\nat handleMessage (child_process.js:324:10)\nat child_process.js:408:7\nat process.handleConversion.net.Native.got (child\nat process. (child_process.js:407:13)\n. i know that websocket is connection oriented and i want to route some http request to known process not websocket connection.\ni want to send requests to process with some thing like '.\\pipe\\socketcluster_app_02307c83d2_w0' in previous version.\n. ",
    "delaneyj": "@mnami if you know the socketId why not subscribe them to a 'user:{socketId}:{guid}' channel?  That way you can send individual things to them and still have pretty good guarantees for not spamming a clients channel.\n. @killingz0e if it works its probably helpful to close this issue.\n. Sorry, have been moving offices.  So far I had just used webstorm's internal debugger. When you start a node config it sets up the debug-brk and ports and auto continues after first line when launched. Because of the convenience never tried node-inspector until now.  I'm now sure if there is support for node-inspector webstorm support is just a master of configuration.\nI know nodemon cascades debug/debug-brk down to the actual node instance.  Perhaps that process could show how to pass info.  Or maybe just have an extra command that sets the debug flag on the first worker, store, etc on different ports.\n. If I understand it correctoly both debug and debug-brk have ports associated with them with the defaults set to 5858.  A config option would be great,  maybe a starting port defaulted to 5858 that increments per worker?\n. It would be nice to have port initial numbers for the the stores (or any other processes) you are spinning up.\n. Finally was able to test this.  Using node-inspector you are able to get to server.js in the example but workers are not accessible.  I'd hope a config/incremental approach per store/server/worker would help this.\n. This is awesome, that you for the fast turnaround!\n. ",
    "MichaelJCole": "@jondubois hey, your first comment should really be in the README.  The designed uses aren't clear from the documentation.\n. ",
    "killingz0e": "I have the port 80 on both inbound and outbound setted up, which other ports are needed in case of a channel subscription? \n. Installed the new sc2, opened up all the ports in outbound on ec2, now it\nworks.\nOn Thu, Apr 23, 2015 at 12:28 AM, Jonathan Gros-Dubois \nnotifications@github.com wrote:\n\nTry to reinstall SocketCluser - Use the latest version of SC1 v1.3.7 or\nSC2 v2.1.11. There was an issue with one of the SC1 dependencies not too\nlong ago so that could be the issue.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/TopCloud/socketcluster/issues/58#issuecomment-95356283\n.\n. \n",
    "woubuc": "@jondubois I've looked for a sc2-specific client code but there's no sc2-client repo that I can find and the NPM entry for sc2-client contains only socketcluster-client, which is the code I used. I already suspected I might have the wrong client (it kept trying to connect through polling and threw errors when that didn't work - which I then fixed by setting it to websocket only), but I couldn't find the correct js file for sc2, not even a reference to where it might be, so I figured the one client there was would work with both.\nBut anyhow, I'm guessing that's probably the cause of my problem then. Where can I find the sc2-client js?\nThe remarks you made about sc1 vs sc2 are things I had removed prior to running, since the docs stated they were unnecessary for sc2, but then it kept throwing errors so I added them back to see if it changed anything. It didn't help, but I haven't removed them again yet. I am going to set it right as soon as I get the whole thing working :)\nThe coffeescript is just my source code, it gets compiled to a javascript file which I then run, so the use of coffeescript couldn't really cause any errors.\n. @jondubois I installed it like that in an empty directory and copied the correct js file to my client, since I don't need all the other stuff. It now works perfectly :smiley: \nFor libraries I need in my client I usually just go to the github repo and download the js file from there, since that's all I really need. But there was no sc2-client repo that I could find so that's what confused me. I just needed that one js file to include in the client nwjs project, not the rest of the default setup, since I'm implementing socketcluster in existing code both server and client side (which used to use socket.io so a lot of the code is similar). So for my server I didn't install the default project either, I just installed the sc2 module and got what I needed for implementation from the docs. So perhaps you could offer the sc2 client files separately as well, instead of having to install it like that?\nIf most people already use sc2, it does sound like it may be time to make that the major version. But, do keep the original one alive as well, don't just pull the plug on it, in case people need a library that can fallback to polling (for web applications or simple web games that have to support older browsers).\n. Perhaps, upon initialising the Socketcluster server, it could show the version. Then, if a dev misses the announcement and just installs socketcluster thinking they'll get sc1, they could tell from the server log.\nIn any case, I think moving to sc2 as the main version is a good idea, as long as sc1 doesn't get forgotten/abandoned, since there are definitely still some cases where sc1 would be needed / preferred.\n. ",
    "tpeace": ":+1: \n. PS: SocketCluster is a great framework.  Thanks so much for all your hard work!\n. ",
    "IngwiePhoenix": "@jondubois Awesome news man, very nicely done! This comes in just at the right time as I am beginning to do profiling on my app. Thanks for your awesome work on this! :) #SCRocks\n. Very interesting! I didn't know that there was a difference. I will simply go and fork avs-rpc and add SC support, then! :) It has an inheritage mechanism built-in - this should allow me to easily make this one work.\nThanks for your response. =)\n. @gigerlin made it work now. :) Now SC can do events, streams and rpc - which, imho, is amazing!\n. The initializing part: http://git.ingwie.me/ingwie/bird3/blob/master/node-lib/socketcluster_worker.js\nThe worker: http://git.ingwie.me/ingwie/bird3/blob/master/node-lib/socketcluster/worker.js\nAssume config.BIRD3.http_port to be 80 and the config.BIRD3.host to be a valid IP.\nThen this error pops up:\n1430952453227 - Origin: Worker (PID 10752)\n    [Error] Error: bind EADDRINUSE\n    at exports._errnoException (util.js:746:11)\n    at cb (net.js:1195:33)\n    at shared (cluster.js:586:5)\n    at Worker.<anonymous> (cluster.js:561:9)\n    at process.<anonymous> (cluster.js:692:8)\n    at process.emit (events.js:129:20)\n    at handleMessage (child_process.js:324:10)\n    at child_process.js:408:7\n    at process.handleConversion.net.Native.got (child_process.js:97:7)\n    at process.<anonymous> (child_process.js:407:13)\nSo I don't even get to see where the error is caused... all I know is that it must happen before the module.exports.run method is called since there is no .listen call inside of it.\n. I checked. There are no other instances of my app. It works on my local Mac, but once deployed to the server, it does not. I suppose it has to do with the host issue.\n. I didn't use the NodeJS debugger or anything the like - i just started it up, that's all. :)\nAwesome news, I'll take a coding break for that time then, since i need to see my result on the server before i can continue. Good luck on this one! :)\n. Epic. going to try it out immediately.\n. It works! Thanks for this fix :)\n. And what about gathering current stats? When talking about monitoring, I am thinking about stuff like the amount of requests in a specific timeframe, amount of connected clients, etc. etc.\nWould there be a way to create, or pick up, such stats?\n. Hey.\nThanks for the infos! I was reading about nData just recently while I was exploring the SocketCluster organization - after all, SC is a vital part of my application in many ways. And thanks to your input, it just got one more task.\nConsidering that the cache is not persistent, I am working on a project on my own called FeatherWeight. It leverages the hprose protocol to enable cross-language communication. That way I could let the SC store run as it already is, but also access it through other services. Due to something I coded, I can pass NodeJS data into my PHP backend, allowing me to pass the current port or socket path easily.\nFeatherWeight stores it\u2019s cached data on disk when it goes down - it will listen to several \u201eshut down\u201c events to archieve this. When it is launched, it will restore it\u2019s memory from the cache.\nI could see nData doing something similar. :) When I progress in FeatherWeight, you can freely re-use some of my code. The current placeholder is hosted here: https://github.com/DragonsInn/FeatherWeight https://github.com/DragonsInn/FeatherWeight . \nAnd just a heads-up: SC is amazing =)\n. Ahh great, the second one will do! :) Thanks.\nI'll make sure to list my software in the \"using socketcluster\" repo once its running at least in Beta.\n. There is no practical way.\nSocketCluster uses child_process.fork in some places - which means, the original \"intro script\" is completely abandoned, leaving no room to just use CoffeeScript's require() \"registration\".\nThe only way this can really work is, by having SC an option that allows to prepare global scope, or even better, a function. In a similar project that I wrote exactly for problems like that and without many features which simply serves as a launcher, I did this:\njavascript\nPowerHouse({\n    master: function(){\n        // This function runs only on the master process.\n    },\n    child: function(){\n        // This function runs on all children.\n    }\n});\nSo basically, Socketcluster could serialize this .child method and execute it before it includes the actual script. That way, you'd get a brief chance to modify global scope. That should work around CoffeeScript's global registrar.\nThis is all I can say for now. The only alternative you have is to manually run the registrar and then require the CoffeeScript itself...which does, even to me, seem off. Just as an example:\n``` javascript\nSC({...controller: \"myfile.js\"});\n// myfile.js\nrequire(\"coffeescript/global\");\nrequire(\"myrealfile.coffee\");\n```\nForgive me if I got the global registrar wrong, I don't work with CoffeeScript. (: I only read about how it does it.\n. Oh nevermind! O.O I must've been waaaaay behind right there. Sorry for my, i think now, pointless answer. (:\n. There should really be a way to do some \"intro\" code for that stuff. I just made https://github.com/IngwiePhoenix/oj-note and would like to use OJ with SC. o.o\n. @jondubois : o.o\n``` javascript\nvar child = function(){\n    require(\"oj-node\");\n    require(\"coffee-script/register\");\n}\n// Serialize\nvar srl = child.toString();\n// ... send over...\n// Execute\nvar fn;\neval(\"fn = \"+srl);\n```\nYes, yes. Eval is evil and this is super hacky. BUT this is only one of many ways. In fact, there are people that did it beyond what I did: https://www.npmjs.com/package/funcster\nIt is nothing impossible, but I would advise taking the step to pick a 3rd party tool to do so. I have seen extended JSON implementations that simply serialized functions too.\nNow, how would that be used? Serialize the \"child preparation function\" and send it to the respective processes along with the configuration - deserialize it there and run it, THEN require the actual module. I can already see that this stuff happens already, in a way. When launching an SC system, a process is spawned which uses a SC internal file. Using this method to spawn the clients would give SC more control over the clients, and the possibility to obtain a serialized function and execute it before the rest.\nThat, at least, is how I would do it. :)\n. You can now modify the global namespace and \"prepare\" the worker object. Supply initController to SC. This file will be able to run before any other worker - meaning, that you can configure the execution context of the process. Add CoffeeScript's register script there, and voila, you can use CoffeeScript in your Worker/Broker controller!\n. @jondubois Well, good day. I basically have no internet at my dorm, so when i checked back here only to see so much response, I was like \"well, g'day man!\" XD.\nOkay, but now for real.\nAs I am not currently really internet-equipped, there is not much I can do as of right now. I do have  mobile data, so I will try to fork SC, commit changes into that, and PR it.\nAs you seem to like a sort of combination of the first and second approach - the configuration part and the callback part - I will be heading to implement that very thing.\nThe implementation will have the user supply the path to a module - much like the controllers are supplied as just the file paths. This module will then be loaded, the module.exported function executed with one next() parameter, which essentially triggers the next step.\nBut one things I would like to mention ahead: SC is huge, I'm small :). So I'll do my best to provide that PR!\n. @jondubois So I just took some time to look at the pieces of code you pointed out. For the WorkerController, it seems totally straight forward to add something by the lines of\njavascript\nthis.PrerunFunction = require(this._paths.prerunScript);\nthis.PrerunFunction.run(this);\nright above it, per-se.\nBut what about the other controllers? If the Broker is part of nData, what would be the most suitable way to pre-run a script on that one? I will look at the Broker related code next.\n. Looks like iocluster is the default module that is required for the Broker stuff. Can you point me towards the right spot to properly pick up in this module?\n. So - both, the actual socketcluster module as well as ndata need to understand the prerunScript option?\n. Alright. I better get started! :)\n. All PRs have landed:\nhttps://github.com/SocketCluster/socketcluster/pull/121\nhttps://github.com/SocketCluster/iocluster/pull/3\nhttps://github.com/SocketCluster/ndata/pull/18\nGot myself a pizza and some good music and put the changes in. I also have extended the sample app to test the new stuff. It works well! :) \nlet me know if there is anything that I need to fix. (I love puns.)\n. @jondubois I did, on ioCluster, nData and SC. :) All you gotta do is test it.\nAnd, thanks! I am depending on this change, it's why im pushing so much for it, to be honest. :)\n. Aaaawesome! :)\nGoing to update my project to use ^2.3.22 and I should be all good.\nGlad it worked out =)\n. Alright - works for me. Just decided to add it in, for testing purposes as well. That is how I tested the xhanges, actually. :)\n. I\u2019ll take care of writing the doc page. I have a lot of time on my hands, so I don\u2019t mind!\nSC is an awesome project, so contributing to it is really awesome. :) I don\u2019t get to put something up to a nice project very often.\n. And there you go!\nI was surprised to find myself looking at AngularJS HTML. I haven'T used Angluar, ever. Anyway, I added some documentation about it. I moved the special note to the bottom so it doesn't jumpscare the user right away.\n. @jondubois Still waiting for merging:\nhttps://github.com/SocketCluster/socketcluster-website/pull/4\nJust letting you know in case you'd overseen it. :)\n. Use Redis events - or something else - and rely the events through the Broker process.\nI am not a python expert, but this should work.\nJust remember, this is pseudo-code. o.o\nscript.py\npython\nimport redis\nredisCon = redis.connect()\nchannel = redisCon.subscribe(\"SCBridge\")\nchannel.publish({ \"toChannel\": \"foo\", \"data\": \"My Message\" })\nbroker.js\njavascript\nmodule.exports.run = function(broker) {\n    var redis = require(\"redis\");\n    var conn = redis.createClient();\n    conn.on(\"message\", function(channel, data){\n        if(channel == \"SCBridge\") {\n            // Assuming that the sent data is JSON\n            try {\n                var o = JSON.parse(data);\n                broker.publish(o.toChannel, o.data);\n            } catch(e) {\n                // Nope, not a JSON.\n                console.error(\"Data has been sent to SCBridge that is no JSON.\");\n                console.error(data);\n            }\n        }\n    });\n}\nI did not see a way to do actual eventing... But I bet you could utilize a Worker for this. Although it is not entirely their task, you could theoretically create a similar setup like above, except that instead of using broker.publish, you'd use something like worker.scServer.global.emit(evName, evData)...\nDocs:\nBroker http://socketcluster.io/#!/docs/api-broker\nSCSocket on Worker http://socketcluster.io/#!/docs/api-scsocket-server\n. You can either use the socketcluster-client on the other server or use a Redis bridge; i.e., if the broker process and the \"remote\" are both able to connect to the same redis, you can send messages into a Redis channel, pick them up from the Broker process, which can then emit to the SC clients it has.\n. Hey @roblav96 !\nGlad to hear that you are almost ready. In order to help you, I will take excerpts from my own source code. Because, believe it or not, I am doing exactly that already within development in order to make sure that things actually work.\nSince I didn't want ot use pm2 for my project, but a simpler project, I coded PowerHouse. In it, I can declare two kinds of workers; a child process and a forked process. They do sound similar, don't they?\nAnd that is exactly where I ran against with SocketCluster.\nInside Node, you have two API's to create a new node instance:\n- child_process.fork(script): Spawn a new process using the specified script.\n- cluster.fork(): Create a copy of the current process and assign it as a child to this one.\nThis second one is SUPER important. Because if you use the ChildProcess method, cluster.isMaster() will return true in both processes. Also, within a ChildProcess forked process, the supplied script is the main one. So if it forkes inside there again, that script is always the main entry point.\nNow that this is sorted, here are some things that you might want to know:\n- SocketCluster uses child_process.fork to spawn the worker process manager: https://github.com/SocketCluster/socketcluster/blob/master/lib/workercluster.js#L48\n- cluster.fork is used inside the manager to spawn the real workers.\n- child_process.fork is used to spawn the broker process, which ACTUALLY is an nData instance: https://github.com/SocketCluster/ndata/blob/master/index.js#L33\nYeah, that was one dive, right? And the answer?\nLaunch your SC server as a child_process.fork instance.\n- The process will think it is it's own, but it is not.\n- SocketCluster will work just as expected.\n- You can talk to the child using events, just like usual.\nYou can use the process' message event to communicate via JSON. You could also use some kind of RPC library like hprose to share functions, or to control the child process via remotely called functions. Your beer. :)\nI never worked with pm2, but what I would suggest you is to make sure that your SC server runs as an isolated process through a ChildProcess fork. You can still use the sc-client or redis events to talk to the cluster - but, that is what I would recommend. In fact, that is exactly what I am doing myself!\nTo demonstrate:\n- Starting:\n  - https://github.com/DragonsInn/BIRD3/blob/yii1_to_laravel5/app/bootstrap/nodejs/app.js#L51-L57\n  - https://github.com/DragonsInn/BIRD3/blob/yii1_to_laravel5/app/Backend/Service/SocketCluster.js\n- Communicating: https://github.com/DragonsInn/BIRD3/blob/yii1_to_laravel5/app/Backend/Communicator.js\nRedis acts as a global eventer. SC's broker process is aware of that using the sc-redis stuff. The web server process doesn't really care, since most communication is for backend stuff.\nI hope this could give you an idea on hwo to setup your pm2 to properly run SC! :)\n. Or, you use the new initController param.\nThat allows you to have one file that calls the babel registrar for you. That is exactly what this is meant for :)\n\nAm 21.11.2015 um 01:12 schrieb Matt Krick notifications@github.com:\nIn my case, I already had a worker written in es2015 syntax. Unfortunately, since my file is called via a dynamic name instead of a require, i get 'reserved word' errors. The easiest fix (albeit not super eloquent) is to stick this at the top of the 2 files in the lib: require('babel-core/register');\n\u2014\nReply to this email directly or view it on GitHub https://github.com/SocketCluster/socketcluster/issues/135.\n. Funnily, I was the one who introduced and PRd this feature - its pretty new, yknow :)\nSo no worries! Thats what questions are for.\n\nEnjoy!\n. You can use SC with ES6, no problem.\n``` javascript\n// Import:\nimport SocketCluster from \"socketcluster\";\nvar sc = new SocketCluster({\n    brokerController: require.resolve(\"./mybroker.js\")\n});\n// In mybroker.js:\nexport var run = function(worker) {\n    // ...\n}\n```\nIn theory, this should work.\n. Also, to load stuff like registrars, use the initController option.\n. Mine. I'll upload it for you real quick (:\nI need to commit my changes, anyway... So give me a sec and youll have an example! ^^\n. Ta-da.\nhttps://github.com/DragonsInn/BIRD3/blob/master/app/Backend/Service/SocketCluster.js\n. Are you aware, that  worker.js is a new process?\nIn order to make it ES6 aware, use initController.\nInstantiation: https://github.com/DragonsInn/BIRD3/blob/master/app/Backend/Service/SocketCluster.js#L18-L20\nThe individual files: https://github.com/DragonsInn/BIRD3/tree/master/app/Backend/SocketCluster\nI highlighted the relevant lines for you. Please see the mentioned files, to understand the flow.\n. I was the one to implement that feature for SC, for the sole reason of being able to drop registrars in, to allow custom JS dialects and transpilers to work. :).\n. Thats not possible. The files are being used to render a new process, so you can not drop arbitary objects there, instead you'll need to supply the path to a module that can be run instead.\n. Your research wasn't deep enough:\nhttps://github.com/SocketCluster/socketcluster/issues/134#issuecomment-156849430\nI had done this research on my own for a system I am coding, its also part of BIRD3. Read the linked post, it should be able to give you some insights of the forking and clustering done in SC. This will also explain why you can't just throw objects around - i.e., classes.\n. Glad you got it working! :)\nHave fun with ES6!\n. Of course it does. initController was designed for that very purpose, to allow you to modify the global execution context. Are you using babel-register correctly? You need to explicitly call the function it returns - a mistake some people tend to do.\n. Odd. It should. I mean, I do the very same thing and it works. Hm\u2026\nYou can see my working stuff here: https://github.com/dragonsinn/bird3/tree/master/app/Backend/SocketCluster https://github.com/dragonsinn/bird3/tree/master/app/Backend/SocketCluster\n. Actually youre right. I re-wrote my broker. Im going to send a proper PR to fix that. Since i am the one that made initController, i should also fix it ^^\n. Yup. just wanted to post the same. Im going to hotfix it.\n. Well I just tried something else, and that actually avoids fixing!\n``` javascript\n// Enable OJ support inside NodeJS\nrequire(\"oj-node\");\n// Bring in babel\nrequire(\"../../bootstrap/nodejs/autoload\");\n// Enable Uniter support\n//require(\"uniter-node\");\nmodule.exports.run = function(thisWorker) {\n// Time to bootstrap workers.\n\n// Put a global BIRD3 object in place\nglobal.BIRD3 = require(\"../../Support/GlobalConfig\");\n//if(thisWorker.kind == \"worker\") { require(\"../Communicator\")(redis, sc); }\n\n}\n```\n(ignore my comments...)\nYou can also just supply an empty run method. But for reigstrars, just add them outside of it. I will think of a better way by fixing this code, so it is symmetric to SCWorkerCluster...but for now that will do.\n. https://github.com/SocketCluster/ndata/pull/19\n. I also use OS X and never had this issue.\nCan you provide some version numbers?\n. Check for zombie processes. You might have a process using the very port here - or it is a debug port problem. But check for zombie procs first.\n. I know that hprose's serializer can do references just fine:\n```\n\nvar hprose = require(\"hprose\")\nundefined\nvar a = { foo : 42 }\nundefined\na.ref = a;\n{ foo: 42, ref: [Circular] }\nvar out = hprose.serialize(a)\nundefined\nout.toString()\n'm2{s3\"foo\"i42;s3\"ref\"r0;}'\n```\n\nhttps://github.com/hprose/hprose-nodejs\nYou should be able to use the serializer and de-serializer independently of the rest.\n. How about using the broker process and forwarding events through that one? You dont need to spawn too many broker processes, so you could effectively reduce those, while keeping the amount of worker processes higher.\n. ",
    "ayZagen": "@jondubois http2 is stable now. I tried httpServerModule option but it seems not working. \nEDIT: I found that we could override createHTTPServer in workers. Still http2 is not working because of websocket libraries lacking support of it. Did some research and created a new issue for it. Please see @/SocketCluster/socketcluster#465. Great framework but we need clients at least in most used languages in mobile technologies such as swift and android.. ",
    "vnistor": "Interested in this as well.\n. 9ccdf2479a1fb603332da5f0fd4d21af36c20025 seems to have fixed the issue. Much appreciated.\n. ",
    "rrNuvoPoint": "Look perhaps at https://github.com/sahat/satellizer and the nodeJS module. It works for me :+1: \n. ",
    "madwill": "It does illustrate the point!\nThank you. \nWhat i was looking for was:\nwsServer.global.add(['rooms', 'cats'], message, res);\nwsServer.global.get(['rooms', 'cats'], res);\nSo i can share information between workers. The rest should be easy. The \"username channel\" was only to be able to find the way back to the initial connecting user. But its absolutely non necessary if i can access the store synchronously with globals.\nAny draw back to this ? Does it slow down requests and potential overall performances ?\nPerhaps this works like cluster hub ? https://github.com/fent/clusterhub ? With in memory key/value pairs synced through the all workers ? So under the hood it its non blocking. \nThanks again!\nPs: It would be nice to add a get and set in the socketCluster example app that comes with creating a new app for newcomers in this technology. \nSince your service appeal to the \"user friendly\" crowd. \n. I guess it could possibly work with https://github.com/jondubois/socket.io-ndata now that i look at your profile :)\n. Ok. \nMy previous experience is with Java, which if we were to put a synchronized data storage in threads you would defeat the thread purpose. \nI'll have a look at how global object works. Try and understand how data in globals can be shared between multiple workers.\nMerci pour tous. \n. ",
    "bencevans": "Please ignore, think I just had it running in the background...\n\n. ",
    "hery84": "@jondubois tested with \"sc-redis\"... Everything works perfect! Thx for the reply.\n. ",
    "bguiz": "Thanks for the super quick answer!\nW: http://bguiz.com\nOn 27 June 2015 at 21:22, Jonathan Gros-Dubois notifications@github.com\nwrote:\n\nThe docs are valid for both v1 and v2 - The general pattern hasn't\nchanged. I should probably update that page to make it sound more current.\nYou can setup a channel for each user and also have group channels shared\nbetween multiple users. So you could have a channel called 'web_developers'\nand all users who are web developers could subscribe to it. You can have\nmore than one channel per client, in fact SC lets you have up to 1000 per\nclient by default (you can configure this to be even higher if you need).\nSC is efficient about how messages are delivered so you don't have to\nworry about subscribing to lots of channels per client.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/SocketCluster/socketcluster/issues/80#issuecomment-116013764\n.\n. \n",
    "Llorx": "Just that is what I was thinking for. In this way: The chat server will have a backlog of 30 seconds with a timestamp for each chat message, and when a user reconnects, it will send the timestamp of the last message received, so the server will know what data has to send to have the user up to date. I don't think that a reconnect will last more than a few seconds in the worst scenario, that's why I only will have a backlog of 30 seconds. If someone lasts more than 30 seconds in reconnecting, then he will be treated like he has a connection problem and his chat client will show so. Fairly reasonable because a server having 1000 messages per second (that's a bunch of messages) and each message being a maximum of half a Kb, that only makes 15 Mb of data.\nThe second approach is not that bad. The server will send a message that is going to be closed in 30 seconds to the clients. The clients then will reconnect to another server and when they reconnect to a second server they will close the connection to the first server. The same as above, in the worst scenario, if an user lasts so many seconds in reconnecting to another server he will be treated like he has a connection problem, just what is actually happening.\nI think that I'm going for the first one, but you gave me a great idea for the future in applications that manage great amounts of data where storing them for future fetch can eat big amounts of memory or where is a bit difficult to have timestamps and check them in each reconnect whitout eating too much CPU. Also the second approach is good for ultra realtime applications, because there will be all the time a writable and readable socket, so they don't have a small pause when one socket loses the connection and reconnects to another server.\nThank you for your reply.\nBtw, I asked just in case the engine has (or thinking in adding) some sort of built-in thingy to workaround this. They made a really good work making a framework that has multiple workers and we just have to focus in client connections and data, so having some builtin thingy to workaround this will make this the best cluster framework out there (just in case someone doubt it xD).\n. ",
    "leedium": "Wonderful!  Thanks mang!  Great Work by the way.  You've saved me NUFF time with what I'm trying to do.\nCheers!\n. OK so..... need some assistance here, am I missing something?\n``` javascript\n  scServer.addMiddleware(scServer.MIDDLEWARE_SUBSCRIBE, function (socket, channel, next) {\nif(!socket.isSubscribed(channel)){\n  socket.global.unsubscribe();\n  socket.global.subscribe(channel);\n  next();\n}else{\n  next('sorry you are already subscribed to this channel');\n}\n\n});\n```\nThe failure condition never fires even though i'm unsubscribing on the client side.  It just keeps subscribing to new Channels which are pending.  If  I don't add the server subscribe it just keeps appending to the same channel, so when messages are sent I get multiple.  Do I need to subscribe through the server using the middleware as well?\nThoughts?\n. Hey Jon! Trust me, it's probably my code.\nThanks for the great response and explanations.  I will try your suggestions and let you know.\nLovin' SC!\nD.\n. Awesome, thanks mang... wow, I must say this version is WAY cleaner than the one I was using 8 months ago..  (I'm back on this...) lol.  Thanks for all your hard work!!\n. ",
    "seiyria": "Is this still a valid way to get a ref to a channel on the server side? The global api link above is broken.\n. Ah, of course, thank you.\n. It's easy to scale horizontally - heroku ps:1 (where 1 is the number of dynos, I believe).\nFrom where I stand, one client connects to an instance, and right now there is nothing but that. I plan to eventually have a store or two dedicated to certain bits of data but those will only be for small groups of clients at most.\nI think you answered my question though - I'll probably focus on scaling workers first, then dynos if I run into problems. Thanks!\n. Interesting. So, I misread the docs. The primary issue is that I was supposed to be using publish instead of emit (in my client code). However, this raises a question - is it not possible to use a channel like an emitter, but just to a limited set? I think I will have to go with my first approach and just do it a bit differently. \nI also am wondering how I can emit something to a server, and in turn, have the server emit to N clients - I don't have any of those variables scoped, and I'm not sure it's wise to hold references to other sockets.\nHowever, the primary issue here is closed so I will close this issue. I am not sure why I wasn't getting errors on on (on the server) or emit (on the client) though, I do think that is an error that should throw an exception.\n. @jondubois - I'm running 4.3.2 right now. The problem was actually a problem in my code, for sure, where I had a recursive structure I was trying to serialize (it was an ES6 promise - I forgot to use await and instead just called a function that returned a promise). To be clear, my problem was that I had no idea where that stack trace was originating (it only showed internal errors in socketcluster).\n. I think I definitely want to be told that my object is circular - I definitely didn't intend for it (maybe having this as an option would be good!). I was just having problems with figuring out where the circular object came from.\n. No, it looked like this:\n1456704624387 - Origin: Worker (PID 2757)\n   [Warning] Error: Cannot traverse circular structure\n    at convertBuffersToBase64 (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/sc-formatter/index.js:52:11)\n    at convertBuffersToBase64 (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/sc-formatter/index.js:75:21)\n    at convertBuffersToBase64 (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/sc-formatter/index.js:75:21)\n    at convertBuffersToBase64 (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/sc-formatter/index.js:75:21)\n    at Object.module.exports.stringify (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/sc-formatter/index.js:83:22)\n    at Emitter.SCSocket.stringify (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/socketcluster-server/scsocket.js:208:20)\n    at Emitter.SCSocket.sendObject (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/socketcluster-server/scsocket.js:214:16)\n    at /Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/socketcluster-server/scsocket.js:249:14\n    at EventEmitter.SCServer.verifyOutboundEvent (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/socketcluster-server/scserver.js:684:5)\n    at Emitter.SCSocket.emit (/Users/seiyria/GitHub/backend/node_modules/socketcluster/node_modules/socketcluster-server/scsocket.js:227:17)\nCannot traverse circular structure\nFor reference, my error handling looks like this:\n```\n    scServer.on('error', e => console.error(e.message));\n    scServer.on('notice', e => console.info(e.message));\nscServer.on('connection', socket => {\n\n    socket.on('error', e => console.error(e.message));\n\n```\n. Even with that, the stack trace is the same.\n. It's tough to nail down something small, but I'm thinking async/await is factoring into this mess somehow. I'm on node 4.2.2. I haven't tried longjohn, but I'll give it a try tomorrow.\n. Strangely, longjohn doesn't work either. I'm not sure what's up, but, I'm not sure if this is anything you can adjust at this point. While I can't provide you a working demo, here's the gist of it:\n```\n // nearbymonsters.js\nexport default async ({ lat, lon }, playerLevel) => {\nreturn new Promise((resolve) => {\n    resolve([]);\n});\n\n};\n```\n// somewhere above: import nearbyMonsters from './nearbymonsters';\n        const monsters = nearbyMonsters(player.homepoint, player.currentLevel);\n        // normally you'd do await nearbyMonsters instead of just nearbyMonsters\n        socket.emit('update:monsters', monsters);\nThat said, if this is out of your control entirely, feel free to close it.\n. Well, the situation I'm in is that I'm sending a lot of data to a client. Clients are on mobile devices and my server is hosted on heroku. Some of the things I send via socket are large sets of data, and I'm trying to lower the size that I send. I'm not worried about computational power on client or server right now because the target devices are pretty powerful and the server is scalable (usually network connectivity is the problem). Because of this, I figured that it would be wise to send either jwt-compressed bits or something.\nTo be specific on what exactly I'm making: I have monsters that are generated for players. They can be a bit large, data-wise (though I'll work on compressing them). I send 650-850 of them to a client per request (generally, per hour or per login). I figured generating a jwt token per monster would be better for sending them in that quantity, instead of sending the raw object. They look like this:\n{\n            \"name\": \"Goblin\",\n            \"profession\": \"Monster\",\n            \"professionLevels\": {\n                \"Monster\": 1,\n                \"Thief\": 1,\n                \"Fighter\": 1,\n                \"Mage\": 1\n            },\n            \"statusEffects\": [],\n            \"stats\": {\n                \"gold\": 0,\n                \"xp\": {},\n                \"hp\": {\n                    \"minimum\": 0,\n                    \"maximum\": 5,\n                    \"__current\": 5,\n                    \"booster\": 0\n                },\n                \"mp\": {\n                    \"minimum\": 0,\n                    \"maximum\": 3,\n                    \"__current\": 3,\n                    \"booster\": 0\n                },\n                \"str\": 1,\n                \"vit\": 9,\n                \"dex\": -1,\n                \"mnt\": 2,\n                \"luk\": 0,\n                \"acc\": -1\n            },\n            \"skills\": [],\n            \"inventory\": [],\n            \"equipment\": {\n                \"weapon\": {\n                    \"itemId\": \"41eba92d-7aab-4cd9-aa1b-7bcdd83f307e\",\n                    \"name\": \"Claw\",\n                    \"stats\": {},\n                    \"levelRequirement\": 1,\n                    \"quality\": 0,\n                    \"value\": 0,\n                    \"type\": \"weapon\"\n                },\n                \"armor\": {\n                    \"itemId\": \"9a268717-142d-4333-a75c-379fde317ddb\",\n                    \"name\": \"Fullplate\",\n                    \"stats\": {\n                        \"vit\": 8,\n                        \"dex\": -2,\n                        \"acc\": -1\n                    },\n                    \"levelRequirement\": 1,\n                    \"quality\": 0,\n                    \"value\": 23,\n                    \"type\": \"armor\",\n                    \"dropRate\": 25\n                },\n                \"profession\": {\n                    \"stats\": {\n                        \"str\": 1,\n                        \"mnt\": 2,\n                        \"dex\": 1,\n                        \"vit\": 1,\n                        \"luk\": 0.3,\n                        \"acc\": 0\n                    }\n                },\n                \"buffs\": {\n                    \"stats\": {}\n                }\n            },\n            \"unlockedProfessions\": [\n                \"Thief\",\n                \"Fighter\",\n                \"Mage\"\n            ],\n            \"cooldowns\": {},\n            \"slug\": \"MON-1\",\n            \"id\": \"58bebdd0-ab05-43a2-9b05-7ed0e3db7646\",\n            \"bonusXp\": 0,\n            \"seed\": 1457067600563,\n            \"verifyToken\": \"049c7cb45bbc5a1025195e3a66f62974\",\n            \"location\": {\n                \"lat\": 44.031542946243775,\n                \"lon\": -88.55779830910286\n            },\n            \"rating\": -2,\n            \"goldDrop\": \"1d4\"\n        }\nIn this, I generate a verifyToken based on some data so the client can't spoof any data about a monster. They send the monster + the token back to the server and the server verifies that the monster was generated correctly. I might be doing it entirely incorrectly, though.\nUnfortunately none of this data is cached, it's recalculated hourly also. Each client has  their own unique set of data that's calculated hourly, on top of that. \n. Alright. I squared away my issue. Surprisingly it was a rendering issue in testing, though I haven't determined if bandwidth or rendering will be the problem in production. If it is, I found that JSONPack gives me approximately 40% savings in compression of 750 of the above objects, so that's the route I'll go. Not sure I'll use middleware since I don't think those can be added on the client(?) and it shouldn't be added for endpoints that aren't a lot of data, anyway.\n. Awesome, thanks @jondubois!\n. No problem. I tried it out real quick and when it didn't work, I knew what to look for. If nothing else, hopefully it will help someone searching the tracker like I was doing.\n. ",
    "batazor": "I have a few workers https://gist.github.com/batazor/0bb20efe76f8ab858179\nI get so many messages as I launched workers, I can get only one message at\na running vorkers?\nSorry for my English.\n. Thanks. This option is not very suitable. Probably you will need to use\nsomething else.\n2015-07-30 16:34 GMT+03:00 Jonathan Gros-Dubois notifications@github.com:\n\nThebidea of workers is that they share the same code so if u only want one\nworker to do something, u should check worker.id\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/SocketCluster/socketcluster/issues/94#issuecomment-126326287\n.\n. Sorry.\nThanks. This option is not very suitable. Probably you will need to use\nsomething else. -> Maybe I need to use something else.\n\n2015-07-30 16:49 GMT+03:00 \u0412\u0438\u043a\u0442\u043e\u0440 \u041b\u043e\u0433\u0438\u043d batazor111@gmail.com:\n\nThanks. This option is not very suitable. Probably you will need to use\nsomething else.\n2015-07-30 16:34 GMT+03:00 Jonathan Gros-Dubois notifications@github.com\n:\n\nThebidea of workers is that they share the same code so if u only want\none worker to do something, u should check worker.id\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/SocketCluster/socketcluster/issues/94#issuecomment-126326287\n.\n. \n\n",
    "mvaullerin": "Thanks for the quick answer.\nIndeed it's work very well.\nI've tried before, but it didn't work, that's why I've ask...\nI don't know why it's working now...\nThanks again !\n. Yeah I load the script from a different host.\nI'm on it, I try to add the socket domain to the cookie generated with SCSocket.prototype._setCookie.\n. I've create a PR on socketCluster Client for this issues :\nhttps://github.com/SocketCluster/socketcluster-client/pull/18\n. ",
    "waltergms": "Understood... \nSo im migrating from Socket.IO to SocketCluster.IO... I have all working using a array of rooms and inside each room i have a array of users, the question is... Are this arrays shared between workers? Or i have persist that list on database to make it visible for all workers? Because if i need to put it on database is easier to me do it on my soket.io system that is already working but arrays arent shared when using pm2 to make clusters...\n. By the way, walking with the company standards, im using Sequelizer to make the ORM and database transactions with MSSQL database.\n. Thank you Jonathan, we currently have a traffic about 1k~10k users online and something about 70k connections/day, i will try to use SC with all the controll on the database and see what we got... I tell you latter.\nThanks\n. Sorry i was using the wrong profile...\nHi Jonathan!\nI have applied the database to controll all the online visibility between users as we talk back, now im getting this errors when i run the app... \n1439928974153 - Origin: Worker (PID 5220)\n    [Notice] Error: Socket Error: Client pong timed out\n    at Emitter.SCSocket._onSCClose (X:\\node_modules\\socketcluster\\lib\\server\\scsocket.js:173:17)\n    at null. (X:\\node_modules\\socketcluster\\lib\\server\\scsocket.js:144:10)\n    at Timer.listOnTimeout (timers.js:110:15)\nand after some time\n1439929225921 - Origin: Broker (PID 4936)\n    [Error] Error: This socket is closed.\n    at Socket._writeGeneric (net.js:656:19)\n    at Socket._write (net.js:709:8)\n    at doWrite (_stream_writable.js:301:12)\n    at clearBuffer (_stream_writable.js:411:7)\n    at onwrite (_stream_writable.js:344:7)\n    at Socket.WritableState.onwrite (_stream_writable.js:105:5)\n    at WriteWrap.afterWrite (net.js:787:12)\n1439929228725 - Worker 2 exited - Exit code: 0\nSome tips?\n. I will make some changes in order to treat these potential openings that may be sending to sockets that have already been closed, but I have some fear that these closed sockets are receiving the events that are published by \"socket.global.publish\" because I always use this method to send a message to a specific user or to a group (room) users. On the client side, the event \"socket.disconnect\" I always do a loop in the channels the user is subscribed and remove them with the command \"channel[x].unsubscribe(userRooms [y])\" and that channel is an instance of the channel (channel [x] = socket .subscribe (userRooms [x]).\nTaking advantage to take a doubt ... there is another method of sending an event to a particular user without using global.publish?\n. Im using socket.emit only in cases that i have to return something to the same person that call the server for some reason, eg.: \"make a socket.emit to the server to get some info for myself\".. all the communications between user to user OR server to users im using global.publish\n. This happens on production only... Im making some code changes, hopefully i will get some better understanding of what is causing the problems...\nabout the versions used, i belive im using the latest...\n    \"socketcluster\": \"2.3.x\",\n    \"socketcluster-client\": \"2.3.x\",\n. No.. just the default code..\nmodule.exports.run = function (broker) {\n  console.log('   >> Broker PID:', process.pid);\n};\n. In my test environment im getting disconnected after some seconds... :|\n. Yes...\nvar socketCluster = new SocketCluster({\n    workers: Number(argv.w) || 4,\n    brokers: Number(argv.b) || 1,\n    port: Number(argv.p) || 8090,\n    appName: argv.n || null,\n    workerController: __dirname + '/worker.js',\n    brokerController: __dirname + '/broker.js',\n    socketChannelLimit: 50,\n    rebootWorkerOnCrash: argv['auto-reboot'] != false,\n    pingTimeout: 5000,\n    pingInterval: 2000\n});\n. using that ping options i need to put in the code that scheme of pinging the client time to time?\n. var interval = setInterval(function () {\n  socket.emit('rand', {\n    rand: Math.floor(Math.random() * 5)\n  });\n}, 1000);\n. What probably could cause the client disconnection?\n. Looks like the disconnection problem has been fixed... :+1: \n. yes... the worker is restarting... but i don't have implemented nothing on brokers... \n. Just restart the server... in my environment... \n. 1440015569109 - Origin: Worker (PID 7580)\n    [Error] Error: Failed to unbind socket from io cluster - nData Error - The u\nnsubscribe action timed out\n    at X:\\node_modules\\socketcluster\\lib\\server\\scserver.js:235:32\n    at bound (domain.js:254:14)\n    at runBound (domain.js:267:12)\n    at X:\\node_modules\\socketcluster\\node_modules\\iocluster\\index.js:608:5\n    at X:\\node_modules\\socketcluster\\node_modules\\iocluster\\node_modules\\async\\l\nib\\async.js:428:21\n    at X:\\node_modules\\socketcluster\\node_modules\\iocluster\\index.js:725:19\n    at EventEmitter. (X:\\node_modules\\socketcluster\\node_modules\\iocl\nuster\\node_modules\\async\\lib\\async.js:428:21)\n    at X:\\node_modules\\socketcluster\\node_modules\\iocluster\\index.js:786:26\n    at cb (X:\\node_modules\\socketcluster\\node_modules\\iocluster\\node_modules\\nda\nta\\index.js:320:26)\n    at bound (domain.js:254:14)\n    at runBound (domain.js:267:12)\n    at null._onTimeout (X:\\node_modules\\socketcluster\\node_modules\\iocluster\\nod\ne_modules\\ndata\\index.js:247:11)\n    at Timer.listOnTimeout (timers.js:110:15)\n1440015569828 - Origin: Broker (PID 3392)\n    [Error] Error: write EPIPE\n    at exports._errnoException (util.js:746:11)\n    at Socket._writeGeneric (net.js:690:26)\n    at Socket._write (net.js:709:8)\n    at doWrite (_stream_writable.js:301:12)\n    at writeOrBuffer (_stream_writable.js:288:5)\n    at Socket.Writable.write (_stream_writable.js:217:11)\n    at Socket.write (net.js:634:40)\n    at EventEmitter.self.write (X:\\node_modules\\socketcluster\\node_modules\\ioclu\nster\\node_modules\\ndata\\node_modules\\ncom\\index.js:82:17)\n    at send (X:\\node_modules\\socketcluster\\node_modules\\iocluster\\node_modules\\n\ndata\\server.js:64:10)\n    at Object.actions.subscribe (X:\\node_modules\\socketcluster\\node_modules\\iocl\nuster\\node_modules\\ndata\\server.js:345:5)\n1440015569828 - Origin: Broker (PID 3392)\n    [Error] Error: This socket is closed.\n    at Socket._writeGeneric (net.js:656:19)\n    at Socket._write (net.js:709:8)\n    at doWrite (_stream_writable.js:301:12)\n    at writeOrBuffer (_stream_writable.js:288:5)\n    at Socket.Writable.write (_stream_writable.js:217:11)\n    at Socket.write (net.js:634:40)\n    at EventEmitter.self.write (X:\\node_modules\\socketcluster\\node_modules\\ioclu\nster\\node_modules\\ndata\\node_modules\\ncom\\index.js:82:17)\n    at send (X:\\node_modules\\socketcluster\\node_modules\\iocluster\\node_modules\\n\ndata\\server.js:64:10)\n    at Object.actions.subscribe (X:\\node_modules\\socketcluster\\node_modules\\iocl\nuster\\node_modules\\ndata\\server.js:345:5)\n    at Socket. (X:\\node_modules\\socketcluster\\node_modules\\iocluster\\\nnode_modules\\ndata\\server.js:406:34)\n1440015569828 - Origin: Broker (PID 3392)\n    [Error] Error: This socket is closed.\n    at Socket._writeGeneric (net.js:656:19)\n    at Socket._write (net.js:709:8)\n    at doWrite (_stream_writable.js:301:12)\n    at writeOrBuffer (_stream_writable.js:288:5)\n    at Socket.Writable.write (_stream_writable.js:217:11)\n    at Socket.write (net.js:634:40)\n    at EventEmitter.self.write (X:\\node_modules\\socketcluster\\node_modules\\ioclu\nster\\node_modules\\ndata\\node_modules\\ncom\\index.js:82:17)\n    at send (X:\\node_modules\\socketcluster\\node_modules\\iocluster\\node_modules\\n\ndata\\server.js:64:10)\n    at Object.actions.subscribe (X:\\node_modules\\socketcluster\\node_modules\\iocl\nuster\\node_modules\\ndata\\server.js:345:5)\n    at Socket. (X:\\node_modules\\socketcluster\\node_modules\\iocluster\\\nnode_modules\\ndata\\server.js:406:34)\nThe scenary is: 24k channels\n1.3k users online\nEventually the client receive a socket hangup, i don't know why the connection is losing the communication with the server... \nUncaught Error: Socket hung up   [ socketcluster.js:685 ]\n. Good morning Jonathan, I'm working vacation starting today, my colleague will make the necessary adjustments, it should continue testing and to contact you today. Thank you very much for your attention, i hope we can get this working 100%\n. We have a meeting with the infrastructure team and we have decided to move to a mini-farm of 2 computers running linux... So, lets forget about it for now.\n. Really? WOW!\nSo the only ajusts that i have to do is change the broker.js to attach sc-redis to broker and in server.js specify in the broker options the host and port for the redis?\n. Another thing i was forgetting...\nShould i use more than 1 broker on each socketcluster instance? Today im using 4 workers and 3 brokers on 1 socketcluster instance with no horizontal scale.\n. Good mornin Jonathan my good friend!\nGreat news, everything is working almost perfect... Now we have 2 servers running linux and a farm server making the balance between them.. The only issue that are preventing we reach perfectness is a latency on client connection... its getting around 1 minute after load all stuff and connect socket to receive data back from server... Do you have some clue what could be slowing things down?\n. Man you are the \"MAN\"\nI change the load balance from the company that hold our servers and im using yours LoadBalancer now... the latency has gone, everything is fine now!\n. \nsocketChannelLimit is already set to 1000. This should be configured on server instance not on client :)\nSolved!. ",
    "kaviproject": "Its working. Thank you for your time.\n. I have other question related to server side debugging. I am not able to hit debugging point on worker.js code.\nI am running node-debug worker.js in one window and other window node server --debug-workers.\nPlease let me know how to debug worker.js on server side.\njavascript\n  socket.on('disconnect', function () {\n      debugger;\n      console.log(socket.remoteAddress);\n      console.log('User disconnected');\n    });\nIts printing user disconnected message on the server but its not hitting debugger statement.\n. Thank you for the information.\n. ",
    "welberty": "Good morning Jonathan, I am a colleague of Walter. I made several adjustments and the server is behaving right now, the only problem I still have is the memory consumption. I believe that a garbage collector solve, but when I try to use the \"global.gc ()\", an exception is thrown and random way.\nHow do I use a garbage collector with socketCluster?\n. Thank's for your attention. With the update of the socketCluster global.gc () worked fine.\n. I have another problem.\nI use a table in the database to store the socket IDs of users, so that I know which users are online. In evenrto disconnect socket remove this table and put the User and offline. It turns out that due to some errors Evente disconnect the socket is not raised, below one of reccorentes errors.:\nTue Sep 01 2015 11:38:31 GMT-0300 (E. South America Standard Time): Error: Socket Error: Socket hung up\n    at Emitter.SCSocket._onSCClose (Y:\\node_modules\\socketcluster\\lib\\server\\scsocket.js:173:17)\n    at WebSocket. (Y:\\node_modules\\socketcluster\\lib\\server\\scsocket.js:44:10)\n    at WebSocket.emit (events.js:110:17)\n    at WebSocket.cleanupWebsocketResources (Y:\\node_modules\\socketcluster\\node_modules\\ws\\lib\\WebSocket.js:926:10)\n    at Socket.emit (events.js:129:20)\n    at net.js:459:14\n    at process._tickDomainCallback (node.js:381:11)\n. ",
    "safiresh": "Hai Team, \nI am new for socketcluster. \nServer SC version : 3.0.0 \nClient SC version : 3.1.1 \ni got this below this issue \n1452426873250 - Origin: Worker (PID 2641)\n   [Notice] Error: Socket Error: Client pong timed out\n    at Emitter.SCSocket._onSCClose (/Users/safi/Projects/Server/hm-chat/node_modules/socketcluster-server/scsocket.js:174:17)\n    at null. (/Users/safi/Projects/Server/hm-chat/node_modules/socketcluster-server/scsocket.js:145:10)\n    at Timer.listOnTimeout (timers.js:92:15)\nkindly suggest to me \n. ",
    "ryanpager": "Example:\n``` coffeescript\nopts =\n  # General Settings\n  appName: 'TalkFusionSS'\n# Process Settings\n  port: ProcessConfig.port or 8000\n  workers: ProcessConfig.maxWorkers or 1\n  brokers: ProcessConfig.maxBrokers or 1\n  rebootWorkerOnCrash: true\n  pingTimeout: 5000\n  pingInterval: 2000\n# Entry Point for socket events\n  workerController: './worker.coffee'\n# Entry Point for socket event management\n  brokerController: './broker.coffee'\n```\n. So this was the solution (unless someone else tells me otherwise):\nBroker.js\njs\nrequire('coffee-script/register');\nmodule.exports.run = require(\"./broker.coffee\");\nBroker.coffee\ncoffeescript\nmodule.exports = (broker) ->\n  Console.debug \"Broker instance started, pid #{process.pid}\"\n...do the same thing for worker as well. This will run without issues.\n. @jondubois \nCompletely agree with what you explained -- we did have some trouble with long lived socket connections but this wasnt the issue. It was an issue with getting the socket connection the first time. We might need to try HTTPS instead of HTTP, \nCompletely weird, will update with what I find out through changes on EC2 / EBS / etc!\n. @jondubois \nThe problem was with the security groups on EC2 & EBS...weird.\nOne other question though, very random people (people in japan), are getting socket disconnects. Is there something that can cause this -- or a server setting I can increase to fix disconnects. I looked at \"ackTimeout\" but im not sure if that has anything to do with disconnects.\nIts not consistent which is really annoying.\n. @jondubois \nWow, I feel like a moron. Yup, that fixed it. We somehow missed a \"0\" in the pingTimeout, so it was extremely low -- fixed a whole bunch of issues.\n. @jondubois\nSome answers to your questions --\nYou mean that some of your pub/sub channels have over 5k concurrent subscribers? How often does the average user send a message to the channel? (On the frontend, does text just stream by really quickly?)\nYep -- a given channel (in the form of \"live-meeting-#{uuid}\") can have 5K+ people concurrently. On average an event gets sent every could seconds -- if chat is closed. If chat is open, its pretty standard to have messages flying through at 3-5/sec. We disabled chat on massive meetings because it was making the problem worse (dropped user limit way down) -- but we still could only handle 5K in a channel.\nDid you find out what was using up the CPU? Was it Node.js (SocketCluster) or Redis?\nRedis usage was minimal -- it was 99% SocketCluster.\nAlso, do all these 5K subscribers come on all at the same time? Does it always happen or only sometimes?\nWe have a lobby where people join when they want for meetings -- so its never all at the same time. Also -- the connections dont seem to be the problem...before the meeting starts and people are just in the lobby with connections -- servers sit at like 1%...no problem. Its when they start shooting off events it becomes an issue.\nWe have set the auto reconnect options before and it didnt make any difference because of what we were seeing. It was only after the meeting started and events start flying through that theres an issue. Once the server starts to choke -- people disconnect/reconnect rapidly which causes issues -- but thats mitigated for the most part.\nOther Questions\n- We are currently on server version 2.3.25... has there been any major performance changes since then? (reading the change logs i dont see anything that jumps out)\n- Events are dynamically run in the middleware layer -- an event comes in through ScServer.MIDDLEWARE_PUBLISH_IN, and when it does we match it with a specific function in a separate include, use a require to bring it in, and then run it. Maybe the require is killing it since require is a blocking function?\n- Before the event is run, it pulls the \"meeting\" from redis so it can inject it into the meeting. It shouldnt be a problem, but maybe it is?\n- I think our node version is pretty old (6.0.0-pre)...could that possibly be an issue?\n. @jondubois \nThe worker processes are almost bang on evenly split in terms of how much work they are doing. Were going to try doing a few more benchmarks + upgrading our SC library version -- and hopefully that helps.\nThanks for the help -- will update with some findings.\n. @jondubois \nGot some good stuff for you --\n1. We upgraded finally to the newest version...this significantly helped out distribution of work -- much like you said.\n2. We found a big performance hit in our code -- we were doing dynamic requires (why, I have no idea). While node is supposed to cache those requires; it seemed like that was never happening.\n3. m4.10xlarge instances do not perform nearly as well as c4.8xlarge. Number of cores != best performance.\nBenchmark Testing:\n1. A new connection was created every 10ms until 2500 connections max were made. We did the test from 2 computers -- so 5000 connections total.\n2. After max connections were made, a new event is published every 1000ms\n3. Wait for server to die (or keep running)\nResults Before Changes:\n500 connections @ 1 event / sec blew up the server (maxed out 1 thread at 100% cpu usage) -- everyone dropped.\nResults After Changes:\n5000 connections were fine -- it took 5 minutes of slamming the server in order for all clients to get disconnected.\nNote -- we are recording chat history in a redis object. We completely overlooked that the redis object would grow to massive proportions as you keep spamming the server. This is why each event took more work -- rather than be consistent.\nGeneral Wrap-up / Where Were At:\n- We figured out that things that usually arent a problem are....talk about feeling dumb\n- We know that a channel on the new version (4+) will handle easily 5000+ people\n- We know that redis, while a great thing -- can be excessively expensive if not done correctly as the record grows.\n\nSo yea...thanks for the help, I'll continue updating as we figure out more stuff - but getting 10x more stability in a couple days is awesome. The only way well know for certain that this works completely is getting a 5000+ person meeting together...which isnt really an easy task. But this greatly helped out.\nThanks, will update soon!\n. @happilymarrieddad So the issue was with the amount of data we were JSON.stringify'ing and parsing. Our objects were stupidly large (something that happened over time while we were building). We ended up ditching Redis all together and using DynamoDB directly so we could do complex queries -- and the problem went away completely. We are still running into an issue where the max is ~ 10K in a channel, but we might have figured out a way around this.\nReally -- this is as resolved as it can get right now, so I am going to close it. Thanks for the help everyone!\n/cc @jondubois \n. ",
    "ccravens": "Is it required that we use the SocketCluster client library on the browser or can we use standard WebSocket connections?\n. Hello @jondubois :\nThe project we're working on requires an minimalist approach, due to the fact that we are implementing so many different technologies and have a requirement to make the code base as small and efficient as possible. This also includes re-implementing some of the angular core-features from scratch such as the 2-way data binding and directives. We also require an extreme fine-grain control of every process. Not to say that the SocketCluster client is inefficient in any way, however we will probably peel back the client and take a look at how it is implemented. SocketCluster, and distributed real-time communication with pub/sub channels is the backbone of what we are working on. If we do end up creating a minimalist, light-weight version of SocketClient and it is useful we would be happy to release back to the community.\nThanks for your quick response!\n. @jondubois The second method you mention worked for me and your explanation here helped clarify for me. Thank you!\n. ",
    "roblav96": "what is this house variable!? lol\n. This is how I figured it out.\nprocess.on( 'SIGUSR2', function () {\n    socketCluster.killWorkers();\n    socketCluster.killBrokers();\n    server.close( function () {\n        process.exit( 0 );\n    } );\n} )\nThank for the tip btw!!!\n. Thank you for the response!\nI'm toying around with the scServer.MIDDLEWARE_PUBLISH_OUT function and the socket parameter. \nFrom my understanding, the client side auth system is sort of obsolete because can't the client just spoof the\nsocket.isAuthenticated\nfunction?\nI'm very familiar with web security fundamentals and token authorization. I think I'm a little confused as to how the flow of everything works. I've been reading all the guides numerous times.\nI'd like to see if there's a way where I can encrypt a token on the client each time a publish is made then before the client receives the data, verify its token with the handshake middleware.\nAre there any ways to set headers or something on the client?\n. I also love how you guys are using RethinkDB in your example app :D\n. @jondubois Excellent response!\nThank you very much for helping me out here. I've successfully been able to get this working property with my Redis DB.\nBy playing around with the\nMIDDLEWARE_PUBLISH_OUT\nmiddleware, I've successfully been able to verify whether the client can receive updates.\nThis is really an amazing framework here. I can't wait to show you all what I've done with it.\nNext up is trying to actually scale it :D\n. I ended up using:\nworker.getSCServer().clients[ doc ].send( 'dataaaa' )\nand\nself.socket.on( 'raw', function ( res ) {})\nI must have skimmed through the APIs too quickly :X\n. My brains must have been fried eggs the other day. I was trying to kick client out of a channel that didn't exist :X \n. What you want to do is cache the users activity to a db (I use redis) and then organize the table how you'd like. I recommend using redis because it has great pub/sub functions.\nHere's an example from one of my projects:\n``` javascript\nserver.post( '/geo/toggle_active', function ( req, res ) {\n    var data = req.body\n// req.xid = the username of the request\n// data.uname = the username the requester would like to toggle from their channel\nredis.sismember( 'groups:' + req.xid, data.uname ).then( function ( doc ) {\n    if ( doc == 1 ) {\n        redis.srem( 'groups:' + req.xid, data.uname )\n        inGroup( false )\n    } else {\n        redis.sadd( 'groups:' + req.xid, data.uname )\n        inGroup( true )\n    }\n} )\n\nvar inGroup = function ( bool ) {\n    if ( bool == true ) {\n        redis.sadd( 'ingroup:' + data.uname, req.xid )\n    } else {\n        redis.srem( 'ingroup:' + data.uname, req.xid )\n    }\n\n    var _data = {}\n    _data.xid = req.xid\n    _data.uname = data.uname\n    _data.data = bool\n    redis.publish( 'actives', JSON.stringify( _data ) )\n    return res.send( bool )\n}\n\n} )\n```\nThe user requests to toggle another out of their group and now we can access the usernames 'groups' table in redis to get the users in that channel.\n. woah! Thanks for this amazing batch of help! I'll play around with this and let you know how I make out.\n. Turns out I forgot to update my socketcluster client to v3.0.0\nI hate my life lol\n. Interesting. I didn't know corporate proxies did that. Great tip!\nI'll be using https://github.com/digitalbazaar/forge as my encryption engine. If you aren't familiar with it, check it out. They've implemented all high level cryptography in native js.\nI just discovered the greatness of https://gitter.im/\nI do apologize for posting my questions to the repo as issues. I'll stop that and use gitter from now on. \nDo you guys accept donations? I could not find a link. Thank you for the help as always! \n. ",
    "robborden": "I had a recursive function in the worker which unintentionally was running around 12,000+ times and it caused a stackoverflow error. That caused a circular reference error in the SC code and it looked like it was where it was trying to put the error into a json object.  Perhaps it was trying to json.stringify the callstack and having so many of the same function over and over in the stack caused it to think there was a circular reference?  I'm not well versed enough in JS to know if that's possible.  It was on line 118 of workercluster.js\njavascript\nprocess.send({\n      type: 'error',\n      data: {\n        error: error,\n        workerPid: process.pid\n      }\n    });\n``` javascript\n1441992742863 - Origin: Worker (PID 28429)\n    [Error] TypeError: Converting circular structure to JSON\n    at Object.stringify (native)\n    at process.target.send (child_process.js:451:23)\n    at EventEmitter.handleError (/var/socketcluster/pubSub/node_modules/socketcluster/lib/workercluster.js:118:13)\n    at EventEmitter.emit (events.js:95:17)\n    at EventEmitter.SCWorker.errorHandler (/var/socketcluster/pubSub/node_modules/socketcluster/lib/scworker.js:242:8)\n    at Domain. (/var/socketcluster/pubSub/node_modules/socketcluster/lib/scworker.js:22:23)\n    at Domain.EventEmitter.emit (events.js:95:17)\n    at process._fatalException (node.js:249:27)\n1441992742866 - Worker 1 exited - Exit code: 0\n\n\nWorker PID: 28454\n1441992743212 - Worker 1 was respawned\n```\n. \n\n",
    "tbashor": "Starting it with sudo worked. Thanks!\nWhy is it necessary run as root? Is there a way to get it to work without the elevated access?\n. Deleting /tmp/socketcluster/ did not allow me to start the processes. Which is strange to me since when starting with only one broker does work but does not result in a new tmp/socket cluster directory. I have a /tmp/ directory in my user account but that does not have a socketcluster directory. \nThe existing error is certainly misleading so it would be great if that was addressed. \nAs far as the fix goes, how can I avoid running the process with sudo? Do I just need to change the user is related to the process after it starts?\n\nOn Oct 17, 2015, at 8:49 PM, Jonathan Gros-Dubois notifications@github.com wrote:\n@tbashor You shouldn't have to run as root. I just wanted to check what the problem was.\nSC creates a /tmp/socketcluster/ directory to store unix domain socket file descriptors.\nMaybe you had existing socket fds from an earlier time that you ran SC as root? Then when you try to run it as non-root, it tries to access the fds under the same directory but it can't because it doesn't have the privilege. Does deleting the /tmp/socketcluster directory allow you to run as non-root?\nI may have to make this case more obvious in the error message because it's confusing.\n\u2014\nReply to this email directly or view it on GitHub.\n. OSX 10.11.1\n. \n",
    "SomeKittens": "Also encountered this problem, running as sudo fixed it, there was no entry in /tmp/socketcluster before running as sudo.\nOSX 10.10.5, if that helps.\n. Tried running the server with sudo (which create /tmp/socketcluster) and chown'ing that directory to my local user, still getting EADDRINUSE.\n. Running with brokers > 1 works fine with non-sudo on my Ubuntu 14.04.3 server, looks like this is an OSX thing.\nConfirmed the error is also on OSX 10.11\n. @tbashor If it helps at all, remember that /tmp on OSX is symlinked to /private/tmp.  Wonder if that's a contributor.\n@jondubois I'll check into that when I get a break later today.  Side note: How many brokers should we be running?  Looking at the docs, they're for syncing across machines, so no more than one per box?\n. Ah!  Figured it out.  Needed to publish to an exchange (not global) and subscribe/watch that exchange.\nServer (this actually publishes twice, both work):\njavascript\n  setInterval(() => {\n    console.log('interval');\n    worker.scServer.exchange.publish('moose', 'cookies');\n    worker.exchange.publish('moose', 'cookies');\n  }, 1000);\nClient:\njavascript\n      var mooseChannel = socket.subscribe('moose');\n      mooseChannel.on('cookies', console.log.bind(console));\n      mooseChannel.watch(function (num) {\n        console.log('moose channel message:', num);\n      });\n. (thanks again, @jondubois, this is a great project)\n. ",
    "ab4drinkadvisor": "Thank you!\nBut is there another way?\nBecause if I use your solution, i have to create private channel for each user.\nIt is not good for performance.\nIs there some function like in Socket.io\nio.sockets.socket(savedSocketId).emit(...)\n. ",
    "Anaphase": "Thanks! This helps fix an annoying bug in my server.\n. ",
    "abhi86813": "I am also unabele to gain more than 4K connection, trying from 1 client or more than 4 clients, result is same for all. Please suggest how to scale on 1 core CPU, more than 4K.. having similar kind of issue, connection not increasing from 4K, giving same error. ulimit and other sysctl parameters were updated, but no improvement in no of connections.\nCan you please suggest a solution, considering good VMs we are using.. 1. yes we have increased all server limits and updated sysctl file, ulimit, etc.\nand we have used the conf from issue https://github.com/SocketCluster/socketcluster/issues/401 \nWe are not making 8 core server as of now.\nour VM servers with 2 core, and we are trying to check maximum capacity for 1 single VM with 2 core. Once we find the tps for smallest entity required i.e 1 worker process, then gradually we can increase the servers as per our requirement.\nHere we are only getting 4K with  core. so is this the final capacity for this limit server.\nand for 40K, I would need 40 such servers?\n. We have used all default configurations provided.\nBelow is the list of details .\n\nHi can I get the code used for this setup...We have to do stress test of socketcluster...\nI am using SocketCluster/sc-stress-tests for testing...\nWe are able to achieve only 4K concurrent connection on Server, then we are getting socket hung up error.\nOur setup :\nworker :1\nbroker :1\nlimits.conf :\n\n          soft    nofile          1000001\n\n          hard    nofile          1000001\n\n20-nproc :\n\n        soft    nproc     100000\n\n        hard    nproc     100000\n\nCPU info:\n\nlscpu\nArchitecture: x86_64\nCPU op-mode(s): 32-bit, 64-bit\nByte Order: Little Endian\nCPU(s): 2\nOn-line CPU(s) list: 0,1\nThread(s) per core: 1\nCore(s) per socket: 1\nSocket(s): 2\nNUMA node(s): 1\nVendor ID: GenuineIntel\nCPU family: 6\nModel: 60\nModel name: Intel Core Processor (Haswell, no TSX)\nStepping: 1\nCPU MHz: 2596.982\nBogoMIPS: 5193.96\nHypervisor vendor: KVM\nVirtualization type: full\nL1d cache: 32K\nL1i cache: 32K\nL2 cache: 4096K\nL3 cache: 16384K\nNUMA node0 CPU(s): 0,1\n++++++++++++++++++++++++++++++++++++\ntop command result :\ntop - 08:43:59 up 1 min, 4 users, load average: 0.19, 0.07, 0.03\nTasks: 107 total, 2 running, 105 sleeping, 0 stopped, 0 zombie\n%Cpu0 : 1.4 us, 0.7 sy, 0.0 ni, 97.3 id, 0.0 wa, 0.0 hi, 0.7 si, 0.0 st\n%Cpu1 : 1.7 us, 1.0 sy, 0.0 ni, 97.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st\nKiB Mem : 3881624 total, 3350252 free, 328080 used, 203292 buff/cache\nKiB Swap: 0 total, 0 free, 0 used. 3311432 avail Mem\nPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND\n1215 root 20 0 1258172 80884 13172 S 5.6 2.1 0:05.55 node\n3 root 20 0 0 0 0 S 0.3 0.0 0:00.02 ksoftirqd/0\n1112 root 20 0 239788 11212 1136 S 0.3 0.3 0:00.47 supervisord\n1187 root 20 0 977248 25000 12124 S 0.3 0.6 0:00.34 node\n1 root 20 0 43228 3616 2492 S 0.0 0.1 0:01.77 systemd\n2 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kthreadd\n4 root 20 0 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0\n5 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H\n\nOn above config the result we are getting is only 4K concurrent connections.\nEven after increasing to 5Worker2broker, result is same.\n. @jondubois Let me know if you need any more info. still not figure out the issue.. ",
    "mattkrick": "Oh man, feel free to tell me to RTFM next time, I can't believe I missed that. Works beautifully, thanks!\n. this helps! Checking around the web I saw a few cases where arrays are used in JWTs too (so long as theyre not huge or arrays of objects, i guess that's a slippery slope). As for the middleware, for database pulls I suppose 1 middleware per server publication is the best way to go about it. thanks!\n. Thanks for getting this all together! Couple thoughts:\n- Is it too verbose to have a listener for each error class? (I say error class where 1 class can have many types). Since the dev will have to do this parsing by error type anyways (eg 'subscribeError' is a class that can contain a tokenError or permissionError or something user defined), the workflow doesn't change, but we do save 6 or 7 listeners from being created on the client if we emit them all under 'error' and it keeps the API lightweight. Not sure which is right...\n- should we have a waitForAuth on emit? That'd make it: socket.emit(event, data,[options],[callback]), where the callback is determined by seeing if the last arg is a function. 4 args is pushing it, but it doesn't seem right to only give that functionality to subscribe.\n. 1 housekeeping item for v4: the website should show return values for events. Eg 'subscribeFail': returns error, channelName. Maybe a table with with 3 columns: listener, return values, description?\n. I like where this is going. I remember you earlier mentioned you wanted to allow for user-defined errors within middleware. Is that still the plan? I also like the parity to HTTP codes where the token fail is a 401 and a middleware fail is like a 403.\nI'm not a fan of 1 event triggering 2 listeners though, I think the errors should happen is a series: first authentication, then authorization. If authentication fails (and the middleware cares about it failing), it should short circuit before hitting the authorization. Maybe something like this?\n```\n//comes from jwt-middleware after a failed token\nconst req = {\n  socket: SCSocket,\n  channel: 'user123',\n  data: {foo: 'bar'},\n  tokenError: TokenError\n}\nfunction userDefinedMiddleware(req, next) {\n  if (req.tokenError) {\n    //don't bother authorizing if authentication failed\n    return next(req.tokenError)\n  }\n  const token = getAuthToken();\n  if (token.channel !== req.channel) {\n    return next(new AuthorizationError('User not allowed in channel'))\n  }\n  next(req);\n}\n//verifyInboundEvent shortcircuits if 'req instanceof Error'\n``\n. One other consideration-- callback errors. Right now, if the first arg isn't null, if get's sent through the 'error' listener. That means if a dev wants to receive an error from their callback that isn't an Error object, or doesn't want that to trigger anerror` listener, they have to put the error in the 2nd argument. Personally, I'm not a fan of this side effect behavior since callbacks & events serve the same purpose, but understand that 'error' was originally designed as a catchall. \nFor v4, I say callbacks shouldn't trigger any errors since they're used for things like failed schema validation, failed DB inserts, etc, Whereas the 'error' event can be for Error objects like ack timeout, token expire, and middleware fails (assuming they're all left under the 'error' heading).\n. I like the deauthenticate event. Will removeAuthToken trigger that as well or will it use a callback? If the client uses an expired token to subscribe, that means the deauthenticate event will fire (with 0 args) as well as a subscribeFail (with a rehydrated Error), right?\nFor user-defined errors, will the devs write the errors as objects, or will they write them as an instanceof an Error & then SC dehydrates the Error into an object before sending it on the wire? If it's the latter, will they be able to import SC errors like 'AuthorizationError' so they can use them in the middleware?\nIf I understand correctly, the client will get something roughly like this?\n| Error Name          | Error Type          | Source                                           | Listener (option #1) | Listener (option #2) |\n|---------------------|---------------------|--------------------------------------------------|----------------------|----------------------|\n| ConnectionError     | ConnectionError     | Can't connect due to [code] or unknown           | connectionFail       | error                |\n| ConnectionError     | HeartbeatError      | Ack timeout                                      | connectionFail       | error                |\n| ConnectionError     | HandshakeError      | Handshake failed (include middleware?)           | connectionFail       | error                |\n| AuthenticationError | AuthenticationError | Token doesn't exist or is expired                | authenticationFail   | error                |\n| SubscribeError      | [userDefined]       | subscribe middleware                             | subscribeFail        | error                |\n| PublishError        | [userDefined]       | publish_in or publish_out (separate?) middleware | publishFail          | error                |\n. Here's what I'm thinking for deauth:\nClient induced:\n1. Client calls removeAuthToken (takes no args) \n2. Deauth is sent to server & AuthEngine optimistically deletes the local token. Also, we set isAuthenticated to false and clear the expiry timeout handler (assuming SocketCluster/socketcluster-client#31). If it can't delete the local token (super rare, but necessary if I'm debugging my custom AuthEngine), locally emit AuthenticationError Cannot delete local token under the error listener.\n3. If deauth is successful on server, emit  deauthenticate to client, else emit AuthenticationError: Cannot delete server token under the error listener. (error case should be super rare)\n4. External client listener for deauthenticate let's the dev do whatever, no internal listener needed.\nThe only edge case with this is that the event doesn't guarantee the token is gone locally by the time it's received since we don't control AuthEngine (eg it could sleep 10 seconds before executing the delete, or it could fail), but realistically I think that's acceptable since we can guarantee that isAuthenticated is locally set to false so worst case scenario is the state is corrected on the next round-trip.\nServer induced starts from the success case of step 3 (if there is an error with deleting the token on the server it should not propagate down to the client, since the client didn't ask to be deauthed).\n\nFor middleware errors, I think SC should be opinionated & only accept one option (although if backwards compatibility is a big issue, it could accept strings but be undocumented & removed by v5). I don't have a strong preference between objects & Error-objects, but If you go the instanceof Error route, here's a good example to follow: https://github.com/neumino/thinky/blob/master/lib/errors.js. This would end up looking like:\nimport {SubscribeError} from 'socketcluster-client`;\ncustomerError = new SubscribeError();\ncustomError.type = 'UserDefinedFail';\nnext(customError);\n\nI agree with the single listener & codes in connection error, that should keep the API clean!\n. Yep, the rename sounds good. \n\nAlso what would happen if the token had expired and we called next(req.authTokenExpiredError); inside the subscribe middleware?\n\nI'm thinking between middlewares we check to see if the object instanceof Error. If it's true, we shortcircuit the middleware chain & emit the error to the client. I'm not sold on this syntax, we could also have the user set the error property on the req & then they could write if (req.error instanceof Error) next() and then every empty request would emit the Error from the error prop (or make one if it's null).\n\nThat's a really good point about Error name & action/source. I think I'm overcomplicating it. As a dev, my thought is, \"I don't care where the error came from, I care about what it is.\" If in a special case I do need to know what middleware it occurred in, I can create a custom Error (eg UserDefinedSubscribeError). This is nice because we don't have to check for all user-defined props on the Error object & only send 2 fields to the client.\nsocket.on('error', function (err) {\n  if (err.name == 'AuthTokenInvalid' || err.name == 'UserDefinedSubscribeError') {\n    // ... Do stuff\n  } else if (err.name == 'AuthTokenExpired'  || err.name == 'HandshakeError') {\nThis could be useful in a later version, where we also emit it internally on the server. This would open the door to log errors generated by certain users (eg user 'abc' with IP 127.0.0.1 keeps requesting data that doesn't belong to him, ban him). \n. Ah, I didn't know there were other points of failure, good to know! So what's the difference between an emit timeout error and a connection heartbeat error? Could we lump emit & publish timeouts in the same heartbeat error & call it a timeout error for the purpose of the client? (Totally OK to shoot the idea down)\n. Agreed, I think it all looks pretty good! I'm happy to help, just give me a piece or 2 of the spec & I'll have something in a day or 2. \nBefore you start the spec, have you thought anymore about isAuthenticated logic on the client? We'll need that for the deauthenticate in additional to the new waitForAuth proposal. I personally think it'd be a good idea to establish a numeric value of how much faster the server clock is compared to the client clock (SocketCluster/socketcluster-client#32). If we did that, we'll need to incorporate a timestamp on the client & server ends of the handshake, so this seems like the right time to introduce it. We might also consider an isAuthenticating status as well.\nPS, not sure if it's useful for this discussion, but I plan on holding all these errors (along with the rest of the socket state) in a redux store (https://github.com/mattkrick/redux-socket-cluster#api, or see it in action here https://github.com/mattkrick/meatier). Obviously I'll change the logic to match the socketcluster spec, but maybe it can serve as a user story. Hopefully this explains why I needed socket caching/multiplexing, isAuthenticated, and well defined errors.\n. Very well thought out.\n- For client step 5, you're also calling AuthEngine.removeAuthToken, right? It doesn't matter when it finishes, but I think it's important to (eventually) remove bad tokens from the client.\n- What are your thoughts on token renewal? In your example app, the server renews the token every 3 mins. Is this still the preferred approach? I like that the renewal originates from the server. Any thoughts on building renewals into socketCluster? Maybe an autoRenew param with a default of an hour? FWIW, here's what the auth0 guys do: http://stackoverflow.com/questions/26739167/jwt-json-web-token-automatic-prolongation-of-expiration\n- Regarding 5.5 and the server-latency heuristic, I think they're the same problem: the client's isAuthenticated is wrong (if only for a couple milliseconds). I agree with your approach. As long as there is a sound renewal strategy, this won't even come up.\n- Regarding the server-latency heuristic, it doesn't matter if the latency changes or the client changes their clock because the setTimeout is initiated during authentication (and if I have a setTimeout to execute in 60 seconds, it'll still takes 60 seconds, even if I set my clock 59 seconds faster). That said, I'm cool if the expiry only happens on the server, just wanted to make sure all your assumptions were correct before you made the decision. Assuming renewals are handled properly, I'm splitting hairs over a no-op.\n. Sounds good, except for renewals. The client can't be guaranteed to handle renewals without having at least an estimate of the server time. The JWT has an expiration in server time, so the client effectively doesn't know when the token will expire until it receives an AuthError from the server, which is no good. In 99% of cases, this is fine because the refresh frequency is greater than the token life (unless the difference between server and client is greater than the life of the token, then we have an infinite series of renewal requests).\nWhat might be nice is having the server perform a renew on a 1 hour (or user-defined) interval. That could save us a trip from the client to the server & make the client 100% independent of the server time. Thoughts?\n. sounds reasonable, but (playing devils advocate here) a user could already flood the buffer while the connection is being established. https://github.com/SocketCluster/socketcluster-client/blob/f67df0c793f0557f2da1a8b56460e478c396cf4a/socketcluster.js#L635-L653\nAn alternative would be to put a LIFO cap on the _emitBuffer (eg if linkedlist.length > 10000 ignore the emit), which would solve both problems. \nBoth are such edge cases that it's really only to prevent malicious actions, so I don't have a strong preference either way. \n. Ahh my bad, I only saw the timeout for durable messages, not for the queue. Thanks for all the work you've put into this!\n. @happilymarrieddad\nNow that i'm done laughing at your awesome username, I do something similar when changes propagate from the DB (and of course the DB doesn't know which socketId made the edit):\n- when worker receives an event, it stores the docId in a socketId-specific queue\n- on any error, remove the docId from the queue, emit error if necessary\n- Before a change is sent to the client, check the queue. If found, remove it & don't emit (emit ack or use callback if necessary)\nThat way you can achieve an optimistic UI while minimizing data over the wire (at the expense of added state to your worker). \n. @jondubois Finally getting time to dig in, here are a couple thoughts after reviewing the new API & website docs, let me know your thoughts:\n- Clearly state that 'pending' is the initial state for authState. Or should there be another initial state? Is it possible for a socket to connect without requesting auth? \n- Are all SCWorker.error and SCWorker.notice messages safe to send to the client? Can we ignore these & assume that all relevant client info is sent to SCSocket (client) as an error? A list of messages would be useful in an appendix somewhere\n- Client: a list of SCSocket.error messages in an appendix would be great to know which ones might be useful to display to the end user or can be used to trigger actions (eg popup a modal if message === x)\n- if you refer to prop names like socket.CONNECTING as a constant, should we export these directly from the package so folks can use them before calling connect? eg import {CONNECTING, CONNECTED} from 'socketcluster-client'\n- Should subscribeStateChange also carry the error for subscribeFail? If we did this, we could get rid of subscribe and subscribeFail (or keep them for backwards compatibility, but not use them)\n- Seems weird there is a getState but no getAuthState, but I'm not sure we need either?\n  That's all for now, I might have 1 or 2 once I dig into the errors & notices & middleware. Cheers!\n- Docs don't mention what is passed to the authenticate callback (error, authStatus) would be nice to include the shape of the authStatus object without going into the SC\n. weird,e up there now! sorry bout that.\n. :+1:\n. ^^ I think that makes a lot of sense. Plus we might be able to do away with that double nested data JSON object that we often send.\nAnother thought I have is to condense socket cluster into 2 repos instead of 3. If we have a server package & a client package, it still feels kinda weird installing socketcluster instead of socketcluster-server. We could technically make it one if we can guarantee that the client uses some form of tree shaking, but I think it'll be best to wait for the Loader API to get finalized before we start that. \n. that's good insight, yeah let's make it as easy as possible for docker deployment.\nthe double nested data isn't terrible, i'll dig into the payload signatures  of things like swarm.js & see how they do it. It'd be nice to get something that's really tiny, but still have payloads that are easily human readable. \n. Heh, fun, I got a different callstack though:\n[Error] Error: scBroker server at socket path /var/folders/r_/sxm2m5wj5zl0k_z_6pczzydc0000gn/T/socketcluster/Action_cc2b3cba44/b0 exited\n    at EventEmitter.<anonymous> (/Users/mk/Code/action2/node_modules/sc-broker-cluster/index.js:352:19)\n    at emitTwo (events.js:106:13)\n    at EventEmitter.emit (events.js:191:7)\n    at EventEmitter.emit (/Users/mk/Code/action2/node_modules/sc-domain/index.js:12:31)\n    at ChildProcess.<anonymous> (/Users/mk/Code/action2/node_modules/sc-broker/index.js:77:10)\n    at emitTwo (events.js:106:13)\n    at ChildProcess.emit (events.js:191:7)\n    at ChildProcess.EventEmitter.emit (/Users/mk/Code/action2/node_modules/sc-domain/index.js:12:31)\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:204:12)\n@jondubois this is a gamechanger if we can get this to work, any ideas on where to start?\nMust be at least node v6.3.0, I'm running v6.4.0\n. Still getting something weird:\n```\n\nNODE_ENV=development node ./src/server/server.babel.js --inspect-workers\n\n[Busy] Launching SocketCluster\n\n\nBroker PID: 52206\nDebugger listening on port 5858.\nWarning: This is an experimental feature and could change at any time.\nTo start debugging, open the following URL in Chrome:\n    chrome-devtools://devtools/remote/serve_file/@62cd277117e6f8ec53e31b1be58290a6f7ab42ef/inspector.html?experiments=true&v8only=true&ws=localhost:5858/node\nDebugger listening on port 5859.\nWarning: This is an experimental feature and could change at any time.\nTo start debugging, open the following URL in Chrome:\n    chrome-devtools://devtools/remote/serve_file/@62cd277117e6f8ec53e31b1be58290a6f7ab42ef/inspector.html?experiments=true&v8only=true&ws=localhost:5859/node\nCreating a pool connected to localhost:28015\nWorker PID: 52208\n   [Active] SocketCluster started\n            Version: 5.0.9\n            WebSocket engine: uws\n            Port: 3000\n            Master PID: 52205\n            Worker count: 1\n            Broker count: 1\n\n\nUnable to open devtools socket: address already in use\nUnable to open devtools socket: address already in use\nUnable to open devtools socket: address already in use\n1471749078806 - Origin: Worker (PID 52208)\n   [Error] Error: channel closed\n    at ChildProcess.target.send (internal/child_process.js:523:16)\n    at Object.HappyThread.configure (/Users/mk/Code/action2/node_modules/happypack/lib/HappyThread.js:74:10)\n    at /Users/mk/Code/action2/node_modules/happypack/lib/HappyThreadPool.js:39:18\n    at /Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:713:13\n    at async.forEachOf.async.eachOf (/Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:233:13)\n    at _parallel (/Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:712:9)\n    at Object.async.parallel (/Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:726:9)\n    at Object.HappyThreadPool.configure (/Users/mk/Code/action2/node_modules/happypack/lib/HappyThreadPool.js:37:13)\n    at /Users/mk/Code/action2/node_modules/happypack/lib/HappyPlugin.js:226:25\n    at /Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:721:13\n    at /Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:52:16\n    at done (/Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:241:17)\n    at /Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:44:16\n    at /Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:718:17\n    at /Users/mk/Code/action2/node_modules/happypack/node_modules/async/lib/async.js:167:37\n    at /Users/mk/Code/action2/node_modules/happypack/lib/fnOnce.js:7:17\n    at ChildProcess. (/Users/mk/Code/action2/node_modules/happypack/lib/HappyThread.js:22:11)\n    at emitTwo (events.js:106:13)\n    at ChildProcess.emit (events.js:191:7)\n    at ChildProcess.EventEmitter.emit (/Users/mk/Code/action2/node_modules/sc-domain/index.js:12:31)\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:204:12)\nUnable to open devtools socket: address already in use\n1471749078916 - Worker 0 exited - Exit code: 1\nDebugger listening on port 5860.\nWarning: This is an experimental feature and could change at any time.\nTo start debugging, open the following URL in Chrome:\n    chrome-devtools://devtools/remote/serve_file/@62cd277117e6f8ec53e31b1be58290a6f7ab42ef/inspector.html?experiments=true&v8only=true&ws=localhost:5860/node\n``\n. With the latest versions of everything, it still fails for me. I made a PR on sc-auth that fixes it (it was throwing a warning aboutexp` being included, so i removed it from the token). Perhaps that was causing an error to be thrown?. proposal:\n\nrelease socketcluster/-server at v.5.2.3 and v5.4.5 that revert back to sc-auth 3.0.0 and hardcodes all deps.\nrelease socketcluster/-server at v5.2.4 and v5.4.6 that bump sc-auth to 3.1.0\n\nthat way, i can just install the former versions and still be OK while we discuss what to do with sc-auth. . ",
    "ibrahim9": "Any plan to resolve this? https://github.com/SocketCluster/socketcluster/issues/133\n. ",
    "hustcer": "@jondubois Shall I use nginx for WebSocket proxying to achieve a better performance? Or there is no need to do it?\n. @jondubois Ok, Thanks.\n. @jondubois \nAny other reason cause the TimeoutError problem? I have met this issue too.\nBut my code works before, it's quite simple, client side:\njavascript\n        socket.emit('queryCapital', { day }, (err, res) => {\n          const data = res.capital;\n          // do something here\n        });\nserver side:\n``` javascript\n    socket.on('queryCapital', (data, res) => {\n  provider.getCapitalFlowOfDay(data.day).then(dt => {\n\n    _l.info(`Query capital of ${data.day.substr(0,10)}, total: ${dt.length}`);\n    res(null, { capital:dt });\n  });\n});\n\n```\nThe logs are displayed almost at the same time:\n[2016-09-26T00:31:37.682Z]  INFO: lark/25085 on MJ.local: Query capital of 2016-09-05, total: 75\nBut res(null, { capital:dt }); seemed as if it were not been executed.\nHowever, the same code used to work before, I even haven't notice when they failed.\nWhen I change the server side code to:\n``` javascript\n    socket.on('queryCapital', (data, res) => {\n    const dt = [{a:1},{b:2}];\n    _l.info(`Query capital of ${data.day.substr(0,10)}, total: ${dt.length}`);\n    res(null, { capital:dt });\n\n});\n\n```\nthey work again. My socketcluster version: 5.0.16. Is there anything I should do when res(null, { capital:dt }); was executed in async way. Thanks!\n. It's quite ridiculous that I have spent more than 5 hours on this problem, and I tried various ways to resolve it, including revert code, using older SC modules, using older node, etc. All what I have done is useless, at the time of despair, then all of a sudden, they worked! I just don't know why and what happened? Can anyone tell me the potential reason? Thanks.\n. @jondubois Actually getCapitalFlowOfDay returned in LESS than 1s, that's why I feel unreasonable and I have changed ackTimeout, it didn't work at that moment. After a few hours of useless work, they suddenly work as well as before without modify anything. It's so weird.\n. @jondubois Okay, Thanks. I will do a cache clean next time.\n. The sc-broker-cluster/index.js:645 line: \njavascript\nemitOptions.stringifiedData = SCSocket.prototype.stringify({\n      event: '#publish',\n      data: packet\n    });\nBut there is no stringify definition in socketcluster-server/scsocket.js\n. sc-broker-cluster@2.1.7 works, I think socketcluster should be updated too, because it depends on sc-broker-cluster\n. ",
    "suhailgupta03": "What was the issue? Facing the same problem. ",
    "JimLiu": "Cool, thanks!\n. Unfortunately, it can't work :disappointed: \n. @jondubois \nI use node v4.2 + Babel 6, the socketcluster version is 3.x, base on the sample code: https://github.com/SocketCluster/socketcluster/tree/master/sample\nhere is the code I changed:\nindex.js\njs\nrequire('babel-register');\nrequire('./server');\nserver.js\n``` js\nimport { SocketCluster } from 'socketcluster'\nimport minimist from 'minimist'\nvar argv = minimist(process.argv.slice(2));\nvar socketCluster = new SocketCluster({\n  workers: Number(argv.w) || 1,\n  brokers: Number(argv.b) || 1,\n  port: Number(argv.p) || 8000,\n  appName: argv.n || null,\n  workerController: __dirname + '/worker.js',\n  brokerController: __dirname + '/broker.js',\n  socketChannelLimit: 1000,\n  rebootWorkerOnCrash: argv['auto-reboot'] != false\n});\n```\nrun with\nnode index.js\nworks perfect if I did not change anything with worker.js or broker.js\nbut if I tried to write some ES6 code like this:\nbroker.js\njs\nmodule.exports.run = function (broker) {\n    const { pid } = process; // es6 code\n    console.log('   >> Broker PID:', pid);\n};\nThen got an error:\n```\n$ node index\n   [Busy] Launching SocketCluster\n/sttest/broker.js:2\n    const { pid } = process; // es6 code\n          ^\nSyntaxError: Unexpected token {\n    at exports.runInThisContext (vm.js:53:16)\n    at Module._compile (module.js:414:25)\n    at Object.Module._extensions..js (module.js:442:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:311:12)\n    at Module.require (module.js:366:17)\n    at require (module.js:385:17)\n    at Object. (/sttest/node_modules/socketcluster/node_modules/iocluster/node_modules/ndata/server.js:25:23)\n    at Module._compile (module.js:435:26)\n    at Object.Module._extensions..js (module.js:442:10)\n1450425115495 - Origin: IOCluster\n   [Error] Error: nData server at socket path /var/folders/4c/hh3fk19n3sq_djpcft9vpf7m0000gn/T/socketcluster/71bea5cc-fa0b-4348-b8f4-b7027900b448_9cba8c95ae/b0 exited\n    at EventEmitter. (/sttest/node_modules/socketcluster/node_modules/iocluster/index.js:353:28)\n    at emitTwo (events.js:87:13)\n    at EventEmitter.emit (events.js:172:7)\n    at ChildProcess. (/sttest/node_modules/socketcluster/node_modules/iocluster/node_modules/ndata/index.js:55:10)\n    at emitTwo (events.js:87:13)\n    at ChildProcess.emit (events.js:172:7)\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:200:12)\n/sttest/broker.js:2\n    const { pid } = process; // es6 code\n``\n. I'm not sure if I use it right, or any ES6 sample code I can refer to?\n. I tried, but did not get the point.server.jsworks, butworker.jscan't work with ES6\nIs there any ES6 sample base on this? \nhttps://github.com/SocketCluster/socketcluster/tree/master/sample\n. Yes, I missed theinitController` config, will try it later :)\n. Cool, as I suggested:\nThe option workerController or brokerController is JS file path, could it changed to Class?  Then we do not need use initController\n. I don't think it should be a path if it's used to render a new process.\nI checked the code:\nhttps://github.com/SocketCluster/socketcluster/blob/master/lib/scworker.js#L240-L241\njs\n  this._workerController = require(this._paths.appWorkerControllerPath);\n  this._workerController.run(this);\nit require the path as an instance, then execute it's run method.\nso the workerController option could be a class too.\nfor example:\njs\nexport default class Worker {\n  run() {...}\n}\n``` js\nimport Worker from './worker'\nvar socketCluster = new SocketCluster({\n  workerController:  Worker,\n});\n```\nin scworker.js\njs\nvar WorderController = this.option.workerController || defaultWorderController;\nvar worker = new WorderController();\nworkder.run();\n. @IngwiePhoenix looks like you are right!\nAnd it works after add initController\njs\nvar socketCluster = new SocketCluster({\n  initController:  __dirname + '/init.js',\n});\ninit.js\njs\nmodule.exports.run = function(thisWorker) {\n    require(\"babel-register\");\n}\nThanks :)\n. ",
    "snegostup": "Is it possible to use ES6 inside the Broker? Seems like initController option has no effect on the Broker.\n. Yes, I call it like this require(\"babel/register\")({stage: 0});\nIt does work in Workers but doesn't work in Broker somehow..\n. May I ask you to drop a line of ES6 (like import fs from 'fs') to the top of your Broker.js and try to run it? (At the moment you don't have ES6 code there). \nI've just tried to test it on fresh SocketCluster boilerplate project and it is the same - ES6 works in Worker, but in Broker it doesn't. It looks like a bug.\n. Found it. The problem is that the code of the Broker is being required before initController's run method is called\nhttps://github.com/SocketCluster/ndata/blob/master/server.js#L25\n. Thanks :thumbsup: \n. Thanks a lot for your answers. After thorough investigation I found that it was not SC that added to the increased load time. In my case SC adds about 0.03 to overal load time which is more than acceptable.\n. ",
    "Kannaj": "Hello - is it ok to to use this method for production? According to babel , the module isnt meant for production\nbabel/example-node-server#13\nIs there any other way possible though?\n. ",
    "carlmathisen": "Thanks, @jondubois! Very useful information.\n. ",
    "Kiranshinde5121": "@jondubois  Hi can I get the code used for this setup...We have to do stress test of socketcluster...\nI am using SocketCluster/sc-stress-tests for testing...\nWe are able to achieve only 4K concurrent connection on Server, then we are getting socket hung up error.\nOur setup : \nworker :1 \nbroker :1 \n1) limits.conf : \n               soft    nofile          1000001\n               hard    nofile          1000001\n2) 20-nproc : \n             soft    nproc     100000\n             hard    nproc     100000\n3) CPU info: \nlscpu\nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                2\nOn-line CPU(s) list:   0,1\nThread(s) per core:    1\nCore(s) per socket:    1\nSocket(s):             2\nNUMA node(s):          1\nVendor ID:             GenuineIntel\nCPU family:            6\nModel:                 60\nModel name:            Intel Core Processor (Haswell, no TSX)\nStepping:              1\nCPU MHz:               2596.982\nBogoMIPS:              5193.96\nHypervisor vendor:     KVM\nVirtualization type:   full\nL1d cache:             32K\nL1i cache:             32K\nL2 cache:              4096K\nL3 cache:              16384K\nNUMA node0 CPU(s):     0,1\n++++++++++++++++++++++++++++++++++++\ntop command result : \ntop - 08:43:59 up 1 min,  4 users,  load average: 0.19, 0.07, 0.03\nTasks: 107 total,   2 running, 105 sleeping,   0 stopped,   0 zombie\n%Cpu0  :  1.4 us,  0.7 sy,  0.0 ni, 97.3 id,  0.0 wa,  0.0 hi,  0.7 si,  0.0 st\n%Cpu1  :  1.7 us,  1.0 sy,  0.0 ni, 97.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem :  3881624 total,  3350252 free,   328080 used,   203292 buff/cache\nKiB Swap:        0 total,        0 free,        0 used.  3311432 avail Mem \nPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                     \n 1215 root      20   0 1258172  80884  13172 S   5.6  2.1   0:05.55 node                                                                                        \n    3 root      20   0       0      0      0 S   0.3  0.0   0:00.02 ksoftirqd/0                                                                                 \n 1112 root      20   0  239788  11212   1136 S   0.3  0.3   0:00.47 supervisord                                                                                 \n 1187 root      20   0  977248  25000  12124 S   0.3  0.6   0:00.34 node                                                                                        \n    1 root      20   0   43228   3616   2492 S   0.0  0.1   0:01.77 systemd                                                                                     \n    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd                                                                                    \n    4 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0                                                                                 \n    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H           \n++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\nThis is the client.js file which we are using to generate load :\nlet argv = require('minimist')(process.argv.slice(2));\nlet socketClusterClient = require('socketcluster-client');\nlet cluster = require('cluster');\nlet os = require('os');\nvar csv = require(\"fast-csv\");\nlet testCooldownDelay = Number(argv.cooldown || 5000);\nlet serverHostname = argv.hostname || '10.139.50.129';\nlet serverPort = Number(argv.port || 8010);\nlet numClients = Number(argv.clients || 1000);\n// The test type.\nlet test = argv.test || 'many-subscribers';\nlet cpuCount = Number(argv.cpus || os.cpus().length);\nlet numClientsPerCPU = Math.round(numClients / cpuCount);\nif (!cluster.isMaster) {\nlet workerList = [];\n  var workersReadyPromises = [];\nfor (let i = 0; i < cpuCount; i++) {\nconsole.log(\"in for\");\n    let worker = cluster.fork();\nconsole.log(\"hiii\");\n    workerList.push(worker);\n    workersReadyPromises.push(\n      new Promise((resolve, reject) => {\n        worker.once('message', (packet) => {\n          if (packet.type == 'success') {\n            resolve();\n          } else if (packet.type == 'error') {\n            reject(new Error(packet.message));\n          }\n        });\n      })\n    );\n  }\nPromise.all(workersReadyPromises)\n  .then((results) => {\n    console.log('All clients are connected... Waiting for CPUs to cool down before starting the test.');\n    // Wait a bit before starting the test.\n    return new Promise((resolve) => {\n      setTimeout(() => {\n        resolve();\n      }, testCooldownDelay);\n    });\n  })\n  .then(() => {\n    let deviceID = [];\n    let mobileNumber = []; \n    csv\n      .fromPath(\"/home/kiranshinde/socketTest/sc-stress-tests/client/data.csv\")\n      .on(\"data\", function(data){\n      deviceID.push(data[0]);\n      mobileNumber.push(data[1])\n    })\n    .on(\"end\", function(){\n       console.log(\"done\"); \n     });\nlet counter =0;\n\nvar controlSocket = socketClusterClient.connect({\n      hostname: serverHostname,\n      port: serverPort,\n      multiplex: false\n    });\n    controlSocket.on('connect', () => {\n      console.log(\"Inside on connect\",controlSocket.id);\n      controlSocket.emit('onConnect', {\n                mobileNo: mobileNumber[counter],\n                deviceId: deviceID[counter]\n            });\n      console.log(\"counter\", counter)\n            counter+=1;\n    }) \n// if (test === 'many-subscribers') {\n//   console.log(`Starting the ${test} test.`);\n\n//   setInterval(() => {\n//     console.log('Publishing a single message string to the testChannel');\n//     console.log('hi kiran');\n//   }, 1000);\n// }\n\n})\n  .catch((err) => {\n    console.log('Failed to setup some workers. ' + err.message);\n  });\n} else {\n      let deviceID = [];\n    let mobileNumber = []; \n    csv\n      .fromPath(\"/home/kiranshinde/socketTest/sc-stress-tests/client/data.csv\")\n      .on(\"data\", function(data){\n      deviceID.push(data[0]);\n      mobileNumber.push(data[1])\n    })\n    .on(\"end\", function(){\n       console.log(\"done\"); \n     });\n    let counter =0;\n  for(let k=0; k<cpuCount; k++) {\n  let socketList = [];\nfor (let i = 0; i < numClientsPerCPU; i++) {\n    socketList.push(\n      socketClusterClient.connect({\n        hostname: serverHostname,\n        port: serverPort,\n        multiplex: false,\n        autoConnect: false\n      })\n    );\n  }\n  socketList.forEach((socket) => {\n    socket.connect();\n      socket.on('connect', () => {\n  console.log(\"Inside on connect\",socket.id);\n\n  /*socket.emit('onConnect', {\n            mobileNo: mobileNumber[counter],\n            deviceId: deviceID[counter]\n        });*/\n  counter++;\n\n});\n//socket.disconnect();\n    socket.on('disconnect', () => {\n    console.log(\"conn disconnected\",socket.id);\n    });\n  });\n\n/\nsocketList.forEach((socket) => {\n    socket.disconnect();\n    console.log(\"disconnected :\",socket.id);\n })\n  /\n  if (test === 'many-subscribers') {\n    let subscribePromises = [];\nsocketList.forEach((socket) => {\n  let testChannel = socket.subscribe('testChannel');\n  subscribePromises.push(\n    new Promise((resolve, reject) => {\n      testChannel.once('subscribe', () => {\n        testChannel.off('subscribeFail');\n        resolve();\n      });\n      testChannel.once('subscribeFail', (err) => {\n        testChannel.off('subscribe');\n        reject(err);\n      });\n    })\n  );\n});\nPromise.all(subscribePromises)\n.then((results) => {\n  console.log('success');\n})\n.catch((err) => {\n  console.log(err.message);\n});\n\n} else {\n    console.error(No '${test}' test exists);\n  }\n}\n}\n . ",
    "drojas": "Yes, what version numbers? (besides those on the issue description)\n. @jondubois that helped, the server is not crashing anymore, but the worker is now. I'm seeing this (again, after a first successful run):\nbash\n1452308011427 - Origin: Worker (PID 24950)\n   [Error] Error: bind EADDRINUSE null:7173\n    at Object.exports._errnoException (util.js:856:11)\n    at exports._exceptionWithHostPort (util.js:879:20)\n    at cb (net.js:1299:16)\n    at shared (cluster.js:588:5)\n    at Worker.<anonymous> (cluster.js:562:9)\n    at process.<anonymous> (cluster.js:714:8)\n    at emitTwo (events.js:92:20)\n    at process.emit (events.js:172:7)\n    at handleMessage (internal/child_process.js:686:10)\n    at internal/child_process.js:497:7\n. I can confirm that the generated code on myApp works fine after the clean/reinstall, it just fails on another codebase (running inside electron, btw). This issue is no longer relevant I guess.\n. For the record (or may be the docs), the \"problem\" with electron was that I wasn't managing the socketcluster process properly, this is how I'm doing it now and it works.\n``` javascript\nvar spawn = require('child_process').spawn;\nvar server = spawn('node', ['server']);\nserver.stdout.on('data', (data) => {\n  console.log(stdout: ${data});\n});\nserver.stderr.on('data', (data) => {\n  console.log(stderr: ${data});\n});\nserver.on('close', (code) => {\n  console.log(child process exited with code ${code});\n})\nprocess.on('exit', function() {\n  server.kill();\n});\n```\n. ",
    "hyatt03": "The object is in the gist\n. Emit to a single client\n. ^4.0.1 is specified in my package.json\n. The data isn't sent until it's ready (ie. no blocking file operations). I'll try to update now\n. @jondubois  Same problem...\n. It works with smaller, similar objects\n. OS X\n. el capitan, it fails on both chrome, and safari in the ios sim\n. ",
    "simplesmiler": "@hyatt03 do you publish (to all clients) or emit (to a single client) this data?\n. From my experience, sc can transfer at least 300kb (b64 encoded image) in one batch without any issues.\n. ",
    "jfsimon": "I have same kind problem. I use socketcluster-server 4.1.4 and socketserver-client 4.1.3, and transferred data reach more than 2Mo. Data is emitted to only one client. It works well on my personal laptop (macbook + chrome or safari), but sometimes on my customer's one (windows + chrome), it leads to one of these errors:\nCase 1\n- Socket is disconnected\n- SocketProtocolError: Server ping timed out, code: 4000\n- Socket is re-connected\nCase 2\n- Socket is disconnected\n- SocketProtocolError: Socket hung up, code: 1006. \n- Socket is re-connected\nIn both cases\n- Then every minute (as configured with pingInterval option):\n  - On client side: SocketProtocolError: Server ping timed out, then socket is disconnected\n  - On server side: SocketProtocolError: Client pong timed out as a warning from a worker\nNotice that\n- The error seems to happen randomly (even sometimes with small objects).\n- Sometimes this error happens as nothing happens in the browser.\n- This never happens on personal my laptop (macbook + chrome or safari), only on my customer one.\n- This also happens on my coworker laptop (windows + chrome).\n- I made tests with Norton deactivated, same problem.\nI'm sorry to bother you with this problem, but I really don't know how to fix it.\n. @jondubois thank you for your tip. I changed configuration from pingInterval: 60000, pingTimeout: 70000 to pingInterval: 60000, pingTimeout: 180000. \nSadly it does not fix the problem, I just have the SocketProtocolError: Server ping timed out less often. More info on this gist: https://gist.github.com/jfsimon/39e9d19ad31097d5617f\n. @jondubois After some tests/logs, it appears that, on my coworker laptop (windows + chrome), when the socket is connected, it gets disconnected exactly 3 minutes after, an error is triggered: Server ping timed out, the socket re-connects, and so on...\nIs there a way to deactivate the ping/pong? I already have events when sockets are connected and disconnected, what is this ping/pong system for? When I get Server ping timed out on the client side, I get Client pong timed out on the server side... at the same moment. I'm not sure to understand.\n. @jondubois I know, it's really strange... I guess the problem comes from my code. I'll continue to investigate, thank you very much for your help, really appreciated! I'll keep in touch if I find something.\n. @jondubois OK, the problem was (of course) errors in my app. I can transfer very large objects (> 2Mo) without any problem. This project is really handy and powerful.\nA very big thanks to all maintainers of SocketCluster.\n. @happilymarrieddad should I understand there is no way to manage sockets/channels subscriptions from the server? Given your example, how can I send data to the right clients?\n. @happilymarrieddad I see a solution:\n- let client subscribe to channels\n- listen to subscription from server (on socket's subscribe event)\n- use socket.kickOut() to cancel unauthorized subscriptions\nLet me know if you think there is a better way.\nThanks for your help!\n. @jondubois oh, it sounds great! If I understand, inside the middleware function, I call next() only if the client is allowed to subscribe to the channel, am I right?\n. @jondubois ah, okay. Thank you for the tips, very helpful! I close this issue.\n. ",
    "cailosidfu": "@jfsimon can you elaborate on what was wrong with your code? since I'm experiencing similar issues... :)\n. ",
    "mkgn": "Currently SocketCluster/socketcluster-client-android doesn't seem to be maintaining properly and seems like a dead project. This client seems to be the next option that is available. Can we publish something workable so that we can move forward with development?\n. Oops, i think my message confuses people. What I wanted to tell was that I am also looking for a native client for Android & since the socketcluster-client-android seems pretty much dead, may be we can get whatever abpopov has done and carry it forward.\n. Thanks! got it sorted. I have missed the concept.\nI have another scenario which I need advice about how to implement. Let me try to explain the steps via a use case.\n1) A passenger emits \"cabrequest\" via an app.\n2) SC Worker picks the event and broadcast it to a channel which is monitored by employees of cab company. At this point, customer only send few data including his location.\n3) Employees gets the data and assigns a cab to the customer\n--- This is where I need a suggestion---\n4) The moment a cab is assigned, a new channel should be created and send control signals to both the customer & the cab to join to the newly created unique channel so that each other than see where they are\n5) After the journey is over that channel has to be released since it's temporarily created.\nAlso, is it a good practice to store client sockets at worker in an array? What if I want to find out the socket which a client sent data?\n. Ok.. my bad.. Shouldn't just copy paste sample code :) Once I register the middlewear once with the worker things seems to work fine. \nBut I still can't figure out why the client fires \"connect\" \"disconnect\" events multiple times. To test I just keep on [connecting] & [disconnecting] on client side. Events start to fire ever increasingly. Have a look at the screen shot. At the point of taking the screen shot I have connected/disconnected like 7 times (so at the 7th connecting; \"connected\" event fires 7 times).\n\nI suppose these events should fire only once for each connect/disconnect session?\nBut on the serverside \"handshake\" event fires once for every new connection.\n. ",
    "MahdiPishguy": "@abpopov hi. Could you share your library? I need to have that on android application. Thanks a lot\n. ",
    "poppahorse": "Sorry should have mentioned that too. Freshly installed via npm so 1.3.2\n. ",
    "stewartcelani": "@poppahorse Ran into the same problem. Switch to node v0.10.44 (use nvm if you like) and seems fine now. 4.2 had same problem as 5.x.\n. Thanks Jon!  It took me many, many hours to make sure socket.io survived via stress testing  (closing/opening chromebook, turning off/on wifi router and having to use forceNew connections) and socketcluster has been a champ. It.. just works so far O.O. =D\nBTW: Aussie?! Where do I send your Patreon-beer? Link me.\nBefore I had to change from socket.io I was nearly ready to launch the alpha of my app/extension for the largest Chromebook school in SA (470 atm). Next step is forcing disconnects/reconnects based on certain params (school hours + public IP) and reconnecting when opposite is true (within school hours + from school public IP). Just planning on using the same object for all of those (i.e. disconnect might be called a bunch of times and connect would be called on a forcibly disconnected socketcluster variable when the device is on the school network within defined times again)... how would that effect SC? Recommendations? With socket.io if connect was called multiple times it had no idea of previous connections so it would spawn a LOT of different connections so it took a lot of code to try guard against making new connections (had to use {forceNew: true}) and then chrome would buffer the requests when I didn't want it to and come back online and spit 100s of requests at my socket.io server (endless streams of \"user connected\" =D)..\nAny advice or recommendations for having 470 chromebooks connected on same private network to the server via DECD proxy at a time on how to minimize socket chatter?\nI'm using a publish pattern from teachers (client = meteor) to the students (chrome extensions) and then extensions can reply via private channel to teachers (and vice versa) all via the publish method on the global socket object (passing {event: blah, from: blah@blah.com, to: channel@lah.com, message: optional} in order to send acks back to the from channel (i.e. teacher sends a 'close tab' event' to a students Chromebook which then handles the event and sends back 'tab closed!' ack to teachers browser which pops up a ui confirmation for the teacher). \nUsing socket.io I used emit messages in from the server but not sure the cleanest way to do things with SC. I don't want to have to use eval in the extension to declare variables for each channel to then watch (performing all SC functionality from global object is VERY important if I can specify channel) [just sad I can't specify event there also, seems to only be supported by emit -> server -> other client pattern] because each extension/student might belong to many classes/groups (determined by a constant sync from google apps ==> mongodb).\nIs the only way to PING -> PONG an extension from the UI I describe via emit? Using socket.io I had to ping the server, and in the handler on the server then had to then ping the client (which would pass back a callback to server) which would then callback the original client (front-end) for a basic \"check if extension is online\" check?\nLast night I was starting to implement some SC and I noticed if I watched the same channel/event multiple times I would then receive the event multiple times if you understand what I mean. Multiple watchers on same channel/event don't know about each other so when data comes in on that channel/event it triggers every watcher although all we really want is one.\nHence this shabby code (watchers.length < 1) from my chrome extension that will get called via interval. One student may be a member of a lot of groups in Google Apps or maybe just one. Calling watch via a loop doesn't seem the best way to go.\nIs there any way keep the subscribe pattern but then call socket.on(EVENT) from the global socket channel (i.e. below I am watching a whole channel and doing if statements against data.event -- not sure if this is very low performance or if its something that would have to be done behind the scenes anyway) and also let clients on the other side publish to the global socket via a channel/group/room AND an event? Publish abstracts away so much complication away and works awesome but if it could also publish events and let middle ware handle the auth it would be nirvana.\n// This code was triggered a lot over the last day even after client device was off and resumed and it reconnected and was still receiving single \"SC viewer active events\" from front end. Before the watchers.length < 1 statement each event would + 1 (i.e. 2 SC viewer active events then 3 then 4 then 5).\nfunction SocketHandler() {\n    // Subcribe to private channel (i.e. student1@blah.com.au)\n    socket.subscribe(clientid)\n```\n// Subscribe to all rooms client is a member of\nfor (let i in jsonGroups) {\nsocket.subscribe(jsonGroups[i])\nvar watchers = socket.watchers(jsonGroups[i])\nif (watchers.length < 1) {\n    socket.watch(jsonGroups[i], function (data) {\n        console.log(\"socket.watch(\" + jsonGroups[i] + \") event: From \" + data.from + \", To: \" + data.to + \", Event: \" + data.event)\n        if (data.event == \"viewer active\") {\n            console.log(\"SC viewer active event received\")\n            socket.publish(data.from, {\n                from: clientid,\n                to: data.from,\n                event: null,\n                message: \"Ack \" + data.event\n            })\n        }\n\n    })\n}\n\n}\n```\n}\n. ",
    "Kequc": "There was some conflicting information on stackoverflow here. This seems like it should be there I'm happy to hear that it is.\nI hope it wasn't inappropriate to have asked in a ticket.\n. ",
    "scriby": "Just a random comment on \"While node is supposed to cache those requires; it seemed like that was never happening\".\nNode does employ a module cache (if you require the same file or module multiple times you can verify you get the same object back each time). However, it still does synchronous disk access to resolve the file that is being requested, which is where the performance hit is coming from.\n. ",
    "rohittailor": "I tried to modify sc-redis and checking redis connection error and trying to connect to other redis server instance but it's trying to connect to OLD instance as well:\n```\nsubClient.on(\"error\", function (err) {\n    console.log(\"Error in redis server connection to \"+subClient.address);\n    brokerOptionIndex = brokerOptionIndex == 0 ? 1 : 0;\n    brokerOptions = broker.options.brokerOptions[brokerOptionIndex];\nconsole.log(\"REDIS HOST \"+brokerOptions.host);\nsubClient.quit();\npubClient.quit();\nsubClient.unref();// = null;\npubClient.unref();// = null;\n\ndelete require.cache[require.resolv('redis')];\nredis = require('redis');\nsubClient = redis.createClient(brokerOptions.port, brokerOptions.host, brokerOptions);\npubClient = redis.createClient(brokerOptions.port, brokerOptions.host, brokerOptions);\n\n});\nsubClient.on(\"ready\",function(obj){\n    console.log(\"Connection established to redis server \"+subClient.address);\n});\n```\nIS there any way completely remove the instance of previous client which is trying to connect o OLD instance ?\n. I am now checking redis connection error at sc server 'fail' event and making connection to different redis instance in case previous instance terminated.\nOn redis connection error dynamically changing brokerOptions with new redis instance and calling killBrokers() and it's taking care of reconnection to redis.\n```\nvar checkMsg = \"\";\nsocketCluster.on('fail',function(error){\n    //check if error is coming from broker + error message is related to redis connection + error message is not same as previous message\n    if(checkMsg !== error.message && error.brokerPid && error.message.indexOf(\"Redis connection\") > -1){\n        checkMsg = error.message;\n        console.log(checkMsg);\n        brokerOptionIndex = brokerOptionIndex === 0 ? 1 : 0;\n        brokerOptions = redisServers[brokerOptionIndex];\n    socketCluster.options.brokerOptions = brokerOptions;\n    socketCluster.killBrokers();\n}\n\n});\n```\n. ",
    "alphashuro": "So I'm not supposed to npm install socketcluster-client? Your documentation only mentions var SocketCluster = ('socketcluster').SocketCluster;, so you're saying thats the object i should use to connect on the client side as well?\n. Would it not be helpful to include import/require instructions for people who use npm rather than the socketcluster cli, because some people my not start development using any cli's or they might decide to add socketcluster to the existing node project just by npm installing the framework's packages.\n. :D I didn't realize it was open source, thank you. I will make a pull request and take it from there!\n. That would be awesome, perhaps a link to the docs github page on the introduction of the docs?\n. ",
    "costa974": "i'm trying the debugger in visual studio 2015.\nbut i'm not able to make it work.\nDebugger listening on [::]:5858\n   [Busy] Launching SocketCluster\nError: listen EADDRINUSE :::5858\n    at Object.exports._errnoException (util.js:1026:11)\n    at exports._exceptionWithHostPort (util.js:1049:20)\n    at Agent.Server._listen2 (net.js:1253:14)\n    at listen (net.js:1289:10)\n    at net.js:1399:9\n    at _combinedTickCallback (internal/process/next_tick.js:77:11)\n    at process._tickCallback (internal/process/next_tick.js:98:9)\n. ",
    "Sigurthorb": "I have been looking more into this and this seems to be an issue with socketcluster server.\nWhen I define a path in the socketcluster server.js the server I cannot see that the server takes any requests.\nSo by removing the path from the server, I was able to get requests on /socket/cluster but sockets are able to connect to the server via any path.\nSo this is still an issue, but I have worked my way around it for now.\n. Great, it works. Thank you\n. ",
    "qLb": "Don't know what's your env but did you try `--no-bin-links`\u200e flag on npm command?                                                                                                                                                                                                                                                                                                                                        qL.b                                                                                                                                                                                                                From: Samir SabriSent: czwartek, 28 kwietnia 2016 12:04To: SocketCluster/socketclusterReply To: SocketCluster/socketclusterSubject: [SocketCluster/socketcluster] Errors when create an app (#173)I have successfully installed socketcluster via:\nnpm install -g socketcluster\nhowever, when I try to create an app, I get this error after creating the files:\nnpm WARN socketcluster-sample@1.0.0 No repository field.\nnpm WARN socketcluster-sample@1.0.0 No license field.\nnpm ERR! Linux 4.1.19-boot2docker\nnpm ERR! argv \"/usr/local/bin/node\" \"/usr/local/bin/npm\" \"install\"\nnpm ERR! node v5.10.1\nnpm ERR! npm  v3.8.3\nnpm ERR! path ../mime/cli.js\nnpm ERR! code EPROTO\nnpm ERR! errno -71\nnpm ERR! syscall symlink\nnpm ERR! EPROTO: protocol error, symlink '../mime/cli.js' -> '/app/myapp/node_modules/.bin/mime'\nnpm ERR!\nnpm ERR! If you need help, you may report this error at:\nnpm ERR!     https://github.com/npm/npm/issues\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     /app/myapp/npm-debug.log\n[Error] Failed to install npm dependencies. Exited with code 185.\nAny help is highly appreciated.\n\u2014You are receiving this because you are subscribed to this thread.Reply to this email directly or view it on GitHub\n. ",
    "amprodes": "I have the same issue!. ",
    "kinsi55": "I know this is rather offtopic but have you ever been able to figure this out? Unfortunately UWS has since been pretty much \"deleted\" / unsupported thus finding anything on how to properly use this seems like a challenge to me. I've tried to call prepareMessage w/ a Buffer as the first arg and the opCode as the second Like I was able to find here, however I always am returned an empty object. The corresponding .send method function header matches the one I see regularly used, so that has me wondering what it might be that I'm doing wrong.\nTrying to optimize Primus.io to the absolute max right now w/ my own rooms plugin and already fixed the double-encode issue with that, however I'd love to implement preparing as well to get the absolute max out of it.\nEdit: So, I've just kinda learned about the beauty of native modules.. I guess. The issue in this case is a non-issue: The Objects I am getting are interpreted as empty objects, but it seems like to \u00b5Ws they are handles... or something like that, so I didnt actually encounter any issue.\nIncase you're wondering about the performance gain: Its about 25x for me, pretty sweet if you ask me.. ",
    "maarteNNNN": "Run the command line as Administrator\n. ",
    "ansarizafar": "@jondubois I am using \"socketcluster\": \"^4.6.1\" and  \"socketcluster-client\": \"^4.3.17\". Client also doesn't work with  ionic2 app on device.\n. Here is my server code \n```\nimport {SocketCluster} from 'socketcluster';\nimport os from 'os';\nimport path from 'path';\nconst numCpus = os.cpus().length;\nexport const options = {\n  authKey: process.env.JWT_SECRET || '2r65sMNTWnNmDb1TzBrHAtT4n7RlBw2srPVKDOPo33Oo/TYZZAAThYj/n3rnWsLRXw3mNbmOGhnCuVWO+94BVA==',\n  logLevel: 1,\n  // change this to scale vertically\n  workers: 1 || numCpus,\n  brokers: 1,\n  port: process.env.PORT || 3000,\n  appName: 'Restock',\n  wsEngine: 'uws',\n  allowClientPublish: false,\n  initController: path.join(__dirname, '/init.js'),\n  workerController: path.join(__dirname, '/worker.js'),\n  brokerController: path.join(__dirname, '/broker.js'),\n  socketChannelLimit: 1000,\n  crashWorkerOnError: true,\n  rebootWorkerOnCrash: true\n};\nnew SocketCluster(options);\n```\nClient code \nconst options = {\n    //protocol: 'https',\n    hostname: 'server-hlynjegodp.now.sh',\n    port: 80,\n     rejectUnauthorized: false \n    //hostname: 'localhost',\n   // port: 3000\n};\n    (<any>window).Server = SocketCluster.connect(options);\n. If its a settings issue then why its working in Chrome for desktop. You can check this link http://restock.surge.sh/\n. I am using Google Chrome Version 50.0.2661.75 (64-bit) on a Ubuntu machine. Its working without any problem.\n. Strange, If you want I can share my screen and show you the console log.\n. Check this screenshot \n\n. I am getting the same response in Firefox and facing the same issue even if I run the server and client locally.\n. Global socketcluster client is available on window.Server\n. I can understand. I am trying to find a solution from last few days. I want to use socketcluster with a web and ionic2 app. I am using https://t.co/UdG6eZSUxA for Server hosting and surge.sh for client hosting. I am facing the same problem If I run both server and client on my local machine. I have already removed and reinstalled both server and client packages.\n. I am using Node ver 5.7.0 and npm ver 3.6.0\n. As I said, I am facing same issue on local machine. If firewall is blocking then why its working with Chrome ver 50\n. @tomasvts I was not able to find a solution and I am  not using socketcluster for my project now.\n. ",
    "tomasvts": "I would take a look at your nginx config, maybe you are making a redirect 301 there.\nAlso, I receive Socket hung up when an exception is thrown at the SocketCluster server. Maybe you should take a look at the server logs.\n. I managed to do the same without touching SocketCluster code.\nThis removes the process.on('SIGTERM') on SocketCluster index.js:48\nprocess.removeListener('SIGTERM', process.listeners('SIGTERM')[0]);\nBut if someone has another way to gracefully shutdown with async operations, it could help a lot to share it here. \n. Hello vivacarvajalito,\nTry this: \n1. In your server choose another port like 23644.\n2. Use npm to install socketcluster\nHere is my folder structure:\n/\n--package.json\n--index.js\n--/node_modules/\n-----/socketcluster/\n-----/socketcluster-client/\nIf you use npm to install socketcluster you will have all the dependencies resolved and you can use require(\"socketcluster-client\") just like that.\n1. package.json contents:\n   this is mandatory:\n....\n  \"dependencies\": {\n    \"socketcluster\": \"4.x.x\",\n    \"socketcluster-client\": \"4.x.x\"\n  },\n....\nYou do an npm install in the root folder and it will install correctly.\nAnd then in your client use this:\n```\nvar socketCluster = require('socketcluster-client');\nvar socket = socketCluster.connect({hostname: '127.0.0.1', port: 23664});\nsocket.on('connect', function () {\n     console.log('Connected');\n});\nsocket.on('error', function(error) {\n    console.log(error);\n});\n```\nIn your server you must be very sure to be like this:\n```\nvar SocketCluster = require('socketcluster').SocketCluster;\nvar socketCluster = new SocketCluster({\n    port: 23644, // important! The port number on which your server should listen\n ....\n....\nmore properties, etc...\n...\n\n});\n```\n. ",
    "sandyplace": "FYI: using uws appears to cause this same message using the latest Microsoft Edge browser as well. \n. @jondubois Works fine with Firefox and chrome. No worries, will use ws as the engine for now.\n. ",
    "aamirmsw": "Hey all Hi, I'm using socket cluster and getting this error \"Firefox can\u2019t establish a connection to the server at ws://......\n.   var options = {\n    port: 8000\n  };\n  var socket = socketCluster.connect(options);\n  socket.on('connect', function () {\n    console.log('CONNECTED');\n  }); \nIs it correct ? I have put it in .html file including socketcluster.js file.\n. Yes it is runing on port 8000, Now my problem has been solved its working fine ,Thank you !\n. ",
    "493326889": "can i use socketcluster-client in node?\ni have run a server and listening port 8000\n`{\n    workers: cpuNums, // Number of worker processes\n    brokers: 1, // Number of broker processes\n    port: 8000, // The port number on which your server should listen\n    appName: 'myapp', // A unique name for your app\n```\n// Switch wsEngine to 'uws' for a MAJOR performance boost (beta)\nwsEngine: 'uws',\n/ A JS file which you can use to configure each of your\n * workers/servers - This is where most of your backend code should go\n /\nworkerController: __dirname + '/worker.js',\n/ JS file which you can use to configure each of your\n * brokers - Useful for scaling horizontally across multiple machines (optional)\n /\nbrokerController: __dirname + '/broker.js',\n// Whether or not to reboot the worker in case it crashes (defaults to true)\nrebootWorkerOnCrash: true\n```\n}`\nand use socketcluster-client in node, then run it ,but it occured error.\n`var socketCluster = require('socketcluster-client');\nvar options = {\n    host: \"127.0.0.1\",\n    port: \"8000\"\n};\nvar socket = socketCluster.connect(options);\nsocket.on('connect', function() {\n    console.log('CONNECTED');\n});\n`\nerror msg:\nSocketProtocolError: Socket hung up\n    at Emitter.SCSocket.onSCClose (D:\\dev\\websocket\\websocket-server-test\\test\\\nnode_modules\\socketcluster-client\\lib\\scsocket.js:596:15)\n    at Emitter. (D:\\dev\\websocket\\websocket-server-test\\test\\node_mod\nules\\socketcluster-client\\lib\\scsocket.js:285:12)\n    at Emitter.emit (D:\\dev\\websocket\\websocket-server-test\\test\\node_modules\\co\nmponent-emitter\\index.js:131:20)\n    at Emitter.SCEmitter.emit (D:\\dev\\websocket\\websocket-server-test\\test\\node\nmodules\\sc-emitter\\index.js:28:26)\n    at Emitter.SCTransport._onClose (D:\\dev\\websocket\\websocket-server-test\\test\n\\node_modules\\socketcluster-client\\lib\\sctransport.js:168:30)\n    at WebSocket.wsSocket.onerror (D:\\dev\\websocket\\websocket-server-test\\test\\n\node_modules\\socketcluster-client\\lib\\sctransport.js:97:12)\n    at WebSocket.onError (D:\\dev\\websocket\\websocket-server-test\\test\\node_modul\nes\\socketcluster-client\\node_modules\\ws\\lib\\WebSocket.js:452:14)\n    at emitOne (events.js:96:13)\n    at WebSocket.emit (events.js:188:7)\n    at ClientRequest.onerror (D:\\dev\\websocket\\websocket-server-test\\test\\node_m\nodules\\socketcluster-client\\node_modules\\ws\\lib\\WebSocket.js:711:10)\n. @jondubois  thanks !!!!\n. @jondubois\ni also have another question\n```\n var socketCluster = require('socketcluster-client');\n  var CONNECT_MAX = 1000,\n    socketArr = [];\nvar options = {\n    hostname: \"127.0.0.1\",\n    port: \"22282\"\n};\nvar i = 0;\nwhile (i < CONNECT_MAX) {\n    i++;\n    socketArr.push(socketCluster.connect(options));\nsocketArr[i - 1].on('connect', function() {\n    console.log('CONNECTED ');\n});\n\nsocketArr[i - 1].on('rand', function(data) {\n    console.log('RANDOM STREAM: ' + data.rand);\n})\n\n}\n```\nwhen i make 1000 connect to the server, but the server log  current count is 1\u3002\n```\n   var count = 0;\n    scServer.on('connection', function(socket) {\n        count++;\n        console.log('current connection: ' + count);\n   var interval = setInterval(function() {\n        socket.emit('rand', {\n            rand: Math.floor(Math.random() * 5) + 'num:' + count + 'pid:' + process.pid\n        });\n    }, 1000);\n\n    socket.on('disconnect', function() {\n        clearInterval(interval);\n     });\n});`\n\n```\nif i want to make 1000 concurrent request , how to do ?\n. ",
    "lokielse": "\nWorking with Chrome, Safari.\nFirefox(macOS 58.0.2) not working \nOS: macOS High Serria 10.13.3 (17D102)\n\nFirefox console error\nuncaught exception: SocketProtocolError: Socket hung up\n\n\n\njs\nvar options = {\n    hostname: 'localhost',\n    port: 8000\n}\nvar socket = socketCluster.connect(options)\n. It has no connection with multiplex option if you open multiple tabs in a browser. \nI think your problem is caused by your worker logic. \n```js\n/\n In here we handle our incoming realtime connections and listen for events.\n/\nscServer.on('connection', function (socket) {\nsetInterval(function () {\n    scServer.exchange.publish('sample', 'sample')\n  }, 1000)\n})\n```\nAs the code say, To create a timer for each connection, publish a message every 1s, That's say four browser tabs will start four timers. Each client will receive 4 times of sample message for there 4 timers publish it for a while. . ",
    "micyee": "I know\uff01can not bind the event handler repeatedly. But socket.io don't like this.Do we need update the code to fixed it?\n. @MegaGM @jondubois - thank you for my doubts! I'm  too young too simple, and not well understood the socketcluster.\n. ",
    "vivacarvajalito": "Thanks thanks thanks for you.. \n. ",
    "naelt": "Good answer, thank you! It was interesting for me, how do i communicate with a specific Broker.\nThe reason is, my Worker subscribe a channel and in the next step (same sequence), he published data to him and wait for response inside this subscribed and watched channel handler  (the Broker even communicate per  async RPC with MQ).\nBut sometimes, as described, subscribing and publishing done in several Broker , which is inappropriate in my use case.\n. Thank you so much, now i understand my problem and solve it :)\nSC is just awesome \ud83d\udc4d . ",
    "zmikolaj": "Its only way?\n. Okey, thanks for response\n. javascript\nsocket.subscribe('test').watch(function (data) {\n    abc(data);\n});\nand i publish it to all clients:\njavascript\nscServer.exchange.publish('test', 'some string');\nbut i want too on first client connection send to only to him\njavascript\nsocket.emit('test', 'some string');\ndoesnt work, so should i do something like this:\njavascript\nsocket.on('test', function(data) {\n    abc(data);\n});\nand on client side i will have ON and SUBSCRIBE same channel?\n. Ye, but i want to use passport.js with http server, so its possible to use setAuthToken in express?\n. How i can create and sign new JWT token? And by sending you mean socket.emit with JWT token?\n. SocketProtocolError\nIts mean that client-side is outdated or server side?. Socketcluster on clientside 5.2.4 version.\nsocketcluster@5.2.1 socketcluster-server@5.4.1 on serverside.. @jondubois its good idea to use express midleware to use redis to rate limite user? so it will work on all workers?. Im using express-throttle with redis support. And if someone spam request like this https://scr.hu/6JMnnm 10+ request in one seconds, like two or three request went through, but it should rate limitting 1 request per 3 seconds.\n.edit\ni see every request its redirect to random worker, is there any way to limit globally socket? or express?\nmaybe anyway to same ip connecting to same worker?. ",
    "juxtaposition": "jondubois has right. The better practices is create a model for you channels, and have a service (handler) for you channel's model. \nfor example: \n```\nsocket.subscribe('alice:UUID_CONTEXT').watch(function(data) {\n   log(data);\n});\n// server side\nfunction sendToSomeone(context, data) {\n  scServer.exchange.publish('alice:context', data);\n}\n```\n. ",
    "picitujeromanov": "it works, thank you mate @jondubois \n. ",
    "tephro": "Yes, I'm using uws.\nHere is the config.\njavascript\nnew SocketCluster({\n    wsEngine: 'uws',\n    workers: 4,\n    brokers: 1,\n    port: 80,\n    appName: \"xxx\",\n    workerController: __dirname + '/worker.js',\n    brokerController: __dirname + '/broker.js',\n    socketChannelLimit: 10,\n    rebootWorkerOnCrash: true,\n    protocol: 'http',\n    pingTimeout: 60000,\n    pingInterval: 25000,\n    ackTimeout: 45000,\n    origins: 'xxx:80',\n    logLevel: 1,\n    propagateNotices: false,\n    middlewareEmitNotices: false,\n    downgradeToUser: 'xxx'\n});\n. Thanks, I will try both options and let you know.\n. Not a single segfault under quite heavy load after updating uws to 0.7.0.\nJonathan, thank you for quick suggestion. You're very helpful.\n. ",
    "jayrylan": "Could you have a single SocketCluster service and use channels? I've done some performance testing with SocketCluster and ran into no problem with a browser being subscribed to even 1,000 SocketCluster channels.\n. @vicneanschi In my experience a SocketCluster worker can do pretty much anything, you could definitely build in some sort of router into the worker. In my app, the worker sends request to Express, and I have a custom abstraction over Express's built-in routing to send different responses depending on the domain name being requested. \nMaybe something like that and a mixture of namespace prefixed channels would suit your use case?\n. @vicneanschi I would just have one process that does nothing but run SocketCluster on it's own domain/subdomain, and then keep all your microservices as their own independent processes which utilizes the ws websocket module on NPM to connect each microservice to SC, just as if it were a web browser, from there the microservice could publish, subscribe to channels, anything you need it to do.\nAll end users that connect to a microservice would then subsequently connect to SC via the shared subdomain.\nIf you don't intend for end users to have the ability to publish via SC, then you could use a secret key for each message that one of the microservices publishes to SC, and if that key isn't present, then the message doesn't get published to the other listeners in the channel(s).\n. @vicneanschi I meant that more as publish directly to the channel. I always opt for setting it up so that an incoming message from an end user must be vetted and screened by the app logic before it is broadcast out and \"republished\" to all listeners by SC.\n. ",
    "vicneanschi": "I need to host each service in a separate process. They come from different developers and should be deployed independently .\n. @jrylan I see what  you mean. But it's a bit different.\nI want to run different services (business logic) but independently so that they are isolated one from another and failure in one of does not affect other services. \nSo I'm thinking that separating services into different processes is the way to go.\nIn your case the owner of the connection is Express which lives in worker. \nBusiness logic also runs in worker. How do you restart just one service if they are hosted in one process?\nIn my understanding microservices are isolated one from another but I don't see how SocketCluster manages this isolation.\nPlease guide me.\n. @jrylan Thanks for your post. That's not a bad idea. I would expect microservices framework to provide multiprocess services support out of the box. Otherwise, I have to manage the lifecycle of the spawned processes.\nSpeaking of end users they need to have the ability to publish via SC. How would they interact with the service otherwise? \n. Alright I'll try to see what I cat get out of SC.\nThanks for fast replies.\n. ",
    "mirague": "@jondubois I ran this on Node 6.2.2 with --use-strict flag on. Without --use-strict the error does not show, but for our production environment we want a strict environment.\n. Thanks for your swift support, as always! @jondubois \n. ",
    "alexhultman": "0.7.6 is the latest. Windows support is only for Node.js 6.3.0 (will crash on any other version). Any SSL usage will also crash.\n. The only limit that can come into play is the 16mb limit per message (this is hardcoded currently), but that is only for receives. Is this 1.7mb file inflated to something larger than 16mb by any kind of base64 or something similar?\n. ",
    "wtgtybhertgeghgtwtg": "\nRemove backwards compatibility , or at most for versions < 4.0.0\n\nCan't this already be done?  If \u00b5WS is the default, and \u00b5WS requires at least 4.0.0, wouldn't that suggest that socketcluster is intended for at least 4.0.0?\n. base64url no longer depends on meow, so minimist@1.2.0 is no longer in the dependency tree.\n. > In the latest versions of SC, you can use Node.js v0.12.x if you comment out some of the default optional code in server.js and broker.js.\nWill this be documented?\n. That would require a bit more work. but that may be an option, as well.  Between socketcluster, socketcluster-server, and sc-broker-cluster, only three functions, applyEachSeries, waterfall, and parallel, are used.  I had taken a look at that a while ago, and it seemed that the functions could be optimized for their specific uses, as well.\n. There are a good number of things that can be done if socketcluster bumps the minimum node version to 4.  It might be enough to warrant a full rewrite.\n. Thank you for merging.\n. ",
    "Charuru": "Thanks, should we turn off logging for this? If so, how?\n. Thanks\n. Updating the client didn't fix it for me. I was using uws. I'll try to get you an example of a message, I think it might've been larger than 100k. \n. Yeah it was a 1.7m log file.\nhttps://gist.github.com/Charuru/ab35171707c62405683b2fa3154663e5\n. I'm going to try with ws.\nServerside error I got is: Got error: connect ECONNREFUSED 127.0.0.1:80\n. Yep works fine with ws. \nI think I'm going to go back to ws for development for now. It's only on localhost, no firewall. Over the network with a test server running ubuntu is actually fine in uws.\n. Thanks. I'm fixing up some errors. Do you have any advice for how to handle the clean up in general in case there are crashes for other reasons?. ",
    "dharma1teja": "Hi, i am using websocket open connection in jmeter to establish the socketcluster connection. I am facing problem in establishing connection, not able to see active users in server side.\nTest plan as below:\nthread group\nwebsocket open connection sampler---selected ws---dedicated ip is given --8000 port is given--path /socketcluster/\nadded view result tree\nadded screen shot for reference\n\n. I am able to see response code as 101 and response message as Response message: Switching Protocols and response headers as fallows\nResponse headers:\nConnection: Upgrade\nSec-WebSocket-Accept: F7b/7JzQ9iAMdhcOPeyoGIbX7ns=\nSec-WebSocket-Version: 13\nUpgrade: websocket\nWebSocket-Server: uWebSockets\nthese are the results i am able to see but no active users in server side.\nobserved this error:\n524146177889 - Origin: Worker (PID 14262)\n   [Warning] SocketProtocolError: Socket hung up\n    at SCSocket._onSCClose (/home/centos/jioplay/node_modules/socketcluster/node_modules/socketcluster-server/scsocket.js:240:17)\n    at WebSocket.internalOnClose (/home/centos/jioplay/node_modules/socketcluster/node_modules/socketcluster-server/scsocket.js:75:10)\n    at process.nextTick (/home/centos/jioplay/node_modules/uws/uws.js:445:27)\n    at _combinedTickCallback (internal/process/next_tick.js:131:7)\n    at process._tickCallback (internal/process/next_tick.js:180:9)\n. ",
    "cometta": "I tested this working fine now. May i know when we view the sourcemap , source file in chrome dev tool, it showed the babel transpiled code instead of raw es6 code. How to display es6 code in dev tool sourcemap? \n. ",
    "marcj": "Note: This does not work with ts-node, only with ts-node-dev.\nSo\nnode_modules/.bin/ts-node src/main.ts --inspect-workers\nwould not work. Just use the ts-node-dev package.\nnode_modules/.bin/ts-node-dev src/main.ts --inspect-workers\nand it prints something like \nDebugger listening on ws://127.0.0.1:5858/b2894045-ca5d-4b8a-ac3f-2594e980f655\nFor help, see: https://nodejs.org/en/docs/inspector\nDebugger listening on ws://127.0.0.1:5859/a9193138-6e08-4c79-b3c1-980434a6a257\nFor help, see: https://nodejs.org/en/docs/inspector\nwhich indicates it opened the debugging ports.. I see, thanks for the detailed explanation.\n\nIf you keep the same socket/exchange object around forever then you should call channel.destroy() when you're no longer using a channel \n\nHow do I detect if there are no subscriber anymore on a particular channel? I mean the memory leak happens in the Broker, which can consist of multiple broker instances. I'd need to connect to each broker and check there, or how do I get rid of those unused channel objects? Rule of thumb is probably to never call channel.destroy() as you can't be sure whether all clients to that Broker have unsubscribed, right?\n\nYou don't need to destroy the individual channels if you call socket.destroy() on the socket itself; destroying the socket will also destroy all the channels that are attached to it.\n\nOh, are you sure about that? Because destroying a channel (channel.destroy()) means all clients currently subscribed to it will automatically unsubscribe as well. Ergo, when I have 2 clients subscribing to channel test and one client disconnects, the channel('test') will be destroyed, resulting in a unsubscribtion (for this particular client it makes sense) and all of the other clients as well. This would be definitely unexpected and I would consider this as a bug. Or are you talking about a different technical implementation of 'destroying a channel upon client disconnect'?\n\nThe reason why channels are reused is because the SC socket needs to keep track of channels in order to pass data to them from the server so it needs to have a reference to the channel object\n\nI definitely see the reason behind that. I'd like to contribute to the website and clear some things up with more detailed explanation. Can you point me to a howto/description on how to contribute here?\nAlso, are you available for consulting? We're currently about to build a rather complex app using SocketCluster and would like to ask some questions. If so I'd love to write you an email/chat via skype/whatsapp/slack/whatever fits you best.. > The channel object is bound to a single client so destroying it only subscribes and destroys it on that client; it doesn't affect other clients\nWhen we talk about the client yes. Sorry, I was talking about the server side, where you have clientSocket.exchange from the scServer.on('connection', (clientSocket) => {}) event, which I thought is always a new instance per each new incoming connection. So I got confused that destroying a channel returned from clientSocket.exchange.subscribe() resulted in a total unsubscribe for all connected clients. Now that I know exchange is basically a own client per worker I understand why this happens. Thanks for clarification.\nSo, I assume the SimpleExchange is instantiated per worker. If so we could probably check on each client 'disconnect' event whether a channel has watchers open, if not then automatically delete that channel object to get rid of the memory leak. WYDT?. Ok, I replaced\njavascript\nscServer.exchange.watch('channel', (data) => {\nwith\njavascript\nexchange.subscribe('channel').watch((data) => {\nand it is working now. It seems the documentation is not very clear about what the difference is between exchange.subscribe('channel').watch(handler) and a simple exchange.watch('channel', handler). I'm afraid there's also a difference between exchange.publish('channel', data) and exchange.subscribe('channel').publish(data)?\nCan someone explain me, when to use exchange.watch if ever?\nIf this setup only works when using exchange.subscribe then I'm afraid I'm trapped with https://github.com/SocketCluster/socketcluster/issues/412.. ",
    "deoqc": "\nYes, both are equal except for env variables\nsocketcluster v4.6.2 (or v5.0.1 just tested)\nsc-broker v2.2.0\nsc-broker-cluster v2.1.3\nconcurrently v2.2.0\n  -node v5.8.0\n\nIt used to work just fine for me, and yesterday after 'npm install' it didn't (so I believe it were some update in the dependency sc-broker).\nI printed the keys:\n[0]    [Busy] Launching SocketCluster\n[1]    [Busy] Launching SocketCluster\n[0] (Top Level) Broker secretKey 432542019b5f9427f28c77571d37f22803dbef14e4c3af18810599f7e8d402da\n[1] (Top Level) Broker secretKey 42fcfe6de8f708326449dc6a65f750a99f6fc63f8facc6114e221d054610e3ae\n [0]    >> Broker PID: 5601\n[1]    >> Broker PID: 5602\n[1] (Check) Command secretKey 432542019b5f9427f28c77571d37f22803dbef14e4c3af18810599f7e8d402da\n[1] (Check) Broker secretKey 42fcfe6de8f708326449dc6a65f750a99f6fc63f8facc6114e221d054610e3ae\n[1] (Check) Command secretKey 432542019b5f9427f28c77571d37f22803dbef14e4c3af18810599f7e8d402da\n[1] (Check) Broker secretKey 42fcfe6de8f708326449dc6a65f750a99f6fc63f8facc6114e221d054610e3ae\n[0] 1470321494617 - Origin: Worker (PID 5605)\n[0]    [Error] Error: Invalid password was supplied to the broker\n(Top level) refers to key here and (Check) to keys here.\nStrangely, the test [0] doesn't print the (Check) - which is in the line before if/else clause - but is the one throwing error.\n\nedit:\njust to compare, this is what it prints when not run with concurrently:\n```\n(Top Level) Broker secretKey d35208dfef287358d93e768e8ca36eeef001a11c0686a7c52fd8f4e5bf4217b1\n\n\nBroker PID: 5702\n(Check) Command secretKey d35208dfef287358d93e768e8ca36eeef001a11c0686a7c52fd8f4e5bf4217b1\n(Check) Broker secretKey d35208dfef287358d93e768e8ca36eeef001a11c0686a7c52fd8f4e5bf4217b1\n(Check) Command secretKey d35208dfef287358d93e768e8ca36eeef001a11c0686a7c52fd8f4e5bf4217b1\n(Check) Broker secretKey d35208dfef287358d93e768e8ca36eeef001a11c0686a7c52fd8f4e5bf4217b1\n```\n\n\nEverything equals....\n. I don't even need to use concurrently for the error to happen, if I start both command rapidly it already does.\nI'm using OSX El Capitan v10.11.5.\nI use dotenv to load env variables at the very top of my call (the 'server/env' call bellow). After it, I don't change anymore.\n``` Javascript\nimport 'server/env'\nimport { SocketCluster } from 'socketcluster'\nimport { cpus } from 'os'\nconst numCpus = cpus().length\nnew SocketCluster({\n  workers: numCpus,\n  brokers: 1,\n  port: process.env.SERVER_PORT,\n  appName: 'App',\n  initController: __dirname + '/init.js',\n  workerController: __dirname + '/worker.js',\n  brokerController: __dirname + '/broker.js',\n  socketChannelLimit: 1000,\n  rebootWorkerOnCrash: true,\n})\n```\nWell, feels like could be it due to async loading, right? Any clues on how to properly do it, or should I try to build a reproducible example?\n. Tried both, didn't work..\n. Thanks @jondubois, both solutions worked!\nAnd thanks for the amazing working in socketcluster... I want to deepen my knowledge about it \n. Thx. Maybe should also update the middleware?\nAlso I think the Publish middlewares should have the data option (maybe req.subscribeOptions) available to them. \nA use case would be verifying credentials for publish in based on the data, or filtering out messages in publish out.\n. The use case I wanted was to use subscribe('some_channel', { data: {id: 'my_id'}}) instead of subscribe('some_channel-my_id'). So I needed to filter out each message in server to send only relevant / authorized data. \nBut I think this would be very inefficient against the first option. It would actually try to mimic the first option (and its middlewares) with a clearer syntax.\nI don't think it is actually worth the hassle. \nThx for the great support.\n. ",
    "ivan1986": "Ok, thanks, on 5.0 works\n. ",
    "JCMais": "Just a point, after working on something related, do not mutate the req.data inside the MIDDLEWARE_PUBLISH_OUT if your intention is to change the data just for this receiving socket.\nLooks like the changes are also forwarded to other sockets\nIs that expected @jondubois ?. @KristofVD nope, I've kept all data change on PUBLISH_IN. . idk how @luozan resolved this, but an easy and fast way to solve this would be to just use Redis to store the client state.. What are the plans here?\nNode.js supports async / await since Node.js 8. And promises are a good foundation to use them.\nFor that it would be needed to drop support for Node.js <= 6.\n6 is currently marked as Maintenance LTS, and will be EOL'd by April 2019. So that give us plenty of time. about your example, there is one thing that is missing on middlewares, you cannot have something similar to next(true), since throw true creates an error object with true.. I like that, socketcluster could also export two custom error objects to make those scenarios easier. So clients would just:\nthrow new StopSilentlyError()\nor\nthrow new HandshakeError(4444)\nJust an idea, the names are probably not that great.. How would you use consumeFooChannel for instance?. Glad it worked \ud83d\ude04 \n. ",
    "KristofVD": "Hi @JCMais , I encountered the same behavior. Did you already found a solution for this ?. ",
    "chegewara": "Try this. Maybe its what you need.\nhttps://github.com/chegewara/socketcluster-client-android\n. It uses webview just to load javascript socketcluster client, which is used to communicate with server thru socket pub/sub messaging. Its not as sophisticated and clean as @abpopov client, but works good to me.\n. I forgot I have node v 0.12 on this platform. I'm guessing so v 5.x.x requires node 4.x.x?\n. No. I wanted to start it on single machine one broker, one worker. Simple configuration.\n. I checked on 2nd machine. On nodejs v0.12.9 I got same error, but on v4.x.x everything works fine. Thanks for help.\n. ",
    "sacOO7": "Yeah, I think it uses WebView internally .Still ,I want native REST based library like socket.io client library.\n. Ok , not a problem. I will try it .\n. Hi @ranhsd , There is a mongo driver available for integration with node.js https://github.com/mongodb/node-mongodb-native. I think you should try out some of examples based on socketcluster APIs , as there is no need to send POST request by client in order to store messages. You can just emit message via socketcluster-client and corresponding server side API will handle everything for you.. Hi @ranhsd ,I think sending POST request is not a good approach. As you are developing real-time application , POST request will introduce some delay while travelling from client to server. I just want to know , why you don't want socketcluster server to have functionality to connect to mongoDB and store the messages ? If both servers are located in same cluster, you can create global mongodb-client driver instance and export it to both servers.. Hi @ranhsd ,Well , as I explained earlier, client will send emit message to server. Message will consist of data that you want to save on your database. Your socketcluster server file will consist of import for mongo client instance. There will be code block to handle incoming message where you will get message data and then you can save it in mongoDB. Then call publish method to publish data to intended users.\nI think this is most detailed explanation I can give without code :p . I think you should try out some examples .. ```\nimport logging\nfrom socketclusterclient import Socketcluster\nlogging.basicConfig(format=\"%s(levelname)s:%(message)s\", level=logging.DEBUG)\nimport json\napi_credentials = json.loads('{}')\napi_credentials[\"apiKey\"]=\"xxx\"\napi_credentials[\"apiSecret\"]=\"xxx\"\ndef onconnect(socket):\n    logging.info(\"on connect got called\")\ndef ondisconnect(socket):\n    logging.info(\"on disconnect got called\")\ndef onConnectError(socket, error):\n    logging.info(\"On connect error got called\")\ndef onSetAuthentication(socket, token):\n    logging.info(\"Token received \" + token)\n    socket.setAuthtoken(token)\ndef onAuthentication(socket, isauthenticated):\n    logging.info(\"Authenticated is \" + str(isauthenticated))\n    def ack(eventname, error, data):\n        print \"eventname is \"+eventname\n        print \"token is \"+ json.dumps(data, sort_keys=True)\n    socket.emitack(\"auth\", api_credentials, ack)\nif name == \"main\":\n    socket = Socketcluster.socket(\"wss://sc-02.coinigy.com/socketcluster/\")\n    socket.setBasicListener(onconnect, ondisconnect, onConnectError)\n    socket.setAuthenticationListener(onSetAuthentication, onAuthentication)\n    socket.setreconnection(False)\n    socket.connect()\n```\nTake a look at this code. Credentials are always supposed to be sent after onAuthentication callback.. Take a look at this issue https://github.com/sacOO7/socketcluster-client-python/issues/2\nStar the client if you like it.. Can you create that issue here https://github.com/sacOO7/socketcluster-client-python. Put your respective Javascript code in there. I think I can refer the same for other users. I'm closing this issue :+1: . No there is not a way to inform a client if it is not received by server. Timeout is the only thing you can do to check if request is received and  corresponding ack is received or not.. I think we have dot net client implementation available. You can use that client to develop unity game :+1: \nhttps://github.com/sacOO7/SocketclusterClientDotNet. Hi @Hirbod, I think you have some wrong assumption. You can use socketcluster js client in both node and browser. That way you do not have to worry about platform you are running. It can either be browser or node environment.. I think we need to take a look into this. Which version of socketcluster server are you using right now?. We have clients developed in both Java and swift. You can use the same for\nmobile app development\nOn Mar 23, 2018 5:31 PM, \"Jo Huang\" notifications@github.com wrote:\n\nHi\nIs Mobile native SDK being developed recently?\nWe would like to use SC but seems lack of mobile app supported.\nAnd the api spec seems not up-to-date.... (we may build our own sdk in C++)\nThanks\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/SocketCluster/socketcluster/issues/391, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AP8vSa26-l3pfZHTFMf-_Xzf8CMr0xB5ks5thOP7gaJpZM4S4mmL\n.\n. Those clients are native clients. So you don't have to worry about\nperformance issues. Please check official website for client info.\n\nOn Mar 24, 2018 12:24 AM, \"Sachin Shinde\" sachinshinde7676@gmail.com\nwrote:\n\nWe have clients developed in both Java and swift. You can use the same for\nmobile app development\nOn Mar 23, 2018 5:31 PM, \"Jo Huang\" notifications@github.com wrote:\n\nHi\nIs Mobile native SDK being developed recently?\nWe would like to use SC but seems lack of mobile app supported.\nAnd the api spec seems not up-to-date.... (we may build our own sdk in\nC++)\nThanks\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/SocketCluster/socketcluster/issues/391, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AP8vSa26-l3pfZHTFMf-_Xzf8CMr0xB5ks5thOP7gaJpZM4S4mmL\n.\n\n\n. Thanks for helping guy out @aza\n\nOn Jun 2, 2018 8:09 PM, \"Aza Noriega\" notifications@github.com wrote:\n\nClosed #418 https://github.com/SocketCluster/socketcluster/issues/418.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/SocketCluster/socketcluster/issues/418#event-1659646721,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AP8vSfouOLxKgzwmjZjL8PmJCeKGUdqkks5t4qOSgaJpZM4UUC6Y\n.\n. hi @pickmeup101 , great to see it's working \ud83d\udc4d . Is there any special request to add this feature in unity? Like having a readymade dll available in the client?. \n",
    "amekkawi": "Alternatively a solution would be to add another option like workerController but for the cluster \"master\" process.\n. Actually this is for when the \"server.js\" process dies either from a kill -9 or from an unhandled error.\nFor example:\n``` javascript\nvar SocketCluster = require('socketcluster').SocketCluster;\nvar socketCluster = new SocketCluster({\n    //...\n});\nsetTimeout(function() {\n    this.somethingThatDoesntExist();\n}, 2000);\n```\nWhen the timeout function runs it will throw an error that causes the SocketCluster entry (server.js) process to die. However since it's not a SIGTERM the workers and broker are not told to terminate and will remaining running.\nHowever, the cluster \"master\" process may eventually throw an error and die if it tries to send a message up to the \"server.js\" process. I'm assuming the broker would do the same.\nThe terminology is a little confusing so here is a diagram of the parts:\n\u2514\u2500\u252c SocketCluster entry (i.e. server.js)\n  \u251c\u2500\u2500 Broker\n  \u2514\u2500\u252c Cluster \"master\" (lib/workercluster.js and cluster.isMaster === true)\n    \u2514\u2500\u2500 Cluster \"worker\" (lib/workercluster.js and cluster.isMaster === false)\nNote: This is on socketcluster 5.0.4\n. Just a note: If the cluster \"master\" is killed the cluster \"worker\" will automatically die as well (which is good). I believe they are internally listening for the \"disconnect\" event on process as well, which means the IPC channel of the \"master\" process was lost.\n. I wouldn't catch the uncaught exceptions just in case someone implementing SocketCluster wants to handle them separately. Since you're exiting right after killing the workers, no other handlers registered after SocketCluster's handler would run.\nFor example:\n``` javascript\nprocess.on('uncaughtException', function (err) {\n  console.error(err);\n  socketCluster.killWorkers(); // This will kill the workercluster master too\n  socketCluster.killBrokers();\nprocess.exit();\n});\nprocess.on('uncaughtException', function(err) {\n    console.log('Second'); // Would never run\n    console.error(err.stack);\n});\n```\nAlso if the process is dies by any other method that doesn't allow code to run (out of memory or kill -9) then the cluster \"master\" and brokers would still remain running.\nInstead I'd duplicate the behavior of the builtin cluster module (see https://github.com/nodejs/node/blob/master/lib/cluster.js#L553) by listening for the \"disconnect\" event on process in the cluster \"master\" and broker processes. That event is triggered the the IPC channel is closed/disconnected.\nWhile I'm not sure where this would go for the brokers, an example of the code for the cluster \"master\" is in my original comment.\nFor the brokers I'm just inserting that code into the brokerController since it gives me a hook into the process. Since there isn't an equivalent for the cluster \"master\" I can't add the same hook.\n. Great! While there is still the issue of the broker, it's possible to address it using the brokerController option.\nOtherwise it would require an edit to https://github.com/SocketCluster/sc-broker/blob/4323889727f49588cea85247981667ae9f1c6ccb/server.js to also add a 'disconnect' handler. That might make sense since the next time process.send is called after a 'disconnect' it will throw an error.\nAlso thanks for the great library! I was just brought on to a project that uses SocketCluster and with this fix I'm behind it 100% :)\n. Absolutely! I am still working through the code base but I've forked with the intent of submitting PRs. Thanks again!\n. Performed clean npm install and confirmed the changes fix the issue. Thanks!\n. ",
    "luozan": "thanks,but I mean make client subscribed channel on server\n. I'm making a online game.Game players in a virtual room (A channel) before game start,but I can't sure whether player entered room (player subscribed channel) or not,then I don't know when to send start event or other events.\nIf server waits for client  to return the result of subscription,I worry that client does't return it.It's a html5 game,so player modifys the code is very easy\n. My English is so bad,so I hope you can understand.Thanks.\n. ",
    "nguyenhaian": "@jondubois I also want this feature.\n@luozan Do you have a solution for this case?. Try to call .lean() before call .exec() to get json object. Otherwise you get a Mongoose Object which can call some special function.\nsocket.on('chat_list_request', function (data, res) {\n    Model.find({ 'ended.value': false, touched_by_an_operator: false }).lean().exec().then(function (chats) {\n    socket.emit(\"chat_list\", chats);\n    res(null, 'Success');\n    });\n});. @jondubois This is my mistake, I update node to 6.9 then it works.\nThank you.. @jondubois Thank you. I understand your solution, but in my case, I want to decide right in MIDDLEWARE_AUTHENTICATE function whether or not user can log in.\nIf I check connection state like in your solution, I have to reject the new connection later. \nMay be I have to do that.. ",
    "toredash": "When using SSl certificates from AWS, you don't get access to the private key. You can only attach the SSL certificate to services within AWS that supports it.\nYou need to assign the SSL certificate to an AWS ELB, and create a target group within EC2 that points to your socketcluster instance(s). Then you run SocketCluster in non-ssl mode.\nDon't use CloudFront, it is for static content primarily. . My bad, I didn't fully understand the deployment on kubernetes. . @jondubois have you have any experience with pubSubBatchDuration and the affects of increasing this value? I'm only interested in the affects it could have on the servers performance.\nI looked at the code in ncom, and if I understand it correctly, by increasing this value one could reduce the number of websocket frames used to sent messages to subscribers, given that the messages was emitted at almost the same time.\nI looked at some stats for one of our broadcast-type channels, and from the timeline of messages that was sent out, quite a few of them was emitted at the same time. For instance we have 54 messages sent out at this specific time: 2017-11-19T02:53:56.310Z\nI'm finding it hard to measure the performance implications since once might not see a difference before you scale to a certain amount of subscribers / events withins pubSubBatchDuration.\nI'll let you know if I find something useful, appreciate any feedback.. @jondubois I'm having a hard time understanding how SCC will scale, and how resources are used within SCC in K8s. I hope you have a few moments to spare to look at \nWe are currently using SCC on AWS with OpenShift 3.6/Kubernetes 1.6. \nThe deployment socketcluster is setup with SOCKETCLUSTER_WORKERS and SOCKETCLUSTER_BROKERS set to 1. scc-state and scc-broker is plain, using the deployment files listed in https://github.com/SocketCluster/socketcluster/tree/master/kubernetes\nDuring testing, we have 20.000 clients subscribed to one channel and are publishing 1 event per second. We use 12x m4.large (2x vCPU / 8GB RAM) for compute nodes in k8s. socketcluster is not configured with SSL, SSL is terminated in a AWS ELB.\nDuring the test, we see next to -nothing- in terms of CPU load, memory usage and network util. on the scc-broker pods. Is this expected behaviour ?\nAbove you write:\n\nIn SCC's case though, because K8s automatically avoids port conflicts (and all SCC instances bind to the same port by default), it should never schedule more than one SC instance per host.\n\nand\n\nI know that there have been debates about whether or not it's better to run single process per container when using Docker/K8s, but in this case, it would add a lot of complexity (especially around load balancing) and it would be less efficient.\n\nI don't believe it is true that K8s won't schedule multiple instance., but I might be misunderstand you ? I'm able to schedule multiple socketcluster pods within the same compute node, nothing is limiting me from doing that unless you use podAntiAffinity on the deployment. I'm currently limiting each socketcluster pod to one core in k8s, and scale by adding multiple pods to the cluster to handle increase in load. Is this not the preferred way of doing it ?\nIf I'm reading you correctly, the best way to scale the socketcluster deployment is to use ENV variables (..._WORKERS and ..._BROKERS) to match your compute node core count(?). If yes, one should add podAntiAffinity rule so that only one socketcluster pod is running on each compute node.\nSome input regarding this would be very helpful.\nAlso, if we subscribe to many clients at once(500 per second), the health-check in the socketcluster deployment starts to fail on every pod, causing the whole service to fail. I haven't figured out why, if was terminated on each socketcluster pod I could get it, but SSL is terminated at AWS. Any experience or advice around this ?\n. K8s will try to spread out pods from the same deployment to multiple hosts if possible, but there is nothing limiting it to have many of the same pod on the same host.\n\nUsing ENV variables is the recommended approach to scale up across CPU cores. Let me know if you can confirm for sure that podAntiAffinity rules are required now because I'm pretty sure that this was not a requirement before (can't remember the exact K8s version I tested with).\n\nIf the goal is to run one socketcluster pod on each compute node, and use all available cores on that particular compute node, then you indeed node podAntiAffinity rules setup\nExample from our environment, we run 6 replicas of socketcluster, and we have 6 compute nodes:\n$ oc get pod -l app=socketcluster  | grep socket | awk '{print $1}' | xargs -n 1 oc describe pod | grep Node: | sort | uniq -c\n   2 Node:          ip-10-20-4-109.eu-central-1.compute.internal/10.20.4.109\n   1 Node:          ip-10-20-4-158.eu-central-1.compute.internal/10.20.4.158\n   1 Node:          ip-10-20-5-124.eu-central-1.compute.internal/10.20.5.124\n   1 Node:          ip-10-20-5-97.eu-central-1.compute.internal/10.20.5.97\n   1 Node:          ip-10-20-6-180.eu-central-1.compute.internal/10.20.6.180\nHere, two pods are sharing the same host, this isn't a issue regarding port assignment, since each pod has its own IP.\nYou can verify this by using a simple nginx container:\n```$ oc run nginx --image nginx --replicas=20\n$oc get pod   | grep nginx | awk '{print $1}' | xargs -n 1 oc describe pod | grep Node: | sort | uniq -c\n   4 Node:          ip-10-20-4-109.eu-central-1.compute.internal/10.20.4.109\n   3 Node:          ip-10-20-4-158.eu-central-1.compute.internal/10.20.4.158\n   5 Node:          ip-10-20-5-124.eu-central-1.compute.internal/10.20.5.124\n   2 Node:          ip-10-20-5-97.eu-central-1.compute.internal/10.20.5.97\n   1 Node:          ip-10-20-6-175.eu-central-1.compute.internal/10.20.6.175\n   5 Node:          ip-10-20-6-180.eu-central-1.compute.internal/10.20.6.180\n$ oc get pod   | grep console | awk '{print $1}' | xargs -n 1 oc describe pod | grep IP:\nIP:         172.16.16.96\nIP:         172.16.20.118\nIP:         172.16.22.83\nIP:         172.16.16.95\nIP:         172.16.16.99\nIP:         172.16.10.118\nIP:         172.16.10.120\nIP:         172.16.14.70\nIP:         172.16.16.98\nIP:         172.16.16.97\nIP:         172.16.22.84\nIP:         172.16.18.74\nIP:         172.16.20.119\nIP:         172.16.10.117\nIP:         172.16.22.80\nIP:         172.16.22.81\nIP:         172.16.14.71\nIP:         172.16.14.69\nIP:         172.16.22.82\nIP:         172.16.10.119\n```\nThere seems to be some parts that is not to clear when it comes to using K8s with SCC. You have given me valuable input and I will share what I can once we have done all of our testing and optimisation. Thanks for the quick reply. @jondubois I've made a PR (https://github.com/SocketCluster/socketcluster/pull/331) to add podAntiAffinity rules to socketcluster deployment.\nAn alternative approach, that seems to be betterfor my usecase, is using DaemonSet (https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/) - this way I always ensure that I have one socketcluster instance running on every k8s nodes available. You can also select nodes based on labels.\nWhen I add or remove k8s nodes in my cluster, new socketcluster instances is brought up/down with the cluster resize, always using all available cores since that is what I've configured the DaemonSet to do.\n\nAlso, regarding my last reply: The reason why the current deployment file for socketcluster doesn't work as intended, is also related to resource assignment (or lack thereof) to the deployment specification (https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/). \nWhen no limit or request is made, k8s doesn't know what the particular pod may require in terms of resources. For all it knows, it may be 1 full core, og just 1/100th of a core. Hence, it can and will schedule multiple instances on the same k8s node.\nUsing podAntiAffinity, you at least ensure only one particular type of pod is running on one k8s node at any given time.\nhttps://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/. Hi Jonathan,\nI made three PRs to upgrade scc-broker and scc-state:\nhttps://github.com/SocketCluster/scc-state/pull/2\nhttps://github.com/SocketCluster/scc-broker/pull/1\nhttps://github.com/SocketCluster/socketcluster/pull/325\nAlso bumbed npm versions of socketcluster* and upgraded node from v6 to v8 as the base image for the Dockerfiles. Added two PRs to update node to use LTS in Dockerfile:\nhttps://github.com/SocketCluster/scc-state/pull/4\nhttps://github.com/SocketCluster/scc-broker/pull/3. Hi,\nWe have done tests internally to see how frequent we can publish messages, at what size, with X amount of different subscribers, before the system will break.\nIt is really hard to give any good numbers here, as there is multiple factors that can cause variation in how quick we can dispatch messages to end-users. Latency on client, variable network throughput per VM in the cloud, noise neighbour etc.\nOne thing I know can \"break\" SCC, is if a large message is sent to a channel with large number of subscribers. Multiple things can happen then while SCC tries to send out the event to subscribers:\n* If SCC is running on Kubernetes, the health check can fail since it can't respond since it is struggling to dispatch events. If K8 then terminates the instance, you can have a cascading failing. I've set a high number \"periodSeconds\" to work around this. But if the message isn't dispatched to everyone within the set time, you will have a cascading failure (from what we have seen at least)\n\n\nIf ping isn't satisfied on the client side, it will try to reconnect, causing more load in SCC. And if you then try to fetch previous events, that can generate even more load.\n\n\nIf you don't spread out reconnects, that can overwhelm a node.\n\n\nIt would be nice if SCC, both on server on client side, would be able to detect and handle increased load in a dynamic way. For instance we dynamically add some latency to queue the process that sends messages to a channel in SCC. So that each message inserted is delayed 50ms before it is sent in SCC, preventing that the process suddenly pushes 10.000 messages at once to SCC.\nI don't know if anything like this could be implemented in SCC to ensure clients doesn't disconnect. Maybe one could use CPU load or load avg as well ? If SCC had two types of channels, e.g. real-time and near-realtime, that could maybe help?\nPosting random ideas and feedback, hope some of it comes to use.\n. @jondubois A lot would be solved for our part if we were certain that clients wouldn't disconnect when the load on SCC was high. A delay of 1-5 sec is fine, but we would also from an operation perspective like to know if SCC is working and just strained for resources, or if it isn't processing anything.\nThats maybe the different requirement we have from others: Real-time is nice to have, but \"near-realtime\" is perfectly fine.\nWe have chosen now to fetch all previous messages sent to a channel if a client reconnects, which we know causes a lot of traffic to our caching instances. We have done this to be sure the client have all messages in the event of a reconnect.\nI haven't seen/found anything in SCC that works like this:\nClient connects to channel\nMessage 1 to 10 is sent to channel, client receives all 10\nClient reconnects\nMessage 11 to 12 is sent\nClient reconnects, informs SCC that message # 10 was the last it received.\nSCC pushes message 11 and 12 to Client\nI don't know how much compute this would require from SCC, but that would at least solve some of our scaling issues if we have a sane way of knowing that clients would get the last X messages sent to a channel.\nA way of offloading large events to a HTTP CDN Cache is also a way to offload those huge events.. @happilymarrieddad \nThe approach is good, but it feels very static. If I understand the code correct, this isn't a more efficient way of publishing messages? If there is available resources there shouldn't be a need to limit how fast SC operates. \n@jondubois \nThanks for input regarding snapshotting. I think that approach wouldn't scale in our setup because of the large amount of subscribers and messages.. FYI,\nWe have tried with success a async queue that uses a (configurable) minimum and maximum delay for emitting messages to a channel. The delay is dynamic, based on load.\nExample, define a minimum delay of 100ms and a maximum delay of 1000ms. When a worker is emitting message, check (os.loadavg()[0] * 1000) / os.cpus().length. If that value is in between min and max, delay message with that amount of ms.\nIf below, use minimum delay.\nIf above, use maximum delay.\nWe run each SCC instance on all cores.\nFor our usecase, this works very well.\nWe did try to play with pubSubBatchDuration with little luck, I'm not sure how much we would save on server-resources. AFAIK we would save some websocket frames but I don't think that would be our main bottleneck either way.. Is there anything I can do to help with this? Would be nice to get new images when e.g. new node security images are available.. Where do you run kubernetes @masalinas  ?. > My questions are: how many concurrent users will this server be able to handle?\nIt depends. This sounds like a single program with multiple users who are allowed to send and receive messages. With that in mind you need to ensure you have enough workers, 1 per CPU seems good.\nMessage size (chat message really), number of messages, and number of subscribers / users will limit the performance.\nI'm just doing a wild guess here, but I would assume that server would be able to support 100.000 users. You can easily test this by spinning up som AWS EC2 instances that spawns 10.000 clients that randomly sends and receive messages. Once one instance is running, add another one to see how your server would perform.\n\nDo I have to setup a nginx proxy to loadbalance? (using like 5-10 ports?).\n\nNot if this is a single server.\n\nDo I have to care about nodejs garbage collection? https://blog.jayway.com/2015/04/13/600k-concurrent-websocket-connections-on-aws-using-node-js/\n\nI'm not sure.\n\nIs there any advice you could give me on this? Do we need more servers to achieve what we need?\n\nIf possible, use cloud and kubernetes. Since each \"live chat event\" is running ~15min, its much better to spin up to much resources for a short amount of time then to overload the server. I've tested to break SCC but overloading it with to many users, and it will break hard. Only way to recover in our test was full restart of the environment while also adding more resources.. 1-2 brokers should be enough IMHO.\nI would consider using Kubernetes. Google Cloud have Kubernetes as a Service (https://cloud.google.com/kubernetes-engine/) that works well. They also provide load balancing services that can distribute load based on number of connections to the backend, so you get efficient distribution.. Thats expected. Each tab is a unique session, and if that session is logged in with the same user and that user receives a message, each tab would of course get the same message since thats how your app is written.\nIf you want your app only to allow a user to be logged in once, you need to write some logic to disconnect an existing user.. Ah that explains it, I didn't understand the question then. Thats not expected AFAIK. Not sure what it can be.. On each worker you should loop through the subscribers and count, and store that in e.g. redis so you can count the total number.. That would be the same. You can look at each socket and see what channels it's subscribe to. If it's a welcome message couldn't you trigger an event when the user subscribes to the channel? . I've found that for best performance, use c4 instances and set aside one CPU core per 10.000 users. I've never consider T2 instances for this workload. \nWith that, I'm able to push one message per second at around 1K.\nI assume you are using at least 6_\n-7 brokers in your setup?\n. In our tests we find that to ensure performance we should limit 5000 users to one CPU core. Then we can emit a single message, every second, more than that the system can struggle. Also it depends on the message size, and quality of the server.\nE.g. a large instance from a cloud provider will have in general better CPU and network performance than a small one.. @MatthewAry do you connect all clients at once, or is distribution even? \nIf possible if would be nice to see how this behaves if you turn of SSL. I suspect that it might be related to low entropy available on the machine, and new SSL connections can't be made quick enough.. ",
    "CoveTechnologyAus": "@jondubois , thank you very much for the reply, that cleared things up heaps.\nThe only question I have is still with the server side, so with what you have explained here:\nSC should be able to pick up and verify your JWT token automatically if it has the same authKey as the one which you used to sign the JWT token.\nDoes this mean I should just be able to pass the token along to the SocketCluster server without the need to emit the \"login\" message to the SocketCluster server. I am guessing I will already have a token on the client that matches the authkey on the server (providing both Passport and SocketCluster are using the same authkey)\nI'm sorry if that is an obvious questions, if I have it right then I have been WAY overthinking it all and this is really much simpler and better than I originally thought.\n. ",
    "ubaidseth": "@jondubois Very nice. Thank you for the clear and concise answer.\nI was trying to kill the channel from the server end whenever the client disconnects.\nThe channels were dynamically created - the name of the channel is the client's session ID. I was trying to privatize each client's interaction with the server as not to mix data on one global channel.\n. ",
    "willypuzzle": "Have you tried array of objects and/or objects that contains arrays of objects?\n. @jondubois I would emit mongoose find results of complex objects stored in MongoDB database.\n. @jondubois I don't receive event at all but If I \"Objectify\" the arrays all works fine. I'm using socketcluster-server 5.1.0.\n. I upgraded to the latest version of server (5.1.1) but the problem persists\n. @jondubois I have to correct myself, the event is emitted but the array I receive in client side is always empty.\nThis is an example:\n```\nvar mongoose = require('mongoose');\nvar Promise = require('promise');\nmongoose.Promise = Promise;\nconst modelName = 'chat';\nvar schema = new mongoose.Schema({\n    attributes: {\n        type: [mongoose.Schema.Types.Mixed],\n        default: []\n    },\n    touched_by_an_operator: {\n        type: Boolean,\n        default: false\n    },\n    operators: {\n        type: [mongoose.Schema.Types.Mixed],\n        default: []\n    },\n    users: {\n        type: [mongoose.Schema.Types.Mixed],\n        default: []\n    },\n    ended: {\n        type: mongoose.Schema.Types.Mixed,\n        default: {\n            value: false,\n            reason: null\n        }\n    },\n    created_at: Date,\n    updated_at: Date\n});\nvar Model = mongoose.model(modelName, schema);\n/You have to retrieve a correct socket instance that is a instance of SCSocket (server, worker)/\nsocket.on('chat_list_request', function (data, res) {\n    Model.find({ 'ended.value': false, touched_by_an_operator: false }).exec().then(function (chats) {\n    socket.emit(\"chat_list\", chats);\n    res(null, 'Success');\n    });\n});\n```\n. @jondubois I discovered that the broadcast system (scServer.exchange.publish()) fails to convert ObjectId (_id of MongoDB) into string when build the json to send. \nMaybe the system is not able to deal with Date Object or ObjectId when emit the event. \nThis because the objects got from MongoDb are not all string but there are Javascript Object too.\nMaybe this is the reason I can't put a MongoDB object directly in the emit stream.\n. I have found a workaround if I wrap the Mongodb results with \nJSON.parse(JSON.stringify(results))\nit works.\n. I can't reproduce it without MongoDB because the issue was on _id field. It fails in ObjectId objects. When I have a few of time I will post the complete stack error.\n. @jondubois Now the situation is better, the result objects/array comes to the client side but the ObjectId fields are not correct. Instead of the normal value e.g. \"57f2126f3f45ed18d9942ad4\" it returns values as \"0\" or \"1\". The problem doesn't persist if I transform ObjectId (for example _id field) into string before sending.\nI think the issue is in the conversion of ObjectId fields into string before sending.\n. @jondubois If I call JSON.stringify directly on the model results the ObjectId fields are correct strings with the correct value e.g. \"57f2126f3f45ed18d9942ad4\"\n. @jondubois I had tried to catch the error in the middleware but I haven't found anything. However I'll check very carefully and I will let you know.\n. @jondubois I have tested in other parts of my code and, as you said, it works correctly. So I think it is a issue of my code. I'm sorry for the wasting of time.\n. ",
    "wmertens": "Oh cool! Thanks :)\n. @jondubois This is no longer possible with v9, what is the recommended way now? I learned a lot about hot reload so I can help out with that part\u2026. I made a custom listener for passing hot reload events via childprocess messages, it turned out to be very simple. https://github.com/ericclemmons/start-server-webpack-plugin/blob/use-the-fork/src/monitor.js\nI also use socketcluster, but in development I use a stub that runs the worker directly, so the monitor hot reloads the worker.\nI just now noticed that SC handles SIGUSR2 to restart workers, and start-server-webpack-plugin (v2, not the branch I linked above) can send SIGUSR2 events on module rebuild events, so SC could instead send a message to the worker to handle the hot reload.\nNote that SIGUSR2 doesn't seem to exist on windows, so instead SC could just have code like this in the server\njs\nif (module.hot) {\n  module.hot.accept(pathToWorker, () => sendHotReloadToWorker())\n}\nand on receiving the hot reload message, handle it as in the monitor I linked above.\n(For that to work, the file handling module.hot must be part of the bundle generated by webpack). I was using this code to run a single-process socketcluster in development:\n```js\nimport socketClusterServer from 'socketcluster-server'\nimport http from 'http'\nimport {run} from './worker'\nconst httpServer = http.createServer()\nconst scServer = socketClusterServer.attach(httpServer)\nrun({httpServer, scServer})\nhttpServer.listen(80)\n```\n(transpiled of course)\nHow should I adjust this so it works again?\n. I already use nginx as a proxy, it doesn't do that either. It seemed to me\nthat sc is in a good position to do this; or is that hard due to its\narchitecture?\nCould you point me to a starting point in the code where something like\nthis could be implemented?\nOn Sun, Apr 8, 2018, 1:35 AM Jonathan Gros-Dubois, notifications@github.com\nwrote:\n\nClosed #384 https://github.com/SocketCluster/socketcluster/issues/384.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/SocketCluster/socketcluster/issues/384#event-1562381654,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADWliwFVzXyKwIS0MS9fcXp9_HG1b4pks5tmU1LgaJpZM4Smen4\n.\n. On Sat, Jul 28, 2018, 8:27 AM Aza Noriega notifications@github.com wrote:\nIt seemed to me that sc is in a good position to do this\nWell, from my POV, if you get 50x errors from an upstream(SocketCluster),\nit seems impossible to do something about it on the upstream side, since\nit's probably is not running (yet or already). But you could intercept such\nerrors in Nginx.\n\n\nactually, the upstream is SC, which controls its workers, and is fully\naware that the workers are being restarted.\nSo handling it in nginx is too late, you lose information.\nCould you point me to a starting point in the code where something like\n\nthis could be implemented?\n@wmertens https://github.com/wmertens Look at the following Nginx\ndirectives:\nproxy_intercept_errors\nhttps://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_intercept_errors\nerror_page\nhttps://nginx.org/en/docs/http/ngx_http_core_module.html#error_page\nI know that nginx can do it, provided you run an extra process that\npretends to be an upstream. It will hide real 500 errors, and it is\ncumbersome to set up. In SC it's probably only a few lines of code that\nwill benefit a lot of users.\n. @MegaGM Aha! Thanks for the detailed answer!\n\nNo, I think you got me right :) I was mistakenly thinking that SC proxies the connections to the workers, and now I realize that would be very inefficient.\nWhat I want to achieve is, if I release a new version of my app, and it doesn't need a new server.js, I can simply tell SC to restart the workers and load the new worker version.\nHow about this approach, the halfway between your approach 1 and 2:\n\nKill+replace all workers (gracefully) with a new SCWorker that just holds incoming requests until signaled\nOnce all workers are replaced, send a signal\nThe signal causes each SCWorker to require() the new worker.js and pass the held connections to it\n\nWould that work?. I found that it wasn't due to USR2 in any case :) Closing.. ",
    "ivopc": "I am noob with git (lol), so, somebody can send a pull request to correct 547 line in the socketcluster-server/scserver.js to:\nreturn !!event && String(event).indexOf('#') == 0;\n Thanks.\n. That is great. I only will use brokers for scaling horizontally?\n. Here are the most \"correct\" way to deal with this error:\n```\nSocketCluster.prototype.warningHandler = function (warning, origin) {\nwarning = warning || new UnknownError(warning);\nwarning.stack = warning.stack || warning.message;\nwarning.origin = origin;\n  warning.time = Date.now();\nthis.emit(this.EVENT_WARNING, warning);\nif (this.options.logLevel > 1) {\n    this._logObject(warning, 'Warning');\n  }\n};\n```\nI do not understand how exactly warning object is passed.\n. the data is just a:\nObject.create({\n    \"any\": \"data\"\n})\nand my version is 5.0.16\n. I really don't know what is causing it, my code is like any other. I'll update my SC version and'll give you the feedback.\n. Planning to write a native webrtc client2server too, maybe with c++ libs implemetations. This will be a necessity of my project and I want to share with devs.\n. @jondubois Thanks for advice, I'll start the project maybe in the next year.\n. ",
    "vaskevich": "To follow up on this, is there a good way to stub out the JWT logic? I'm using client-sessions to maintain sessions that are stored in an HTTP-only cookie. Instead of JWT-based auth, I'd just like to use the scServer.MIDDLEWARE_AUTHENTICATE middleware to handle reading the cookie and authenticating, without dealing w/JWT.. Gotcha, thanks for explaining. The issue with authentication state remaining constant during the connection isn't an issue for me.\nOn the implementation side, would you just recommend setting a custom auth engine that essentially does nothing on the client and server side? Would like to avoid sending/validating JWT tokens if they won't be at all used.. ",
    "artooroff": "@jondubois  can You help us to implement?  Here are skypes : djortoor,  gevorg19965\n. ",
    "jsynowiec": "Thank you for the explanation. Those were the missing peaces that I needed. One more thing - if, for some reason, a worker crashes and is restarted, does it get the same id or a new one? Currently I'm using only the leader worker as a MQ forwarder and I'm wondering if I can somehow loose the leader? I know that this is not an optimal solution due to lack of scaling but there is currently only one queue (topic) to rebroadcast.\n\nStoring session data inside a JWT token using \n\nYes, this is a common pattern but I'm dealing with a lot more state information. After reading documentation, issues and source code I can see that I have to implement some sort of state-syncing between workers myself, right?\n\nYou can require custom Node.js modules using var myModule = require('./someModule.js') inside worker.js so you can spread out your logic over multiple files.\n\nThanks, I know this. My case is a bit different than just splitting the code.\n. ",
    "jscheel": "You can sync state between your workers by using the exchange, I believe.\n. ",
    "iMoses": "No, npm install goes smoothly.\nI get this message on a loop when trying to run a worker, it keeps crashing.\nWhat information can I provide that will assist?\nI need to get it working as part of an electron application, so docker is not really an option.\n. 64-bit, on two different PCs with Ubuntu 16.04\nBoth were bought in the last 18 months, both are strong PCs\nIt seems that the worker crashes just by trying to import uws\n1479419902894 - Origin: Worker (PID 5931)\n   [Error] Error: Compilation of \u00b5WebSockets has failed and there is no pre-compiled binary available for your system. Please install a supported C++11 compiler and reinstall the module 'uws'.\n    at e (/home/imoses/repos/tools_client/app/node_modules/uws/uws.js:25:19)\n    at Object.<anonymous> (/home/imoses/repos/tools_client/app/node_modules/uws/uws.js:29:3)\n    at Module._compile (module.js:556:32)\n    at Object.Module._extensions..js (module.js:565:10)\n    at Module.load (module.js:473:32)\n    at tryModuleLoad (module.js:432:12)\n    at Function.Module._load (module.js:424:3)\n    at Module.require (module.js:483:17)\n    at require (internal/module.js:20:19)\n    at EventEmitter.SCServer (/home/imoses/repos/tools_client/app/node_modules/socketcluster-server/scserver.js:83:18)\n1479419902896 - Worker 0 exited - Exit code: 1\n1479419903031 - Origin: Worker (PID 5936)\n   [Error] Error: Compilation of \u00b5WebSockets has failed and there is no pre-compiled binary available for your system. Please install a supported C++11 compiler and reinstall the module 'uws'.\n    at e (/home/imoses/repos/tools_client/app/node_modules/uws/uws.js:25:19)\n    at Object.<anonymous> (/home/imoses/repos/tools_client/app/node_modules/uws/uws.js:29:3)\n    at Module._compile (module.js:556:32)\n    at Object.Module._extensions..js (module.js:565:10)\n    at Module.load (module.js:473:32)\n    at tryModuleLoad (module.js:432:12)\n    at Function.Module._load (module.js:424:3)\n    at Module.require (module.js:483:17)\n    at require (internal/module.js:20:19)\n    at EventEmitter.SCServer (/home/imoses/repos/tools_client/app/node_modules/socketcluster-server/scserver.js:83:18)\n1479419903033 - Worker 0 exited - Exit code: 1\nThis goes on and on and on...\n. I tried deleting node_modules several times already.. no luck\n. Linux imoses-pc 4.4.0-45-generic #66-Ubuntu SMP Wed Oct 19 14:12:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nI haven't tried npm cache clean until now, it does seem to have changed something.\nI think I have a bigger bug here that may not belong to you.\nFor some reason, SocketCluster still ignores my wsEngine: 'ws' but it does seem to work:\n```\n   [Busy] Launching SocketCluster\n\n\nWorker PID: 8426\n   [Active] SocketCluster started\n            Version: 5.0.24\n            Environment: dev\n            WebSocket engine: uws\n            Port: 8000\n            Master PID: 8407\n            Worker count: 1\n            Broker count: 1\n```\n\n\nBut when I try to run it as part of an electron application I still get the same error messages.\n. No, it was installed as a regular dependency.\n. The part about wsEngine was my bad, I was indeed loading configuration from the wrong place.\nThanks a lot for you help\n. ",
    "CoolHandLuke88": "I ran into this exact issue.\nI wanted to leave this here for anyone else that may run into this issue with docker and uws installation.\nHope you guys don't mind I drop this here.\nIn Dockerfile\n\nFROM node:8.9-alpine\nRUN apk add --update \\\nlibc6-compat\n\nNeeded libc6-compact\nThis should resolve the issue seen below.\nError: Compilation of \u00b5WebSockets has failed and there is no pre-compiled binary available for your system. Please install a supported C++11 compiler and reinstall the module 'uws'.. I ran into this exact issue.\nI wanted to leave this here for anyone else that may run into this issue with docker and uws installation.\nHope you guys don't mind I drop this here.\nIn Dockerfile\n\nFROM node:8.9-alpine\nRUN apk add --update \\\nlibc6-compat\n\nNeeded libc6-compact\nThis should resolve the issue seen below.\nError: Compilation of \u00b5WebSockets has failed and there is no pre-compiled binary available for your system. Please install a supported C++11 compiler and reinstall the module 'uws'.. I ran into this exact issue.\nI wanted to leave this here for anyone else that may run into this issue with docker and uws installation.\nHope you guys don't mind I drop this here.\n*In Dockerfile\n*******\nFROM node:8.9-alpine\nRUN apk add --update \\\nlibc6-compat\n\nNeeded libc6-compact\nThis should resolve the issue seen below.\nError: Compilation of \u00b5WebSockets has failed and there is no pre-compiled binary available for your system. Please install a supported C++11 compiler and reinstall the module 'uws'.. @FinaOePrs This if your specifically using Docker Containers with Nodejs. Dockerfile is the file edited to fix uws. see link: https://docs.docker.com/engine/reference/builder/. Please let me know if this helps. . ",
    "seclace": "As a workaround I run cd node_modules/uws and node-gyp rebuild commands.\n(This module is used by socket cluster server in my react-native project). \nConsider that your python binary has version is > 2.5 and < 3.0.0, node-gyp uses python for it.\nCommand | Value\n------------ | -------------\nuname -a | Darwin here's my name 16.7.0 Darwin Kernel Version 16.7.0: Mon Nov 13 21:56:25 PST 2017; root:xnu-3789.72.11~1/RELEASE_X86_64 x86_64\nnode -v | v8.9.4\nnpm -v | 5.6.0\npython --version | Python 2.7.10. ",
    "cjmling": "Had this same problem. And I got it solved by\nDelete node_modules folder then npm install which download everything again DIDN'T SOLVE\nDelete node_modules\\uws folder then npm install which only re download uws SOLVED . ",
    "brunolemos": "I was able to fix this way:\n\n\nInstall the LTS version of nodejs (I used the command npx n lts)\n\n\nRun:\nshell\nrm -rf node_modules/\nnpm install\npushd node_modules/uws\nnpm install\npopd\nnpm start -- --reset-cache\n\n\n\n\nEDIT: If using react-native, you may also need to do this first:\n\nbrew install watchman\nnpm install -g react-native-cli\nwatchman watch-del-all && rm -rf $TMPDIR/react-*\n(and then run the commands above). ",
    "ghoshabhi": "@cjmling's solution works!. ",
    "dotbloup": "Using node 10, npm 5.6 and python 2.7.14, I have tried the solution from @cjmling but there is a built error. after typing npm i uws, \"make\" failed during built of uws. in node_modules/uws/build_log.txt\nDoes it mean the issue is related to the uws package?\nmake: *** [Release/obj.target/uws/src/addon.o] Error 1\nmake: Leaving directory `/root/seoserverdev2/node_modules/uws/build'\ngyp ERR! build error \ngyp ERR! stack Error: `make` failed with exit code: 2\ngyp ERR! stack     at ChildProcess.onExit (/usr/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:258:23)\ngyp ERR! stack     at ChildProcess.emit (events.js:182:13)\ngyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:225:12)\ngyp ERR! System Linux 3.10.0-514.el7.x86_64\ngyp ERR! command \"/usr/bin/node\" \"/usr/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js\" \"rebuild\"\ngyp ERR! cwd /root/seoserverdev2/node_modules/uws\ngyp ERR! node -v v10.0.0\ngyp ERR! node-gyp -v v3.6.2\ngyp ERR! not ok\nThe file is really long so it is attached\nbuild_log.txt\n. Here is what I did as a workaround to fix the issue, I added SOCKETCLUSTER_WS_ENGINE='ws' to a .env file in the main root path and I added require('dotenv').config(); at the top of my server.js\nSo, rather than using uws, i use ws. I also discovered that ws was maintained by many more people than uws. \nAlternative: replace wsEngine: process.env.SOCKETCLUSTER_WS_ENGINE || 'uws' by \nwsEngine: process.env.SOCKETCLUSTER_WS_ENGINE || 'ws' in server.js\ndo something similar for scc-state / scc-broker. @cryptoking117 i have updated my answer.. @jondubois \nI solved a first issue related to the different instance versions of socketcluster that scc-state and scc-broker use. \nI have decided to install the servers locally from scratch. I did:\nnpm i scc-state scc-broker socketcluster\nIt appeared that the versions of the installed socketcluster were different. \nunder scc-broker/node_modules/socketcluster the version was 9.1 rather than 13.1.8 which is the actual version. \nMeanwhile, under socketcluster the version was 13.1.8\nI have also re installed npm i scc-broker-client@latest under myApp/node_modules/\nUnfortunately, I have big problems with publish and watch...\nWhen I run the instance by doing node server.js it works it publishes and watch 'channel' locally.\nBUT when I run the instance by doing SCC_STATE_SERVER_HOST='127.0.0.1' SOCKETCLUSTER_PORT='8000' node serve\nthen, the instance does not return any published data to channel called \"channel\".\nthen, following your wise advice, I looked into the versions of the packages of node_modules and found that the packages were not up-to-date still. I used \nI went to scc-state folder and typed npm outdated\n```\nroot@minis:~/server/node_modules/scc-state# npm outdated\nPackage               Current  Wanted   Latest  Location\nminimist              MISSING   1.2.0    1.2.0  scc-state\nlodash                 4.13.1  4.13.1  4.17.10  scc-state\nsocketcluster-server    9.1.3   9.1.3   13.1.2  scc-state\n```\nroot@minis:~/server/node_modules/scc-broker# npm outdated\nPackage                    Current  Wanted  Latest  Location\nexpress                    MISSING  4.13.1  4.16.3  scc-broker\nsc-framework-health-check  MISSING   2.0.0   2.0.0  scc-broker\nsocketcluster-client       MISSING   9.0.4  13.0.0  scc-broker\nminimist                     1.1.0   1.1.0   1.2.0  scc-broker\nI checked it for my socketcluster app and the dependencies versions were the following\nroot@minis:~/server/zoo# npm outdated\nPackage   Current  Wanted  Latest  Location\nconnect     3.0.1   3.0.1   3.6.6  socketcluster-sample\nminimist    1.1.0   1.1.0   1.2.0  socketcluster-sample\nmorgan      1.7.0   1.7.0   1.9.0  socketcluster-sample\nI updated the missing or old dependencies using npm except for socketcluster-sample, i don't know where it is :<\nDon't forget I installed scc-state and scc-broker yesterday from scratch (clean install) using npm install. Does it mean there is an issue with dependencies versions of the original package from npm ?\nstill no luck with publish / watch, but some progress. Let me know if there are things that I can check.\n. It is working now, I had to perform a fresh install of scc-state, scc-broker and socketcluster client. thank you.. I closed it because I have to investigate more. It can related to what I have added in my catch block. \n}).catch((authError)=>{\n          console.log(\"Authentication error\",authError);\n          let errorResp = (\"Error\",authError); // The first word Error is used to determine that it is an error on the other side.\n          respond(errorResp);\n          socket.disconnect();\n        });\n. ",
    "boogerlad": "have the same problem. ",
    "klren0312": "I don't use the alpine ,fix it. ",
    "hiepxanh": "still cannot fix. ",
    "cryptoking117": "tried all of the above no luck. ",
    "sp-suresh": "In my case installing latest nodejs and npm on Ubuntu(16.04) with PPA, solved this problem.\nEarlier version\nnode - v6.14.3\nnpm - 3.10.10\n\nLatest version which solved the problem-\nnode - v10.6.0\nnpm - 6.1.0\n\nRefer - How to Install Latest Node.js and NPM on Ubuntu with PPA\n1: https://tecadmin.net/install-latest-nodejs-npm-on-ubuntu/. Installing Latest nodejs and npm on Ubuntu(16.04) with PPA, solved this problem.\nEarlier version\nnode - v6.14.3\nnpm - 3.10.10\n\nLatest version which solved the problem-\nnode - v10.6.0\nnpm - 6.1.0\n\nRefer - How to Install Latest Node.js and NPM on Ubuntu with PPA",
    "anton-mladenov": "hey developers of SocketCluster, check this out: https://www.npmjs.com/package/uws\nsharing the link above because of the message I got when I ran yarn upgrade which is:\n\nwarning remotedev-server > socketcluster > socketcluster-server > uws@8.14.0: stop using this version\n\nso, now the question is which version should I use? how can I change the version I am using?. ",
    "pbassut": "For me the program was node 10.\nWhen downgrading to node 9 it worked.\nnvm use 9\nrm -rf node_modules/\nnpm install. ",
    "vickylance": "\nFor me the program was node 10.\nWhen downgrading to node 9 it worked.\nnvm use 9\nrm -rf node_modules/\nnpm install\n\nI downgraded to node 8 and it worked thanks \ud83d\udc4d . ",
    "nicubarbaros": "@pbassut thank you. ",
    "paxperscientiam": "Thanks @vickylance , I downgraded to 9 and that worked for me too.. ",
    "mrspartak": "++. ",
    "heiba": "Yes I have tried it and didn't find it that easy to use. Will give it another shot. But seriously, consider developing an official android client for socketcluster.. I am currently trying hard yet again with https://github.com/sacOO7/socketcluster-client-java\nI keep getting ERROR 400 \"Reason Phrase = URL not supported\"\nI've raised the issue in the client repo, here's the link: https://github.com/sacOO7/socketcluster-client-java/issues/2\nThanks for the attention and support\n. That's superb. It's fine, 7.10 supports async and await which is exactly what I want. Sure happy to wait for the v8 updates when the issue is resolved and a need arises.\nSincerely, thank you man.. This is desperately needed especially to enable https in a suitable way.\nSo far to use Socketcluster boot options, I followed your advice and am using\nbaasil run -e baasil run -e SOCKETCLUSTER_OPTIONS='{}'\nBut following your example here https://github.com/SocketCluster/socketcluster#using-over-https,\nyou have to put protocolOptions including key and cert.\nThe problem is fs.readFileSync cannot be placed inside a JSON so we can't use it inside the SOCKETCLUSTER_OPTIONS parameter.\nTo get it working, I had to paste the entire ssl key and cert in the SOCKETCLUSTER_OPTIONS JSON argument. Which is crazy! It was the only way to get it working, because putting fs.readFileSync would never work\nHere's what worked for me.\nbaasil run -e SOCKETCLUSTER_OPTIONS='{\\\"appName\\\":\\\"exampl-loc-scc\\\",\\\"protocol\\\":\\\"https\\\",\\\"protocolOptions\\\":{\\\"key\\\":\\\"-----BEGIN RSA PRIVATE KEY-----.-----END RSA PRIVATE KEY-----\\n\\\",\\\"cert\\\":\\\"-----BEGIN CERTIFICATE----------END CERTIFICATE-----\\n\\\",\\\"passphrase\\\":\\\"example\\\"},\\\"logLevel\\\":3}'. We love you!!. Tested. Works like a lovely charm!. ",
    "ranhsd": "Hi @jondubois , thanks a lot for your quick response.. \nI forgot to mention that my stack is k8s stack and currently i deployed both NodeJS servers there (my application server and socketcluster server) so both are located in the same cluster which means that i can access from my application-server and vice versa in a very simple way (k8s really make life easy for me with that) and my app is a mobile app (both android and iOS) so based on that what do you think?. hi @sacOO7 yes but the socketcluster and my NodeJS app server are decoupled and i don't want to use the MongoDB driver on my socketcluster  server i want to use it only in my application server what do you think about the following: \n\nthe Mobile client will send POST request to the application server to create a new message\nthe application server will store the message in MongoDB \nAfter the message will be stored the application server will use socketcluster client (NodeJS) to emit the message to the socketcluster server\nThe socketcluster server will receive the message and will publish it to the specific channel\nAll subscribes (on the mobile device) will receive the message\n\nThis way we can create something similar to \"real time database\" so events will be emitted only after the data has being saved to the database. \nwhat do you think ? . Hi @sacOO7 yes I can .. but I don't 100% sure that I understand your suggestion ..\nWhat will be the flow starting from the client through saving it into the DB until it sent to other clients in your suggestion?\nThank.. ",
    "DiSiqueira": "tag v5.1.2 available.\nbash\ndisiqueira@teste01:~$ docker pull socketcluster/socketcluster:v5.1.2\nv5.1.2: Pulling from socketcluster/socketcluster\n5c90d4a2d1a8: Pull complete\nab30c63719b1: Pull complete\n29d0bc1e8c52: Pull complete\nf222342d2902: Pull complete\n27808f091869: Pull complete\na5f3825caa0a: Pull complete\nDigest: sha256:d466ab21339117e03aad3f97583cdb3320a4520f3d515f8dd6c1bfd19dba1c75\nStatus: Downloaded newer image for socketcluster/socketcluster:v5.1.2\ndisiqueira@teste01:~$\n. ",
    "prashcr": "I took a look at node_modules/uws/build_log.txt, it seems node-gyp errored due to Python 3. I ran npm config set python C:\\Python27\\python.exe and it works now.. ",
    "liuqimin323": "same error, but my uws/build_log.txt says D:\\XodoV3\\app\\node_modules\\uws>if not defined npm_config_node_gyp (node \"C:\\Users\\kk\\AppData\\Roaming\\npm\\node_modules\\npm\\bin\\node-gyp-bin\\\\..\\..\\node_modules\\node-gyp\\bin\\node-gyp.js\" rebuild )  else (node \"\" rebuild ) \ngyp WARN install got an error, rolling back install\ngyp ERR! configure error \ngyp ERR! stack Error: unable to verify the first certificate\ngyp ERR! stack     at TLSSocket.<anonymous> (_tls_wrap.js:1098:38)\ngyp ERR! stack     at emitNone (events.js:105:13)\ngyp ERR! stack     at TLSSocket.emit (events.js:207:7)\ngyp ERR! stack     at TLSSocket._finishInit (_tls_wrap.js:628:8)\ngyp ERR! stack     at TLSWrap.ssl.onhandshakedone (_tls_wrap.js:458:38)\ngyp ERR! System Windows_NT 10.0.15063\ngyp ERR! command \"D:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\kk\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\npm\\\\node_modules\\\\node-gyp\\\\bin\\\\node-gyp.js\" \"rebuild\"\ngyp ERR! cwd D:\\XodoV3\\app\\node_modules\\uws\ngyp ERR! node -v v8.1.4\ngyp ERR! node-gyp -v v3.6.2\ngyp ERR! not ok anyone knows what it means?. I have it solved by downgrade my node js to 6.11.1, thanks!. ",
    "codedogfish": "@prashcr work for me.\nI drill down node_modules/socketcluster-server/node_modules/uws/build_log.txt find it needs python 2.x to build.\nSo set python 2.x as default (npm config set python $(which python2) may also work).. ",
    "unijad": "on windows 10 you need C++ windows build tools\nhttps://www.npmjs.com/package/windows-build-tools. on windows 10 you need C++ windows build tools\nhttps://www.npmjs.com/package/windows-build-tools. ",
    "jansenignacio": "@ImBrek did you find a way to suppress the message? I want to do it too but I haven't found a way yet.\nTo give more insight, this is the error message I'm seeing when verification of the JWT token fails: \n1488275406345 - Origin: Worker (PID 22988)\n   [Warning] Error\n    at SCSocket._onSCClose (/Users/jansen/project/socketcluster/node_modules/socketcluster-server/scsocket.js:207:17)\n    at SCSocket.disconnect (/Users/jansen/project/socketcluster/node_modules/socketcluster-server/scsocket.js:227:10)\n    at disconnectInvalidSocket (/Users/jansen/project/socketcluster/build/utils/disconnect-invalid-socket.js:9:12)\n    at SCServer.exports.default (/Users/jansen/project/socketcluster/build/middleware/on-connection.js:9:47)\n    at emitOne (events.js:96:13)\n    at SCServer.emit (events.js:189:7)\n    at SCServer.EventEmitter.emit (/Users/jansen/project/socketcluster/node_modules/sc-domain/index.js:12:31)\n    at /Users/jansen/project/socketcluster/node_modules/socketcluster-server/scserver.js:512:12\n    at /Users/jansen/project/socketcluster/node_modules/socketcluster-server/scserver.js:368:7\n    at /Users/jansen/project/socketcluster/node_modules/jsonwebtoken/verify.js:27:18. Nevermind, I found it. There's an option called logLevel. If you set it to 1, it will (from what I understand) only log exceptions that cause socketcluster to stop working.. ",
    "FantomHD": "Why not have the server send the client data about the notification and when it expires then have the client handle the rest? Such as it checking to see if the notification is passed expiration, and how to handle it. I don't know about 'pinning' something to a channel, because that doesn't really make sense, seems like it would just me handier to on log in check and see if the person is a new user, if so send them some data, whether through a channel or socket it wont matter. . So been working on it for a while now, and now hititng this error:\nWebSocket connection to 'ws://xxx.xxx.xxx/socketcluster/' failed: WebSocket is closed before the connection is established.\n(index):12 Uncaught Socket error - SocketProtocolError: Client connection establishment timed out\nI'm still confused, but less confused lol. here is my index.html:\nand my worker.js\nEdit: I can get it to send data if I remove scServer middleware function. But after that I'm back to being stuck without my user info from passport in the socket. . Update: So after following a lot of what you said, I've gotten to the point where I sign my passport token with worker.auth.signToken and currently and sending it to my client as a cookie. However, I'm stuck here. The cookie shows up on the client but I don't know how to save it to local storage to set it as the \"socketclsuter.authToken\". I tried to get the cookie but that didn't really work. You also said somewhere I should just send it as part of the response body but I couldn't figure that out. Could you elaborate here please? Sorry for being a nuisance since i'm so inexperienced! . Great! I got it to work! Without using the JWT module and just using worker.auth.signToken, how secure is this? Do I need to secure the cookie? If so could you point me to how, this is sorta leaving your domains so i dont want to continue being a burden. Thanks so much for getting me here though!\nEdit: dont need authorization, just need to verify the person sending data really is the person that the cookie they are sending back says they are. I already have authorization done. . Ok great, thanks for the top notch support, honestly! This solidifies my decision to stick with socketclusters over socket.io!. Great! That asnwers all of my concerns! Thanks for adding that bit about how sc can handle plenty of channels too! I would have worried about that later on. I don't know if you caught my edit about how sc handles multiple workers and all the connected clients though? Because that is a pretty big issue for me. Also, instead of making another issue ill piggy back here. So the passport fix works great, for now. I realized there was an issue that I will eventually have to address, so I might as well do it now. So with passport, it has its own cookie that it saves and checks for when a player opens a part of my site, to see if they are authorized to be on that site. Now in the past, since my passport cookie and the cookie I used to get their information from was the same thing, I had no issues. But now, since I have 2 cookies saved, one from passport, which it uses to check if im signed in with steam still, and one from sc that takes that same passport cookie data and saves it as another cookie, except signed through sc. Now if i delete that cookie and refresh the page, the page will refresh because Im still signed in on passport with all the right data, but the sc cookie is gone so i dont have any information about who the server is talking to now. In the past this wasnt an issue because if you deleted the passport cookie, you couldnt refresh the page since you were no longer logged in. Now I assume I could use authorization here to check if they still have this cookie and it is all the correct stuff, however this seems redundant as passport already does the same exact thing. Is there anyway I can merge these cookies? Passport's cookie is set through a session with a secret and such, would that work as sc token? \nI tried moving the signing of the token into the passport serialization function then sending back the passport cookie for the server to check, but i didnt work, i assume because the passport key already has been signed with the session secret I set. Any ideas? This is where i moved it, \npassport.serializeUser(function(user, done) {\n        worker.auth.signToken(user, worker.options.authKey, null, function (err, token) {\n            done(null, token);\n        });\n    });\n. Yea, it seems like I will just have to deal with them separately. \nEdit: I figured out how to deal with them separately. I had another block of asking what to do, but i figured out that socket.getAuthToken will be null if there is no auth token or if its not valid. \nEdit: So at the end of my very post here I edited on this paragraph, I never got a response and it's pretty critical knowledge for me to know before I move on, so Ill post it again. Thanks again, I hope this is the last time I have to bother you!\nAlso if a user's actions are what cause a global emit (say a user clicks a button then the server sends out a message to the channel where everyone is subscribed) will it only contact users who are connected to that worker file, or all users overall. This is something I don't understand about how socketclusters works. I know if I launch more workers, its the equivalent of running 3 diff instances and the load balancer moves clients around between them. However, are all these clients still connected on some level or are all 3 running separate instances of the same app? For example if it was a chat room and I had 3 workers. If 100 people were logged on, would each client see that there was 100 people on line or 33 people online (since the load balancer splits up the connections per worker)? And jumping off that, are variables shared between the workers? If I have a list variable that a user can add to anytime, will it be updated live in other workers too? Or do i need to move that to a db? \n. Alright! Cannot thank you enough for the well written and thorough responses! My life will be busy and hectic for the next few weeks so I wont get much time to start moving over and transitioning to SC but i think this sums up most everything a quick google couldn't solve for me! Ill close the issue now and hopefully - but for some reason I doubt it! - this will be the last time I have to open a new one.. Great this is everything I needed! Thank you once again!. Okay, I'm switching to using JWT to authenticate. How can I verify the sc token I set earlier with jwt? \nI have this to sign the token i pull from socket.authToken:\nworker.auth.signToken(cookie, worker.options.authKey, null, function (err, token) {\n        res.cookie('GameID', token);\n        res.redirect('/'); \n    });\ninside my ensure authenticated function, im trying to use jwt to verify that cookie, how can I go about that? Or do I have to set a whole other cookie for this? . never mind. I had this: jwt.verify(req.cookies.GameID, worker.options.authKey, function(err, cookie){} to try and verify the token and it didn't work the first time, but now it does. So i guess that's it! This was super simple, dunno why i didn't use this to begin with. Now inside of my ensureAuthenticated instead of checking if req.user exists I just check if this cookie is legit lol. \nedit: closing this, hopefully last one I have to close!. ",
    "githubfreedcamp": "Hey!\nThanks for sharing.\nCan you share more on point 3 - how many nodes, what horse power, how reliable it is when node fails both on client side and your side?\nAnything like open connections, messages per day, messages per minute to show how loaded these systems are?\nCheers,\nIgor. ",
    "pataiadam": "@jondubois Thank you for your answer :)\nI also use Linux and run the client on a different machine (both machines (server, client) have i5-3470 CPU @ 3.20GHz)\nAnd an other issue:\nI've updated my code: now client is logging the ratio between emitted/published and received message(P/R) (server will reply if it got a msg from client, so P/R should be ~1.0)\n(the client and server are on different machine:)\nwith ws:\n```\n|=|  TC/MC: 1000/1000\n|=|  msgPublished: 213000\n|=|  msgReceived: 212932\n|=|  P/R: 1.0003193507786523\n|=|  msg/sec: 12832.640269993371\n==================\n```\nwith uws:\n```\n|=|  TC/MC: 1000/1000\n|=|  msgPublished: 219000\n|=|  msgReceived: 103204\n|=|  P/R: 2.1220107747761716\n|=|  msg/sec: 5204.700186595391\n==================\n```\nSo client \"received\" the half of the messages when I use uws instead of ws (?)\n\nI was able to get over 20K messages per second (with responses) with uws last time I tested and only 10K m/s with ws.\n\nCould you share your benchmark code? . > There may be other issues in your code though because uws should be always be faster regardless.\nProbably there are some problem with my code, but I can't see what is the problem. (I've used the sample app of this repository as a base). . ",
    "trakout": "@jondubois worker.exchange.subscribe().watch() was the missing key. I'm using dynamically created channels (created on socket connection within the worker), and I've got a 'listener' channel at the redis level that announces new channels for redis to subscribe to. I've simply been missing a similar mechanism at the broker <-> worker level.\nThanks for the prompt & detailed response!. ",
    "frank-dspeed": "@JCMais yes your save if you use something that is free :). i think that can be closed as its related to javascript + http basics. it is possible you only need to learn javascript + http you can close this as this is not a support forum and you posted no bug thanks. @LukeXF Your doing it 100% right . One Alternate method that is also use able but makes no sense in your case would be coding ES6 class account with a constructor that takes socket and then you do new Account(socket).login(credentials,response). I think promisify is enought to archive that it don't matters if socketCluster it self uses callback or promise pattern as you can always convert with 1 till 3 lines of code from promise to callback and from callback to promise.\nSo This is simply waisting time if this would get applyed to this project it self.\nIts a Developer Desission if he wants to use a promise api or a callback api\nLitle Maybe not working Pseudo code to make it clear\n```js\nfunction usingCallback(callback) {\n  callback(err,result)\n}\n// to Promise\nfunction promiseFromCallback(callback) {\n  return new Promise(function(resolve,reject){\n    usingCallback(function(err,result) {\n      if (result) {  resolve(result) }\n      reject(err)\n    })\n  })\n}\n// from Promise\nfunction callbackFromPromise(callback,promise) {\n promise.then((result)=>callback(null, result)).catch((err)=>callback(err,null))\n}\n```\nHey @JCMais i know your junior thats why i will not rant about your rating but i hope you know that i am right i have over 30 years of expirence i am sure i am right :+1: . ",
    "gantir": "@KCypher13 is the issue solved? I think I have resolved the issue you mentioned here. However,  have another issue with authentication. \nThe following snippet might help you.\n```\nboot(app, __dirname, (err) => {\n      if (err) throw err;\n  // Add GET /health-check express route\n  healthChecker.attach(this, app);\n\n  httpServer.on('request', app);\n\n  app.emit('started');\n  // const baseUrl = app.get('url').replace(/\\/$/, '');\n  // logger.info('Web server listening at: %s', baseUrl);\n  if (app.get('loopback-component-explorer')) {\n    const explorerPath = app.get('loopback-component-explorer').mountPath;\n    logger.info('Browse your REST API at %s', explorerPath);\n  }\n  app.scServer = scServer;\n});\n\n```\n. ",
    "TimoRuetten": "passing killMasterOnSignal: true to the init object did the job.\nhttp://stackoverflow.com/questions/33311344/how-do-i-get-socketcluster-to-restart-on-file-change. ",
    "ddolheguy": "Anyone?  Just to add, I also get the \"Socket, Hung up\" errors too.\nAgain this request is more about he ability to handle them than resolve them.\nAny ideas how?   Please?. Thanks but unfortunately that doesn't cravat he the error as I'm already doing this.\nThe error itself is really rare, like we have probably 1k plus connections per day and we see 2-3 errors per day.  I'm guessing it's because the client gets an unknown error code or message from the server.   I only ask as I'm looking for more of a global wrapper but the connection on error you referenced too doesn't seem to catch this.. ",
    "BojDom": "Why is this being ignored?\nAlso will be nice to have something like socket.subscribe('mychannel/*'). ",
    "Haocen": "I usually clean it up next time I run into that session, which usually happens next time user try to connect.\nI also have scheduled cleanup run on disaster recovery/hot redundant, but not my immediate failover.. ",
    "alexus85": "Was facing the same issue last time when I wanted to test something on my laptop with Windows 10. I was unable to figure out as why the messages are not being distributed between all the active SC nodes. But it all started working when I switched to my Ubuntu. So I'd suggest you to do the same. . ",
    "xuejipeng": "@alexus85 I solved the problem, I changed the command to start broker \"SCC_INSTANCE_IP = '127.0.0.1' SCC_STATE_SERVER_HOST = '127.0.0.1' SOCKETCLUSTER_SERVER_PORT = '8888' node server\" I still set up a loadblancer in front of the cluster, and then loadblancer As an entrance, but I still do not particularly understand the role of scc-broker, you can tell me how you understand. @jondubois  I use the docker mirror, mirror it with the node to do it, the cluster has to try to connect again, but the same will have been disconnected, many times after no longer try again. Oh oh so thank you. ",
    "joysonvd": "Hi,\nDid you get through the issue you were facing? Can you post your solution?. @happilymarrieddad : Yes, I will be following the below method:\n1. Sender sends the message. Store it in a DB with ack value 0.\n2. Send it to the receiver and wait for ack.\n3. Receiver sends the ack, change ack value to 1.\n4. In case receiver reconnects, receiver sends all pending acks and asks the server to send all pending messages with ack 0.\nRegards,\nJoyson.\n. I faced the same issue and I did a small workaround in index.js of the sc-cluster-broker-client module. Not sure if this is the right way to go about it:\n``\nvar SCC_INSTANCE_IP = process.env.SCC_INSTANCE_IP;\nvar SCC_INSTANCE_IP_FAMILY = process.env.SCC_INSTANCE_IP_FAMILY ||'IPv4';`\nvar stateSocketData = {\n    instanceId: broker.instanceId,\n    instanceIp: SCC_INSTANCE_IP,\n    instanceIpFamily: SCC_INSTANCE_IP_FAMILY\n  };\n```\nIn the socketcluster yaml file, added the following in the environment variable:\n        - name: SCC_INSTANCE_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n. Tried this with socketcluster 5.16 and still getting undefined at the state server logs. Would this affect scaling?\nClient e7fda3ab-4e72-4489-b319-e6ee2d07a827 at address undefined joined the cluster\nCluster state converged to active:[]\nServer 00eaadd0-3569-4fc2-87f1-57abe06bbf05 at address undefined on port 8888 joined the cluster\nCluster state converged to updatedSubs:[\"ws://[undefined]:8888\"]\nCluster state converged to updatedPubs:[\"ws://[undefined]:8888\"]\nCluster state converged to active:[\"ws://[undefined]:8888\"]\n. Hi,\nPlease close this. I was not using the correct version on the state server.\nThanks. ",
    "rachlies": "Hey joyson, \nI just changed the service type for socketcluster to NodePort and then I am able to access over public internet through the minikube ip and the port which is assigned to socketcluster service. But I am still facing issue for load balancing purpose.. @jondubois,  what is the message limit I should expect with the configuration that I mentioned.\n@happilymarrieddad I just modified the worker.js according to the examples shown in the Docs. and then build a docker image of it to use it in the GKE. \n```\nscServer.on('connection', function (socket) {\n    console.log('User connected: ', count++);\n    socket.on('chat', function (data) {\n      var msg = '', channel_name = '';\n      if(typeof data == 'object') {\n        msg = data.msg;\n        channel_name = data.channel_name;\n      }\n      if(msg == undefined || msg == '')\n        msg = 'hello';\n      if(channel_name ==  undefined || channel_name == '')\n        channel_name = 'broadcast';\n      scServer.global.publish(channel_name, data);\n      console.log(\"channel_name: \", channel_name);\n      console.log('Chat:', data);\n    });\nsocket.on('disconnect', function () {\n  console.log('User disconnected');\n});\n\n});\n``\nFollowing is the result shown when I runtop` in one of the node. As u can see aroung 50% memory is used in cached memory.\ntop - 09:49:28 up 1 day, 22:44,  1 user,  load average: 0.00, 0.00, 0.00\nTasks: 114 total,   1 running, 113 sleeping,   0 stopped,   0 zombie\n%Cpu(s):  1.3 us,  1.0 sy,  0.0 ni, 97.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem:   3794460 total,  2840072 used,   954388 free,   266064 buffers\nKiB Swap:        0 total,        0 used,        0 free.  1803020 cached Mem\n. ",
    "shengis": "Thanks @happilymarrieddad !\nI expected a solution at the broker level, but ok, I think your solution could work.. I was waiting for the thoughts of @jondubois, but actually it's solving my problem, so thanks \ud83d\udc4d . ",
    "nagamanojv": "Okay, this turned out to be because socket.remoteAddress is coming as 'undefined' in sc-state/server.js on serverJoinCluster and clientJoinCluster. Because of this socketcluster was given undefined as the port to connect which it obviously couldn't. When I hardcoded socket.instanceIp = '127.0.0.1';  in both serverJoinCluster and clientJoinCluster everything is working perfectly. \nNow, can anyone help me how can I overcome this limitation.!! For sc-broker, I can set SCC_INSTANCE_IP env variable to inform state server about the source ip, but for socketcluster I don't see any corresponding variable being used. . @jondubois  it is  node v7.4.0\n. @jondubois the piece of code you gave is giving ::ffff:127.0.0.1 as socket.remoteAddress for me also. It is surprising why it is not giving the same value when socket-state tries to read.!! . ",
    "crazyyi": "@happilymarrieddad  I use expressjs to serve the static files. I try to use socketcluster as socket.io maybe that's the problem. I think socket.io will serve the socket.io.js file on the server when I link its websocket server to the http server. In this way I don't have to put socket.io.js in the client directory such as 'public'.  In socketcluster I don't know how to do that properly.. ",
    "dotob": "awesome, thanks this is much better now. i tried it and it worked. thank you very much.. ",
    "dakkafex": "didnt work sadly. ",
    "devyu": "Try reduce your node version to 6.9.1 and run npm cache clean and then npm install. ",
    "efistokl": "Probably related: the issue https://github.com/uNetworking/bindings/issues/31 (see comments). ",
    "FinaOePrs": "@CoolHandLuke88 , new to nodejs, can u be more specific about the files to be edited, with sample paths.. @CoolHandLuke88 , Thanks, We are working on windows 7 machine, and same application is working on other colleague system. with similar node and npm versions.\nbelow is in our dockerfile:\nENV NODE_ENV docker\nENV MONGO_HOST mongo\nRUN apk update && apk add curl\nEXPOSE 3000\nWORKDIR /home/src\nCOPY . /home/src/\nCMD node . -m && node .. The most logical solution i had is : installing \"MS visual studio 2015 build tools\"\nafter installing this, i just did npm install again after removing  prebaked node_modules folder.\nthen the uws build went successful, creating binaries.. ",
    "kaynz": "As an archlinux user I had to install the package nodejs-lts-boron (version 6.13.1-1). The packages nodejs-lts-carbon and nodejs lead to the error described in the first post.. ",
    "amin-mir": "@jondubois I'm on OS X 10.13.6 (Node v10.13.0). sc-uws seems to not work on my mac. I get Compilation of \u00b5WebSockets has failed and there is no pre-compiled binary available for your system. Please install a supported C++11 compiler and reinstall the module 'sc-uws'. I tried to compile it with node-gyp but couldn't succeed. Apparently there isn't a pre-compiled binary for this version of OS X. I wondered if you could help me get it up and running. As a workaround, I am using uws v10.148.1 and it works fine.. Thanks @mihranharutyunyan. Just curious to see if @jondubois would recommend using it with SocketCluster as well.. @Coldzer0 Try npm update socketcluster in the directory where your package.json lives.. @beingshashi The multiplex option in ScClient library is true by default, which means that the browser will use the same socket for several tabs. Maybe you have written some logic which caused your client app to subscribe to a channel multiple times. Remember to unsubscribe or unwatch channels if you don't need them. . @carlosfusion You don't usually create channels. Sc brokers does this for you. They create and keep track of existing channels along with sharding and whole bunch of other stuff. Creating channels in server and subscribing users to them will defeat the purpose of pub/sub architecture. But as @chnauman said, you can use middlewares to prevent clients from subscribing to unwanted channels.. @chnauman I am not sure if I have understood your question correctly, so let me know if my answer does not help. Are you using a microservices style (X and Y communicate) or client simply connects to both server X and Y? In any case, I would generate a JWT token after user logs in, on server X, and send it back to the user. Then when user tries to connect to server Y, he/she would send that token as well. The token basically contains everything you need about the user and you can also verify it with your private key to make sure it has not been tampered with.. @chnauman To generate the token you need a private key. If both servers have the same key, then they can decode and verify the token. You don't need to store the token anywhere, and compare tokens against a dataset of generated tokens. . @meriamBenSassi  Have you used export default Config; inside you Config.ts file? if not, you should probably import it like import {Config} frim './Config';. I think you are missing something on typescript syntax.. @Hirbod @MegaGM I don't think MQTT is needed here really. ScServers can act as message brokers. Also sc-redis is not scalable. The best approach, I think, is to use the ScClient in your node.js servers as well. So you have a message broker through which your nodes can communication with each other (pub/sub). You might want to include special secret tokens as well, so only trusted clients can do particular stuff.. First, install socket cluster client in your node.js server:\nnpm install socketcluster-client\nThe rest is as simple as the code snippet below:\njavascript\nconst socketCluster  = require('socketcluster-client');\nconst scOptions = {\n    hostname: 'localhost',\n    port: 3000\n};\nconst scClient = socketCluster.connect(scOptions);\n// ...\nAlso, this will become handy when testing your code. Let me know if it works.. @slidenerd Yeah you are right. If you still want to connect to a third party library that uses pure websocket protocol, then you have to use pure websocket client in your SocketCluster application to connect to it. The idea is the same; only do you need to use a different client library.. ",
    "mihranharutyunyan": "@amin-mir take a look @clusterws/uws  they overwrite the code and it builds for node 10. \nThere is a need for exporting Server besides WebSocketServer and it works with socketcluster. ",
    "EAT-CODE-KITE-REPEAT": "Follow. I'd like to do the same.. Nobody knows?. Yeah @jondubois , very worthwhile because I think most people are using socketio though it's not as scalable it seems.... \n. ",
    "MatthieuHPP": "Many thanks. I will look at it.. ",
    "mnuckols": "Thanks, that's helpful to know.. ",
    "Louies89": "@happilymarrieddad \nHi,\nI have a doubt, regarding memory foot print between scServer.exchange.publish(To Channel) and socket.emit('event',data).\nAmong this 2 which consumes less memory?\nAnd in a single channel how many broadcasts can be done at a time?. @jondubois \nThank you so much for your reply.. :+1: \nI am having Cassandra as backed db, so when I want data from db, I send socket.emit('event',JSONdata) to server. Using the JSON data, server quarries Cassandra and once gets data sends it back to client. \nSo in this situation if server emits another event to client, to send the db data, then socket information has to be present in the stack. When I log the socket, I'm getting 1700bytes  of chareters, so roughly 1.5 kb of data.\nSo another way is, my each of clients shall have there own private channels subscribed. So once i get back the data from db, then can use that channel to deliver the data.\nIf i will have a lot of clients connected & quarrying simultaneously, then socket information of each user shall be 1.5kb, so what will be the best way to save some memory.\nActually I don't have any idea, how optimally scServer keeps the channel information and socket information also. \nIt will be a great help if you will give some information.\nThank You:)\n@jondubois Please can you share some info? :)\n. @jondubois Thank you for the info :). and Special thanks for SocketCluster : )\n@happilymarrieddad Thank you for the stats and detailed information...:)\n. Thanks all for wonderful replies...  And sorry for late reply, I didn't check my mails.\n@happilymarrieddad : I just used below code:\nNewsocket = socketCluster.connect({\n        hostname: 'localhost',\n        port: 80})\nAnd in gitter sacOO7 pointed out to set secure false, after doing that, it get connected.\nAlso the code can be referred from here: https://github.com/SocketCluster/socketcluster-client/issues/102\n@sacOO7 : I am using \n\"socketcluster\": \"~9.1.3\",\n    \"socketcluster-client\": \"~9.0.0\",\n@MegaGM : I am using simple http only\nAnd i had gone through the code, but the code you have shown, i got that but didnt get from where global.location and location.protocol are getting updated.\n. Sorry to all, by mistake I clicked on Close and comment. ooh, got it. :)\nThe code is working fine for me now.\nThank you for the reply @MegaGM . ",
    "renaudguerin": "Thank you for this great answer. It could probably go straight into the docs !\nEven with multi-core hosts, there are usually quite a few other processes running in a k8s cluster anyway, so I think it makes sense to just to leave these variables at 1, and just scale the number of replicas if needed (at worst several of them will end up on the same host).\nAlso, when you say \"number of processes per host\", in the Docker/k8s context this translates to \"per pod\" right ? You're forking n processes from a master process (much like a web server would do), all inside the same container correct ?. ",
    "libressence": "documentation of socketCluster is good but very poorly done. Thank for your response ! I use a object inside worker (appManager), i use this for play with user, context and the logic of server-side. It's just un object for playing with multiple class make by myself.\nThe problem is when socketcluster restart after file change i loose my object (a new object is created in worker.js, new appManager()).\nMy strategy is i want to save some data who are inside my appManager before socketCluster restart for finding them afer restart.\nIs it possible or not ? Thank jondubois (french?) :)\nSorry for my english.... i mean is complicated to use this documentation because there are not a lot of example. Like scripts. I try some methods in worker but they don't work. I know it's because i am wrong but impossible to know why.... ok, thanks. ",
    "LukeXF": "As a work around I'm currently doing:\nsocket.on('account/loginTest2', function (credentials, respond) {\n    account.login(credentials, respond, socket);\n});\nBut I'm sure it can be done more efficiently. Any suggestions?. Thanks Frank, going to close this issue now since my problem is solved. Thanks once again, documentation is less confusing now!. ",
    "lshusharin": "Now it seems to be connected and authenticated, but in which order I should make a requests and which method use to receive a data?\n. ",
    "Panoplos": "Yes, I got this working a little after posting with the following code:\n```es6\n/ @flow /\nimport socketCluster from 'socketcluster-client'\nexport default (options) => {\n  return {\n    query: (request) => {\n      const socket = socketCluster.connect(options)\n      return new Promise((resolve, reject) => {\n        if (!!localStorage.getItem('socketCluster.authToken') && socket.authState === socket.UNAUTHENTICATED) {\n          console.log(>>> sockerCluster.connect() => authenticating socket...)\n          socket.authenticate(localStorage.getItem('socketCluster.authToken'), (error, status) => {\n            if (error) reject(error)\n          })\n        }\n        while (!!localStorage.getItem('socketCluster.authToken') && socket.authState === socket.UNAUTHENTICATED) {\n          setTimeout(() => {}, 100)\n        }\n        socket.emit('graphql', request, (error, data) => {\n          if (error) reject(error)\n          resolve(data)\n        })\n      })\n    }\n  }\n}\n``\nCan you see if there are any corner cases this would hang on?. In fact, this is a big problem as many of my local imports have dependencies as well... Also, I am usingmodule-resolverbabel plugin to keep imports clean, i.e.import something from 'server/something'as opposed tovar something = require('../../path/to/server/something').. Note that I approached this slightly differently in that I included-r babel-register` on the initial command line, as it appears you guys are copying over all args to the forked process. Of course, this is for dev purposes, only, as I build the server in production env.. ",
    "FallingSnow": "That's unfortunate. Thanks for the response anyway.. I intend to write a websocket api for a service I'm developing. The ability to notify clients when they have made an unknown request would not only help with my development but also developers that will use that api in the future.\nMy primary use case is for requests for events that require authentication. For security reasons I don't attach certain event listeners to a socket until it has been authenticated. If there was an api to catch unhandled events I could compare the event against my list of handlers for authorized events and notify clients that they need to authenticate before calling this event or that this event doesn't exist at all.\nLastly I think it would add a better user experience. A timeout error suggests that any number of errors could have occurred between the client and the server (when I think timeout I think connection loss personally). With a catch-all you can provide the client with a more specific error.\nRant over. Thanks.. ",
    "nardeas": "Passing app.callback() instead of the app instance seems to work. Is this the correct way to use it?. Thanks! I think since Koa is also so popular these days it would be beneficial to include & document a Koa example somewhere where it would be easily accessible for SC users.\nI could do a writeup but where do you think would be best to put it?. I did a writeup here https://medium.com/@nardeas/socketcluster-with-koa-ff760c402588. Feel free to comment and improve, a link from the website would be great :-). ",
    "Nicholi": "Excellent :). ",
    "sheeldotme": "@ZenPylon did you start on this?. ",
    "akshaychand": "@ZenPylon Is this in the works?. Thanks @jondubois! Worked like a charm. . ",
    "ZenPylon": "Hi @akshaychand and @sheeldotme, sorry for the huge delay in response.  I had started, but abandoned it after not too long.  I decided to use Firebase as the websocket server.  Sorry - I think I deleted the small bit of progress I'd made :( .\n. ",
    "ansubur": "any reference for \"how to do batch subscribe\"?\nIs it like scClient.subscribe('channel1,channel2,channel3');. Was never able to find it. Thanks a lot!\nI'm used to .net IDE & hence intellisense minded ;). I still haven't figured out, Any suggestions?. I use .net client with following BasicClientListener events.\nWhen I disconnect the client server side, I'm unable to capture message & the code. However the client gets disconnected successfully and OnDisconnected event is triggered.\nPublic Sub OnDisconnected(socket As Socket) Implements IBasicListener.OnDisconnected\n    TotalConnectedClient -= 1\n    Debug.WriteLine(\"Disconnected \")\nEnd Sub\n\nPublic Sub OnConnectError(socket As Socket, e As ErrorEventArgs) Implements IBasicListener.OnConnectError\n    Debug.WriteLine(\"Connection Error \" & vbNewLine & \"Error : \" & e.Exception.ToString)\nEnd Sub\n\n. Will do it. Thanks for your time.. anybody to help?. I'm not aware of it, can you point me how it is done?. anybody to help?. Have to spend time on reading the document completely. Thanks Jon.. ",
    "PawanWagh": "@jondubois First of all thanks for such a great library.\nThis same configuration works on all different deployments like test server,alpha server but don't why not working on dev deployment server. Is it something environment specific ?. @jondubois Which one should you prefer to use, \n1. SCChannel Object\n2. SCSocket Object. @jondubois I have re-checked the code in all deployments & nothing is different. As a note this code was functional uptill yesterday but don't know something went off & it suddenly stopped working.\nPlz make a note that yesterday we upgraded our server from from t2.micro to t2.large with EBS volume expansion. Could this cause above scenario ?. ",
    "igorarkhipenko": "@jondubois thank you for the fast response, it was a confusing moment for me too.. ",
    "mauritslamers": "A more detailed description of the issue at hand:\nIn Node v8.6.1 it is possible to start using ES6 modules in NodeJS. Because of the lack of a dynamic loader that works (the proposed import() loader is available in V8 through --harmony_dynamic_import but not yet implemented on the NodeJS side) it causes all kinds of problems with SC versions up to and including 8.0.2.\nNodeJS currently requires the entry point to be an .mjs file (or ES6 Module file) in order to switch to ES6 module mode. It is possible to use the ES6 import statement to load CommonJS modules, but their environment is a bit different from a non ES6 Module entry point.\nOne of the key differences is the lack of require.main entry which SC uses to determine the root path of the SC project.\nAdditionally, there are some problems regarding options.environment which doesn't seem to get passed on properly.\nIt is possible to rewrite the boilerplate server.js and worker.js in ES6 module form and rename them to .mjs. However SC uses require to load the worker.js file and this is not allowed for ES6 modules.\nThis means that currently it is not possible to use code written using ES6 Module form to be used directly in SC (unless transpiled).. Set of rudimentary changes to socketcluster to allow workers to run as ES6 modules. \nhttps://gist.github.com/mauritslamers/1e5e24207e389dd00373b57b1f0ce359. There are a few issues with the extends approach. \n- it pretends to be class based, which in essence it is not. The class and extends keywords are syntactical sugar over the prototypal inheritance\n- extends creates a new constructor + prototype. It doesn't create an instance\n- As described in the comments in the gist: To keep the option of creating a new SCWorker instance you need a reference to the class somehow. When you extend SCWorker using extends you get back a reference to a new constructor + prototype, which you still need to feed to the incoming worker incoming message handler.. In a way I don't see the point of adding the extra boilerplate code of instantiation when you can achieve the same by having the developer call a function which does both extending and instantiation by means of an object literal. So, in a way you could even merge these two approaches and just have something like:\nnew SCWorker({ \n  run() { \n    // attach handlers here.\n    this.on('masterMessage', (data, respond) => {\n      // etc\n    });\n  }\n})\nI think that calling something like:\nSCWorker.setup({\n  run () {\n    this.on('masterMessage', (data, respond) => {\n      // etc\n    });\n  }\n});\nis just as clear.. ",
    "gustojs": "Thanks for letting us know about that and asking for opinions!\nI fully support this change, it would be a very welcomed feature and the breaking changes seem pretty trivial.\nAs for which of the options... honestly that's more or less just syntax sugar. Can I vote for all of them?. ",
    "rubou": "@jondubois\nI am new for socketcluster.\nnode: v7.2.1\nSC Server: socketcluster@9.1.3\nSC Client: socketcluster-client@9.0.0\ni tried to do stress test follow your sample code.\nTest goes well to 4k users, but find no way to increase it.\ni did the FD limit ajustment and also broke from 1 to 5, but no improvement.\nWhen over 4k, i got the error below:\nTest client CPUs used: 4\nserverHostname: \nserverPort: 8000\nnumClients: 5000\nD:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\socketcluster-client\\lib\\scsocket.js:533\n      throw err;\n      ^\nD:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\socketcluster-client\\lib\\scsocket.js:533\n      throw err;\n      ^\nD:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\socketcluster-client\\lib\\scsocket.js:533\n      throw err;\n      ^\nSocketProtocolError: Socket hung up\n    at SCSocket._onSCClose (D:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\socketcluster-client\\lib\\scsocket.js:631:15)\n    at SCTransport. (D:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\socketcluster-client\\lib\\scsocket.js:286:12)\n    at SCTransport.Emitter.emit (D:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\component-emitter\\index.js:133:20)\n    at SCTransport._onClose (D:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\socketcluster-client\\lib\\sctransport.js:209:28)\n    at WebSocket.wsSocket.onerror (D:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\socketcluster-client\\lib\\sctransport.js:117:12)\n    at WebSocket.onError (D:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\ws\\lib\\EventTarget.js:109:16)\n    at emitOne (events.js:96:13)\n    at WebSocket.emit (events.js:188:7)\n    at ClientRequest._req.on (D:\\FiscoAPP\\trunk\\01.src\\JS_StressTest\\node_modules\\ws\\lib\\WebSocket.js:649:10)\n    at emitOne (events.js:96:13)\nNo improvement by adjusted os limits as  below:\n hard nofile 1000000\n soft nofile 1000000\nroot hard nofile 1000000\nroot soft nofile 1000000\nref: https://blog.jayway.com/2015/04/13/600k-concurrent-websocket-connections-on-aws-using-node-js/\ni wonder how to do the same test for 1 server as you did below\nhttp://socketcluster.io/#!/performance\nplease kindly suggest to me the detail step.. @jondubois\nThank your for your early reply.\nulimit -n gives 1000000 on our system (CentOS Linux release 7.3.1611).\nOther setting:\nBroker: 5\nWorker: 3\nnode: v7.2.1\nSC Server: socketcluster@9.1.3\nSC Client: socketcluster-client@9.0.0\ni used 2 different clients did the same test and got different results.\nclient: windows 7 64bit\n->only 4k connections OK\nModel: HP ProDesk 600 G2 SFF\nCPU: 4CPUS, Core i5-6500 @3.20GHz\nRAM: 12GB\nclient: CentOS Linux release 7.3.1611\n->16k connections OK\nModel: HVM domU\nCPU: 4CPUS, Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\nRAM: 16GB\nSo, if there are some tuning points necessary for client side?\nAnd one more question, when i succeeded 16k connections, stopped the client by Ctrl+C, but failed to have 16k connections again.\nIt is out of my control. Would you kindly tell me how to get stable connection?. ",
    "vikramvm75": "I have exactly same issue.\nI am running server and client from sc-stress-tests tool mentioned above.\nNot able to go beyond 4K connections. Getting same error.  The VM on which SC server is running has 8 cores with 64GB RAM.  I tried to generate load from 6 VMs with each VM simulating 1000 users.\nHave applied all recommended sysctl, ulimit parameters. \nSame behaviour is observed on 2 Core, 4GB VM also. It means CPU & RAM resources are not the constraints here. \nPlease suggest if we need to look into any specific parameters.. ",
    "Hirbod": "I provided a solution which fixed the issue for me, see #404. @toredash thank you so much for your quick and friendly answer. We will consider implementing cloud instances. Do you have any understandable example (code) how to setup horizontally scaling? I just found a paper describing some MQTT techniques but I did not really understand how to achieve this.\nLast question:  8 CPUS = 8 Workers, but how may brokers?\n-w 8 -b 8 ?\nThank you!. This is kinda political decision based on privacy policy. Do you have any self hosted server examples? . I have a redis server running, but how can socketcluster get triggered doing something if any action happened on redis? Is there kinda redis watch? I worked with MQTT long time ago using raspberry and home automation (lmao), but not sure how to listen for mqtt events inside my worker or broker js. Is there any documentation ?. Ok, if I get this right, I just need to install a Mosquitto Server inside my worker.js listening for MQTT messages. Should be easy.. Sounds good, thanks @MegaGM . @amin-mir merci, but how can I include ScClient inside node? I can\u2019t require anything and I have to include the socketcluster.js file. Scaleabillity isn\u2019t a big deal though at this stage (I\u2019m only sending \u201csignals\u201d to the socket for initiating some stuff inside the app). But I would love to know how to use scClient inside node. . Thanks everbody, I have sc-client fully working inside nodejs and I can communicate as I wish. It works flawlessly :) (without sc-redis and mqtt)\nVery happy now! Thanks for your help.. Yeah but the message content is specific (based on several facts). I can see if that user subscribed to the channel, but I tried to do something like this:\nscServer.clients[socket.id].emit('foo', mySpecialObject); but there was no way for me to receive that answer. For now, I've ended up \"subscribing' (on client) to .subscribe('private_uniqueUserId').watch().\nThis is working, but I don't know how much overhead this is. Actually, I would love to just listen in my already existing channel \"foo\".\n. @jondubois as I don\u2019t know the internals I thought the overhead will be much more. \nWe ended up creating a hidden private channel to achieve what we want.\n. Thanks everybody!. Thank you very much for your answer. I found out, that cordova does not fire the unload event, thats the reason why \"disconnectOnUnload: true,\" does not work, while it works inside the browser.\nI though it is an error, since the log file say \"worker exited 1; worker respawned\". Sounds like a crash like more then a warning. . ```log\n1519397254959 - Origin: Worker (PID 20442)\n  [Warning] SocketProtocolError: Socket hung up\n   at SCSocket._onSCClose (/srv/quiz/node_modules/socketcluster-server/scsocket.js:229:17)\n   at WebSocket.internalOnClose (/srv/quiz/node_modules/socketcluster-server/scsocket.js:74:10)\n   at process.nextTick (/srv/quiz/node_modules/uws/uws.js:445:27)\n   at _combinedTickCallback (internal/process/next_tick.js:131:7)\n   at process._tickCallback (internal/process/next_tick.js:180:9)\n1519397254959 - Origin: Worker (PID 20442)\n  [Error] UnknownError: Socket error - SocketProtocolError: Socket hung up\n   at SocketCluster._convertValueToUnknownError (/srv/quiz/node_modules/socketcluster/index.js:449:13)\n   at SocketCluster.emitFail (/srv/quiz/node_modules/socketcluster/index.js:460:14)\n   at SocketCluster._workerErrorHandler (/srv/quiz/node_modules/socketcluster/index.js:492:8)\n   at ChildProcess.workerHandler (/srv/quiz/node_modules/socketcluster/index.js:687:14)\n   at emitTwo (events.js:126:13)\n   at ChildProcess.emit (events.js:214:7)\n   at emit (internal/child_process.js:772:12)\n   at _combinedTickCallback (internal/process/next_tick.js:141:11)\n   at process._tickCallback (internal/process/next_tick.js:180:9)\n1519397254962 - Worker 2 exited - Exit code: 1\n\n\nWorker PID: 20739\n1519397255229 - Worker 2 was respawned\n```\n\n\nThis only happens when I call \"window.location.reload()\" inside my app (or if I change a .js file and socketcluster reloads). \nAs my app listens to some special events, I need to call that reload function sometimes which will flood or kill the server when 100k users are connected).     \"socketcluster\": \"~9.3.1\",\n    \"socketcluster-client\": \"~9.0.2\". Updated to 9.3.3, problem remains the same. . we have a node.js running, there are no issues. We also have the client inside a brower, also no issue. It only happens on a hard disconncet from my app.. :/. To give more informations. I've downloaded a copy of \"socketcluster.js\" into my cordova app, which is included via js. . I will dig into this, but to be honest, the server/worker.js stuff was auto generated with \"socketcluster create app\". I did not do anything on that part, I will have a look if I can find something.. Dang... @jondubois here we go\n...\nscServer.on('connection', function (socket) {\n        socket.on('error', function (err) {\n            throw 'Socket error - ' + err;\n        });\nThis is AUTOGENERATED. I did not write this, but thanks for figuring out that very annoying problem. You saved my day!. Changed throw 'Socket error - ' + err to console.log('Socket error - ' + err); and this fixed the problem. THANK YOU!. That is actually something really important I've been struggling with, too. I've ended up using a timeout on clientside when receiving an error. Works OK for me. I also do receive the warnings in console:\n\nWhen I try to emit inside that browser, I can see that \"watch\" never gets called but on another device, I can see the messages enter. So I guess the only way to prevent illegal accessing is to add another security layer inside of emit, am I right?. Hi @jondubois yeah I will do this then.. But to be honest, IMHO, a blocked user from subscribe should not be emitting anything. Thats just another overhead, cause I have to do so much cryptography (validating JWT) in every single request now. It worked, feel free to close or leave it open if you like to discuss @jondubois . I see your point, its legit.. @jondubois  ?. Ok I understand. You try to prevent \"all of the users reconnecting\" at the same time in case of a worker-crash or something. thanks. ping @jondubois ?. thank you so much!. @jondubois @toredash any help here? I don't want a \"setupready\" code, I just want a guide. \nhttps://socketcluster.io/#!/docs/scaling-horizontally is totally useless. I doesn't help us to get a real idea how a \"broker.js\" should look and how to setup all the other servers if we want to scale horizontally.. \nI have a lot of pressure on this so I would really appreciate a quick answer. . I had the same issue. We could not have more then 4096 concurrent users. After digging into it deeply, I found out that \"systemd\" daemonized processes (I use nginx as a proxy on debian) won't inherit from \"ulimit\" configs. Means, even ulimit -n was set to 1000000, it got stuck on 4096.\nThe fix for me was:\nnano /etc/systemd/system.conf\nnano /etc/systemd/user.conf\nuncomment following lines and add these limits:\nDefaultLimitRSS=infinity\nDefaultLimitNOFILE=999999\nDefaultLimitAS=infinity\nDefaultLimitNPROC=1048576\nREBOOT.\nAfter that, it worked flawlessly.\nBut be CAREFUL: you can't exceed the limits which may be set inside \"sysctl.conf\".\nIf you have following values (like me)\nfs.nr_open = 1000000\nfs.file-max = 1000000\nyou have to be -1 in your setting or your system won't boot ever again (been there) and you will be forced to boot a rescue image to fix that. (done that, it sucks)\nIf you use nginx, also make sure that your \"nginx.conf\" has this line:\nworker_rlimit_nofile 999999;\nevents {\n    worker_connections 1048076;\n    use epoll;\n    multi_accept on;\n}. And here a simple script to test how many files can be opened:\n\nnano max_fd\n```bash\n\ninclude \ninclude \nint main(int argc, char **argv)\n{\n        int fd = 0, fd_max;\n        while((fd = dup(0)) > 0) {\n                fd_max = fd;\n        }\n        printf(\"fd = %i\\n\", fd_max);\n        return 0;\n}\n```\n\n./max_fd\n\nroot@chat ~ # ./max_fd \nfd = 999998. Some more facts I forgot to mention.\nInstalled server/client version: 12.0.0\nServer:\n1 Single Server currently, fully dedicated (redis is also a single server, fully dedicated)\nAMD Ryzen 7 1700X Octa-Core \"Summit Ridge\" (Zen)\n64 DDR4 RAM\n500GB SSD\n14 workers, 2 brokers. All on the same machine. We have no code inside broker.js, except the one which was created from CLI using \"socketcluster create app\". We're using sc-uws.\nI might need to mention that we have nginx on the same server as socketcluster, as we're using SSL and we just proxy_pass everything from nginx to node. We've highly tuned sysctl.conf and the limits.conf to use the total maximum on a linux distro based on hundreds of tutorials on the net.\nThe clients are connected on port 443 with a https domain to node and node is passing everything to socketcluster. I don't know if this could also be any reason for the delayed arrivals.. 0,2 % CPU, the server is just running nginx and socketcluster with \"forever\". mysql, redis etc are dedicated own servers.. MySQL will not be called when answers getting in, only redis, which is a dedicated, 8 core intel i7 with SSD and 64GB DDR4 RAM. We've been running millions of request against redis in under a sec, redis is extremely performant . Watching \"top\" live, I've never seen the CPU load going over 1%. Memory also 61GB free from 64GB. Using \"speedometer\" to watch the network-interface, there is an output around 1Mbit and input about 1 Mbit.\nThe server is basically sleeping and has a lot of headroom. \n. @happilymarrieddad nope, self-hosted, on hetzner. https://www.hetzner.com/dedicated-rootserver/matrix-ax?country=gb\nUsing AX60-SSD. I was start to think that AMD sucks and we should switch to an Intel Xeon E3...\n. Please share your informations @MatthewAry if it help.\nI also adjusted rfile_limit and set \"tcp_nodelay\" to \"off\" and added \"proxy_buffering off;\" and \"proxy_request_buffering\" to off; Tomorrow we will see how it goes. . Did you do all of this behind an nginx proxy using ssl? I would love to know how this will perform. I am sure there are no multiple attached event handlers, this has been tested very well inside our app (we had that issue but fixed it)\n@jondubois but more to mention: we're using \"forever\", 14 workers, 2 brokers, single machine and we're also doing a lot of logging. Every \"received message\" on the server will be stored asap into redis after it has been processed. . @jondubois are you using SC without nginx? Could you recommend to renounce nginx as proxy and accessing node.js directly, setting port to 443? Could this help to increase performance? From my understanding, this should be avoided and always proxied by nginx. Should we use a single dedicated server for proxying connections instead of running nginx on the same machine ?. We had so many other issues with our app today that I didn't have any chance to check it deeply enough, but from a quick look it seems like it's working so far. . So, proxy_buffering seemed to fix it for me. Furthermore, there was a memory leak inside my app (beside the trivia feature, we have a live chat integrated) and 500 incoming messages per second and an immediate DOM append caused a very high reflow on my app which peaked Android CPUs up to the limit, causing the answers beeing transmitted very very slow. After fixing this issues, I can't see any delayed messages anymore.. @MatthewAry have a look here\nhttps://github.com/emqtt/emqttd/wiki/linux-kernel-tuning\nThe 1 Million Socket sysctl.conf  in that Wiki looks totally wrong to me and also it has some security issues imho.\nI choosed @behrad recommendation as it mostly fits to other docs I've seen. (like https://blog.jayway.com/2015/04/13/600k-concurrent-websocket-connections-on-aws-using-node-js/)\nI don't see any issues anymore. Keep in mind that calling \u201esysctl -p\u201c won\u2019t propergate everything immediately, tw-reuse needs an reboot for example.\nSo the best thing is to tweak and reboot.. @jondubois may I ask for a litte snippet how to trigger a restart inside of the worker.js for all workers? Currently I am doing some dirty hacks.. (touching a file inside of my app-dir, which force the restart). How can I listen to \"sendToMaster\" events?. @jondubois ?. PM2 shouldn't be used with socketcluster as far as I know. (socketcluster does that scaling stuff itself). Therefore, I switched to \"forever\".. @jondubois \nhaving \nnet.ipv4.tcp_tw_recycle = 1\nin my /etc/sysctl.conf caused the issue. Setting to 0 or removing the line fixed my problem. Finally no stalled connections when workers restart.. Yes. Nginx is on the same machine as socketcluster . ",
    "Kindlysertir": "Hi, so how to adapt socketcluster to my ip hosting vps ?. ",
    "botzill": "Not sure what was the purpose of this issue, but do you plan to make a helm chart?. Hi.\nI would like to ask what is the state of this PR? I would like to test k8s part but would be great to have the updated part. \nThx, great work. . ",
    "debadaz": "@jondubois Thank you, will look into the pointers u shared !!. ",
    "astutesoftware": "Yes you are right. That is exactly what i have in mind. My query was now that does the middleware expose the socket id of the person emitting the message to a channel and the socket id of the person going to receive the message from a channel.\nFor ex. At the middle ware level can i know the following\n1. Dick has sent a message to the channel LOBBY. (I get to know Dicks' socket id which i can lookup in memory and map it and figure out that it is indeed Dick).\n2. Jane is the intended recipient for the current message. (This is where i do the lookup to see if Jane indeed wants the receive the message from Dick, I get Jane's socket id in this case).\n. Yes. @jondubois @happilymarrieddad - Thank you for your input.\nStoring unsent message in localStorage is the way to go then. \nI keep hearing this \"Channels are cheap\". On a group chat room - Is it advisable to subscribe to a channel and intercept via middleware OR create an individual channel for each participant and emit messages to all of them who are supposedly in a room (No subscription - Just intent that they are currently in a room) ?. ",
    "brunoalano": "I've the same issue.. ",
    "austinkelleher": "@jondubois Thanks a lot! I really appreciate you getting the fix in so quickly. I tried it out and everything works great except for error reporting. If either the broker's run method or starting the HTTP server reject with an error, it is not getting propagated properly. I opened up these two PRs to fix the issues:\nhttps://github.com/SocketCluster/socketcluster/pull/353\nhttps://github.com/SocketCluster/sc-broker/pull/5. This issue is fixed, so I'm going to close this out. Thanks again @jondubois!. Also I changed this block of code to only execute handleReady if the start function properly resolves.. ",
    "samlevin": "Am interested in the same. . ",
    "yaiceltg": "Am interested in the same, any example. ",
    "pungggi": "this may help someone > https://github.com/apollographql/apollo-server/issues/637#issuecomment-339055629. ",
    "Coldzer0": "i already did that and nothing happen but anyway i think i should build new project with the newest version and copy my code to it\ncuz there's some changes in the files\nand next time i'll write my code in separated files then import it inside the server & worker. ",
    "fkhateeb": "Hi Man, \nAs I think  updating only the dependency modules only, you couldn't request update and to find all  of your code in worker or any other file have been editing , so  only you need to change the version  on the package.json  and npm update or remove the module dependency folder and npm install.\n. thank you,\nhow I can get the subscribers count in the worker, I can get the socket connected count but the subscribers I couldn't!?. do  you mean to get the sockets scServer.clients then loop on them socket.subscriptions() so  I can know how many subscribers to the channel in this worker and store in redis to sum them up ?!. ",
    "masalinas": "Meaby yes I will use kubernetes, but other question is possible use the SocketCluster/loadbalancer for my problem??\nRegards. We have experience under IBM Bluemix. ",
    "beingshashi": "I don't know why you saying \"That's expected\", Maybe I am not able to convey the problem properly.\nConsider the example of Facebook, it has one chat box, if I open the same FB page in multiple tabs and someone sends me a message, Its shown only one time.\nWe want to have the same concept, but whats happening is in my case, I am receiving messages 4 times in each tab ( I have opened 4 tabs ).\nIs there any way to convey socket cluster that it should create sessions or socket connections based on user Id and not based on tabs session?. ",
    "chnauman": "Hello @carlosfusion \nI am also new to socketCluster, reading the documentations at this time and saw your question. According to what I read till now.. I think the solution to your problem is:\nYou can add a middleware using scServer.MIDDLEWARE_SUBSCRIBE\nin middleware function write an if to check the name by socket.channel == YOUR_RESERVED_NAME\non success use next(); other wise throw and error... \nyou can read more details about the middleware here. Thanks @amin-mir \nI have another question, please give me your thoughts on that...\nI am using an apache server to serve html pages with is running on server X.. I am using socketCluster only for pub/sub feature on server Y.. is there a way that I can some how authenticate user on server Y before they get connected to websocket, and remember I cannot ask user to login again so that I can verify credentials database, and I cannot save his user/pass in JS to send later for websockets connection, for security reasons...\n. yes, @amin-mir .. you got it right... \nI thought that I can only verify JWT token on the server where I generated it... According to you I can create it on one server and check it on other to verify client... I should definitely read JWT documentation, before I go in detail tell me on thing... if I create JWT token on one server and then send it to other server to connect websocket.. how will second server verify that its right... second server does not already have that token, so it will be compared to what??. @amin-mir, I understand..  Thank you so much for making it easier for me.. . ",
    "kherock": "Whoops, I'm sorry, I actually can read scServer during my run() method. However this definitely did initially break my setup from 9.2 => 9.3 since I was previously relying on the constructor being synchronous in a couple spots, but I guess I might be alone since it's been a few weeks without anyone else complaining.\nIt still wouldn't hurt to keep _init() sync if createHTTPServer() doesn't return a Promise though.. ",
    "sravia": "THANK YOU! Could not find it before :). ",
    "takaaptech": "Hi @sacOO7 Thank so much! I will try it now!. ",
    "drew-r": "@jondubois I'm not passing a wsEngine option. This is on node 8.4 and also presented on 6.9.\nIt's running in Docker on kubernetes.\nI am 99.99% positive it correlates to whether SocketCluster is attached or not.\nUnfortunately there is no reliable repro case or snippet though I have been trying to find one all day.\nA related similar issue https://github.com/expressjs/express/issues/2357 if helpful.\nOn my local Docker server I am seeing \nCompilation of \u00b5WebSockets has failed and there is no pre-compiled binary available for your system. Please install a supported C++11 compiler and reinstall the module 'uws'.\nwhich I am working to resolve now.\n. No HTTPS at play.\nOne of these two changes resolved the issue:\n - updating socketcluster from 7 to 9 \nOR\n- wsEngine: 'ws' \nThe uWS compilation issue i think was isolated to my local docker set up but not entirely sure.\nWould love to know the root cause here but probably too many variables at play. Among the above my broker controller was crashing out and rebooting on every new channel subscription. ",
    "HoplaGeiss": "Thanks!. ",
    "hardikamutech": "you can use emit method of SCSocket (Client)/SCSocket (Server), check document here for SCSocket client https://socketcluster.io/#!/docs/api-scsocket-client same for the SCSocket (Server) https://socketcluster.io/#!/docs/api-scsocket-server and find emit Method. for example find https://socketcluster.io/#!/docs/handling-failure. Hello to @toredash  and @MegaGM ,\nThanks a lot for your quick response as you guys suggested we have added 8 brokers with the same configuration, and we saw a major boost in performance. we are now getting message within a second to all connected client YaaY!! we have tested this with around 50k online client. On each client connection we are sending welcome message to that single connected client using emit method, and after all connection we are broadcasting message each second for stress test. Everything works perfect. Thanks again.\n@MegaGM I also wanted to test your suggestion to send message on \"setTimeout(func, rand(1-500ms))\" in the MIDDLEWARE_PUBLISH_OUT, can you please explain how can I achieve this? \nwe are using \"scServer.exchange.publish('match',json_object);\" where match is channel name and json_object is a big json data object.\nA sample would be great.. @MegaGM and @toredash Thanks for the responsive support! I really appreciate your contributions here. \n@jondubois Thanks for this scalable application. Keep up the good work guys.\nclosing this issue.. Thanks a lot @jondubois for a quick response, I will try your suggestion and let you know.. ",
    "shcheuk": "behavior :\nif you specify a value less than processTermTimeout, it will actually kill all workers before the processTermTimeout. \nif you specify 0, it will not kill\nif you killMasterOnSignal:true, it will not kill anything after forceKillTimeout. As everything get killed immediately\n. added a forceKillSignal option default to SIGHUP, for the reason of choosing it, I just follow this link: https://askubuntu.com/questions/644404/what-are-the-different-htop-kill-signals\nit suggest this seems like the safest kill. I tested, it is able to kill the \"waiting debugger close connection bug\" introduced by nodejs. and some simple infinite loop. \n. options.processTermTimeout = 0 wiil return default 10000 since if(0) is false. Oh really, sorry, it is a global similar to terminatedCount, I missed a big part of the commit. It used to record down which workers exit signal are received.. childExitMessage[i] will be some like:\n{1:true,3:true}\n{1:true,3:true,8:true}. .. Thanks for your paitent. ",
    "HassanShulli": "yes I am using cmd.exe on windows, can you advise on where I can find the equivalent windows commands?. ",
    "Tuccinator": "The main process must only be run on one instance so in my case it wouldn't need to scale horizontally, but it's workers which connect to it will need to. Essentially there is a primary process on it's own server that all the workers will publish their data to. Do you think it would be fine to separate the entire logic of the primary process away from the socket cluster, into its own process, and only access the said primary process through Redis?. All right. Thanks for the help!. Thanks for your answer regarding both of the questions.\nsc-stateless-presence says \"It's ideal for tracking the presence of users within channels that have fewer than 100 concurrent subscribers online at any given time.\" The channel will have up to 5000 concurrent connections so it sounds like this approach wouldn't scale very well. If someone has 3 tabs open, does it count all 3 tabs as separate subscriptions?. Well I don't need the actual usernames, just the online count.\nReferring to 334, do you know how many subscribers we are talking about? I'm looking to publish a message every 200 milliseconds to all subscribers. The max amount of subscribers would be around 5000. Unlike what \"toredash\" said, I cannot implement a 1-5 second delay.. ",
    "MadGeometer": "It does not show messages like \"The scc-worker instance 2e40a451-16f3-4ac6-b410-11e4386fa7b9 at address ::ffff:172.18.0.6 joined the cluster\"\nOne of my coworkers got the tutorial to work, using 9.3.3. Another coworker was unable to get it to work until he updated to SC 11, as well as modifying some worker code.. ",
    "fas3r": "Hello @jondubois , \nThanks for this great tool, is is something that you implemented ? :) \nthanks by advance.. ",
    "tiaod": "Just run:\nnpm install -g socketcluster\nsocketcluster create myapp. ",
    "miladr0": "@tiaod thanks man, i didn't know sample used express.. no one can help me? :(. ",
    "MatthewAry": "I'm having the same problem and I've spent days working on it. I do not, by any means have the same traffic as the OP. I'm still developing the application that's using SC. However I've been trying to isolate the problem by measuring the time it takes for the client's request to arrive to the server. \nMy method to track latency is not super accurate but its accurate enough for me to identify that the problem does not exist in any code that I've written. My server is also not very powerful either. It doesn't need to be for multiple reasons.\n\nIt's still under development.\nAt any time, the most users that we have using the application is 5.\nSC is being used instead of a regular REST API.\nIt's traffic isn't anything close to that of a chat application, or a game where state needs to be shared across multiple clients. It's just a simple REST API replacement.\n\nRegardless of these factors, responsiveness and performance of client/server communication has not been consistent. My investigations into this problem have shown that the lag that I'm seeing can happen because there is a lag time in one or both of these situations.\n\nIt takes a long time (seconds) for the client's request to reach the event handler in the worker.\nIt takes a long time (seconds) for the server's response to the client's message to reach the client.\n\nThe performance problems are intermittent. The server, under normal load hasn't once gone over 15% of its overall CPU capacity. RAM consumption hovers usually around 17% and doesn't have any wild fluctuations. The SC run application is behind an NGINX reverse proxy, and that's been updated, reconfigured, and tested to see if it was responsible for the performance issues, and at this point NGINX has been eliminated as the cause for the intermittent slow downs.\nThis application has been on SC 9.3.1, 11.1.0, 11.3.1, and now the latest 13.1.3. Only recently has fixing this irregularity in performance has become a priority for me, so since 11.3.1 have I been trying to track down the problem.\nThe Server's configuration is as follows:\n\n1 vCPU (Intel Sandy Bridge)\n3.75 GB of RAM\nDNS is being handled through Cloud Flare.\nServer is running on Google Cloud in Google Compute Engine.\n\nTypical ping time is 70 ms to the server from client computers that have experienced the slow down.\nApache Benchmark hitting the /health-check route on the server shows the following.\nConnection Times (ms)\n              min  mean[+/-sd] median   max\nConnect:      415  934 243.8    901    2136\nProcessing:    77  190 115.7    144     619\nWaiting:       77  155  71.5    134     496\nTotal:        575 1124 240.3   1063    2235\nLastly, I'm measuring the execution times for all server operations as part of my investigation, they are not responsible for the slow downs in SC traffic.. It's not the cloud provider. I've seen it degrade on ws, sc-uws, and uws. I haven't tried running a plain node.js HTTP server next to it. Yes, it's a small machine, but what it's doing isn't too major either. Google's infrastructure ties instance bandwith to the number of vCPU's (we have 1) the instance has.\n\nThe egress throughput cap is dependent on the number of vCPUs that a virtual machine instance has. Each vCPU has a 2 Gbps egress cap for peak performance. Each additional vCPU increases the network cap, up to a theoretical maximum of 16 Gbps for each virtual machine. For example, a virtual machine instance with 4 vCPUs has an intra-zone network throughput cap of 2 Gbps * 4 = 8 Gbps. A virtual machine instance with 8 vCPUs has an intra-zone network throughput cap of 2 Gbps * 8 = 16 Gbps.\nSpecific workloads and benchmarks are regularly measured:\n\nA single stream performance test can achieve a maximum of 8.5 Gbps on average.\nA multistream performance test can achieve a maximum of 15 Gbps on average.\n\n\nOn the same server, we are serving up static files for the front end of the application using NGINX,\nit's performance as tested using Apache Benchmark is as follows.\nConnection Times (ms)\n              min  mean[+/-sd] median   max\nConnect:      302  932 338.9    856    5595\nProcessing:    74  161  88.1    126     399\nWaiting:       74  126  51.0    104     321\nTotal:        412 1093 344.9    999    5793\nKeep in mind that while doing my benchmarks, I'm hitting the server with 100 concurrent connections at a time.\nI'm currently using sc-uws which version is 10.148.0 according to package-lock.json. @jondubois It's a dedicated instance (not a shared vCPU) with guaranteed memory and computational power. Before we were on a shared instance where that could be the case, but we moved to a dedicated instance to eliminate the possibility even though our resource consumption was not high enough to justify the move.\nIn any case, @happilymarrieddad works down stairs from me and he's got me trying out one more thing with NGINX. I'll let you know how that goes.. Hahaha. @happilymarrieddad is hoping that my rlimit_nofile value is not high enough. So that's what I'm testing.. Nope, that didn't fix it.. I should have mentioned that we're using our NGINX reverse proxy to SSL the connection to the application too.. Well, I can try turning proxy buffering off entirely. @happilymarrieddad has his on and he hasn't seen any of the problems that I've been having.. Correction @happilymarrieddad doesn't have proxy buffering on. I've turned off Proxy Buffering on my machines. I'm in the process of collecting data to see if the issue is resolved.. @Hirbod Have you observed the issue since you turned off proxy buffering?. Well, I've got Proxy Buffering off, but I'm still seeing issues. I'm going to look into this kernel tuning stuff.. I don't know yet. It's gonna be awhile until I find out for sure. My priorities have changed for the moment.. Still seeing the issue. I'm working on some other things but as a side effect of that work I'm still seeing the slowness.. Yes I did all of that. I determined that lag does not exist in my server\nside code or on the client side code but the mechanisms that facilitate\ncommunication between client and server. I added time stamps to the client\nand server and compared times. I also measured execution times of my server\nside code. The slow down happens when I pass things off to Socket Cluster\nto send to the client/server. I can see slow down in the client's message\nreaching the server or the server's message reaching the client. I've also\ntried to eliminate the possibility that the issue is network related, but\nmy tests show good ping and jitter values. So in the end, I'm not sure what\nthe hold up is.. ",
    "mahdiyousofun": "i mean that i send a message to specific user not to all user.\nso as you said it is possible.\ncan you help me in this subject?\nhow can save online users? actually if a user connected to server can i save its connection in one list?\n@MegaGM . ",
    "dafivius": "@MegaGM this on('publish') handler. No errors at console. But before errors i can see console.log() message well. It's broker.js file - default brokerController.\n```\nlet SCBroker              = require('socketcluster/scbroker');\nlet scClusterBrokerClient = require('scc-broker-client');\nlet EventHelper           = require('./public/js/helpers/EventHelper.js');\nlet XMPPClient            = require('./public/js/xmpp/XMPPClient.js');\nclass Broker extends SCBroker {\n    run() {\n        console.log('>> Broker PID:', process.pid);\n    this.xmppStorage = {};\n\n    if (this.options.clusterStateServerHost) {\n        scClusterBrokerClient.attach(this, {\n            stateServerHost               : this.options.clusterStateServerHost,\n            stateServerPort               : this.options.clusterStateServerPort,\n            mappingEngine                 : this.options.clusterMappingEngine,\n            clientPoolSize                : this.options.clusterClientPoolSize,\n            authKey                       : this.options.clusterAuthKey,\n            stateServerConnectTimeout     : this.options.clusterStateServerConnectTimeout,\n            stateServerAckTimeout         : this.options.clusterStateServerAckTimeout,\n            stateServerReconnectRandomness: this.options.clusterStateServerReconnectRandomness\n        });\n    }\n\n    this.on('publish', (channel, data) => {\n        console.log(process.pid, 'Broker received data from channel', channel, 'data:', data);\n        throw new Error(); //nothing\n\nthis.notExistedMethod(); //nothing\nabcdefgh //nothing;\n        });\n}\n\n}\nnew Broker();\n```. @jondubois node 9.7.1, SC is latest.\n@MegaGM exactly as you wrote above. I didn't use redis adapter. \nThanks for your replies. I've reinstalled SC, reinstalled my NPM and began to gather errors in console (no ideas why). Sorry for that situation, you can close an issue. My config is: MacOSX, Node 9.7.1, NPM 6.1.0, PhpStorm 2017.3, SC is latest. If somebody will face similar situation - try my steps first. . ",
    "ayberkanilatsiz": "@MegaGM it works like a charm! Thankss =). I use it for direct message and it works. It's for inboxes it means place where you show the profiles that the member is already chatting. . ",
    "mahmoudsalem": "[Busy] Launching SocketCluster\nnode[23351]: pthread_create: Resource temporarily unavailable\n\n\nBroker PID: 23351\nWorkerCluster PID: undefined\n1543746594818 - Origin: WorkerCluster\n   [Error] Error: spawn /usr/bin/node EAGAIN\n    at _errnoException (util.js:1024:11)\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:190:19)\n    at onErrorNT (internal/child_process.js:372:16)\n    at _combinedTickCallback (internal/process/next_tick.js:138:11)\n    at process._tickCallback (internal/process/next_tick.js:180:9)\n\n\ni also get this error @jondubois . ",
    "leyue": "add some info: \nform docker container: \n\n\nsocketcluster-sample@1.0.0 start:docker /usr/src\nnode dockerwait.js && node ${SOCKETCLUSTER_MASTER_CONTROLLER:-server.js}\n\n\u001b[0;33m[Busy]\u001b[0m Launching SocketCluster\n\n\nBroker PID: 43\nWorkerCluster PID: 53\nWorker PID: 59\n   \u001b[0;32m[Active]\u001b[0m SocketCluster started\n            Version: 13.1.7\n            Environment: prod\n            WebSocket engine: ws\n            Port: 8000\n            Master PID: 33\n            Worker count: 1\n            Broker count: 1\n\n\n{ SocketProtocolError: Socket hung up\n    at SCSocket._onSCClose (/usr/src/node_modules/scc-broker-client/node_modules/socketcluster-client/lib/scsocket.js:652:15)\n    at SCTransport. (/usr/src/node_modules/scc-broker-client/node_modules/socketcluster-client/lib/scsocket.js:294:12)\n    at SCTransport.Emitter.emit (/usr/src/node_modules/component-emitter/index.js:133:20)\n    at SCTransport._onClose (/usr/src/node_modules/scc-broker-client/node_modules/socketcluster-client/lib/sctransport.js:212:28)\n    at WebSocket.SCTransport.wsSocket.onclose (/usr/src/node_modules/scc-broker-client/node_modules/socketcluster-client/lib/sctransport.js:66:10)\n    at WebSocket.onClose (/usr/src/node_modules/ws/lib/event-target.js:124:16)\n    at emitTwo (events.js:126:13)\n    at WebSocket.emit (events.js:214:7)\n    at WebSocket.emitClose (/usr/src/node_modules/ws/lib/websocket.js:172:10)\n    at Socket.socketOnClose (/usr/src/node_modules/ws/lib/websocket.js:774:15)\n  name: 'SocketProtocolError',\n  message: 'Socket hung up',\n  code: 1006 }\n1529463542362 - Origin: Worker (PID 59)\n   [Warning] SocketProtocolError: Socket hung up\n    at SCServerSocket._onSCClose (/usr/src/node_modules/socketcluster-server/scserversocket.js:249:17)\n    at WebSocket. (/usr/src/node_modules/socketcluster-server/scserversocket.js:79:10)\n    at emitTwo (events.js:126:13)\n    at WebSocket.emit (events.js:214:7)\n    at WebSocket.emitClose (/usr/src/node_modules/ws/lib/websocket.js:172:10)\n    at Socket.socketOnClose (/usr/src/node_modules/ws/lib/websocket.js:774:15)\n    at emitOne (events.js:116:13)\n    at Socket.emit (events.js:211:7)\n    at TCP._handle.close [as _onclose] (net.js:554:12)\n1529463542648 - Origin: Worker (PID 59)\n   [Warning] SocketProtocolError: Failed to complete handshake\n    at SCServerSocket._onSCClose (/usr/src/node_modules/socketcluster-server/scserversocket.js:249:17)\n    at WebSocket. (/usr/src/node_modules/socketcluster-server/scserversocket.js:79:10)\n    at emitTwo (events.js:126:13)\n    at WebSocket.emit (events.js:214:7)\n    at WebSocket.emitClose (/usr/src/node_modules/ws/lib/websocket.js:172:10)\n    at Socket.socketOnClose (/usr/src/node_modules/ws/lib/websocket.js:774:15)\n    at emitOne (events.js:116:13)\n    at Socket.emit (events.js:211:7)\n    at TCP._handle.close [as _onclose] (net.js:554:12)\n1529463542791 - Origin: Worker (PID 59)\n   [Warning] SocketProtocolError: Failed to complete handshake\n    at SCServerSocket._onSCClose (/usr/src/node_modules/socketcluster-server/scserversocket.js:249:17)\n    at WebSocket. (/usr/src/node_modules/socketcluster-server/scserversocket.js:79:10)\n    at emitTwo (events.js:126:13)\n    at WebSocket.emit (events.js:214:7)\n    at WebSocket.emitClose (/usr/src/node_modules/ws/lib/websocket.js:172:10)\n    at Socket.socketOnClose (/usr/src/node_modules/ws/lib/websocket.js:774:15)\n    at emitOne (events.js:116:13)\n    at Socket.emit (events.js:211:7)\n    at TCP._handle.close [as _onclose] (net.js:554:12)\n1529463543308 - Origin: Worker (PID 59)\n   [Warning] SocketProtocolError: Socket hung up\n    at SCServerSocket._onSCClose (/usr/src/node_modules/socketcluster-server/scserversocket.js:249:17)\n    at WebSocket. (/usr/src/node_modules/socketcluster-server/scserversocket.js:79:10)\n    at emitTwo (events.js:126:13)\n    at WebSocket.emit (events.js:214:7)\n    at WebSocket.emitClose (/usr/src/node_modules/ws/lib/websocket.js:172:10)\n    at Socket.socketOnClose (/usr/src/node_modules/ws/lib/websocket.js:774:15)\n    at emitOne (events.js:116:13)\n    at Socket.emit (events.js:211:7)\n    at TCP._handle.close [as _onclose] (net.js:554:12)\n1529463571382 - Origin: Worker (PID 59)\n   [Warning] SocketProtocolError: Socket hung up\n    at SCServerSocket._onSCClose (/usr/src/node_modules/socketcluster-server/scserversocket.js:249:17)\n    at WebSocket. (/usr/src/node_modules/socketcluster-server/scserversocket.js:79:10)\n    at emitTwo (events.js:126:13)\n    at WebSocket.emit (events.js:214:7)\n    at WebSocket.emitClose (/usr/src/node_modules/ws/lib/websocket.js:172:10)\n    at Socket.socketOnClose (/usr/src/node_modules/ws/lib/websocket.js:774:15)\n    at emitOne (events.js:116:13)\n    at Socket.emit (events.js:211:7)\n    at TCP._handle.close [as _onclose] (net.js:554:12)\n. ",
    "tangquoctuan": "Hi @happilymarrieddad, thanks you for your reply,\nYah! Before I make an question about this problem, i solved it nearly as your solutions, but i used socket id per each user as an private channel to communicate between server and client. \nAt the begnning, i choose socket.io as an framework for my project, but as you know that, it make my feel difficult to manage session between those node server. So, that is the reason why i have choosen socketcluster. \nIf compare socket.io vs socketcluter, I feel each type has different strengths and weaknesses. The weaknesses of socketcluster is about pub/sub between client/server. In my opinion, i recommend author improve, separate emit/broadcast/v.v... as socket.io as done.\nThanks you!. Hi @MegaGM , thanks you for your reply.\n\ndifficult to manage session between those node server\n\nIn this situation, i mention the weakness about the socket.io. When i hosted real-time server (socket.io) with cluster mode. I got an problem when those socket servers share socket id. After all an research, i have to use socket.io-redis acting as a management place to share session between nodes. That made things complicated. But socketcluster do it very well.\n\nimprove, separate emit/broadcast/v.v... as socket.io as done.\n\nFYI, socket.io a lots of method communicate between server/client (https://stackoverflow.com/a/10099325/3205195). So, return to my issue when apply socketcluster in this post, A want to connect with B, A emit event to server, server make an private event between A - B -> alert B that A want to communicate. But how can server alert to B because socketcluster does not support emit  to specified channel through their socket_id. So we have use trick as an recommend of @happilymarrieddad said.\nThanks you!. Hi @happilymarrieddad,\nBase on your suggestion that each channel subcribe their individual id and...  the error has occurred:\n```\n[Warning] BrokerError: Failed to subscribe socket to the tuan: 1,tuan: 2,tuan: 3,tuan: 4,tuan: 4,tuan: 5 channel - Socket imsWT8xa5sFCmNx0AAAB provided an invalid channel name\n    at /home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/socketcluster-server/scserver.js:444:23\n    at EventEmitter.SCServer._subscribeSocket (/home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/socketcluster-server/scserver.js:239:17)\n    at Emitter. (/home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/socketcluster-server/scserver.js:442:12)\n    at Emitter.emit (/home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/component-emitter/index.js:133:20)\n    at /home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/socketcluster-server/scserversocket.js:165:38\n    at /home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/socketcluster-server/scserver.js:748:15\n    at /home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/async/dist/async.js:1110:9\n    at /home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/async/dist/async.js:460:16\n    at replenish (/home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/async/dist/async.js:977:25)\n    at /home/tangquoctuan/sc-demo-chat/socketcluster/dm/node_modules/async/dist/async.js:986:9\n```\n. I saw the problem and solved it, thanks for reply @jondubois! I'm appriciate it.. ",
    "deusz": "I got it. Server socket doesn't have socket.subscribe but socket.exchange.subscribe.. ",
    "Crypto-Q": "Yeah would nice to see this public thank you.. ",
    "petecz": "Very much so! We have also made private type definitions for our internal use case but they are also incomplete. Would be great to finally see a public type definition. I'm up to help out with PRs later.. ",
    "DanielRose": "My current state is at https://github.com/DanielRose/DefinitelyTyped/tree/socketcluster There are type definitions for sc-auth, socketcluster, socketcluster-client and socketcluster-server. It is still incomplete, especially missing tests (except for sc-auth).. @jondubois Once it is in a somewhat releasable state, I'll send a PR. I'm currently expanding the code by adding expirymanager, fleximap, sc-broker, sc-broker-cluster and adding additional methods and so on.. I now have a version that throws no errors when compiling for DefinitelyTyped. I have the type definitions (though incomplete in some places) for:\n\nsc-auth\nsocketcluster\nsocketcluster-client\nsocketcluster-server\nexpirymanager\nfleximap\nsc-broker\nsc-broker-cluster\nsc-channel\n\nPlease take a look. If nobody complains I'll send a PR in the next days.. @Akuukis typeRoots is deprecated. It is a relic from TypeScript v1 (or something like that) and doesn't work with modern type definitions. The correct way to add custom type definitions is via the combination of baseUrl and paths, i.e.\njson\n{\n  \"compilerOptions\": {\n    \"baseUrl\": \".\",\n    \"paths\": {\n      \"*\": [\"src/types/*\"]\n    }\n  }\n}\nNote that by convention, the type definitions in node_modules/@types and those placed next to the js-files are always loaded.\nI've updated the type definitions to add attach and listen.. sc-uws is basically the same as uws. Unfortunately the type definitions there are not up to date. I could work on them later, but first I would want to finish these.. Leaving aside how to get the .d.ts files (either autogenerated because the code is written in Typescript, or manually written), there are two main options, as @Akuukis wrote:\n\nInclude them as part of the bundle (ex. moment)\nPlace them in DefinitelyTyped (ex. express)\n\nAdvantage of bundling the type definitions:\n\nDevelopers see them directly, and can update them, if necessary\nMore likely that they will get updated\n\nDisadvantages:\n\nUpdating them means a new library release\nThey get distributed to everyone (i.e. not only developers using Typescript)\nA Microsoft employee looks at updates and (especially) new type definitions in DefinitelyTyped, but not somewhere else. Sorry I've been absent for so long. I was on vacation, and then we had major production issues (hangs and crashes). I'll try to finish the PR in the next couple of days.. Finally got everything done. Found a few places where I had wrong definitions or was missing them: https://github.com/DefinitelyTyped/DefinitelyTyped/pull/30944. PR got merged!\n\nhttps://www.npmjs.com/package/@types/socketcluster. ",
    "Akuukis": "@DanielRose thanks for types! I tried it out like this:\n\nAdd type roots to tsconfig\n...\n        \"typeRoots\": [\n            \"../../node_modules/@types/\",\n            \"node_modules/@types/\",\n            \"src/types/\"\n        ]\n...\ngit clone your repo, copy the following to \"src/types\", install external types and delete tests from them\nyarn add socketcluster-server socketcluster-client\n mkdir src/types\n cp -r ../../../DefinitelyTyped/types/socketcluster src/types/\n cp -r ../../../DefinitelyTyped/types/sc-broker-cluster src/types/\n cp -r ../../../DefinitelyTyped/types/sc-broker src/types/\n cp -r ../../../DefinitelyTyped/types/fleximap src/types/\n cp -r ../../../DefinitelyTyped/types/socketcluster-server src/types/\n cp -r ../../../DefinitelyTyped/types/sc-broker-cluster src/types/\n cp -r ../../../DefinitelyTyped/types/expirymanager src/types/\n cp -r ../../../DefinitelyTyped/types/sc-auth src/types/\n cp -r ../../../DefinitelyTyped/types/sc-channel src/types/\n yarn add -D @types/expirymanager @types/jsonwebtoken @types/jsonwebtoken @types/async @types/component-emitter @types/ws\nNo TS type errors in typing directors, so far so good.\nback in my code types are not found in neither form\nimport * as socketClusterServer from 'socketcluster-server'\n// OR\nimport socketClusterServer = require('socketcluster-server');\n\nI am not sure whether problem is in setup of DefinitelyTyped or types themselves, so here's the steps to reproduce and please let me know!\n. I copied socketcluster-server/*.d.ts into ./node_modules/socketcluster-server and it is found now. \nBut I have a error in SocketCluster's own example\n```\nimport * as socketClusterServer from 'socketcluster-server'\n... do express stuff, create httpServer ...\nconst scServer = socketClusterServer.attach(httpServer);\n//                                   ^\n```\n\n[ts] Property 'attach' does not exist on type 'typeof import(\"node_modules/socketcluster-server/index\")'.. @DanielRose Thanks, that worked.\n\nTypes looks good so far. Can you please also type sc-uws? E.g. in Webpack's case it should be imported separately and passed as  option.. @DanielRose Right, sc-uws can be done seperately. In that case types looks good to me . I have seen three cases:\n1. DefinitelyTyped repo, that follows versioning at major and minor level\n2. bundled types inside repo, and also a stub DefinitelyTyped repo that throws warning about being only a stub\n3. is written in TypeScript itself, but otherwise the same as No.2\nPersonally, when doing yarn add something I automatically do also yarn add -D @types/something and just press CTRL+C if that throws warning about being a stub. In such case either way is equally accessible.. bump.\n@jondubois , what's the checklist to get types into the repo?. ",
    "pscanlon1": "Sorry for ignorance... But could you provide how to get these types? Im not seeing them in any of the source. Thanks!. apologies, I found the types, SCServer import worked when I threw them all in the node_modules/@types directory... But SCWorker is not?. ",
    "tarilo": "Change the question, testing and testing we detect scServer.exchange.subscribe works perfect in one servers machine, if you mount a cluster with one state server, one scc brokers and x servers with brokers and server the comunication between machines dont work. The messages in origin machine works but other server dont receive nothing.. Hi @MegaGM We updated to scc-state 6.1.0 and can't connect from machines to the horizontal cluster. \nLaunching 2 server on same server works fine but when add external machines, the state server show new conection but server reports this error and there is not connection between servers\n{ SocketProtocolError: Socket hung up\n    at SCClientSocket._onSCClose (/home/xxxx/xxxxxx/node_modules/scc-broker-client/node_modules/socketcluster-client/lib/scclientsocket.js:647:15)\n.....\n  name: 'SocketProtocolError',\n  message: 'Socket hung up',\n  code: 1006 }. Hi @MegaGM . Investigating we found the problem. All the machines need to have a local scc-broker running to woth with hotizontal cluster. Any code try to connect to 127.0.0.1 or localhost. If you run local scc-broker on each server all works good. The problem is your architecture picture are not correct.. Hi @jondubois all the servers are in the same network on google cloud. firewall has open ports. We need to run one scc-broker on each machine to setup cluster working. The parameters you say are in the scc-broker, i need to pass the scc-broker ip to the sc-server to reach the scc-broker. Setup x workers, one broker and one scc-brokers on each machine works fine. Thanks. ",
    "sportsbook123": "Nevermind I was stupid, I was killing workers and brokers but forgot to kill scserver.js as well bcos it wasn't showing up in ps ax | grep socketcluster...it's like I'm brain dead or something on saturdays.. ",
    "dkruchinin": "@jondubois \nThank you for fast reply.\n\nFor example, if a channel has 1000 subscribers and only 999 of them receive the message successfully; should we tell the publisher client that the publish operation was a success or a failure?\n\nI don't think the publisher has to know anything about how its messages get distributed by SocketCluster and how many subscribers receive it. Delivery guarantees are good enough as long as I can assume that the messages at least hit the server-side handler that can be modified to persist them. In your example I would care more about building a mechanism that would notify the publisher once the message it sent is persisted by the server.\n\nIf you want to track if specific subscribers have received specific messages, then you can create special receipt/acknowledgement channels which subscribers can use to inform publishers whenever they receive certain messages.\n\nIdeally, I don't want subscribers to deal with re-sending messasges to publishers, I would prefer it being resolved on the server side. It is perfectly fine if the subscriber sends a bunch of messages and then goes offline. If the server managed to receive all those messages, it can take care of propagating them to subscribers and provide some delivery guarantees like letting the subscribers know that the stream of messages was interrupted by a scc-broker failure and they have to re-connect and pull those messages that they've missed.\nBasically, I'm trying to understand if SocketCluster is a good option for what I want to achive, namely:\n- the server acknowledges subscribers once their messages are written to a persistent sotre\n- in case of a hardware failure affecting one of the core components of the cluster responsible for publishing messages to subscribers (like scc-broker or woker), all clinet connections directly or indirectly managed by the failed component are interrupted, so that they can reinitialize the connection and figure out what they missed.. @jondubois Thank you! Is there already a branch with a prototype I can keep an eye on? . ",
    "rasmuserik": "+1\nI also need a changelog, - as we are upgrading from version 8 here, and want to know about possible incompatibilities/changes in protocol or API. Especially: are old clients compatible with newer versions of the server.. @jondubois Thanks a lot :)\nDon't know how I missed it, as I now realise that it is clearly mentioned in the README. I'll add a pull request which adds the link you gave, and closes this issue.. ",
    "bebeo92": "@jondubois Yes, if I kill main process, it will turn off that child process\nBut you know, when you deploy it into production, you should find a way to run it in background and that it nothing else (no blank screen....).\nAnd in my case, our team using pm2, Imagine like you have hundred app running on server and each app need a console to display... it will be a mess right?\nSo my expectation is find out a way to deploy app using socketcluster using script and it will running silently in background. Is there a way to do it using pm2 or other tool I would like to know, or directly using socketcluster by itself?. @jondubois Ok then so is there any easy way to start and stop SC automatically?\nSorry but I stick with window ....\nOh forget to update, same issue when use powers hell ...... @jondubois pm2 already in latest version ...\nOption 2 look promise then. ",
    "alex198211": "Should I do mychannel.off() after publishing? or will .unsubscribe do that? Can't seem to figure it out from the docs.. ",
    "eranegozy": "gotcha. Thanks. I did manage to write my own customized stress test using this example. A bit busy right now, but yeah, I'll take a look and maybe try to clean up this repo sometime in the near future.. ",
    "d-m-cc": "@jondubois fantastic -- thank you for your suggestions!. ",
    "0xsegfault": "@jondubois Hey John, \nI'll make those changes shortly. I only add the server and deployment to the name to make it easier for me to remember what's going on in our production environment. There is no need to do it here. Sorry about that. As far as ClusterIP is concerned, it's the way you're supposed to do internal networking in Kubernetes. The other kind is going to be deprecated like loadbalancer is. That's at least my understanding. Thanks!. oops... wrong account.. sorry lol. ",
    "Jerar": "I'll give it a try, thank you for your answer :). ",
    "nmhung109": "@jondubois , pls give to me any suggestion about this issue. I think it's very similar to #218 that @hustcer met. @jondubois The problem is that I saw Server responsed to client via res function. And it's fast, just below 1s while default is 10s. That's why Browser client can still work properly. But it happened occasionally on Mobile. ",
    "pickmeup101": "Hi @sacOO7,\nAs I know, in Unity, most developers are used to using the Asset Store (https://assetstore.unity.com/) to find and download resources. So compared to the dll, I think it will be much compatible and simple to have an asset in the Asset Store. \nFYI: https://unity3d.com/asset-store/sell-assets\nPS. Waiting for the feature of \"WaitForAuth\". \nFYI: https://socketcluster.io/#!/docs/api-scchannel-client\nThank you very much! \n. ",
    "VincentRichard555": "@sacOO7 \nA readymade dll would be very nice. Thanks!. ",
    "maxwellhaydn": "Ah yes, I like your solution of accepting a string or an Error object better.. @jondubois Great! Thanks for the quick turnaround!. ",
    "OzySky": "What have you tried doing on the client?. It seems to be related to the .net client. \nYou probably should open an issue there.. ",
    "JoshuaVSherman": "socketCluster already does this for you, so you don't need node_redis. ",
    "kylebernhardy": "Thanks Jon! That makes a lot of sense. One other area I am looking into is server to server replication of data between instances of SocketCluster.  I see you can use scc-broker & scc-state to scale horizontally, which I assume would allow you to broker data between instances. However my use case involves sometimes just publishing to another instance sometimes just subscribing or both based on needs and configuration.  It doesn't feel like scc-broker/state would be the best fit for that.  What I was thinking instead would be a need to create socketcluster-client(s) between instances.  Would this be the best way to handle this form of inter-node data sharing?  Is there a way to attach a process/processes to handle these clients that would be attached to the SocketServer to watch the broker? Or would I need to manually spawn a process to do this.\nThank you for your feedback and creating this amazing framework!. ",
    "bodaghialib4": "Dear @jondubois ,\ndo you have any solution to my problem?. Dear @jondubois , thanks a lot for your response and sorry for the delay in my response.\nI tested most of the situation and I find out that this situation only occurred when there is only one connection in the current worker.\nI create a simple test project and the error exists yet. my code is:\nin client(react native - in App.js file):\n```iavascript\ncomponentDidMount() {\n        this.SCClient = null;\n        let options = {\n            hostname: '192.168.1.104',\n            port: 8000,\n            disconnectOnUnload: true,\n            autoReconnect: true\n        };\n    this.SCClient = socketCluster.create(options);\n\n    this.SCClient.on('connect', () => {\n        this.SCClient.subscribe(\"Hello\");\n\n        try {\n            this.SCClient.publish(\"Hello\",\n                {\n                    uuid: userAccountStore.UID,\n                    negotiation: 'hello',\n                }\n            );\n        } catch (error) {\n            console.warn(\"error in SCClient.publish:\" + error);\n        }\n    });\n\n    this.SCClient.on('error', (data) => {\n        console.log('socketCluster error:' + data);\n    });\n\n}\n```\nin worker:\n```javascript\nvar SCWorker = require('socketcluster/scworker');\nvar express = require('express');\nvar serveStatic = require('serve-static');\nvar path = require('path');\nvar morgan = require('morgan');\nvar healthChecker = require('sc-framework-health-check');\nclass Worker extends SCWorker {\n    run() {\n    console.log('   >> Worker PID:', process.pid);\n    var environment = this.options.environment;\n\n    var app = express();\n\n    var httpServer = this.httpServer;\n    var scServer = this.scServer;\n\n    if (environment === 'dev') {\n        // Log every HTTP request. See https://github.com/expressjs/morgan for other\n        // available formats.\n        app.use(morgan('dev'));\n    }\n    app.use(serveStatic(path.resolve(__dirname, 'public')));\n\n    // Add GET /health-check express route\n    healthChecker.attach(this, app);\n\n    httpServer.on('request', app);\n\n    var interval = setInterval(function () {\n        console.log(\"\" + process.pid + \" is OK\")\n    }, 5000);\n\n\n    scServer.on('connection', function (socket) {\n\n        console.log('new socket #' + socket.id + ' connected in (' + process.pid + ')');\n\n        socket.on('message', function (data) {\n            //console.log('message (' + process.pid + \"): \", data);\n        });\n\n        socket.on('close', function (data) {\n            console.log('socket #' + socket.id + ' closed in (' + process.pid + \"): \", data);\n        });\n\n        socket.on('error', function (data) {\n            console.log('error in (' + process.pid + \"): \", data);\n        });\n\n    });\n}\n\n}\nnew Worker();\n```\nlogs:\n```\n/usr/local/bin/node /Users/ali/IdeaProjects/testSocketCluster/server.js\n     [Busy] Launching SocketCluster\n     !! The sc-hot-reboot plugin is watching for code changes in the /Users/ali/IdeaProjects/testSocketCluster directory\n     >> Broker PID: 36811\n     >> WorkerCluster PID: 36812\n     >> Worker PID: 36815\n     >> Worker PID: 36814\n     >> Worker PID: 36813\n     [Active] SocketCluster started\n                        Version: 14.3.3\n                        Environment: dev\n                        WebSocket engine: ws\n                        Port: 8000\n                        Master PID: 36810\n                        Worker count: 3\n                        Broker count: 1\n\n36813 is OK\n36814 is OK\n36815 is OK\n\n36813 is OK\n36814 is OK\n36815 is OK\nnew socket #gKs9p-evCfaxntJdAAAA connected in (36813)\n\n36813 is OK\n36814 is OK\n36815 is OK\n\n36814 is OK\n36813 is OK\n36815 is OK\n\n36813 is OK\n36814 is OK\n36815 is OK\nsocket #gKs9p-evCfaxntJdAAAA closed in (36813):  1006\n1552229441997 - Origin: Worker (PID 36813)\n     [Warning] SocketProtocolError: Socket hung up\n        at SCServerSocket._onSCClose (/Users/ali/IdeaProjects/testSocketCluster/node_modules/socketcluster-server/scserversocket.js:249:17)\n        at WebSocket. (/Users/ali/IdeaProjects/testSocketCluster/node_modules/socketcluster-server/scserversocket.js:80:10)\n        at WebSocket.emit (events.js:182:13)\n        at WebSocket.emitClose (/Users/ali/IdeaProjects/testSocketCluster/node_modules/socketcluster-server/node_modules/ws/lib/websocket.js:180:10)\n        at Socket.socketOnClose (/Users/ali/IdeaProjects/testSocketCluster/node_modules/socketcluster-server/node_modules/ws/lib/websocket.js:802:15)\n        at Socket.emit (events.js:182:13)\n        at TCP._handle.close (net.js:611:12)\nerror in (36813):  { SocketProtocolError: Socket hung up\n        at SCServerSocket._onSCClose (/Users/ali/IdeaProjects/testSocketCluster/node_modules/socketcluster-server/scserversocket.js:249:17)\n        at WebSocket. (/Users/ali/IdeaProjects/testSocketCluster/node_modules/socketcluster-server/scserversocket.js:80:10)\n        at WebSocket.emit (events.js:182:13)\n        at WebSocket.emitClose (/Users/ali/IdeaProjects/testSocketCluster/node_modules/socketcluster-server/node_modules/ws/lib/websocket.js:180:10)\n        at Socket.socketOnClose (/Users/ali/IdeaProjects/testSocketCluster/node_modules/socketcluster-server/node_modules/ws/lib/websocket.js:802:15)\n        at Socket.emit (events.js:182:13)\n        at TCP._handle.close (net.js:611:12)\n    name: 'SocketProtocolError',\n    message: 'Socket hung up',\n    code: 1006 }\nnew socket #Mao7kZuvI1RebUezAAAA connected in (36815)\n\n36815 is OK\n36813 is OK\n36814 is OK\n\n36814 is OK\n36815 is OK\n36813 is OK\n\n36814 is OK\n36815 is OK\n36813 is OK\n\n36815 is OK\n36814 is OK\n\n36814 is OK\n36815 is OK\n\n36815 is OK\n36814 is OK\n\n36815 is OK\n36814 is OK\n\n36815 is OK\n36814 is OK\n\n36815 is OK\n36814 is OK\n\n```\nI closed the client completely and reopened it. then this error occurred. \nAt first there are three workers but in the end, only two of them is OK (it seem process 36813 was crashed).\nthis error does not occur all times but most of the time I have this error. \n. ",
    "mnce92": "@happilymarrieddad you mean https://github.com/happilymarrieddad/vue-socketcluster ?\n. "
}