{
    "klokan": "The sample project files for MapBox Studio are available at:\nhttps://github.com/klokantech/vector-tiles-sample\nRendered MBTiles are downloadable at:\nhttps://github.com/klokantech/vector-tiles-sample/releases\nMapnik XML styles (for testing of the first version of VectorTileServer Docker #5):\nhttps://github.com/klokantech/vector-tiles-sample/blob/master/countries.tm2source/data.xml\nhttps://github.com/klokantech/vector-tiles-sample/blob/master/countries.tm2/project.xml\nThe sample vector tiles with a client-side rendering via MapBox GL JS viewer (as standalone) are at:\nhttp://klokantech.github.io/mapbox-gl-js-offline-example/\nhttps://github.com/klokantech/mapbox-gl-js-offline-example\n. TileMaker puts everything into RAM and does not use Mapnik to define the styles. So, it seems it will never be able to render whole world OSM planet and it would be hard to modify for custom Mapnik styles (only with coding in lua). I think this is not a good idea...\n. The FOSS4G presentation mentioned in #2 recommends on 15:10 time solution which is most straighforward probably for the first implementations.\nIf a single binary should be used then ideally something like: https://github.com/vross/vector-tiles-producer (as mentioned in #13)\n. Here was #28\nCompare with wikimedia style (powered by osm2pgsql)\n. Anybody looking on Google for the OSMBright TM2Source check our open-streets.tm2source at:\nhttps://github.com/geometalab/osm2vectortiles/\n. The implementation with tesssara exists now.\nLet's compare it with mod_renderd.\n. BTW we work on improved tessera: https://github.com/klokantech/tileserver-tessera/issues on docker hub at https://hub.docker.com/r/klokantech/tileserver-tessera/\nIt should be used on announcement of this project - will give people the same sample viewers (but with a new colors / branding for osm2vector tiles), static maps api, etc.\n. The #25 is duplicate to this ticket now. \n. Reopening and removing from FINAL milestone. This work is not fiinished, but is is not suppose to be done now.\n. This ticket is practically beeing implemented under:\nhttps://github.com/geofabrik/openstreetmap-carto-vector-tiles\nand related GL JSON style under:\nhttps://github.com/stirringhalo/openstreetmap-mapboxgl\n. The OSM-Bright2 repo uses OpenSans font, which is freely available:\nhttps://github.com/mapbox/mapbox-studio-osm-bright.tm2/blob/master/labels.mss#L21\nSo there is probably no need for change at all...\nBut the OSM-Brigth.tm2 on GitHub has been upgraded from mapbox-streets-v5 to mapbbox-streets-v6, with the upgrade from release v1.0 to v2.0. It seems the changes in the style are not huge: https://github.com/mapbox/mapbox-studio-osm-bright.tm2/commits/master\n. Duplicate for #13\n. Great!\nPlease include the relevant PostgreSQL tuning in the standard Dockerfile directly: https://github.com/geometalab/osm2vectortiles/tree/master/database/postgis\nWhat is the total size of the Postgres database now? It looks like less then 100GB?\nTotal import time seems to be cca 15 hours. That's fine - esp. if incremental updates are possible. What hardware has been used?\n. Please provide also the report of speed after rerun with Postgre tunning. \n. +1 to continue the sample rendering.\nWe should put an effort into improvement of the tile size.\nIt would be also interesting to compare the above mentioned big tiles with V6 - to identify why are our so large. It can be easily done with:\nhttp://klokantech.github.io/ol3-sandbox/vector/tile-inspector.html#http://a.tiles.mapbox.com/v4/mapbox.mapbox-streets-v6.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ|0|0|0\n. @lukasmartinelli please report here rough analytics data (total time or rendering, size trimmed by removing empty tiles, etc). \n. Another tool which may be helpful for us: http://lxbarth.com/compare/ & https://github.com/mapbox/compare\n. @petrsloup this is the discussed x-ray debug viewer.\nThe default colours are derived from names of layers: see https://github.com/mapbox/tilelive-vector/pull/51/files#diff-168726dbe96b3ce427e7fedce31bb0bcR543\n. The first version of the online debug-viewer is now implemented in OpenLayers3 - thanks @petrsloup\nThere are two tools, both accepting after a hash the url of a vector tileset TileJSON:\n- x-ray preview with possibility to turn on/off individual layers and with mouse hover study the values of features under the cursor.\n  See:\n  http://klokantech.github.io/ol3-sandbox/vector/xray.html#http://tileserver.maptiler.com/zurich.json\n- tile inspector: which allows to interactively pick a tile and extract relevant information such as the size in bytes, list of layers, number of features, classes, types, etc.\n  See:\n  http://klokantech.github.io/ol3-sandbox/vector/tile-inspector.html#http://tileserver.maptiler.com/zurich.json\nOn both tools, it is good to turn off the heaviest layers before you interact with the map, because most of the parsing/displaying is made on (blocking) CPU in OpenLayers without the hardware acceleration of MapBox GL JS - and our tiles are sometimes huge!\nTry it and comment.\n. Source code is of course available, feel free to fork, patch, make pull\nrequest:\nhttps://github.com/klokantech/ol3-sandbox\nOn Wednesday, 4 November 2015, Lukas Martinelli notifications@github.com\nwrote:\n\nThis is amazing. Huge thanks to @petrsloup https://github.com/petrsloup.\nEspecially the tile inspector will be a big help at this stage. We will\nuse this to take closer look at the Mapbox layers too see which layers are\nvisible where and how many are shown (a visual approach to our tile\ncomparing).\nThe X-Ray preview has similar features to Mapbox Studio Debug Viewer but\nmore practical to use because it shows the values on hover and we don't\nhave to always try to click on tiny elements.\nIs the source also available so we can look at it / contribute?\nIf not it is not that bad because we can just modify the source of the\npage and point it to Mapbox Streets.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/geometalab/osm2vectortiles/issues/12#issuecomment-153595605\n.\n\n\nPetr Pridal, Ph.D.\nCEO\nKlokan Technologies GmbH\nHofnerstrasse 98, 6314 Unterageri, Switzerland\nTel: +41 (0)41 511 26 12\nEmail: info@klokantech.com\nWeb: http://www.klokantech.com/\n. The TileJSON for V5 and V6 are mentioned at: https://github.com/geometalab/osm2vectortiles/issues/25#issuecomment-151569602\nThis viewer had to be changed from JSONP to XHR/AJAX to support MapBox TileJSON hosting.\nWe have added also permalink lat/lon/zoomlevel functionality for easier linking to a certain place - if we discuss in future one particular tile.\nClosing this ticket. Your improvements and contributions to the Debug Viewer are welcome via pull request.\n. One more, which looks promising, is developed by people around Wikipedia Maps Tile Server.\nSee and test:\nhttps://www.mediawiki.org/wiki/Maps/Tile_server_implementation\nhttps://github.com/wikimedia/maps-tilerator\nhttps://github.com/kartotherian/kartotherian\nsee:\nhttps://www.mediawiki.org/wiki/Maps\nhttps://maps.wikimedia.org/\n. Improved documentation for usage on a small OSM planet dumps (cities extracts, etc) without the cluster is necessary...\nThis especially for export docker running on local machine directly #80 \n. Correct. We have just fixed the vector tile opening via TileJSON from tileserver-mapnik into MapBox Studio Classic, ensured that OGC WMTS runs in QGIS and the whole docker is usable also behind on HTTPS.\n. Yes. See: https://github.com/klokantech/tileserver-mapnik/issues/8\n. +1\nLower priority, FINAL milestone. If time allows...\nBTW Do we know how exactly Wikimedia's kartoherian detects the dirty tiles?\n. WikiMedia uses osm2pgsql expiry list method:\nSee: https://wiki.openstreetmap.org/wiki/Tile_expire_methods\nThe OmniScale has some private scripts for detecting dirty tiles (which they use together with imposm3).\nSome people use: Matt's ruby scripts: http://svn.openstreetmap.org/applications/utils/export/tile_expiry/\nIt would make sense to somehow reuse the information from the mapnik data tiles for the expiry.\n. Reopening - and removing from FINAL milestone.\n. BTW OpenLayers V3 project has basic styling for MapBox Streets done now:\nhttp://ahocevar.net/ol3/vectortile/examples/mapbox-vector-tiles.html\n(backup: https://gist.github.com/klokan/5f7bedff2597e3576bbd)\nThe example of offline use of MapBox GL JS without a need for their API key is at:\nhttps://github.com/klokantech/mapbox-gl-js-offline-example\nhttps://klokantech.github.io/mapbox-gl-js-offline-example/\nIf our vector tiles MBTiles are compatible with MapBox Streets (which I hope will be true), then any of the above mentioned MapBox styles could be used directly.\n. First sample:\nhttp://tileserver.maptiler.com/zurich/bright-v7.html\n. Example with latest MapBox GL JS and our own MBTiles:\nhttp://tileserver.maptiler.com/zurich/bright-v8.html\n. I have pushed online the world Open-Streets down to zoomlevel 10. See: http://osm.tileserver.com/open-streets-z10.json (for MapBox Studio) and with WebGL viewer at: http://osm.tileserver.com/open-streets/bright-v8.html\nWe need to clean the upper zoom levels as well probably, the OSM Bright v5 does not show watter - and tiles seems to be quite big. Still wonder if it would not make sense to go for v6 compatibility in upper zoom levels...\n. Our latest Open Streets MBTiles:\nhttp://osm.tileserver.com/open-streets/bright-v8ch.html#13.41/47.2195/8.8220/-11.3\ncould be compared to MapBox GL JS Bright with:\nMapBox Streets V5:\nhttp://osm.tileserver.com/open-streets/bright-v8v5.html#13.41/47.2195/8.8220/-11.3\nMapBox Streets V6: \nhttp://osm.tileserver.com/open-streets/bright-v8v6.html#13.41/47.2195/8.8220/-11.3\nImprovements of the WebGL rendering tracked now under #71\n. +1\n. It seems we target compatibility with MapBox Streets V5 with max zoom level 14 - see comments in #11 in the first implementation of the tm2source.\nPublic specification is at:\nhttps://www.mapbox.com/developers/vector-tiles/mapbox-streets-v5/\nIf you want to to ensure compatibility you can write tests which downloads some sample tiles from MapBox Streets V5 example (or store them in our Github), and compare output of tileinfo command (or similar) between the two implementations... to ensure these are the same whenever possible.\n. The decision if v5 or v6 compatibility was for me mostly about being able to render and store 4^15 more tiles (each level has 4x more then previous - so instead of 325 million it is over 1.3 billion tiles -with theoretically only 30% land, but still). It means for sure an MBTiles with hunderds+ GByte size. This starts to be even a problem to host on an ordinary linux VPS.\nThis does not sound realistic for this project. I am sure we should target max zoom 14.\nV6 was redesigned primarily for MapBox GL JS - and new MapBox Studio (not open-source anymore? and not available right now) - it is the future, even MapBox is not yet there...\nV5 is used in all existing Mapnik styles in MapBox Studio Classic now - probably to be deprecated soon - but this is what is used now for the server side rendering with mapnik.\nBy reading the changelog - they seems to mention localrank as important feature on more condensed tiles. I wonder if we are able to prepare it in SQL queries?\nPerfect V6 compatibility would be amazing result - but we are probably not able to finish it (with z15 tiles).\nIf we go for V6 which stops at z14 - the visual MapBox styles for v6 would still need to be modified, right?\nI would primarily target 100% v5 compatibility.\nWe may introduce some back-compatible GL JS improvements (like elevating some of the features to smaller zoom levels) if required.\n. I was just thinking about the same renaming of osm-bright-2.tm2source in the repo...\nopen-streets-v5 sounds good and allow us to work later on v6, if required.\nThe v5 is MapBox specific, but it will make it easy for people to recognise which existing styles they should use...\n. TileJSON:\nhttp://a.tiles.mapbox.com/v4/mapbox.mapbox-streets-v5.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ\nPreview:\nhttp://a.tiles.mapbox.com/v4/mapbox.mapbox-streets-v5/page.html?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ#0/0/0\nvs our sample:\nhttp://tileserver.maptiler.com/zurich.json\n. For developing the open-streets.tm2source style you will need to get the vector tile of choice after every edit you make... In such case it is easiest to open MapBox Studio Classic, open the source style, then pick the URL of a tile:\n\nFor example:\nhttp://localhost:3000/source/6/33/22.png?id=tmsource:///Users/klokan/Documents/MapBox/project/countries.tm2source&ifzmgklw\nand replace format of the request to:\nhttp://localhost:3000/source/6/33/22.vector.pbf?id=tmsource:///Users/klokan/Documents/MapBox/project/countries.tm2source&ifzmgklw\nThis way you can iteratively improve the tm2style without generating the MBTiles by our export worker.\nWhat you described above is true for the CI tests (Travis).\n. For a picked tile you need to be able to compare included:\n- list of layers and their names (landuse)\n- in each layer the available features, their attributes and values of attributes (name_en=\"Zurich\")\nComparing can be done either by a custom written JavaScript code as you propose, or by making a dump with defined formatting and using \"diff\". In both cases - we need to be able to print out on command line the differences - so these can be checked by Travis at later point.\nIt is important to get an output which helps you to add the missing layers into the .tm2source.\nNo output means you are done for this tile and you can continue a different one (on a different zoom level for example).\nI would like to mention here - that our target is not an exact copy of MapBox Streets.\nYou may identify layers of information of lower importance for our project - or come up with improvements. We study what they did and how they did it, learn from their excellent work and are keen to produce an open and free representation of OpenStreetMap data available under ODbL license - which is our own result. The primary target for us are free vector tiles running with the BSD licensed OSM Bright TM2 style.\n. Could you please make the output more clear, it is a mess now, use hierarchy with spaces/tabs, line oriented output:\n[layer]\n    [class]\n        [type]\nBefore printing out, please order the names in given block alphabetically, so that it is really comparable semantically. Complete example could look like:\n```\nname: open-streets\ntile: 10/4141/5356\nfeatures: 5000\nlayers: 10\nclasses: 20\ntypes: 1000\nlanduse\n    agriculture\n        allotments\n        farm\n    ... /structure alphabetically ordered\n```\nDon't put this into drive. It is for big binary files primarily.\nGist or a separate github repo (for example) makes better storage for online preview - with online diffs automatically - on the revisions of files.\nSave mapbox-streets and rewrite it with open-streets.\nSample:\nhttps://gist.github.com/klokan/8b46f63a3b773416098f/revisions?diff=split\nLocally, on your computer you can use vimdiff or other editors to see the diff between files directly.\nTips:\n- care in first case about structure (names of layers, names of classes, names of types). What is in MapBox should be in Open as well.\n- smaller tile is better tile - if we have everything what is necessary\n- in case you already now know about features in Carto which would be missing - add them. But Carto is secondary for us, as there is no .tm2 for it now.\n- start with upper levels (smaller zoom numbers)\n- be as systematic as possible, document what you do and why (clear commits, forks, etc).\nPlease make diffs also with mapbox-streets-v6 to get overview of the changes (diff with v5 and existing open).\n. BTW If there is many more information - why at http://tileserver.maptiler.com/zurich/bright-v8.html there are no streets names and no POIs when zoomed-in?\nI would start with adding missing things. Tweaking the zoom levels on which things appear.\nDeleting and cleaning can be done in the next step...\n. @manuelroth cool thanks.\nBTW A gist can have multiple files (sample tiles for all different zoomlevels), instead of one gist for one tile! But anyway...\nbest would be to create a repo and have a branch for mapbox-streets-v5 with all tiles, another branch for mapbox-streets-v6 and another for open-streets-2015-10-23. Later versions, as we improve the styles, may have separate branches. In GitHub you can easily compare any two branches of choice...\nI miss list of attributes of features (\"name_en\", ...).\n. Superb @manuelroth !\n- v5 vs v6: \n  https://github.com/geometalab/comparevectortiles/compare/mapbox-streets-v5...mapbox-streets-v6\n- open vs v5:\n  https://github.com/geometalab/comparevectortiles/compare/mapbox-streets-v5...open-streets-2015-10-24\n- open vs v6:\n  https://github.com/geometalab/comparevectortiles/compare/mapbox-streets-v6...open-streets-2015-10-24\n. Vector tiles - difference between mapbox-streets-v5 vs mapbox-streets-v6: \nhttp://osm.tileserver.com/open-streets/bright-v8v5.html\nhttp://osm.tileserver.com/open-streets/bright-v8v6.html\n. Attributes can be added into diffs per layer probably, right?\nBTW in CartoCSS typically the layers names are mentioned with prefix # such as #landuse and attributes are in brackets so [name] - maybe we can have the same notation used in the tile log output and diffs? Some of the attributes are in all layers (such as [name], or [osm-id]) but some are specific to a layer - in such case we can write these after layer names - with indentation equal to a class?\n. @manuelroth - we agreed yesterday, that by the end of this week you will have:\n- [x] updated exports of diffs with different alphabetically sorted [attributes] under #layers.\n- [x] tm2source for zoom level 14 (at this zoomlevel only the layers required for OSM Bright 2 in latest MapBox Studio Classic). It means tiles on z14 - z19 will look the same with open-streets as with mapbox-streets source.\n- [x] from the sample area (possibly Zurich from http://download.bbbike.org/osm/bbbike/Zuerich/, if it has the lake?) you save on your computer with MapBox Studio a vector MBTiles file so that we can test the zooming against Mapnik and MapBox GL JS on weekend.  \nFirst step of work on z14 implementation is probably to identify layers we need there (used in OSM Bright MapBox Studio CartoCSS) - please write a list of the layers first (here or in a new ticket for \"z14\" on https://github.com/geometalab/open-streets.tm2source) - and track progress on which you have implemented and which are still missing. OK?\nIt is surprising on the diffs that Mapbox Streets V6 has on z14+z15 together smaller amount of features then V5 on z14 alone. Smaller amount of features in open-streets is a good thing, if we have all geodata required for OSM Bright 2 style (at least now).\n. BTW The complete layer names, with attributes are also printed out in TileJson under \"vector_layers\" field:\nhttp://a.tiles.mapbox.com/v4/mapbox.mapbox-streets-v5.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ\nhttp://a.tiles.mapbox.com/v4/mapbox.mapbox-streets-v6.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ\n. BTW The vector tiles of Switzerland z8-z14 with our latest styles has ~350 MB - thanks @lukasmartinelli:\nhttp://osm.tileserver.com/open-streets/bright-v8ch.html\nhttp://osm.tileserver.com/switzerland-z14.json\n. Top priority is having minimal tiles for OSM Bright 2 style, not a perfect compatibility with V5 or V6. Removing stuff is indeed important - every byte in a tile counts - because it is multiplied by 300 millions tiles ;-).\nWhen last time speaking to @manuelroth - I mentioned:\n\nIt is surprising on the diffs that Mapbox Streets V6 has on z14+z15 together smaller amount of features then V5 on z14 alone. Smaller amount of features in open-streets is a good thing, if we have all geodata required for OSM Bright 2 style (at least now).\n\nand\n\n\nsmaller tile is better tile - if we have everything what is necessary\n. While doing early testing we have realized some of the vector tiles on z5-z6 has now over 20MBytes (one tile!) in open-streets.tm2source. Cleaning is absolutely essential, such a tile kills Chrome browser when parsed in JavaScript! [comment moved here]\n. What is the status of z14?\nDuring the weekend I expected a sample from @manuelroth - when is it going to be delivered?\nI would like to replace online zurich or switzerland tilesets with the latest version we have...\n. Great! Thanks @manuelroth. Updated: http://osm.tileserver.com/open-streets/bright-v8ch.html\n\n\n@lukasmartinelli feel free to use already the new Cloud infrastructure for the test rendering.\n. Our latest Open Streets MBTiles:\nhttp://osm.tileserver.com/open-streets/bright-v8ch.html#13.41/47.2195/8.8220/-11.3\ncould be compared to MapBox GL JS Bright with:\nMapBox Streets V5:\nhttp://osm.tileserver.com/open-streets/bright-v8v5.html#13.41/47.2195/8.8220/-11.3\nMapBox Streets V6: \nhttp://osm.tileserver.com/open-streets/bright-v8v6.html#13.41/47.2195/8.8220/-11.3\n. Natural Earth data integration for ranks is in #46 \n. The MapBox Streets example shows that two layer names can be combined with comma:\nhttps://b.tiles.mapbox.com/v4/mapbox.mapbox-terrain-v2,mapbox.mapbox-streets-v6/10/299/386.vector.pbf?access_token=pk.eyJ1IjoibWFwYm94IiwiYSI6IlhHVkZmaW8ifQ.hAMX5hSW-QnTeRCMAy9A8Q\nTileJSON is modified as well:\nhttps://b.tiles.mapbox.com/v4/mapbox.mapbox-terrain-v2,mapbox.mapbox-streets-v6.json?access_token=pk.eyJ1IjoibWFwYm94IiwiYSI6IlhHVkZmaW8ifQ.hAMX5hSW-QnTeRCMAy9A8Q\nThis can be trivially implemented in TileServer-PHP, because vector tiles are designed in a way which supports merging by direct binary concatenation...\n. Note: In case the XML would be required from a C/C++ binding this is the function for conversion:\nhttps://github.com/mojodna/tilelive-tmsource/blob/master/index.js#L143\n. I like the imposm3 more and more as well. OmniScale guys do a good job on the tool it seems. It has a database designed for fast access and tile rendering.\nMy +1 on choosing it.\nIt means we go with our own forked tm2source (which was expected in the beginning of the project).\nThe efficient and complete definition of the data style seems to be the most critical point of the whole project. Inspiration from Wikimedia layers is welcome.\nGood point about the stored queries, but it means there will be extra SQL dump with saved queries which we need to distribute together with our tm2source and executed on PostgreSQL before we let Mapnik/Tilelive to read the datastyle.\n. My notes to the ideas:\nparallelisation\nAgree on horizontal scaling. We may probably need to prepare a virtual machine image (what is in docker + the preprocessed PostGIS data) so each machine has it's own copy of complete database - to ensure PostGIS is not the bottleneck. The partitioning with metapyramid makes sense esp. on lower zoom-levels. Upper zoomlevels (z0 to z8 for example) may be done in a single task quite easily.\nHaving perfect datastyle in #25 quite soon is critical - any change later on implies need to re-render all the tiles again!\nBETA has as a deliverable MBTiles of Switzerland #9 - ideally done the way we want to do the world as well later on. It is a great test for the parallelisation.\nOK about the multiple MBTiles as results. Maybe ATTACH command can be used in SQLite3 to virtually merge multiple SQLite files together - for testing or even copying to a different final file in post-processing.\nz14 required:\nThere is a limit of 500KB per tile defined by MapBox Studio - larger tiles may be refused (probably for a good reason). I am afraid z14 is required - even there it may be challenging to fit all the information and manage the less then 500 KB condition.\nFor our datastyle is probably easiest is to reverse-engineer the MapBox and follow 1:1 what they did.\nMapBox Streets V5 has max z14 - let's target compatibility with V5 in #25\nMapBox Streets V6 has max  z15\nempty tiles\nTo eliminate the need for empty ocean tiles check: \"maskLevel tiles\" at https://github.com/mapbox/tilelive-vector\n. @sfkeller are these reported issues documented somewhere, or is it a bug of imposm tracked under some ticket? Is the problem related to imposm3 which is used here or to an old version of imposm?\n@lukasmartinelli I really like the idea of having vector tileset truly compatible with MB Streets as it gives a lot of practical benefits...\nI wonder why wikimedia people in kartotherian project uses osm2pgsql?\nHave you been in touch with them?\nAfter @lukasmartinelli tests the Kartotherian workflow #28 we may need to make the definitive decision if imposm3 or osm2pgsql, and if to commit to our own improved tm2source with all (almost) unmodified visual styles (both Mapnik and GL) or wikipedia's tm2source with only single style now (fork of OSM-Bright).\nIf the diff updates runs fine with imposm3 - then it seems to me that there are benefits.\nImposm3 was also used in the Alpha milestone.\nIf imposm3 is confirmed, then @manuelroth (?) should probably start to work actively on improvements of the tm2source and compatibility with MapBox Streets as defined in #25 to be finished for BETA milestone (by November 16th latest). \n. @sfkeller could you please provide a link to a report which mentions the difference in tags interpretation causing the recognision of less buildings during the import - to have a real example to look for in the OSM data?\nSo far everything speaks for imposm3.\n. Nice. A very good idea to apply xray in case another style is not available...\nThe #12 was about MapBox GL JS viewer (client side) - you have made here mapnik x-ray (server side).\nLet's discuss #12 on Monday.\n. It is visually appealing when done on raster tiles...\nIt makes much more sense to make the diffs on the vector tiles, because on raster you don't see half of the information and structure.\nThe diffs (ideally as tests in Travis) were proposed in https://github.com/geometalab/osm2vectortiles/issues/25#issuecomment-147366671\nWe need to compare structure and information included in the sample of vector tiles.\nEach vector tile can be dumped into JSON or other textual format - so diffs are then easier and more meaningful (but maybe not that visual appealing as your raster diffs). Dump does not need to contain shapes of the vectors - but all the structural metadata (layers, features, and values inside of the features).\nIn #25 was suggested to use the C++ \"tileinfo\" utility, but if you are not capable of compiling, feel free to use another parser (https://github.com/mapbox/awesome-vector-tiles#parsers--generators) in JavaScript or Python, ...\nThe purpose of the suggested debug viewer #12 made purely in JavaScript GL was exactly the visual tool  for exploring and comparing of the information present in the whole dataset (layers from TileJSON), and features in individual tiles (picking by tile or picking by feature) - without extra styling.\nA tool which helps to visually see the differences between open-streets-v5 and mapbox-streets-v5 - or later on open-streets-v6 and mapbox-streets-v6.\n. BTW a similar raster verification is used in CI of OpenLayers (ol3) - for testing client side rendering differences between WebGL renderer and HTML Canvas renderer. You can check the Travis of OL3.\n. Check: \"maskLevel tiles\" at https://github.com/mapbox/tilelive-vector\nIt seems it is enough to set on the source a maskLevel attribute and tilelive-vector will ignore any empty tiles bellow that zoom level (and such tiles does not need to be present inside of the MBTiles).\n. If done this way, then it must run on non-generalised land polygons and we must really trust these land polygons...\n- Does such decision happen only on the top tile of a job - so it enforces our maskLevel to be relevant to the top level of parallel job metapyramids?\n- It also brings dependency on postgresql to enqueue-job :-(.\nI wonder if it would not be better to run this test inside of the export job? There we have postgresql anyway, we could make the test on a zoom level defined in advance (docker's sysenv MASKLEVEL +1?) or the minzoom of the job, whatever is max, and set the job independently of the top level zoom of the job metapyramid. It would also allow non-paralelised rendering on a single docker instance to ignore the water tiles bellow maskLevel... Isn't it more elegant?\nI wonder if there is a point and title \"Atlantic ocean\", we will ignore it. Question is if this is an issue visually for zooms deeper then maskLevel. Probably not. We could check on MapBox tiles how they do that...\nOther approach would be to decide based on the bytesize / md5 or number of layers of a produced vector tile - so if an empty vector is detected, cancel all rendering bellow this particular tile in the renderer export process. But this approach is dangerous because it is very style dependant. I like to land polygon overlap more.\nBTW It seems the vector MBTiles produced by tilelive supports the internal symlinks. If you look inside with sqlite3 the tiles table is just a view for images - where the real .pbf blobs are stored.\nThis is normally used to store an empty PNG tile blob just once and use the same tile_id on multiple XYZ positions. This needs to be handled in the merge phase - and will be probably used for upper zoom levels (up from maskLevel) automatically by tilelive?\nsql\n$ sqlite3 zurich.mbtiles\nsqlite> .tables\ngeocoder_data  grid_key       grids          keymap         metadata\ngrid_data      grid_utfgrid   images         map            tiles\nsqlite> .schema tiles\nCREATE VIEW tiles AS\n    SELECT\n        map.zoom_level AS zoom_level,\n        map.tile_column AS tile_column,\n        map.tile_row AS tile_row,\n        images.tile_data AS tile_data\n    FROM map\n    JOIN images ON images.tile_id = map.tile_id;\nsqlite> .schema map\nCREATE TABLE map (\n   zoom_level INTEGER,\n   tile_column INTEGER,\n   tile_row INTEGER,\n   tile_id TEXT,\n   grid_id TEXT\n);\nsqlite> .schema images\nCREATE TABLE images (\n    tile_data blob,\n    tile_id text\n);\n. I still strongly believe the decisions should be done inside of export docker, not in the enqueue-jobs as you suggested...\n. BTW Both mapbox-streets v5 and v6 has maskLevel: 8 defined in TileJSON (see: https://github.com/geometalab/osm2vectortiles/issues/25#issuecomment-151569602)\nWe should target the same one...\n. MapBox hosting serves the water tiles for deep water zoom - these contains the 'water' layer with 'osm-id' at z14:\nhttps://b.tiles.mapbox.com/v4/mapbox.mapbox-streets-v6/14/8146/11773.vector.pbf?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ\nbut the tile is exactly the same (binary identical) as when deep zoomed-in to z20:\nhttps://b.tiles.mapbox.com/v4/mapbox.mapbox-streets-v6/20/521375/753503.vector.pbf?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ\nsurprisingly the tile at maskLevel=8 so z8:\nhttps://b.tiles.mapbox.com/v4/mapbox.mapbox-streets-v6/8/127/183.vector.pbf?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ\ndiffers from z14 above or from z9 in the binary form:\nhttps://b.tiles.mapbox.com/v4/mapbox.mapbox-streets-v6/9/254/366.vector.pbf?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ\nWould be interesting to see the dumps of these tiles (how they differ) - another practical use-case for #12, if we would have it...\n. It has surprised me as well. I expected z8 to be rendered - and bellow all levels either equal to z8 or at least equal to z9.\n+1 on testing the maskLevel in mapnik/tilelive/tessara.\nWe may need to adjust tileserver-php as well to provide the right \"empty\" tile for pbf requests... https://github.com/klokantech/tileserver-php/issues/56\n. @lukasmartinelli could you please prepare me an valid empty tile with no feature?\nI will include it into tileserver.php.\n. Thanks! So maskLevel runs as expected - despite the test above on MapBox hosting.\nIt seems the only test on water tiles is to construct an SQL test query for region in question and all tables which potentially may provide something to the tiles on deeper zoomlevels. If such query tells there is nothing bellow - skip all related sub pyramid.\nBTW I hope we manage the world under 32 GB - to fit on a USB stick ;-).\n. I am OK with this dummy but universal approach.\nWe will render a lot of data which we later on throw away... :-(\n. Agreed today that parallelisation will use the Pull Queue as the central point of the task scheduling.\nImportTasker creates and pushes (in batches) into an online queue all the tasks which needs to be done (task description to be JSON - defining the metapyramid).\nIndividual machines with the export docker container and complete PostGIS data will ask queue for a lease for certain time (time to finish the single assigned task, 5 hours?) and will do the processing on assigned task individually.\nOnce they are finished they upload the results to a central storage (S3 / GCS), mark the task as finished (delete from queue) and ask for another task, until the queue is empty.\nIf a node dies or is not able to finish the task, after the timeout the task is assigned to a different cluster node.\nThis approach allows to run a docker container anywhere possible and scale the cluster up and down (friends can help this project with rendering for example). The complete OSM PostGIS with planet must run on each cluster node separately (over 200 GB data on a local disk and quite a lot of RAM required on each node).\nIt will also allow to use cheaper Preemptible / Spot Instances in the cloud ( https://cloud.google.com/compute/docs/instances/preemptible or https://aws.amazon.com/ec2/spot/pricing/)\nDocs:\nhttp://boto.readthedocs.org/en/latest/sqs_tut.html\nhttps://cloud.google.com/appengine/docs/python/taskqueue/overview-pull\nhttps://github.com/john2x/gtaskqueue_sample\n. I suggested @manuelroth start to work on styles of z14 of OSM-Bright and later continue to z13, etc. The tm2source should be developed from bottom zoomlevels up - for OSM-Bright-2 compatibility as the main target.\nThe reasons:\n- Deeper zoom levels are strictly based only on OSM data, and does not need ranks\n- Upper zoom levels in contrary needs information from Natural Earth Data such as ranks - see #46\n- Most of the tiles are in z14 - and rendering whole z14 later on would take much more time then any other layer.\nI did not really think about changing the approach of rendering tasks and sub-pyramids - and I believe ideal performance may be on render of z11,z12,z13,z14 in one task.\nBetter then to start to work on tm2source from z11 or even upper zoom level is to start from bottom.\nIt is easy to re-render upper zoom-levels (even for the whole world), but hard to render planet on deep zoom levels, and we should start to render soon...\n. That's correct.\nIt means you need styles for z8-z14, z9-z14 or z10-z14. The priority on tm2source implementation is therefore on the deepest zoom levels first...\nOur upper zoom levels are pretty messy still - but we can clean the mess #46 after the deeper zoomlevels are finished - as re-rendering world z0-z9 is much easier then re-rendering z10-14.\n. Superb! We are on track to finish this project successfully!\n\nOne single MBTiles at z8 only containing water is 400KB.\n\nWhy? This is wrong - a bug! A similar tile with 1 layer, 1 feature (ocean) has at MapBox 58 Bytes.\nIf a layer has no features, it should not be present in the vector tiles.\n. Duplicate to #43 \n. The \"import\" and \"export\" folder for the data accessed by docker are gone? Pity.\nI hoped that the main docker-compose run image names are going to be import and export - same as the directories for the data people need to interact with. Now we have worker instead of export...\n. If you have a clear vision about this restructuring then explain it please.\nIn this moment the names of the paragraphs in main README.md, the diagrams and mentioned folders speaks about import and export (which is quite straightforward and understandable).\nEither adjust the structure of the code or change README.md, please.\n. The relevant code for enrichment of cities with scalerank - to run on OSM data imported with imposm:\nhttps://github.com/mapbox/osm-place-ranks\n. Country labels with scalerank and labelrank for upper zoom levels could be possibly taken from:\nhttps://github.com/mapbox/natural-earth-tm2/blob/master/natural-earth.tm2source/data.yml#L355\n. We probably don't need to merge natural-earth into osm database for our vector tiles. We can have two separated databases in Postgres - and the .tm2source style could query both.\nThis approach is used in Mapzen Vector Tiles (see https://github.com/mapzen/vector-datasource/blob/master/queries/landuse.jinja2) and was used in early MapBox Streets.\n@lukasmartinelli could you please reply on:\n\nIt seems that https://maps.wikimedia.org/ #28 are not using the Natural Earth data at all ... right? Do we have any comments from them on this point?\n. @lukasmartinelli application of https://github.com/mapbox/osm-place-ranks for places looks pretty straightforward.\nWhere would it fit into our import process?\nShall this run always in the import container?\n. - [ ] rank-places osm planet update\n\nAre you sure this should be a separate step?\nThey write:\n\nThese can be from a full planet dump, a regional extract...\n\nIt must run just after (or together with) an planet import - because it is modifying the imposm's osm_places table. The ne_cities table is only a temporary table  - and probably does not need to be used in our tm2source directly. Maybe it is not even required once you run the rank-places.py, and could be then removed from postgres...\n- [ ] natural_earth\nBut we will need a separate docker import_natural_earth which will import into postgres the \"natural_earth\" database - see ./util/setup_db.sh from https://github.com/mapbox/natural-earth-tm2. This should be quite straight forward and it does for sure belongs to a separate docker.\nCould you please look into these two things?\n. OK. Thanks.\nBTW I think it is not dependent on the natural earth data at all - is uses only a single .sql file included in the repo: ne_cities.sql - so points 1. and 2. are not true IMHO.\nAnyway - we will need both points mentioned above for the scalerank to appear in the vector tiles... THX!\n. Perhaps we could use the OSM-ID to NaturalEarthData linking which KlokanTech has made about two years ago for GeoSEO applications: http://www.mapranksearch.com/geoseo/ - it would be 12092 records (for ne_10m_geography_regions, ne_10m_admin_0_countries, ne_10m_admin_0_map_subunits, ne_10m_admin_1_states_provinces, ne_10m_populated_places) with a structure like:\n[ne_title VARCHAR, type_id VARCHAR, osm_id VARCHAR]\nFor example:\nZ\u00fcrich|10m_cultural/ne_10m_populated_places.shp:7161|relation/1682248\nfor http://www.openstreetmap.org/relation/1682248\nCould you please check if it would be helpful enough for binding the ranks to OSM-IDs?\nWith KlokanTech data we would need to find the right records in the appropriate ne_ tables by their ne_title - to find the scalerank / labelrank.\n. Could you please try the latest OSM Bright 2 from GitHub in the MapBox Studio Classic - the one which is using Streets V6? I tend recently to be more V6 compatible then V5 on upper zoom levels - whenever possible. See #71 \n. If I remember well labelrank in Natural Earth is if you want to reduce number of labels displayed (typically show smaller number of labels on the map) while scalerank is about importance of the features  - if it is more important then others then you can use bigger font or display it on upper zoom levels then other features.\n. +1. This is fine.\nWe may move the open-streets.tm2source into https://github.com/geometalab/open-streets.tm2source\n. Regarding the split to two repos decide together with @manuelroth. I don't care that much... the pros/cons are mentioned.\nIf it is in single repo - the tm2source should be in the root probably - as all other things in /src/ are Docker containers. The open-streets.tm2source is quite different the everything else in /src.\nShould the travis tests run on style update or it should run on Dockerfiles updates? Now it is on both...\nWhile you work on your thesis, there should be a single place for issues and milestones.\nIf we go for single repo, we should probably git push the diff branches such as mapbox-streets-v5 or mapbox-streets-v6 into this repo (maybe as 'diff/mapbox-streets-v5'?) and remove the other repo completely? It makes no sense to have a repo only for diffs... It is helpful to have online preview like:\ngeometalab/comparevectortiles@mapbox-streets-v5...mapbox-streets-v6\n(but this could be also generated into HTML and saved into gh-pages, with something like http://technogems.blogspot.ch/2011/09/generate-side-by-side-diffs-in-html.html - the question is how much time to spend with this, we need some clear visualisation, and github diffs are almost perfect and done now).\nNone of these things are extremely important for the final result of the project.\nIt should be just easy to use for people, documented and it should make sense in usage.\nI like if people can use tileserver easily from Kitematic. The import/export deps managed by docker compose are perfect.\nSome ideas (refuse or accept as you wish):\n- Shall we unify the names of dockers to verb-based? \"verify\" instead of \"verifier\", or \"serve\" instead of \"tileserver\", \"import\", \"export\", etc.?\n- This would give water -> import-water?\n- Or gatling maybe test-performance?\n- Not sure about scheduler (despite the fact I suggested it) - it is not really scheduling...\n. +1\nPlease proceed.\nOn the repo osm2vectortiles may be set also docker hub webhook - to update the images of containers (which don't need rebuild in case of change of the style).\n. > Regarding the split to two repos decide together with @manuelroth. I don't care that much... the pros/cons are mentioned.\n. Done in #69 \n. Great news on the academic Switch download hosting possibility...\nI guess suitable project name for HSR-IT would be: osm2vectortiles\n. @sfkeller could you please report what is the status of the hosting possibility on HSR?\n. SWITCHengines is the Amazon AWS for Swiss Academia (powered by OpenStack) - this would be great to have access to indeed - especially for the EC2 equivalent (compute machines). If we get there a virtual machine it is great...\nFor the \"download hosting\" the simplest would be probably just a public bucket in SWITCHEngines for storing ~100-150 GB data:  https://help.switch.ch/engines/documentation/s3-like-object-storage/ (which is OpenStack Swift I guess).\n. Great - this sounds great. I can get the file download https://osm2vectortiles.os.zhdk.cloud.switch.ch/Wolken.jpg directly.\nIs CNAME supported (so pointing downloads.osm2vectortiles.org to osm2vectortiles.os.zhdk.cloud.switch.ch) to use it instead?\nI am really keen to get my Switchengines account as well, if possible - so that I can see their system...\n. Aha, it seems you have just deleted the Wolken.jpg file ;-)\n. I don't see a real reason to make this test. The bucket is required for downloading individual large .mbtiles.\nTechnically hosting of vector tiles this way is possible - but it makes not much sense for the world - (upload would take an year probably) - for Zurich or smaller are you can do that of course, but you can do that on github too. The hosting should support CORS. See: countries folder in https://github.com/klokantech/mapbox-gl-js-offline-example ...\n. All of the above are perfect news!\nVector tiles uploaded to Drive for backup - it took less then 30 minutes from our server!\n@lukasmartinelli I have recommended you rclone utility for working with Drive in the past.\n. Hosting is done on SWITCH S3.\nExtracts to be done in #88\n. The latest https://github.com/mapbox/mapbox-studio-osm-bright.tm2 and a few others .tm2 on MapBox GitHub are already powered by V6.\nWe could indeed visually try these - and of course test against the MapBox GL JSON styles available in https://github.com/mapbox/mapbox-gl-styles and latest MapBox Studio.\n. Latest Switzerland z14: http://osm.tileserver.com/open-streets/bright-v8ch.html#8/46.800/8.800\nLatest World z7 to http://osm.tileserver.com/open-streets/bright-v8world.html#3.92/41.73/1.87\nBoth looks quite OK.\nHave you checked the size of biggest tiles on the latest version?\n. Compare our tiles (and their size) to V6 - to be done in #77\n. If we find a serious problem let's reopen or create a new ticket.\n. @manuelroth tried http://electron.atom.io/ successfully. Could you please push it to GitHub?\n. I tried - it was running fine on Mac. The server stopped after some time unfortunately.\nWe need to wrap the whole app in installer and finish this task.\n. Is MapBox Studio build with Electron? If it is, you can get from them automated build scripts (probably for appveyor.com - the CI a la Travis for windows apps) or even extract the binaries from existing MapBox Studio package and reuse these with the same version of environment as they use...\n. Preferred would be to have our own repo with autobuild in AppVeyor of course...\nRelated: https://github.com/atom/electron/issues/533\n. Compilation of MapBox studio is made in:\nhttps://github.com/mapbox/mapbox-studio-classic/blob/mb-pages/.travis.yml\nand\nhttps://github.com/mapbox/mapbox-studio-classic/blob/mb-pages/scripts/build-atom.sh\n. Another approach would be to create a basic QT application with binaries for different platforms which would use https://github.com/tmpsantos/qmapboxgl and render the vector tiles offline directly from the USB disk with OpenGL. We can try this approach at @klokantech.\n. Advantage of going with QT is guarantee that OpenGL will run on all platforms. This is hard to get with embedded WebKit and Node.js...\nOffline native MapBox GL for both Android and iOS apps could be prototyped with Phonegap online service / Apache Cordova and the plugin: http://plugins.telerik.com/cordova/plugin/mapbox and the sample app.\nWith JavaScript MapBox GL for Android and iOS offline app should be doable as well with http://trevorpowell.com/2015/02/20/mapbox-gl-js-with-offline-vector-tiles-on-cordova/ and https://github.com/trevorpowell/mapbox-gl-js-cordova-offline-example - but this a bit of hack and will have troubles on different mobile phone because of missing WebGL in WebKit, unless we pack webkit with the app as well (which ads about 50 MB to the app size).\nIn all cases, if we go for mobile app - it should be tracked in a different ticket.\n. @sfkeller - the projects I mentioned are powered by mapbox-gl-native.\nI have made and compiled first version of the mobile app:\nhttps://github.com/klokan/osm-vector-offline/\nStill, most of the work still must be done:\nhttps://github.com/klokan/osm-vector-offline/issues\n. Show stopper for QMapBoxGL or native MapBox GL in general: the mapbox-gl-native does not compile on Windows: https://github.com/mapbox/mapbox-gl-native/issues/1421\n. The basic binary web server application for USB stick is now finished. Looks like:\n\nIt is standalone signed windows .exe and mac .app. It serves on localhost the content of \"static\" directory (with index.html and all assets) and it serves also raster or vector tiles dynamically from .mbtiles located next to the application binary.\nWe will release it soon. Now it would be great to have v2 tiles which fits to 64GB disk ;-).\n. Regarding offline use on mobile apps SDKs for Android / iOS: https://github.com/mapbox/mapbox-gl-native/issues/4178\n. The preview application for USB disk is now finished. I am closing this ticket.\nThe USB disks must be ordered one month before they are delivered. For placing the order the new complete world map with MBTiles not bigger than 60 GB should be uploaded to the remote location.\nNext events where the USB disks would be practical are: GeoSummit (June 5th), FOSSGIS (July 4th), FOSS4G (24th August).\nTo meet the GeoSummit deadline - the new world MBTiles should be available by the end of April, latest in the beginning of May.\nCould you prioritize the tasks related to world rendering and fixing of the SQL mapping - to start the rendering of world on cluster in following few weeks @lukasmartinelli @manuelroth?\nBTW what about to meet on Hangout this week to catch up on the progress?\n. Unverified. By looking on the web it seems the final limit for MBTiles is going to be more 59 GB - we may need some space for the software itself ~100 MB (Mac signed fat binary with Intel 32+64bit+PowerPC + Windows statically compiled QT for compatibility from XP SP3 above + probably a basic start.py for Linux or general multi-platform command-line use by hackers on a computer with python interpret).\nI will check the used filesystem and exact numbers (in bytes) with the manufacturer and let you know.\n. To test the apps and sample content of the USB disk download and unpack this ZIP file:\nhttps://drive.google.com/open?id=0BwUe1kqIRJWST2FGTFFGQ0RfZjg\nNext week for the Hangout meeting would be nice. Monday 14:00?\n. Is there a preview of world for 0 to 6 or 7? Could you please upload one on Google Drive?\n. Thans @manuelroth. The zooming and ranking looks quite good - but there seems to be some issues on GL version generalisation of land shapes. See screenshot and the live version bellow:\n\nhttp://osm.tileserver.com/open-streets/bright-v8world.html\ncompared to:\nhttp://osm.tileserver.com/open-streets/bright-v8v6.html\nLet's keep this in mind for GL optimisation #71, please.\n. The tl command is too dummy - it can in fact be more clever and stop: https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/export/export-local.sh#L16\n. You may try to precalculate the centroids you need to label later on during the PLANET import and just after creating of the database - before you even start the cluster... see the \"materialized view\" in PostgreSQL - this way we can at least calculate the centroid for each polyton always only once - not for each tile which is overlapping it again and again... \n. My previous comment:\n\nWe should put an effort into improvement of the tile size.\nIt would be also interesting to compare the above mentioned big tiles with V6 - to identify why are our so large. It can be easily done with:\nhttp://klokantech.github.io/ol3-sandbox/vector/tile-inspector.html#http://a.tiles.mapbox.com/v4/mapbox.mapbox-streets-v6.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ|0|0|0\n. It's nice the same core code is reused in both...\nI am voting for renaming to:\nexport-local -> export\nexport-remote -> export-worker\n. This should have been a comment on #5 instead of a new ticket here - without milestone...\n. Can we get this feature into https://github.com/klokantech/tileserver-tessera docker?\n\nI would be happier to offer people the docker image from https://hub.docker.com/r/klokantech/tileserver-tessera/ for direct downloading and testing.\nThe look&feel is now adjusted to green OSM2Vector tiles - and it will be more user friendly with sample code for different viewers.\nWe have added the vector tile preview as well - and there is a way how to display multiple styles directly - if correct index.json can be generated by tessara.\n. +1 :-)\n. Cool!\nIs the fixed version on downloads.osm2vectortiles.org now?\nOn Monday, 14 December 2015, Lukas Martinelli notifications@github.com\nwrote:\n\nRunning VACUUM on the database file saves 3GB.\nhttps://sqlite.org/lang_vacuum.html\nNow the world file from z0 to z14 with water removed is 62GB.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/87#issuecomment-164510872\n.\n\n\nPetr Pridal, Ph.D.\nCEO\nKlokan Technologies GmbH\nHofnerstrasse 98, 6314 Unterageri, Switzerland\nTel: +41 (0)41 511 26 12\nEmail: info@klokantech.com\nWeb: http://www.klokantech.com/\n. +1 on versioning vie directory\nAre the data on a cloud mashine? And the extracts? I can start upload to\ngdrive myself...\nOn Monday, 14 December 2015, Lukas Martinelli notifications@github.com\nwrote:\n\nI will now start to version the files and start with v1.0 (even when they\nactually are from the v0.2 rendering but the upper level tiles are from the\nupdated version that will be the v1.0 release this thursday). Files will\nend with suffix _v1.0.\nNope. Better idea - versioning makes more sense at a folder level.\nEach version will get it's own folder in the download bucket. The extracts\nof the version\ncontain the country extracts and the tiles contain the tile pyramid\nsources (what is now on S3) from which the world.mbtiles is built. The zoom\nsuffixes can be omitted if it is from z0 to z14.\n.\n\u2514\u2500\u2500 v1.0\n    \u251c\u2500\u2500 extracts\n    \u2502   \u2514\u2500\u2500 andorra.mbtiles\n    \u251c\u2500\u2500 tiles\n    \u2502   \u2514\u2500\u2500 135_147_z8-z14.mbtiles\n    \u2514\u2500\u2500 world.mbtiles\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/87#issuecomment-164568327\n.\n\n\nPetr Pridal, Ph.D.\nCEO\nKlokan Technologies GmbH\nHofnerstrasse 98, 6314 Unterageri, Switzerland\nTel: +41 (0)41 511 26 12\nEmail: info@klokantech.com\nWeb: http://www.klokantech.com/\n. Tracked under https://github.com/klokantech/tileserver-php/issues/56\n. Havn't you forgotten where name=\"bounds\";?\n. MapBox GL JS + OpenLayers x-ray viewer for vector tiles:\nhttp://klokantech.github.io/mapbox-gl-js-offline-example/xray.html#http://osm2vectortiles.tileserver.com/v1.json\nnow on http://osm2vectortiles.tileserver.com/\n. BTW @klokantech team has added also support for open-source static maps requests, like:\nhttp://klokantech.tileserver.com/streets-basic/static/8.82,47.225,15/500x500@2x.png\nhttp://klokantech.tileserver.com/osm-bright/static/8.82,47.225,15/500x500@2x.png\nTomorrow I want to work on Kitematic friendliness #15  - to make it child easy to use the docker... even for newbies...\n. Yes and Yes.\n. OSM2VectorTiles for sure wins over Wikimedia Maps stack in simplicity of deployment and usage, and in this moment also in quality of the maps :). We have learned from them a lot as well.\nCritical next step is going to be the implementation of incremental updates from planet diffs and of the  gazetteer search - which are both on the roadmap for the follow-up project.\nYou and Manuel did a great job indeed!\n. @daliborjanak works on merging recent changes.\n. Please generate the vector tiles from an OSM planet dump for your country yourself.\nHere is a step-by-step guide:\nhttp://osm2vectortiles.org/docs/own-vector-tiles/\n. Fixed in OL3 and Leaflet viewers.\nThe original reason is that our tileviewer project (the frontend of the tileserver-maptiler) has been developed originally for http://www.maptiler.com/ project - and it run on various tile backend (S3/PHP/NODE/local files/etc).\n. @lukasmartinelli - the OGC WMTS, TileJSON and tutorials for usage in QGIS and ArcGIS are in the sidebar. Just scroll down on the right side...\nI see this is a usability problem.\nThe issue with missing port acknowledged and to be fixed.\n. The port has been added to TileJSON link in tileviewer. I believe this issue is resolved.\n. Well, this has been done and it runs already - exactly with the syntax mentioned above.\nTry it on the tileserver-maptiler docker or on CDN hosting at http://maps.klokantech.com/.\nThere is also Static Maps API for requests like: /osm-bright/static/8.82,47.225,15/500x500@2x.png see PR https://github.com/mojodna/tessera/pull/31\n. Does Leaflet switch to Retina tiles with suffix @2x automatically in case there is \"autoscale:true\" in TileJSON metadata?\n. @hyperknot thank you for the implementation tips.\nWe have made the retina support for tilesets with autoscale in metadata in the Leaflet and OL3 viewer template - so you should see now in Docker.\nLeaflet and OL3 runs automatically in retina on supported hardware.\n. Check buffer-size on the tm2source for related layers - and compare with MapBox maps - to be sure the buffers are correct in vector tiles.\nTweaking of raster tile rendering is next step - you can study how https://github.com/mojodna/tessera runs internally and prepare an improved config...\nComments on results of your research are welcome - this is an open-source project. Just make what you want - fix the bug for you and share the solution with others!\n. Wiki enabled\n. The relevant vector tiles appears in the JavaScript tile inspector:\nhttp://klokantech.github.io/ol3-sandbox/vector/tile-inspector.html#http://osm2vectortiles.tileserver.com/v1.json|41.70886829782091|44.78902816772461|14\nWe should probably try to get the logs from mapnik about the rendering. Looks strange - as a corrupted tiles ignored by mapnik for some reason.\n. The vector tile is really not in there (in tile inspector appears only upper zoom levels).\nProbably duplicate problem to #116 \n. - Is there a problem with the sample tile: zoom_level=14 tile_column=12767 tile_row=8823 during generating?\n. The work on terrain and hill-shading vector tiles is not planned on our side right now - feel free to jump on this challenge ;-). Pull requests are welcome.\nTechnically our toolset and docker containers for generating vector tiles could be used with a small modification to generate the terrain vector tiles as well.\nSteps which must be done first:\n- insert the contour lines into postgis tables, generalised for appropriate zoom levels\n- generate the raster hill-shading and turn it into vector polygons with similar colours (gdal_polygonize can be helpful, but you may need some preprocessing such as posterisation to a defined number of colours). Once hillshading is made via polygons, save these into postgis.\n- create a new open-terrain.tm2source and define SQL queries and ensure compatibility with existing terrain layers (landcover, hillshade, contour layers) - a la https://www.mapbox.com/developers/vector-tiles/mapbox-terrain/\nCheck the x-ray viewer:\nhttp://klokantech.github.io/mapbox-gl-js-offline-example/xray.html#http://a.tiles.mapbox.com/v4/mapbox.mapbox-terrain-v2.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ|39.17552111913693|-16.352123460464668|2.056126768822307\nand the tile inspector:\nhttp://klokantech.github.io/ol3-sandbox/vector/tile-inspector.html#http://a.tiles.mapbox.com/v4/mapbox.mapbox-terrain-v2.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ|46.36044862505827|364.8205033694648|7\n. Making raster terrain hillshading tiles for MapBox GL JS or GL Native (Android / iOS) is easy:\nFollow thw HOWTO_DEM tutorial. After step \"# Create hillshade for different zoom levels\" drop the tiff files to MapTiler and generate MBTiles, while defining on which zoom levels appears which source tiff files (https://youtu.be/WQbX4dqlHgY?list=PLGHe6Moaz52PiQd1mO-S9QrCjqSn1v-ay). When displaying the hill shading the client can overzoom the tiles.\nAlternative would be to use my old open-source project called GDAL2Tiles. To get the free MapTiler Pro Demo fill the request form\nIf you want to serve raster tiles rendered on demand by mapnik tileserver out of OSM2VectorTiles and the raster hill shading, then it is possible to use the tiff files from HOWTO_DEM tutorial above directly in your .tm2 style as input. Be sure to create overviews and allow random access to these tifs in EPSG:3857.\n. OpenTerrain is an interesting project indeed. Esp. the wiki page:\nhttps://github.com/openterrain/openterrain/wiki/Terrain-Data\n(and it seems they have a copy on S3 for easier processing - such as calculating of contour lines?)\nBTW I have seen discussion in MapBox GL JS about possible implementation of the hill-shading via TIN (which could bring it closer to Cesium and other existing 3D terrain tiles as well): https://github.com/mapbox/mapbox-gl-js/issues/1295\n. First tests on OSM2VectorTiles with hill-shading (whole world) + contour lines (for now only Zurich area):\nhttp://labs.klokantech.com/hillshading/\n. A screenshot for reference (this ticket does not have any yet :-):\n\n. You can apply opacity or composite operation of your choice to receive visual effect you expect.\nDisplaying contour lines on top helps as well (see areas around Zurich which have hills with elevation similar to Hungary but also displays contour lines - for real tests).\nWe continue testing compositing with GL JSON styles (tileserver-gl) and CartoCSS (tileserver-mapnik) renderers now.\nI have added opacity slider to the demo app (top right corner) - to change the darkness of the hill-shading. See: http://labs.klokantech.com/hillshading/\n. @stirringhalo I am keen to make a Skype/Hangout call with you - and provide you with the report of our status, with the access to the global data we have available in-house now, and tips on how the whole terrain layer can be moved forward, from where we are at @klokantech.\nPlease let me know your availability - ideally by email.\n. @lukasmartinelli - we have the MBTiles made with MapTiler. Let's discuss on FOSS4G how to proceed.\n. Points mentioned as important are without doubts highest on the priority list and are for sure on the roadmap. The project must be cleaned and documented and stabilised and updates must run. I am keen to dig deeper into technical details and tickets in two weeks... This is priority number one.\nOther points are for discussion on that meeting... after estimates of effort on more important tasks.\nThe ideas behind the way HOW the osm2vectortiles project is build can be easily applied on a basic geocoding approach as well - which is crucial for offline use and processing of OSM extracts.\nDuring the vector tile rendering we have in Postgres already a lot of cleaned data in imposm3 tables, with mapped tags and names in multiple languages - I would like to enrich the data and simply export it - to feed an existing fulltext-based geocoder service such as Pelias or the search service behind Swiss GeoAdmin https://map.geo.admin.ch (https://github.com/geoadmin/service-sphinxsearch) or a simple SQLite FTS5 index. We can think about the update process of what we have in the vector tiles in relation to the place search service as well. This is about being able to find what is in the generated vector tiles and zoom to the relevant area.\nPreference would be therefore on having bounding boxes and extra rank for fulltext search in the data (derived from Natural Earth + Wikipedia) - and index esp. countries, administrative units, towns, street names and data we put as name into vector tiles. This is a basic version of index of what somebody has in his vector tiles, if he/she generates one from a small OSM extract (such as Switzerland only).\nPOIs and postal addresses with ZIP and house numbers are lower priority for me personaly, but there are tools and processes in Nominatim and other projects, which can be applied on the PostGIS imposm3 mapping to push this part forward - Andreas has master thesis at HSR about address search processing  (http://wiki.hsr.ch/StefanKeller/PA2EgloffAufgabenstellung) and there is synergy and low hanging fruit in this regards in the osm2vectortiles project. It is the other side of coin.\nI don't want to code a new gazetteer service software, we concentrate on automating and scaling of data processing in OSM2VectorTiles anyway...\nIf there is already fruitful discussion:\n- Does anybody know of a single geocoder project, where you can download ready to use world data and a docker for the software and have something close to useful for whole world up in minutes running on a desktop? I doubt that, but would love to hear something else...\nI mean, can you get of dump of world data to feed https://github.com/pelias/pelias?\nThere used to be NPI download for Nominatim, but it is gone...\nYou always ends up with a week of processing of planet dump with osm2pgsql...\nBTW Carmen is not THE MapBox Geocoder API...\nIt makes sense to discuss this on the roadmap meeting for sure. \n. New milestones and tickets are created. Closing this ticket.\n. Tests to be done on diffs of a smaller area - such as osc.gz from http://download.geofabrik.de/europe/switzerland.html\n. @lukasmartinelli - does the import sets the timestamp only on records which have really been modified in our database?\nIf a tag present in OSM raw data, which is ignored by our mapping to SQL tables, is changed/modified/added/deleted, then there may be no change for this feature in our database.\nThis way we can eliminate a lot of the edits in OSM. It sounds like this approach ignores this for now. If it i does - we need a new ticket for solving this properly at later point (BBeta milestone?)\n. Thanks! This is what I meant.\n. A code for generating list of relevant tiles by traversing mercator tile quadtree directly with SQL from: http://javisantana.com/2014/10/22/traversing-quadtree.html\nWITH RECURSIVE t(x, y, z, e) AS (\n      -- root node (0, 0, 0)\n        SELECT 0, 0, 0, exists(select 1 from ships where the_geom_webmercator && CDB_XYZ_Extent(0, 0, 0))\n      UNION ALL\n        -- coordinate for the children\n        SELECT x*2 + xx, y*2 + yy, z+1,\n               exists(select 1 from ships where the_geom_webmercator && CDB_XYZ_Extent(x*2 + xx, y*2 + yy, z+1)) from t,\n               -- iterate over 4 children\n               (VALUES (0, 0), (0, 1), (1, 1), (1, 0)) as c(xx, yy) \n               -- only for tiles with geometry and up to zoom level 8\n               where e AND z < 8\n    )\n    SELECT z, x, y FROM t where e\nwe can use TileBBox() from https://github.com/mapbox/postgis-vt-util instead of CDB_XYZ_Extent().\n. Well - tiles are not requested on zoom level 18 - as metadata tells maxzoom 14.\nWe have fixed this in source code in December - but forgot to deploy the latest version.\nThe new version returns 404 error instead.\nTODO @klokan: redeploy.\n. Latest version of the tileserver deployed. Now there is 404 error message instead.\n. We have talked about this approach on the roadmap meeting as well - the \"give me a changed feature and I tell you what tiles are dirty for it\" way. In ideal case also on which zoom levels.\nIt seems you can generate the list of affected tiles directly in SQL as well - as I have mentioned already in comment in #123. See: http://javisantana.com/2014/10/22/traversing-quadtree.html This could run in the SQL trigger on import / update / delete of a feature. The example select is only for points - but the same principle can be applied on a single shape (polygon/line/point). You get the list of tiles on all zoom levels out the SQL command - and can save the list of tiles into a separate table.\nFor a single shape it could be very fast.\nWould not this be better then calling for the same task an external node-based utility?\n. If the concept proves to be correct - the code could be rewritten to golang for direct integration in imposm3, before it enters PostGIS- with the list of dirty tiles directly stored in LevelDB cache. But let's make first the proof of concept in Node.js. Everything else is performance optimisation.\n. +1 This is very important!\n. Maybe a patch of imposm3 - or how do you want to detect this?\n. I am going to make a draft.\n. Will jump on it soon.\n. My suggestion for the proposal for the two talks:\nWorld on a USB stick: turning OpenStreetMap to vector tiles\nOSM2VectorTiles.org project offers free downloadable vector tiles ready to use by people interested in hosting custom base maps on their own infrastructure. The whole world fits on a USB stick, and can be served from an ordinary web hosting and styled and enriched to make beautiful and fast maps for web and mobile applications.\nThis talk will demonstrate the open-source tools and process used to generate the world vector tiles (called Open Streets) and it will show how the same software stack can be applied to create customised vector tiles from your own geodata or OpenStreetMap Planet extracts.\nThanks to the Docker containers and open-source tools such as Mapnik with vector tile extension, PostGIS, TileLive and Mapbox Studio Classic the process is straightforward and repeatable. The OSM2VectorTiles process allows also updates of the tiles on regular bases. Practical tips and live demonstration of how to generate custom tiles is going to be presented.\nTileServer GL: Serving vector tiles to the web, mobile apps, desktop GIS, raster tiles and static images\nHosting base maps with your custom look&feel, even for the whole world, is thanks to the OSM vector tiles and open-source software easy and achievable even with a low-end hardware. Such maps can power web sites, mobile apps, large production services as well as run behind firewalls, or completely offline - for example on the board of an airplane.\nThis talk demonstrates examples of practical use of the vector tiles downloaded from the OSM2VectorTiles.org project or any other tiles in MVT format generated with open-source tools or other software.\nA new open-source project called TileServer GL is going to be presented. This project exposes map styles written in JSON into web applications using WebGL powered by MapBox GL JS library as well as into native mobile SDKs for iOS and Android. In the same moment the style can be rendered on server side with the OpenGL ES 2.0 graphic acceleration into traditional raster tiles and served to older web browsers using any of the tranditional clients such as Leaflet or OpenLayers. Raster tiles are OGC WMTS compatible - allowing opening of the maps in destkop GIS software such as QGIS or ArcGIS. The maps can be served with variable scale (Retina / HiDPI) or drawn in defined extent and zoom for printing purposes or static illustration.\nAlternative projects are going to be presented as well - such as TileServer-Mapnik derived from Tessera & TileLive for serving maps made with CartoCSS .tm2 styles in MapBox Studio Classic.\nThe vector tiles itself could be hosted even in a basic unpacked form in directories or served directly from SQLite/MBTiles.\nAll these project shows how to use vector tiles according specification made by MapBox and all the related popular open-source projects and in the same moment retain control of the data and costs, while hosting maps on a custom infrastructure.\n. @manuelroth please add \"petr.pridal@klokantech.com\" as another speaker.\n. I am not sure what is current approach, but what makes sense to me is:\n- run the SQL query generating list of tiles for each changed feature separately (small and fast queries getting you tiles on all zoom levels for one feature)\n- save the list of dirty tiles together with zoom and osm_id in a special table\n- getting list of changed osm_id from the saved views - for individual zoom levels defined by our mapping style\n- selecting distinct list of dirty tiles based on zoom and osm_ids from the previously saved table with all dirty tiles records\n- asking mapnik to render this list of tiles\nThis would be fast and save to do. Can you in details describe your current approach please?\nI am now also on Hangouts - if you prefer to chat about this shortly instead...\n. I believe you compare here apples and pears.\nThe SQL dirty tiles must be calculated on each shape separately. Please read my described approach above - then it is comparable. You can't iterate on the whole view with the dirty_tiles approach - as these queries are for sure slow.\nFrom the view you can only extract the identifiers of the changed features.\nWouldn't it make sense to try it? Please comment.\n. Please check #153 @lukasmartinelli \n. In the above statement I would replace GROUP BY 1, 2, 3 with DISTINCT in the SELECT (for better readability) and add missing WHERE timestamp - to be more transparent.\nYou approach has one significant drawback - if the same geometry appears on landuse_z12 and landuse_z11 then you will several times calculate all tiles for this geometry down to zoom level 14!\nIt would be better to calculate it only once and cache it in RAM instead.\nSo a boost in speed could be probably made by calculating all tiles on z0 - z14 for each modified geometry just once - store it in a temporary table - and select the distinct tiles appearing on zoom level of your interest for list of modified osm_ids in the view of your interest (such as landuse_z12).\nTo calculate the zxy tiles for all modified geometries on one table (like \"places\") just once you can use something like:  CREATE TEMP UNLOGGED TABLE dirty_places AS SELECT z, x, y .... This table could be ordered (with an index) and possibly live only inside of transaction (with ON COMMIT DROP).\nIt would be then worth to check what caches in Postgres should be increased so these temp tables with all dirty tiles for one day (or our final update period) all stay in RAM.\nAnother optimisation could be to add into overlapping_tiles also z as argument - to stop the recursion sooner - if you know you have no interest in deeper zoom levels.\n. List of all layers / tables which has \"name\", \"name_en\", etc. and whether we have bounding box: a) in the same table b) in a different table - and which one c) not imported by imposm3 mapping d) completely missing in OSM\n. Where can we download the exported data for the whole world?\n. Anybody can use OSM2VectorTiles software stack (docker containers, etc) to generate a secondary vector tileset containing only extra tags or detailed POIs for a country or even whole world - which can be then by a tileserver combined with our official OSM2VectorTiles base maps during the request.\nWe plan to have the binary concatenation of several PBF vector tiles available in https://github.com/klokantech/tileserver-gl/ (which is also able to render GL JSON styles on the server side into raster tiles for clients not able to render directly with WebGL).\n. The dirty tiles detection is always very relevant to a zoom level - what is the purpose of this summary view exactly?\n. Yes - the styles are otherwise untouched. See commit:\nhttps://github.com/klokantech/osm2vectortiles-gl-styles/commit/9b9d3ff0dd50e5a1d5647dbb33bb3a8bde183031\nThese styles were made primarily for the USB stick for Cebit (#72) and for basic offline use without dynamic server: http://klokantech.github.io/osm2vectortiles-gl-styles/\nJSON styles hosted with TileServer-GL can use the original doubled fonts unmodified - as https://github.com/klokantech/tileserver-gl/ serves the fonts correctly combined together. It means you really need to only replace the URL to load the vector tiles (from a local \"mbtiles://\") and use local sprites and fonts.\nWhen working on reviews it would be worth to check compatibility issues with the latest version of the styles at https://github.com/mapbox/mapbox-gl-styles - which are now using mapbox streets v7.\n. Thanks for looking into this. If we upgrade vector tiles to v7 compatibility we indeed should upgrade to the latest JSON GL styles as well...\n\nWhen working on reviews it would be worth to check compatibility issues with the latest version of the styles at https://github.com/mapbox/mapbox-gl-styles - which are now using mapbox streets v7.\n. The function to calculate bbox for ZXY in Mercator defined in SQL could be improved to accept buffer size in pixels.\n. @manuelroth shouldn't the above mentioned automatically appear on zoom levels like 5 or 6 - directly from Natural Earth?\n\nThere is a need for \"seas\" custom geojson probably - but aren't the states and countries sufficient in the Natural Earth Data itself?\n. Modification of imposm3 required - to not do DELETE + INSERT in case there is no change in the data?\n. I see DNS connectivity issues at:\nhttps://status.digitalocean.com/\n. +1\n. Could be helpful:\n``` python\ndef QuadTree(tx, ty, zoom ):\n    \"Converts XYZ tile coordinates to Microsoft QuadTree\"\n\n    quadKey = \"\"\n    for i in range(zoom, 0, -1):\n        digit = 0\n        mask = 1 << (i-1)\n        if (tx & mask) != 0:\n            digit += 1\n        if (ty & mask) != 0:\n            digit += 2\n        quadKey += str(digit)\n\n    return quadKey\n\n```\nDerived from globalmaptiles.py at http://www.maptiler.org/google-maps-coordinates-tile-bounds-projection/\n. I don't see this problem on https://klokantech-1.tileserver.com/osm-bright/6/36/23.png?key=USE-YOUR-KEY\nHow to reproduce the error?\nCan you test it properly and prepare a Pull Request with a fix of the problem please?\n. Thanks @hyperknot for the report and details. We will try to reproduce.\nMoving this ticket to https://github.com/klokantech/tileserver-mapnik/issues/14\nIt does belong to tileserver-mapnik project. Let's continue there, please.\n. Cool! \nBTW Shall we not better test against the JSON GL styles now?\n. We have used beanstalkd for similar job management on large raster processing tasks.\nIt has exactly what a similar project with long running (hours) tasks pulled from a job queue needs - and is designed to run exactly this sort of task well. No long TCP connections open for acknowledgment, no heartbeats, no extra functionality and optimization for different use-cases such as general message queue, possibility to ask for a status of a particular task, etc. \nHere is a picture of the typical job lifecycle:\nput            reserve               delete\n  -----> [READY] ---------> [RESERVED] --------> *poof*\nHere is a picture with more possibilities:\n``\n   put with delay               release with delay\n  ----------------> [DELAYED] <------------.\n                        |                   |\n                        | (time passes)     |\n                        |                   |\n   put                  v     reserve       |       delete\n  -----------------> [READY] ---------> [RESERVED] --------> *poof*\n                       ^  ^                |  |\n                       |   \\  release      |  |\n                       |-------------'   |\n                       |                      |\n                       | kick                 |\n                       |                      |\n                       |       bury           |\n                    [BURIED] <---------------'\n                       |\n                       |  delete\n                        `--------> poof\n```\nYou could also prioritize certain tasks (such give higher priority to rendering diff tiles, if another rendering runs - so it is not strictly FIFO).\nSee for a more complete overview: https://www.digitalocean.com/community/tutorials/how-to-install-and-use-beanstalkd-work-queue-on-a-vps\nThere are several client libraries and graphical web user interfaces:\nhttps://github.com/kr/beanstalkd/wiki/client-libraries\n. Here you have it:\nhttps://github.com/klokantech/cloudwrapper/blob/master/btd.py\nThe interface follows the official python Queue class.\nPlease use it directly or forked - as a submodule in OSM2VectorTiles codebase.\nPull request and improvements are very welcome.\nNext to the native queues for Amazon / Google it does contain also logging and metrics.\nFor open-source / private cloud the queues mean Beanstalkd and metrics & logging mean InfluxDB (WIP).\n. Sounds great. Cool!\n. Awesome! Very glad to hear the good news!\nDid you count the tiles on zoom 1-7 while comparing the extracts?\nBTW Design of the mailer for the USB stick grows here:\nhttps://www.pixelapse.com/klokantech/projects/OSM2VT%20USB/files\n. BTW how is it with the size of individual tiles (the 500K limit for upload to MapBox.com).\nIs it better now?\n. So if I understand it correctly - the use_single_id_space is an internal imposm3 implementation of the what Mapbox OSM ID does - just done differently.\nAccording to my understanding, both are convertable there and back and equal in semantic.\nImposm3 process the diffs correctly only if used with use_single_id_space.\nCorrect?\n. For the water layer - union of polygons which are overlapping the bounding box of the tile which should be rendered - before sending it to Tilelive Mapnik for rendering PBF - could solve the problem. Not sure about the performance - ideally the union result should be cached by Postgres for nearby tiles and repeated use.. I am keen to make one more complete world rendering, with diff updates turned on - and fixed this as well as other reported issues.\nWould it be doable in the first half of July at latest, @lukasmartinelli? Then we can manage the world USB sticks for FOSS4G.\n. Great! Yes, it would be good to test properly before we start rerendering.\n. Rendering finished.\n. V2 deployed at http://osm2vectortiles.tileserver.com/\nThere are issues with the new planet MBTiles - missing bounds (!) + metadata contains SQL(!?) + name mentions version 1.4 not 2.\n. or this tool: http://boundingbox.klokantech.com/ - choose CSV as format.\n. v1 zurich.mbtiles has:\ncenter|8.5367150000,47.3774550000,10\nbounds|8.448060,47.320230,8.625370,47.434680\n. Rendering finished.\n. See: https://github.com/osm2vectortiles/mapbox-gl-styles/issues/3\n@michaelsteffen is a lawyer from MapBox. You can discuss with him about the legal usage of the removed styles.\n. @klokantech can provide commercial support for installation of tileservers.\ntileserver-gl-light is a port of tileserver-gl: https://github.com/klokantech/tileserver-gl.\nThe light variant does not serve raster tiles. @klokantech team is now working on bringing the functions from the \"light\" fork back to the master branch of the project (details to be discussed with @manuelroth and @lukasmartinelli soon).\nWe use the tileserver-gl behind NGINX - with HTTPS in production in several of our projects. For example: http://boundingbox.klokantech.com/, http://epsg.io/map#srs=4326&x=8.679199&y=47.085085&z=7&layer=streets, soon we are going to port the OldMapsOnline style and use it also on http://www.oldmapsonline.org/ with over 125k visitors a month and in all our larger projects.\nIf you want to try our server get your key at: http://maps.klokantech.com/\nThe TileServer-GL project is going to be presented and formally announced at FOSS4G.\nFollow: https://github.com/klokantech/tileserver-gl and our twitter @klokantech\n. Another issues reported at #379\n. @brianshaler Could you please create a new ticket where you mentioned the exact ZXY tiles which are missing in the latest planet?\n. @daniyel the issue in TileServer-GL is https://github.com/klokantech/tileserver-gl/issues/38\n. Download the tiles from\nhttps://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v2.0/extracts/iran.mbtiles\nand follow how-tos in this project.\nVector tiles are 0-14 - but your can render these on 0-22 easily - with TileServer-GL or TileServer-Mapnik.\nIran country extract is (and always was) available in the Download section:\n\n. Yes of course - the maps can run completely offline.\nIf you need PNG tiles then: tileserver-gl, or older tileserver-mapnik\nIf you need vector tiles in browser, then tileserver-gl-light, or tileserver-php with an external directory in Apache containing HTML+JavaScript+JSON from similar to https://github.com/klokantech/osm2vectortiles-gl-styles (made for tiles version 1 of osm2vectortiles now).\nThe maps can display the street names in Iran with an Arabic font too...\nWe have a USB stick desktop application as well - for Windows and Mac OS X - showing the maps offline directly without a need to have another application installed on a desktop - as a demo of the offline use. If you need commercial support contact us at https://www.klokantech.com/contact/, otherwise study the source code an available documentation in this open-source project.\n. My comment: Don't use (patched) RabbitMQ - use instead a true job queue, like Beanstalkd - for example via https://github.com/klokantech/cloudwrapper\nI have recommended this to @lukasmartinelli as well, but it did not make it to the project before the bachelor thesis was finished. He started to work on it ...\nSee: https://github.com/osm2vectortiles/osm2vectortiles/issues/251#issuecomment-211758388\n. RabbitMQ is designed for messaging - millions of small messages, short living inter-process communication, typically in web environments with HTTP health check / open connections, etc.\nThis is not what OSM2VectorTiles tile rendering on a hybrid cluster does...\nBeanstalkd is designed for job management.\nWe have used beanstalkd in tests on large production cluster deployments. It was fine and fitting the task - able to replace Amazon SQS or Google Task Queue API directly.\nThe cloudwrapper library is now released, which makes the switch easier. See: \nhttps://github.com/klokantech/cloudwrapper/blob/master/cloudwrapper/btq.py\nThis includes methods for auto reconnect, extending TimeToRun on long running tasks, etc.\nPutting the jobs from command line almost like with https://github.com/lukasmartinelli/pipecat seems to be quite easy as well with https://github.com/nutrun/lentil/tree/master/lentil\nDecission is on @lukasmartinelli...\n. This project, as well as https://maps.wikimedia.org/ and many others, is built around the \"OSM Bright\" cartography.\nThe complete cartography of the original \"OSM Bright\" map style has been released under BSD license - with imposm/osm2pgsql for going from raw OSM planet data to rendered map tiles with a complete look and feel. Complete means everything from\n\nThis includes choices from among multiple possible data sources for different features, the particular selection of elements to incorporate from those sources, our tagging schemes and arrangement of the data elements, label placement methods, decisions about prominence and use of features at different zoom levels, iconography decisions, ranking of features, and more.\n\nThe repo is here: https://github.com/mapbox/osm-bright, it renders maps by Mapnik from OSM SQL database directly. Similarly, the complete cartography is in https://github.com/mapbox/natural-earth-tm2.\nThese are amazing sources of information and a great 100% open resources from MapBox cartographers.\nThe \"OSM Bright\" map style has been ported to TileMill2 by MapBox. The style uses Mapnik to render almost the same cartography as original \u201cOSM Bright\u201d, this time from vector tiles, which can be in fact seen as \"saved results of SQL database queries\" for the individual map tiles.\nCompatible vector tiles were implemented in OSM2VectorTiles V1 milestone (in December 2015) - to deliver with osm-bright.tm2 maps original look&feel - it automatically implies partial compatibility with vector tiles V5/V6 from MapBox. Similar vector tiles are made by Wikipedia.\nThe repo with plain BSD license of \"OSM Bright\" in TM2 version is available at https://github.com/mapbox/mapbox-studio-osm-bright.tm2/tree/v2.0.2 (see the license)\nLater, the \"OSM Bright\" cartography has been ported to GL JSON styles by MapBox and released again under a very open ISC license - and later republished under a more restrictive \"Open Design License\". All details are here: https://github.com/osm2vectortiles/mapbox-gl-styles/issues/3#issuecomment-229917810\nOSM2VectorTiles upgraded the vector tiles to V2 (May 2016) - and fixed the visual glitches of OSM Bright look&feel against the GL JSON styles.\n\nAs you know, the license we've provided for OSM Bright (BSD for the code, CC-BY SA for the design elements) expressly excludes the Mapbox Streets Vector Tiles and the cartography they contain. \n\nThe license which \u201cexpressly excludes vector tiles\u201d has been applied for the first time in May 2016. This is after OSM2VectorTiles milestone V2.0 - after most of the work has been done. Before that point, there is no mention of intention on MapBox side to restrict somehow the cartography of \u201cOSM Bright\u201d style.\nOSM2VectorTiles does exactly the same with latest \"OSM Bright\" what MapBox made possible in 2012 - \"Having your own base map under 30 minutes\": https://www.mapbox.com/blog/create-a-custom-map-of-your-city-in-30-minutes-with-tilemill-and-openstreetmap/.\nThis time with vector tiles and JSON GL styles - which can be applied in vector tile viewers or rendered into raster tiles with https://github.com/klokantech/tileserver-gl\n. @gisgraphy \nThe problem discussed here is the internal structure of the tiles and selection of what data is inside. Call it \"schema\", see the documentation of the schema under Mapbox Streets V7 Vector Tiles (do not mix it with Mapbox Streets Style - it is not the same!). Schema influences the look of the map (in shapes of the features, generalization, and what appears where and what features are available to styles) but it is not the look of the map itself which is described in the style (such colors, icons, line borders, appearance on zoom level, etc). Usage of openly released MapBox styles is not an issue - as confirmed by Mapbox above.\nMapbox claims it is illegal:\n- to produce vector tiles which are reproducing their tile schema directly\n- to distribute and use such map tiles\nThe team of OSM2VectorTiles was asked to adjust this open-source project. If we would not do that we are under a legal threat - as well as anybody who uses the vector tiles downloaded from OSM2VectorTiles or produced with the schema made in this repository.\nOur formal reply is 14 days ago: https://github.com/osm2vectortiles/osm2vectortiles/issues/387#issuecomment-252240138\n\nwe are committed to work on a new v3.0 with new vector tile schema free of the legal issues and hope to publish it until the end of this year.\n\nI would wait with a production deployment of vector tiles for this milestone. We do everything what we can to release soon new improved tiles which are 100% open and legal.\n@severak\nOSM2VectorTiles is compatible with MapBox styles directly - so nobody has to write the migration script. This is exactly what Mapbox does not like.\nMapbox has never identified any exact laws we are breaking - but it is not as important. People should be aware that this project builds on top of a lot of open-source components and open standards produced by Mapbox. Gentleman agreement acceptable for both sides is the best for the community and future. It seems we are getting there.\n. @severak No. Tile schema differs. You need to adjust your existing JSON / TM2 style.\n. Thank you a lot @lukasmartinelli for the report! Great progress with the @klokantech rendering cluster.\nLooking forward to having all tiles in the planet in V2 spec...\n. Vector tiles are typically overzoomed - so by default the OSM2VectorTiles project vector tile schema have maxzoom 14 - but you can display and draw the maps, streets, houses, etc. down to zoomlevel 22 from these vector tiles. No need to render vector tiles deeper.\nIf you want to change the schema / style for the vector tiles check https://github.com/osm2vectortiles/osm2vectortiles/tree/master/osm2vectortiles.tm2source\n. Try \"OSM2VectorTiles\" on iOS or Android (search AppStore / Play). It demos the zoom 14 vector tiles (online and offline) over-zoomed without limits.\n. BTW a nice ticket number on this issue ;-)\n. The sample Shapefile is available for download at https://goo.gl/nGFLR9\nIt has contour line every 10m - we may need to assign attributtes to contour lines - for styling every second and for the important lines - modulo 50, 100, etc.\nAnd it is visible (practically unstyled) in the preview at \n\nOnline preview on http://labs.klokantech.com/hillshading/ (zoom into the Zurich area)\n. @romanshuvalov thanks!\nI am now travelling to FOSS4G, on bad Internet connection, and I don't have direct access to the individual segments immediately. Everything is packed in one .tar archive with 270+ GB on Google Drive. Otherwise, I have to download, unpack, select and share with you the relevant segment.\nCould you please run the tests on the provided sample?\n@lukasmartinelli suggested adding the vector tiles into osm2vectortiles.tm2source.\nThe question is how much size the contours add to the zoom level 14 tiles...\nI am in favour of separating these into a different terrain.tm2source and creating a different set of vector tiles in MBTiles. This is to not reach 500K limit on the maxzoom tiles.\nThe GL JSON styles can load multiple tile sources easily - and TileServer-GL is able to concatenate the vector tiles into one anyway - for saving extra http requests or rendering with Mapnik (Tessara or TileServer-Mapnik).\nAll of the contours should be probably in the tiles for zoom level 14 in the .tm2source.\nWhat attributes are you going to assign to contours, @romanshuvalov?\n. Great @romanshuvalov!\nFor the styling in GL JSON - I am not sure into what extent you can really make \"every modulo 100  contour darker/thicker\" without having the relevant attributes precalculated in the vector tiles...\nSee: https://www.mapbox.com/mapbox-gl-style-spec/#types-filter\nI think it is not possible - therefore the attributes with correct values are required.\n. I guess we could put all the individual Shape files on the OSM2VectorTiles\ndownload infrastructure, where we put the vector tiles with contours as\nwell...\nAre you fine with this @yvecai?\nOn Monday, 22 August 2016, Zsolt Ero notifications@github.com wrote:\n\n@yvecai https://github.com/yvecai also, if hosting is a problem, I'd be\nhappy to provide hosting on a small Kimsufi server.\n. Please create a pull request on this GitHub repo with the suggested changes.\nFor an example see: https://github.com/osm2vectortiles/osm2vectortiles/pull/378/files\n. Replace in your JSON style the \"name_en\" by \"name_zh\".\n. You may also need to install on your server an unicode font and add it to your JSON style.\nThis is a free unicode font we have released:\nhttps://github.com/klokantech/klokantech-gl-fonts\nTo use it, just add into JSON style text-font definitions similar to:\n\n\"text-font\": [\n                    \"KlokanTech Noto Sans Regular\",\n                    \"KlokanTech Noto Sans CJK Regular\"\n                ],\nHere is a live preview of the font https://maps.klokantech.com/ - deep zoom to China to see street names and other labels.\n. Let us know if you succeed or if there are troubles. I am closing this ticket now - we can reopen. Good luck!\n. Done in a first version.\nSee: http://osm2vectortiles.org/downloads/embed/\n. Thanks @daliborjanak. Closes #422\n. Maps.me have pretty nice splitting into smaller regions for various countries:\nhttp://direct.mapswithme.com/direct/latest/\nThe database of bounding boxes should be very probably somewhere under the github account\nhttps://github.com/mapsme\nYou can also try to filter it from the http://OSMNames.org/ data.\n. Start to use a config file with TileServer GL...\nIn the config, you can specify the folder where you store your JSON styles, as well as create a record for the individual .json files you want to serve by the server. Format of the config is described here:\nhttp://tileserver.readthedocs.io/en/latest/config.html\nCheck the documentation please, at http://tileserver.readthedocs.io/en/latest/usage.html and let us know if something is unclear.\nIt would be great if you can help us to make it easier for people to use the project ;-)\n. +1 for V3\n. @stirringhalo did a great job here... Big \"thank you\" belongs to him!\nBTW It seems there is a space for a small improvement on the Eiffel tower shape:\n\nhttps://www.mapbox.com/bites/00295/streets.html\nvs\n\n. FYI https://github.com/mapbox/mapbox-gl-style-spec/issues/456#issuecomment-221927660. Yes. We may need help of community on porting the existing open CartoCSS styles from MapBox schema to the new tile schema.\n. TileServer GL Light is lightweight - and runs everywhere where node.js runs - no limits. It serves only PBF vector tiles - it does not render raster tiles (PNG/JPEG) from these on the server. Any cheap VPS is fine. Test performance on your selected hosting platform for the number of visits you need.\nTileServer GL renders the tiles on the server side - and needs better hardware and must be used with a cache for serious deploy. Binary libraries are compiled only for 64bit systems - elsewhere you need to compile yourself. Loadbalancer recommended.\nThis discussion belongs to repository https://github.com/klokantech/tileserver-gl where is the code of the project.\nBe aware of legal issues with deploying OSM2VectorTiles tiles #387\n. We can provide you with the source code of our sample mobile app which is able to read MBTiles offline directly.\nSee \"OSM2VectorTiles\" on Google Play or App Store - and contact info@klokantech.com.\n. url is \"mbtiles://planet.mbtiles\", but you need our source code.\nIt is available here: https://openmaptiles.com/mobile-app/. Looks like a duplicate to this request:\nhttps://github.com/mapbox/mbtiles-spec/issues/43\nThe documentation should happen on the mbtiles-spec repo probably...\n. Answer to 4 is https://github.com/mapbox/serialtiles-spec\nWe are working on the updates at @klokantech\n. Great. Thanks!\nPart of the work on 3d has been done already in OSM2VectorTiles V3 / OpenMapTiles:\nhttps://openmaptiles.github.io/klokantech-3d-gl-style/#14.47/40.7086/-74.0049/16/56\nPlease see: https://github.com/openmaptiles/openmaptiles/tree/master/layers/building. TileServer GL runs behind HTTPS very well. We use it always on deploy.\nSee for example: https://demo.tileserver.org/\nRelevant:\nhttp://tileserver.readthedocs.io/en/latest/deployment.html#running-behind-a-proxy-or-a-load-balancer. This will probably fail for files larger then 5GB.\nIn case we may allow user to make larger files then multipart boto upload is required:\nhttp://stackoverflow.com/questions/10355941/how-can-i-copy-files-bigger-than-5-gb-in-amazon-s3\n. ",
    "lukasmartinelli": "Perhaps this is something worth looking into:\nhttps://github.com/systemed/tilemaker\nIf tilemaker can already export vector tiles from OSM that are well suited for applying an OSM bright visual style later on, it would make live much easier because it is a single binary without the stack.\n. > TileMaker puts everything into RAM and does not use Mapnik to define the styles. So, it seems it will never be able to render whole world OSM planet and it would be hard to modify for custom Mapnik styles (only with coding in lua). I think this is not a good idea...\nDidn't know this. Let's start with the proposed approach from the video.\n. Explanation of TM2Source:\nMapnik style produces PBFs. You don't care about the look at feel, you care about what is available at which zoom level. XML of Mapnik (Style) to define the layers.\n. Answer from Yuri from Kartotherian to this question.\nTilelive vs native Mapnik\nFrom what we know you use tilelive to create the vector tiles which uses node-mapnik under the hood. Do you think calling the code from Node causes much overhead?\nAn other alternative would be to use mod_renderd and mod_tile as Apache modules to generate the raster tiles directly with Mapnik without any Node code in between. We hope to gain performance from this approach, but we don\u2019t see any examples of people doing this and it seems we would have to compile a custom Mapnik version. Any advice on that?\n\nThis is how OSM was built - everyone has been using mod_renderd + mod_tile.  But, most experts have told us that this approach has no future. Generating raster images do not scale for high DPI devices, require large infrastructure for image caching, cannot easily support multiple languages, cannot be easily re-styled, and many other problems. That's why Mapbox has implemented vector tiles in Mapnik, and that's why they are switching to WebGL in-browser rendering instead of the raster. Moreover, there has been some conversations about switching osm.org to Kartotherian as well.\nYes, implementing everything in Assembler can always be made faster than in C++, and C++ can be made faster than Node.  The problem is, as always - resources. The time required to make the entire system in C++ is too costly, and would produce results that are not that different from nodejs. Since we are using an extremely efficient caching layer in front of the nodejs servers, plus good SSD disks, we don't think that saving a few extra CPU milliseconds will make a large difference. On the other hand, the nodejs flexibility allowed us to implement the whole system in a few months using ready-made components, something that we could have never achieved with C++. Plus, the system is extremely easy to maintain since our code is less than 10 small files.\n. Answer from Max from Kartotherian to this question.\n\nTilelive vs native Mapnik\nFrom what we know you use tilelive to create the vector tiles which uses node-mapnik under the hood. Do you think calling the code from Node causes much overhead?\n\nNode is just plumbing, all the heavy stuff is done in native code.\n\nAn other alternative would be to use mod_renderd and mod_tile as Apache modules to generate the raster tiles directly with Mapnik without any Node code in between. We hope to gain performance from this approach, but we don\u2019t see any examples of people doing this and it seems we would have to compile a custom Mapnik version. Any advice on that?\n\nBy mod_renderd you mean renderd? Standard OSM stack has a load of problems which resulted in its maintenance-only development and slow dying out:\n- It does not scale.\n- Cache misses result in slowwww metatile generation on the fly.\n- No vector support.\n- High storage requirements.\n. > BTW we work on improved tessera: https://github.com/klokantech/tileserver-tessera/issues on docker hub at https://hub.docker.com/r/klokantech/tileserver-tessera/\n\nI will set up a raster tile server on Switch infrastructure based on the forked tessera version.\nYou still recommend hosting the vector tiles with tileserver-php?\nOr should we use tessera, because MBTiles serving is fixed in tessera now.\n. Out of scope for the bachelor thesis.\n. The only visual style we have to change would be the fonts (because they are custom Mapbox licensed). But this is we serving the tiles, not when the user styles the vectortiles MBTiles in Mapbox Studio.\nWe could search and replace the custom licensed fonts in our tileserver and replace them with their OSS alternatives (like we do it already with the source url).\n. > Regarding Open Source Fonts: OSM main map took \"DejaVu Sans\" (http://dejavu-fonts.org ) because it's one of the few fonts which support non-european languages (like Hebrew).\nYes supporting original place names is very important.\nThe new Mapbox specification also supports all labels in English, Spanish, French, German, Russian and Chinese.\n. Kartotherian uses Google Noto for http://maps.wikimedia.org\nhttps://github.com/kartotherian/osm-bright.fonts\n. Spun up a new server for testing Switzerland: AWS r3.xlarge with 5 x 100GB EBS volumes attached in raid-0.\nFor switzerland imposm took 4.5 minutes and osm2pgsql took 29 minutes. \nSwitzerland with imposm:\n[Oct  8 19:01:48] [INFO] [reader] reading /data/import/switzerland-latest.osm.pbf with data till 2015-10-07 21:22:03 +0000 UTC\n[Oct  8 19:02:38] [INFO] [   50s] C:  897000/s (26000465) N:    6700/s (194598) W:  149100/s (3136392) R:      0/s (26979)\n[Oct  8 19:02:39] [INFO] Reading OSM data took: 50.477994381s\n[Oct  8 19:02:39] [INFO] Imposm took: 50.478111688s\n[Oct  8 19:02:39] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  8 19:02:39] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  8 19:02:41] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  8 19:03:00] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  8 19:03:39] [INFO] [  1m0s] C:       0/s (0) N:       0/s (0) W:   16000/s (605720) R:   1390/s (26979)\n[Oct  8 19:04:39] [INFO] [  2m0s] C:       0/s (0) N:       0/s (0) W:   17800/s (1748973) R:   1390/s (26979)\n[Oct  8 19:05:39] [INFO] [  3m0s] C:       0/s (0) N:       0/s (0) W:   18600/s (2944070) R:   1390/s (26979)\n[Oct  8 19:05:47] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  8 19:05:54] [INFO] [ 3m15s] C:       0/s (0) N:   35700/s (194598) W:   18700/s (3136392) R:   1390/s (26979)\n[Oct  8 19:05:54] [INFO] Writing OSM data took: 3m15.675655898s\n[Oct  8 19:05:55] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen1 took: 1.114519817s\n[Oct  8 19:05:58] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen1 took: 3.979092028s\n[Oct  8 19:06:00] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen1 took: 5.515614097s\n[Oct  8 19:06:17] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen1 took: 22.617553173s\n[Oct  8 19:06:18] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen0 took: 891.743444ms\n[Oct  8 19:06:18] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen0 took: 1.406280582s\n[Oct  8 19:06:19] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen0 took: 2.303304275s\n[Oct  8 19:06:22] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen0 took: 5.330423867s\n[Oct  8 19:06:22] [INFO] [PostGIS] Creating generalized tables took: 27.94897963s\n[Oct  8 19:06:23] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers_interpolated took: 374.013157ms\n[Oct  8 19:06:23] [INFO] [PostGIS] Creating geometry index on osm_housenumbers_interpolated took: 124.236229ms\n[Oct  8 19:06:23] [INFO] [PostGIS] Creating OSM id index on osm_barrierways took: 521.219538ms\n[Oct  8 19:06:23] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers took: 551.233773ms\n[Oct  8 19:06:23] [INFO] [PostGIS] Creating OSM id index on osm_places took: 472.848479ms\n[Oct  8 19:06:24] [INFO] [PostGIS] Creating geometry index on osm_barrierways took: 1.249736997s\n[Oct  8 19:06:24] [INFO] [PostGIS] Creating OSM id index on osm_waterways took: 2.092327647s\n[Oct  8 19:06:24] [INFO] [PostGIS] Creating geometry index on osm_places took: 1.129064757s\n[Oct  8 19:06:25] [INFO] [PostGIS] Creating OSM id index on osm_landusages took: 678.627749ms\n[Oct  8 19:06:26] [INFO] [PostGIS] Creating geometry index on osm_waterways took: 1.866522358s\n[Oct  8 19:06:26] [INFO] [PostGIS] Creating geometry index on osm_housenumbers took: 3.421333202s\n[Oct  8 19:06:26] [INFO] [PostGIS] Creating OSM id index on osm_minorroads took: 2.387227069s\n[Oct  8 19:06:26] [INFO] [PostGIS] Creating OSM id index on osm_aeroways took: 244.434574ms\n[Oct  8 19:06:27] [INFO] [PostGIS] Creating geometry index on osm_aeroways took: 566.096004ms\n[Oct  8 19:06:27] [INFO] [PostGIS] Creating OSM id index on osm_mainroads took: 966.640456ms\n[Oct  8 19:06:27] [INFO] [PostGIS] Creating OSM id index on osm_amenities took: 224.095755ms\n[Oct  8 19:06:28] [INFO] [PostGIS] Creating geometry index on osm_amenities took: 509.261974ms\n[Oct  8 19:06:29] [INFO] [PostGIS] Creating geometry index on osm_mainroads took: 1.37146749s\n[Oct  8 19:06:29] [INFO] [PostGIS] Creating OSM id index on osm_transport_areas took: 11.799328ms\n[Oct  8 19:06:29] [INFO] [PostGIS] Creating geometry index on osm_transport_areas took: 19.098144ms\n[Oct  8 19:06:29] [INFO] [PostGIS] Creating OSM id index on osm_admin took: 12.384452ms\n[Oct  8 19:06:29] [INFO] [PostGIS] Creating geometry index on osm_admin took: 49.641228ms\n[Oct  8 19:06:29] [INFO] [PostGIS] Creating OSM id index on osm_motorways took: 20.037053ms\n[Oct  8 19:06:29] [INFO] [PostGIS] Creating geometry index on osm_motorways took: 138.838063ms\n[Oct  8 19:06:29] [INFO] [PostGIS] Creating OSM id index on osm_transport_points took: 69.111387ms\n[Oct  8 19:06:30] [INFO] [PostGIS] Creating geometry index on osm_transport_points took: 863.340401ms\n[Oct  8 19:06:30] [INFO] [PostGIS] Creating OSM id index on osm_barrierpoints took: 22.315041ms\n[Oct  8 19:06:30] [INFO] [PostGIS] Creating geometry index on osm_barrierpoints took: 175.763751ms\n[Oct  8 19:06:30] [INFO] [PostGIS] Creating geometry index on osm_landusages took: 4.960480183s\n[Oct  8 19:06:30] [INFO] [PostGIS] Creating OSM id index on osm_waterareas took: 47.206186ms\n[Oct  8 19:06:31] [INFO] [PostGIS] Creating geometry index on osm_waterareas took: 579.374073ms\n[Oct  8 19:06:31] [INFO] [PostGIS] Creating OSM id index on osm_buildings took: 2.828438222s\n[Oct  8 19:06:31] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen1 took: 26.736237ms\n[Oct  8 19:06:31] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen1 took: 7.411517ms\n[Oct  8 19:06:31] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen0 took: 7.111796ms\n[Oct  8 19:06:31] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen0 took: 3.342948ms\n[Oct  8 19:06:31] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen0 took: 247.124837ms\n[Oct  8 19:06:31] [INFO] [PostGIS] Creating OSM id index on osm_roads took: 1.085797733s\n[Oct  8 19:06:34] [INFO] [PostGIS] Creating geometry index on osm_roads_gen0 took: 2.767046277s\n[Oct  8 19:06:34] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen1 took: 182.499145ms\n[Oct  8 19:06:37] [INFO] [PostGIS] Creating geometry index on osm_roads_gen1 took: 2.808771024s\n[Oct  8 19:06:37] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen0 took: 72.99682ms\n[Oct  8 19:06:38] [INFO] [PostGIS] Creating geometry index on osm_waterways_gen0 took: 1.133336945s\n[Oct  8 19:06:38] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen1 took: 180.868219ms\n[Oct  8 19:06:39] [INFO] [PostGIS] Creating geometry index on osm_waterways_gen1 took: 879.558087ms\n[Oct  8 19:06:39] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen1 took: 74.374641ms\n[Oct  8 19:06:40] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen1 took: 715.557869ms\n[Oct  8 19:06:40] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen0 took: 25.181952ms\n[Oct  8 19:06:40] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen0 took: 95.305991ms\n[Oct  8 19:06:43] [INFO] [PostGIS] Creating geometry index on osm_minorroads took: 16.892934203s\n[Oct  8 19:06:48] [INFO] [PostGIS] Creating geometry index on osm_roads took: 16.63839296s\n[Oct  8 19:07:00] [INFO] [PostGIS] Creating geometry index on osm_buildings took: 29.520873669s\n[Oct  8 19:07:00] [INFO] [PostGIS] Creating geometry indices took: 37.852974286s\n[Oct  8 19:07:00] [INFO] Importing OSM data took: 4m21.477717575s\n[Oct  8 19:07:00] [INFO] Imposm took: 4m21.477756346s\nSwitzerland with osm2pgsql:\n```\nosm2pgsql SVN version 0.87.2 (64bit id space)\nUsing built-in tag processing pipeline\nUsing projection SRS 900913 (Spherical Mercator)\nSetting up table: planet_osm_point\nSetting up table: planet_osm_line\nSetting up table: planet_osm_polygon\nSetting up table: planet_osm_roads\nAllocating memory for dense node cache\nAllocating dense node cache in one big chunk\nAllocating memory for sparse node cache\nSharing dense sparse\nNode-cache: cache=2000MB, maxblocks=256000*8192, allocation method=11\nMid: loading persistent node cache from /data/cache/nodes.bin\nFailed to allocate space for node cache file: No space on disk\nError occurred, cleaning up\nreal    0m0.131s\nuser    0m0.004s\nsys 0m0.017s\ncore@ip-10-81-155-115 /data $ docker run --name osm2pgsql \\\n\n-v /data/import2:/data/import \\\n-v /data/cache:/data/cache \\\n--link postgis:db \\\n-e PROC_NUM=4 \\\n-e NODES_CACHE=2000 \\\n--rm osm2vectortiles/osm2pgsql bash -c 'time ./import.sh'\n\nError response from daemon: Cannot find child for /osm2pgsql\ncore@ip-10-81-155-115 /data $ docker rm -f osm2pgsql\nError response from daemon: no such id: osm2pgsql\nError: failed to remove containers: [osm2pgsql]\ncore@ip-10-81-155-115 /data $ docker run --name osm2pgsql \\\n    -v /data/import2:/data/import \\\n    -v /data/cache:/data/cache \\\n    --link postgis:db \\\n    -e PROC_NUM=4 \\\n    -e NODES_CACHE=2000 \\\n    --rm osm2vectortiles/osm2pgsql bash -c 'time ./import.sh'\nosm2pgsql SVN version 0.87.2 (64bit id space)\n\nUsing built-in tag processing pipeline\nUsing projection SRS 900913 (Spherical Mercator)\nSetting up table: planet_osm_point\nSetting up table: planet_osm_line\nSetting up table: planet_osm_polygon\nSetting up table: planet_osm_roads\nAllocating memory for dense node cache\nAllocating dense node cache in one big chunk\nAllocating memory for sparse node cache\nSharing dense sparse\nNode-cache: cache=2000MB, maxblocks=256000*8192, allocation method=11\nMid: loading persistent node cache from /data/cache/nodes.bin\nAllocated space for persistent node cache file\nMaximum node in persistent node cache: 0\nMid: pgsql, scale=100 cache=2000\nSetting up table: planet_osm_nodes\nSetting up table: planet_osm_ways\nSetting up table: planet_osm_rels\nReading in file: /data/import/switzerland-latest.osm.pbf\nProcessing: Node(26000k 44.9k/s) Way(3136k 27.76k/s) Relation(51220 98.50/s)  parse time: 1212s\nNode stats: total(26000465), max(3777398230) in 579s\nWay stats: total(3136392), max(374362950) in 113s\nRelation stats: total(51224), max(5568014) in 520s\nMaximum node in persistent node cache: 3778019327\nCommitting transaction for planet_osm_point\nCommitting transaction for planet_osm_line\nCommitting transaction for planet_osm_polygon\nCommitting transaction for planet_osm_roads\nMid: loading persistent node cache from /data/cache/nodes.bin\nMaximum node in persistent node cache: 3778019327\nSetting up table: planet_osm_nodes\nSetting up table: planet_osm_ways\nSetting up table: planet_osm_rels\nUsing built-in tag processing pipeline\nMid: loading persistent node cache from /data/cache/nodes.bin\nMaximum node in persistent node cache: 3778019327\nSetting up table: planet_osm_nodes\nSetting up table: planet_osm_ways\nSetting up table: planet_osm_rels\nUsing built-in tag processing pipeline\nMid: loading persistent node cache from /data/cache/nodes.bin\nMaximum node in persistent node cache: 3778019327\nSetting up table: planet_osm_nodes\nSetting up table: planet_osm_ways\nSetting up table: planet_osm_rels\nUsing built-in tag processing pipeline\nMid: loading persistent node cache from /data/cache/nodes.bin\nMaximum node in persistent node cache: 3778019327\nSetting up table: planet_osm_nodes\nSetting up table: planet_osm_ways\nSetting up table: planet_osm_rels\nUsing built-in tag processing pipeline\nGoing over pending ways...\n    2096534 ways are pending\nUsing 4 helper-processes\nFinished processing 2096534 ways in 240 sec\n2096534 Pending ways took 240s at a rate of 8735.56/s\nCommitting transaction for planet_osm_point\nCommitting transaction for planet_osm_line\nCommitting transaction for planet_osm_polygon\nCommitting transaction for planet_osm_roads\nCommitting transaction for planet_osm_point\nCommitting transaction for planet_osm_line\nCommitting transaction for planet_osm_polygon\nCommitting transaction for planet_osm_roads\nCommitting transaction for planet_osm_point\nCommitting transaction for planet_osm_line\nCommitting transaction for planet_osm_polygon\nCommitting transaction for planet_osm_roads\nCommitting transaction for planet_osm_point\nCommitting transaction for planet_osm_line\nCommitting transaction for planet_osm_polygon\nCommitting transaction for planet_osm_roads\nGoing over pending relations...\n    0 relations are pending\nUsing 4 helper-processes\nFinished processing 0 relations in 0 sec\nCommitting transaction for planet_osm_point\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_line\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_polygon\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_roads\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_point\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_line\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_polygon\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_roads\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_point\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_line\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_polygon\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_roads\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_point\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_line\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_polygon\nWARNING:  there is no transaction in progress\nCommitting transaction for planet_osm_roads\nWARNING:  there is no transaction in progress\nSorting data and creating indexes for planet_osm_point\nStopping table: planet_osm_nodes\nStopped table: planet_osm_nodes in 0s\nSorting data and creating indexes for planet_osm_line\nStopping table: planet_osm_ways\nBuilding index on table: planet_osm_ways\nStopping table: planet_osm_rels\nBuilding index on table: planet_osm_rels\nSorting data and creating indexes for planet_osm_roads\nSorting data and creating indexes for planet_osm_polygon\nStopped table: planet_osm_rels in 4s\nCopying planet_osm_roads to cluster by geometry finished\nCreating geometry index on  planet_osm_roads\nCreating osm_id index on  planet_osm_roads\nCreating indexes on  planet_osm_roads finished\nAll indexes on  planet_osm_roads created  in 18s\nCompleted planet_osm_roads\nCopying planet_osm_point to cluster by geometry finished\nCreating geometry index on  planet_osm_point\nCopying planet_osm_line to cluster by geometry finished\nCreating geometry index on  planet_osm_line\nCreating osm_id index on  planet_osm_point\nCreating indexes on  planet_osm_point finished\nAll indexes on  planet_osm_point created  in 78s\nCompleted planet_osm_point\nCopying planet_osm_polygon to cluster by geometry finished\nCreating geometry index on  planet_osm_polygon\nCreating osm_id index on  planet_osm_line\nCreating indexes on  planet_osm_line finished\nAll indexes on  planet_osm_line created  in 164s\nCompleted planet_osm_line\nCreating osm_id index on  planet_osm_polygon\nCreating indexes on  planet_osm_polygon finished\nAll indexes on  planet_osm_polygon created  in 231s\nCompleted planet_osm_polygon\nStopped table: planet_osm_ways in 277s\nMaximum node in persistent node cache: 3778019327\nMaximum node in persistent node cache: 3778019327\nMaximum node in persistent node cache: 3778019327\nMaximum node in persistent node cache: 3778019327\nnode cache: stored: 26000465(100.00%), storage efficiency: 51.94% (dense blocks: 5799, sparse nodes: 22058558), hit rate: 100.14%\nOsm2pgsql took 1730s overall\nSuccessfully imported /data/import/switzerland-latest.osm.pbf\nreal    28m49.315s\nuser    11m41.307s\nsys 1m58.139s\n```\n. https://drive.google.com/open?id=0B56n5MCkYKPreUtydXlQc19xUjg\nSwitzerland rendered from z8 to z14 in latest run of #43 \n. I imported the latest planet pbf with imposm. The generalized tables take a lot of time (they will save some time when generating the mbtiles though).\nNext step will be to export the MBTiles.\nWhile this is a long time I think we can live with it when we provide an updated MBTiles file every week.\n[Oct  6 13:21:29] [INFO] [reader] reading /data/import/planet-latest.osm.pbf with data till 2015-09-28 02:00:00 +0000 UTC\n[Oct  6 13:22:29] [INFO] [  1m0s] C: 1262000/s (73824000) N:    7500/s (442841) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:23:29] [INFO] [  2m0s] C: 1306000/s (155456000) N:    7500/s (894933) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:24:29] [INFO] [  3m0s] C: 1272000/s (227152000) N:    9100/s (1637167) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:25:29] [INFO] [  4m0s] C: 1234000/s (294960000) N:   13500/s (3234019) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:26:29] [INFO] [  5m0s] C: 1250000/s (373104000) N:   13100/s (3937425) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:27:29] [INFO] [  6m0s] C: 1241000/s (445136000) N:   14200/s (5093122) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:28:29] [INFO] [  7m0s] C: 1228000/s (514592000) N:   13900/s (5829468) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:29:29] [INFO] [  8m0s] C: 1234000/s (591104000) N:   13500/s (6474629) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:30:29] [INFO] [  9m0s] C: 1243000/s (669520000) N:   14200/s (7686464) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:31:29] [INFO] [ 10m0s] C: 1248000/s (747696000) N:   15600/s (9346084) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:32:29] [INFO] [ 11m0s] C: 1256000/s (827984000) N:   15400/s (10180688) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:33:29] [INFO] [ 12m0s] C: 1266000/s (909920000) N:   15900/s (11448059) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:34:29] [INFO] [ 13m0s] C: 1275000/s (993456000) N:   16200/s (12671317) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:35:29] [INFO] [ 14m0s] C: 1287000/s (1079888000) N:   15900/s (13355243) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:36:29] [INFO] [ 15m0s] C: 1297000/s (1166784000) N:   15300/s (13824203) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:37:29] [INFO] [ 16m0s] C: 1305000/s (1250976000) N:   14800/s (14271043) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:38:29] [INFO] [ 17m0s] C: 1310000/s (1335168000) N:   14700/s (15009219) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:39:29] [INFO] [ 18m0s] C: 1318000/s (1421488000) N:   14400/s (15631356) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:40:29] [INFO] [ 19m0s] C: 1324000/s (1509072000) N:   14200/s (16179265) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:41:29] [INFO] [ 20m0s] C: 1334000/s (1598992000) N:   14000/s (16820115) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:42:29] [INFO] [ 21m0s] C: 1343000/s (1690432000) N:   14100/s (17788289) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:43:29] [INFO] [ 22m0s] C: 1348000/s (1779200000) N:   14200/s (18801370) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:44:29] [INFO] [ 23m0s] C: 1355000/s (1869088000) N:   14500/s (20012250) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:45:29] [INFO] [ 24m0s] C: 1361000/s (1959296000) N:   14600/s (21136325) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:46:29] [INFO] [ 25m0s] C: 1367000/s (2048480000) N:   14800/s (22289505) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:47:29] [INFO] [ 26m0s] C: 1372000/s (2139072000) N:   15200/s (23735098) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:48:29] [INFO] [ 27m0s] C: 1376000/s (2228208000) N:   17000/s (27537558) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:49:29] [INFO] [ 28m0s] C: 1381000/s (2318944000) N:   19500/s (32847123) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:50:29] [INFO] [ 29m0s] C: 1387000/s (2411296000) N:   20300/s (35345057) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:51:29] [INFO] [ 30m0s] C: 1391000/s (2502864000) N:   20500/s (37024299) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:52:29] [INFO] [ 31m0s] C: 1395000/s (2593728000) N:   21100/s (39367048) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:53:29] [INFO] [ 32m0s] C: 1398000/s (2684192000) N:   21000/s (40452624) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:54:29] [INFO] [ 33m0s] C: 1402000/s (2775520000) N:   20800/s (41327738) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:55:29] [INFO] [ 34m0s] C: 1406000/s (2867744000) N:   20600/s (42117354) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:56:29] [INFO] [ 35m0s] C: 1409000/s (2958784000) N:   20400/s (42933262) W:       0/s (0) R:      0/s (0)\n[Oct  6 13:57:29] [INFO] [ 36m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  860000/s (2000000) R:      0/s (0)\n[Oct  6 13:58:29] [INFO] [ 37m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  558500/s (35032000) R:      0/s (0)\n[Oct  6 13:59:29] [INFO] [ 38m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  519200/s (63464000) R:      0/s (0)\n[Oct  6 14:00:29] [INFO] [ 39m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  510900/s (93104000) R:      0/s (0)\n[Oct  6 14:01:29] [INFO] [ 40m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  505100/s (122432000) R:      0/s (0)\n[Oct  6 14:02:29] [INFO] [ 41m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  510000/s (148792000) R:      0/s (0)\n[Oct  6 14:03:29] [INFO] [ 42m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  502500/s (182280000) R:      0/s (0)\n[Oct  6 14:04:29] [INFO] [ 43m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  492300/s (207896000) R:      0/s (0)\n[Oct  6 14:05:29] [INFO] [ 44m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  501800/s (241984000) R:      0/s (0)\n[Oct  6 14:06:29] [INFO] [ 45m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  498100/s (270664000) R:      0/s (0)\n[Oct  6 14:07:29] [INFO] [ 46m0s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  510100/s (307224000) R:      0/s (0)\n[Oct  6 14:07:51] [INFO] [46m22s] C: 1412000/s (3046040299) N:   20300/s (43823052) W:  499600/s (309876032) R: 464220/s (2094057)\n[Oct  6 14:07:52] [INFO] Reading OSM data took: 46m23.40921214s\n[Oct  6 14:07:52] [INFO] Imposm took: 46m23.409403024s\n[Oct  6 14:07:52] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  6 14:07:52] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  6 14:07:57] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  6 14:08:52] [INFO] [  1m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:    730/s (40581)\n[Oct  6 14:09:52] [INFO] [  2m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1110/s (127715)\n[Oct  6 14:10:52] [INFO] [  3m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1170/s (206024)\n[Oct  6 14:11:52] [INFO] [  4m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1330/s (313903)\n[Oct  6 14:12:52] [INFO] [  5m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1290/s (382146)\n[Oct  6 14:13:37] [INFO] [GEOS] TopologyException: side location conflict at 1262953.6463945815 5372535.5919273971\n[Oct  6 14:13:52] [INFO] [  6m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1360/s (484223)\n[Oct  6 14:14:52] [INFO] [  7m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1560/s (651901)\n[Oct  6 14:15:52] [INFO] [  8m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1790/s (853842)\n[Oct  6 14:16:52] [INFO] [  9m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1930/s (1037181)\n[Oct  6 14:17:52] [INFO] [ 10m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   2030/s (1212932)\n[Oct  6 14:18:52] [INFO] [ 11m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   2210/s (1453122)\n[Oct  6 14:19:52] [INFO] [ 12m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   2320/s (1659129)\n[Oct  6 14:20:52] [INFO] [ 13m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   2430/s (1843690)\n[Oct  6 14:21:52] [INFO] [ 14m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   2340/s (1962809)\n[Oct  6 14:22:15] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  6 14:22:52] [INFO] [ 15m0s] C:       0/s (0) N:       0/s (0) W:   18700/s (318343) R:   2440/s (2094057)\n[Oct  6 14:23:52] [INFO] [ 16m0s] C:       0/s (0) N:       0/s (0) W:    6600/s (650197) R:   2440/s (2094057)\n[Oct  6 14:24:52] [INFO] [ 17m0s] C:       0/s (0) N:       0/s (0) W:   10100/s (1586114) R:   2440/s (2094057)\n[Oct  6 14:25:52] [INFO] [ 18m0s] C:       0/s (0) N:       0/s (0) W:   14900/s (3144348) R:   2440/s (2094057)\n[Oct  6 14:26:52] [INFO] [ 19m0s] C:       0/s (0) N:       0/s (0) W:   15800/s (4371026) R:   2440/s (2094057)\n[Oct  6 14:27:52] [INFO] [ 20m0s] C:       0/s (0) N:       0/s (0) W:   16000/s (5401228) R:   2440/s (2094057)\n[Oct  6 14:28:52] [INFO] [ 21m0s] C:       0/s (0) N:       0/s (0) W:   16800/s (6600096) R:   2440/s (2094057)\n[Oct  6 14:29:52] [INFO] [ 22m0s] C:       0/s (0) N:       0/s (0) W:   16200/s (7416841) R:   2440/s (2094057)\n[Oct  6 14:30:52] [INFO] [ 23m0s] C:       0/s (0) N:       0/s (0) W:   16000/s (8240422) R:   2440/s (2094057)\n[Oct  6 14:31:52] [INFO] [ 24m0s] C:       0/s (0) N:       0/s (0) W:   15300/s (8827459) R:   2440/s (2094057)\n[Oct  6 14:32:52] [INFO] [ 25m0s] C:       0/s (0) N:       0/s (0) W:   15100/s (9501124) R:   2440/s (2094057)\n[Oct  6 14:33:52] [INFO] [ 26m0s] C:       0/s (0) N:       0/s (0) W:   14500/s (10129632) R:   2440/s (2094057)\n[Oct  6 14:34:52] [INFO] [ 27m0s] C:       0/s (0) N:       0/s (0) W:   14800/s (11169269) R:   2440/s (2094057)\n[Oct  6 14:35:52] [INFO] [ 28m0s] C:       0/s (0) N:       0/s (0) W:   16400/s (13407296) R:   2440/s (2094057)\n[Oct  6 14:36:52] [INFO] [ 29m0s] C:       0/s (0) N:       0/s (0) W:   16300/s (14368620) R:   2440/s (2094057)\n[Oct  6 14:37:52] [INFO] [ 30m0s] C:       0/s (0) N:       0/s (0) W:   16400/s (15408481) R:   2440/s (2094057)\n[Oct  6 14:38:52] [INFO] [ 31m0s] C:       0/s (0) N:       0/s (0) W:   16600/s (16577696) R:   2440/s (2094057)\n[Oct  6 14:39:52] [INFO] [ 32m0s] C:       0/s (0) N:       0/s (0) W:   16600/s (17643039) R:   2440/s (2094057)\n[Oct  6 14:40:52] [INFO] [ 33m0s] C:       0/s (0) N:       0/s (0) W:   16800/s (18804019) R:   2440/s (2094057)\n[Oct  6 14:41:52] [INFO] [ 34m0s] C:       0/s (0) N:       0/s (0) W:   17100/s (20140872) R:   2440/s (2094057)\n[Oct  6 14:42:52] [INFO] [ 35m0s] C:       0/s (0) N:       0/s (0) W:   17200/s (21325848) R:   2440/s (2094057)\n[Oct  6 14:43:52] [INFO] [ 36m0s] C:       0/s (0) N:       0/s (0) W:   17400/s (22609059) R:   2440/s (2094057)\n[Oct  6 14:44:52] [INFO] [ 37m0s] C:       0/s (0) N:       0/s (0) W:   17500/s (23829731) R:   2440/s (2094057)\n[Oct  6 14:45:52] [INFO] [ 38m0s] C:       0/s (0) N:       0/s (0) W:   18000/s (25620949) R:   2440/s (2094057)\n[Oct  6 14:46:52] [INFO] [ 39m0s] C:       0/s (0) N:       0/s (0) W:   18100/s (26869589) R:   2440/s (2094057)\n[Oct  6 14:47:52] [INFO] [ 40m0s] C:       0/s (0) N:       0/s (0) W:   18300/s (28133045) R:   2440/s (2094057)\n[Oct  6 14:48:52] [INFO] [ 41m0s] C:       0/s (0) N:       0/s (0) W:   18300/s (29312091) R:   2440/s (2094057)\n[Oct  6 14:49:52] [INFO] [ 42m0s] C:       0/s (0) N:       0/s (0) W:   18400/s (30553496) R:   2440/s (2094057)\n[Oct  6 14:50:52] [INFO] [ 43m0s] C:       0/s (0) N:       0/s (0) W:   18500/s (31875006) R:   2440/s (2094057)\n[Oct  6 14:51:52] [INFO] [ 44m0s] C:       0/s (0) N:       0/s (0) W:   19000/s (33880906) R:   2440/s (2094057)\n[Oct  6 14:52:52] [INFO] [ 45m0s] C:       0/s (0) N:       0/s (0) W:   19200/s (35401176) R:   2440/s (2094057)\n[Oct  6 14:53:52] [INFO] [ 46m0s] C:       0/s (0) N:       0/s (0) W:   19600/s (37200188) R:   2440/s (2094057)\n[Oct  6 14:54:52] [INFO] [ 47m0s] C:       0/s (0) N:       0/s (0) W:   19800/s (38779944) R:   2440/s (2094057)\n[Oct  6 14:55:52] [INFO] [ 48m0s] C:       0/s (0) N:       0/s (0) W:   19600/s (39655396) R:   2440/s (2094057)\n[Oct  6 14:56:52] [INFO] [ 49m0s] C:       0/s (0) N:       0/s (0) W:   19700/s (40965264) R:   2440/s (2094057)\n[Oct  6 14:57:52] [INFO] [ 50m0s] C:       0/s (0) N:       0/s (0) W:   20200/s (43179103) R:   2440/s (2094057)\n[Oct  6 14:58:52] [INFO] [ 51m0s] C:       0/s (0) N:       0/s (0) W:   20500/s (45090328) R:   2440/s (2094057)\n[Oct  6 14:59:52] [INFO] [ 52m0s] C:       0/s (0) N:       0/s (0) W:   20600/s (46539426) R:   2440/s (2094057)\n[Oct  6 15:00:52] [INFO] [ 53m0s] C:       0/s (0) N:       0/s (0) W:   20500/s (47607955) R:   2440/s (2094057)\n[Oct  6 15:01:52] [INFO] [ 54m0s] C:       0/s (0) N:       0/s (0) W:   20900/s (49845931) R:   2440/s (2094057)\n[Oct  6 15:02:52] [INFO] [ 55m0s] C:       0/s (0) N:       0/s (0) W:   20700/s (50567042) R:   2440/s (2094057)\n[Oct  6 15:03:52] [INFO] [ 56m0s] C:       0/s (0) N:       0/s (0) W:   20800/s (51638919) R:   2440/s (2094057)\n[Oct  6 15:04:52] [INFO] [ 57m0s] C:       0/s (0) N:       0/s (0) W:   20600/s (52911786) R:   2440/s (2094057)\n[Oct  6 15:05:52] [INFO] [ 58m0s] C:       0/s (0) N:       0/s (0) W:   20500/s (53702326) R:   2440/s (2094057)\n[Oct  6 15:06:52] [INFO] [ 59m0s] C:       0/s (0) N:       0/s (0) W:   20300/s (53977837) R:   2440/s (2094057)\n[Oct  6 15:07:52] [INFO] [1h0m0s] C:       0/s (0) N:       0/s (0) W:   20100/s (55213528) R:   2440/s (2094057)\n[Oct  6 15:08:52] [INFO] [1h1m0s] C:       0/s (0) N:       0/s (0) W:   20300/s (56821654) R:   2440/s (2094057)\n[Oct  6 15:09:52] [INFO] [1h2m0s] C:       0/s (0) N:       0/s (0) W:   20300/s (58150078) R:   2440/s (2094057)\n[Oct  6 15:10:52] [INFO] [1h3m0s] C:       0/s (0) N:       0/s (0) W:   20300/s (59422604) R:   2440/s (2094057)\n[Oct  6 15:11:52] [INFO] [1h4m0s] C:       0/s (0) N:       0/s (0) W:   20500/s (61029227) R:   2440/s (2094057)\n[Oct  6 15:12:52] [INFO] [1h5m0s] C:       0/s (0) N:       0/s (0) W:   20500/s (62527452) R:   2440/s (2094057)\n[Oct  6 15:13:52] [INFO] [1h6m0s] C:       0/s (0) N:       0/s (0) W:   20600/s (63982296) R:   2440/s (2094057)\n[Oct  6 15:14:52] [INFO] [1h7m0s] C:       0/s (0) N:       0/s (0) W:   20800/s (65525671) R:   2440/s (2094057)\n[Oct  6 15:15:52] [INFO] [1h8m0s] C:       0/s (0) N:       0/s (0) W:   20600/s (66538772) R:   2440/s (2094057)\n[Oct  6 15:16:52] [INFO] [1h9m0s] C:       0/s (0) N:       0/s (0) W:   20700/s (67910752) R:   2440/s (2094057)\n[Oct  6 15:17:52] [INFO] [1h10m0s] C:       0/s (0) N:       0/s (0) W:   20700/s (69290495) R:   2440/s (2094057)\n[Oct  6 15:18:52] [INFO] [1h11m0s] C:       0/s (0) N:       0/s (0) W:   20900/s (71049460) R:   2440/s (2094057)\n[Oct  6 15:19:52] [INFO] [1h12m0s] C:       0/s (0) N:       0/s (0) W:   20900/s (72560198) R:   2440/s (2094057)\n[Oct  6 15:20:52] [INFO] [1h13m0s] C:       0/s (0) N:       0/s (0) W:   21000/s (74090887) R:   2440/s (2094057)\n[Oct  6 15:21:52] [INFO] [1h14m0s] C:       0/s (0) N:       0/s (0) W:   21100/s (75727637) R:   2440/s (2094057)\n[Oct  6 15:22:52] [INFO] [1h15m0s] C:       0/s (0) N:       0/s (0) W:   21000/s (75883940) R:   2440/s (2094057)\n[Oct  6 15:23:52] [INFO] [1h16m0s] C:       0/s (0) N:       0/s (0) W:   21000/s (77741909) R:   2440/s (2094057)\n[Oct  6 15:24:52] [INFO] [1h17m0s] C:       0/s (0) N:       0/s (0) W:   20700/s (77944363) R:   2440/s (2094057)\n[Oct  6 15:25:52] [INFO] [1h18m0s] C:       0/s (0) N:       0/s (0) W:   20600/s (78817244) R:   2440/s (2094057)\n[Oct  6 15:26:52] [INFO] [1h19m0s] C:       0/s (0) N:       0/s (0) W:   20600/s (79646159) R:   2440/s (2094057)\n[Oct  6 15:27:52] [INFO] [1h20m0s] C:       0/s (0) N:       0/s (0) W:   20600/s (81231227) R:   2440/s (2094057)\n[Oct  6 15:28:52] [INFO] [1h21m0s] C:       0/s (0) N:       0/s (0) W:   20500/s (82192314) R:   2440/s (2094057)\n[Oct  6 15:29:52] [INFO] [1h22m0s] C:       0/s (0) N:       0/s (0) W:   20400/s (83164037) R:   2440/s (2094057)\n[Oct  6 15:30:52] [INFO] [1h23m0s] C:       0/s (0) N:       0/s (0) W:   20400/s (83930475) R:   2440/s (2094057)\n[Oct  6 15:31:52] [INFO] [1h24m0s] C:       0/s (0) N:       0/s (0) W:   20900/s (87459366) R:   2440/s (2094057)\n[Oct  6 15:32:52] [INFO] [1h25m0s] C:       0/s (0) N:       0/s (0) W:   21500/s (91463192) R:   2440/s (2094057)\n[Oct  6 15:33:52] [INFO] [1h26m0s] C:       0/s (0) N:       0/s (0) W:   22200/s (95532673) R:   2440/s (2094057)\n[Oct  6 15:34:52] [INFO] [1h27m0s] C:       0/s (0) N:       0/s (0) W:   22300/s (97591106) R:   2440/s (2094057)\n[Oct  6 15:35:52] [INFO] [1h28m0s] C:       0/s (0) N:       0/s (0) W:   22500/s (99791198) R:   2440/s (2094057)\n[Oct  6 15:36:52] [INFO] [1h29m0s] C:       0/s (0) N:       0/s (0) W:   22700/s (101679154) R:   2440/s (2094057)\n[Oct  6 15:37:52] [INFO] [1h30m0s] C:       0/s (0) N:       0/s (0) W:   22800/s (103548323) R:   2440/s (2094057)\n[Oct  6 15:38:52] [INFO] [1h31m0s] C:       0/s (0) N:       0/s (0) W:   22900/s (105692337) R:   2440/s (2094057)\n[Oct  6 15:39:52] [INFO] [1h32m0s] C:       0/s (0) N:       0/s (0) W:   23100/s (107737633) R:   2440/s (2094057)\n[Oct  6 15:40:52] [INFO] [1h33m0s] C:       0/s (0) N:       0/s (0) W:   23300/s (110115550) R:   2440/s (2094057)\n[Oct  6 15:41:52] [INFO] [1h34m0s] C:       0/s (0) N:       0/s (0) W:   23500/s (112073960) R:   2440/s (2094057)\n[Oct  6 15:42:52] [INFO] [1h35m0s] C:       0/s (0) N:       0/s (0) W:   23600/s (114295878) R:   2440/s (2094057)\n[Oct  6 15:43:52] [INFO] [1h36m0s] C:       0/s (0) N:       0/s (0) W:   23800/s (116627140) R:   2440/s (2094057)\n[Oct  6 15:44:52] [INFO] [1h37m0s] C:       0/s (0) N:       0/s (0) W:   23900/s (118679208) R:   2440/s (2094057)\n[Oct  6 15:45:52] [INFO] [1h38m0s] C:       0/s (0) N:       0/s (0) W:   24000/s (120871594) R:   2440/s (2094057)\n[Oct  6 15:46:52] [INFO] [1h39m0s] C:       0/s (0) N:       0/s (0) W:   24000/s (121708593) R:   2440/s (2094057)\n[Oct  6 15:47:52] [INFO] [1h40m0s] C:       0/s (0) N:       0/s (0) W:   23900/s (123287572) R:   2440/s (2094057)\n[Oct  6 15:48:52] [INFO] [1h41m0s] C:       0/s (0) N:       0/s (0) W:   24000/s (124864502) R:   2440/s (2094057)\n[Oct  6 15:49:52] [INFO] [1h42m0s] C:       0/s (0) N:       0/s (0) W:   23900/s (126072198) R:   2440/s (2094057)\n[Oct  6 15:50:52] [INFO] [1h43m0s] C:       0/s (0) N:       0/s (0) W:   23800/s (126988126) R:   2440/s (2094057)\n[Oct  6 15:51:52] [INFO] [1h44m0s] C:       0/s (0) N:       0/s (0) W:   23800/s (127957897) R:   2440/s (2094057)\n[Oct  6 15:52:52] [INFO] [1h45m0s] C:       0/s (0) N:       0/s (0) W:   23600/s (128649160) R:   2440/s (2094057)\n[Oct  6 15:53:52] [INFO] [1h46m0s] C:       0/s (0) N:       0/s (0) W:   23600/s (129829309) R:   2440/s (2094057)\n[Oct  6 15:54:52] [INFO] [1h47m0s] C:       0/s (0) N:       0/s (0) W:   23400/s (130446964) R:   2440/s (2094057)\n[Oct  6 15:55:52] [INFO] [1h48m0s] C:       0/s (0) N:       0/s (0) W:   23400/s (131550939) R:   2440/s (2094057)\n[Oct  6 15:56:52] [INFO] [1h49m0s] C:       0/s (0) N:       0/s (0) W:   23300/s (132576859) R:   2440/s (2094057)\n[Oct  6 15:57:52] [INFO] [1h50m0s] C:       0/s (0) N:       0/s (0) W:   23200/s (133320636) R:   2440/s (2094057)\n[Oct  6 15:58:52] [INFO] [1h51m0s] C:       0/s (0) N:       0/s (0) W:   23200/s (134735389) R:   2440/s (2094057)\n[Oct  6 15:59:52] [INFO] [1h52m0s] C:       0/s (0) N:       0/s (0) W:   23200/s (136211911) R:   2440/s (2094057)\n[Oct  6 16:00:52] [INFO] [1h53m0s] C:       0/s (0) N:       0/s (0) W:   23200/s (137689785) R:   2440/s (2094057)\n[Oct  6 16:01:52] [INFO] [1h54m0s] C:       0/s (0) N:       0/s (0) W:   23000/s (137793315) R:   2440/s (2094057)\n[Oct  6 16:02:52] [INFO] [1h55m0s] C:       0/s (0) N:       0/s (0) W:   23000/s (138706582) R:   2440/s (2094057)\n[Oct  6 16:03:52] [INFO] [1h56m0s] C:       0/s (0) N:       0/s (0) W:   22900/s (139561548) R:   2440/s (2094057)\n[Oct  6 16:04:52] [INFO] [1h57m0s] C:       0/s (0) N:       0/s (0) W:   22800/s (140647607) R:   2440/s (2094057)\n[Oct  6 16:05:52] [INFO] [1h58m0s] C:       0/s (0) N:       0/s (0) W:   22700/s (141616227) R:   2440/s (2094057)\n[Oct  6 16:06:52] [INFO] [1h59m0s] C:       0/s (0) N:       0/s (0) W:   22600/s (142221690) R:   2440/s (2094057)\n[Oct  6 16:07:52] [INFO] [2h0m0s] C:       0/s (0) N:       0/s (0) W:   22600/s (143458678) R:   2440/s (2094057)\n[Oct  6 16:08:52] [INFO] [2h1m0s] C:       0/s (0) N:       0/s (0) W:   22600/s (144740070) R:   2440/s (2094057)\n[Oct  6 16:09:52] [INFO] [2h2m0s] C:       0/s (0) N:       0/s (0) W:   22600/s (145983052) R:   2440/s (2094057)\n[Oct  6 16:10:52] [INFO] [2h3m0s] C:       0/s (0) N:       0/s (0) W:   22600/s (147637884) R:   2440/s (2094057)\n[Oct  6 16:11:52] [INFO] [2h4m0s] C:       0/s (0) N:       0/s (0) W:   22700/s (149560717) R:   2440/s (2094057)\n[Oct  6 16:12:52] [INFO] [2h5m0s] C:       0/s (0) N:       0/s (0) W:   22700/s (150879886) R:   2440/s (2094057)\n[Oct  6 16:13:52] [INFO] [2h6m0s] C:       0/s (0) N:       0/s (0) W:   22600/s (151489392) R:   2440/s (2094057)\n[Oct  6 16:14:52] [INFO] [2h7m0s] C:       0/s (0) N:       0/s (0) W:   22600/s (153252221) R:   2440/s (2094057)\n[Oct  6 16:15:52] [INFO] [2h8m0s] C:       0/s (0) N:       0/s (0) W:   22600/s (154649569) R:   2440/s (2094057)\n[Oct  6 16:16:52] [INFO] [2h9m0s] C:       0/s (0) N:       0/s (0) W:   22700/s (156332392) R:   2440/s (2094057)\n[Oct  6 16:17:52] [INFO] [2h10m0s] C:       0/s (0) N:       0/s (0) W:   23000/s (159682335) R:   2440/s (2094057)\n[Oct  6 16:18:52] [INFO] [2h11m0s] C:       0/s (0) N:       0/s (0) W:   23000/s (161463646) R:   2440/s (2094057)\n[Oct  6 16:19:52] [INFO] [2h12m0s] C:       0/s (0) N:       0/s (0) W:   23100/s (163597644) R:   2440/s (2094057)\n[Oct  6 16:20:52] [INFO] [2h13m0s] C:       0/s (0) N:       0/s (0) W:   23200/s (165764757) R:   2440/s (2094057)\n[Oct  6 16:21:52] [INFO] [2h14m0s] C:       0/s (0) N:       0/s (0) W:   23300/s (167952438) R:   2440/s (2094057)\n[Oct  6 16:22:52] [INFO] [2h15m0s] C:       0/s (0) N:       0/s (0) W:   23500/s (170599466) R:   2440/s (2094057)\n[Oct  6 16:23:52] [INFO] [2h16m0s] C:       0/s (0) N:       0/s (0) W:   23600/s (172644768) R:   2440/s (2094057)\n[Oct  6 16:24:52] [INFO] [2h17m0s] C:       0/s (0) N:       0/s (0) W:   23700/s (174994056) R:   2440/s (2094057)\n[Oct  6 16:25:52] [INFO] [2h18m0s] C:       0/s (0) N:       0/s (0) W:   23800/s (177100459) R:   2440/s (2094057)\n[Oct  6 16:26:52] [INFO] [2h19m0s] C:       0/s (0) N:       0/s (0) W:   23900/s (178826136) R:   2440/s (2094057)\n[Oct  6 16:27:52] [INFO] [2h20m0s] C:       0/s (0) N:       0/s (0) W:   23900/s (180844336) R:   2440/s (2094057)\n[Oct  6 16:28:52] [INFO] [2h21m0s] C:       0/s (0) N:       0/s (0) W:   24000/s (182598873) R:   2440/s (2094057)\n[Oct  6 16:29:52] [INFO] [2h22m0s] C:       0/s (0) N:       0/s (0) W:   24100/s (184692590) R:   2440/s (2094057)\n[Oct  6 16:30:52] [INFO] [2h23m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (186993478) R:   2440/s (2094057)\n[Oct  6 16:31:52] [INFO] [2h24m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (188784098) R:   2440/s (2094057)\n[Oct  6 16:32:52] [INFO] [2h25m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (190249858) R:   2440/s (2094057)\n[Oct  6 16:33:52] [INFO] [2h26m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (191444044) R:   2440/s (2094057)\n[Oct  6 16:34:52] [INFO] [2h27m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (193480933) R:   2440/s (2094057)\n[Oct  6 16:35:52] [INFO] [2h28m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (195147862) R:   2440/s (2094057)\n[Oct  6 16:36:52] [INFO] [2h29m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (197063373) R:   2440/s (2094057)\n[Oct  6 16:37:52] [INFO] [2h30m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (198841008) R:   2440/s (2094057)\n[Oct  6 16:38:52] [INFO] [2h31m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (200367808) R:   2440/s (2094057)\n[Oct  6 16:39:52] [INFO] [2h32m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (201973157) R:   2440/s (2094057)\n[Oct  6 16:40:52] [INFO] [2h33m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (202816648) R:   2440/s (2094057)\n[Oct  6 16:41:52] [INFO] [2h34m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (203777088) R:   2440/s (2094057)\n[Oct  6 16:42:52] [INFO] [2h35m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (205659739) R:   2440/s (2094057)\n[Oct  6 16:43:52] [INFO] [2h36m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (207889704) R:   2440/s (2094057)\n[Oct  6 16:44:52] [INFO] [2h37m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (208571594) R:   2440/s (2094057)\n[Oct  6 16:45:52] [INFO] [2h38m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (209658136) R:   2440/s (2094057)\n[Oct  6 16:46:52] [INFO] [2h39m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (210495326) R:   2440/s (2094057)\n[Oct  6 16:47:52] [INFO] [2h40m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (211687139) R:   2440/s (2094057)\n[Oct  6 16:48:52] [INFO] [2h41m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (214308398) R:   2440/s (2094057)\n[Oct  6 16:49:52] [INFO] [2h42m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (216590717) R:   2440/s (2094057)\n[Oct  6 16:50:52] [INFO] [2h43m0s] C:       0/s (0) N:       0/s (0) W:   24500/s (218465021) R:   2440/s (2094057)\n[Oct  6 16:51:52] [INFO] [2h44m0s] C:       0/s (0) N:       0/s (0) W:   24600/s (220858836) R:   2440/s (2094057)\n[Oct  6 16:52:52] [INFO] [2h45m0s] C:       0/s (0) N:       0/s (0) W:   24600/s (221632167) R:   2440/s (2094057)\n[Oct  6 16:53:52] [INFO] [2h46m0s] C:       0/s (0) N:       0/s (0) W:   24500/s (222232230) R:   2440/s (2094057)\n[Oct  6 16:54:52] [INFO] [2h47m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (223293743) R:   2440/s (2094057)\n[Oct  6 16:55:52] [INFO] [2h48m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (224419271) R:   2440/s (2094057)\n[Oct  6 16:56:52] [INFO] [2h49m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (226542840) R:   2440/s (2094057)\n[Oct  6 16:57:52] [INFO] [2h50m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (228551057) R:   2440/s (2094057)\n[Oct  6 16:58:52] [INFO] [2h51m0s] C:       0/s (0) N:       0/s (0) W:   24500/s (230635143) R:   2440/s (2094057)\n[Oct  6 16:59:52] [INFO] [2h52m0s] C:       0/s (0) N:       0/s (0) W:   24600/s (232803027) R:   2440/s (2094057)\n[Oct  6 17:00:52] [INFO] [2h53m0s] C:       0/s (0) N:       0/s (0) W:   24600/s (234355241) R:   2440/s (2094057)\n[Oct  6 17:01:52] [INFO] [2h54m0s] C:       0/s (0) N:       0/s (0) W:   24600/s (236183692) R:   2440/s (2094057)\n[Oct  6 17:02:52] [INFO] [2h55m0s] C:       0/s (0) N:       0/s (0) W:   24600/s (236890933) R:   2440/s (2094057)\n[Oct  6 17:03:52] [INFO] [2h56m0s] C:       0/s (0) N:       0/s (0) W:   24500/s (237964378) R:   2440/s (2094057)\n[Oct  6 17:04:52] [INFO] [2h57m0s] C:       0/s (0) N:       0/s (0) W:   24500/s (239158936) R:   2440/s (2094057)\n[Oct  6 17:05:52] [INFO] [2h58m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (239524813) R:   2440/s (2094057)\n[Oct  6 17:06:52] [INFO] [2h59m0s] C:       0/s (0) N:       0/s (0) W:   24300/s (240367482) R:   2440/s (2094057)\n[Oct  6 17:07:52] [INFO] [3h0m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (241373518) R:   2440/s (2094057)\n[Oct  6 17:08:52] [INFO] [3h1m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (242663515) R:   2440/s (2094057)\n[Oct  6 17:09:52] [INFO] [3h2m0s] C:       0/s (0) N:       0/s (0) W:   24200/s (243416094) R:   2440/s (2094057)\n[Oct  6 17:10:52] [INFO] [3h3m0s] C:       0/s (0) N:       0/s (0) W:   24400/s (247487761) R:   2440/s (2094057)\n[Oct  6 17:11:52] [INFO] [3h4m0s] C:       0/s (0) N:       0/s (0) W:   24500/s (249443924) R:   2440/s (2094057)\n[Oct  6 17:12:52] [INFO] [3h5m0s] C:       0/s (0) N:       0/s (0) W:   24500/s (251625586) R:   2440/s (2094057)\n[Oct  6 17:13:52] [INFO] [3h6m0s] C:       0/s (0) N:       0/s (0) W:   24600/s (253643228) R:   2440/s (2094057)\n[Oct  6 17:14:52] [INFO] [3h7m0s] C:       0/s (0) N:       0/s (0) W:   24700/s (256024715) R:   2440/s (2094057)\n[Oct  6 17:15:52] [INFO] [3h8m0s] C:       0/s (0) N:       0/s (0) W:   24700/s (257880398) R:   2440/s (2094057)\n[Oct  6 17:16:52] [INFO] [3h9m0s] C:       0/s (0) N:       0/s (0) W:   24700/s (259331824) R:   2440/s (2094057)\n[Oct  6 17:17:52] [INFO] [3h10m0s] C:       0/s (0) N:       0/s (0) W:   24800/s (262198911) R:   2440/s (2094057)\n[Oct  6 17:18:52] [INFO] [3h11m0s] C:       0/s (0) N:       0/s (0) W:   24900/s (264525308) R:   2440/s (2094057)\n[Oct  6 17:19:52] [INFO] [3h12m0s] C:       0/s (0) N:       0/s (0) W:   25000/s (266512448) R:   2440/s (2094057)\n[Oct  6 17:20:52] [INFO] [3h13m0s] C:       0/s (0) N:       0/s (0) W:   25000/s (268417632) R:   2440/s (2094057)\n[Oct  6 17:21:52] [INFO] [3h14m0s] C:       0/s (0) N:       0/s (0) W:   25000/s (270251642) R:   2440/s (2094057)\n[Oct  6 17:22:52] [INFO] [3h15m0s] C:       0/s (0) N:       0/s (0) W:   25100/s (272418261) R:   2440/s (2094057)\n[Oct  6 17:23:52] [INFO] [3h16m0s] C:       0/s (0) N:       0/s (0) W:   25100/s (274259354) R:   2440/s (2094057)\n[Oct  6 17:24:52] [INFO] [3h17m0s] C:       0/s (0) N:       0/s (0) W:   25100/s (275937499) R:   2440/s (2094057)\n[Oct  6 17:25:52] [INFO] [3h18m0s] C:       0/s (0) N:       0/s (0) W:   25200/s (278100171) R:   2440/s (2094057)\n[Oct  6 17:26:52] [INFO] [3h19m0s] C:       0/s (0) N:       0/s (0) W:   25300/s (280448072) R:   2440/s (2094057)\n[Oct  6 17:27:52] [INFO] [3h20m0s] C:       0/s (0) N:       0/s (0) W:   25300/s (282586910) R:   2440/s (2094057)\n[Oct  6 17:28:52] [INFO] [3h21m0s] C:       0/s (0) N:       0/s (0) W:   25400/s (285097793) R:   2440/s (2094057)\n[Oct  6 17:29:52] [INFO] [3h22m0s] C:       0/s (0) N:       0/s (0) W:   25500/s (287270235) R:   2440/s (2094057)\n[Oct  6 17:30:52] [INFO] [3h23m0s] C:       0/s (0) N:       0/s (0) W:   25500/s (289473912) R:   2440/s (2094057)\n[Oct  6 17:31:52] [INFO] [3h24m0s] C:       0/s (0) N:       0/s (0) W:   25600/s (291531252) R:   2440/s (2094057)\n[Oct  6 17:32:52] [INFO] [3h25m0s] C:       0/s (0) N:       0/s (0) W:   25700/s (294008849) R:   2440/s (2094057)\n[Oct  6 17:33:52] [INFO] [3h26m0s] C:       0/s (0) N:       0/s (0) W:   25700/s (296241321) R:   2440/s (2094057)\n[Oct  6 17:34:52] [INFO] [3h27m0s] C:       0/s (0) N:       0/s (0) W:   25800/s (298676041) R:   2440/s (2094057)\n[Oct  6 17:35:52] [INFO] [3h28m0s] C:       0/s (0) N:       0/s (0) W:   25900/s (301191795) R:   2440/s (2094057)\n[Oct  6 17:36:52] [INFO] [3h29m0s] C:       0/s (0) N:       0/s (0) W:   25900/s (303608550) R:   2440/s (2094057)\n[Oct  6 17:37:52] [INFO] [3h30m0s] C:       0/s (0) N:       0/s (0) W:   26000/s (305795230) R:   2440/s (2094057)\n[Oct  6 17:38:52] [INFO] [3h31m0s] C:       0/s (0) N:       0/s (0) W:   26000/s (307145717) R:   2440/s (2094057)\n[Oct  6 17:39:52] [INFO] [3h32m0s] C:       0/s (0) N:       0/s (0) W:   26000/s (308473128) R:   2440/s (2094057)\n[Oct  6 17:40:52] [INFO] [3h33m0s] C:       0/s (0) N:       0/s (0) W:   25900/s (309547751) R:   2440/s (2094057)\n[Oct  6 17:40:59] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  6 17:41:52] [INFO] [3h34m0s] C:       0/s (0) N:   69800/s (3685513) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:42:52] [INFO] [3h35m0s] C:       0/s (0) N:   72200/s (8142960) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:43:52] [INFO] [3h36m0s] C:       0/s (0) N:   73800/s (12800105) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:44:52] [INFO] [3h37m0s] C:       0/s (0) N:   76000/s (16783031) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:45:52] [INFO] [3h38m0s] C:       0/s (0) N:   68900/s (19726112) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:46:52] [INFO] [3h39m0s] C:       0/s (0) N:   62900/s (22206219) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:47:52] [INFO] [3h40m0s] C:       0/s (0) N:   63900/s (26421593) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:48:52] [INFO] [3h41m0s] C:       0/s (0) N:   63700/s (30180785) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:49:52] [INFO] [3h42m0s] C:       0/s (0) N:   61500/s (32810920) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:50:52] [INFO] [3h43m0s] C:       0/s (0) N:   59500/s (35328133) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:51:52] [INFO] [3h44m0s] C:       0/s (0) N:   60100/s (39072965) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:52:52] [INFO] [3h45m0s] C:       0/s (0) N:   61100/s (43559996) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 17:53:14] [INFO] Writing OSM data took: 3h45m21.903290284s\n[Oct  6 17:53:14] [INFO] [3h45m21s] C:       0/s (0) N:   61000/s (43823052) W:   25900/s (309876032) R:   2440/s (2094057)\n[Oct  6 20:38:00] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen1 took: 2h44m46.144205557s\n[Oct  6 21:03:38] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen1 took: 3h10m23.97708513s\n[Oct  6 22:12:31] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen1 took: 4h19m17.045599683s\n[Oct  6 22:36:59] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen1 took: 4h43m45.098202681s\n[Oct  6 22:53:59] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen0 took: 16m59.245248897s\n[Oct  6 23:09:43] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen0 took: 32m43.831074885s\n[Oct  6 23:13:02] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen0 took: 36m2.297581434s\n[Oct  6 23:26:03] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen0 took: 49m3.359798021s\n[Oct  6 23:26:03] [INFO] [PostGIS] Creating generalized tables took: 5h32m48.458854383s\n[Oct  6 23:27:20] [INFO] [PostGIS] Creating OSM id index on osm_aeroways took: 1m16.956326115s\n[Oct  6 23:27:23] [INFO] [PostGIS] Creating geometry index on osm_aeroways took: 2.947772781s\n[Oct  6 23:27:26] [INFO] [PostGIS] Creating OSM id index on osm_transport_areas took: 1m23.837730255s\n[Oct  6 23:27:30] [INFO] [PostGIS] Creating geometry index on osm_transport_areas took: 3.540493389s\n[Oct  6 23:29:35] [INFO] [PostGIS] Creating OSM id index on osm_amenities took: 3m32.773925122s\n[Oct  6 23:31:27] [INFO] [PostGIS] Creating OSM id index on osm_barrierpoints took: 5m24.032837156s\n[Oct  6 23:34:43] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen0 took: 8m39.992435299s\n[Oct  6 23:37:26] [INFO] [PostGIS] Creating geometry index on osm_amenities took: 7m51.031513373s\n[Oct  6 23:42:20] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers_interpolated took: 16m17.087577594s\n[Oct  6 23:42:55] [INFO] [PostGIS] Creating OSM id index on osm_places took: 16m52.731567648s\n[Oct  6 23:45:21] [INFO] [PostGIS] Creating geometry index on osm_barrierpoints took: 13m54.282957426s\n[Oct  6 23:47:13] [INFO] [PostGIS] Creating OSM id index on osm_transport_points took: 21m10.325139134s\n[Oct  6 23:57:39] [INFO] [PostGIS] Creating OSM id index on osm_motorways took: 31m36.313025622s\n[Oct  6 23:57:40] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen1 took: 31m37.111522275s\n[Oct  7 00:05:28] [INFO] [PostGIS] Creating OSM id index on osm_barrierways took: 39m25.648136715s\n[Oct  7 00:15:34] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen0 took: 40m50.972492163s\n[Oct  7 00:17:19] [INFO] [PostGIS] Creating OSM id index on osm_admin took: 51m16.149869234s\n[Oct  7 00:25:25] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen0 took: 59m22.034640111s\n[Oct  7 00:39:35] [INFO] [PostGIS] Creating geometry index on osm_housenumbers_interpolated took: 57m15.581421659s\n[Oct  7 00:53:13] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen0 took: 1h27m10.862931387s\n[Oct  7 01:12:24] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen1 took: 1h46m21.862313488s\n[Oct  7 01:17:27] [INFO] [PostGIS] Creating geometry index on osm_places took: 1h34m31.220609848s\n[Oct  7 01:32:08] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen0 took: 2h6m5.15903129s\n[Oct  7 01:32:54] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen1 took: 2h6m51.637240818s\n[Oct  7 01:42:41] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen1 took: 1h45m1.616316779s\n[Oct  7 02:04:56] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen1 took: 2h38m53.289406849s\n[Oct  7 02:35:03] [INFO] [PostGIS] Creating geometry index on osm_admin took: 2h17m44.646010826s\n[Oct  7 02:41:26] [INFO] [PostGIS] Creating OSM id index on osm_mainroads took: 3h15m23.120780477s\n[Oct  7 02:46:57] [INFO] [PostGIS] Creating geometry index on osm_motorways took: 2h49m18.188008412s\n[Oct  7 03:07:33] [INFO] [PostGIS] Creating geometry index on osm_barrierways took: 3h2m5.040495364s\n[Oct  7 03:09:25] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen0 took: 2h43m59.98240896s\n[Oct  7 03:18:57] [INFO] [PostGIS] Creating OSM id index on osm_waterareas took: 3h52m54.67163911s\n[Oct  7 03:32:03] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers took: 4h6m0.684993413s\n[Oct  7 04:22:27] [INFO] [PostGIS] Creating OSM id index on osm_waterways took: 4h56m24.727568486s\n. List of relations\n Schema |             Name              | Type  |  Owner   |  Size   | Description\n--------+-------------------------------+-------+----------+---------+-------------\n public | osm_admin                     | table | osm      | 3001 MB |\n public | osm_aeroways                  | table | osm      | 28 MB   |\n public | osm_amenities                 | table | osm      | 82 MB   |\n public | osm_barrierpoints             | table | osm      | 119 MB  |\n public | osm_barrierways               | table | osm      | 625 MB  |\n public | osm_buildings                 | table | osm      | 33 GB   |\n public | osm_housenumbers              | table | osm      | 3603 MB |\n public | osm_housenumbers_interpolated | table | osm      | 282 MB  |\n public | osm_landusages                | table | osm      | 15 GB   |\n public | osm_landusages_gen0           | table | osm      | 1052 MB |\n public | osm_landusages_gen1           | table | osm      | 3331 MB |\n public | osm_mainroads                 | table | osm      | 3357 MB |\n public | osm_minorroads                | table | osm      | 19 GB   |\n public | osm_motorways                 | table | osm      | 583 MB  |\n public | osm_places                    | table | osm      | 298 MB  |\n public | osm_roads                     | table | osm      | 26 GB   |\n public | osm_roads_gen0                | table | osm      | 1936 MB |\n public | osm_roads_gen1                | table | osm      | 2114 MB |\n public | osm_transport_areas           | table | osm      | 31 MB   |\n public | osm_transport_points          | table | osm      | 346 MB  |\n public | osm_waterareas                | table | osm      | 5443 MB |\n public | osm_waterareas_gen0           | table | osm      | 243 MB  |\n public | osm_waterareas_gen1           | table | osm      | 748 MB  |\n public | osm_waterways                 | table | osm      | 6269 MB |\n public | osm_waterways_gen0            | table | osm      | 1306 MB |\n public | osm_waterways_gen1            | table | osm      | 1719 MB |\n. Data can not be viewed as accurate, just saw that I forget to tune the PostgreSQL config to the amount of memory :disappointed:  like the last time. No wonder the index building and the queries take so long.\n. On the import level one can probably only impact the index building (maintenance_work_mem) and write speed (checkpoint_segments) with the config.\nI tried it again with the data of Europe. Next step is to check the speed of the queries (e.g. with pgBadger) and try to pump out an MBTiles (serial for now).\nIm just logging all the statements here so I can later go back and analyze them more deeply.\nI am running on a cluster with 40cores and 250GB memory. But disk speed is quite slow.\nI will have to check the exact hardware specifications.\nI will write down the tuning config but because it usually depends on the infrastructure one is running I am hesitant of hardcoding this directly into the image.  I opened a pull request on the official postgres image to include the tuning directly in the env vars passed to the container, then we could specify it like that.\nshared_buffers = 64000MB\neffective_cache_size = 192000MB\nwork_mem = 1600MB\nmaintenance_work_mem = 2GB\ncheckpoint_segments = 128\ncheckpoint_completion_target = 0.9\nwal_buffers = 16MB\ndefault_statistics_target = 500\nLog of europe import.\n[Oct  7 20:20:52] [INFO] [reader] reading /data/import/europe-latest.osm.pbf with data till 2015-10-06 21:22:02 +0000 UTC\n[Oct  7 20:21:52] [INFO] [  1m0s] C:  648000/s (38848000) N:    7400/s (448915) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:22:52] [INFO] [  2m0s] C:  739000/s (88344000) N:   17100/s (2045763) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:23:52] [INFO] [  3m0s] C:  751000/s (134880000) N:   15300/s (2750124) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:24:52] [INFO] [  4m0s] C:  772000/s (184936000) N:   14800/s (3558175) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:25:52] [INFO] [  5m0s] C:  809000/s (242304000) N:   13100/s (3930839) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:26:52] [INFO] [  6m0s] C:  825000/s (297264000) N:   15600/s (5633277) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:27:52] [INFO] [  7m0s] C:  832000/s (349168000) N:   13900/s (5865447) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:28:52] [INFO] [  8m0s] C:  836000/s (401416000) N:   13100/s (6322224) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:29:52] [INFO] [  9m0s] C:  848000/s (458000000) N:   13300/s (7209857) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:30:52] [INFO] [ 10m0s] C:  863000/s (517744000) N:   13000/s (7798923) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:31:52] [INFO] [ 11m0s] C:  867000/s (572120000) N:   12400/s (8212742) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:32:52] [INFO] [ 12m0s] C:  870000/s (626384000) N:   12000/s (8679427) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:33:52] [INFO] [ 13m0s] C:  879000/s (686160000) N:   11900/s (9303489) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:34:52] [INFO] [ 14m0s] C:  887000/s (744776000) N:   11500/s (9677774) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:35:52] [INFO] [ 15m0s] C:  896000/s (806696000) N:   11400/s (10349270) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:36:52] [INFO] [ 16m0s] C:  905000/s (869288000) N:   11700/s (11326884) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:37:52] [INFO] [ 17m0s] C:  918000/s (936440000) N:   12300/s (12635907) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:38:52] [INFO] [ 18m0s] C:  928000/s (1002352000) N:   12600/s (13633008) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:39:52] [INFO] [ 19m0s] C:  936000/s (1067560000) N:   13300/s (15157966) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:40:52] [INFO] [ 20m0s] C:  940000/s (1128512000) N:   15500/s (18692478) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:41:52] [INFO] [ 21m0s] C:  953000/s (1201704000) N:   19400/s (24456729) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:42:52] [INFO] [ 22m0s] C:  964000/s (1273696000) N:   20600/s (27243740) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:43:52] [INFO] [ 23m0s] C:  972000/s (1342112000) N:   21600/s (29861682) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:44:52] [INFO] [ 24m0s] C:  983000/s (1415144000) N:   21500/s (31032567) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:45:52] [INFO] [ 25m0s] C:  990000/s (1484584000) N:   21200/s (31889520) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:46:52] [INFO] [ 26m0s] C:  998000/s (1557112000) N:   21100/s (32975532) W:       0/s (0) R:      0/s (0)\n[Oct  7 20:47:52] [INFO] [ 27m0s] C:  998000/s (1565729219) N:   21100/s (33091370) W:  726400/s (37942781) R:      0/s (0)\n[Oct  7 20:48:52] [INFO] [ 28m0s] C:  998000/s (1565729219) N:   21100/s (33091370) W:  717800/s (80206781) R:      0/s (0)\n[Oct  7 20:49:52] [INFO] [ 29m0s] C:  998000/s (1565729219) N:   21100/s (33091370) W:  608900/s (102750781) R:      0/s (0)\n[Oct  7 20:50:52] [INFO] [ 30m0s] C:  998000/s (1565729219) N:   21100/s (33091370) W:  547700/s (126662781) R:      0/s (0)\n[Oct  7 20:51:52] [INFO] [ 31m0s] C:  998000/s (1565729219) N:   21100/s (33091370) W:  521700/s (152214781) R:      0/s (0)\n[Oct  7 20:52:52] [INFO] [ 32m0s] C:  998000/s (1565729219) N:   21100/s (33091370) W:  495400/s (173534781) R:      0/s (0)\n[Oct  7 20:53:42] [INFO] [32m49s] C:  998000/s (1565729219) N:   21100/s (33091370) W:  480600/s (191634793) R: 429090/s (1417770)\n[Oct  7 20:53:42] [INFO] Reading OSM data took: 32m51.269170169s\n[Oct  7 20:53:42] [INFO] Imposm took: 32m51.269444342s\n[Oct  7 20:53:42] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  7 20:53:42] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  7 20:53:47] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  7 20:54:42] [INFO] [  1m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   1520/s (83577)\n[Oct  7 20:55:42] [INFO] [  2m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   2240/s (257495)\n[Oct  7 20:56:00] [INFO] [GEOS] TopologyException: side location conflict at 1262953.6463945815 5372535.5919273971\n[Oct  7 20:56:42] [INFO] [  3m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   2710/s (476079)\n[Oct  7 20:57:42] [INFO] [  4m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   3290/s (773950)\n[Oct  7 20:58:42] [INFO] [  5m0s] C:       0/s (0) N:       0/s (0) W:       0/s (0) R:   4020/s (1184896)\n[Oct  7 20:59:12] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  7 20:59:42] [INFO] [  6m0s] C:       0/s (0) N:       0/s (0) W:   20000/s (617992) R:   4360/s (1417770)\n[Oct  7 21:00:42] [INFO] [  7m0s] C:       0/s (0) N:       0/s (0) W:   26300/s (2396016) R:   4360/s (1417770)\n[Oct  7 21:01:42] [INFO] [  8m0s] C:       0/s (0) N:       0/s (0) W:   25400/s (3833293) R:   4360/s (1417770)\n[Oct  7 21:02:42] [INFO] [  9m0s] C:       0/s (0) N:       0/s (0) W:   25100/s (5305274) R:   4360/s (1417770)\n[Oct  7 21:03:42] [INFO] [ 10m0s] C:       0/s (0) N:       0/s (0) W:   25900/s (7024699) R:   4360/s (1417770)\n[Oct  7 21:04:42] [INFO] [ 11m0s] C:       0/s (0) N:       0/s (0) W:   26900/s (8755338) R:   4360/s (1417770)\n[Oct  7 21:05:42] [INFO] [ 12m0s] C:       0/s (0) N:       0/s (0) W:   24800/s (9685508) R:   4360/s (1417770)\n[Oct  7 21:06:42] [INFO] [ 13m0s] C:       0/s (0) N:       0/s (0) W:   25400/s (11463483) R:   4360/s (1417770)\n[Oct  7 21:07:42] [INFO] [ 14m0s] C:       0/s (0) N:       0/s (0) W:   27300/s (13931830) R:   4360/s (1417770)\n[Oct  7 21:08:42] [INFO] [ 15m0s] C:       0/s (0) N:       0/s (0) W:   29600/s (16926896) R:   4360/s (1417770)\n[Oct  7 21:09:42] [INFO] [ 16m0s] C:       0/s (0) N:       0/s (0) W:   32500/s (20504410) R:   4360/s (1417770)\n[Oct  7 21:10:42] [INFO] [ 17m0s] C:       0/s (0) N:       0/s (0) W:   35400/s (24520060) R:   4360/s (1417770)\n[Oct  7 21:11:42] [INFO] [ 18m0s] C:       0/s (0) N:       0/s (0) W:   37400/s (28108258) R:   4360/s (1417770)\n[Oct  7 21:12:42] [INFO] [ 19m0s] C:       0/s (0) N:       0/s (0) W:   38900/s (31575250) R:   4360/s (1417770)\n[Oct  7 21:13:42] [INFO] [ 20m0s] C:       0/s (0) N:       0/s (0) W:   39900/s (34825860) R:   4360/s (1417770)\n[Oct  7 21:14:42] [INFO] [ 21m0s] C:       0/s (0) N:       0/s (0) W:   40700/s (37716652) R:   4360/s (1417770)\n[Oct  7 21:15:42] [INFO] [ 22m0s] C:       0/s (0) N:       0/s (0) W:   40700/s (37716652) R:   4360/s (1417770)\n[Oct  7 21:16:42] [INFO] [ 23m0s] C:       0/s (0) N:       0/s (0) W:   40700/s (37716652) R:   4360/s (1417770)\n[Oct  7 21:17:42] [INFO] [ 24m0s] C:       0/s (0) N:       0/s (0) W:   35300/s (39302329) R:   4360/s (1417770)\n[Oct  7 21:18:42] [INFO] [ 25m0s] C:       0/s (0) N:       0/s (0) W:   36000/s (42264810) R:   4360/s (1417770)\n[Oct  7 21:19:42] [INFO] [ 26m0s] C:       0/s (0) N:       0/s (0) W:   37000/s (45608644) R:   4360/s (1417770)\n[Oct  7 21:20:42] [INFO] [ 27m0s] C:       0/s (0) N:       0/s (0) W:   38000/s (49165964) R:   4360/s (1417770)\n[Oct  7 21:21:42] [INFO] [ 28m0s] C:       0/s (0) N:       0/s (0) W:   38600/s (51034940) R:   4360/s (1417770)\n[Oct  7 21:22:42] [INFO] [ 29m0s] C:       0/s (0) N:       0/s (0) W:   38600/s (51034940) R:   4360/s (1417770)\n[Oct  7 21:23:42] [INFO] [ 30m0s] C:       0/s (0) N:       0/s (0) W:   35700/s (51061727) R:   4360/s (1417770)\n[Oct  7 21:24:42] [INFO] [ 31m0s] C:       0/s (0) N:       0/s (0) W:   35700/s (51061727) R:   4360/s (1417770)\n[Oct  7 21:25:42] [INFO] [ 32m0s] C:       0/s (0) N:       0/s (0) W:   35700/s (51061727) R:   4360/s (1417770)\n[Oct  7 21:26:42] [INFO] [ 33m0s] C:       0/s (0) N:       0/s (0) W:   33100/s (54733739) R:   4360/s (1417770)\n[Oct  7 21:27:42] [INFO] [ 34m0s] C:       0/s (0) N:       0/s (0) W:   34300/s (58715582) R:   4360/s (1417770)\n[Oct  7 21:28:42] [INFO] [ 35m0s] C:       0/s (0) N:       0/s (0) W:   35300/s (62507222) R:   4360/s (1417770)\n[Oct  7 21:29:42] [INFO] [ 36m0s] C:       0/s (0) N:       0/s (0) W:   36300/s (66529959) R:   4360/s (1417770)\n[Oct  7 21:30:42] [INFO] [ 37m0s] C:       0/s (0) N:       0/s (0) W:   35400/s (67077149) R:   4360/s (1417770)\n[Oct  7 21:31:42] [INFO] [ 38m0s] C:       0/s (0) N:       0/s (0) W:   36500/s (71209051) R:   4360/s (1417770)\n[Oct  7 21:32:42] [INFO] [ 39m0s] C:       0/s (0) N:       0/s (0) W:   37400/s (75356001) R:   4360/s (1417770)\n[Oct  7 21:33:42] [INFO] [ 40m0s] C:       0/s (0) N:       0/s (0) W:   38300/s (79399200) R:   4360/s (1417770)\n[Oct  7 21:34:42] [INFO] [ 41m0s] C:       0/s (0) N:       0/s (0) W:   39000/s (83131372) R:   4360/s (1417770)\n[Oct  7 21:35:42] [INFO] [ 42m0s] C:       0/s (0) N:       0/s (0) W:   39000/s (83538023) R:   4360/s (1417770)\n[Oct  7 21:36:42] [INFO] [ 43m0s] C:       0/s (0) N:       0/s (0) W:   37300/s (83986330) R:   4360/s (1417770)\n[Oct  7 21:37:42] [INFO] [ 44m0s] C:       0/s (0) N:       0/s (0) W:   38100/s (88074348) R:   4360/s (1417770)\n[Oct  7 21:38:42] [INFO] [ 45m0s] C:       0/s (0) N:       0/s (0) W:   38700/s (91909244) R:   4360/s (1417770)\n[Oct  7 21:39:42] [INFO] [ 46m0s] C:       0/s (0) N:       0/s (0) W:   39500/s (96056138) R:   4360/s (1417770)\n[Oct  7 21:40:42] [INFO] [ 47m0s] C:       0/s (0) N:       0/s (0) W:   40000/s (99650896) R:   4360/s (1417770)\n[Oct  7 21:41:42] [INFO] [ 48m0s] C:       0/s (0) N:       0/s (0) W:   39300/s (100454786) R:   4360/s (1417770)\n[Oct  7 21:42:42] [INFO] [ 49m0s] C:       0/s (0) N:       0/s (0) W:   40000/s (104537388) R:   4360/s (1417770)\n[Oct  7 21:43:42] [INFO] [ 50m0s] C:       0/s (0) N:       0/s (0) W:   40600/s (108694902) R:   4360/s (1417770)\n[Oct  7 21:44:42] [INFO] [ 51m0s] C:       0/s (0) N:       0/s (0) W:   41200/s (112634506) R:   4360/s (1417770)\n[Oct  7 21:45:42] [INFO] [ 52m0s] C:       0/s (0) N:       0/s (0) W:   41900/s (117004169) R:   4360/s (1417770)\n[Oct  7 21:46:42] [INFO] [ 53m0s] C:       0/s (0) N:       0/s (0) W:   42000/s (117837765) R:   4360/s (1417770)\n[Oct  7 21:47:42] [INFO] [ 54m0s] C:       0/s (0) N:       0/s (0) W:   40700/s (118223548) R:   4360/s (1417770)\n[Oct  7 21:48:42] [INFO] [ 55m0s] C:       0/s (0) N:       0/s (0) W:   39900/s (118285511) R:   4360/s (1417770)\n[Oct  7 21:49:42] [INFO] [ 56m0s] C:       0/s (0) N:       0/s (0) W:   39300/s (118565362) R:   4360/s (1417770)\n[Oct  7 21:50:42] [INFO] [ 57m0s] C:       0/s (0) N:       0/s (0) W:   39300/s (118565362) R:   4360/s (1417770)\n[Oct  7 21:51:42] [INFO] [ 58m0s] C:       0/s (0) N:       0/s (0) W:   37900/s (119479964) R:   4360/s (1417770)\n[Oct  7 21:52:42] [INFO] [ 59m0s] C:       0/s (0) N:       0/s (0) W:   38600/s (124209982) R:   4360/s (1417770)\n[Oct  7 21:53:42] [INFO] [1h0m0s] C:       0/s (0) N:       0/s (0) W:   39400/s (129156279) R:   4360/s (1417770)\n[Oct  7 21:54:42] [INFO] [1h1m0s] C:       0/s (0) N:       0/s (0) W:   40200/s (133947449) R:   4360/s (1417770)\n[Oct  7 21:55:42] [INFO] [1h2m0s] C:       0/s (0) N:       0/s (0) W:   40800/s (138324515) R:   4360/s (1417770)\n[Oct  7 21:56:42] [INFO] [1h3m0s] C:       0/s (0) N:       0/s (0) W:   40100/s (138398389) R:   4360/s (1417770)\n[Oct  7 21:57:42] [INFO] [1h4m0s] C:       0/s (0) N:       0/s (0) W:   39700/s (138604934) R:   4360/s (1417770)\n[Oct  7 21:58:42] [INFO] [1h5m0s] C:       0/s (0) N:       0/s (0) W:   39700/s (138604934) R:   4360/s (1417770)\n[Oct  7 21:59:42] [INFO] [1h6m0s] C:       0/s (0) N:       0/s (0) W:   38400/s (138795716) R:   4360/s (1417770)\n[Oct  7 22:00:42] [INFO] [1h7m0s] C:       0/s (0) N:       0/s (0) W:   38400/s (138795716) R:   4360/s (1417770)\n[Oct  7 22:01:42] [INFO] [1h8m0s] C:       0/s (0) N:       0/s (0) W:   38000/s (142842269) R:   4360/s (1417770)\n[Oct  7 22:02:42] [INFO] [1h9m0s] C:       0/s (0) N:       0/s (0) W:   38500/s (147001873) R:   4360/s (1417770)\n[Oct  7 22:03:42] [INFO] [1h10m0s] C:       0/s (0) N:       0/s (0) W:   38900/s (150864507) R:   4360/s (1417770)\n[Oct  7 22:04:42] [INFO] [1h11m0s] C:       0/s (0) N:       0/s (0) W:   39300/s (154865318) R:   4360/s (1417770)\n[Oct  7 22:05:42] [INFO] [1h12m0s] C:       0/s (0) N:       0/s (0) W:   39100/s (156021053) R:   4360/s (1417770)\n[Oct  7 22:06:42] [INFO] [1h13m0s] C:       0/s (0) N:       0/s (0) W:   39500/s (160218535) R:   4360/s (1417770)\n[Oct  7 22:07:42] [INFO] [1h14m0s] C:       0/s (0) N:       0/s (0) W:   39900/s (164068793) R:   4360/s (1417770)\n[Oct  7 22:08:42] [INFO] [1h15m0s] C:       0/s (0) N:       0/s (0) W:   40200/s (167925634) R:   4360/s (1417770)\n[Oct  7 22:09:42] [INFO] [1h16m0s] C:       0/s (0) N:       0/s (0) W:   40600/s (171968391) R:   4360/s (1417770)\n[Oct  7 22:10:42] [INFO] [1h17m0s] C:       0/s (0) N:       0/s (0) W:   40200/s (172584739) R:   4360/s (1417770)\n[Oct  7 22:11:42] [INFO] [1h18m0s] C:       0/s (0) N:       0/s (0) W:   40200/s (175198674) R:   4360/s (1417770)\n[Oct  7 22:12:42] [INFO] [1h19m0s] C:       0/s (0) N:       0/s (0) W:   40700/s (179806373) R:   4360/s (1417770)\n[Oct  7 22:13:42] [INFO] [1h20m0s] C:       0/s (0) N:       0/s (0) W:   41300/s (184837151) R:   4360/s (1417770)\n[Oct  7 22:14:42] [INFO] [1h21m0s] C:       0/s (0) N:       0/s (0) W:   41900/s (189878316) R:   4360/s (1417770)\n[Oct  7 22:15:04] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Oct  7 22:15:42] [INFO] [1h22m0s] C:       0/s (0) N:  143600/s (613794) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:16:42] [INFO] [1h23m0s] C:       0/s (0) N:  143600/s (613794) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:17:42] [INFO] [1h24m0s] C:       0/s (0) N:    8100/s (1291981) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:18:42] [INFO] [1h25m0s] C:       0/s (0) N:   19000/s (4170171) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:19:42] [INFO] [1h26m0s] C:       0/s (0) N:   43600/s (12170111) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:20:42] [INFO] [1h27m0s] C:       0/s (0) N:   55600/s (18813480) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:21:42] [INFO] [1h28m0s] C:       0/s (0) N:   67900/s (27074315) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:22:42] [INFO] [1h29m0s] C:       0/s (0) N:   68300/s (31321206) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:23:17] [INFO] Writing OSM data took: 1h29m34.059957146s\n[Oct  7 22:23:17] [INFO] [1h29m34s] C:       0/s (0) N:   69400/s (33091370) W:   42000/s (191634793) R:   4360/s (1417770)\n[Oct  7 22:45:13] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen1 took: 21m55.994020571s\n[Oct  7 22:48:14] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen1 took: 24m57.290209018s\n[Oct  7 23:09:12] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen1 took: 45m55.102401197s\n[Oct  8 00:38:52] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen1 took: 2h15m34.975047472s\n[Oct  8 00:44:01] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen0 took: 5m9.918561s\n[Oct  8 00:47:03] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen0 took: 8m11.412999565s\n[Oct  8 00:47:16] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen0 took: 8m24.498297535s\n[Oct  8 01:02:36] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen0 took: 23m44.911462518s\n[Oct  8 01:02:36] [INFO] [PostGIS] Creating generalized tables took: 2h39m19.887263997s\n[Oct  8 01:02:38] [INFO] [PostGIS] Creating OSM id index on osm_transport_areas took: 1.129896141s\n[Oct  8 01:02:38] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers_interpolated took: 1.205334244s\n[Oct  8 01:02:38] [INFO] [PostGIS] Creating OSM id index on osm_aeroways took: 1.205387702s\n[Oct  8 01:02:38] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen1 took: 1.305764717s\n[Oct  8 01:02:47] [INFO] [PostGIS] Creating geometry index on osm_aeroways took: 8.885894801s\n[Oct  8 01:03:21] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen1 took: 45.026685134s\n[Oct  8 01:04:32] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen1 took: 1m56.04514976s\n[Oct  8 01:04:32] [INFO] [PostGIS] Creating geometry index on osm_transport_areas took: 1m54.915371039s\n[Oct  8 01:04:32] [INFO] [PostGIS] Creating OSM id index on osm_waterways took: 1m56.045342946s\n[Oct  8 01:04:32] [INFO] [PostGIS] Creating OSM id index on osm_waterareas took: 1m56.045349212s\n[Oct  8 01:04:32] [INFO] [PostGIS] Creating geometry index on osm_housenumbers_interpolated took: 1m54.839918476s\n[Oct  8 01:04:39] [INFO] [PostGIS] Creating OSM id index on osm_amenities took: 2m2.492783737s\n[Oct  8 01:04:49] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen1 took: 2m12.266586146s\n[Oct  8 01:04:49] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen0 took: 2m12.266681073s\n[Oct  8 01:04:49] [INFO] [PostGIS] Creating OSM id index on osm_roads took: 2m12.26676065s\n[Oct  8 01:04:49] [INFO] [PostGIS] Creating OSM id index on osm_landusages took: 2m12.266809865s\n[Oct  8 01:05:16] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen0 took: 27.767631678s\n[Oct  8 01:05:27] [INFO] [PostGIS] Creating geometry index on osm_amenities took: 48.476326848s\n[Oct  8 01:05:29] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen1 took: 2m51.7000331s\n[Oct  8 01:06:18] [INFO] [PostGIS] Creating OSM id index on osm_barrierpoints took: 3m41.991565349s\n[Oct  8 01:07:33] [INFO] [PostGIS] Creating geometry index on osm_barrierpoints took: 1m14.878875065s\n[Oct  8 01:08:10] [INFO] [PostGIS] Creating geometry index on osm_waterareas took: 3m37.503574999s\n[Oct  8 01:08:11] [INFO] [PostGIS] Creating geometry index on osm_waterways took: 3m38.792958997s\n[Oct  8 01:08:11] [INFO] [PostGIS] Creating geometry index on osm_waterways_gen1 took: 4m49.811496318s\n[Oct  8 01:09:18] [INFO] [PostGIS] Creating OSM id index on osm_transport_points took: 6m42.050322308s\n[Oct  8 01:11:31] [INFO] [PostGIS] Creating OSM id index on osm_places took: 8m54.332030736s\n[Oct  8 01:11:41] [INFO] [PostGIS] Creating OSM id index on osm_motorways took: 9m4.260840797s\n[Oct  8 01:12:16] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen0 took: 9m39.593440502s\n[Oct  8 01:12:22] [INFO] [PostGIS] Creating geometry index on osm_motorways took: 41.007277668s\n[Oct  8 01:13:27] [INFO] [PostGIS] Creating OSM id index on osm_barrierways took: 10m50.737518645s\n[Oct  8 01:13:49] [INFO] [PostGIS] Creating geometry index on osm_places took: 2m18.167318222s\n[Oct  8 01:13:51] [INFO] [PostGIS] Creating geometry index on osm_transport_points took: 4m32.173349356s\n[Oct  8 01:14:24] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen1 took: 9m35.255140059s\n[Oct  8 01:15:01] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen0 took: 12m24.987942175s\n[Oct  8 01:15:11] [INFO] [PostGIS] Creating geometry index on osm_roads_gen1 took: 10m38.136821401s\n[Oct  8 01:15:24] [INFO] [PostGIS] Creating geometry index on osm_waterways_gen0 took: 3m8.239759199s\n[Oct  8 01:15:32] [INFO] [PostGIS] Creating OSM id index on osm_admin took: 12m55.675370974s\n[Oct  8 01:15:44] [INFO] [PostGIS] Creating geometry index on osm_admin took: 11.764336482s\n[Oct  8 01:15:55] [INFO] [PostGIS] Creating geometry index on osm_barrierways took: 2m27.832267717s\n[Oct  8 01:16:00] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen0 took: 58.665576583s\n[Oct  8 01:18:43] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen0 took: 16m6.41774007s\n[Oct  8 01:22:14] [INFO] [PostGIS] Creating geometry index on osm_roads_gen0 took: 3m31.318617813s\n[Oct  8 01:22:26] [INFO] [PostGIS] Creating geometry index on osm_landusages took: 17m37.602853947s\n[Oct  8 01:38:04] [INFO] [PostGIS] Creating geometry index on osm_roads took: 33m14.858275344s\n[Oct  8 01:42:54] [INFO] [PostGIS] Creating OSM id index on osm_mainroads took: 40m17.724414947s\n[Oct  8 01:43:53] [INFO] [PostGIS] Creating geometry index on osm_mainroads took: 58.588116443s\n[Oct  8 01:54:23] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers took: 51m46.57911938s\n[Oct  8 02:02:44] [INFO] [PostGIS] Creating geometry index on osm_housenumbers took: 8m20.925898231s\n[Oct  8 02:15:52] [INFO] [PostGIS] Creating OSM id index on osm_minorroads took: 1h13m15.469596783s\n[Oct  8 02:37:00] [INFO] [PostGIS] Creating geometry index on osm_minorroads took: 21m7.822030129s\n[Oct  8 03:01:58] [INFO] [PostGIS] Creating OSM id index on osm_buildings took: 1h59m21.607747233s\n[Oct  8 05:05:23] [INFO] [PostGIS] Creating geometry index on osm_buildings took: 2h3m24.634307575s\n[Oct  8 05:05:23] [INFO] [PostGIS] Creating geometry indices took: 4h2m46.242590479s\n[Oct  8 05:05:23] [INFO] Importing OSM data took: 8h11m40.190085632s\n[Oct  8 05:05:23] [INFO] Imposm took: 8h11m40.190148229s\n. Another world import this time on a weaker machine (AWS r3.xlarge 30GB RAM with 5 x 100GB EBS volumes attached in raid-0.)  where it took 12hours and 20minutes.\n[Oct  9 07:16:06] [INFO] removing existing cache /data/cache\n[Oct  9 07:16:09] [INFO] [reader] reading /data/import/planet-latest.osm.pbf with data till 2015-10-05 02:00:01 +0000 UTC\n[Oct  9 07:17:09] [INFO] [  1m0s] C: 1891000/s (111392000) N:   12300/s (724975) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:18:09] [INFO] [  2m0s] C: 1876000/s (223104000) N:   13400/s (1596511) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:19:09] [INFO] [  3m0s] C: 1781000/s (318704000) N:   19400/s (3486370) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:20:09] [INFO] [  4m0s] C: 1790000/s (427664000) N:   20700/s (4945741) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:21:09] [INFO] [  5m0s] C: 1812000/s (542784000) N:   19900/s (5976505) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:22:09] [INFO] [  6m0s] C: 1827000/s (655760000) N:   20300/s (7319837) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:23:09] [INFO] [  7m0s] C: 1806000/s (756640000) N:   22300/s (9366592) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:24:09] [INFO] [  8m0s] C: 1812000/s (868880000) N:   22200/s (10648925) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:25:09] [INFO] [  9m0s] C: 1820000/s (981888000) N:   23300/s (12601932) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:26:09] [INFO] [ 10m0s] C: 1846000/s (1106752000) N:   22500/s (13508502) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:27:09] [INFO] [ 11m0s] C: 1861000/s (1227792000) N:   21400/s (14159291) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:28:09] [INFO] [ 12m0s] C: 1878000/s (1350448000) N:   21000/s (15113149) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:29:09] [INFO] [ 13m0s] C: 1897000/s (1477904000) N:   20600/s (16047211) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:30:09] [INFO] [ 14m0s] C: 1915000/s (1608080000) N:   20100/s (16884618) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:31:09] [INFO] [ 15m0s] C: 1930000/s (1736624000) N:   20400/s (18353647) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:32:09] [INFO] [ 16m0s] C: 1947000/s (1867472000) N:   20800/s (20003861) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:33:09] [INFO] [ 17m0s] C: 1961000/s (1998608000) N:   21300/s (21711599) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:34:09] [INFO] [ 18m0s] C: 1971000/s (2128512000) N:   21800/s (23558052) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:35:09] [INFO] [ 19m0s] C: 1964000/s (2238400000) N:   24600/s (28124331) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:36:09] [INFO] [ 20m0s] C: 1962000/s (2352912000) N:   28400/s (34056490) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:37:09] [INFO] [ 21m0s] C: 1976000/s (2488208000) N:   29200/s (36768040) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:38:09] [INFO] [ 22m0s] C: 1984000/s (2617488000) N:   30100/s (39737202) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:39:09] [INFO] [ 23m0s] C: 2000000/s (2760128000) N:   29800/s (41137694) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:40:09] [INFO] [ 24m0s] C: 2017000/s (2903552000) N:   29400/s (42361290) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:41:09] [INFO] [ 25m0s] C: 2032000/s (3047232000) N:   29200/s (43831644) W:       0/s (0) R:      0/s (0)\n[Oct  9 07:42:09] [INFO] [ 26m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  118100/s (6600000) R:      0/s (0)\n[Oct  9 07:43:09] [INFO] [ 27m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  117700/s (13640000) R:      0/s (0)\n[Oct  9 07:44:09] [INFO] [ 28m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  119700/s (21056000) R:      0/s (0)\n[Oct  9 07:45:09] [INFO] [ 29m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  120300/s (28408000) R:      0/s (0)\n[Oct  9 07:46:09] [INFO] [ 30m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  121200/s (35944000) R:      0/s (0)\n[Oct  9 07:47:09] [INFO] [ 31m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  122900/s (43824000) R:      0/s (0)\n[Oct  9 07:48:09] [INFO] [ 32m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  125700/s (52312000) R:      0/s (0)\n[Oct  9 07:49:09] [INFO] [ 33m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  126800/s (60456000) R:      0/s (0)\n[Oct  9 07:50:09] [INFO] [ 34m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  126900/s (68088000) R:      0/s (0)\n[Oct  9 07:51:09] [INFO] [ 35m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  127500/s (76008000) R:      0/s (0)\n[Oct  9 07:52:09] [INFO] [ 36m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  128400/s (84224000) R:      0/s (0)\n[Oct  9 07:53:09] [INFO] [ 37m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  129300/s (92600000) R:      0/s (0)\n[Oct  9 07:54:09] [INFO] [ 38m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  130000/s (100984000) R:      0/s (0)\n[Oct  9 07:55:09] [INFO] [ 39m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  130900/s (109456000) R:      0/s (0)\n[Oct  9 07:56:09] [INFO] [ 40m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  131600/s (118024000) R:      0/s (0)\n[Oct  9 07:57:09] [INFO] [ 41m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  132200/s (126392000) R:      0/s (0)\n[Oct  9 07:58:09] [INFO] [ 42m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  132800/s (134928000) R:      0/s (0)\n[Oct  9 07:59:09] [INFO] [ 43m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  133100/s (143336000) R:      0/s (0)\n[Oct  9 08:00:09] [INFO] [ 44m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  133500/s (151808000) R:      0/s (0)\n[Oct  9 08:01:09] [INFO] [ 45m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  134000/s (160432000) R:      0/s (0)\n[Oct  9 08:02:09] [INFO] [ 46m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  134700/s (169352000) R:      0/s (0)\n[Oct  9 08:03:09] [INFO] [ 47m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  135300/s (178064000) R:      0/s (0)\n[Oct  9 08:04:09] [INFO] [ 48m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  135600/s (186688000) R:      0/s (0)\n[Oct  9 08:05:09] [INFO] [ 49m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  136000/s (195328000) R:      0/s (0)\n[Oct  9 08:06:09] [INFO] [ 50m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  136400/s (204176000) R:      0/s (0)\n[Oct  9 08:07:09] [INFO] [ 51m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  136500/s (212520000) R:      0/s (0)\n[Oct  9 08:08:09] [INFO] [ 52m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  136800/s (221168000) R:      0/s (0)\n[Oct  9 08:09:09] [INFO] [ 53m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  137000/s (229728000) R:      0/s (0)\n[Oct  9 08:10:09] [INFO] [ 54m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  137200/s (238288000) R:      0/s (0)\n[Oct  9 08:11:09] [INFO] [ 55m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  137300/s (246760000) R:      0/s (0)\n[Oct  9 08:12:09] [INFO] [ 56m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  137600/s (255448000) R:      0/s (0)\n[Oct  9 08:13:09] [INFO] [ 57m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  137800/s (264080000) R:      0/s (0)\n[Oct  9 08:14:09] [INFO] [ 58m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  138000/s (272776000) R:      0/s (0)\n[Oct  9 08:15:09] [INFO] [ 59m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  138300/s (281568000) R:      0/s (0)\n[Oct  9 08:16:09] [INFO] [1h0m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  138700/s (290848000) R:      0/s (0)\n[Oct  9 08:17:09] [INFO] [1h1m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  139200/s (300240000) R:      0/s (0)\n[Oct  9 08:18:09] [INFO] [1h2m0s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  139600/s (309496000) R:      0/s (0)\n[Oct  9 08:18:41] [INFO] [1h2m32s] C: 2032000/s (3053883296) N:   29200/s (43897350) W:  139600/s (310751627) R:  88650/s (2101802)\n[Oct  9 08:18:42] [INFO] Reading OSM data took: 1h2m32.872657707s\n[Oct  9 08:19:42] [INFO] [  1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:      0/s ( 0.0%)\n[Oct  9 08:20:42] [INFO] [  2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:      0/s ( 0.0%)\n[Oct  9 08:21:42] [INFO] [  3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:      0/s ( 0.0%)\n[Oct  9 08:22:42] [INFO] [  4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:      0/s ( 0.0%)\n[Oct  9 08:23:42] [INFO] [  5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:      0/s ( 0.1%)\n[Oct  9 08:24:42] [INFO] [  6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:      0/s ( 0.1%)\n[Oct  9 08:25:42] [INFO] [  7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     10/s ( 0.3%)\n[Oct  9 08:26:42] [INFO] [  8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     20/s ( 0.5%)\n[Oct  9 08:27:42] [INFO] [  9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     20/s ( 0.8%)\n[Oct  9 08:28:42] [INFO] [ 10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     30/s ( 0.9%)\n[Oct  9 08:29:42] [INFO] [ 11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     20/s ( 0.9%)\n[Oct  9 08:30:42] [INFO] [ 12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     30/s ( 1.1%)\n[Oct  9 08:31:42] [INFO] [ 13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     30/s ( 1.3%)\n[Oct  9 08:32:42] [INFO] [ 14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     30/s ( 1.5%)\n[Oct  9 08:33:42] [INFO] [ 15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     40/s ( 1.9%)\n[Oct  9 08:34:42] [INFO] [ 16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     50/s ( 2.4%)\n[Oct  9 08:35:42] [INFO] [ 17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     50/s ( 2.7%)\n[Oct  9 08:36:42] [INFO] [ 18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     50/s ( 3.0%)\n[Oct  9 08:37:42] [INFO] [ 19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     60/s ( 3.4%)\n[Oct  9 08:38:42] [INFO] [ 20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     60/s ( 3.7%)\n[Oct  9 08:39:42] [INFO] [ 21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     60/s ( 4.1%)\n[Oct  9 08:40:42] [INFO] [ 22m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     60/s ( 4.3%)\n[Oct  9 08:41:42] [INFO] [ 23m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     60/s ( 4.5%)\n[Oct  9 08:42:42] [INFO] [ 24m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     60/s ( 4.7%)\n[Oct  9 08:43:42] [INFO] [ 25m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     70/s ( 5.2%)\n[Oct  9 08:44:42] [INFO] [ 26m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     70/s ( 5.8%)\n[Oct  9 08:45:42] [INFO] [ 27m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     80/s ( 6.2%)\n[Oct  9 08:46:42] [INFO] [ 28m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     80/s ( 6.4%)\n[Oct  9 08:47:42] [INFO] [ 29m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     80/s ( 6.7%)\n[Oct  9 08:48:42] [INFO] [ 30m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     90/s ( 7.7%)\n[Oct  9 08:49:42] [INFO] [ 31m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     90/s ( 8.0%)\n[Oct  9 08:50:42] [INFO] [ 32m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     90/s ( 8.4%)\n[Oct  9 08:51:42] [INFO] [ 33m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     90/s ( 8.8%)\n[Oct  9 08:52:42] [INFO] [ 34m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     90/s ( 9.3%)\n[Oct  9 08:53:42] [INFO] [ 35m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     90/s ( 9.6%)\n[Oct  9 08:54:42] [INFO] [ 36m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:     90/s ( 9.9%)\n[Oct  9 08:55:42] [INFO] [ 37m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    100/s (10.8%)\n[Oct  9 08:56:42] [INFO] [ 38m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    100/s (11.3%)\n[Oct  9 08:57:42] [INFO] [ 39m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    100/s (11.7%)\n[Oct  9 08:58:42] [INFO] [ 40m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    100/s (12.4%)\n[Oct  9 08:59:42] [INFO] [ 41m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    110/s (13.1%)\n[Oct  9 09:00:42] [INFO] [ 42m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    110/s (13.8%)\n[Oct  9 09:01:42] [INFO] [ 43m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    110/s (14.2%)\n[Oct  9 09:02:42] [INFO] [ 44m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    110/s (14.6%)\n[Oct  9 09:03:42] [INFO] [ 45m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    110/s (15.1%)\n[Oct  9 09:04:42] [INFO] [ 46m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    110/s (15.5%)\n[Oct  9 09:05:42] [INFO] [ 47m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    110/s (16.0%)\n[Oct  9 09:06:42] [INFO] [ 48m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (16.5%)\n[Oct  9 09:07:42] [INFO] [ 49m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (17.0%)\n[Oct  9 09:08:42] [INFO] [ 50m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (17.4%)\n[Oct  9 09:09:42] [INFO] [ 51m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (17.9%)\n[Oct  9 09:10:42] [INFO] [ 52m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (18.1%)\n[Oct  9 09:11:42] [INFO] [ 53m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (18.2%)\n[Oct  9 09:12:42] [INFO] [ 54m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    110/s (18.5%)\n[Oct  9 09:13:42] [INFO] [ 55m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (19.0%)\n[Oct  9 09:14:42] [INFO] [ 56m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (19.6%)\n[Oct  9 09:15:42] [INFO] [ 57m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (20.1%)\n[Oct  9 09:16:42] [INFO] [ 58m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (20.5%)\n[Oct  9 09:17:42] [INFO] [ 59m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (20.9%)\n[Oct  9 09:18:42] [INFO] [1h0m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (21.4%)\n[Oct  9 09:19:37] [INFO] [GEOS] TopologyException: side location conflict at 1262953.6463945815 5372535.5919273971\n[Oct  9 09:19:42] [INFO] [1h1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (21.8%)\n[Oct  9 09:20:42] [INFO] [1h2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (22.2%)\n[Oct  9 09:21:42] [INFO] [1h3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (22.5%)\n[Oct  9 09:22:42] [INFO] [1h4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (22.7%)\n[Oct  9 09:23:42] [INFO] [1h5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (23.1%)\n[Oct  9 09:24:42] [INFO] [1h6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (23.4%)\n[Oct  9 09:25:42] [INFO] [1h7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (23.7%)\n[Oct  9 09:26:42] [INFO] [1h8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (24.0%)\n[Oct  9 09:27:42] [INFO] [1h9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (24.2%)\n[Oct  9 09:28:42] [INFO] [1h10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (24.6%)\n[Oct  9 09:29:42] [INFO] [1h11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (25.0%)\n[Oct  9 09:30:42] [INFO] [1h12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (25.5%)\n[Oct  9 09:31:42] [INFO] [1h13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (26.0%)\n[Oct  9 09:32:42] [INFO] [1h14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (26.6%)\n[Oct  9 09:33:42] [INFO] [1h15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (27.2%)\n[Oct  9 09:34:42] [INFO] [1h16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (27.8%)\n[Oct  9 09:35:42] [INFO] [1h17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (28.4%)\n[Oct  9 09:36:42] [INFO] [1h18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (28.8%)\n[Oct  9 09:37:42] [INFO] [1h19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    120/s (29.3%)\n[Oct  9 09:38:42] [INFO] [1h20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (29.9%)\n[Oct  9 09:39:42] [INFO] [1h21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (30.7%)\n[Oct  9 09:40:42] [INFO] [1h22m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (31.1%)\n[Oct  9 09:41:42] [INFO] [1h23m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (31.5%)\n[Oct  9 09:42:42] [INFO] [1h24m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (32.0%)\n[Oct  9 09:43:42] [INFO] [1h25m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (32.4%)\n[Oct  9 09:44:42] [INFO] [1h26m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (32.7%)\n[Oct  9 09:45:42] [INFO] [1h27m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (32.9%)\n[Oct  9 09:46:42] [INFO] [1h28m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (33.1%)\n[Oct  9 09:47:42] [INFO] [1h29m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (33.5%)\n[Oct  9 09:48:42] [INFO] [1h30m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (34.0%)\n[Oct  9 09:49:42] [INFO] [1h31m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (34.4%)\n[Oct  9 09:50:42] [INFO] [1h32m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (34.9%)\n[Oct  9 09:51:42] [INFO] [1h33m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (35.5%)\n[Oct  9 09:52:42] [INFO] [1h34m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (36.0%)\n[Oct  9 09:53:42] [INFO] [1h35m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (36.5%)\n[Oct  9 09:54:42] [INFO] [1h36m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (37.0%)\n[Oct  9 09:55:42] [INFO] [1h37m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (37.5%)\n[Oct  9 09:56:42] [INFO] [1h38m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (37.9%)\n[Oct  9 09:57:42] [INFO] [1h39m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (38.4%)\n[Oct  9 09:58:42] [INFO] [1h40m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (38.9%)\n[Oct  9 09:59:42] [INFO] [1h41m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (39.5%)\n[Oct  9 10:00:42] [INFO] [1h42m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (39.9%)\n[Oct  9 10:01:42] [INFO] [1h43m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (40.6%)\n[Oct  9 10:02:42] [INFO] [1h44m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (41.2%)\n[Oct  9 10:03:42] [INFO] [1h45m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (41.8%)\n[Oct  9 10:04:42] [INFO] [1h46m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (42.3%)\n[Oct  9 10:05:42] [INFO] [1h47m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (42.7%)\n[Oct  9 10:06:42] [INFO] [1h48m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (43.1%)\n[Oct  9 10:07:42] [INFO] [1h49m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (43.5%)\n[Oct  9 10:08:42] [INFO] [1h50m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    130/s (43.9%)\n[Oct  9 10:09:42] [INFO] [1h51m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (44.3%)\n[Oct  9 10:10:42] [INFO] [1h52m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (44.9%)\n[Oct  9 10:11:42] [INFO] [1h53m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (45.6%)\n[Oct  9 10:12:42] [INFO] [1h54m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (46.0%)\n[Oct  9 10:13:42] [INFO] [1h55m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (46.6%)\n[Oct  9 10:14:42] [INFO] [1h56m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (47.2%)\n[Oct  9 10:15:42] [INFO] [1h57m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (47.8%)\n[Oct  9 10:16:42] [INFO] [1h58m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (48.0%)\n[Oct  9 10:17:42] [INFO] [1h59m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (48.5%)\n[Oct  9 10:18:42] [INFO] [2h0m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (49.2%)\n[Oct  9 10:19:42] [INFO] [2h1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (49.5%)\n[Oct  9 10:20:42] [INFO] [2h2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (50.0%)\n[Oct  9 10:21:42] [INFO] [2h3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (50.4%)\n[Oct  9 10:22:42] [INFO] [2h4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (50.9%)\n[Oct  9 10:23:42] [INFO] [2h5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (51.3%)\n[Oct  9 10:24:42] [INFO] [2h6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (51.6%)\n[Oct  9 10:25:42] [INFO] [2h7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (52.0%)\n[Oct  9 10:26:42] [INFO] [2h8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (52.2%)\n[Oct  9 10:27:42] [INFO] [2h9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (52.5%)\n[Oct  9 10:28:42] [INFO] [2h10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (52.9%)\n[Oct  9 10:29:42] [INFO] [2h11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (53.3%)\n[Oct  9 10:30:42] [INFO] [2h12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (53.6%)\n[Oct  9 10:31:42] [INFO] [2h13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (54.0%)\n[Oct  9 10:32:42] [INFO] [2h14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (54.4%)\n[Oct  9 10:33:42] [INFO] [2h15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (54.9%)\n[Oct  9 10:34:42] [INFO] [2h16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (55.2%)\n[Oct  9 10:35:42] [INFO] [2h17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (55.5%)\n[Oct  9 10:36:42] [INFO] [2h18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (55.9%)\n[Oct  9 10:37:42] [INFO] [2h19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (56.3%)\n[Oct  9 10:38:42] [INFO] [2h20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (56.7%)\n[Oct  9 10:39:42] [INFO] [2h21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (57.1%)\n[Oct  9 10:40:42] [INFO] [2h22m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (57.5%)\n[Oct  9 10:41:42] [INFO] [2h23m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (57.9%)\n[Oct  9 10:42:42] [INFO] [2h24m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (58.4%)\n[Oct  9 10:43:42] [INFO] [2h25m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (58.8%)\n[Oct  9 10:44:42] [INFO] [2h26m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (59.4%)\n[Oct  9 10:45:42] [INFO] [2h27m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (59.8%)\n[Oct  9 10:46:42] [INFO] [2h28m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (60.3%)\n[Oct  9 10:47:42] [INFO] [2h29m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (60.7%)\n[Oct  9 10:48:42] [INFO] [2h30m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (61.2%)\n[Oct  9 10:49:42] [INFO] [2h31m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (61.8%)\n[Oct  9 10:50:42] [INFO] [2h32m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (62.2%)\n[Oct  9 10:51:42] [INFO] [2h33m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (62.8%)\n[Oct  9 10:52:42] [INFO] [2h34m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (63.2%)\n[Oct  9 10:53:42] [INFO] [2h35m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (63.9%)\n[Oct  9 10:54:42] [INFO] [2h36m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (64.3%)\n[Oct  9 10:55:42] [INFO] [2h37m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (64.8%)\n[Oct  9 10:56:42] [INFO] [2h38m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (65.3%)\n[Oct  9 10:57:42] [INFO] [2h39m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (65.5%)\n[Oct  9 10:58:42] [INFO] [2h40m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (65.9%)\n[Oct  9 10:59:42] [INFO] [2h41m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (66.4%)\n[Oct  9 11:00:42] [INFO] [2h42m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (66.7%)\n[Oct  9 11:01:42] [INFO] [2h43m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (67.1%)\n[Oct  9 11:02:42] [INFO] [2h44m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (67.6%)\n[Oct  9 11:03:42] [INFO] [2h45m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (68.2%)\n[Oct  9 11:04:42] [INFO] [2h46m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (68.7%)\n[Oct  9 11:05:42] [INFO] [2h47m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (69.2%)\n[Oct  9 11:06:42] [INFO] [2h48m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (69.6%)\n[Oct  9 11:07:42] [INFO] [2h49m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (70.0%)\n[Oct  9 11:08:42] [INFO] [2h50m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (70.5%)\n[Oct  9 11:09:42] [INFO] [2h51m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (70.9%)\n[Oct  9 11:10:42] [INFO] [2h52m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (71.3%)\n[Oct  9 11:11:42] [INFO] [2h53m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (71.7%)\n[Oct  9 11:12:42] [INFO] [2h54m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (72.0%)\n[Oct  9 11:13:42] [INFO] [2h55m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (72.5%)\n[Oct  9 11:14:42] [INFO] [2h56m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (73.1%)\n[Oct  9 11:15:42] [INFO] [2h57m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (73.8%)\n[Oct  9 11:16:42] [INFO] [2h58m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (74.3%)\n[Oct  9 11:17:42] [INFO] [2h59m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (74.6%)\n[Oct  9 11:18:42] [INFO] [3h0m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (75.0%)\n[Oct  9 11:19:42] [INFO] [3h1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (75.4%)\n[Oct  9 11:20:42] [INFO] [3h2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (75.8%)\n[Oct  9 11:21:42] [INFO] [3h3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (76.4%)\n[Oct  9 11:22:42] [INFO] [3h4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (77.0%)\n[Oct  9 11:23:42] [INFO] [3h5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (77.5%)\n[Oct  9 11:24:42] [INFO] [3h6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (77.9%)\n[Oct  9 11:25:42] [INFO] [3h7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (78.4%)\n[Oct  9 11:26:42] [INFO] [3h8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (78.9%)\n[Oct  9 11:27:42] [INFO] [3h9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (79.6%)\n[Oct  9 11:28:42] [INFO] [3h10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (80.3%)\n[Oct  9 11:29:42] [INFO] [3h11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (81.0%)\n[Oct  9 11:30:42] [INFO] [3h12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (81.6%)\n[Oct  9 11:31:42] [INFO] [3h13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (82.0%)\n[Oct  9 11:32:42] [INFO] [3h14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (82.6%)\n[Oct  9 11:33:42] [INFO] [3h15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (83.1%)\n[Oct  9 11:34:42] [INFO] [3h16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (83.7%)\n[Oct  9 11:35:42] [INFO] [3h17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (84.2%)\n[Oct  9 11:36:42] [INFO] [3h18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    140/s (84.7%)\n[Oct  9 11:37:42] [INFO] [3h19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (85.6%)\n[Oct  9 11:38:42] [INFO] [3h20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (86.4%)\n[Oct  9 11:39:42] [INFO] [3h21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (87.1%)\n[Oct  9 11:40:42] [INFO] [3h22m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (88.0%)\n[Oct  9 11:41:42] [INFO] [3h23m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (89.1%)\n[Oct  9 11:42:42] [INFO] [3h24m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (90.0%)\n[Oct  9 11:43:42] [INFO] [3h25m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (91.5%)\n[Oct  9 11:44:42] [INFO] [3h26m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (92.3%)\n[Oct  9 11:45:42] [INFO] [3h27m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (93.3%)\n[Oct  9 11:46:42] [INFO] [3h28m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (93.6%)\n[Oct  9 11:47:42] [INFO] [3h29m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (94.2%)\n[Oct  9 11:48:42] [INFO] [3h30m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (94.7%)\n[Oct  9 11:49:42] [INFO] [3h31m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (95.5%)\n[Oct  9 11:50:42] [INFO] [3h32m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (95.9%)\n[Oct  9 11:51:42] [INFO] [3h33m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (96.4%)\n[Oct  9 11:52:42] [INFO] [3h34m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (97.0%)\n[Oct  9 11:53:42] [INFO] [3h35m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (97.6%)\n[Oct  9 11:54:42] [INFO] [3h36m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (97.9%)\n[Oct  9 11:55:42] [INFO] [3h37m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (98.3%)\n[Oct  9 11:56:42] [INFO] [3h38m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (98.7%)\n[Oct  9 11:57:42] [INFO] [3h39m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (99.1%)\n[Oct  9 11:58:42] [INFO] [3h40m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (99.4%)\n[Oct  9 11:59:42] [INFO] [3h41m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:       0/s ( 0.0%) R:    150/s (99.8%)\n[Oct  9 12:00:42] [INFO] [3h42m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:     200/s ( 0.0%) R:    150/s (100.0%)\n[Oct  9 12:01:42] [INFO] [3h43m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:     300/s ( 0.0%) R:    150/s (100.0%)\n[Oct  9 12:02:42] [INFO] [3h44m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:     400/s ( 0.0%) R:    150/s (100.0%)\n[Oct  9 12:03:42] [INFO] [3h45m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:     700/s ( 0.1%) R:    150/s (100.0%)\n[Oct  9 12:04:42] [INFO] [3h46m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:    1000/s ( 0.1%) R:    150/s (100.0%)\n[Oct  9 12:05:42] [INFO] [3h47m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:    1800/s ( 0.2%) R:    150/s (100.0%)\n[Oct  9 12:06:42] [INFO] [3h48m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:    4000/s ( 0.5%) R:    150/s (100.0%)\n[Oct  9 12:07:42] [INFO] [3h49m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:    6200/s ( 0.9%) R:    150/s (100.0%)\n[Oct  9 12:08:42] [INFO] [3h50m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:    7300/s ( 1.2%) R:    150/s (100.0%)\n[Oct  9 12:09:42] [INFO] [3h51m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:    8300/s ( 1.5%) R:    150/s (100.0%)\n[Oct  9 12:10:42] [INFO] [3h52m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:    9400/s ( 1.9%) R:    150/s (100.0%)\n[Oct  9 12:11:42] [INFO] [3h53m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   10400/s ( 2.3%) R:    150/s (100.0%)\n[Oct  9 12:12:42] [INFO] [3h54m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   11000/s ( 2.7%) R:    150/s (100.0%)\n[Oct  9 12:13:42] [INFO] [3h55m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   11600/s ( 3.1%) R:    150/s (100.0%)\n[Oct  9 12:14:42] [INFO] [3h56m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12100/s ( 3.4%) R:    150/s (100.0%)\n[Oct  9 12:15:42] [INFO] [3h57m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12700/s ( 3.8%) R:    150/s (100.0%)\n[Oct  9 12:16:42] [INFO] [3h58m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13000/s ( 4.2%) R:    150/s (100.0%)\n[Oct  9 12:17:42] [INFO] [3h59m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13400/s ( 4.6%) R:    150/s (100.0%)\n[Oct  9 12:18:42] [INFO] [4h0m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13300/s ( 4.8%) R:    150/s (100.0%)\n[Oct  9 12:19:42] [INFO] [4h1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12900/s ( 4.9%) R:    150/s (100.0%)\n[Oct  9 12:20:42] [INFO] [4h2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12800/s ( 5.1%) R:    150/s (100.0%)\n[Oct  9 12:21:42] [INFO] [4h3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12600/s ( 5.3%) R:    150/s (100.0%)\n[Oct  9 12:22:42] [INFO] [4h4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12500/s ( 5.5%) R:    150/s (100.0%)\n[Oct  9 12:23:42] [INFO] [4h5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 5.6%) R:    150/s (100.0%)\n[Oct  9 12:24:42] [INFO] [4h6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12200/s ( 5.8%) R:    150/s (100.0%)\n[Oct  9 12:25:42] [INFO] [4h7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12100/s ( 6.0%) R:    150/s (100.0%)\n[Oct  9 12:26:42] [INFO] [4h8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12100/s ( 6.2%) R:    150/s (100.0%)\n[Oct  9 12:27:42] [INFO] [4h9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12200/s ( 6.5%) R:    150/s (100.0%)\n[Oct  9 12:28:42] [INFO] [4h10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12200/s ( 6.7%) R:    150/s (100.0%)\n[Oct  9 12:29:42] [INFO] [4h11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12200/s ( 7.0%) R:    150/s (100.0%)\n[Oct  9 12:30:42] [INFO] [4h12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12100/s ( 7.2%) R:    150/s (100.0%)\n[Oct  9 12:31:42] [INFO] [4h13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12100/s ( 7.4%) R:    150/s (100.0%)\n[Oct  9 12:32:42] [INFO] [4h14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12100/s ( 7.7%) R:    150/s (100.0%)\n[Oct  9 12:33:42] [INFO] [4h15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 8.0%) R:    150/s (100.0%)\n[Oct  9 12:34:42] [INFO] [4h16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 8.2%) R:    150/s (100.0%)\n[Oct  9 12:35:42] [INFO] [4h17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 8.5%) R:    150/s (100.0%)\n[Oct  9 12:36:42] [INFO] [4h18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 8.7%) R:    150/s (100.0%)\n[Oct  9 12:37:42] [INFO] [4h19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 9.0%) R:    150/s (100.0%)\n[Oct  9 12:38:42] [INFO] [4h20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 9.2%) R:    150/s (100.0%)\n[Oct  9 12:39:42] [INFO] [4h21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 9.4%) R:    150/s (100.0%)\n[Oct  9 12:40:42] [INFO] [4h22m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 9.7%) R:    150/s (100.0%)\n[Oct  9 12:41:42] [INFO] [4h23m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12300/s ( 9.9%) R:    150/s (100.0%)\n[Oct  9 12:42:42] [INFO] [4h24m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12400/s (10.2%) R:    150/s (100.0%)\n[Oct  9 12:43:42] [INFO] [4h25m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12500/s (10.5%) R:    150/s (100.0%)\n[Oct  9 12:44:42] [INFO] [4h26m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12500/s (10.8%) R:    150/s (100.0%)\n[Oct  9 12:45:42] [INFO] [4h27m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12600/s (11.1%) R:    150/s (100.0%)\n[Oct  9 12:46:42] [INFO] [4h28m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12600/s (11.4%) R:    150/s (100.0%)\n[Oct  9 12:47:42] [INFO] [4h29m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12700/s (11.7%) R:    150/s (100.0%)\n[Oct  9 12:48:42] [INFO] [4h30m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12800/s (12.0%) R:    150/s (100.0%)\n[Oct  9 12:49:42] [INFO] [4h31m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12800/s (12.3%) R:    150/s (100.0%)\n[Oct  9 12:50:42] [INFO] [4h32m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12900/s (12.6%) R:    150/s (100.0%)\n[Oct  9 12:51:42] [INFO] [4h33m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12800/s (12.8%) R:    150/s (100.0%)\n[Oct  9 12:52:42] [INFO] [4h34m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   12900/s (13.1%) R:    150/s (100.0%)\n[Oct  9 12:53:42] [INFO] [4h35m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13100/s (13.6%) R:    150/s (100.0%)\n[Oct  9 12:54:42] [INFO] [4h36m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13300/s (14.1%) R:    150/s (100.0%)\n[Oct  9 12:55:42] [INFO] [4h37m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13500/s (14.5%) R:    150/s (100.0%)\n[Oct  9 12:56:42] [INFO] [4h38m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13600/s (15.0%) R:    150/s (100.0%)\n[Oct  9 12:57:42] [INFO] [4h39m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13800/s (15.4%) R:    150/s (100.0%)\n[Oct  9 12:58:42] [INFO] [4h40m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   13900/s (15.8%) R:    150/s (100.0%)\n[Oct  9 12:59:42] [INFO] [4h41m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14000/s (16.2%) R:    150/s (100.0%)\n[Oct  9 13:00:42] [INFO] [4h42m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14100/s (16.5%) R:    150/s (100.0%)\n[Oct  9 13:01:42] [INFO] [4h43m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14200/s (16.9%) R:    150/s (100.0%)\n[Oct  9 13:02:42] [INFO] [4h44m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14200/s (17.3%) R:    150/s (100.0%)\n[Oct  9 13:03:42] [INFO] [4h45m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14300/s (17.6%) R:    150/s (100.0%)\n[Oct  9 13:04:42] [INFO] [4h46m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14300/s (18.0%) R:    150/s (100.0%)\n[Oct  9 13:05:42] [INFO] [4h47m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14400/s (18.3%) R:    150/s (100.0%)\n[Oct  9 13:06:42] [INFO] [4h48m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14400/s (18.6%) R:    150/s (100.0%)\n[Oct  9 13:07:42] [INFO] [4h49m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14400/s (18.9%) R:    150/s (100.0%)\n[Oct  9 13:08:42] [INFO] [4h50m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14500/s (19.3%) R:    150/s (100.0%)\n[Oct  9 13:09:42] [INFO] [4h51m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14500/s (19.6%) R:    150/s (100.0%)\n[Oct  9 13:10:42] [INFO] [4h52m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14500/s (19.9%) R:    150/s (100.0%)\n[Oct  9 13:11:42] [INFO] [4h53m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14600/s (20.2%) R:    150/s (100.0%)\n[Oct  9 13:12:42] [INFO] [4h54m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14600/s (20.5%) R:    150/s (100.0%)\n[Oct  9 13:13:42] [INFO] [4h55m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14600/s (20.9%) R:    150/s (100.0%)\n[Oct  9 13:14:42] [INFO] [4h56m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14700/s (21.3%) R:    150/s (100.0%)\n[Oct  9 13:15:42] [INFO] [4h57m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14700/s (21.5%) R:    150/s (100.0%)\n[Oct  9 13:16:42] [INFO] [4h58m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14700/s (21.8%) R:    150/s (100.0%)\n[Oct  9 13:17:42] [INFO] [4h59m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14700/s (22.1%) R:    150/s (100.0%)\n[Oct  9 13:18:42] [INFO] [5h0m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14700/s (22.4%) R:    150/s (100.0%)\n[Oct  9 13:19:42] [INFO] [5h1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14700/s (22.7%) R:    150/s (100.0%)\n[Oct  9 13:20:42] [INFO] [5h2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14800/s (23.1%) R:    150/s (100.0%)\n[Oct  9 13:21:42] [INFO] [5h3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14800/s (23.4%) R:    150/s (100.0%)\n[Oct  9 13:22:42] [INFO] [5h4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14800/s (23.7%) R:    150/s (100.0%)\n[Oct  9 13:23:42] [INFO] [5h5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14800/s (24.0%) R:    150/s (100.0%)\n[Oct  9 13:24:42] [INFO] [5h6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14900/s (24.4%) R:    150/s (100.0%)\n[Oct  9 13:25:42] [INFO] [5h7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14900/s (24.8%) R:    150/s (100.0%)\n[Oct  9 13:26:42] [INFO] [5h8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   14900/s (25.1%) R:    150/s (100.0%)\n[Oct  9 13:27:42] [INFO] [5h9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15000/s (25.4%) R:    150/s (100.0%)\n[Oct  9 13:28:42] [INFO] [5h10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15000/s (25.8%) R:    150/s (100.0%)\n[Oct  9 13:29:42] [INFO] [5h11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15100/s (26.2%) R:    150/s (100.0%)\n[Oct  9 13:30:42] [INFO] [5h12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15100/s (26.6%) R:    150/s (100.0%)\n[Oct  9 13:31:42] [INFO] [5h13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15200/s (26.9%) R:    150/s (100.0%)\n[Oct  9 13:32:42] [INFO] [5h14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15200/s (27.3%) R:    150/s (100.0%)\n[Oct  9 13:33:42] [INFO] [5h15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15300/s (27.7%) R:    150/s (100.0%)\n[Oct  9 13:34:42] [INFO] [5h16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15300/s (28.0%) R:    150/s (100.0%)\n[Oct  9 13:35:42] [INFO] [5h17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15300/s (28.3%) R:    150/s (100.0%)\n[Oct  9 13:36:42] [INFO] [5h18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15300/s (28.7%) R:    150/s (100.0%)\n[Oct  9 13:37:42] [INFO] [5h19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15400/s (29.0%) R:    150/s (100.0%)\n[Oct  9 13:38:42] [INFO] [5h20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15400/s (29.4%) R:    150/s (100.0%)\n[Oct  9 13:39:42] [INFO] [5h21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15500/s (29.8%) R:    150/s (100.0%)\n[Oct  9 13:40:42] [INFO] [5h22m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15500/s (30.3%) R:    150/s (100.0%)\n[Oct  9 13:41:42] [INFO] [5h23m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15600/s (30.6%) R:    150/s (100.0%)\n[Oct  9 13:42:42] [INFO] [5h24m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15600/s (30.9%) R:    150/s (100.0%)\n[Oct  9 13:43:42] [INFO] [5h25m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15600/s (31.3%) R:    150/s (100.0%)\n[Oct  9 13:44:42] [INFO] [5h26m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15600/s (31.7%) R:    150/s (100.0%)\n[Oct  9 13:45:42] [INFO] [5h27m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15600/s (32.0%) R:    150/s (100.0%)\n[Oct  9 13:46:42] [INFO] [5h28m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15700/s (32.4%) R:    150/s (100.0%)\n[Oct  9 13:47:42] [INFO] [5h29m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15700/s (32.8%) R:    150/s (100.0%)\n[Oct  9 13:48:42] [INFO] [5h30m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15800/s (33.1%) R:    150/s (100.0%)\n[Oct  9 13:49:42] [INFO] [5h31m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15800/s (33.5%) R:    150/s (100.0%)\n[Oct  9 13:50:42] [INFO] [5h32m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15800/s (33.9%) R:    150/s (100.0%)\n[Oct  9 13:51:42] [INFO] [5h33m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15900/s (34.3%) R:    150/s (100.0%)\n[Oct  9 13:52:42] [INFO] [5h34m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15900/s (34.7%) R:    150/s (100.0%)\n[Oct  9 13:53:42] [INFO] [5h35m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15900/s (35.0%) R:    150/s (100.0%)\n[Oct  9 13:54:42] [INFO] [5h36m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   15900/s (35.3%) R:    150/s (100.0%)\n[Oct  9 13:55:42] [INFO] [5h37m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16000/s (35.7%) R:    150/s (100.0%)\n[Oct  9 13:56:42] [INFO] [5h38m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16000/s (36.1%) R:    150/s (100.0%)\n[Oct  9 13:57:42] [INFO] [5h39m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16000/s (36.5%) R:    150/s (100.0%)\n[Oct  9 13:58:42] [INFO] [5h40m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16000/s (36.9%) R:    150/s (100.0%)\n[Oct  9 13:59:42] [INFO] [5h41m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16100/s (37.2%) R:    150/s (100.0%)\n[Oct  9 14:00:42] [INFO] [5h42m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16100/s (37.6%) R:    150/s (100.0%)\n[Oct  9 14:01:42] [INFO] [5h43m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16100/s (38.0%) R:    150/s (100.0%)\n[Oct  9 14:02:42] [INFO] [5h44m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16200/s (38.4%) R:    150/s (100.0%)\n[Oct  9 14:03:42] [INFO] [5h45m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16200/s (38.7%) R:    150/s (100.0%)\n[Oct  9 14:04:42] [INFO] [5h46m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16200/s (39.1%) R:    150/s (100.0%)\n[Oct  9 14:05:42] [INFO] [5h47m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16200/s (39.4%) R:    150/s (100.0%)\n[Oct  9 14:06:42] [INFO] [5h48m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16200/s (39.7%) R:    150/s (100.0%)\n[Oct  9 14:07:42] [INFO] [5h49m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16200/s (40.1%) R:    150/s (100.0%)\n[Oct  9 14:08:42] [INFO] [5h50m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16300/s (40.5%) R:    150/s (100.0%)\n[Oct  9 14:09:42] [INFO] [5h51m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16300/s (40.9%) R:    150/s (100.0%)\n[Oct  9 14:10:42] [INFO] [5h52m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16300/s (41.2%) R:    150/s (100.0%)\n[Oct  9 14:11:42] [INFO] [5h53m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16300/s (41.6%) R:    150/s (100.0%)\n[Oct  9 14:12:42] [INFO] [5h54m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16300/s (42.0%) R:    150/s (100.0%)\n[Oct  9 14:13:42] [INFO] [5h55m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16400/s (42.4%) R:    150/s (100.0%)\n[Oct  9 14:14:42] [INFO] [5h56m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16400/s (42.7%) R:    150/s (100.0%)\n[Oct  9 14:15:42] [INFO] [5h57m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16300/s (42.9%) R:    150/s (100.0%)\n[Oct  9 14:16:42] [INFO] [5h58m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16400/s (43.3%) R:    150/s (100.0%)\n[Oct  9 14:17:42] [INFO] [5h59m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16400/s (43.7%) R:    150/s (100.0%)\n[Oct  9 14:18:42] [INFO] [6h0m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16400/s (44.1%) R:    150/s (100.0%)\n[Oct  9 14:19:42] [INFO] [6h1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16400/s (44.5%) R:    150/s (100.0%)\n[Oct  9 14:20:42] [INFO] [6h2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16500/s (44.8%) R:    150/s (100.0%)\n[Oct  9 14:21:42] [INFO] [6h3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16500/s (45.2%) R:    150/s (100.0%)\n[Oct  9 14:22:42] [INFO] [6h4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16500/s (45.6%) R:    150/s (100.0%)\n[Oct  9 14:23:42] [INFO] [6h5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16500/s (46.0%) R:    150/s (100.0%)\n[Oct  9 14:24:42] [INFO] [6h6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16500/s (46.3%) R:    150/s (100.0%)\n[Oct  9 14:25:42] [INFO] [6h7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16600/s (46.7%) R:    150/s (100.0%)\n[Oct  9 14:26:42] [INFO] [6h8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16600/s (47.0%) R:    150/s (100.0%)\n[Oct  9 14:27:42] [INFO] [6h9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16600/s (47.4%) R:    150/s (100.0%)\n[Oct  9 14:28:42] [INFO] [6h10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16600/s (47.8%) R:    150/s (100.0%)\n[Oct  9 14:29:42] [INFO] [6h11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16600/s (48.2%) R:    150/s (100.0%)\n[Oct  9 14:30:42] [INFO] [6h12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16700/s (48.6%) R:    150/s (100.0%)\n[Oct  9 14:31:42] [INFO] [6h13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16700/s (49.0%) R:    150/s (100.0%)\n[Oct  9 14:32:42] [INFO] [6h14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16700/s (49.4%) R:    150/s (100.0%)\n[Oct  9 14:33:42] [INFO] [6h15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16700/s (49.8%) R:    150/s (100.0%)\n[Oct  9 14:34:42] [INFO] [6h16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16700/s (50.1%) R:    150/s (100.0%)\n[Oct  9 14:35:42] [INFO] [6h17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16800/s (50.5%) R:    150/s (100.0%)\n[Oct  9 14:36:42] [INFO] [6h18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16800/s (50.9%) R:    150/s (100.0%)\n[Oct  9 14:37:42] [INFO] [6h19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16800/s (51.2%) R:    150/s (100.0%)\n[Oct  9 14:38:42] [INFO] [6h20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16800/s (51.6%) R:    150/s (100.0%)\n[Oct  9 14:39:42] [INFO] [6h21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16800/s (52.0%) R:    150/s (100.0%)\n[Oct  9 14:40:42] [INFO] [6h22m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16800/s (52.4%) R:    150/s (100.0%)\n[Oct  9 14:41:42] [INFO] [6h23m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16900/s (52.8%) R:    150/s (100.0%)\n[Oct  9 14:42:42] [INFO] [6h24m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   16900/s (53.3%) R:    150/s (100.0%)\n[Oct  9 14:43:42] [INFO] [6h25m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (53.7%) R:    150/s (100.0%)\n[Oct  9 14:44:42] [INFO] [6h26m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (54.2%) R:    150/s (100.0%)\n[Oct  9 14:45:42] [INFO] [6h27m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (54.7%) R:    150/s (100.0%)\n[Oct  9 14:46:42] [INFO] [6h28m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (55.0%) R:    150/s (100.0%)\n[Oct  9 14:47:42] [INFO] [6h29m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (55.3%) R:    150/s (100.0%)\n[Oct  9 14:48:42] [INFO] [6h30m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (55.6%) R:    150/s (100.0%)\n[Oct  9 14:49:42] [INFO] [6h31m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (55.9%) R:    150/s (100.0%)\n[Oct  9 14:50:42] [INFO] [6h32m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (56.2%) R:    150/s (100.0%)\n[Oct  9 14:51:42] [INFO] [6h33m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (56.6%) R:    150/s (100.0%)\n[Oct  9 14:52:42] [INFO] [6h34m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (56.9%) R:    150/s (100.0%)\n[Oct  9 14:53:42] [INFO] [6h35m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17000/s (57.3%) R:    150/s (100.0%)\n[Oct  9 14:54:42] [INFO] [6h36m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (57.7%) R:    150/s (100.0%)\n[Oct  9 14:55:42] [INFO] [6h37m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (58.1%) R:    150/s (100.0%)\n[Oct  9 14:56:42] [INFO] [6h38m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (58.4%) R:    150/s (100.0%)\n[Oct  9 14:57:42] [INFO] [6h39m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (58.8%) R:    150/s (100.0%)\n[Oct  9 14:58:42] [INFO] [6h40m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (59.1%) R:    150/s (100.0%)\n[Oct  9 14:59:42] [INFO] [6h41m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (59.5%) R:    150/s (100.0%)\n[Oct  9 15:00:42] [INFO] [6h42m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (59.8%) R:    150/s (100.0%)\n[Oct  9 15:01:42] [INFO] [6h43m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (60.2%) R:    150/s (100.0%)\n[Oct  9 15:02:42] [INFO] [6h44m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17100/s (60.6%) R:    150/s (100.0%)\n[Oct  9 15:03:42] [INFO] [6h45m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17200/s (61.0%) R:    150/s (100.0%)\n[Oct  9 15:04:42] [INFO] [6h46m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17200/s (61.3%) R:    150/s (100.0%)\n[Oct  9 15:05:42] [INFO] [6h47m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17200/s (61.7%) R:    150/s (100.0%)\n[Oct  9 15:06:42] [INFO] [6h48m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17200/s (62.1%) R:    150/s (100.0%)\n[Oct  9 15:07:42] [INFO] [6h49m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17200/s (62.4%) R:    150/s (100.0%)\n[Oct  9 15:08:42] [INFO] [6h50m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17200/s (62.8%) R:    150/s (100.0%)\n[Oct  9 15:09:42] [INFO] [6h51m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17200/s (63.2%) R:    150/s (100.0%)\n[Oct  9 15:10:42] [INFO] [6h52m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17300/s (63.7%) R:    150/s (100.0%)\n[Oct  9 15:11:42] [INFO] [6h53m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17300/s (64.2%) R:    150/s (100.0%)\n[Oct  9 15:12:42] [INFO] [6h54m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17300/s (64.6%) R:    150/s (100.0%)\n[Oct  9 15:13:42] [INFO] [6h55m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (65.1%) R:    150/s (100.0%)\n[Oct  9 15:14:42] [INFO] [6h56m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (65.5%) R:    150/s (100.0%)\n[Oct  9 15:15:42] [INFO] [6h57m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (65.9%) R:    150/s (100.0%)\n[Oct  9 15:16:42] [INFO] [6h58m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (66.2%) R:    150/s (100.0%)\n[Oct  9 15:17:42] [INFO] [6h59m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (66.5%) R:    150/s (100.0%)\n[Oct  9 15:18:42] [INFO] [7h0m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (66.9%) R:    150/s (100.0%)\n[Oct  9 15:19:42] [INFO] [7h1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (67.4%) R:    150/s (100.0%)\n[Oct  9 15:20:42] [INFO] [7h2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (67.7%) R:    150/s (100.0%)\n[Oct  9 15:21:42] [INFO] [7h3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17400/s (68.1%) R:    150/s (100.0%)\n[Oct  9 15:22:42] [INFO] [7h4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17500/s (68.5%) R:    150/s (100.0%)\n[Oct  9 15:23:42] [INFO] [7h5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17500/s (68.9%) R:    150/s (100.0%)\n[Oct  9 15:24:42] [INFO] [7h6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17500/s (69.4%) R:    150/s (100.0%)\n[Oct  9 15:25:42] [INFO] [7h7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17600/s (69.9%) R:    150/s (100.0%)\n[Oct  9 15:26:42] [INFO] [7h8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17600/s (70.4%) R:    150/s (100.0%)\n[Oct  9 15:27:42] [INFO] [7h9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17600/s (70.9%) R:    150/s (100.0%)\n[Oct  9 15:28:42] [INFO] [7h10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17700/s (71.3%) R:    150/s (100.0%)\n[Oct  9 15:29:42] [INFO] [7h11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17700/s (71.8%) R:    150/s (100.0%)\n[Oct  9 15:30:42] [INFO] [7h12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17700/s (72.2%) R:    150/s (100.0%)\n[Oct  9 15:31:42] [INFO] [7h13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17700/s (72.6%) R:    150/s (100.0%)\n[Oct  9 15:32:42] [INFO] [7h14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17800/s (73.1%) R:    150/s (100.0%)\n[Oct  9 15:33:42] [INFO] [7h15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17800/s (73.5%) R:    150/s (100.0%)\n[Oct  9 15:34:42] [INFO] [7h16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17800/s (74.0%) R:    150/s (100.0%)\n[Oct  9 15:35:42] [INFO] [7h17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17800/s (74.4%) R:    150/s (100.0%)\n[Oct  9 15:36:42] [INFO] [7h18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17800/s (74.8%) R:    150/s (100.0%)\n[Oct  9 15:37:42] [INFO] [7h19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (75.2%) R:    150/s (100.0%)\n[Oct  9 15:38:42] [INFO] [7h20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (75.6%) R:    150/s (100.0%)\n[Oct  9 15:39:42] [INFO] [7h21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (75.9%) R:    150/s (100.0%)\n[Oct  9 15:40:42] [INFO] [7h22m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (76.3%) R:    150/s (100.0%)\n[Oct  9 15:41:42] [INFO] [7h23m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (76.6%) R:    150/s (100.0%)\n[Oct  9 15:42:42] [INFO] [7h24m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (76.9%) R:    150/s (100.0%)\n[Oct  9 15:43:42] [INFO] [7h25m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (77.3%) R:    150/s (100.0%)\n[Oct  9 15:44:42] [INFO] [7h26m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (77.7%) R:    150/s (100.0%)\n[Oct  9 15:45:42] [INFO] [7h27m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (78.1%) R:    150/s (100.0%)\n[Oct  9 15:46:42] [INFO] [7h28m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (78.5%) R:    150/s (100.0%)\n[Oct  9 15:47:42] [INFO] [7h29m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (78.9%) R:    150/s (100.0%)\n[Oct  9 15:48:42] [INFO] [7h30m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (79.4%) R:    150/s (100.0%)\n[Oct  9 15:49:42] [INFO] [7h31m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (79.7%) R:    150/s (100.0%)\n[Oct  9 15:50:42] [INFO] [7h32m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (80.1%) R:    150/s (100.0%)\n[Oct  9 15:51:42] [INFO] [7h33m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (80.4%) R:    150/s (100.0%)\n[Oct  9 15:52:42] [INFO] [7h34m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (80.8%) R:    150/s (100.0%)\n[Oct  9 15:53:42] [INFO] [7h35m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (81.1%) R:    150/s (100.0%)\n[Oct  9 15:54:42] [INFO] [7h36m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   17900/s (81.5%) R:    150/s (100.0%)\n[Oct  9 15:55:42] [INFO] [7h37m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (81.9%) R:    150/s (100.0%)\n[Oct  9 15:56:42] [INFO] [7h38m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (82.3%) R:    150/s (100.0%)\n[Oct  9 15:57:42] [INFO] [7h39m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (82.7%) R:    150/s (100.0%)\n[Oct  9 15:58:42] [INFO] [7h40m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (83.1%) R:    150/s (100.0%)\n[Oct  9 15:59:42] [INFO] [7h41m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (83.5%) R:    150/s (100.0%)\n[Oct  9 16:00:42] [INFO] [7h42m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (83.8%) R:    150/s (100.0%)\n[Oct  9 16:01:42] [INFO] [7h43m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (84.2%) R:    150/s (100.0%)\n[Oct  9 16:02:42] [INFO] [7h44m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (84.5%) R:    150/s (100.0%)\n[Oct  9 16:03:42] [INFO] [7h45m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (84.9%) R:    150/s (100.0%)\n[Oct  9 16:04:42] [INFO] [7h46m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (85.2%) R:    150/s (100.0%)\n[Oct  9 16:05:42] [INFO] [7h47m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (85.6%) R:    150/s (100.0%)\n[Oct  9 16:06:42] [INFO] [7h48m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (86.0%) R:    150/s (100.0%)\n[Oct  9 16:07:42] [INFO] [7h49m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (86.4%) R:    150/s (100.0%)\n[Oct  9 16:08:42] [INFO] [7h50m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18000/s (86.9%) R:    150/s (100.0%)\n[Oct  9 16:09:42] [INFO] [7h51m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18100/s (87.3%) R:    150/s (100.0%)\n[Oct  9 16:10:42] [INFO] [7h52m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18100/s (87.7%) R:    150/s (100.0%)\n[Oct  9 16:11:42] [INFO] [7h53m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18100/s (88.0%) R:    150/s (100.0%)\n[Oct  9 16:12:42] [INFO] [7h54m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18100/s (88.4%) R:    150/s (100.0%)\n[Oct  9 16:13:42] [INFO] [7h55m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18100/s (88.8%) R:    150/s (100.0%)\n[Oct  9 16:14:42] [INFO] [7h56m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18100/s (89.3%) R:    150/s (100.0%)\n[Oct  9 16:15:42] [INFO] [7h57m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18100/s (89.7%) R:    150/s (100.0%)\n[Oct  9 16:16:42] [INFO] [7h58m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18100/s (90.1%) R:    150/s (100.0%)\n[Oct  9 16:17:42] [INFO] [7h59m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18200/s (90.5%) R:    150/s (100.0%)\n[Oct  9 16:18:42] [INFO] [8h0m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18200/s (91.0%) R:    150/s (100.0%)\n[Oct  9 16:19:42] [INFO] [8h1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18200/s (91.5%) R:    150/s (100.0%)\n[Oct  9 16:20:42] [INFO] [8h2m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18200/s (91.9%) R:    150/s (100.0%)\n[Oct  9 16:21:42] [INFO] [8h3m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18200/s (92.4%) R:    150/s (100.0%)\n[Oct  9 16:22:42] [INFO] [8h4m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18300/s (92.9%) R:    150/s (100.0%)\n[Oct  9 16:23:42] [INFO] [8h5m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18300/s (93.3%) R:    150/s (100.0%)\n[Oct  9 16:24:42] [INFO] [8h6m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18300/s (93.8%) R:    150/s (100.0%)\n[Oct  9 16:25:42] [INFO] [8h7m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18300/s (94.2%) R:    150/s (100.0%)\n[Oct  9 16:26:42] [INFO] [8h8m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18300/s (94.7%) R:    150/s (100.0%)\n[Oct  9 16:27:42] [INFO] [8h9m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (95.2%) R:    150/s (100.0%)\n[Oct  9 16:28:42] [INFO] [8h10m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (95.7%) R:    150/s (100.0%)\n[Oct  9 16:29:42] [INFO] [8h11m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (96.1%) R:    150/s (100.0%)\n[Oct  9 16:30:42] [INFO] [8h12m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (96.4%) R:    150/s (100.0%)\n[Oct  9 16:31:42] [INFO] [8h13m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (96.8%) R:    150/s (100.0%)\n[Oct  9 16:32:42] [INFO] [8h14m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (97.2%) R:    150/s (100.0%)\n[Oct  9 16:33:42] [INFO] [8h15m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (97.6%) R:    150/s (100.0%)\n[Oct  9 16:34:42] [INFO] [8h16m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (98.0%) R:    150/s (100.0%)\n[Oct  9 16:35:42] [INFO] [8h17m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (98.4%) R:    150/s (100.0%)\n[Oct  9 16:36:42] [INFO] [8h18m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (98.8%) R:    150/s (100.0%)\n[Oct  9 16:37:42] [INFO] [8h19m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18400/s (99.1%) R:    150/s (100.0%)\n[Oct  9 16:38:42] [INFO] [8h20m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18500/s (99.5%) R:    150/s (100.0%)\n[Oct  9 16:39:42] [INFO] [8h21m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:40:42] [INFO] [8h22m0s] C:       0/s ( 0.0%) N:   51200/s ( 6.1%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:41:42] [INFO] [8h23m0s] C:       0/s ( 0.0%) N:   50400/s (13.0%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:42:42] [INFO] [8h24m0s] C:       0/s ( 0.0%) N:   50200/s (19.7%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:43:42] [INFO] [8h25m0s] C:       0/s ( 0.0%) N:   50200/s (26.6%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:44:42] [INFO] [8h26m0s] C:       0/s ( 0.0%) N:   50200/s (33.5%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:45:42] [INFO] [8h27m0s] C:       0/s ( 0.0%) N:   50300/s (40.4%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:46:42] [INFO] [8h28m0s] C:       0/s ( 0.0%) N:   50200/s (47.2%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:47:42] [INFO] [8h29m0s] C:       0/s ( 0.0%) N:   50200/s (54.1%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:48:42] [INFO] [8h30m0s] C:       0/s ( 0.0%) N:   50100/s (60.8%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:49:42] [INFO] [8h31m0s] C:       0/s ( 0.0%) N:   50100/s (67.6%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:50:42] [INFO] [8h32m0s] C:       0/s ( 0.0%) N:   50000/s (74.4%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:51:42] [INFO] [8h33m0s] C:       0/s ( 0.0%) N:   50000/s (81.1%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:52:42] [INFO] [8h34m0s] C:       0/s ( 0.0%) N:   49900/s (88.0%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:53:42] [INFO] [8h35m0s] C:       0/s ( 0.0%) N:   50000/s (94.9%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 16:54:27] [INFO] Writing OSM data took: 8h35m45.425395065s\n[Oct  9 16:54:27] [INFO] [8h35m45s] C:       0/s ( 0.0%) N:   50000/s (100.0%) W:   18500/s (100.0%) R:    150/s (100.0%)\n[Oct  9 17:13:53] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen1 took: 19m26.031911487s\n[Oct  9 17:15:03] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen1 took: 20m36.070114056s\n[Oct  9 17:18:29] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen1 took: 24m2.160830013s\n[Oct  9 17:41:06] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen1 took: 46m39.334818318s\n[Oct  9 17:44:34] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen0 took: 3m27.486238851s\n[Oct  9 17:45:45] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen0 took: 4m38.570748409s\n[Oct  9 17:46:24] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen0 took: 5m18.079130212s\n[Oct  9 17:51:27] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen0 took: 10m21.156595666s\n[Oct  9 17:51:27] [INFO] [PostGIS] Creating generalized tables took: 57m0.491603489s\n[Oct  9 17:51:29] [INFO] [PostGIS] Creating OSM id index on osm_transport_areas took: 1.718912763s\n[Oct  9 17:51:31] [INFO] [PostGIS] Creating geometry index on osm_transport_areas took: 2.122709994s\n[Oct  9 17:51:31] [INFO] [PostGIS] Creating OSM id index on osm_amenities took: 3.842486531s\n[Oct  9 17:51:34] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers_interpolated took: 2.770671097s\n[Oct  9 17:51:40] [INFO] [PostGIS] Creating OSM id index on osm_transport_points took: 12.487013102s\n[Oct  9 17:51:44] [INFO] [PostGIS] Creating geometry index on osm_amenities took: 12.820996196s\n[Oct  9 17:51:46] [INFO] [PostGIS] Creating OSM id index on osm_barrierpoints took: 2.0405118s\n[Oct  9 17:52:06] [INFO] [PostGIS] Creating geometry index on osm_housenumbers_interpolated took: 32.042143361s\n[Oct  9 17:52:10] [INFO] [PostGIS] Creating geometry index on osm_barrierpoints took: 23.519926191s\n[Oct  9 17:52:10] [INFO] [PostGIS] Creating OSM id index on osm_aeroways took: 349.755212ms\n[Oct  9 17:52:12] [INFO] [PostGIS] Creating geometry index on osm_aeroways took: 1.987600364s\n[Oct  9 17:52:42] [INFO] [PostGIS] Creating geometry index on osm_transport_points took: 1m1.692983083s\n[Oct  9 17:56:20] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers took: 4m13.500012355s\n[Oct  9 17:58:16] [INFO] [PostGIS] Creating OSM id index on osm_waterways took: 6m4.304477711s\n[Oct  9 18:07:17] [INFO] [PostGIS] Creating geometry index on osm_waterways took: 9m0.942106493s\n[Oct  9 18:07:34] [INFO] [PostGIS] Creating OSM id index on osm_places took: 16.738107383s\n[Oct  9 18:08:54] [INFO] [PostGIS] Creating geometry index on osm_places took: 1m19.908755074s\n[Oct  9 18:10:45] [INFO] [PostGIS] Creating geometry index on osm_housenumbers took: 14m25.801850603s\n[Oct  9 18:11:48] [INFO] [PostGIS] Creating OSM id index on osm_admin took: 1m2.866706283s\n[Oct  9 18:17:05] [INFO] [PostGIS] Creating OSM id index on osm_roads took: 25m37.202907001s\n[Oct  9 18:19:34] [INFO] [PostGIS] Creating OSM id index on osm_landusages took: 10m39.742781254s\n[Oct  9 18:20:24] [INFO] [PostGIS] Creating geometry index on osm_admin took: 8m35.654479159s\n[Oct  9 18:20:59] [INFO] [PostGIS] Creating OSM id index on osm_barrierways took: 34.535077417s\n[Oct  9 18:21:58] [INFO] [PostGIS] Creating geometry index on osm_barrierways took: 59.306611588s\n[Oct  9 18:25:16] [INFO] [PostGIS] Creating OSM id index on osm_waterareas took: 3m18.077083582s\n[Oct  9 18:27:51] [INFO] [PostGIS] Creating OSM id index on osm_buildings took: 35m9.214271801s\n[Oct  9 18:32:20] [INFO] [PostGIS] Creating geometry index on osm_waterareas took: 7m4.53192568s\n[Oct  9 18:32:41] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen1 took: 20.316986441s\n[Oct  9 18:33:11] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen1 took: 29.771705731s\n[Oct  9 18:33:14] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen0 took: 3.275610329s\n[Oct  9 18:33:30] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen0 took: 16.679476446s\n[Oct  9 18:34:49] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen0 took: 1m18.702742761s\n[Oct  9 18:42:18] [INFO] [PostGIS] Creating geometry index on osm_roads_gen0 took: 7m28.627995703s\n[Oct  9 18:42:41] [INFO] [PostGIS] Creating geometry index on osm_landusages took: 23m7.591260986s\n[Oct  9 18:43:37] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen1 took: 1m19.557107691s\n[Oct  9 18:43:50] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen0 took: 1m8.452232903s\n[Oct  9 18:50:04] [INFO] [PostGIS] Creating geometry index on osm_waterways_gen0 took: 6m14.119449063s\n[Oct  9 18:50:09] [INFO] [PostGIS] Creating geometry index on osm_roads_gen1 took: 6m31.985523216s\n[Oct  9 18:51:14] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen1 took: 1m9.705042752s\n[Oct  9 18:51:50] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen1 took: 1m41.156671184s\n[Oct  9 18:54:42] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen1 took: 2m51.429006864s\n[Oct  9 18:54:57] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen0 took: 15.498820169s\n[Oct  9 18:55:51] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen0 took: 53.3650642s\n[Oct  9 18:56:33] [INFO] [PostGIS] Creating geometry index on osm_waterways_gen1 took: 5m19.737411945s\n[Oct  9 19:15:10] [INFO] [PostGIS] Creating geometry index on osm_roads took: 58m5.694728623s\n[Oct  9 19:39:51] [INFO] [PostGIS] Creating geometry index on osm_buildings took: 1h11m59.635023833s\n[Oct  9 19:39:51] [INFO] [PostGIS] Creating geometry indices took: 1h48m23.029634352s\n[Oct  9 19:39:51] [INFO] Importing OSM data took: 11h21m8.948190644s\n[Oct  9 19:39:51] [INFO] Imposm took: 12h23m41.821079397s\n. Size of a full OSM planet database including indizes (on ext4) is 194 GB.\n. New infrastructure is providing much better IO. :+1:  Importing the world is nearly twice as fast.\nI am using an attached SSD now (instead of the persistent volumes that go over the wire and therefore can never provide the IOPS a local SSD can).\nI can later clone that volume, create a new local one and then attach it to the workers.\nMakes updating much more a pain in the later run but is more performant.\nWill test the other option with one shared volume (with workers accessing as readonly) as well.\n. Did a test run for one z2 tile (4^6 jobs -> 4k jobs).\n\nI will try to stitch it together later that day and check how everything workes out.\nThis is quite a data-heavy area but in worst case we might have 12h for 4k z8 tiles.\nThis is without HSR infrastructure (which is still importing).\nSo new estimate would be (64 / 4) * 12 192h -> 8 days\n\n. Just checked the size.. it is better than in earlier tries but we still have some tiles with more than 500KB. At least no longer any monster tiles.\nSadly the MBTiles of this file is already 23GB and Europe is half the data..\nThe reason tiles need to be below 500KB is that they can be styled in the new Mapbox Studio.\nThe use case there is that people will upload a small data sample from our MBTiles and style that. Because most people only have a limit of 100MB for upload.\n8/129/88    597.2 kB\n12/2074/1408    530.6 kB\n12/2074/1409    561.1 kB\n14/8298/5634    544.1 kB\n14/8300/5635    521.9 kB\n14/8298/5635    651.0 kB\n14/8299/5635    638.9 kB\n14/8298/5636    632.6 kB\n14/8299/5636    700.3 kB\n14/8300/5636    529.6 kB\n14/8298/5637    512.4 kB\n14/8257/5982    592.3 kB\n14/8258/5982    549.9 kB\n8/131/84    817.1 kB\n12/2103/1346    517.9 kB\n14/8403/5381    503.7 kB\n14/8402/5383    664.1 kB\n14/8403/5383    593.6 kB\n14/8413/5383    657.1 kB\n14/8414/5383    810.1 kB\n14/8412/5384    592.8 kB\n14/8413/5384    984.9 kB\n14/8414/5384    1.0 MB\n14/8415/5384    681.0 kB\n14/8416/5384    586.2 kB\n14/8412/5385    560.8 kB\n14/8413/5385    732.2 kB\n14/8414/5385    869.3 kB\n14/8415/5385    805.0 kB\n14/8416/5385    646.7 kB\n14/8427/5395    514.3 kB\n14/8396/5399    581.1 kB\n14/8396/5400    703.0 kB\n14/8437/5400    546.6 kB\n14/8424/5404    761.6 kB\n14/8386/5405    550.1 kB\n14/8387/5405    610.3 kB\n14/8388/5405    547.4 kB\n14/8425/5404    687.8 kB\n14/8386/5406    780.1 kB\n14/8387/5406    877.9 kB\n14/8388/5406    775.0 kB\n14/8424/5405    579.8 kB\n14/8425/5405    692.7 kB\n14/8385/5407    540.2 kB\n14/8386/5407    525.1 kB\n14/8387/5407    562.3 kB\n14/8388/5407    641.5 kB\n14/8424/5406    508.5 kB\n14/8389/5411    513.6 kB\n14/8390/5411    583.0 kB\n14/8395/5416    591.6 kB\n14/8395/5417    674.6 kB\n14/8396/5417    584.0 kB\n14/8394/5418    605.9 kB\n14/8396/5419    602.2 kB\n14/8404/5426    509.1 kB\n14/8433/5434    506.8 kB\n8/131/85    691.4 kB\n14/8423/5443    554.7 kB\n14/8422/5444    530.7 kB\n14/8423/5444    587.8 kB\n14/8389/5495    510.0 kB\n14/8391/5495    514.6 kB\n14/8389/5496    505.4 kB\n14/8390/5497    502.6 kB\n14/8437/6001    592.4 kB\n14/8436/6002    576.2 kB\n14/8490/5319    533.0 kB\n14/8490/5320    676.1 kB\n14/8458/5423    524.7 kB\n8/132/85    1.1 MB\n8/133/85    930.9 kB\n9/266/170   503.3 kB\n8/133/86    615.1 kB\n8/133/87    597.7 kB\n8/133/89    554.0 kB\n14/8634/8006    508.2 kB\n14/8635/8009    552.8 kB\n8/134/86    689.0 kB\n8/134/87    676.6 kB\n8/134/88    570.7 kB\n8/134/89    547.5 kB\n8/134/91    664.5 kB\n12/2152/1465    802.5 kB\n14/8704/5971    533.6 kB\n12/2190/1522    564.9 kB\n12/2190/1521    507.7 kB\n14/8878/6347    607.2 kB\n14/8878/6348    590.8 kB\n14/8936/5681    529.2 kB\n12/2318/1579    561.3 kB\n. I want to finish this part of the map. This should be done by tomorrow and we get more information.\nAfter that we have a quarter of the map and should see accurately nicely how size and speed will turn out.\n\n. Archived conversation:\n\nWe have weird spikes in completion time.\nWe investigated a bit yesterday. Also restarted most Docker services but that didn't help.\nOne hypothesis was that it is because now it is rendering land again (with the Americas) while\npreviously it was all ocean and ice.\nWhen I was rendering Europe it was about 4k tiles per 12h - the same speed we now have again.\nBut I also randomly checked one tile that took quite long - and it was a water tile?!\nI will check some more tiles that took long and were rendered in the night.\nAt the moment it look like it is going in the right direction again since 3hrs.\n. Getting better now. Back to the level when we were rendering Europe.\n\n. Back to bad again...really have no idea know other than the queries are just that more expensive. Must be the tiles not infra - HSR server takes long for the tiles as well. HSR infrastructure is helping now to keep up with slowed down time. Sometimes close to the 20min hard limit of jobs.\n\n. Perhaps this is just a cake walk with tessera.\nhttps://github.com/mojodna/tilelive-xray\n. This is amazing. Huge thanks to @petrsloup.\nEspecially the tile inspector will be a big help at this stage. We will use this to take closer look at the Mapbox layers too see which layers are visible where and how many are shown (a visual approach to our tile comparing).\nThe X-Ray preview has similar features to Mapbox Studio Debug Viewer but more practical to use because it shows the values on hover and we don't have to always try to click on tiny elements.\nIs the source also available so we can look at it / contribute?\nIf not it is not that bad because we can just modify the source of the page and point it to Mapbox Streets.\n. Just the links. Great trick to allow appending the TileJSON url to the url hashbang btw.\nMapbox Streets X-Ray Preview:\nhttp://klokantech.github.io/ol3-sandbox/vector/xray.html#http://a.tiles.mapbox.com/v4/mapbox.mapbox-streets-v5.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ|47.35929250871075|8.562469482421875|13\nMapbox Streets Tile Inspector:\nhttp://klokantech.github.io/ol3-sandbox/vector/tile-inspector.html#http://a.tiles.mapbox.com/v4/mapbox.mapbox-streets-v5.json?access_token=pk.eyJ1Ijoib3NtMnZlY3RvcnRpbGVzIiwiYSI6ImNpZnlkb2d0dTAyaDd1M2x6ZGg5cGp4aXQifQ.74RX5npQKmCE1jxsbXYNzQ|47.389696670088995|368.5221578025774|13\n. I want to keep the documentation on our own http://osm2vectortiles.org page where we also provide download links, introduction etc. We can still write Markdown like before and just use Github Pages. That's the easiest way to do it where we have the most control.\nRead the docs gives better options (with Sphinx and restructured text) for generating documentation but by controlling the page ourselves we can make it look better and more uniform and can also build our own custom stuff into the page (like Mapbox GL samples or data comparisons).\nChanges on http://osm2vectortiles.org/ are online (not looking good on mobile though).\n\n. I don't know where to best put this but a few things I noticed when we talked with people about the project\n- People care about labels and label ranks -> new idea there was using Wikipedia links of OSM data to determine importance (but that's a topic for itself)\n- People don't like that data in the vector tiles might be missing because it is not considered important by us\n- People do like that there is an open alternative to the all mighty Mapbox\n- It was asked pretty quickly, how the MBTiles would get updated\n- Disputed borders really are kind of a undecided problem. People map the border and set disputed=yes. And borders are the relations that are updated the most.\n- People are also interested in rendering MBTiles themselves (so making our PostGIS / export stack approachable would make also sense - it is not just for us)\n- Documentation will be absolutely crucial - explaining the project on the site and helping as fast as possible to get to the goal of MBTiles is important\n- Packaging tessera/Mapbox GL locally makes for an extrem good demo use case even though it is perhaps of limited use. One can just give the people an executable (on a branded stick?), they click on it and choose an MBTiles and voil\u00e0 - a nice map rendered from own data from OpenStreetMap. This will get people talking. Docker while very powerful and actually the end goal is an additional obstacle when just trying to get started as fast as quickly (My guess is especially for Windows people)\n. Copy sample data outside of the container so people have something.\nSo when people click on the volume Docker can copy the sample data there.\n. In my opinion this has been resolved.\n. > We have just fixed the vector tile opening via TileJSON from tileserver-mapnik into MapBox Studio Classic\nWow nice!! So the TMS/XYZ issue has been resolved?\n. Imposm supports the diff mode and importing changes files works however now that we see how much time rendering the vector tiles MBTiles of the whole world takes we need to think about our approach.\nWe cannot simply rerender the tiles, instead we would have to keep track of the changed tiles and explicitly rerender those tiles. This is quite a big feature if we would really want to do that.\nPerhaps this requirement of updating the world MBTiles does no longer fit into the time budget of this project.\n. Comment moved to https://github.com/osm2vectortiles/osm2vectortiles/issues/14\n. yes..detaching from milestone makes more sense than closing it.\nSent from my iPhone\n\nOn 17 Nov 2015, at 17:18, Petr Pridal notifications@github.com wrote:\nReopened #16.\n\u2014\nReply to this email directly or view it on GitHub.\n. Next step is to apply the diff updates with imposm3 to figure out how diff updates work.\n\nRead the Golang https://github.com/omniscale/imposm3 code to find out what extra information about changed tiles (from applying the diffs) is available and how we can use that to detect dirty tiles.\n. Goal: On the osm2vectortiles downloads we want to have daily diffs of the data.\nFor each update that imposm3 does on the database we need to know a timestamp. Perhaps we can implement a INSERT  trigger that will set a new timestamp or work with row versioning directly or perhaps implement something in imposm3 to track changes directly in the database.\nOnce we have a timestamp information about each row we can filter for the newest changed shapes and only rerender those tiles.\n. Geofabrik provides minutely diffs for countries. http://download.geofabrik.de/europe.html\n. > I have created some experimental imposm3 mapping types - like : jobstart_datetimeutc timestamp , maybe you can use!\n\nimportant: this code not working with the current imposm3 version, need adapting. If you need help : ping me - and I will create a patch.\n\nThanks a lot for participating in the discussion!!\nWe will check that out. Sounds like what we need!\n. > There is an interesting project : https://github.com/mapbox/tile-cover\nThanks for the golden tip! tile-cover is exactly what we need.\n. > Is it a convention that the mbtiles must have the same name as the tm2 project?- One could also have a mbtiles file called switzerland.mbtiles and a tm2 project called osm-bright.tm2. The mbtiles file is not always related to the style.\nThe docker container only supports one single project at the moment. Therefore it would be possible to link any mbtiles file with any tm2 project by default.\nBut in the future one might support multiple projects (like tileserver-php) does and then this convention makes a bit more sense.\n\nIn a future iteration we could give the possibility of declaring the name of the mbtiles file or just take any file with the .mbtiles file extension.\n\nAlot of people like explicit configuration better indeed.\nSomething like:\nMBTILES_FILE=/data/countries.mbtiles\nTM2_PROJECT_FILE=/data/countries.tm2\nThis might be a bit confusing because one has to take the path of the /data volume.\n. Another thing about tessera. It does not serve pbf files directly to clients like e.g. Mapbox Studio or Mapbox GL. This should be added in the future as well.\n. > Import Container cant connect to database container because the database requires the password to be md5 hashed.\nIf I follow the instructions on a clean machine I should be able to replicate this?\nIs this the osm user with a password differrent than osm?\n. Got another weird error on a small 500MB machine that I could not replicate.\n/docker-entrypoint.sh: line 70: cannot create temp file for here-document: Cannot allocate memory\nWe need to find out the system requirements. When importing I got an out of memory with imposm3.\nHowever I had no problems connecting with imposm3 o the postgresql container.\n. > Getting out-of-memory is a typical problem when converting ways to lines, since all nodes (which are referred to from the ways and contain the coordinates) need to be loaded or at least queried.\n\nIn osm2pgsql we initially had similar problems before setting \"slim mode\":\nhttp://wiki.openstreetmap.org/wiki/Osm2pgsql#Slim_mode\n\nMany thanks for this experience. There are some config options http://imposm.org/docs/imposm3/latest/tutorial.html#config-file that could be tweaked to get more conservative memory usage.\n- [ ] Measure memory usage of imposm3 and check the limits\n. Not able to replicate the md5 error so far.\nLog:\ndocker run --name postgis \\\n    -v /data/pgdata:/var/lib/postgresql/data \\\n    -e POSTGRES_USER=postgres \\\n    -e POSTGRES_PASSWORD=postgres \\\n    -e OSM_DB=osm \\\n    -e OSM_USER=osm \\\n    -e OSM_PASSWORD=osm \\\n    -d osm2vectortiles/postgis\nOutput:\n```\nThe files belonging to this database system will be owned by user \"postgres\".\nThis user must also own the server process.\nThe database cluster will be initialized with locale \"en_US.utf8\".\nThe default database encoding has accordingly been set to \"UTF8\".\nThe default text search configuration will be set to \"english\".\nData page checksums are disabled.\nfixing permissions on existing directory /var/lib/postgresql/data ... ok\ncreating subdirectories ... ok\nselecting default max_connections ... 100\nselecting default shared_buffers ... 128MB\nselecting dynamic shared memory implementation ... posix\ncreating configuration files ... ok\ncreating template1 database in /var/lib/postgresql/data/base/1 ... ok\ninitializing pg_authid ... ok\ninitializing dependencies ... ok\ncreating system views ... ok\nloading system objects' descriptions ... ok\ncreating collations ... ok\ncreating conversions ... ok\ncreating dictionaries ... ok\nsetting privileges on built-in objects ... ok\ncreating information schema ... ok\nloading PL/pgSQL server-side language ... ok\nvacuuming database template1 ... ok\ncopying template1 to template0 ... ok\ncopying template1 to postgres ... ok\nsyncing data to disk ... ok\nWARNING: enabling \"trust\" authentication for local connections\nYou can change this by editing pg_hba.conf or using the option -A, or\n--auth-local and --auth-host, the next time you run initdb.\nSuccess. You can now start the database server using:\npostgres -D /var/lib/postgresql/data\n\nor\n    pg_ctl -D /var/lib/postgresql/data -l logfile start\nwaiting for server to start....LOG:  database system was shut down at 2015-09-26 18:15:52 UTC\nLOG:  MultiXact member wraparound protections are now enabled\nLOG:  database system is ready to accept connections\nLOG:  autovacuum launcher started\n done\nserver started\nALTER ROLE\n/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/10_postgis.sh\nCREATE DATABASE\nUPDATE 1\nLoading PostGIS into template_postgis\nCREATE EXTENSION\nCREATE EXTENSION\nCREATE EXTENSION\nCREATE EXTENSION\nCREATE EXTENSION\nLoading PostGIS into postgres\nCREATE EXTENSION\nCREATE EXTENSION\nCREATE EXTENSION\nCREATE EXTENSION\nCREATE EXTENSION\nLoading vt-util functions into template_postgis\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\nCREATE FUNCTION\n/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/20_osm.sh\nCreating database osm with owner osm\nCREATE ROLE\nCREATE DATABASE\nLOG:  received fast shutdown request\nLOG:  aborting any active transactions\nLOG:  autovacuum launcher shutting down\nLOG:  shutting down\nwaiting for server to shut down....LOG:  database system is shut down\n done\nserver stopped\nPostgreSQL init process complete; ready for start up.\nLOG:  database system was shut down at 2015-09-26 18:16:00 UTC\nLOG:  MultiXact member wraparound protections are now enabled\nLOG:  database system is ready to accept connections\nLOG:  autovacuum launcher started\n```\nThen in the directory /data/import:\nwget https://s3.amazonaws.com/metro-extracts.mapzen.com/zurich_switzerland.osm.pbf\nThen import:\ndocker run --rm --name imposm \\\n    -v /data/import:/data/import \\\n    -v /data/cache:/data/cache \\\n    --link postgis:db \\\n    -e OSM_DB=osm \\\n    -e OSM_USER=osm \\\n    -e OSM_PASSWORD=osm \\\n    osm2vectortiles/imposm3\nOutput:\n[Sep 26 18:18:18] [INFO] [reader] reading /data/import/zurich_switzerland.osm.pbf with data till 2015-09-26 00:26:02 +0000 UTC\n[Sep 26 18:18:31] [INFO] [   12s] C: 7409000/s (2434364) N:   70800/s (31384) W:       0/s (384353) R:      0/s (1091)\n[Sep 26 18:18:31] [INFO] Reading OSM data took: 12.538288601s\n[Sep 26 18:18:31] [INFO] Imposm took: 12.53966314s\n[Sep 26 18:18:31] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Sep 26 18:18:31] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Sep 26 18:18:33] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Sep 26 18:18:35] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Sep 26 18:19:16] [INFO] [mapping] warn: zorder type is deprecated and will be removed. See enumerate type.\n[Sep 26 18:19:20] [INFO] Writing OSM data took: 48.892667108s\n[Sep 26 18:19:20] [INFO] [   48s] C:       0/s (0) N:    8700/s (31384) W:    9500/s (384353) R:    350/s (1091)\n[Sep 26 18:19:20] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen1 took: 62.961692ms\n[Sep 26 18:19:20] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen1 took: 773.614761ms\n[Sep 26 18:19:21] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen1 took: 122.466352ms\n[Sep 26 18:19:21] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen1 took: 921.142615ms\n[Sep 26 18:19:21] [INFO] [PostGIS] Generalizing osm_waterareas into osm_waterareas_gen0 took: 8.594081ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Generalizing osm_roads into osm_roads_gen0 took: 161.60764ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Generalizing osm_waterways into osm_waterways_gen0 took: 58.593286ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Generalizing osm_landusages into osm_landusages_gen0 took: 133.107723ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Creating generalized tables took: 2.242825964s\n[Sep 26 18:19:22] [INFO] [PostGIS] Creating OSM id index on osm_transport_points took: 6.371737ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Creating geometry index on osm_transport_points took: 52.424753ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Creating OSM id index on osm_places took: 5.781669ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Creating geometry index on osm_places took: 9.688599ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Creating OSM id index on osm_waterways took: 15.38781ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Creating geometry index on osm_waterways took: 56.781927ms\n[Sep 26 18:19:22] [INFO] [PostGIS] Creating OSM id index on osm_landusages took: 32.811096ms\n[Sep 26 18:19:23] [INFO] [PostGIS] Creating geometry index on osm_landusages took: 495.701173ms\n[Sep 26 18:19:23] [INFO] [PostGIS] Creating OSM id index on osm_admin took: 5.745659ms\n[Sep 26 18:19:23] [INFO] [PostGIS] Creating geometry index on osm_admin took: 4.158402ms\n[Sep 26 18:19:23] [INFO] [PostGIS] Creating OSM id index on osm_motorways took: 6.378245ms\n[Sep 26 18:19:23] [INFO] [PostGIS] Creating geometry index on osm_motorways took: 13.160455ms\n[Sep 26 18:19:23] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers took: 29.319599ms\n[Sep 26 18:19:23] [INFO] [PostGIS] Creating geometry index on osm_housenumbers took: 372.938085ms\n[Sep 26 18:19:23] [INFO] [PostGIS] Creating OSM id index on osm_roads took: 134.406989ms\n[Sep 26 18:19:25] [INFO] [PostGIS] Creating geometry index on osm_roads took: 2.290931655s\n[Sep 26 18:19:25] [INFO] [PostGIS] Creating OSM id index on osm_mainroads took: 10.845542ms\n[Sep 26 18:19:25] [INFO] [PostGIS] Creating geometry index on osm_mainroads took: 56.78444ms\n[Sep 26 18:19:26] [INFO] [PostGIS] Creating OSM id index on osm_minorroads took: 88.481339ms\n[Sep 26 18:19:27] [INFO] [PostGIS] Creating geometry index on osm_minorroads took: 1.170438295s\n[Sep 26 18:19:27] [INFO] [PostGIS] Creating OSM id index on osm_barrierways took: 5.810747ms\n[Sep 26 18:19:27] [INFO] [PostGIS] Creating geometry index on osm_barrierways took: 21.418123ms\n[Sep 26 18:19:27] [INFO] [PostGIS] Creating OSM id index on osm_barrierpoints took: 4.274905ms\n[Sep 26 18:19:27] [INFO] [PostGIS] Creating geometry index on osm_barrierpoints took: 13.985625ms\n[Sep 26 18:19:27] [INFO] [PostGIS] Creating OSM id index on osm_aeroways took: 2.192094ms\n[Sep 26 18:19:27] [INFO] [PostGIS] Creating geometry index on osm_aeroways took: 1.147361ms\n[Sep 26 18:19:27] [INFO] [PostGIS] Creating OSM id index on osm_buildings took: 178.68782ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_buildings took: 5.682785822s\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_transport_areas took: 57.384106ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_transport_areas took: 2.514972ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_housenumbers_interpolated took: 4.627406ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_housenumbers_interpolated took: 1.273504ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_waterareas took: 4.459777ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_waterareas took: 22.591076ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_amenities took: 3.392727ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_amenities took: 7.013615ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen1 took: 3.044772ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen1 took: 1.264709ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_waterareas_gen0 took: 2.058706ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_waterareas_gen0 took: 1.067293ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen0 took: 31.5211ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_roads_gen0 took: 255.974161ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_roads_gen1 took: 19.462774ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_roads_gen1 took: 243.612577ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen0 took: 10.548183ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_waterways_gen0 took: 40.664384ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_waterways_gen1 took: 6.142841ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_waterways_gen1 took: 69.235131ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen1 took: 10.272743ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen1 took: 32.21894ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating OSM id index on osm_landusages_gen0 took: 3.228397ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry index on osm_landusages_gen0 took: 3.008936ms\n[Sep 26 18:19:33] [INFO] [PostGIS] Creating geometry indices took: 11.607891144s\n[Sep 26 18:19:33] [INFO] Importing OSM data took: 1m2.743559952s\n[Sep 26 18:19:33] [INFO] Imposm took: 1m2.743873809s\n. We cannot fix that ourselves. The official Postgres image needs to fix that. It is a bit cumbersome for development but because most people will never execute the import step (as it requires huge infrastructure) it is not that bad if it only runs nice on Linux.\n. Created an issue at the tessera project.\nhttps://github.com/mojodna/tessera/issues/30\n. I think we should move this feature into the STABLE milestone and focus entirely on getting the source style and vector tiles produced in BETA milestone.\nTileserver PHP works quite wonderful with serving the vector tiles to MapboxStudio, I think of including it in the vectortile server just for the nice display and serving the PBFs to Mapbox Studio. This means the Docker image will get a bit fatter.\nThe rendering would be taken over by tessera (with an Apache redirect rule like the one that is used to redirect to the filesystem).\nOne architecture I would fancy:\n\n. What do you @manuelroth @klokan  think about supporting the newest iteration directly?\nhttps://www.mapbox.com/developers/vector-tiles/mapbox-streets-v6/#Overview\nAt the time we hit the STABLE release Mapbox Streets v6 will probably have replaced Mapbox Streets v5 (as it happened with v5 and v4).\nChangelog v6\nThe Changelog section in https://www.mapbox.com/developers/vector-tiles/mapbox-streets-v6/#Overview\n\nMost elements will appear 1 or 2 zoom levels lower compared to v5. For example, the street class of road was available from zoom level 12 and up in v5, and is now available from zoom level 11 and up. Depending on how your styles have been put together adjustments may be required when moving projects from v5 to v6.\n\nThis is the most important change.\n\nThe maximum vector tile zoom level has increased from z14 to z15. As always, overzooming to even higher zoom levels for rendering is possible.\n\nWe probably cannot handle z15 so we need to skip support for that feature.\nAdditionally there are some new fields in some layers.\n. Great insights, did not know about these details! That's what I hoped for in this discussion.\nYes all existing styles in Mapbox Studio Classic are for v5 and if v6 is primarily for MapboxGL they probably will not upgrade the styles of the \"old\" Mapbox Studio soon.\nWe have no chance at doing z15 as z14 is already quite a challenge.\n\nI would primarily target 100% v5 compatibility.\nWe may introduce some back-compatible GL JS improvements (like elevating some of the features to smaller zoom levels) if required.\n\nReading through it again it makes alot of sense to support v5 instead of v6. I guess we are able to make v5 look good enough for GL JS.\n\nIf we go for V6 which stops at z14 - the visual MapBox styles for v6 would still need to be modified, right?\n\nUsers just won't see all the details they would when overzooming. Styles targeting missing layers don't show up - but we are not really v6 compliant then.\n. Good ideas for a name? \nMy suggestion is something like open-streets (\u00e0 la mapbox-streets-v5).\nosm-bright-2 is a bit too specific when we try to be Mapbox compatible.\n. Oh attention, Switzerland only appears after z8. So one needs to zoom to at least z8. I always fall for that.\n. > which layers are still missing.\nGreat, now we already know more :+1: \n\nI created an issue in the open-streets repository to track which layers are still missing.\n\nCan we manage all issues in one repo? It is just easier to keep track off.\n. Ok :+1: \n. We discussed once that adding the missing data is more important than removing the data that is too much. But if it is possible we should save as much bandwidth as possible - every MB that is too much directly affects performance. Just rendering two z4 tiles is currently causing 10TB of throughput from SQL server to the export process.\nDon't want to be a nitpicker but regarding the source issues discussed above but now we already have several issues discussing stuff that is relevant for both repos in the source repository. (e.g. scale rank discussion).\n. > During the weekend I expected a sample from @manuelroth - when is it going to be delivered?\nWe pushed that deadline a week further. Just too many things were missing.\nWe will deliver the MBTiles for Switzerland this weekend.\n. > @lukasmartinelli will generate a mbtiles for europe over the weekend\nI will use the HSR infrastructure like last time. \n. > It seems to me that at z14 the borders are way too much generalized.\nThanks for the remark. Thats a small change, we just have to show the real water bodies instead of the generalized ones at higher zoom levels.\nThe map looks much better with the older v5 Mapnik OSM Bright style.\nMap looks ok with Mapbox GL but it expects the data one zoom level lower because it was programmed with v6 in mind. Perhaps we can add small improvements that make it a bit better on Mapbox GL.\nWe now have a blend between v5 and v6 but data in general is at the zoom levels v5 expects it to be.\n. > Top priority is having minimal tiles for OSM Bright 2 style, not a perfect compatibility with V5 or V6. Removing stuff is indeed important - every byte in a tile counts - because it is multiplied by 300 millions tiles ;-).\nWe have much less data throughput now. From what I see we have 5x to 8x less traffic between Mapnik and PostgreSQL than before. It is still in the TB's though.\n. Tried some things with tilelive modules and python landez. There is no existing way of merging mbtiles with different layers together - we would have to write that ourselves.\nI propose the following approach:\nI someone wants to put a custom data overlay over a custom styled OSM base map he should do that on\nthe client side with e.g. LeafletJS.\n. > I propose the following approach:\n\nI someone wants to put a custom data overlay over a custom styled OSM base map he should do that on\nthe client side with e.g. LeafletJS.\n\nWhat I mean is that the user pulls in base map layers but he can still use his custom produced thematic vector layer as an overlay. But he has to specify that in e.g. LeafletJS and the base map and thematic layer are not merged automagically into the same vector tile source.\n``` javascript\nvar grayscale = L.tileLayer(mapboxUrl, {id: 'MapID', attribution: mapboxAttribution}),\n    streets   = L.tileLayer(mapboxUrl, {id: 'MapID', attribution: mapboxAttribution});\nvar map = L.map('map', {\n    center: [39.73, -104.99],\n    zoom: 10,\n    layers: [grayscale, cities]\n});\n```\n. > Putting a \"thematic\" layer on top of a \"base map\" is best practice in cartography/GIS.\n\nSince this project is about making map styling so easy (possibly worldwide), we probably have to decide about which users we want to address: Is it both, or the few but important base map stylers or is it the mass users doing thematic maps? If we have to choose, I would concentrate on \"base map\" stylers.\n\nOne nice example where I think osm2vectortiles could have helped alot is this custom Nightlife map of Lisa Stolz (as a bachelor thesis).\nhttp://blog.geofabrik.de/?p=332\nInstead of using Geofabrik servers http://sanday.geofabrik.de/night.html?layers=0B\nperhaps she could have used our vector tiles to do the same styling.\n\n. In the bachelor thesis I found this sentence:\n\nWie auch Kosmtik greift die Software auf PostGIS zu und ist mit der neuen Version\nTileMill 2 noch immer ein g\u00e4ngiges Programm. TileMill 2 benutzt zudem Vektortiles,\ndie auf dem Server des Herstellers MapBox liegen. TileMill 2 ist im Vergleich zu\nTileMill 1 st\u00e4rker an den Hersteller gebunden. Da man bei der Erstellung des neuen\nKartenstils m\u00f6glichst unabh\u00e4ngig bleiben m\u00f6chte wird von der Nutzung von TileMill\nabgesehen und stattdessen Kosmtik verwendet.\n\nAnd this is really what we are trying to solve here, by providing our own vector tiles people can use Mapbox Studio Classic. Great to see that the problem really exist.\n. When using the tmsource tilelive provider whe do not need the Mapnik data.xml.\nhttps://github.com/mojodna/tilelive-tmsource\n. The quality of the tm2source is very good. I am tempted to switch to osm2pgsql just for this reason because it will save us alot of work but then there are all the disadvantages from an engineering perspective.\nI want to go the route of imposm3. And because we need to refactor alot of the queries anyway I would try to be directly compliant with mapbox-streets-v6 instead of mapbox-streets-v5.\nSince the bottleneck is the rendering of the world it is very important that we can deliver the fastest possible performance there and imposm gives us alot of room to optimize already at the import step.\nHowever we can learn alot of the tm2source of wikimedia. Especially at which zoom level they show what.\nWikimedia tm2source with osm2pgsql\nAdvantages:\n- Mapbox compliant styles for free (big one!)\n- Reuse (don't maintain a separate style)\nDisadvantages:\n- Slower tile generation (min. 2x) <- this could be improved by additional tuning\n- Performance tuning required for alot of queries (stored procs)\n- Slower import (6x)\n- Requires tweaking to work with latest Mapbox vt-util functions\n- GPL license\nSlower PostgreSQL\nAnother fun fact: It probably makes sense to create stored procedures just to save the bytes when transmitting the queries because the queries get sent billion of times over the wire (or IPC). In the docker daemon I see dozens of GBs that were sent from the export container to the database container.\nIn the case of wikimedia it actually sent 30GB of queries just for rendering switzerland (and  not even down to z14).\nAttributes are are stored in individual columns which are not indexed by default. And if we index them\nwe have the space tradeoff. With imposm we can map buildings directly into their own table and\nonly leave the tags we actually need.\nOne of the smallest queries is the query for buildings:\nsql\nSELECT osm_id, way\nFROM planet_osm_polygon\nWHERE\nz(!scale_denominator!) >= 14\nAND building IS NOT NULL\nAND building <> 'no'\nAND way && !bbox!\nThis query is not as bad because the GIST index already restricts the data to the polygons that are in the tile, but then all polygons need to be scanned whether they are buildings or not. And this pattern occurs\nall over the queries.\nAnd here the query for the roads. The mapping of the appropriate OSM tags happens in the queries, while in imposm it happens in the import directly. The CASE statement is not very performance critical though. But the WHERE clause hits the railway and highway attributes quite often which require an additional index to get the performance.\nsql\nSELECT osm_id, way, class, \"is\" FROM (\nSELECT\n    osm_id,\n    way,\n    CASE\n      WHEN highway IN ('motorway', 'motorway_link', 'driveway') THEN highway\n      WHEN highway IN ('primary', 'primary_link', 'trunk', 'trunk_link', 'secondary', 'secondary_link', 'tertiary', 'tertiary_link') THEN 'main'\n      WHEN highway IN ('residential', 'unclassified', 'living_street') THEN 'street'\n      WHEN highway IN ('pedestrian', 'construction') OR access = 'private' THEN 'street_limited'\n      WHEN railway IN ('rail', 'monorail', 'narrow_gauge', 'subway', 'tram') THEN 'major_rail'\n      WHEN highway IN ('service', 'track') THEN 'service'\n      WHEN highway IN ('path', 'cycleway', 'ski', 'steps', 'bridleway', 'footway') THEN 'path'\n      WHEN railway IN ('funicular', 'light_rail', 'preserved') THEN 'minor_rail'\n      ELSE bail_out('Unexpected road row with osm_id=%s', osm_id::TEXT)\n    END AS class,\n    z_order,\n    CASE\n      WHEN bridge IS NOT NULL AND bridge <> 'no' AND bridge <> '0' THEN 'bridge'\n      WHEN tunnel IS NOT NULL AND tunnel <> 'no' AND tunnel <> '0' THEN 'tunnel'\n      ELSE 'road'\n    END AS \"is\"\n  FROM planet_osm_line\n  WHERE\n    (\n        (\n          highway IN ('motorway', -- 'motorway'\n            'primary', 'primary_link', 'trunk', 'trunk_link' -- 'main'\n          )\n          AND z(!scale_denominator!) >= 6\n        )\n        OR\n        ( -- 'main'\n          highway IN ('secondary', 'secondary_link')\n          AND z(!scale_denominator!) >= 9\n        )\n        OR\n        ( -- 'main'\n          highway IN ('tertiary', 'tertiary_link')\n          AND z(!scale_denominator!) >= 12\n        )\n        OR\n        ( -- 'street'\n          highway IN ('residential', 'unclassified', 'living_street')\n          AND z(!scale_denominator!) >= 12\n        )\n        OR\n        ( -- 'street_limited'\n          (highway IN ('pedestrian', 'construction') OR access = 'private')\n          AND z(!scale_denominator!) >= 12\n        )\n        OR\n        ( -- 'major_rail'\n          railway IN ('rail', 'monorail', 'narrow_gauge', 'subway', 'tram')\n          AND z(!scale_denominator!) >= 12\n        )\n        OR\n        ( -- 'motorway_link'\n          highway IN ('motorway_link')\n          AND z(!scale_denominator!) >= 13\n        )\n        OR\n        ( -- 'service'\n          highway IN ('service', 'track')\n          AND z(!scale_denominator!) >= 14\n        )\n        OR\n        ( -- 'driveway'\n          highway IN ('driveway')\n          AND z(!scale_denominator!) >= 14\n        )\n        OR\n        ( -- 'path'\n          highway IN ('path', 'cycleway', 'ski', 'steps', 'bridleway', 'footway')\n          AND z(!scale_denominator!) >= 14\n        )\n        OR\n        ( -- 'minor_rail'\n          railway IN ('funicular', 'light_rail', 'preserved')\n          AND z(!scale_denominator!) >= 14\n        )\n      )\n    AND way && !bbox!\n) data JOIN (\n  VALUES\n    ('motorway', 1000),\n    ('main', 900),\n    ('street', 800),\n    ('motorway_link', 700),\n    ('street_limited', 600),\n    ('driveway', 500),\n    ('major_rail', 400),\n    ('service', 300),\n    ('minor_rail', 200),\n    ('path', 100)\n) AS ordertable(feature, prio) ON class=feature\n  ORDER BY z_order + prio +\n    CASE \"is\"\n      WHEN 'tunnel' THEN -100000\n      WHEN 'road' THEN 0\n      WHEN 'bridge' THEN 100000\n      ELSE bail_out('Unexpected row with is=%s, osm_id=%s', \"is\", osm_id::TEXT)::INT\n    END\n)\n. Discussion for our custom tm2source by @manuelroth  should be moved to a new issue. Evaluation of the tm2source has been completed.\n. We can take a look at the original osm bright tilemill project for the queries.\nhttps://github.com/mapbox/osm-bright/blob/master/osm-bright/osm-bright.imposm.mml\n. First tests for the world have been concluded. Some notes (mostly for myself).\nInteresting:\n1. For zoom level 0 to 9 PostgreSQL is the bottleneck with most queries taking quite a long time\n2. After that Mapnik takes most of the CPU while PostgreSQL still has to do alot of work\n3.  The throughput is heavy. Just to render from z0 to z10 it streams 3.3 TB of data from PostgreSQL to the Mapnik container. For z11 half way through it is already additional 5 TB.\nTiles from zoom level 10 on are much faster to generate but still require alot of throughput and CPU time.\nWe now use https://github.com/mojodna/tl for generating the MBTiles which is the  async.parallel feature. This actually utilizes the CPU capacity very well (100% usage).\nTimings:\nTo generate the entire planet from zoom level 0 to zoom level 10 it takes 21 hours and 55 minutes.\nOf these 1398018 tiles 1024566 tiles (73% -> matches pretty close with the 71% of earth water coverage) contain no data at all.\nOn average the renderer using 3 cores or approx. 8 AWS ECU processed 17 tiles per second.\nOn the second experiment where I tried to render z11 to z12 (but stopped) average was 17 tiles per second as well. So after z10 I guess one can estimate 17 tiles per second (using approx. 8 ECU).\nWhat needs to happen to render the world until zoom level 14?\nAlot actually. At z14 we have to render 358 million tiles which takes 358 million / (17 per second) -> 243 days - for z13 it would be 60 days. I guess the speed will increase much more as there are more and more zero data tiles at lower zoom levels so this is quite a wild guess. But it will definitly take a long long time for the lower zoom levels and the sheer amount of data volume passing through the containers is already a challenge in distributing this system.\nThe whole process has to be massively parallized if we want to achieve the goal of producing vector tiles for the world at z14. And this means PostGIS still needs to be able to keep up. At the end we perhaps even need to run several PostGIS servers serving several renderers.\nNotes for myself:\nGet zero tiles: cat export.logs | cut -d $'\\t' -f2 | grep -Fx  \"0\" | wc -l\nCalc sum of all tiles: cat export.logs | cut -d $'\\t' -f1 | grep '/' | wc -l\n-> for z10 it should be the same as 4^10+4^9+4^8+4^7+4^6+4^5+4^4+4^3+4^2+4^1\n. Comments to Petr.\n\nTo render cca 358 millions of tiles (1 + 4 + 16 + 64 + 256 + 1024 + 4096 + 16384 + 65536 + 262144 + 1048576 + 4194304 + 16777216 + 67108864 + 268435456 = 357913941) you could start the tasks with defined parallelism.\n\nI like the metapyramid idea for partitioning the work into tasks.\n\nI believe that if we can get rid of HTTP and crawling of the tiles from localhost web-server, and instead call the mapnik library directly\n\nThe tilelive module is using Mapnik directly via the Node bindings (no crawling or HTTP involved), there is no much overhead (since most work is IO related anyway).\n\nIf correctly implemented, all the processes could insert into the same SQLite. We do that with MapTiler - details can be provided on request.\n\nWe probably even need to generate multiple MBTiles and merge them together (since we probably have to go multi-host), rather than inserting in parallel. The landez library looks very promising for tasks like that and mbutil provides a patch utility as well.\n. Ideas for solving the parallelizing problem:\nSplit the world up in multiple databases each serving multiple local renderers.\nWe probably have to do work on multiple hosts with this amount of data and network throughput of that many TBs of data is not the best.\nCreate fat vector tiles at z13 and skip z14\nPerhaps by packing much more data into z13 instead of z14 and z15 we can overzoom much mure and it is probably faster for generating the mbtiles (although rendering the rasters will be slower).\n. Answers from Robert Nordan which are relevant for this topic.\nIs the process you have used with Tilelive.js documented somewhere?\n\nThe presentation is probably the best documentation I\u2019ve written! (The video files should be uploaded by FOSS4G soon so you can hear what I said as well..) Since it\u2019s been a part-time project here at work, things have been pretty fragmented and hacky. I wish I had a better answer.\n\nHow much time the rendering of Noway from your own data took?\n\nWe\u2019ve had some database trouble and I\u2019ve had to do other (paying) work, so I haven\u2019t been able to do all of Norway in full detail yet. But I did some tests with a subset of data and zoom levels up to 16 on a i7 desktop machine with 8 cores, connected to a rather weak database server. There it took around five days running in the background without any optimization to do all of Norway at Z16. It spread the work well over all the cores, and RAM usage was never very high, so I think the main issue was waiting on the database server. That was with a scanline method, some later tests down to level 14 (which is done in a matter of hours) showed that pyramids worked better for Norway. I think you can probably improve on these numbers quite a lot if you optimize all the stages properly!\n\nCould you please describe a bit more how you parallelised the vector rendering?\n\nThe parallelization was very simple: I used the tilelive.copy command (https://github.com/mapbox/tilelive/blob/5a968955510415edd5dc981592c2d88c95469758/bin/tilelive-copy#L30) without any concurrency options. That sets tilelive to use all the available cores (https://github.com/mapbox/tilelive/blob/master/lib/stream-util.js#L1) , which worked well on my desktop. However, I suspect that using it on a server with 24 cores has overwhelmed my database, so you should probably experiment with different values until you find the setting that gives maximum throughput before you try doing really big jobs.\n\nWhat storage system (MBTiles, key/value store, directory, SQL database) have you used for the vector tiles?\n\nI\u2019ve simply exported them to mbtiles using tilelive, which was quick and easy and lets me upload them to mapbox. I have noticed that mbtiles being an SQLite DB doesn\u2019t parallelize so great, so for the whole world you might want to look into other options. I know that mapbox uses serialtiles internally, though I don\u2019t really know how exactly they use them.\n\nWhat hardware infrastructure?\n\nAs I\u2019ve described, it\u2019s been a bit of this and a bit of that. But in general I would say you need the same kind of hardware that you would use to render traditional tiles. Good I/O speeds are important, when I tried writing tiles to a traditional hard drive instead of an SSD it went a lot slower.\n\nIs there a GitHub repo for the toolset you have used to produce vector tiles - so it can be reproduced?\n\nWe don\u2019t have a GitHub repo because all the code is rather messy and refers to a lot of internal stuff like our SLD style rules and database schemas which are sadly proprietary. I would like to clean it up, make it independent and put it out there, but don\u2019t have time right now.\n. Answer from Yuri from Kartotherian.\n\nWhy did you choose osm2pgsql and how are the query times for producing the vector tiles?\n\nWe chose osm2pgsql because it is well established and because it can generate the list of invalidated tiles - this way we can regenerate tiles that have been changed. We have been thinking about other options, but for now we will probably stay with osm2pgsql. The initial PBF import runs about 12 hours, after which we will only import the changes, which should be very fast.\n. Answer from Max from Kartotherian.\n\nWhy did you choose osm2pgsql and how are the query times for producing the vector tiles?\n\nimposm2 doesn't support replication, which is a showstopper for us. imposm3 is not yet production ready, and was even more raw when we were making our decisions. Having stock Debian packages for osm2pgsql/osmosis is also extremely nice.\n. Decision has been made.\n. Yeah nice work!\n\nI am not sure whether we want to check in the results into the Git repo (2k files is quite something).\nBut we definitely need to store the results somewhere.\n. Results are removed :+1: \n. This solves #12. I initially wanted to create a additional debug viewer container but we can kill that branch if we merge this pull request.\n. Yes we should actually work on the vector tiles not the visual representation for QA in our project.\nBut I guess the visual representation is more helpful for other project, e.g. to ensure when switching to our source that the map still looks the same.\nWhat is much better than scraping the tiles is generating a raster map.\nI wrote it all up in a blog post because I guess it is helpful to other people as well.\nhttp://lukasmartinelli.ch/gis/2015/10/16/creating-diff-maps-for-regression-testing.html\nI will close down this pull request because everything is decribed in the blog post and\nwe can use the script from there to generate a webmap when we want to do QA.\nFor CI integration textual diffs are much more helpful.\n. I want to exclude the water tiles at the job level. The enqueue-jobs component will ask the PostGIS database whether the tile bounding box touches any land polygons: If it does, the job is not even \"scheduled\". And the maskLevel tile implementation of tilelive-vector will then do the rest.\n\n. > BTW It seems the vector MBTiles produced by tilelive supports the internal symlinks. If you look inside with sqlite3 the tiles table is just a view for images - where the real .pbf blobs are stored.\n\nThis is normally used to store an empty PNG tile blob just once and use the same tile_id on multiple XYZ positions. This needs to be handled in the merge phase - and will be probably used for upper zoom levels (up from maskLevel) automatically by tilelive?\n\nI saw the same. For empty MBTiles there is just one blob record in the image table and all records in the map table reference it.\n. > If done this way, then it must run on non-generalised land polygons and we must really trust these land polygons...\nWe just found another problem. Admin zones that lap over land polygons could perhaps be affected if I query the land polygons only. But the land polygons we are using now are not generalized.\n\nOther approach would be to decide based on the bytesize / md5 or number of layers of a produced vector tile - so if an empty vector is detected, cancel all rendering bellow this particular tile in the renderer export process. But this approach is dangerous because it is very style dependant. I like to land polygon overlap more.\n\nYes I thought about this as well. We already have the vectortiles of the world down to z10 and I could check there and see whether a tile is empty or not and then decide to not schedule it.\n. > I wonder if it would not be better to run this test inside of the export job? There we have postgresql anyway, we could make the test on a zoom level defined in advance (docker's sysenv MASKLEVEL +1?) or the minzoom of the job, whatever is max, and set the job independently of the top level zoom of the job metapyramid. It would also allow non-paralelised rendering on a single docker instance to ignore the water tiles bellow maskLevel... Isn't it more elegant?\nThought about it. I'll move the logic into the export component.\nIn message based workflows I usually like to control the flow from a single point not from the workers themselves but in this case your proposed approach has indeed more pros than cons.\nPros:\n- enqueue-jobs component can stay stateless \n- Scalability is easier to achieve because queries are distributed (making that many queries for the job zoom level will take some time)\n- Works for a single docker instance as well.\n- export container knows more about the tile he needs to render than the enqueue-jobs component because he also knows the style etc.\n- It is easier to test because we don't need SQS as well\nCons:\n- It makes the rendering process more complex. Now it is just \"Render that BBOX\".\n- No single control point\nI really have to test whether the land polygon overlap works. I am no longer sure it will be that simple but hope so. In the end I want the fastest solution to implement to save the most work in rendering while still serving the correct tiles.\nPerhaps not every job needs to produce a MBTiles file. A MBTiles with a single z8 tile containing nothing is the same as not merging it at all.\n. Well thats suprising. They should reuse the z8 tile all the way down if they have a mask level specified..\nI just dumped them to GeoJSON (but should look at the raw vector tile data preferably) and they all look the same even if they differ in their binary form: They all contain a polygon spanning over the entire area of the tile with OSM id 0.\n. I really need to test the maskLevel out next thing I do. Generate MBTiles for some empty ocean and then I will just manually remove the higher layers, adjust the mask level and check how it looks.\n. If no maskLevel is set it is automatically assumed that the maskLevel is 10 https://github.com/mapbox/tilelive-vector/blob/24b2112a5b77c45f265c8b1834487a613884b7a5/backend.js#L37\n. Some research.\nRendering Times and Time/Space Savings\nMy hypothesis that water tiles render much faster than normal tiles was wrong!\nRendering water is only two to three times as fast as rendering urban areas.\nTime of local machine for a z8 all water tile: 206 seconds\nTime of server (8cores + 50GB): 84 seconds\nSize of MBTiles:  428KB\nTime of local machine for a z8 urban tile like around Zurich: 447.5  seconds\nTime of server (8cores + 50GB): 192 seconds\nSize MBTiles:  129MB\nIf we assume we can avoid rendering 40% of the world (even though 70% of world of water still have to render alot of water due to marine labels, borders, island etc). Because rendering water is 2.5x faster we can save 24% time (1 - 0.6 - (0.4 * (1 / 2.5))).\nWe can also save 11 GB in size of MBTiles (65536 * 0.4 * 428KB).\nImplementation Details of maskLevel in tilelive\nIf the source tells tilelive that the tile does not exist and zoom level is higher than the specified\nmask Level the tile parent with the masked zoom level for the missing tile is calculated and requested.\nExplained differently: If a z14 tile is missing and z8 is specified as mask level the z8 parent of a z14 tile is calculated and returned.\nhttps://github.com/mapbox/tilelive-vector/blob/24b2112a5b77c45f265c8b1834487a613884b7a5/backend.js#L85-L91\njavascript\nif (typeof backend._maskLevel === 'number' &&\n    err && err.message === 'Tile does not exist' &&\n    bz > backend._maskLevel) {\n    bz = backend._maskLevel;\n        bx = Math.floor(x / Math.pow(2, z - bz));\n        by = Math.floor(y / Math.pow(2, z - bz));\n        return source.getTile(bz, bx, by, sourceGet);\n}\n. There are two approaches.\nVariant 1: Query Data in Worker\nOne is to do the decision whether to render all tiles of z8 directly in the worker and avoid doing any extra work. In this case we need to query whether the source would render data. We need to build a query that is coupled to the source project.\nPros:\n- 24% savings in time\n- No additional component needed\nCons:\n- Prone to errors (query needs to be pretty close to the actual source project query)\n- More complex approach\n- How do we know that we haven't missed something?\nVariant 2: Optimize MBTiles\nWe could also do it in the aftermath after we generated the entire world. In this case we have to go through each z8 tile in the world MBTiles and check all it's descendants whether they contain the same data as the tile on z8. In this case we can remove them from the database.\nPros:\n- Simpler algorithm -> easier to test and no rerendering needed if something is skipped)\n- Also supports stuff like antarctica and desert\n- More generic (works with any source project)\nCons:\n- No saved time -> more expensive\n- Actual optimizing might take a long time (assumption?)\n. I personally want to do it afterwards (variant 2).\nThe querying is certainly doable in 6-8 hours but it is much harder to test and ensure quality.\nAnd if we don't render something we need to rerender that part and fix it.\nThe second approach (although not as elegant perhaps) is more straightforward to implement and does not have any loopholes. If the algorithm works it works for any source project and kind of data redundancy.\n. @klokan are you ok with the increased rendering time?\n\nThe second approach (although not as elegant perhaps) is more straightforward to implement and does not have any loopholes. If the algorithm works it works for any source project and kind of data redundancy.\n\nImplementation took only a hour. I can just check the checksum of the z8 tile and compare it with the\nchecksums of all descendants and I get the z8 pyramid which can be left out. Not performant but dead simple.\n``` python\ndef find_optimizable_tiles(mbtiles_file, maskLevel, scheme):\n    mbtiles = MBTiles(mbtiles_file, scheme)\n    parent_tiles = [t for t in mbtiles.tiles_at_zoom_level(maskLevel)]\ndef descendant_checksums(x, y, zoom, max_zoom):\n    for tile in all_descendant_tiles(x, y, zoom, max_zoom=14):\n        yield mbtiles.inspect_tile(tile.x, tile.y, tile.z)\n\nfor tile in parent_tiles:\n    parent_checksum = mbtiles.inspect_tile(tile.x, tile.y, tile.z)\n    counter = Counter(descendant_checksums(tile.x, tile.y, tile.z, 14))\n\n    checksum, _ = counter.most_common(1)[0]\n    if parent_checksum == checksum and len(counter) == 1:\n        yield tile\n\n```\n. Finally got some time to hack on it. Did a first test run with workers and SQS for switzerland and everything turned out fine so far.\nAWS\nSQS is used as job queue and S3 to store the MBTiles. I will distribute the access keys by email (as they should kept secret even though they are very restricted to the queue and bucket only).\nVerifying\nI still have to do a detailed inspect of the bounding box edges (to make sure the data is ok there after merging).\nI previously had experienced that Mapnik only generated partial vector data for tiles on the edges of bounding boxes (because it probably laps a bit over the bounding box). This is why I wrote a verifier script which verifies that a the MBTiles for example 8/133/90 contains all needed subtiles and also no other redundant data (which is a problem when merging the tiles together).\nhttps://github.com/geometalab/osm2vectortiles/blob/feature/verify/export/verify/verify.py\nGenerate Jobs\nThere is a jobmaker script which just generates the subtile jobs for a parent tile.\n1. Calculate all needed tiles for a zoom level (e.g. for switzerland we tell to generate jobs for 6/33/22 until zoom level 8)\n2. Push jobs to queue\nhttps://github.com/geometalab/osm2vectortiles/blob/feature/worker/export/jobmaker/create_jobs.py\nI still have to filter out all tiles that do not touch any land polygons #42 \nAt zoom level 8 a job takes roughly 15 minutes on my slow virtual machine.\nWork through Jobs\nI wrote an export.py Python wrapper around tilelive which\n1. Pulls job from queue\n2. Runs tilelive with the bounds specified in the job message\n3. Upload the MBTiles to S3\nhttps://github.com/geometalab/osm2vectortiles/blob/feature/worker/export/worker/export.py\nStitch the different MBTiles together\nThe aggregating of the tiles is not automated yet but for now I just ran the patch util from mbutil in a loop over all files from S3.\nhttps://github.com/mapbox/mbutil/blob/master/patch\naws s3 sync s3://osm2vectortiles-jobs .\ncp 133_88.mbtiles switzerland.mbtiles\nfor f in 1*.mbtiles; do\n   ./patch.sh \"$f\" switzerland.mbtiles\ndone\nWhich results in a stitched together vector mbtiles file of switzerland (350MB).\nThe patch util just does a replace into database which is pretty fast but I don't know yet how well it will scale for an SQLite database of several GBs.\nPRAGMA journal_mode=PERSIST;\nPRAGMA page_size=80000;\nPRAGMA synchronous=OFF;\nATTACH DATABASE '$1' AS source;\nREPLACE INTO map SELECT * FROM source.map;\nREPLACE INTO images SELECT * FROM source.images;\"\\\nBTW Amazon has just announced spot instances which are guaranteed to run for a certain time frame which are perfect for export tasks like these. \nhttps://aws.amazon.com/de/blogs/aws/new-ec2-spot-blocks-for-defined-duration-workloads/\n. @manuelroth just told me that we are gonna make z14 look perfect and then start rendering z14 because it is most of the work.\nI will need to adapt the scheduler to support another mode to the pyramid rendering (bounding box from z8 down to z14) where just one single zoom level over a very big bounding box is requested (bounding box from z14 to z14). But this is just a few lines of code and it changes nothing about merging the tiles so go for it :+1: \n. What I am doing currently is your idea of subpyramid rendering?\nCurrent Rendering Approach\nOne job is currently to render z8 until z14 for tile 8/143/89.\nWhich means rendering the bounding box below from z8 to z14. Which results in a MBTiles\ncontaining 4^0 z8 tiles, 4^1 z9 tiles, 4^2 z10 tiles down to z14. This is done for each z8 tile of the world.\n8.4375 47.040182144806664\n9.84375 47.989921667414166\nEvery tile in the map below is a separate job with all tiles down from z8 to z14.\nz8 can be done in a single export run (should only take a few hours).\n\nRendering\nIt would be really cool if we have z10 until z14 ready. Then we just create jobs for z10 - which are a bit smaller jobs than now at z8 - but it has to be tested anyhow what is faster.\n. That poor database..\nCONTAINER                       CPU %               MEM USAGE/LIMIT     MEM %               NET I/O\nosm2vectortiles_export_run_12   95.00%              198.3 MB/270.4 GB   0.07%               7.581 GB/93.45 MB\nosm2vectortiles_export_run_2    98.91%              164 MB/270.4 GB     0.06%               75.31 GB/1.11 GB\nosm2vectortiles_export_run_3    94.21%              289.5 MB/270.4 GB   0.11%               39.37 GB/552.9 MB\nosm2vectortiles_export_run_4    19.66%              125.6 MB/270.4 GB   0.05%               54.51 GB/810.6 MB\nosm2vectortiles_export_run_7    105.26%             225.4 MB/270.4 GB   0.08%               12.33 GB/155.1 MB\nosm2vectortiles_export_run_8    80.98%              150.4 MB/270.4 GB   0.06%               34.46 GB/477.2 MB\nosm2vectortiles_postgis_1       1535.97%            22.18 GB/270.4 GB   8.20%               2.832 GB/223.7 GB\n. Just exported a small version of europe down to z14. This took ~ 24  hours with 5 workers on our HSR infrastructure. Water is not excluded yet.\n\nFor rendering 960 z8 tiles down to z14 it took ~24 hours. With 87k z8 tiles for the entire world (including water!) it takes 91 days (40 z8 tiles per hour).\nBut this prediction is not correct at all:\n- Europe is half of the data of OSM (less edited areas are much faster to generate)\n- By avoiding water we can perhaps avoid rendering (60%? - world is covered by 71% water) of the tiles. \nSo perhaps by avoiding the water, optimizing database  and rendering less edited area takes less tim the real time to render with 5 workers might be less than 40 days.\nWith additional help of the Klokan Technologies infrastructure we can cut down that time even more (if we have 5 machines available for example).\nMBTiles Size\n\nThe world from z0 to z8 and big part of europe from z8 to z14 is 18GB. So expect to double that for the world MBTiles.\nOne single MBTiles at z8 only containing water is 400KB.\n\nI also rendered the world down from z0 to z8 and merged it with Europe.\nRendering the world took only 2 hours (and not even causing much IO/CPU).\nOther stats:\nRendering 900 z8 tiles caused 19TB of throughput from the database and 300GB incoming queries!\nThe tilelive rendering does not do internal connection pooling which is also a bit of performance drawback and makes it hard to attach more than 5 workers to the database (due to connection overhead).\nMBTiles is currently uploading to Google Drive. Oceans are there but we are missing the lakes (because it is the latest tm2source where we are working on).\nAnd here a gorgeous zoom in from z0 to z14!\n\n. Merging 900 SQLite databases does not have a scalability issue so far. Was pretty fast (15 minutes).\nOh and a very nasty trap I fell in. If I merge z14 tiles into a MBTiles where the max zoom level is 8\nit will still do overzooming from z8 for z14. \nOne needs to open the SQLite database and change the max zoom level in the metadata table for the map to work correctly.\n. > Why? This is wrong - a bug! A similar tile with 1 layer, 1 feature (ocean) has at MapBox 58 Bytes.\n\nIf a layer has no features, it should not be present in the vector tiles.\n\nOh sorry. This is a MBTile of an area like this. Not a single tile.\n\nSo those are actually 5461 tiles (all with ocean).\nImage data looks like this:\n\nAnd the empty ocean PBF is 85 bytes (but also why? - it should be 58 bytes).\n\nI also need to investigate why there are still different PBFs used even though it is all water.\n\n. PostgreSQL always has very high CPU while rendering (which is normally a bit weird for a database? - they should eat IO and memory).\nRendering with tilelive actually causes alot of open database connections which are closed and reopened alot - even though Mapnik is able to use a connection pool and even would support async querying from what I read.\nHigh CPU is usually the effect of having a too high max_connections setting.\nTo take the connection handling load from Postgres I now use a connection pooler https://wiki.postgresql.org/wiki/PgBouncer in front and use very aggressive connection pooling (statement pooling - so actually only one connection and transaction is used for the queries).\n. This was just a hypothesis but it turns out it does help indeed.\nIt does not help that much when only three workers are using the database like in the example below.\nBut for HSR where I have 7 workers attached it matters much more - since connection cost is not linear and I can now attach more workers to the same database.\n\n. Discussion moved to #47\n. > It seems that https://maps.wikimedia.org/ #28 are not using the Natural Earth data at all ... right? Do we have any comments from them on this point?\nI will ask them specifically but from the two people we asked last time this topic never popped up.\n. Quality of the labels is indeed quite noticable.\nMapbox OSM Bright\n\nWikimedia\n\n. > Where would it fit into our import process?\n\nShall this run always in the import container?\n\nI would like to create a new container rank-places like import-water because then each container has one single purpose and process. And from what I see it does not matter whether this runs before import or after import.\nWe need to query the improved places table ne_cities in the source project so the component is required to run otherwise the tm2source will fail.\nI will write that container, shouldn't take long. @manuelroth can then query the data at a later stage of our zoom level improvements.\n. Oh did not look to deeply into rank-places.py before, but it is a UPDATE so it must run after import.\nAnd because it requires the python runtime is additional pro for using separate image.\nWhat it does:\n1. Merge overrides into natural earth data\n2. Query natural earth data \n3. Query OSM data\n4. Do fuzzy matching in python of both results\n5. Update osm_places\nI will first try to fix the water problem. Then I will look into the ranks.\n. Didn't get https://github.com/mapbox/osm-place-ranks to work after first try. Doesn't find any matches in my case - it is pretty hacky code, I wonder how it worked once.\nPerhaps we just show the cities directly from natural earth data (and leave the translations from OSM be for lower zoom levels). Need to check that out.\n. We could use it to just do the mapping - that probably would be the best solution but also requires most time. \nLet's try simple name matching first and see how far we get - perhaps it is good enough.\nIn https://github.com/osm2vectortiles/osm2vectortiles/commit/cfa4ab5db33eac0a04819a8db90ed97d9bceb34d I just do very simple name matching in PostgreSQL (also tried using fuzzy matching in PostgreSQL like in the Python script but results where not that much better (just had more false positives) - so better have less scaleranks at all than wrong scaleranks in my opinon).\nWe now import the natural earth data in https://github.com/osm2vectortiles/osm2vectortiles/tree/feature/natural-earth so we can start querying it.\nThis introduced two additional docker containers (rank-places and import-natural-earth) but at one point we have to simplify the amount of docker containers again e.g. just use one import container for external data.\n. We can still use OSM data and just merge the scalerank for the following features:\n- Cities\n- Marine (Oceans and Seas)\n- Countries\nFor admin we have to try out how it looks if we just use Naturalearth data instead of OSM data - I don't know how detailed it is.\n. We just found out that actually all admin layers in Mapbox have the OSM id set to 0 until zoom level 13.\nOn zoom level 14 they have an OSM id.\nThis looks like they use natural earth data for admin down to z13 and then use OSM data.\n. Wrong assumption -> Mapbox only uses OpenStreetMap data for boundaries.\nWe can actually see that they have the same fails in boundaries as we have with OSM data.\nIn v6 they mark it as maritime so that it looks better.\nWhat we have to add is marking all boundaries which are in a water polygon as maritime=1\nBelow is all Mapbox with the same problems we have.\n\n\n\n. What we are doing now with the borders:\n- We take the maritime borders from OSM data because Natural Earth only provides partial data there\n- And we take all other data we take from Natural Earth (including disputed, country borders)\n. > But I just figured out, that if we add one to the natural earth scalerank of the marine labels we get very close to it.\n:+1: \n\nThere are still labels which have too high scalerank\n\nYes we have to write a normalize function that ensures the values are in the range specified by Mapbox.\nI did something similar for the place_label query.\n. > since we use osm data starting level 7 on the admin layer some borders are still broken\nYou mean OSM borders that are in the water but are not marked as maritime?\nCan we even solve this without fiddling with the data?\nAt least it looks much better from far away - having the weird borders show up when you zoom in looks much better and is perhaps even expected (I mean there must be some reason they exist - otherwise people wouldn't tag them).\n\nwe show too many marine labels with wrong scalerank\n\nIs it a problem of the matching - that some entities have higher scalerank than they should have from natural earth?\nPerhaps I match the wrong OSM ids with natural earth data?\n. Weird so the data of Mapbox has the iso_code  set as name? In v6 they provide it as additional field.\nIs the scalerank attribute set for the screenshot on the left? Because then Brazil and Mexico should be bigger..?\n. > But I still don't know how they decide when to show the iso codes of the countries.\nHave you tried using the iso_code as name for countries with e.g. a scalerank > 3?\nAnd I saw you use the labelrank from Natural Earth instead of scalerank - you know what the difference is there?\n. Hey @manuelroth that looks much better!! Thanks!\n\n@lukasmartinelli I found some issues with the name comparison.\n\nGreat. When importing with the container you should see how many rows have been updated.\nWe could go back to fuzzy matching - but I am a bit afraid we match too many.\nWe also seem to have quite different marine labels and they are quite difficult to get right from OSM data with matching alone. What about using only Natural Earth data for marine labels instead of merging it?\nWe could use the marine polygons (or there is also a point table) from Natural Earth for labeling and don't support all translations on seas.\n. > We may move the open-streets.tm2source into https://github.com/geometalab/open-streets.tm2source\nI'm not sure whats better..\nPoints for it:\n- Easier for people to explore\n- tm2source projects are usually in their own repo (Kartotherian and the others do the same)\n- Since comparison already happens there it makes sense to move it there as well\nPoints against it:\n- open-streets.tm2source is tightly coupled with water import and imposm schema (imposm3)\n- issue and documentation management is easier with one monorepo\n- we perhaps have to include it in this repo as git submodule or better git subtree - but both are a pain to work with\n. Let's move it into a separate repo and document all differences between our vector tiles and those from Mapbox there. Then we can also setup Travis there to only test generating the vector tiles and log its differences and on the main repo we can verify that the entire stack runs (one huge integration test).\nLet's leave it with the diffs like it is today. We can present the diffs in a nice way at the end of the project and they will also find their way into our thesis documentation.\nI like the verb based component names (works for everything except postgis):\n- postgis\n- serve\n- import\n- export\n- verify\n- merge\n- import-water\n- enqueue-jobs\n- test-performance\nOur components grow and grow :) I understand why Kartotherian is such a huge project now.\n. > Let's move it into a separate repo and document all differences between our vector tiles and those from Mapbox there.\nI really want to revert that decision.\nWhy?\nThe more I work with the two repos the more painful it is. The imposm mapping schema and the open-streets.tm2source project are just too intermingled / dependant on each other.\nIf I add something in imposm I also need to change something in open streets most of the times.\nThen I need two commits which have basically the same commit message. And if I work on a feature branch in imposm I have to create two feature branches.\nI also think we want to rely on SQL functions to reduce redundancy and stay DRY \nhttps://github.com/geometalab/open-streets.tm2source/commit/207c501f74958e7aa37434fd8406c89889f51900 (especially since the classification is done in SQL) which requires a prepare container  https://github.com/geometalab/osm2vectortiles/commit/418222fe5a0357850ec0db491e96a44f2e599c71 needing access to the SQL files to update.\nAlso export container is now cloning the open-streets repo down into the container but that also means that if the open-streets master branch no longer works together with the current master branch it just starts failing.\nIf we move back\nWe already have some discussion on the repository in open-streets but we can leave that archived there for some time or I try to copy it manually back here (as citations).\nI can merge the commits from open-streets (including history) back into this repo with git subtree.\n. It is your call @manuelroth  :grin: \n. Has been moved several times and at the moment our workflow actually works well in practice. The suggestions mentioned above won't bring significant improvement now.\nHowever if we have good idea how to improve automated testing we should create a new issue.\n. Let's fix the small stuff here later (technical debt :ghost: ). I want to merge stuff into master fast to get stable versions.\n. Let's use this issue for schema discussions instead of https://github.com/geometalab/open-streets.tm2source/issues/3\nHere is a first megaschema of our mapping. Drawing it took quite some time but showed up where data is still missing and where we need to improve the schema. We should probably refine this tomorrow @manuelroth.\nThis is not how the schema looks today but how it should look (except things like place_label where we need to find out more).\nOn the left you see the imposm tables and on the right how the layers should look like in the end.\nThis helps identifying where data from imposm is still missing (e.g. names in different languages).\nDiagram can be edited with draw.io and the PNG (containing all XML metadata needed for draw.io) is here https://github.com/geometalab/osm2vectortiles/blob/master/docs/figures/mapping_schema.png\n\n. Some notes what we should discuss about the layers tomorrow, what the problems are and how progress is.\nAdmin\nIn order to be able to merge the scalerank values from natural earth we should provide an empty field scalerank on the imposm table that can then be replaced by the natural earth data.\nIf there is no scalerank value we can calculate it from the area or something.\n- [x] But in general we just need to do a thorough investigation what the state of admin layers is\n- [x] Support maritime borders\nState labels are a weird affair. In old OSM Bright (based on v5) they are not even styled even though they are required but in styles for v6 they are styled. We have to check that when trying it out visually how it works not that we have information in both places and states.\nWe cannot support disputed areas easily. OpenStreet map has no no data there - only a proposal http://wiki.openstreetmap.org/wiki/Proposed_features/DisputedTerritories\nPerhaps we can add them at a later stage.\nRoads\nTunnels, roads and bridges are displayed correctly, sometimes the shield look a bit different.\nLater on we might also check how well our generalization works on the roads (do we strip no enough data away?).\nRailways are not good yet as too many rails are classified as major.\n- [x] Check railway classification -> We now map the railway service tag to detect whether it is a service rail\n- [x] Check shield labels\nAeroways\n\n[x] Add mapping\n[x] Check whether labels are included in the POIs\n[x] Show aeroways as lines\n[x] Verify different types of aeroways actually come out correcly\n\nWater\nThe water labels and marine labels we need to evaluate. I have never checked whether these are mapped correctly. I think marine labels will come from the water table as well but I am not sure.\n- [x] Find out more about marine label\n- [x] Check labels for fjords and bays\n- [x] Check labels for lakes\n- [x] Where are the labels for Oceans? -> marine_labels\nMarine labels are only for \"salty water\". Mapbox says big lakes are are marine labels as well but this is not true. They only appear from zoom level 2 to 6. Marine labels can be point or lines.\nHouses\nWe got this one, just need to cleanup. I saw that in Mapbox v6 very big buildings are also shown at lower zoom levels (not only z14).\n- [x]  Remove unnecessary values from housing and numbers table (like name)\n- [x] Large buildings appear at zoom level 13, and all buildings are included in zoom level 14 and up.\nPoint of Interests\nCorrect maki labels and classes need to be handled in the queries but we still need to demistify the\nnetwork tag and find the correct values. Also Mapbox specifies the ref value, but I could not found a POI on the official OSM Bright map with a ref value (so it is really necessary?).\nWe also need to merge transport points and areas into the point of interests. It might also be that aeroway points like helipads or airports should be contained in the POIs as well.\n- [x] Are aeroways points contained within POIs?\n- [x] Add network\n- [x] Add ref\n- [x] Include transport points into the POI table\n- [x] Add address to query and very it\nLandusages\nWe already added alot of tags and think are complete there.\nI haven't ever checked the #landuse_overlay layer though.\n- [x] Unify landusages_overlay and landusages\nBarriers\nBarriers shouldn't be too much work. We just need to look into it and check whether we have most of the barriers at z14. I think we are close but we just have never checked.\n- [x] Verify barrier data\n- [x] There is a bit a weird thing in the documentation where it is not sure whether barrier_lines only contains lines or additionally polygons or even points as well.\n. Code is messy but we can now automatically generate mapping diagrams from the tm2source (where I parse the SQL functions for referenced tables) and mapping.yml.\nhttps://github.com/geometalab/osm2vectortiles/commit/9c7b67f33fd7fd56b725bad4f5d592642c27c380\nLooks like this (old version - not our improved mapping, so we see lot of unused tables).\n\n. Creating the first diagram in the editor actually took more time than writing code to generate the second diagram :grinning: \n. When you are improving the queries you can actually look in the newest generated diagram which layers you need to adapt.\nLayers referencing stuff in a circle means that the tables has not been found so the query must be adapted to our new naming scheme.\nAnd in the end every table should be at least once be used from one layer (otherwise we should remove it).\n\n. Shall we already merge that? I think we will change the mapping quite a bit tomorrow as well and can then make sure the style works together with it.\nI also somehow lost the zorder ranks form landusages - need to include them again.\n. Let's merge this now. We have to do further work for this but we can create a new branch.\nAnd build is green because it works together with open streets at this point.\nAfter the merge we should create release for open streets and reference this in the export container \n(otherwise our tests will always fail on travis because they require an open-streets version depending on something other than the master branch).\n. We improved the scalerank significantly so that the local rank does no longer play such a huge role and seems to be at adequate level.\n. Maki icons can be mapped with the classify SQL generation from https://github.com/geometalab/osm2vectortiles/pull/63 as well.\n. Okay, of course build fails we need to fix the queries first.\nLet's just make sure they run through and don't crash and then improve the queries in a new branch.\n. > We probably can just append the functions to the end of the functions.sql file. So that we are still able to add other sql functions like 'format_to_uppercase'\nPerhaps easier to just create a new file and always overwrite it with what was generated. git will then automatically sort it out if something changed.\nIn the original functions.sql we can call these functions and do format_to_uppercase etc.\n. > @lukasmartinelli We have right now some generalized tables which are based on a type filters in the imposm mapping.\nYes I know. Assumption is that on the lower zoom levels different classes are shown - but I don't know whether it is really like that. We can check that out using the new Debug Viewer whether certain classes are hidden at lower zoom levels.\nI agree. Let's only do geometry simplification in the generalized tables. Filtering out the unnecessary types in the query is not really as bad for performance as on higher zoom levels (because rendering to z8 is quite fast anyway) and it is much cleaner that way :+1: \n. We reviewed mapping and queries.\n\n. We can actually find out whether a state is disputed (it is a bit messy though): https://github.com/kartotherian/osm-bright.tm2source/blob/master/data.yml#L378-L384\n. I suggest we skip the #state_label. In Mapbox v5 it is only partially completed (and no one of the styles is using it - Kartotherian neither).\nIt seems to be something for english speaking countries (supporting only US, Canada, Australia and GB) and it is not really clear for which admin_level this should be or whether it is a handcrafted layer.\nIn Mapbox v6 data set they additionally support chinese provinces but that's it. Some v6 styles start displaying it but they still look good if there is no state_label present.\nFor countries we already have the countries_label and most admin regions are already present in the place_label.\n\nWe can actually remove some data if we skip the layer because the state_label requires the correct area to be displayed and therefore needs the admin polygons and not the places table like other labels.\n. > Okey, I agree as it has no clear perpose and we can save some data. I will remove the unused fields of the admin table in the imposm mapping and remove the layer of the source project\nLet's check it out tomorrow when the world is imported whether we already get something useful out - if not we leave it.\n. - Funicular stations are tagged as \"railway=station\" and therefore have a too high scalerank\n- Because we modify the scalerank some stuff without area appears to early\n- No distinction between muslim and christian place of worships\n- Too many shields (because we always return default?)\n\n\n\n\nOSM Tag for harbor?\n\n\n. Golfclubs are missing?\n\n\n\n\n\n\n\n\n. For admin layers:\n- If zoom level <= z2 then all admin_level <= 3 are shown\n- After z3 more and more admin_level=4 are shown depending on the area of the admin layer\n- Until z6 where all admin_level=4 polygons are shown\n. \n. Improved some additional queries.\n\nNot yet, but I added the additional mappings to the classify.yml file in the generate-sql branch. We can merge this tomorrow.\n\nYep, let's do this later.\n\nI really enjoy these graphs. As the source project an mapping get more complex. It is nice to have an \noverview over what is mapped to what.\n\nIt has gotten out of control with all these layers and tables :grinning:  Difficult to fit it all into the head.\n. Replaced alot of UNION queries with WHERE statements. We only need UNION if we query different tables otherwise we can just specify big OR queries.\nI hope I got it sommentically the same as before.\nWe can still improve it alot but I want to merge it for now :)\n. > I already talked to IT staff at HSR and they are helping us. I apply for one VM and 100 GB storage.\nThanks alot - that is perfect!\n\nIs this storage estimation enough?\n\nShould be enough - more is better of course but the most important thing is that we can host the planet file on a network where we don't have to pay much for the traffic.\n\nWhat amount of traffic do we estimate? Around 100 planet downloads per day (= 5 TB)?\n\nThat's the best case. We won't get over 10 downloads a day in the start phase - and if Switch (but they have so much excess capacity) cannot handle the load we could still switch to a CDN.\n\nWhat could be a good name: \"Open Streets Vector Tiles\"?\n\nAll we need is a simple mirror to download files. Only needs to be an HTTP server like Apache which can serve large files for download. We can manage the download links from http://osm2vectortiles.org/data/download.html and just point to the server download urls.\n. > 1. how would point clustering fit into vector tiles format?\nOne approach to display millions and billions of points for example is using https://github.com/mapbox/tippecanoe\nThis actually works beautifully, one does pipe in GeoJSON features and tippecanoe will automatically drop points as it moves to lower level zoom layers.\nThat's how I was able to display 10 million points http://lukasmartinelli.ch/swiss-location/\nI don't know how well Mapbox GL handles that many features but there is a recommended max feature count per layer additional to the size limit of 500KB.\n\n\nand is there a fast query to count the total no. of features in a tile?\n\n\nThe compare script @manuelroth wrote is able to do that.\nIt parses the vector tile format, takes a look into each layer and counts the features (among other things).\n. Upload to Google Drive with the https://github.com/Grive/grive failed several times even with max. part size. This made me wonder - when users will download such a big file like 54 GB over HTTP they will nearly always run into download problems.\nWith the wget -c continue option it should be better but  downloading files without tools for special resumable HTTP downloads is not really easy for people who don't want to use the command line.\nI suggest we serve the big MBTiles file via Torrent as well (we can run it on the SwitchCloud VM).\nUsually people split up files like these into several parts that need to be merged again (and then use tools like e.g. http://jdownloader.org/). For the GitHub archive they do it like this https://www.githubarchive.org/. But then again for OSM planet they also provide a 46 GB planet file via HTTP - so it definitly works as well.\n. File available for download: http://downloads.osm2vectortiles.org/world.mbtiles\nA vector tile server is set up as well using tileserver-php: http://vectortiles.osm2vectortiles.org/\nIn Mapbox Studio Classic a user can now simply switch the TileJSON URL to http://vectortiles.osm2vectortiles.org/world.json and can start designing.\n. Basic and OSM Bright are now available.\nSadly all other available Mapbox Studio themes also use Mapbox Terrain.\n- http://osm2vectortiles.org/maps/basic-v8.html\n- http://osm2vectortiles.org/maps/bright-v8.html\nThe map is now embedded directly on the start page. Not sure if good idea yet.\n\n. I also set up a tessera based rastertile server for all mapbox-studio classic projects that use mapbox streets. And overview of the all the supported maps can be found at: http://osm2vectortiles.org/maps/\nThe server is also running on Switch http://rastertiles.osm2vectortiles.org on a different smaller server.\n\nI also found some severe bugs in this process :cry: , like too long labels in the carribean and a tile loading problem for new york (as if the tiles there are missing!).\n. Apart from that we put quite some time in it last week to make sure everything looks good on v6...so from my standpoint of view the big nasty things are done in the Mapbox GL optimization task.\n. > Amazing would be to have on the stick, next to the world MBTiles file (ideally under 32GB size), also a basic viewer running everywhere - just like the \"docker serve\" - but with basic double click start for most platforms.\nI like it - hope we have time for this. I forgot those kinds of applications - but they are as good use cases as having a custom base map.\nThat's the beauty of our project - because we provide the data it is possible to integrate it into offline applications like these.\nIt is very fancy nowadays to deploy packaged node apps as single binaries - there should be enough resources describing how to do this.\n. Compilation for Windows can be found here:\nhttps://github.com/mapbox/mapbox-studio-classic/blob/mb-pages/appveyor.yml and\nhttps://github.com/mapbox/mapbox-studio-classic/blob/mb-pages/scripts/build-appveyor.bat\n. > Another approach would be to create a basic QT application with binaries for different platforms which would use https://github.com/tmpsantos/qmapboxgl and render the vector tiles offline directly from the USB disk with OpenGL. We can try this approach at @klokantech.\nFor the end user this is the most convenient option as he gets a native application. Would need to work a bit on QT skills but for a basic application that should be doable. \nLet's keep it in the backlog for the kick off.\nbtw: It would also be cool if we can prototype something offline with Mapbox GL on Android.\n. Nice, now we have a skeleton to start with :+1: . If offline support is coming in Q1 \nhttps://github.com/mapbox/mapbox-gl-native/issues/584 we can actually do this.\n. This issue was primarily for the CeBit right? Can we close it?\nThe size problem with 64 GB is stated elsewhere.\n. > 60 GB\nIs this verified? A NTFS (or the planned filesystem) formatted 64GB USB stick still has 60GB of space?\n\nCould you prioritize the tasks related to world rendering and fixing of the SQL mapping - to start the rendering of world on cluster in following few weeks @lukasmartinelli @manuelroth?\n\n@manuelroth now works on v7 which includes a lot of mapping changes. It is the same as last time, we first need to freeze the mapping before we can start rendering at all. And this time it is even more important to have enough time for the mapping because you can't change it after the diff process is running.\nOur goal is to start rendering end of April so it will be close..\n. > Unverified. By looking on the web it seems the final limit for MBTiles is going to be more 59 GB - we may need some space for the software itself ~100 MB (Mac signed fat binary with Intel 32+64bit+PowerPC + Windows statically compiled QT for compatibility from XP SP3 above + probably a basic start.py for Linux or general multi-platform command-line use by hackers on a computer with python interpret).\nOkay, I know it is quite difficult to estimate.\nThe bad thing is we can only guess/estimate whether we will make it below 60GB even when we improve the road problem #86 (which might have already been resolved by #187). Especially since we are when we are adding stuff again when implementing v7.\n\nBTW what about to meet on Hangout this week to catch up on the progress?\n\nWhat about next week? Would also be good to have input from Andreas then to check how we should proceed.\n. Yes 2pm works. We have the next meeting at 3pm.\n. Some thoughts...\nAfter we have the updating process in place we need to render the world once (which is expensive once). After that we only update the changed parts (which we hope will be cheap when done continuously).\nIgnoring the water directly only saves 24% of the first rendering. For the update the ignore water feature doesn't help to improve performance at all - since empty areas won't have any OSM edits.\nYet another way to approach it is since we already rendered the world once we now know where the water is (from the subpyramid removal tool) and can prevent rendering directly based on a dataset that tells us which pyramids are water. This of course will not incorporate changes to empty areas that are now no longer empty (like if someone added a label to a large sea) - but I guess this is a really rare event. \n. My solution now is the same as in v1.0  (but automated) see the statement above for the justification.\nBefore the export_remote worker uploads the MBTiles file to S3 it will optimize it and remove all subpyramids that contain the same data (using the Python module from https://github.com/lukasmartinelli/mbtoolbox directly).\n. > Is this function necessary?\nWe need to turn the polygon into a point for labelling it.\nI thought creating the expression index should help speed up the select part because the point is already precalculated - but it turns out this doesn't help.\nMy guess is that calculating the point on surface for a very large polygon is expensive.\n\nAnd should'nt you use GISt index?\n\nThe GISt is actually used to find out, whether the polygon is even in the boundary.\nsql\ngeometry && ST_SetSRID('BOX3D(-12854262.17266152 8817164.086751651,-12850593.19530383 8820833.064109337)'::box3d, 3857)\n. Thanks for the analysis!! We are several factors larger in for most tile indizes.\nRoads should be possible to improve in a next release. Perhaps the roads are not filtered simply by class like we assumed but also filtered by other criterias.\nFunny that this slipped through - as I remembered we went through each zoom level for the roads and tried to bring it as close to Mapbox as possible.\nAt zoom level 14 it is difficult to throw away any buildings, roads and road labels because we do not have a z15 that can contain them like Mapbox does.\n. I have drawn 30+ lines.\nSadly a lot of marine labels are not present in OSM data. For these ones I just searched for the local name and added them by hand (but no other translations).\nThe red circles are not in OSM for example. http://rastertiles.osm2vectortiles.org/osm-bright/#6/16.541/-72.861\n\n\nThere is one bug #85 occuring that perhaps because the line is too long. \nBut apart from that I think lines are ok. We can still add more improvements later on.\n. Approach:\nWe use the Overpass API to extract states, countries, oceans and seas.\nThen we export GeoJSON features and edit those on geojson.io\nCountries:\n- update scalerank by hand\nStates:\n- remove small state\n- update scalerank by hand\nMarine:\n- update scalerank by hand\n- replace point geometry with hand drawn line geometry\n. Completed the approach from above:\nCommon credo: If possible every feature should have the corresponding osm_id set and take all data from there and we should\nuse hand crafted features carefully because we also have to maintain them.\nCountries\nRank has been updated - we do not have all countries from Mapbox (labels like islands that are not individual countries but belong to other countries) but everything that is in OSM enriched with a rank attribute.\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/feature/optimize-water-tiles/src/import-external/countries.geojson\n- [x] Still some countries missing like Algeria #79\nStates\nStates have been selected only for the same countries as Mapbox did but everything from OSM.\n- [x] We need to add states of the common wealth by hand as they are not in OSM #79\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/feature/optimize-water-tiles/src/import-external/states.geojson\nSeas and Oceans\nOpenStreetMap is missing many seas and bays that are important (like the Adriatic Sea) #78.\nBecause our dataset is based on OSM as well we are missing those.\nI added some missing seas but only with the english name. The translations would need to be taken\nfrom other sources like Wikipedia.\nFor some seas and bays I started drawing lines instead of points for nice label placement.\n- [x] Add more lines for OSM values\n- [x] Add additional seas that are not in OSM\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/feature/optimize-water-tiles/src/import-external/seas.geojson\n. Countries and states are ok now.\nCountries\n\n\nStates\n\n\n\n. Export has been split up into remote and local components.\nThe python wrapper no longer wraps around the local export (no benefits there).\nAnd the export-remote works like before (perhaps export-worker would be a better name).\nyaml\nexport-remote:\n  build: ./src/export\n  command: ./export-remote.sh\n  volumes:\n   - ./open-streets.tm2source:/data/tm2source\n  links:\n   - pgbouncer:db\n  environment:\n    AWS_ACCESS_KEY_ID: \"${AWS_ACCESS_KEY_ID}\"\n    AWS_SECRET_ACCESS_KEY: \"${AWS_SECRET_ACCESS_KEY}\"\n    AWS_REGION: \"eu-central-1\"\nexport-local:\n  build: ./src/export\n  command: ./export-local.sh\n  volumes:\n   - ./export:/data/export\n   - ./open-streets.tm2source:/data/tm2source\n  links:\n   - pgbouncer:db\n  environment:\n    BBOX: \"8.4375 46.07323062540838 9.84375 47.040182144806664\"\n    MIN_ZOOM: \"8\"\n    MAX_ZOOM: \"14\"\n. This is just for archival purposes.\n. Sorry for the inconvenience. That's why we should keep the master branch stable at all time :/\nIt also should have been documented better, but Travis was the right place to take a look :+1: \nIn the https://github.com/osm2vectortiles/osm2vectortiles/tree/feature/optimize-water-tiles branch are the newest changes, we will merge this soon so the issues you mentioned should be fixed.\n\nHey all! I am trying to demo this awesome repo & upon following the setup steps in the .travis.yml file, docker-compose run update-scaleranks fails with missing sql files: https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/update-scaleranks/update-scaleranks.sh#L22-L24. Then upon trying to export anyway I get a failure due to missing osm_countries table. Related: osm2vectortiles/osm2vectortiles#80\n\nWe have changed the way we import our custom labels. Should be good in the next merge.\n\nAs a side note, getting python to display the text from the tl subprocess when it fails in the export docker could be a really handy enhancement. So that way I don't have to docker run the export and exec the command by hand to see why it fails. Currently it only displays the exit code. Sweet, ty\n\nWe stop using a Python wrapper around tl in the next release so you get the raw output.\nThe wrapper is only used when using multiple workers for processing - if someone just wants to do a local export he should get the raw tl output. Thanks for the input.\n. > Can we get this feature into https://github.com/klokantech/tileserver-tessera docker?\nI'll create a pull request next week after thesis has been handed out.\n\nI would be happier to offer people the docker image from https://hub.docker.com/r/klokantech/tileserver-tessera/ for direct downloading and testing.\n\nIt makes sense. The serve container is kind of a foreign thing inside the osm2vectortiles project because it is just a method to serve the tiles and does not belong to the entire workflow.\nBut perhaps we should make the switch after we've handed out the code inside the thesis (because the serve component now is part of the thesis deliverables and after that it can be moved out to klokantech).\nLet's discuss this more thoroughly tomorrow.\nI also want to discuss when to use tileserver-php for serving vectortiles\nand how we should deploy it (with NGINX in front etc.).\n. In Mapbox Streets the lines actually get shorter while zooming in.\n\nBut Mapbox has the same problem with the labels (they appear several times).\nCould really be that those are lines split across multiple tiles. What one can do in this case is using a label grid again and ensure that only one label in 500px or so is shown of the same osm_id.\n\n. Sometimes stuff solves itself. This issue no longer occurs with Mapbox GL. \n\n. > Question: At \"Zoom Layer Reference\" http://osm2vectortiles.org/docs/layer-reference/ it's indicated that roads are included starting with zoom level 5. I think this could be true but at least in the raster version, roads are not shown: http://klokantech-3.tileserver.com/osm-bright/5/16/11.png . Why?\nThe zoom level table is for the data in the vector tiles not the rendered end product. \nAlot of styles also define certain zoom levels at which data appears. It is not uncommon that you only show data at closer zoom levels and not when it is already available.\n``` css\nroads [zoom >= 6] {\n// my style definitions\n}\n```\n. > I was just wondering why that is the case here, since both stylings - raster/Mapnik-rendered and vector/MapboxGL rendered - are called \"OSM Bright\"\nThe decision to where which layers should be shown was taken straight from Mapbox. @manuelroth went through the Mapbox Streets zoom levels and figured out which layers appear on which zoom level.\n\nbecause I am looking for ways to reduce vector tile size.\n\nI think simplifying the roads should help decreasing the size. We somehow forgot to generalize the roads at lower zoom levels - we had it at one point in time.\nBut the big difference lays in the number of road labels we have.\nPerhaps the simplifying can also solve the problems with many road parts like e.g. main roads (where some parts are not main roads and therefore there is no line at all but it would look better if it was just a straight line for styling even if it is not true).\n\n. I think this looks solved as of today @manuelroth?\nSize reduction indicates that we got the bad boy that made the tiles too big #266.\n\n. Find the real tiles that should exist.\nbash\nmercantile children \"[0,0,0]\" --depth 8 > correct_tiles.txt\nFind the list of MBTiles from S3\nbash\naws s3 ls s3://osm2vectortiles > real_tiles.txxt\nBring both in to the same format and also sort them.\nbash\nawk '{print $4;}' list_of_mbtiles.txt \\\n| sed 's/_z8-z14.mbtiles/_8/g' \\\n| sed 's/_/\\//g' \\\n| sort > fixed_real_tiles.txt\ncat mercantile_children.txt \\\n| sed 's/, /\\//g' \\\n| sed 's/\\[//g' \\\n| sed 's/\\]//g' \\\n| sort > fixed_correct_tiles.txt\nFind out the missing tiles\ndiff --unchanged-line-format=\"\" fixed_correct_tiles.txt fixed_real_tiles.txt > missing_tiles.txt\n. It really seems I forgot a tile area to schedule.\nhttps://gist.github.com/lukasmartinelli/b1a5c672dd83f344e76c#file-missing_tiles-csv\n. No completely wrong - the files actually are all there. One chunk of files was in a folder :see_no_evil: therefore they were not listed. In fact only 2 tiles are missing (and those are the same that were hanged up in the bucket).\nThis means it was a merging problem and requires no rerendering.\nThe tiles that are missing:\n49/70/8\n60/87/8\nI started a remerge of the files and then will check after it has finished whether it has been improved.\n. Wohooo good news. The remerge fixed the issues and the areas that were missing now are there. Seems some files were just not merged because they were in a other folder at the first merge: dumb mistake.\nCurrently uploading the files to drive and then I will also merge the lower zoom level tiles into it and put it on the download server as well. But it will take a while until everything is uploaded and updated.\nBad news - the MBTiles files are now even bigger:\n- All tiles from z8 to z14: 81GB\n- Tiles from z8 to z14 with water removed: 65GB\nWhen we do the second rerender and fix the roads this will drop down to the size where it fits on a USB stick again - but until then I would wait ordering them.\n. Running VACUUM on the database file saves 3GB. https://sqlite.org/lang_vacuum.html\nNow the world file from z0 to z14 with water removed is 62GB.\n. > downloads.osm2vectortiles.org\nHave to reupload it again. Missed correct zoom levels in MBTiles metadata.\nThe downloads.osm2vectortiles.org was actually the same Apache server that also served the vector tiles. So this was more for testing purposes. Now I upload the files directly to Switch S3. Thanks to @manuelroth for finding out how to do that in Switch.\nSadly one cannot associate a domain with Switch S3. The download urls look more like this:\n- https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/world_z0-z14_v1.0.mbtiles\nI will now start to version the files and start with v1.0 (even when they actually are from the v0.2 rendering but the upper level tiles are from the updated version that will be the v1.0 release this thursday). Files will end with suffix _v1.0.\nBTW. I cannot upload to Google Drive with rclone - it seems that if I upload the files are counted against my quota even when I upload to the Klokantech public folder. Weird issue. I will create a list of all downloads that we then have to mirror to Google Drive.\n. The world is already updated on the raster tile server (I repaired the metadata by hand for the world download).\nNew York is now looking good!! http://rastertiles.osm2vectortiles.org/osm-bright/#11/40.6601/-73.9915\n\nWhat also works now that I have the maskLevel set in the MBTiles is the overzooming into water (previously did not work with tessera).\n\n. > I will now start to version the files and start with v1.0 (even when they actually are from the v0.2 rendering but the upper level tiles are from the updated version that will be the v1.0 release this thursday). Files will end with suffix _v1.0.\nNope. Better idea - versioning makes more sense at a folder level.\nEach version will get it's own folder in the download bucket. The extracts of the version\ncontain the country extracts and the tiles contain the tile pyramid sources (what is now on S3) from which the world.mbtiles is built. The zoom suffixes can be omitted if it is from z0 to z14.\n.\n\u2514\u2500\u2500 v1.0\n    \u251c\u2500\u2500 extracts\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 andorra.mbtiles\n    \u251c\u2500\u2500 tiles\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 135_147_z8-z14.mbtiles\n    \u2514\u2500\u2500 world.mbtiles\n. > Are the data on a cloud mashine?\nNow it is finally uplaoded. This is the link for the fixed world mbtiles:\nhttps://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.0/world.mbtiles\n\nAnd the extracts?\n\nCurrently \"extracting\" the extracts.\n. The issue with the missing tiles is resolved from my point of view.\n. This is the script to create the all extracts\nhttps://gist.github.com/lukasmartinelli/33385087c01ca5f42487\nIt makes sense to run multiple once in parallel to speed this up.\nCurrently running the extracts.\n. Extract of Switzerland: https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.0/extracts/switzerland.mbtiles\nWe plan to merge the world from z0-z4 (20mb or so) into each country mbtiles because it looks a bit weird on lower zoom levels otherwise.\n. Extract of Czech Republic: https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.0/extracts/czech_republic.mbtiles\nThis already contains world z0 to z4.\nI've not been able to test the generated extracts yet - would be glad for feedback whether they worked.\n. Note to myself:\nI need to generate the following extracts later because they are quite large.\n./tilelive-copy --minzoom=0 --maxzoom=14 --bounds=-179.1591529,-52.9213686,179.4643594,-28.9303302 world.mbtiles extracts/new_zealand.mbtiles\n./tilelive-copy --minzoom=0 --maxzoom=14 --bounds=-9.7848145,-54.7539999,34.7891253,81.128076 world.mbtiles extracts/norway.mbtiles\n./tilelive-copy --minzoom=0 --maxzoom=14 --bounds=-180.0999999,41.0858711,180.1,82.1586232 world.mbtiles extracts/russian_federation.mbtiles\n./tilelive-copy --minzoom=0 --maxzoom=14 --bounds=-180.0999999,-14.8608357,180.1,71.7048217 world.mbtiles extracts/united_states_of_america.mbtiles\n./tilelive-copy --minzoom=0 --maxzoom=14 --bounds=-178.4873748,-50.3187168,172.4057152,51.368318 world.mbtiles extracts/france.mbtiles\n. Except the 5 extracts mentioned the rest of them is available for download at http://osm2vectortiles.org/data/download.html\n. Open until #92 is fixed.\n. I will reupload the extracts again and world again.\nFix the name.\nbash\nfor f in *.mbtiles; do sqlite3 \"$f\" 'update metadata set value=\"Open Streets v1.0\" where value=\"OSM Bright 2\"'; done\nFix the attribution.\nbash\nfor f in *.mbtiles; do sqlite3 \"$f\" 'INSERT OR IGNORE INTO metadata VALUES(\"attribution\",\"&copy; OpenStreetMap contributors\")'; done\nPatch bounds\nbash\nsqlite3 afghanistan.mbtiles 'update metadata set value=\"60.403889,29.288333,74.989862,38.5899217\" where name=\"bounds\"'\nsqlite3 albania.mbtiles 'update metadata set value=\"19.0246095,39.5448625,21.1574335,42.7611669\" where name=\"bounds\"'\nsqlite3 algeria.mbtiles 'update metadata set value=\"-8.7689089,18.868147,12.097337,37.3962055\" where name=\"bounds\"'\nsqlite3 andorra.mbtiles 'update metadata set value=\"1.3135781,42.3288238,1.8863837,42.7559357\" where name=\"bounds\"'\nsqlite3 angola.mbtiles 'update metadata set value=\"11.3609793,-18.1389449,24.18212,-4.2888889\" where name=\"bounds\"'\nsqlite3 anguilla.mbtiles 'update metadata set value=\"-63.7391991,17.9609378,-62.6125448,18.8951194\" where name=\"bounds\"'\nsqlite3 argentina.mbtiles 'update metadata set value=\"-73.6603073,-55.285076,-53.5374514,-21.6811679\" where name=\"bounds\"'\nsqlite3 armenia.mbtiles 'update metadata set value=\"43.3471395,38.7404775,46.7333087,41.400712\" where name=\"bounds\"'\nsqlite3 australia.mbtiles 'update metadata set value=\"72.1460938,-55.4228174,168.3249543,-9.090427\" where name=\"bounds\"'\nsqlite3 austria.mbtiles 'update metadata set value=\"9.4307487,46.2722761,17.260776,49.1205264\" where name=\"bounds\"'\nsqlite3 azerbaijan.mbtiles 'update metadata set value=\"44.6633701,38.2929551,51.1090302,42.0502947\" where name=\"bounds\"'\nsqlite3 bahrain.mbtiles 'update metadata set value=\"50.1697989,25.435,51.0233693,26.7872444\" where name=\"bounds\"'\nsqlite3 bangladesh.mbtiles 'update metadata set value=\"87.9075306,20.2756582,92.7804979,26.7382534\" where name=\"bounds\"'\nsqlite3 barbados.mbtiles 'update metadata set value=\"-59.9562114,12.745,-59.1147174,13.635\" where name=\"bounds\"'\nsqlite3 belarus.mbtiles 'update metadata set value=\"23.0783386,51.1575982,32.8627809,56.2722235\" where name=\"bounds\"'\nsqlite3 belgium.mbtiles 'update metadata set value=\"2.2889137,49.3969821,6.508097,51.6516667\" where name=\"bounds\"'\nsqlite3 belize.mbtiles 'update metadata set value=\"-89.3261456,15.7857286,-87.2098493,18.596001\" where name=\"bounds\"'\nsqlite3 benin.mbtiles 'update metadata set value=\"0.676667,5.9398696,3.943343,12.5065612\" where name=\"bounds\"'\nsqlite3 bermuda.mbtiles 'update metadata set value=\"-65.2232221,31.9469651,-64.3109841,32.6913693\" where name=\"bounds\"'\nsqlite3 bhutan.mbtiles 'update metadata set value=\"88.6464724,26.602016,92.2252321,28.346987\" where name=\"bounds\"'\nsqlite3 bolivia.mbtiles 'update metadata set value=\"-69.7450072,-23.0005473,-57.3529999,-9.5689437\" where name=\"bounds\"'\nsqlite3 bosnia_and_herzegovina.mbtiles 'update metadata set value=\"15.6287433,42.4543231,19.7217086,45.3764771\" where name=\"bounds\"'\nsqlite3 botswana.mbtiles 'update metadata set value=\"19.8986474,-27.0059668,29.475304,-17.6781369\" where name=\"bounds\"'\nsqlite3 brazil.mbtiles 'update metadata set value=\"-74.0830624,-33.9689055,-28.5341163,5.3842873\" where name=\"bounds\"'\nsqlite3 british_indian_ocean_territory.mbtiles 'update metadata set value=\"70.936504,-7.7454078,72.8020157,-4.9370659\" where name=\"bounds\"'\nsqlite3 british_virgin_islands.mbtiles 'update metadata set value=\"-65.055961,18.0055311,-63.9597293,19.0503802\" where name=\"bounds\"'\nsqlite3 brunei.mbtiles 'update metadata set value=\"113.976123,3.902508,115.4635623,5.2011857\" where name=\"bounds\"'\nsqlite3 bulgaria.mbtiles 'update metadata set value=\"22.257337,41.1353929,28.9875409,44.3162214\" where name=\"bounds\"'\nsqlite3 burkina_faso.mbtiles 'update metadata set value=\"-5.6175099,9.293889,2.50261,15.184\" where name=\"bounds\"'\nsqlite3 burundi.mbtiles 'update metadata set value=\"28.9007401,-4.5693154,30.9495759,-2.2096795\" where name=\"bounds\"'\nsqlite3 cote_d_ivoire.mbtiles 'update metadata set value=\"-8.7017249,4.0621205,-2.3930309,10.840015\" where name=\"bounds\"'\nsqlite3 cambodia.mbtiles 'update metadata set value=\"102.2338282,9.3230459,107.7276788,14.7902471\" where name=\"bounds\"'\nsqlite3 cameroon.mbtiles 'update metadata set value=\"8.2822176,1.5546659,16.2921476,13.183333\" where name=\"bounds\"'\nsqlite3 canada.mbtiles 'update metadata set value=\"-141.1027499,41.5765556,-52.223198,83.4362128\" where name=\"bounds\"'\nsqlite3 cape_verde.mbtiles 'update metadata set value=\"-25.6731072,14.5066229,-22.3547751,17.507117\" where name=\"bounds\"'\nsqlite3 cayman_islands.mbtiles 'update metadata set value=\"-81.7313747,18.9620619,-79.4110953,20.0573759\" where name=\"bounds\"'\nsqlite3 central_african_republic.mbtiles 'update metadata set value=\"14.3155426,2.1156553,27.5540764,11.101389\" where name=\"bounds\"'\nsqlite3 chad.mbtiles 'update metadata set value=\"13.37348,7.34107,24.1,23.5975\" where name=\"bounds\"'\nsqlite3 chile.mbtiles 'update metadata set value=\"-109.7795788,-56.8249999,-65.9734088,-17.3983997\" where name=\"bounds\"'\nsqlite3 china.mbtiles 'update metadata set value=\"73.3997347,14.8082548,134.8754563,53.6608154\" where name=\"bounds\"'\nsqlite3 colombia.mbtiles 'update metadata set value=\"-82.1000001,-4.3316871,-66.7511906,16.2219145\" where name=\"bounds\"'\nsqlite3 comoros.mbtiles 'update metadata set value=\"42.925305,-12.7209999,44.8451922,-11.0649999\" where name=\"bounds\"'\nsqlite3 congo-brazzaville.mbtiles 'update metadata set value=\"10.9048205,-5.2358572,18.743611,3.813056\" where name=\"bounds\"'\nsqlite3 congo-kinshasa.mbtiles 'update metadata set value=\"11.9374291,-13.5590349,31.4056758,5.4920026\" where name=\"bounds\"'\nsqlite3 cook_islands.mbtiles 'update metadata set value=\"-166.1856467,-22.2580699,-157.0154965,-8.6168791\" where name=\"bounds\"'\nsqlite3 costa_rica.mbtiles 'update metadata set value=\"-87.3722646,5.2329698,-82.4060207,11.3196781\" where name=\"bounds\"'\nsqlite3 croatia.mbtiles 'update metadata set value=\"13.101983,42.0748212,19.5470842,46.655029\" where name=\"bounds\"'\nsqlite3 cuba.mbtiles 'update metadata set value=\"-85.2679701,19.5275294,-73.8190003,23.5816972\" where name=\"bounds\"'\nsqlite3 cyprus.mbtiles 'update metadata set value=\"31.9227581,34.3383706,34.9553182,36.013252\" where name=\"bounds\"'\nsqlite3 czech_republic.mbtiles 'update metadata set value=\"11.9905901,48.4518144,18.959216,51.1557036\" where name=\"bounds\"'\nsqlite3 denmark.mbtiles 'update metadata set value=\"7.6153255,54.3516667,15.6530641,58.0524297\" where name=\"bounds\"'\nsqlite3 djibouti.mbtiles 'update metadata set value=\"41.6713139,10.8149547,43.7579046,12.8923081\" where name=\"bounds\"'\nsqlite3 dominica.mbtiles 'update metadata set value=\"-61.7869183,14.9074207,-60.9329894,15.8872222\" where name=\"bounds\"'\nsqlite3 dominican_republic.mbtiles 'update metadata set value=\"-72.1657709,17.166222,-68.0148509,20.234528\" where name=\"bounds\"'\nsqlite3 east_timor.mbtiles 'update metadata set value=\"123.9415703,-9.6642774,127.6335392,-7.9895458\" where name=\"bounds\"'\nsqlite3 ecuador.mbtiles 'update metadata set value=\"-92.7828789,-5.1159313,-75.0925039,2.4495499\" where name=\"bounds\"'\nsqlite3 egypt.mbtiles 'update metadata set value=\"24.606389,21.8999975,37.2153517,31.9330854\" where name=\"bounds\"'\nsqlite3 el_salvador.mbtiles 'update metadata set value=\"-90.2602721,12.9262117,-87.4498059,14.551667\" where name=\"bounds\"'\nsqlite3 equatorial_guinea.mbtiles 'update metadata set value=\"5.3172943,-1.7732195,11.4598628,4.089\" where name=\"bounds\"'\nsqlite3 eritrea.mbtiles 'update metadata set value=\"36.343333,12.2548219,43.4001714,18.1479356\" where name=\"bounds\"'\nsqlite3 estonia.mbtiles 'update metadata set value=\"21.2826069,57.4093124,28.3100175,60.0383754\" where name=\"bounds\"'\nsqlite3 ethiopia.mbtiles 'update metadata set value=\"32.897734,3.297448,48.0823797,14.9944684\" where name=\"bounds\"'\nsqlite3 falkland_islands.mbtiles 'update metadata set value=\"-61.8726771,-53.2186765,-57.2662366,-50.6973006\" where name=\"bounds\"'\nsqlite3 faroe_islands.mbtiles 'update metadata set value=\"-7.8983833,61.1880991,-6.0413261,62.5476162\" where name=\"bounds\"'\nsqlite3 federated_states_of_micronesia.mbtiles 'update metadata set value=\"137.1234512,0.727,163.3364054,10.391\" where name=\"bounds\"'\nsqlite3 fiji.mbtiles 'update metadata set value=\"-180.0999999,-21.3286516,180.1,-12.1613865\" where name=\"bounds\"'\nsqlite3 finland.mbtiles 'update metadata set value=\"18.9832098,59.3541578,31.6867044,70.1922939\" where name=\"bounds\"'\nsqlite3 france.mbtiles 'update metadata set value=\"-178.4873748,-50.3187168,172.4057152,51.368318\" where name=\"bounds\"'\nsqlite3 gabon.mbtiles 'update metadata set value=\"8.4002246,-4.201226,14.639444,2.4182171\" where name=\"bounds\"'\nsqlite3 georgia.mbtiles 'update metadata set value=\"39.7844803,40.9552922,46.8365373,43.6864294\" where name=\"bounds\"'\nsqlite3 germany.mbtiles 'update metadata set value=\"5.7663153,47.1701114,15.1419319,55.199161\" where name=\"bounds\"'\nsqlite3 ghana.mbtiles 'update metadata set value=\"-3.3607859,4.4392525,1.3732942,11.2748562\" where name=\"bounds\"'\nsqlite3 greece.mbtiles 'update metadata set value=\"19.1477876,34.6006096,29.8296986,41.8488862\" where name=\"bounds\"'\nsqlite3 greenland.mbtiles 'update metadata set value=\"-74.394555,59.4209376,-9.4914437,83.8491212\" where name=\"bounds\"'\nsqlite3 grenada.mbtiles 'update metadata set value=\"-62.1065867,11.686,-61.0732142,12.6966532\" where name=\"bounds\"'\nsqlite3 guatemala.mbtiles 'update metadata set value=\"-92.4105241,13.5278662,-88.0648019,17.9166179\" where name=\"bounds\"'\nsqlite3 guernsey.mbtiles 'update metadata set value=\"-3.1204014,49.1208333,-1.9351849,50.0416066\" where name=\"bounds\"'\nsqlite3 guinea-bissau.mbtiles 'update metadata set value=\"-16.9945229,10.5514215,-13.5348776,12.7862384\" where name=\"bounds\"'\nsqlite3 guinea.mbtiles 'update metadata set value=\"-15.3470907,7.0906045,-7.5381992,12.77563\" where name=\"bounds\"'\nsqlite3 guyana.mbtiles 'update metadata set value=\"-61.5149049,1.0710017,-56.3689542,8.7038842\" where name=\"bounds\"'\nsqlite3 haiti.mbtiles 'update metadata set value=\"-74.7575356,17.8099291,-71.5221296,20.3181368\" where name=\"bounds\"'\nsqlite3 honduras.mbtiles 'update metadata set value=\"-89.4519439,12.879722,-82.0816379,17.719526\" where name=\"bounds\"'\nsqlite3 hungary.mbtiles 'update metadata set value=\"16.0138867,45.637128,22.9974573,48.685257\" where name=\"bounds\"'\nsqlite3 iceland.mbtiles 'update metadata set value=\"-25.1135068,62.9859177,-12.7046161,67.453\" where name=\"bounds\"'\nsqlite3 india.mbtiles 'update metadata set value=\"68.0113787,6.4546079,97.495561,35.7745457\" where name=\"bounds\"'\nsqlite3 indonesia.mbtiles 'update metadata set value=\"94.6717124,-11.3085668,141.1194444,6.3744496\" where name=\"bounds\"'\nsqlite3 iran.mbtiles 'update metadata set value=\"43.9318908,24.7465103,63.4332704,39.8816502\" where name=\"bounds\"'\nsqlite3 iraq.mbtiles 'update metadata set value=\"38.6936612,28.9612087,48.9412702,37.480932\" where name=\"bounds\"'\nsqlite3 ireland.mbtiles 'update metadata set value=\"-11.1133787,51.122,-5.5582362,55.736\" where name=\"bounds\"'\nsqlite3 isle_of_man.mbtiles 'update metadata set value=\"-5.2707284,53.745,-3.865406,54.6534288\" where name=\"bounds\"'\nsqlite3 israel.mbtiles 'update metadata set value=\"34.1674994,29.3533796,35.9950234,33.4356317\" where name=\"bounds\"'\nsqlite3 italy.mbtiles 'update metadata set value=\"6.5272658,35.1889616,18.8844746,47.1921462\" where name=\"bounds\"'\nsqlite3 jamaica.mbtiles 'update metadata set value=\"-78.6782365,16.4899443,-75.6541142,18.8256394\" where name=\"bounds\"'\nsqlite3 japan.mbtiles 'update metadata set value=\"122.6141754,20.1145811,154.305541,45.8112046\" where name=\"bounds\"'\nsqlite3 jersey.mbtiles 'update metadata set value=\"-2.6591666,48.7721667,-1.7333332,49.5605\" where name=\"bounds\"'\nsqlite3 jordan.mbtiles 'update metadata set value=\"34.7844372,29.083401,39.4012981,33.4751558\" where name=\"bounds\"'\nsqlite3 kazakhstan.mbtiles 'update metadata set value=\"46.392161,40.4686476,87.4156316,55.5804002\" where name=\"bounds\"'\nsqlite3 kenya.mbtiles 'update metadata set value=\"33.8098987,-4.9995203,41.999578,4.72\" where name=\"bounds\"'\nsqlite3 kiribati.mbtiles 'update metadata set value=\"-174.8433549,-11.7459999,177.1479136,5\" where name=\"bounds\"'\nsqlite3 kuwait.mbtiles 'update metadata set value=\"46.4526837,28.4138452,49.1046809,30.2038082\" where name=\"bounds\"'\nsqlite3 kyrgyzstan.mbtiles 'update metadata set value=\"69.1649523,39.0728437,80.3295793,43.3667971\" where name=\"bounds\"'\nsqlite3 laos.mbtiles 'update metadata set value=\"99.9843247,13.8096752,107.7349989,22.602872\" where name=\"bounds\"'\nsqlite3 latvia.mbtiles 'update metadata set value=\"20.5715407,55.5746671,28.3414904,58.1855688\" where name=\"bounds\"'\nsqlite3 lebanon.mbtiles 'update metadata set value=\"34.7825667,32.9479858,36.725,34.7923543\" where name=\"bounds\"'\nsqlite3 lesotho.mbtiles 'update metadata set value=\"26.91123,-30.7755749,29.5557099,-28.4705972\" where name=\"bounds\"'\nsqlite3 liberia.mbtiles 'update metadata set value=\"-11.7080763,4.0555907,-7.2673229,8.6519717\" where name=\"bounds\"'\nsqlite3 libya.mbtiles 'update metadata set value=\"9.291081,19.4008138,25.4541226,33.4512055\" where name=\"bounds\"'\nsqlite3 liechtenstein.mbtiles 'update metadata set value=\"9.3716736,46.9484291,9.7357143,47.370581\" where name=\"bounds\"'\nsqlite3 lithuania.mbtiles 'update metadata set value=\"20.553783,53.7967893,26.9355198,56.5504213\" where name=\"bounds\"'\nsqlite3 luxemburg.mbtiles 'update metadata set value=\"5.6357006,49.3478539,6.6312481,50.2827712\" where name=\"bounds\"'\nsqlite3 macedonia.mbtiles 'update metadata set value=\"20.3532236,40.7545226,23.134051,42.4735359\" where name=\"bounds\"'\nsqlite3 madagascar.mbtiles 'update metadata set value=\"42.8729705,-25.9054593,50.7983545,-11.6490749\" where name=\"bounds\"'\nsqlite3 malawi.mbtiles 'update metadata set value=\"32.5703616,-17.2295216,36.0185731,-9.268326\" where name=\"bounds\"'\nsqlite3 malaysia.mbtiles 'update metadata set value=\"98.8372144,0.753821,119.5390876,7.6111989\" where name=\"bounds\"'\nsqlite3 maldives.mbtiles 'update metadata set value=\"72.2554187,-1.0074934,74.0700962,7.4106246\" where name=\"bounds\"'\nsqlite3 mali.mbtiles 'update metadata set value=\"-12.3407704,10.047811,4.3673828,25.101084\" where name=\"bounds\"'\nsqlite3 malta.mbtiles 'update metadata set value=\"13.8324226,35.5029696,14.9267966,36.3852706\" where name=\"bounds\"'\nsqlite3 marshall_islands.mbtiles 'update metadata set value=\"160.494934,4.274,172.4737007,14.973\" where name=\"bounds\"'\nsqlite3 mauritania.mbtiles 'update metadata set value=\"-17.1684993,14.6206601,-4.7333343,27.414942\" where name=\"bounds\"'\nsqlite3 mauritius.mbtiles 'update metadata set value=\"56.2825151,-20.8249999,63.8151319,-10.0379999\" where name=\"bounds\"'\nsqlite3 mexico.mbtiles 'update metadata set value=\"-118.6991899,14.2886243,-86.3932659,32.8186553\" where name=\"bounds\"'\nsqlite3 moldova.mbtiles 'update metadata set value=\"26.5162823,45.3667022,30.2635137,48.5918695\" where name=\"bounds\"'\nsqlite3 monaco.mbtiles 'update metadata set value=\"7.3090279,43.416333,7.633167,43.8519311\" where name=\"bounds\"'\nsqlite3 mongolia.mbtiles 'update metadata set value=\"87.63762,41.4804176,120.031949,52.2496\" where name=\"bounds\"'\nsqlite3 montenegro.mbtiles 'update metadata set value=\"18.3334249,41.6495999,20.4638002,43.658844\" where name=\"bounds\"'\nsqlite3 montserrat.mbtiles 'update metadata set value=\"-62.5506669,16.375,-61.8353817,17.1152978\" where name=\"bounds\"'\nsqlite3 morocco.mbtiles 'update metadata set value=\"-17.4479238,20.5144392,-0.8984289,36.1027875\" where name=\"bounds\"'\nsqlite3 mozambique.mbtiles 'update metadata set value=\"30.1131759,-27.0209426,41.1545908,-10.2252148\" where name=\"bounds\"'\nsqlite3 myanmar.mbtiles 'update metadata set value=\"92.0719423,9.4375,101.2700796,28.647835\" where name=\"bounds\"'\nsqlite3 namibia.mbtiles 'update metadata set value=\"11.4280384,-29.0694499,25.3617476,-16.8634854\" where name=\"bounds\"'\nsqlite3 nauru.mbtiles 'update metadata set value=\"166.6099864,-0.8529999,167.2597301,-0.2029999\" where name=\"bounds\"'\nsqlite3 nepal.mbtiles 'update metadata set value=\"79.9586109,26.2477172,88.3015257,30.546945\" where name=\"bounds\"'\nsqlite3 new_zealand.mbtiles 'update metadata set value=\"-179.1591529,-52.9213686,179.4643594,-28.9303302\" where name=\"bounds\"'\nsqlite3 nicaragua.mbtiles 'update metadata set value=\"-87.933972,10.6084923,-82.5227022,15.1331183\" where name=\"bounds\"'\nsqlite3 niger.mbtiles 'update metadata set value=\"0.0689653,11.593756,16.096667,23.617178\" where name=\"bounds\"'\nsqlite3 nigeria.mbtiles 'update metadata set value=\"2.576932,3.9690959,14.777982,13.985645\" where name=\"bounds\"'\nsqlite3 niue.mbtiles 'update metadata set value=\"-170.2595028,-19.4548664,-169.4647228,-18.6534558\" where name=\"bounds\"'\nsqlite3 north_korea.mbtiles 'update metadata set value=\"123.9913902,37.5279512,131.024647,43.1089642\" where name=\"bounds\"'\nsqlite3 norway.mbtiles 'update metadata set value=\"-9.7848145,-54.7539999,34.7891253,81.128076\" where name=\"bounds\"'\nsqlite3 oman.mbtiles 'update metadata set value=\"51.9,16.3649608,60.154577,26.8026737\" where name=\"bounds\"'\nsqlite3 pakistan.mbtiles 'update metadata set value=\"60.766944,23.4393916,77.2203914,37.184107\" where name=\"bounds\"'\nsqlite3 palau.mbtiles 'update metadata set value=\"130.9685462,2.648,134.8714735,8.322\" where name=\"bounds\"'\nsqlite3 palestine.mbtiles 'update metadata set value=\"33.9689732,31.1201289,35.6734946,32.6521479\" where name=\"bounds\"'\nsqlite3 panama.mbtiles 'update metadata set value=\"-83.1517244,6.9338679,-77.0393778,9.9701757\" where name=\"bounds\"'\nsqlite3 papua_new_guinea.mbtiles 'update metadata set value=\"140.7416553,-11.9555738,159.792724,-0.4573575\" where name=\"bounds\"'\nsqlite3 paraguay.mbtiles 'update metadata set value=\"-62.7442035,-27.7069156,-54.1579999,-19.1876463\" where name=\"bounds\"'\nsqlite3 peru.mbtiles 'update metadata set value=\"-84.7732789,-20.2984471,-68.5519905,0.0607183\" where name=\"bounds\"'\nsqlite3 philippines.mbtiles 'update metadata set value=\"113.9783252,4.1158064,126.9072562,21.4217806\" where name=\"bounds\"'\nsqlite3 pitcairn_islands.mbtiles 'update metadata set value=\"-130.9049861,-25.2306735,-124.6175339,-23.7655768\" where name=\"bounds\"'\nsqlite3 poland.mbtiles 'update metadata set value=\"14.0229707,48.9020468,24.245783,55.1336963\" where name=\"bounds\"'\nsqlite3 portugal.mbtiles 'update metadata set value=\"-31.6575302,29.7288021,-6.0891591,42.2543112\" where name=\"bounds\"'\nsqlite3 qatar.mbtiles 'update metadata set value=\"50.4675,24.3707534,52.738011,26.4830212\" where name=\"bounds\"'\nsqlite3 republic_of_china.mbtiles 'update metadata set value=\"114.2521088,10.2706406,122.397,26.5015754\" where name=\"bounds\"'\nsqlite3 republic_of_kosovo.mbtiles 'update metadata set value=\"19.9185549,41.7554981,21.8995285,43.3691934\" where name=\"bounds\"'\nsqlite3 romania.mbtiles 'update metadata set value=\"20.1619773,43.518682,30.1454257,48.3653964\" where name=\"bounds\"'\nsqlite3 russian_federation.mbtiles 'update metadata set value=\"-180.0999999,41.0858711,180.1,82.1586232\" where name=\"bounds\"'\nsqlite3 rwanda.mbtiles 'update metadata set value=\"28.7617546,-2.9389803,30.9990738,-0.9474509\" where name=\"bounds\"'\nsqlite3 sao_tome_and_principe.mbtiles 'update metadata set value=\"6.160642,-0.3135136,7.7704783,2.0257601\" where name=\"bounds\"'\nsqlite3 sahrawi_arab_democratic_republic.mbtiles 'update metadata set value=\"-15.1405655,21.2370952,-8.5663889,27.7666834\" where name=\"bounds\"'\nsqlite3 saint_kitts_and_nevis.mbtiles 'update metadata set value=\"-63.1511289,16.795,-62.2303518,17.7158146\" where name=\"bounds\"'\nsqlite3 saint_lucia.mbtiles 'update metadata set value=\"-61.3853866,13.408,-60.5669362,14.3725\" where name=\"bounds\"'\nsqlite3 saint_vincent_and_the_grenadines.mbtiles 'update metadata set value=\"-61.765747,12.4166548,-60.8094145,13.683\" where name=\"bounds\"'\nsqlite3 samoa.mbtiles 'update metadata set value=\"-173.1091863,-14.3770915,-171.0929228,-13.1381891\" where name=\"bounds\"'\nsqlite3 san_marino.mbtiles 'update metadata set value=\"12.3033246,43.7937002,12.6160665,44.092093\" where name=\"bounds\"'\nsqlite3 saudi_arabia.mbtiles 'update metadata set value=\"34.3571718,16.19,55.7666985,32.3305891\" where name=\"bounds\"'\nsqlite3 senegal.mbtiles 'update metadata set value=\"-17.8862418,12.1372838,-11.2458995,16.7919959\" where name=\"bounds\"'\nsqlite3 serbia.mbtiles 'update metadata set value=\"18.71403,42.1357356,23.106309,46.2900608\" where name=\"bounds\"'\nsqlite3 seychelles.mbtiles 'update metadata set value=\"45.8988759,-10.5649257,56.5979396,-3.4119999\" where name=\"bounds\"'\nsqlite3 sierra_leone.mbtiles 'update metadata set value=\"-13.6003388,6.655,-10.1716829,10.1000481\" where name=\"bounds\"'\nsqlite3 singapore.mbtiles 'update metadata set value=\"103.4666667,1.0303611,104.6706735,1.6130449\" where name=\"bounds\"'\nsqlite3 slovakia.mbtiles 'update metadata set value=\"16.7331891,47.6314286,22.6657096,49.7138162\" where name=\"bounds\"'\nsqlite3 slovenia.mbtiles 'update metadata set value=\"13.2754696,45.3214242,16.6967702,46.9766816\" where name=\"bounds\"'\nsqlite3 solomon_islands.mbtiles 'update metadata set value=\"155.2190556,-13.3424297,170.4964667,-4.7108499\" where name=\"bounds\"'\nsqlite3 somalia.mbtiles 'update metadata set value=\"40.8864985,-1.9031968,51.7177696,12.2889121\" where name=\"bounds\"'\nsqlite3 south_africa.mbtiles 'update metadata set value=\"16.2335213,-47.2788334,38.3898954,-22.02503\" where name=\"bounds\"'\nsqlite3 south_georgia_and_the_south_sandwich_islands.mbtiles 'update metadata set value=\"-42.2349052,-59.7839999,-25.7468302,-53.3531685\" where name=\"bounds\"'\nsqlite3 south_korea.mbtiles 'update metadata set value=\"124.254847,32.77788,132.2483256,38.7234602\" where name=\"bounds\"'\nsqlite3 south_sudan.mbtiles 'update metadata set value=\"23.347778,3.38898,36.048997,12.336389\" where name=\"bounds\"'\nsqlite3 spain.mbtiles 'update metadata set value=\"-18.4936844,27.3335426,4.6918885,44.0933088\" where name=\"bounds\"'\nsqlite3 sri_lanka.mbtiles 'update metadata set value=\"79.2741141,5.619,82.1810141,10.135\" where name=\"bounds\"'\nsqlite3 sudan.mbtiles 'update metadata set value=\"21.7145046,9.247221,39.1576252,22.324918\" where name=\"bounds\"'\nsqlite3 suriname.mbtiles 'update metadata set value=\"-58.1708329,1.7312802,-53.7433357,6.325\" where name=\"bounds\"'\nsqlite3 swaziland.mbtiles 'update metadata set value=\"30.6908,-27.41752,32.2349923,-25.6187599\" where name=\"bounds\"'\nsqlite3 sweden.mbtiles 'update metadata set value=\"10.4920778,55.0331192,24.2776819,69.1599699\" where name=\"bounds\"'\nsqlite3 switzerland.mbtiles 'update metadata set value=\"5.8559113,45.717995,10.5922941,47.9084648\" where name=\"bounds\"'\nsqlite3 syria.mbtiles 'update metadata set value=\"35.3714427,32.211354,42.4745687,37.4184589\" where name=\"bounds\"'\nsqlite3 tajikistan.mbtiles 'update metadata set value=\"67.2308737,36.5710411,75.2539563,41.1450935\" where name=\"bounds\"'\nsqlite3 tanzania.mbtiles 'update metadata set value=\"29.2269773,-11.8612539,40.7584071,-0.8820299\" where name=\"bounds\"'\nsqlite3 thailand.mbtiles 'update metadata set value=\"97.2438072,5.512851,105.7370925,20.5648337\" where name=\"bounds\"'\nsqlite3 the_bahamas.mbtiles 'update metadata set value=\"-80.800194,20.6059846,-72.347752,27.5734551\" where name=\"bounds\"'\nsqlite3 the_gambia.mbtiles 'update metadata set value=\"-17.1288253,12.961,-13.6977779,13.9253137\" where name=\"bounds\"'\nsqlite3 the_netherlands.mbtiles 'update metadata set value=\"-70.3695875,11.677,7.3274985,53.8253321\" where name=\"bounds\"'\nsqlite3 togo.mbtiles 'update metadata set value=\"-0.2439718,5.826547,1.9025,11.2395355\" where name=\"bounds\"'\nsqlite3 tokelau.mbtiles 'update metadata set value=\"-172.8213672,-9.7442498,-170.8797585,-8.232863\" where name=\"bounds\"'\nsqlite3 tonga.mbtiles 'update metadata set value=\"-179.4951979,-24.2625705,-173.4295457,-15.2655721\" where name=\"bounds\"'\nsqlite3 trinidad_and_tobago.mbtiles 'update metadata set value=\"-62.1830559,9.7732106,-60.1895847,11.6628372\" where name=\"bounds\"'\nsqlite3 tunisia.mbtiles 'update metadata set value=\"7.4219807,30.14238,11.9801133,37.8612052\" where name=\"bounds\"'\nsqlite3 turkey.mbtiles 'update metadata set value=\"25.5212891,35.7076804,44.9176638,42.397\" where name=\"bounds\"'\nsqlite3 turkmenistan.mbtiles 'update metadata set value=\"52.235076,35.0355776,66.784303,42.8975571\" where name=\"bounds\"'\nsqlite3 turks_and_caicos_islands.mbtiles 'update metadata set value=\"-72.7799045,20.8553418,-70.764359,22.2630989\" where name=\"bounds\"'\nsqlite3 tuvalu.mbtiles 'update metadata set value=\"-180.0999999,-11.0939388,180.1,-5.336961\" where name=\"bounds\"'\nsqlite3 uganda.mbtiles 'update metadata set value=\"29.4727424,-1.5787899,35.100308,4.3340766\" where name=\"bounds\"'\nsqlite3 ukraine.mbtiles 'update metadata set value=\"22.037059,44.084598,40.3275801,52.4791473\" where name=\"bounds\"'\nsqlite3 united_arab_emirates.mbtiles 'update metadata set value=\"51.3160714,22.5316214,56.7024458,26.2517219\" where name=\"bounds\"'\nsqlite3 united_kingdom.mbtiles 'update metadata set value=\"-14.1155169,49.574,2.1919117,61.161\" where name=\"bounds\"'\nsqlite3 united_states_of_america.mbtiles 'update metadata set value=\"-180.0999999,-14.8608357,180.1,71.7048217\" where name=\"bounds\"'\nsqlite3 uruguay.mbtiles 'update metadata set value=\"-58.5948437,-35.8847311,-52.9755832,-29.9853439\" where name=\"bounds\"'\nsqlite3 uzbekistan.mbtiles 'update metadata set value=\"55.8985781,37.0772144,73.2397362,45.690118\" where name=\"bounds\"'\nsqlite3 vanuatu.mbtiles 'update metadata set value=\"166.2355255,-20.5627424,170.549982,-12.7713776\" where name=\"bounds\"'\nsqlite3 vatican_city.mbtiles 'update metadata set value=\"12.3457442,41.8002044,12.5583555,42.0073912\" where name=\"bounds\"'\nsqlite3 venezuela.mbtiles 'update metadata set value=\"-73.4529631,0.547529,-59.4427078,16.0158431\" where name=\"bounds\"'\nsqlite3 vietnam.mbtiles 'update metadata set value=\"102.04441,8.0790665,114.4341924,23.493395\" where name=\"bounds\"'\nsqlite3 yemen.mbtiles 'update metadata set value=\"41.50825,11.8084802,54.8389375,19.1\" where name=\"bounds\"'\nsqlite3 zambales.mbtiles 'update metadata set value=\"117.411894,14.5033824,120.549421,15.958218\" where name=\"bounds\"'\nsqlite3 zambia.mbtiles 'update metadata set value=\"21.896389,-18.1766964,33.8025,-8.1712821\" where name=\"bounds\"'\nsqlite3 zimbabwe.mbtiles 'update metadata set value=\"25.1373,-22.5241095,33.1627122,-15.5097038\" where name=\"bounds\"'\n. World metadata is updated and uploaded again (takes ~2 hrs to reupload it).\nThe extracts are still uploading.\n\nHavn't you forgotten where name=\"bounds\";?\n\nHehe you've seen it directly - I only realized it after I've ran it :see_no_evil: \nIt messed up all local extracts and I had to download the extracts again from S3 to update the metadata.\n. The updated extracts have been uploaded.\n. Great seeing everything coming along so quickly! :+1: \nIncluding the website. Now we can reference the CDN in the documentation.\nThe raster tiles server is based on Klokantech tileserver tessera with a caching proxy in front?\nThis is amazingly fast.\n. > BTW @klokantech team has added also support for open-source static maps requests, like:\n\nhttp://klokantech.tileserver.com/streets-basic/static/8.82,47.225,15/500x500@2x.png\nhttp://klokantech.tileserver.com/osm-bright/static/8.82,47.225,15/500x500@2x.png\n\nNow it is almost a Wikimedia Maps replacement! :)\nClarification Questions:\nWe will host OSM Bright and Streets Classic (and your Retro style) as raster tile examples\non the Klokantech CDN?\nThe other examples we will continue to serve from a separate server (respectively prerender the raster tiles for small areas)?\n. CDN is up and running for the launch. Let's close this so we can close the milestone as well.\nIf there are additional CDN features we can move them to a new ticket.\n. Great work @daliborjanak!  Everything works smoothly and also works on the phone.\nWe will remove the osm2vectortiles-gh-pages.zip file and also configure Jekyll to support highlighted code sections.\n. Great idea! We will do that, thanks for the suggestion. Alot of knowledge is in the mapping of tags, values and classes.\nBelow is a diagram visualizing the different mappings to the tables.\n\n. Done and waiting until PR is merged.\n. Hehe yeah. Nice to be listed.\n. IMHO the raster tiles served by tessera on http://osm2vectortiles.org/maps/ works well enough for demo purposes. Therefore I won't create a workflow for prerendering the raster tiles.\n. Added a few city extracts. We will work with Zurich in all examples!\n\n. Pulled in Analytics again. Forgot it was already running since the beginning. \nGave @klokan and @manuelroth access to the analytics property.\n\n. \n\n. - [x] Thanks Switch for the hosting of the MBTiles files \"Download hosting generously provided by Switch Academic Network\"\n- [x] Add Thesis to the documentation\n. - [x] Add note (ref to tutorial) to tileserver-mapnik\n. - [x] Upload lower zoom levels on download page\n. - [x] Link something in vector maps (repo of mapbox-gl-js-example)\n- [ ] ~~Fork mapbox gl styles and work on it to provide example~~\u00a0Will be realized in an other ticket at onther point in time\n. - [x] Change license text in FAQ\n- [x] Link to license in download page\n. > Thank you for the instructions for generating the tiles. If there is a way to setup the coordinate bounds for Puerto Rico and merge them into this project, so as make the Puerto Rico extract available in your site, I would gladly contribute such a patch.\nIf you provide me with the BBOX of Puerto Rico I will add it to the extracts :)\n. Finally uploaded it and added to the countries list (I know not politically correct but hope is ok).\nhttps://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.0/extracts/puerto_rico.mbtiles\n. > Did a python script which batch fixes fonts in projects. The lookup table can be extended/customized.\n\nhttps://gist.github.com/hyperknot/6106b253cfe852f84124\n\nI only see this now - sorry. The script is great, we will try to include it into the container to automatically\nfix fonts of the users.\n. This is a tileserver-mapnik thinf https://github.com/klokantech/tileserver-mapnik.\n@klokan: me and @manuel also wondered why there is always an OpenStreetMap basemap underneath?\nIt is not tragic because people can remove it but I also think it is a bit confusing.\n. I don't see it :see_no_evil:  Are you referring to this tutorial?\nhttp://osm2vectortiles.org/docs/serve-raster-tiles-docker/\nSource can be found here: https://github.com/osm2vectortiles/osm2vectortiles/blob/gh-pages/docs/serve-raster-tiles-docker.md\nI thought I corrected that before the launch.\n\n. Good idea. Added the MD5 hash of the world planet file 8f72dc1279d27f0b3e29d27957c7ad7a.\n@hyperknot What do you think about distributing the planet file as torrent. Would that be more convenient for you?\n\n. > This is probably the hardest / most infamous problem when rendering vector tiles, Mapbox has talked a lot about how hard it is.\nYou have some resources there we can read/watch to learn how to improve the problem?\nI only find bug reports.\n\nOut of the box, these cut lables are quite common in the docker image. I don't know what would be a proper solution, but a common workaround seems to be to raise the buffer zone around meta-tiles. So a meta-tile would be buffered +128 px / +256 px etc. on each side, and cropped afterwards.\n\nFor the vector tiles we use the same buffer configurations Mapbox has defined in https://www.mapbox.com/developers/vector-tiles/mapbox-streets-v6/#Layer.Reference.\nMost of the time for labels we have bigger buffer (the maximum of 256px).\nWe may increase the buffers in the source project even more - but this increases the size of the MBTiles even more and from what we have tested does not always solve the problem.\nBut you think this is a rendering issue?\nThere are some tricks that I read on the issues on the Mapbox projects like setting text-avoid-edges: true; in CartoCSS - but those seem more like workarounds.\nWith raster tiles it was not that bad so far even Mapbox has quite alot of label bugs we've seen so far in their official raster maps.\nMapbox GL has even more weird label issues.\n\n. This will consolidate the reports from https://github.com/osm2vectortiles/osm2vectortiles/issues/112 https://github.com/osm2vectortiles/osm2vectortiles/issues/194, #116.\n. Yes this was before the rerendering of #326. But process has not changed since sadly.\nIt re-emerged as #380.\n. Will be dealt with in #111.\n. Thanks. Hmm the bounds are indeed wrong. I guess all bounds on all extracts\nare corrupt :(\nIf I update the bounds of the MBTiles to the max. bounds with sqlite3 it works and I can upload it.\nbash\nsqlite3 zurich.mbtiles\nsql\nupdate metadata\nset value='-180,-85.0511,180,85.0511'\nwhere name='bounds'\nNeed to set new bounds for each extract. I previously used the bounds of the bounding box but perhaps in the wrong order. In worst case I just update the bounds to the max. value.\n. > Could be a Mapbox Studio error but my guess is, it's a problem in the files. (Sorry, if not!)\nSadly you can't upload the file even then because some rogue tiles (a few dozen) exceed the 500K limit.\nIf you want to design a map in the new Mapbox Studio I suggest you use their normal Mapbox Streets v5 or v6 and then switch to osm2vectortiles in production.\nWe are pretty close to their data set except for terrain data.\nThis is a custom styled map I am working on that entirely works with osm2vectortiles.\nhttp://schweizerkarte.lukasmartinelli.ch/#8/47.380/8.520\nhttps://github.com/lukasmartinelli/schweizerkarte\nBut for designing it I work in Mapbox Studio and just export the json file when I am finished.\nWe hope we can soon get all tiles below the 500K limit in the next rendering of the world.\n. > If I modify the mbtiles sqlite \"metadata\" table, row \"center\" with the averaged min/max lon and min/max lat coordinates taken from the \"bounds\" row\nThanks @numenor. I use this approach now to calculate the center of each MBTile https://github.com/osm2vectortiles/osm2vectortiles/commit/b0f3679a6261e05164ae61f66e6a1eb3a2100e4c.\n. This is probably an issue in our mapping where we only match linestrings with imposm instead of polygons.\nCould you attach a screenshot/coordinates so we can test that later?\n. Thanks @hannesj. This gives us more context.\nNice to know about http://dev.digitransit.fi/. I really like the style!!\n\nWhat parts are missing for you from osm2vectortiles for a project like http://dev.digitransit.fi/ ?\nWe are planning for the second iteration this year and are happy for any input that would help\npeople building maps like these.\nI guess in your case you require very detailed transportation infromation that is missing from osm2vectortiles.org.\n. > Temporary fix can be found in 3e58298\nWow nice. From what I understand adding road_polygons table and extending the mapping of roads resolves the issue?\nHow can you add a commit on top without creating a pull request? Never saw that on GitHub before.\nCan you create a pull request for that?\nWe can than merge it and will modify the queries (since we are currently refactoring the tm2source project to make updating dirty tiles easier).\n. Hmmm. Perhaps due to https://github.com/osm2vectortiles/osm2vectortiles/pull/305?\nBecause when we tested this we saw that imposm3 takes care of avoiding duplicate ids when you use a geometry table containing both linestrings and polygons.\nOne we can do would be to remove the duplicates in a SQL (but kind of a hack - imposm3 shouldn insert both).\n. > so my guess - this type of problem has existed before #305\nGood follow up. This means we need to go a different route than via imposm.\n@ImreSamu What do you think about removing duplicates via a SQL query? I think that might be a viable solution.\n@manuelroth I think this happened in our many SQL optimizations because joining road linestrings and polygons to remove the duplicates was just too slow in query time.\n. > Currently it is impossible to distinguish between different types of stations, e.g. railway and subway stations, as they both have type set to \"Station\" and network set to \"rail\" in the poi_label layer. Proper keys for network should come from the station tag.\nYes we once had all transport POI in a separate table with all the extra attributes needed, but in the current architecture we don't have any station value.\nWe have to reevaluate how to get those attributes, but it is a change that requires rerendering.\n. So this is already solved by #204 right @manuelroth? Reopen it if not :grinning: \n. Thanks for the detailed inspection and report!\nIt affects distinct tiles and not a entire subpyramid - so it is not the \"remove subpyramids\" process.\nOn the top of my head I think certain tiles failed in Mapnik when rendering the planet.\nI need to dig through the Mapnik logs from CloudWatch to search for those tiles to see a error message that Mapnik spit out when rendering those tiles. Or rerender parts where we know tiles are missing.\nI thought I ran my verify.py script to check whether each of the subpyramids that were merged together contains all tiles- but apparently not. We need to introduce a better verification process in the next rerendering then.\n. > Is this the process you also followed internally? http://osm2vectortiles.org/docs/own-vector-tiles/\nThis is exactly what we do - just on a distributed scale.\n. > Your documentation misses to mention that you need to adjust the bounding box.\nWe'll add that. Or you can create a PR as the documentation is based on GitHub pages.\nhttps://github.com/osm2vectortiles/osm2vectortiles/tree/gh-pages/docs\n\nMy first try does have no gaps. Missing lowzoom data, but maybe this is related to not touching min/max zoom settings. So can't say why your setup misses tiles.\n\nGood to know. This indicates it might be some kind of race condition.\nWhat could be is that the PostgreSQL server fails to respond in a certain time frame and Mapnik aborts the rendering of the tile - that would explain the missing tiles.\nIt is possible that this happended in our distributed rendering process (where the load on the different PostgreSQL servers is not always constant) while when you are doing this locally it does not occur.\nWe will dig into this bug once we are preparing for the next rerendering and rework the rendering scripts.\nWith the new update process in place #129 we have a method in the future to rerender missing or buggy tiles.\n. Will be fixed in #111.\n. > Their status does'nt mention problems currently https://twitter.com/switchdrive_op \n\nShould we send a mail to support?\n\nThanks.\nNo, probably just a process on the host that hang itself up. It's a host problem not an infrastructure one is my guess. \n. Works again.\nRemoved some other instances we were no longer using on Switch.\n. > I'm trying to write Java code to display the vector tile data, using OpenMap combined with the java-vector-tile decoder. When I pull the tile_data byte array out of the database, the java-vector-tile decoder doesn't read it correctly. I've compared the bytes with other tile data I've received from servers, and it seems off - it looks really different, like it's encoded, compressed or something. I've tried running the bytes through Base64/zip decoding, but that doesn't help.\nNice, didn't know about https://github.com/ElectronicChartCentre/java-vector-tile\nThe protocol buffer files inside the MBTiles data field are gzip compressed and need to be decoded first.\nWe do this in our compare tool by @manuelroth \njavascript\n zlib.unzip(tile, function(err, tile) {\n        if (!err) {\n            var rawTile = new VectorTile(new Protobuf(tile))\n            var tileName = program.z + \"-\" + program.x + \"-\" + program.y;\n            var tileInfo = tileInformation.printOutput(rawTile.layers, program.provider, tileName);\n            console.log(tileInfo);\n        }\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/tools/compare/tileInfo.js#L33\nIf you wget the file from the server and then parse it with the java-vector-tile decoder, does that work?\n. I would like supporting a vector based terrain map.\nEspecially since the offline ability is perhaps the most important aspect of this project - where terrain matters most.\nIt is quite a big additional effort though with not that much information about it like creating vector tiles from OSM. We have a big roadmap planning meeting soon, after which we can tell you more and you'll see more frequent commits again ;)\nThanks for the link, that's a way how we get contours into the database.\nDane Springmeyer recommends using gdal_polygonize to turn the raster terrain data into vector tiles.\nhttps://github.com/mapbox/mapnik-vector-tile/issues/47\n. Just had a talk with @miccferr and he shared an interesting link about open terrain data: http://openterrain.tumblr.com/\n. > Incidentally, there's been a recent post on Mapzen's blog about terrain styling:\n\nhttps://mapzen.com/blog/mapping-mountains/\n\nI love this blog post. This is a read for everyone interested in maps.\n. Yeeess very very exciting. That's so cool. Looking forward to hear the details.\n. @hyperknot @stirringhalo @klokan \nI know this is not really a terrain layer but check what you can do with a cool raster background in Mapbox GL by using the Natural Earth raster data set (only small scale of course not for detailed maps).\nhttp://naturalearthtiles.org/\nPerhaps you can even go further to apply some shading in the client.\n\n. > First tests on OSM2VectorTiles with hill-shading (whole world) \n@klokan Do you have a hillshading GeoTIFF or already webp/png tiles of the hillshading in MBTiles format?\nPerhaps we could also provide this on the CDN (or on the S3 endpoint) or provide it as download.\nWould like to try it out. Started with my own GeoTIFF of the world (just curious) but it takes ages to process.\n. > IMHO the issues in the \"important\" sections are so essential that all points below pale in comparison.\nDefinitely!! Good to know that those are really the top priority ones for you as well. Thanks for the collaboration.\n\nMapbox' geocoding is opensource as well afaik: https://github.com/mapbox/carmen However geocoding is a really really hard thing that many opensource and even commercial projects fail to do properly. That would be project of its own altogether.\n\nAlso agree, that's why I am hesitant. Some context for you, we need some interesting topics to include into osm2vectortiles to make the new paper more interesting/challenging.\n\nOffline use is just a label, right? Using the Mapbox GL SDKs and osm2vectortiles an offline usecase on iOS and Android can already be implemented today. (+1 for the label.)\n\nYes that's only kind of a motto/label/vision to focus on in future. Nothing more. \nThis can be implemented today but without guidance, docs and examples it is difficult for people to realize the possibility.\n. > Any estimation when the next release will happen?\nSorry that we always talk about the next release but you don't see us committing anything :)\nJust as context. We will continue development of osm2vectortiles as part of our bachelor thesis which means we will have 3 days a week where we can work and improve this project in after next week. The maintainers will meet all together at 22nd february where we can sketch out the details of the bachelor thesis and then we can tell you about a roadmap after 22nd february. Writing a thesis is a bit more waterfall than agile :)\nWith next release we usually mean a rerendering of the world which requires at least 1-2 weeks of just computing power.\n. Was a bad idea to separate the classification. I thought it is a more general problem but actually this is pretty tied to our project and not alot of other people can use that. Therefore reintroduced it again in https://github.com/osm2vectortiles/osm2vectortiles/commit/4909ddf17eec423630bfb247e0dc1c881f4c57c2\nThe mbtoolbox part makes still sense to live separate because it is a utility that can be used very well by other people.\n. Played a bit with the diff files. Much dumber approach for versioning might work as well.\n1. After the initial import I add a a column sequence_number which is the initial OSMOSIS sequence number stored in the state.txt file http://download.geofabrik.de/europe/liechtenstein-updates/state.txt ALTER TABLE <table> ADD column sequencenumber int and then UPDATE <table> SET sequence_number=1048\n2. Run the diff imports and after each diff import UPDATE <table> SET sequence_number=1049 WHERE sequence_number IS NULL. imposm3 will overwrite the existing sequence number with NULL values which is how we can detect what updated.\nAnd we have versioned feature. We ca use timestamp (more practical) instead of sequence number.\nThis is faster than triggers (doesn't solve the \"updated with no actual values changed\" problem, but not sure whether this problem actually exists).\nSome usage notes.\nDon't use Switzerland for playing with diff imports - takes too long. Use Lichtenstein.\n``` bash\nDownload changes for Lichtenstein\nwget http://download.geofabrik.de/europe/liechtenstein-updates/000/001/0{0..75}.osc.gz\nDownload state files\nwget http://download.geofabrik.de/europe/liechtenstein-updates/000/001/0{0..75}.state.txt\nImport lichtenstein first\ndocker-compose up import-osm\nImport changes in import dir\ndocker-compose up import-osm-diff\n```\nThe new import-osm-diff container is actually the same Docker image, just executing a different command.\n. ## How to import diffs into the database.\n1. Given you have downloaded an older PBF file\n   wget http://download.geofabrik.de/europe/liechtenstein-151001.osm.pbf\n2. Run docker-compose up import-osm will do an initial import of the PBF file, extract the timestamp of the PBF file and store it as timestamp column for each imported OSM table\n3. Now you want to download and apply the diffs. Run docker-compose up import-osm-diff which will use osmupdate to download all diffs until today for the PBF file found in the import directory and write them to a latest-changes.osc.gz file. This diff file will then be imported with imposm3 diff imports and then the timestamp of that chanages file is updated for all modified rows.\nIn order for osmupdate to work with Geofabrik extracts you need to export set the OSM_UPDATE_BASEURL variable in the container to http://download.geofabrik.de/europe/liechtenstein-updates/\n. > If a tag present in OSM raw data, which is ignored by our mapping to SQL tables, is changed/modified/added/deleted, then there is no change for this feature in our database.\nA tag that is not explicitely defined in mapping will cause no deletes or inserts into the database.\nIt is possible however that a tag that we don't map to columns (in fields) has changed (e.g. name:de_ch for a POI shop=icecream) and therefore still triggers the update but with the same values.\nBefore we implement detection of real updates we must ensure that this case really occurs #132. In the best case imposm3 already ignores changes to attributes that are not mapped to columns e.g. if not it makes sense to implement that directly into imposm3 since it would be quite a useful feature.\n. Btw. updating the timestamp on several million rows after importing does slow down the import quite a bit (on top of the additional time required for diffed imports which is factor x2).\nWould be great imposm3 could write the timestamp of the PBF directly into the database at a later stage.\n. Okay setting the timestmap per UPDATE takes as much time as importing in the first place. Didn't think that just updating one column takes so much time.\n. Given we want to evaluate dirty tiles for zoom level 4 we start at zoom level 1.\n1. We take the query of the source project and replace the zoom level with 4 and the bounding box of one zoom level 1 tile\n2. If something is dirty in zoom level 1 we do the queries for zoom level 4 again but with the bounding box of zoom level 2 tile\n3. Go down deeper with query for zoom level 4 and bbox of level 3 tile.\n4. Now we are at the targeted tile zoom level and have the actual tiles that are dirty.\n. The approach from #129 is superior IMHO and we should no longer pursue the approach from #123.\nWith this approach I mean detecting changes by executing the queries from the tm2source file and probing whether something changed.\n. This is done now via a bash script (in retroperspective Python would have been worth it as the file grew alot - but still readable imho) in #137 \n. Currently the script is updating all existing extracts.. this takes ca. 2 days until done.\nI suggest later we update the extracts each week.\n. I suggest we implement not a direct replacement of the export worker at first but a tool similar to tl , tilelive-copy that takes a list of dirty tiles and renders the tiles from tm2source into a tilelive sink (for simplicity MBTiles at first, later serialtiles).\nIf someone is finishing up #129  (at the moment it looks really promising) another one can work on #125 so we can test the tile updates for real asap.\n. Pleasant surprise. tilelive-copy actually supports a list rendering scheme which allows rendering a list of dirty tiles into a MBTiles file (which can then be patched to the original MBtiles file).\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/feature/detect-dirty-tiles/src/export/export-list.sh\nAdded an additional export-list script to the exisisting export-local and export-worker scripts.\nThis removes the need of rewriting the export to support rendering dirty tiles.\nThe current naive implementation already supports detecting dirty tiles and rerendering them (not yet distributed).\n``` bash\nWrites a tiles.txt to the export folder of the latest dirty tiles\ndocker-compose up detect-dirty-tiles\nRenders the missing tiles from tiles.txt to a new MBTiles file that can then be patched.\ndocker-compose up export-list\n```\n. The export list feature works so far. It is not distributed yet but it is enough to rerender dirty tiles at smaller scale in the next sprints.\n. Approach works for more complex layers like landuse 4db5524ea9278c3ecbd738b2bfaab78990bf5ede. Perhaps we should implement some DSL to make it more readable.\n. > Would not this be better then calling for the same task an external node-based utility?\nIf it works as well as tile-cover it is much more elegant indeed (SQL :heart: ).\nWill play with those queries as well and try to implement the same examples as proof of concept.\nIf we can adapt the query to work for polygons and lines in a reasonable amount of time doing everything on the database is much more elegant (performance wise I guess it will be about the same).\nI'm a bit afraid it could end up in a big ball of SQL code but so far we actually managed to keep the SQL reasonably clean with the pgsql functions in the tm2source project so far.\nRunning it on the trigger or on demand  doesn't matter imho. But I would prefer explicitly querying for dirty tiles (and then a external tool can decide how to schedule it as jobs or print it as list etc) instead of keeping a table of dirty tiles in the database.\n. Thanks for the good constructive feedback @klokan, like always.\nI like the SQL solution. It is reasonably fast and worked on first try as well.\nWe just need to organize the code well. Below is example for osm_poi_points.\nsql\nWITH RECURSIVE dirty_tiles(x, y, z, e) AS (\n  -- root node (0, 0, 0)\n  SELECT 0, 0, 0, EXISTS(\n    SELECT 1 FROM changed_poi_points WHERE geometry && CDB_XYZ_Extent(0, 0, 0)\n  )\n  UNION ALL\n  -- coordinate for the children\n  SELECT x*2 + xx, y*2 + yy, z+1, EXISTS(\n    SELECT 1 FROM changed_poi_points\n    WHERE geometry && CDB_XYZ_Extent(x*2 + xx, y*2 + yy, z+1)\n    ) FROM dirty_tiles,\n    -- iterate over 4 children\n    (VALUES (0, 0), (0, 1), (1, 1), (1, 0)) as c(xx, yy) \n    -- only for tiles with geometry and up to zoom level 14\n    WHERE e AND z < 14\n), changed_poi_points AS (\n  SELECT * FROM osm_poi_points WHERE timestamp > '2015-10-01 21:23:01'::timestamp AND name <> ''\n)\nSELECT z, x, y FROM dirty_tiles where e;\nOn the other hand having it in Node is quite comfortable because rendering the missing tiles will also take place in Node.\nI suggest we continue prototyping in Node (all we do is stitch together SQL queries in node - which is quite comfortable and productive so far). Porting it to pure SQL afterwards is straightforward (we only need to replace the \"figure out dirty tiles from geometry part\"). Lets discuss this tomorrow @manuelroth.\nI also think it is important that we have a complete walkthrough the entire process asap so we can actually verify that it works with a concrete example.\n\nthe code could be rewritten to golang for direct integration in imposm3,\n\nWe would need to hardcode the rules into Golang. Because now we really look at the queries of the tm2source project and build queries for each zoom level. The solution is not as abstract in the DFS approach. It all depends on the performance we will experience later down the road or until we can make more educated guesses and then start optimizing.\nI am actually quite confident at the moment that figuring out the dirty tiles with the second approach is fast enough.\nWhat is another idea (perhaps unnecessarily complicated - but definitly fun) is abstracting the tm2source queries into another format (Mapzen uses a Jade templating language to generate the tm2source queries - and you can solve any CS problem by another layer of indirection ;) \nPerhaps we can generate from that DSL both the queries for the tm2source and the queries to select the dirty tiles.\n. Another idea how to write the \"what features are displayed on what zoom\" level only once and not in the queries and the dirty tiles logic.\nWe can create views for each zoom level and the layer is a UNION ALL query across all zoom level views.\nExample\nQuery for landuse before.\nsql\n        (\n          SELECT osm_id, geometry, classify_landuse(type) as class, type\n            FROM (\n              SELECT osm_id, geometry, type FROM osm_landusages_gen0\n              WHERE geometry && !bbox!\n              AND type IN ('wood', 'nature_reserve', 'national_park', 'forest')\n              AND (\n                (\n                  st_area(geometry) > 300000000\n                  AND z(!scale_denominator!) = 5\n                )\n                OR\n                (\n                  st_area(geometry) > 100000000\n                  AND z(!scale_denominator!) = 6\n                )\n                OR\n                (\n                  st_area(geometry) > 25000000\n                  AND z(!scale_denominator!) = 7\n                )\n                OR\n                (\n                  st_area(geometry) > 5000000\n                  AND z(!scale_denominator!) = 8\n                )\n                OR\n                (\n                  st_area(geometry) > 2000000\n                  AND z(!scale_denominator!) = 9\n                )\n                OR\n                (\n                  st_area(geometry) > 500000\n                  AND z(!scale_denominator!) = 10\n                )\n              )\n              UNION ALL\n              SELECT osm_id, geometry, type FROM osm_landusages_gen1\n              WHERE geometry && !bbox!\n              AND (\n                  type IN ('wood', 'nature_reserve', 'national_park', 'forest')\n                  AND st_area(geometry) > 100000\n              )\n              AND z(!scale_denominator!) = 11\n              UNION ALL\n              SELECT osm_id, geometry, type FROM osm_landusages\n              WHERE geometry && !bbox!\n              AND (\n                (\n                  type IN ('wood', 'nature_reserve', 'national_park', 'forest')\n                  AND st_area(geometry) > 10000\n                  AND z(!scale_denominator!) = 12\n                )\n                OR\n                (\n                  type NOT IN ('wetland', 'marsh', 'swamp', 'bog', 'mud', 'tidalflat')\n                  AND z(!scale_denominator!) >= 13\n                )\n              )\n            ) AS landusages\n        ) AS data\nQuery for landuse after. All logic for the zoom level distinction would be put into views. And we need to hope the query optimizer likes UNION ALL.\nsql\n        (\n          SELECT osm_id, geometry, classify_landuse(type) as class, type\n            FROM (\n              SELECT * FROM landuse_z5 WHERE z(!scale_denominator!) = 5\n              UNION ALL\n              SELECT * FROM landuse_z5 WHERE z(!scale_denominator!) = 6\n              UNION ALL\n              SELECT * FROM landuse_z7 WHERE z(!scale_denominator!) = 7\n              UNION ALL\n              SELECT * FROM landuse_z8 WHERE z(!scale_denominator!) = 8\n              UNION ALL\n              SELECT * FROM landuse_z9 WHERE z(!scale_denominator!) = 9\n              UNION ALL\n              SELECT * FROM landuse_z10 WHERE z(!scale_denominator!) = 10\n              UNION ALL\n              SELECT * FROM landuse_z11 WHERE z(!scale_denominator!) = 11\n              UNION ALL\n              SELECT * FROM landuse_z12 WHERE z(!scale_denominator!) = 12\n              UNION ALL\n              SELECT * FROM landuse_z13-z22 WHERE z(!scale_denominator!) >= 13\n            ) AS landusages\n            WHERE geometry && !bbox!\n        ) AS data\nAnd for the dirty tiles we can then specifically query the view only SELECT * FROM landuse_z12 WHERE timestamp > ...\n. We now refactored the tm2source project to pull the data together from zoom level specific views. This has the benefit that we don't need to duplicate logic in order to query the dirty tiles.\nFor detecting the dirty tiles we are no longer using tile cover since the SQL scripts works so well. We use a dynamic SQL function detect_dirty_tiles that you can pass a timestamp and view to get back the dirty tile indizes.\nThis is very convenient to use for generating the dirty tiles. Querying the dirty tiles for the pois is a one liner.\nsql\nSELECT * FROM detect_dirty_tiles('poi_label_z14', 'timestamp-of-last-change'::timestamp)\nWHERE z = 14\nWe use this function from the Node script to write the dirty tiles to the list.\njavascript\nfunction recentDirtyViews() {\n    return db\n        .one('SELECT MAX(timestamp) FROM osm_timestamps')\n        .then(function(result) { return result.max; })\n        .then(function(timestamp) {\n            return q.all([\n                detectDirtyTiles('water_label_z10', timestamp, 10, 10),\n                detectDirtyTiles('water_label_z11', timestamp, 11, 11),\n                detectDirtyTiles('water_label_z12', timestamp, 12, 12),\n                detectDirtyTiles('water_label_z13', timestamp, 13, 13),\n                detectDirtyTiles('water_label_z14', timestamp, 14, 14),\n                detectDirtyTiles('poi_label_z14', timestamp, 14, 14),\n                detectDirtyTiles('road_label_z8toz10', timestamp, 8, 10),\n                detectDirtyTiles('road_label_z11', timestamp, 11, 11),\n                detectDirtyTiles('road_label_z12toz13', timestamp, 12, 13),\n                detectDirtyTiles('road_label_z14', timestamp, 14, 14),\n                detectDirtyTiles('waterway_label_z8toz12', timestamp, 8, 12),\n                detectDirtyTiles('waterway_label_z13toz14', timestamp, 13, 14),\n                detectDirtyTiles('housenum_label', timestamp, 14, 14)\n            ]);\n        }).then(_.flatten);\n}\n. @manuelroth We need to add the views to the drop_views function\nin  the import-osm container. Otherwise imposm cannot remove the tables that are referenced by the views.\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/feature/detect-dirty-tiles/src/import-osm/import.sh#L81-L83\n. Yes it is a bit nasty but i found no other way to do it because imposm3 drops the tables.\nThis also means that after each docker-compose import-osm you have to run docker-compose run import-sql. But perhaps we can find a better way.\n. In this issue the goal was to find out whether the \"Shapes first\" approach works - and it does work fast enough by using tilecover #154.\nNext steps will happen in the next sprint (v1.2) where we'll continue work on related issues like #149 #151 #148 #144 \n. Yes we can do that. I had it at one point - problem is it is just a really huge diagram where almost too much is displayed.\nI will generate a new diagram for you when I get to it.\n. We just played around by creating manual .osc file and found at that if a tag changed that we don't have in our table columns it will still be updated.\nAnd not via a SQL UPDATE but with a DELETE and then INSERT.\nWe can perhaps reduce the amount of dirty tiles by ensuring we only calculate dirty tiles for rows that have really changed.\n. Goal of this issue was to figure out how it works. Implementation will continue in a different issue.\nThe implementation in #191 using triggers is sadly too slow at the moment for an entire world diff import. Glad we didn't use triggers earlier for detecting the dirty tiles.\n. Will merge it when we start working on the mapping/queries again - but it might take some time until we get there.\n. > However, this does not completely fix the issue, as now some areas are now represented as both ways and areas. Most of then seem to be parking areas that are not explicitly tagged as areas. example\nI think we can solve that by letting imposm3 importing all geometry types (and then it will hopefully figure out duplicates based on osm_id).\nDo you @hannesj  have a plaza example that is not tagged as area so we can do testing?\n. I am working on it on our add_area_polygons branch.\nSadly somehow GitHub doesn't get that it is your original code that has\nbeen submitted at https://github.com/osm2vectortiles/osm2vectortiles/commit/eef98465fd7a9021c4254790c8757f5a54b2e726. Sorry for that.\nI now import the road linestrings and road polygons separately as you suggested but then remove the duplicates in a view based on the osm_id. All other layers operate on that view.\nsql\nCREATE OR REPLACE VIEW osm_unique_road AS (\n    SELECT rp.osm_id, rp.geometry, rp.type, rp.service,\n           rp.oneway, rp.is_bridge, rp.is_tunnel, rp.timestamp,\n           rp.ref, rp.name, rp.name_en, rp.name_es,\n           rp.name_fr, rp.name_de, rp.name_ru, rp.name_zh,\n           rp.layer, rp.z_order\n    FROM osm_road_polygon AS rp\n    UNION ALL\n    SELECT rl.osm_id, rl.geometry, rl.type, rl.service,\n           rl.oneway, rl.is_bridge, rl.is_tunnel, rl.timestamp,\n           rl.ref, rl.name, rl.name_en, rl.name_es,\n           rl.name_fr, rl.name_de, rl.name_ru, rl.name_zh,\n           rl.layer, rp.z_order\n    FROM osm_road_linestring AS rl\n    LEFT JOIN osm_road_polygon AS rp ON rp.osm_id = rl.osm_id\n    WHERE rp.osm_id IS NULL\n);\n. > @lukasmartinelli thanks. I added a second commit which removes the parking areas from the road linestrings. As per OSM wiki it is used only for areas.\nWe don't handle parking spaces right now, but they are quite a prominent feature that should be displayed somewhere. Mentioned in #166\n. This plaza now works.\nhttp://www.openstreetmap.org/way/26261827\nPerhaps you can merge back the changes in add_area_polygons back to your remote branch and then I can merge the PR - because you initiated the change :+1: \nhttps://github.com/osm2vectortiles/osm2vectortiles/tree/add_area_polygons\nOr I just create a new PR - your call.\n. Great stuff @hannesj !! We still need to continue to work on it and I need to review and test the road polygon issue but this will happen in separate issues.\nWe also learned in this issue how to work with multiply geometry types and then\nremove the duplicates.\n. I just added empty import and export folders. They are usually created by docker-compose at startup but as someone who starts the project the first time one cannot know where to put the PBF file.\nThere is a import folder in the root project now where you need to put the PBF file.\nAfter that if you run import-osm it should work.\nThanks for the feedback. Tell us if that works for you.\nWe try to make the docs more clear - or you can create a PR yourself  as the documentation is based on GitHub pages.\nhttps://github.com/osm2vectortiles/osm2vectortiles/tree/gh-pages/docs\n. Sorry it is very confusing. The /data/import location is actually the volume that is mounted into the Docker container. If you look in the docker-compose.yml file you can see that actually the local folder import is then mapped to the Docker container volume /data/import. The Docker ecosystem is not that approachable to be honest.\nSo you need to put the downloaded PBF file into the import.\nChange your workflow to:\n- I've downloaded Docker Compose\n- cloned this repo/ cd'd into it\n- run docker-compose up -d postgis\n- cd import\n- downloaded .pbf data wget https://s3.amazonaws.com/metro-extracts.mapzen.com/zurich_switzerland.osm.pbf\n- run docker-compose up import-osm\n. > Just to be sure, once I download and cd into the repo, I also need to run make to setup all of Docker's images etc, right?\nWe use the Makefile only to use the latest images locally. When you use docker-compose it should automatically pull down the latest images from Docker hub we prebuilt for you.\nBut try to just rebuild the import image with make import-osm.\n\nIt behaves like there's either no .pbf file, nor the mapping works as expected.\n\nWe once had issues before with Docker and OSX. Usually Virtualbox mounts the directory into the VM where Docker is running and everything is fine. If you installed the Docker toolbox \nLet's do a Hangout/Skype call to debug the issue. Really sounds like a OSX/Docker issue.\nSkype: lukas.martinelli\nHangout: me@lukasmartinelli.ch\n. So it definitly was a Docker issue :grin: Happy mapping @miccferr and I hope you can still use osm2vectortiles even though it lacks terrain data.\n. > I am having the same issue. Can you elaborate how this issue was resolved.\nUsing OSX? Are you mounting the import folder in the docker compose to a special folder?\nOr elaborate a bit.\nHave you put the PBF file into the ./import folder at the repo root?\nWhat happens is because Docker runs on VirtualBox on OSX mounting the filesystem raises weird issues. But we no longer had problems with this now.\n. > I am using windows 7. The problem I am facing is that docker virtual folder is not being mapped to a physical folder. I did place the .pbf file in ./import folder at the root.\nDon't know how Docker on Windows works - but another thing you can try is if you have Kitematic (https://kitematic.com/) or so installed you can click on the volume folders there to open the actual mounted location.\nOtherwise I recommend running it on a Linux virtual machine (most Windows guys at the uni use Docker this way - but I know this recommendation is never cool).\n. Good it worked. We merge the lower zoom levels of the planet in the\nextracts so zooming out looks nice - but 155KB seems really tiny..\nOn Jun 14, 2016 22:30, \"nitinlkoin1984\" notifications@github.com wrote:\n\nI am doing is that way. Opening Kitematic and mapping the folders to\nphysical folders. At the end of the process I get a very small file. For\nexample the houston extract on your website is 55mb. My houston extract\nfollowing the process outlined is 155 kb\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/136#issuecomment-226006393,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ABOok0u4CpCQeAJ3fX6kUk8TF_DDfjiXks5qLw9QgaJpZM4HlMAo\n.\n. You're right, we stil lneed to add:\n- [x] Merging z0 to z5 into the extracts\n- [ ] Add city boundaries\n\nHm, let's keep this PR open until it's done. It is pretty standalone so merging shouldn't be an issue.\n. City boundaries are in separate ticket #146 \nAlso added automated S3 upload so now we can just kickstart the extracts and it will\nupload new versions once we have a new updated planet file.\nThis also resolves #145 \n. It works in the feature/detect-dirty-tiles branch though.. :thought_balloon: \n. Weird now the geofabrik URL no longer works. Perhaps they don't keep the extracts forever.\n\n. It is possible to do it in SQL as well but the advantage to do it in JS is that we have lots of smaller queries for the zoom levels (which puts less load on the PostgreSQL server). Plus we have stats about what changed on each level. \n. > This issue is fixed, if all tiles in the dirty tiles file are distinct\nYou can use Underscore uniq.\nhttp://underscorejs.org/\n. > @manuelroth I can see you reversed most of the changes there, and for the worse, because now it again tries to allocate a virtual connection for every single request, instead of doing it once, inside a task.\nNo worries we are fully aware of that - we just had to port over an old piece of code in a rush to see whether it is faster. We were planning refactor the code again to use the Task feature.\n. > writing the timestamp of a PBF via imposm3 (write a imposm patch in Golang)\nTried tuning PostgreSQL but update just takes too long to be practical. The bigger problem is that the database size actually doubles (until the VACUUM is done) which means it no longer fits on the 375GB SSD we have attached to the machines - therefore the only option is to add the timestamp at import time.\nThis has a higher priority because until the timestamp is not there we cannot actually test performance of the diff update approaches.\nWill dig into the imposm3 code now and check how we best write an additional column at import time and then add a new field type to imposm3.\n. > Here are the best documents optimising PostgreSQL for full planet OSM import, in case you haven't read them yet. Also, what helped me (strangely!) was to add a huge swap partition (like 60 GB), and just let it swap. In my case it meant using cache 26000 on a 32 GB server, but that was with osm2pgsql.\nThanks a lot of @hyperknot. Didn't know all of those links.\nWe already did tuning on the import but we can certainly still improve it.\nI only did PostgreSQL settings tuning so far - no tuning of the machine settings. Worth investigating there as well. What we found out there is that for the imposm phase having fast CPU is most important and then later IO becomes the bottleneck (there it helps to have fast SSDs).\nWe run the import on 52GB memory machines with 8 cores and then store the database files on a shared disk that we attach to the workers and then copy the DB files over to the local SSD disks of the workers. And then we start the rendering.\nBut in this issue the problem is actually adding a timestamp to each row that contains the date of the OSM snapshot in the PBF file in the most performant way possible.\n. PR https://github.com/omniscale/imposm3/pull/94 adds a pbf_timestamp to imposm3 which makes setting the timestamp initially really fast.\nI can't figure out the timestamp for the current diff import in the field type therefore this setting timestamp of diffed rows works with UPDATE so far.\n\nThis introduces a new field type pbf_timestamp which will set the value to the timestamp defined in the PBF Header.\n. FOSS4G Proposal - v0.2\n\nCreate Vector Tiles from OpenStreetMap\nThe advantages of vector tiles over traditional raster tiles are well known. There are already a handful of vector tile provider present, but they may not always serve your use case optimally. After this talk you will know how to create your own custom vector tiles based on OpenStreetMap and will know the tools and processes you need to use. \nThe talk will cover how to import OpenStreetMap data into PostGIS and then shows how to generate vector tiles using tilelive and Mapnik. We will present the open source workflow we use at OSM2VectorTiles to prerender global vector tiles and instruct you how to adapt the workflow to fit your vector tile needs. Furthermore we will explain how the OSM data can be enriched with other datasources to improve the map.\nOSM2VectorTiles is a project simplifying installation of free and offline world maps powered by OpenStreetMap. It offers freely downloadable OSM vector tiles, and a set of open-source tools for use and generating of the maps.\n. @klokan We created a first draft of the proposal. We will focus a bit more on how to create vector tiles and what tools to use and then go over and show how to adapt OSM2VectorTiles for your needs.\nWhat would @hannesj @hyperknot @ImreSamu like to hear in a FOSS4G talk about OSM2VectorTiles (or lessons learnt from the project)?\n. > Benchmarks and data sizes :\n\nplanet\nbig country ( osm pbf extract size: 1-5 GB )\nsmall country ( < 500Mb )\nFuture roadmap\nExtending the data modell & customisation:\nHow to add new language code\nHow to add new osm keys ( like whllechair= )\nHow to add new layers\nComparing the Alternative solutions with osm2vectortiles\nMapzen , Kartotherian, ...\n\nWe should definitly add most of them to documentation. We can show one or two customization scenarios at FOSS4G. \nYes we need to differentiate more cleanly between Mapzen (which is not offline) and Kartotherian (which we try to collaborate with).\nBenchmark wise we have a lot of data layour around in the issues. Just for your interest \nrendering the entire world takes a 52 GB RAM machine with 8 cores using 8? Mapnik workers 5 weeks. But we use 5 machines so we get down the actual time of rendering the entire world to one week. For updates we hope we can get by with much less infrastructure.\n. @klokan Could you send us your proposal draft for the second part that is focusing on using the vector tiles?\nWould be best if we have the proposal done today.\n. Yesss!!! The FOSS4G talk got accepted! \nThanks for voting and helping to prepare the draft!\n. @muesliq @numenor @hyperknot @hannesj or who else we have interacted with over the past months: Someone at State of the Map in Brussels? Would love to talk with you.\nI know @sfkeller @klokan @ImreSamu and myself @lukasmartinelli will be there so we can\nprobably have good time discussing the future of OSM2VectorTiles perhaps also do some hacking on it.\n. Okay good and bad news.\nUsing the planet PBF  from  2016-02-29 and doing diff updates until 2016-03-09 covers 10 days of updates. Applying the diff updates with imposm3 takes around 3 hours.\nDetecting the dirty tiles of the 10 days only takes  1 hour which I am very happy with - hurray.\nNow the bad part: 10 days of changes already affects 42'802'075 tiles. Much more than we expected. This really might require distributed processing of the updates due to the huge amount of tiles.\nBut we also need to double check whether we do some serious mistakes and the tile count is therefore so high.\nSo 10 days ~= 43 million tiles. If we want to continuously rerender the world updates on a single machine (to keep it cheap) this means we must be finished with rendering the vector tiles in at least 10 days to be ready for the next update coming in. That could actually still be doable on a single fast server (thinking of reinstating the fat HSR server again).\n. Good news.\nAdding the objects from #210 only adds a 3 million tiles on top for the same time span.\n45263435 tiles for 10 days. This hints at the correctness of the hypothesis that a few tiles change very often. Takes ~\u00a0 1hour 50 minutes for the entire world (including solving #210 #183), which is not bad but not perfect as well. We can still do a lot of optimisation to avoid querying osm_delete tables on the wrong zoom levels if we want to bring that time frame down.\n. To elaborate the problem.\nWhen you run import-diff it will look at the timestamp of PBF and then fetch all changes since then and apply them.\nNow the problem is if you run this one day later it will do the same again but this time download the diffs for two days which means too many rows get updates than there should be.\nOne way to solve it is to always apply the downloaded diffs to the planet PBF in the import folders. This then ensures that the PBF file in import always matches the data that is in the database. Which is a nice guarantee to have.\n. Resolved by #154 \n. > Wouldn't it make sense to try it? Please comment.\nI understand the approach you describe if we try it like that only then we can actually compare the two approaches. Because then we basically do the same in both approaches (from shape -> tiles) not from (tiles -> shapes like now in PostgreSQL).\nIMHO it is unlikely we will get faster than with tilecover - in the best case just as fast at the expense of a more complex approach. My hope in using SQL was that it becomes simpler because of less moving parts, if it is not simpler than the JS approach we can continue with tilecover.\nIf the tilecover approach does not scale for the entire world (who knows..) we can look at the SQL approach again.\nWhat exactly is the disadvantage using tilecover from your perspective?\n. This also resolves #141 \n. Long monologue ahead...\nPerformance Comparisons\n@manuelroth Hmmpf embarassing error. What we actually timed in JS was only the mapping for the tiles to results. Not even the tile cover or querying code.\nWith new measurements the situation looks more realistic. Like always - most things are too good to be true - JS is still pretty darn fast though.\nThe SQL function works perfect btw. And it is definitly much faster to use it this way.\nsql\nCREATE OR REPLACE FUNCTION overlapping_tiles(\n    geom geometry\n) RETURNS TABLE (\n    tile_z INTEGER,\n    tile_x INTEGER,\n    tile_y INTEGER\n) AS $$\nBEGIN\n    RETURN QUERY \n        WITH RECURSIVE tiles(x, y, z, e) AS (\n            SELECT 0, 0, 0, geom && CDB_XYZ_Extent(0, 0, 0)\n            UNION ALL\n            SELECT x*2 + xx, y*2 + yy, z+1,\n                   geom && CDB_XYZ_Extent(x*2 + xx, y*2 + yy, z+1)\n            FROM tiles,\n            (VALUES (0, 0), (0, 1), (1, 1), (1, 0)) as c(xx, yy) \n            WHERE e AND z < 14\n        )\n        SELECT z, x, y FROM tiles WHERE e;\nEND;\n$$ LANGUAGE plpgsql IMMUTABLE;\nNow let's select all overlapped tiles by all geometries of landuse_z12.\nsql\nSELECT osm_id,\n       tile_x(overlapping_tiles(geometry)) AS x,\n       tile_y(overlapping_tiles(geometry)) AS y,\n       tile_z(overlapping_tiles(geometry)) AS z\nFROM landuse_z12;\nTakes 9440ms. But the second and third time it takes 2500ms.\nThis is reasonable fast  :+1: \nFor landuse_z13toz14 it takes 30s (5 samples) on PostgreSQL.\nlanduse_z13toz14 has 270k objects.\nNow I think this is equivalent to the same Node code which will also find all tiles of all geometries returned.\njavascript\n// Will calculate the tiles from z0 to z14\n//  from the geoms loaded from landuse_z12 view \ndetect_dirty_tiles('landuse_z12', 0, 14);\nTakes ca. 500msto calculate tile boundaries inclusive transfering the geometries from data to Node (the transfering is likely to not scale).\nKind of weird that Node is still faster because it needs to transfer the geometries first and then run the algorithm)\nFor landuse_z13toz14 Node  takes 1700ms. Now in context I guess performance will decrease once too many geometries need to be transfered to Node.\nBut this is just the comparison performance wise.\nHow to detect Changes More Efficiently in SQL\nPlease correct me here where I am wrong @klokan  \nWe will use the overlapping_tiles function differently in SQL so perhaps the performance decrease is still worth it because we can use it smarter.\nInstead of calculating the tile indizes for all zoom level views in SQL we will calculate the tile indizes for all objects of osm_landusages and store them.\nLike a table osm_changes.\nsql\nCREATE TABLE osm_tiles (\n    layer char(30),\n    osm_id bigint,\n    z INTEGER,\n    x INTEGER,\n    y INTEGER,\n    PRIMARY KEY(layer, osm_id, z, x, y)\n);\nAnd now all osm shapes that are used in the landuse layer are inserted in\nosm_tiles. Takes 40s (which is probably the 30s + 10s IO).\nsql\nINSERT INTO osm_tiles\nSELECT '#landuse',\n       osm_id,\n       tile_x(overlapping_tiles(geometry)) AS x,\n       tile_y(overlapping_tiles(geometry)) AS y,\n       tile_z(overlapping_tiles(geometry)) AS z\nFROM osm_landusages;\nBut the layer is also served by the generalized table osm_landusages_gen0 and osm_landusages_gen1. Now in theory the generalized tables e.g. could cover different tiles because they are different geometries? - but I hope we can ignore that. So actually we need to do.\nsql\nWITH landuse_layer_sources AS (\n    SELECT osm_id, geometry FROM osm_landusages_gen0\n    UNION ALL\n    SELECT osm_id, geometry FROM osm_landusages_gen1\n    UNION ALL\n    SELECT osm_id, geometry FROM osm_landusages\n)\nINSERT INTO osm_tiles\nSELECT '#landuse',\n       osm_id,\n       tile_x(overlapping_tiles(geometry)) AS x,\n       tile_y(overlapping_tiles(geometry)) AS y,\n       tile_z(overlapping_tiles(geometry)) AS z\nFROM landuse_layer_sources\nGROUP BY 1, 2, 3, 4, 5\nWhich takes 45s. But again timing doesn't matter so much perhaps because this only need to be done once (as long as it still performs for entire planet).\nAnd now after an update happens on a row we take the OSM id of our changed row and look up in osm_tiles which tiles are affected.\nIt is also still possible to do it all in one batch.\nGet all affected osm_ids.\nsql\nSELECT DISTINCT osm_id (\n--- union all landuse zoom level views\nSELECT * FROM landuse_z12\nUNION ALL\nSELECT * FROM landuse_z11 \n...\n)\nAnd now those osm_ids can be looked up to affected tiles by joining them (still pretty fast).\nConclusion\nWrote it down primarily to keep it in my own head.\nSo the SQL function is not quite as fast as I hoped for.\nIt is a pretty sophisticated and efficient approach - with the big advantage that it works on TRIGGER level very well.\nI am however a worried about the osm_id (I don't know how well they really identify a shape, I think it could be multiple geoms in different tables exist with the same osm_id due to the mapping config we use). And performance wise I still need to test the real deal with planet data.\n. Now we also discussed about the performance differences between going from shapes to tiles (SQL above) and from tiles to shapes (SQL in this comment).\nQueries\nShapes to Tiles:\nsql\nSELECT tile_x(overlapping_tiles(geometry)) AS x,\n       tile_y(overlapping_tiles(geometry)) AS y,\n       tile_z(overlapping_tiles(geometry)) AS z\nFROM landuse_z12\nGROUP BY 1, 2, 3\nORDER BY 3\nTiles to Shapes\nsql\nWITH RECURSIVE overlapping_tiles(x, y, z, e) AS (\n  -- root node (0, 0, 0)\n  SELECT 0, 0, 0, EXISTS(\n    SELECT 1 FROM changed_poi_points WHERE geometry && CDB_XYZ_Extent(0, 0, 0)\n  )\n  UNION ALL\n  -- coordinate for the children\n  SELECT x*2 + xx, y*2 + yy, z+1, EXISTS(\n    SELECT 1 FROM changed_poi_points\n    WHERE geometry && CDB_XYZ_Extent(x*2 + xx, y*2 + yy, z+1)\n    ) FROM overlapping_tiles,\n    -- iterate over 4 children\n    (VALUES (0, 0), (0, 1), (1, 1), (1, 0)) as c(xx, yy) \n    -- only for tiles with geometry and up to zoom level 14\n    WHERE e AND z < 14\n), changed_poi_points AS (\n  SELECT * FROM landuse_z12\n)\nSELECT z, x, y FROM overlapping_tiles where e;\nTimings\nNow the weird part. The tiles to shapes approach is just as fast.\nThis invalidates our hypothesis that doing the recursive function on one geometry is faster than doing it on all geometries.\nThe query asking for the overlapping tiles for each shape is just as fast as the query we had all along. There is no significant difference whether we ask for overlapping tiles for each shape or once for all shapes.\nTime for query 1 (5 samples): 2500-2700ms\nTime for query 2 (5 samples):  2800-2900ms\n. I need to test all of these things on the world db - only then it matters. Last time it also happened that I had alot of small scale tests and on world everything behaves more extreme.\nThe PostGIS of the world import ran out of space (due to the update query - that is why the update was hanging for days). Creating a new one now.\n. We discussed using LATERAL JOIN for performance today.\nThe EXPLAIN ANALYZE returns a bit different approaches but the timings on small datasets are the same. Need to test this on a larger set though to be sure.\nsql\nSELECT t.x, t.y, t.z FROM landuse_z12 AS l\nINNER JOIN LATERAL (\nSELECT tile_x(overlapping_tiles(geometry)) AS x,\n       tile_y(overlapping_tiles(geometry)) AS y,\n       tile_z(overlapping_tiles(geometry)) AS z\n) AS t ON true\nGROUP BY 1, 2, 3\nORDER BY 3\n. > You approach has one significant drawback - if the same geometry appears on landuse_z12 and landuse_z11 then you will several times calculate all tiles for this geometry down to zoom level 14!\n\nIt would be better to calculate it only once and cache it in RAM instead.\nSo a boost in speed could be probably made by calculating all tiles on z0 - z14 for each modified geometry just once - store it in a temporary table - and select the distinct tiles appearing on zoom level of your interest for list of modified osm_ids in the view of your interest (such as landuse_z12).\n\nExactly I tried to describe this approach above in How to detect Changes More Efficiently in SQL . The queries here are for performance testing only (that is why they have to timestamp clause).\n\nIt would be then worth to check what caches in Postgres should be increased so these temp tables with all dirty tiles for one day (or our final update period) all stay in RAM.\n\nThis can be configured with the \"running with scissors\" mode of PostgreSQL.\nIf we use the TRIGGER approach we would insert the affected tiles into a permament table not a temp table. But if we only do a query once we need a temp table.\n\nAnother optimisation could be to add into overlapping_tiles also z as argument - to stop the recursion sooner - if you know you have no interest in deeper zoom levels.\n\nDefinitly we already used that in some examples and it indeed helps a lot.\nIf we calculate the affected tiles once and store them in a temp table we will have to go down to z14 at least once. But if we don't do that optimization (but we really need it because otherwise it is too slow now) then we need to stop the recursion earlier.\n. > We discussed using LATERAL JOIN for performance today.\nI used the LATERAL JOIN the wrong way.\nNow it is indeed approximately 3x faster.\nsql\nSELECT DISTINCT tile_x AS x, tile_y AS y, tile_z AS z\nFROM landuse_z12 AS l\nINNER JOIN LATERAL overlapping_tiles(geometry) AS t ON true\nORDER BY tile_z\n. Will retry upload to our S3 share. It is a 12GB TSV file that is 4GB gzipped.\nSomehow I got quota errors uploading to Google Drive.\n. > Where can we download the exported data for the whole world?\nDownload link of streets osmnames export.\nhttps://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.2/osmnames/roads.tsv.gz\n. > I noticed on the examples page that raster and vector maps are very different in how they show data and which data they show, despite using the same stylesheet (OSM bright). How come?\nGood question.\nThe OSM Bright stylesheets for Mapbox GL and Mapnik are different. There is much room to optimize in the Mapbox GL OSM Bright style (weird that they haven't done it - even on Mapbox.com the raster OSM Bright looks better). But that is out of our control, we did not touch the styles and let them be maintained by Mapbox and other people with talent for designing maps :grin: .\n- https://github.com/mapbox/mapbox-gl-styles\n- https://github.com/mapbox/mapbox-studio-osm-bright.tm2\nIn the future we want to go more in the direction of making sure Mapbox GL looks good instead of traditional raster maps (with Mapbox Streets v7 it is probably not possible to make the data work well with GL styles (which depend on v7) and raster maps (which depend on Mapbox Streets v5).\n. Wrote low quality  text so we don't forget those chapters later.\nBut definitly needs to be revisited in the writing phase again.\n. Thanks for the great insights guys.\nWill @ImreSamu or @hyperknot look after/fix this issue or shall we take over?\n. > I'm not an expert on this, but I've just seen other projects recommending to use only Node 0.10.x for tilelive-vector, and it's also the required engine in it's package.json:\n\nhttps://github.com/mapbox/tilelive-vector/blob/master/package.json\n\nGreat feedback. This is stuff we would never notice. Thanks.\nOur build suddenly started breaking with node 0.10.x (even though we fixed the npm versions) #139 that's why it thankfully got fixed in #160.\nI want to keep this issue open as a reminder for some time when bugs and weird things start happening we have a clue why.\n. Thanks again @hyperknot for the detailed research.\nLet's roll back to v0.10 again and try get a working set of dependencies based on \nmapnik@3.5.2.\n. > Referring to http://osm2vectortiles.org/docs/database-schema/ make table names even more consistent in order to make it more self-documenting.\nCompletly agree. We should also define this naming rules in the documentation as well.\n\nWhen you mention osm_id here, do you mean the osm_id from OSM or the \"enhanced\" osm_id?\n\nUntil now we used the raw osm_id. This could be another issue to create an enhanced OSM id following the multiplication rules of Mapbox (chapter OSM IDs) https://www.mapbox.com/developers/vector-tiles/mapbox-streets-v7/\n\nIn addition (especially if this table renaming is no feasible) indicate as field type not \"geometry\" but the geometry type (point, linestring, polygon),\n\nYes this will make the diagram much more useful :+1: \n. Worked well. Doesn't slow down the import (import now takes 24+hrs but this is because of the diff mode which is 3x slower).\n. This is such a great listing @numenor!\nWe scheduled time for quality improvement but the big work would have been figuring out what is missing - exactly what you have done now!\nDid you previously base your Mapnik stylesheet on Mapbox Streets?\nOur layers, fields etc. all are directly based upon the decision to be compatible with the Mapbox Streets .\nWith some of the issues you mentioned it is probably the case that we simply overlooked them when reverse engineering Mapbox Streets for others they are simply not there.\nWe do have the freedom to add additional data to the layers or introduce new layers for example peaks (as long as the tile size stays reasonable).\nWe also want to try to get the tile size under 500KB for the future (so people can use Mapbox Studio to style them).\nDid you find the no. of occurrences with taginfo?\nWe will try to do a first assesment of those 16 issues listed and find out whether they would require a new layer or fit into an existing one.\nWe will do this assesment in this issue and after that we can split create new issues for the individual points listed.\n. Wow this is so much faster than the recursive function.\nsql\nCREATE TYPE tile AS (x INTEGER, y INTEGER, z INTEGER);\nCREATE OR REPLACE FUNCTION point_to_tile(\n    _point geometry,\n    zoom_level INTEGER\n) RETURNS tile\nAS $$\nDECLARE\n    d2r CONSTANT DOUBLE PRECISION := pi() / 180;\n    lon CONSTANT DOUBLE PRECISION := st_x(ST_Transform(_point, 4326));\n    lat CONSTANT DOUBLE PRECISION := st_y(ST_Transform(_point, 4326));\n    z2 CONSTANT DOUBLE PRECISION := pow(2, zoom_level);\n    _sin CONSTANT DOUBLE PRECISION := sin(lat * d2r);\n    t tile;\nBEGIN\n    t.x = floor(z2 * (lon / 360 + 0.5));\n    t.y = floor(z2 * (0.5 - 0.25 * log((1 + _sin) / (1 - _sin)) / pi()));\n    t.z = zoom_level;\n    RETURN t;\nEND;\n$$ LANGUAGE plpgsql IMMUTABLE;\n. Thanks a lot for the quality research and changes. :clap: \nWe would have never been able to foresee issues with the newer Node version.\n. > In Travis this is not a problem, as it always starts with a clean environment, there is no cache there. But on real environments, I believe the cache can be any age. I don't know how are you publishing the images, or how frequently are docker build commands run, but Makefile might need --no-cache for consistent results.\nOur public Docker images use automated trusted builds so we do not push any\nimages explicitly.\nFor local development we want the docker build in  Makefile to cache otherwise\nit would be too slow for development. Users of osm2vectortiles can build it themselves but we recommend to use the prebuilt images at https://hub.docker.com/u/osm2vectortiles/.\n\nDocker build caches each command, so an apt-get update, etc. makes no change, if it was ever run on the same image before.\n\nI would actually like to fix the the versions of aptitude packages installed to guarantee more repeatable builds. I will use this issue ticket to check out whether the Dockerfile are all good other\nwe can improve something.\nBtw. shameless self plug. I wrote a Dockerfile linter http://hadolint.lukasmartinelli.ch exactly for this purpose to help people to create best practice Dockerfiles.\n. What is the concrete improvement we can do here? Otherwise I close this :wink:  Adding --no-cache to the Makefile would make it too slow to work with.\nI actually never ran into a problem with our apt installs so far.\n. > No improvement / bug here, just wanted to raise the point that local builds and Travis build can be on different versions, so we might need to manually rebuild with --no-cache from time to time. I was surprised when I first understood this, might not be clear for others as well.\nWe should create kind of a contributing / developer docs where we can write stuff like this down.\nRight now we don't have much information on GitHub as the docs are on the website. But contributor information like this could live in the GitHub README imho.\n. This also creates lower zoom level extracts of the world :+1: \n. We already use pgtune in production but not on a dynamic basis like you propose.\nThe config files are usually tuned for each server separately using pgtune (depending on the server specs).\nLuckily your script is still compatible with that approach - the good thing is that it now automatically will create a good config at startup without manual intervention. :+1: \nSomething that is especially useful for people that want to try out osm2vectortiles.\n. > I will make some tests ..\n\nplease do not merge yet\n\nIt look okay, shall we merge it?\n. > The only problem, that this solution is not support PG 9.5 yet. :(\nWe'll solve that once we switch to PG 9.5.\n. Create views that query all zoom levels that can be used in the detect dirty tile process.\nExample.\nsql\nCREATE VIEW landuse_zoom_level_changes_geom AS (\n    SELECT osm_id, timestamp, geometry FROM landuse_z13toz14\n    UNION\n    SELECT osm_id, timestamp, geometry FROM landuse_z12\n    UNION\n    SELECT osm_id, timestamp, geometry FROM landuse_z11\n    UNION\n    SELECT osm_id, timestamp, geometry FROM landuse_z10\n    UNION\n    SELECT osm_id, timestamp, geometry FROM landuse_z9\n    UNION\n    SELECT osm_id, timestamp, geometry FROM landuse_z8\n    UNION\n    SELECT osm_id, timestamp, geometry FROM landuse_z7\n    UNION\n    SELECT osm_id, timestamp, geometry FROM landuse_z6\n    UNION\n    SELECT osm_id, timestamp, geometry FROM landuse_z5\n);\n. > The dirty tiles detection is always very relevant to a zoom level - what is the purpose of this summary view exactly?\nTo create a list of osm_ids with their dirty tiles based on what changed\nyou cannot work with the table osm_landusages or osm_roads directly. \nBecause the osm_landusages table actually is the source for both layers landusage and landusage_overlay and osm_roads for bridge, tunnel, road.\nAnd the geometries of the tables can also be changed into different ones. Like POI point labels that were originally a polygon.\nWith the summary view we can get the list of changed geometries for a given layer\nwhich then allows to query the OSM ids with their respective dirty tiles.\nThe summary view also removes the OSM ids that appear on many zoom levels (UNION).\nWe can then query all dirty tiles for a layer. The query below for the complex landusages layer actually completes in 40s (for the entire world with 10 days of updates) which is pretty fast IMHO.\nWe still need to validate whether the query really returns the dirty tiles #149 \n``` sql\n--Query all changed geometries for layer landusage\nWITH changed_geometries AS (\n    SELECT osm_id, geometry FROM layer_landusage\n    WHERE timestamp = '2016-03-09 14:15:02'\n--Calculate the dirty tiles for each OSM id\n), changed_tiles AS (\n    SELECT DISTINCT c.osm_id, t.tile_x AS x, t.tile_y AS y, t.tile_z AS z\n    FROM changed_geometries AS c\n    INNER JOIN LATERAL overlapping_tiles(c.geometry) AS t ON true\n)\nSELECT c.x, c.y, c.z FROM landuse_z13toz14 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z BETWEEN 13 AND 14\nUNION\nSELECT c.x, c.y, c.z FROM landuse_z12 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 12\nUNION\nSELECT c.x, c.y, c.z FROM landuse_z11 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 11\nUNION\nSELECT c.x, c.y, c.z FROM landuse_z10 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 10\nUNION\nSELECT c.x, c.y, c.z FROM landuse_z9 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 9\nUNION\nSELECT c.x, c.y, c.z FROM landuse_z8 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 8\nUNION\nSELECT c.x, c.y, c.z FROM landuse_z7 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 7\nUNION\nSELECT c.x, c.y, c.z FROM landuse_z6 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 6\nUNION\nSELECT c.x, c.y, c.z FROM landuse_z5 AS l\nINNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 5\n```\n. Roll back to commit https://github.com/osm2vectortiles/osm2vectortiles/commit/3e249cd81b7a92092c64bcfb72e9c3978a0f0404\nAlso keep in mind to fix timing again https://github.com/osm2vectortiles/osm2vectortiles/commit/d4be86456a3920ec277fac1792784eed06d942a5\nQuery for detecting dirty tiles (sufficiently fast for world, 3minutes for all landusages and 45seconds for all POIs). Query only works if #172  is done first.\nsql\nWITH changed_geometries AS (\n    SELECT geometry FROM poi_label_zoom_level_changes\n    WHERE timestamp = '2016-03-09 14:15:02'\n), changed_tiles AS (\n    SELECT DISTINCT t.tile_x AS x, t.tile_y AS y, t.tile_z AS z\n    FROM changed_geometries AS c\n    INNER JOIN LATERAL overlapping_tiles(c.geometry) AS t ON true\n)\nSELECT COUNT(*) FROM changed_tiles\n. > Query for detecting dirty tiles (sufficiently fast for world, 3minutes for all landusages and 45seconds for all POIs). Query only works if #172 is done first.\nUuups bad thought error. Of course this does not work.\nWe need to use the approach defined in How to detect Changes More Efficiently in SQL #155.\n. We now have functions in src/import-sql/views for each layer to find out the dirty tiles . They look ~ like this. They would have no chance running on the entire planet directly but thanks that the timestamp constraint makes the data set so much smaller they actually complete reasonably fast (All dirty tiles of all layers in < 1h).\n``` sql\nCREATE OR REPLACE FUNCTION changed_tiles_road(ts timestamp)\nRETURNS TABLE (x INTEGER, y INTEGER, z INTEGER) AS $$\nBEGIN\n    RETURN QUERY (\n        WITH changed_geometries AS (\n            SELECT osm_id, geometry FROM layer_road\n            WHERE timestamp = ts\n        ), changed_tiles AS (\n            SELECT DISTINCT c.osm_id, t.tile_x AS x, t.tile_y AS y, t.tile_z AS z\n            FROM changed_geometries AS c\n            INNER JOIN LATERAL overlapping_tiles(c.geometry, 14) AS t ON true\n        )\n    SELECT c.x, c.y, c.z FROM road_z14 AS l\n    INNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 14\n    UNION\n\n    SELECT c.x, c.y, c.z FROM road_z13 AS l\n    INNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 13\n    UNION\n\n    SELECT c.x, c.y, c.z FROM road_z12 AS l\n    INNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 12\n    UNION\n\n    SELECT c.x, c.y, c.z FROM road_z11 AS l\n    INNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 11\n    UNION\n\n    SELECT c.x, c.y, c.z FROM road_z8toz10 AS l\n    INNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z BETWEEN 8 AND 10\n    UNION\n\n    SELECT c.x, c.y, c.z FROM road_z7 AS l\n    INNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z = 7\n    UNION\n\n    SELECT c.x, c.y, c.z FROM road_z5toz6 AS l\n    INNER JOIN changed_tiles AS c ON c.osm_id = l.osm_id AND c.z BETWEEN 5 AND 6 \n);\n\nEND;\n$$ LANGUAGE plpgsql;\n```\n. No longer want to merge it due to the incompability with the CDB_Extent extension suggested in #188.\nThe few minutes saved on time are probably not worth making the project much more complex by creating custom extensions.\nI will archive the branch and we can pull it out again if we don't use the approach of #188 or feel we need the extra speed.\n. > In the src/import-osm/import.sh code, the function exec_sql() always return true. ( || true )\n\nSo maybe this is the reason , that travis not detect the SQL errors.\n\nYup it is important that travis fails if something fails.\nNo longer sure why we added that. No longer necessary - removing it in #182.\n. > What is the status of detecting changed-tiles when OSM objects are deleted?\nLike always great issue and documentation @ImreSamu! :+1: \nActually we never thought of that problem. We also don't know how imposm3 reacts\nto that. I have no on the top of my head solution for this problem, but we need to think about it.\nGeometries that are deleted will vanish over time as stuff around them needs to be updated and therefore causes a rerendering (but that's a cheap excuse I know) but in 10 days of diffs more than 10-20% of our tiles change.\n. > probably a simple delete trigger is enought to catch this information.\nMight work. Not sure whether imposm3 does update rows or completely delete and reinsert them.\nIn the extreme case I could also extend imposm3 even further to act on deleted rows. Btw. for #122 I was glad to have your Imposm 3 pull request from https://github.com/omniscale/imposm3/pull/86 at hand to find out how to implement a custom type.\n\nMy other extreme test is the node number 1\n\nTrue, good testing node. Your approaches defined above are also useful for #149 \n\nI have removed the osmupdate part from the ./src/import-osm/import.sh\n\nDo you think it is kind of unintuitive that the import-osm-diff tries to update the PBF in the import folder? Is it perhaps better to explicitly let the user put a changes file in the import folder themselves and just apply the changes file.\nUsers can still use osmupdate.\n. > As I remember Imposm3 diff use :\n\nsql delete\nsql insert ( now this is ok - with timestamp )\n\nWe checked it with the audit trigger https://wiki.postgresql.org/wiki/Audit_trigger\nand it really is like that.\n-[ RECORD 1 ]-+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------schema_name   | public\ntable_name    | osm_poi_point\nuser_name     | osm\naction_tstamp | 2016-03-15 13:45:10.584987+00\naction        | D\noriginal_data | (493,1234,\"2016-12-09 06:57:37\",HSR,\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",school,0101000020110F0000E2EE0DE126C72DC1067E08CC91BF3441)\nnew_data      |\nquery         | DELETE FROM \"public\".\"osm_poi_point\" WHERE \"osm_id\" = $1\n-[ RECORD 2 ]-+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nschema_name   | public\ntable_name    | osm_poi_point\nuser_name     | osm\naction_tstamp | 2016-03-15 13:45:10.584987+00\naction        | I\noriginal_data |\nnew_data      | (494,1234,,HSR,\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",school,0101000020110F0000E2EE0DE126C72DC1067E08CC91BF3441)\nquery         | INSERT INTO \"public\".\"osm_poi_point\" (\"osm_id\", \"geometry\", \"timestamp\", \"name\", \"name_int\", \"name_fr\", \"name_de\", \"name_en\", \"name_es\", \"name_ru\", \"name_zh\", \"website\", \"housenumber\", \"street\", \"place\", \"city\", \"postcode\", \"country\", \"ref\", \"type\") VALUES ($1, $2::Geometry, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20)\n. > I would like if import_pbf_diffs() will be separated smaller callable functions\nI like that separation. For diffs it is useful to have a more power at hand than a single Docker command that does everything magically.\n. Okay this was a tough one.\nWe now detect the deleted dirty tiles. Currently we detect to many dirty tiles for deletions but this is because once an element is deleted we have no additional metadata apart from the geometry which means we can no longer use the zoom level views for deletes to check whether they really appear in the vector tiles.\nResults for the test of @ImreSamu:\n- 443 tiles in first run\n- 482 tiles in second run (where deletes are detected)\nThis is still correct because the 482 tiles contain all 443 tiles of the first tile. Performance wise we can try to filter out deletes that are not really necessary (like deletes for POI on zoom level 14) - but for the case of deletes I would much rather be 100% correct and having too many false positives than having false negatives by optimizing it per layer.\n. > Vatican city overrides label of Rome:\nThat's a different problem. Vatican city is a country and therefore is layered above\nthe city label of Rome. One way to solve it is to not put micro countries into vector tiles until a very high zoom level.\nWork continues in #185\n. > 1) \"Zurich\" label never appears on the map with streets-v8:\n\nhttp://klokantech.github.io/osm2vectortiles-gl-styles/#11.26/47.3721/8.5414\n\nWe never tested the streets-v8, light-v8 and dark-v8 vector maps. We need to check whether it could be filter constraint on the style. Because the data is there in the vector tiles.\nWhat you did to port those styles is simply removing the dependency to Mapbox terrain data set, otherwise they remained unchanged right?\n. I took a look at the style JSON in Mapbox Studio. The city labels also don't show up with the official Mapbox source. And I also saw that there are no longer any layer groups for example.\nMy guess is that we need to download the style.json from Mapbox Studio online not from the repo (this does look different than the one in the osm2vectortiles-gl-styles repo.\n. The city label problem was solved in #185. When we release the next rendering we will have to create the GL styles.\nBut this issue is for the old v1.0 version together with Mapbox GL styles where we cannot do much.\n. You can only solved by the style (by only showing scalerank=6 at very high zoom levels) or by removing the Vatican City.\nGiven that people will start of with the default Mapbox styles that don't solve the issue we should remove the Vatican City from the country labels.\n. Made a comparison. Seems road_label have a too big buffer compared to the Mapbox streets vector tiles. For poi_label we might also decrease the buffer as v7 has done it, but there I would be more cautious. We should definitely tweak road_label.\n77 also has good research about our differences. There the size differences also points to the road_label as root cause.\n| Layer | Mapbox Streets v6 | Mapbox Streets v7 | OSM2VectorTiles v1 |\n| --- | --- | --- | --- |\n| #landuse | 4 | 4 | 4 |\n| #waterway | 4 | 4 | 4 |\n| #water | 8 | 8 | 8 |\n| #aeroway | 4 | 4 | 4 |\n| #barrier_line | 4 | 4 | 4 |\n| #building | 2 | 2 | 2 |\n| #landuse_overlay | 4 | 4 | 4 |\n| #tunnel | 4 | - | 4 |\n| #road | 4 | 4 | 4 |\n| #bridge | 4 | - | 4 |\n| #admin | 4 | 4 | 4 |\n| #country_label | 256 | 256 | 256 |\n| #marine_label | 256 | 256 | 256 |\n| #state_label | 256 | 256 | 256 |\n| #place_label | 128 | 128 | 128 |\n| #water_label | 64 | 64 | 64 |\n| #poi_label | 128 | 64 | 128 |\n| #road_label | 8 | 8 | 64 |\n| #waterway_label | 8 | 8 | 8 |\n| #housenum_label | 64 | 64 | 64 |\n| #motorway_junction | - | 8 | - |\n| #airport_label | - | 64 | - |\n| #rail_station_label | - | 64 | - |\n| #mountain_peak_label | - | 64 | - |\n. I adapted the buffer value for road_label. Seems to save 10KB on avg. on z14 tiles, detailed tile size statistics will follow once we start rendering bigger areas again.\nI guess the poi_label buffer label changes in v7 because in v7 they are pushing down the POIs that previously were in z14 down to z15. But that is just a guess.\nBut we cannot do that so we leave the value at the 128px from v6.\n. > The function to calculate bbox for ZXY in Mercator defined in SQL could be improved to accept buffer size in pixels.\n:+1: Genius idea!! Much simpler and also allows optimizing for buffer values that are not that large.\n. This approach has problems that are intended to be solved in #197.\n. Usually ranking for bigger cities should come for NaturalEarth which assigns importance ranks\nto over 7000 cities in the worlds, if not we fall back to a ranking based on population.\nIn this case it seems oddly off.\nKansas City: http://www.openstreetmap.org/node/1856296860 with population 463202.\nTopeka: http://www.openstreetmap.org/node/25141246 with population 124331.\n. The population is only relevant for something called the localrank. The localrank is the importance of the label compared to the labels in close proximity, in case of city all cities in a cell in a grid are ranked by their population. So this will be correct for the cities mentioned here.\nBut for a city to be displayed at a low zoom level the important part that the scalerank is set and has a minimal value. Now the question is how to find out whether Sao Paulo has a good scalerank. Scaleranks are not derived from population but whether the city is well known/important.\nWe take the scale straight from Natural Earth (so does Mapbox), now the problem with the cities above is that the code that tries to merge OSM data with Natural Earth data does not pick up all important cities.\nI am modifying the code in https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/update-scaleranks/update.sql to improve the matching from OSM to Natural Earth.\n. Matching is slightly improved - hope we don't have many false positives.\nMatched Natural Earth cities before:\n- 5629 osm_place_point\n- 1399 osm_place_polygon\nOkay matching the additional meganame doesn't help much.\nMatched Natural Earth cities after:\n- 5633 osm_place_point (+4)\n- 1400 osm_place_polygon (+1)\nMatching the additional gn_ascii from Natural Earth helps more.\nMatched Natural Earth cities after:\n- 5805 osm_place_point\n- 1447 osm_place_polygon\nMatching the additional nameasciifield from Natural Earth (after matching gn_ascii).\n- 5809 osm_place_point (+4)\n- 1448 osm_place_polygon (+1)\n. Probably related to #116.\n. Will be dealt with in #111.\n. > I see DNS connectivity issues at:\n\nhttps://status.digitalocean.com/\n\nDNS is indeed managed by Digital Ocean. I can switch the nameservers but I would wait until they come back.\n. Site was approximately 2 hrs down.\nDigital Ocean DNS is working again - those poor sysadmins had a rough day I guess. \n. > The page http://osm2vectortiles.org/downloads shows no indicators when the data was rendered the last time. A date (plus version number?) would solve that.\nGood idea! Thanks.\nEspecially when we start rolling out the regular diff updates.\n. > Any forecast on when the next rendering will happen, btw?\nBefore june. We need to start rendering in may and after that switch to rendering weekly updates.\nAfter we have the update process in place we no longer need the huge and costly rerendering effort - you will be able to upload the latest weekly world MBTiles file.\n. > The page http://osm2vectortiles.org/downloads shows no indicators when the data was rendered the last time. A date (plus version number?) would solve that.\nPut up the date and version on the site for the last rendering.\nhttp://osm2vectortiles.org/downloads\n. And one step closer to a better map :)\n. First of all, thanks for the great issue (including test!!) and the OSM talk on osm2vectortiles today :grin: \nWe need to enable delete tracking for updates as well.\nYour test works now with the 21a9173 commit.\nI hope this does not slow down the import as crazy as last time - because this time we only use the delete trigger. Will need to test it on a reasonably large extract or import the world again.\n. Yess!! Doesn't slow down the diff import as much as I feared. Diff import of ~15 days only takes 6h57m even though there is a trigger on every DELETE call.\nFor ~15 days back it recorded 2'839'020 updated or deleted geometries that were tracked in the osm_delete table.\nThat is really good news. So as lesson learnt: Complexity in triggers matters a lot! If the trigger is simple enough performance can still be ok.\n. Okay but as downside the changed tiles detection is now running since 14 hrs instead of one.\nBut I hope we can fix this by introducing a GIST index to the deleted geometry table. The recursive algorithm for detecting the dirty tiles makes heavy use geom1 && geom2.\n. First of all, thanks again for the very insightful points raised and like always great suggestions @ImreSamu \n\nBut I hope we can fix this by introducing a GIST index to the deleted geometry table. The recursive algorithm for detecting the dirty tiles makes heavy use geom1 && geom2.\n\nYes the missing GIST index was the problem - now calculating the dirty tiles for just the deletes is done in 30minutes. So good news there.\n\nforcing an extreme parallelism in the postprocessing part ( by imposm3 tables )\n\nWriting to the delete tables is not the problem in my experience but the cost of just triggering the trigger for each delete. In the main imposm3 import we write sometimes half a billion records into a table and it scales.\n\nparallel generation of changed tiles\n\nIn the previous solution on NodeJS we did 15 parallel SQL queries and then merged the results back together. Then we switched to doing just one SQL query (which in turn does a UNION of 15 SQL queries) and found out it was just as fast - main cost is simply waiting for all that massive IO that is happening.\n\nwith more optimalisation we can create an intelligent\n\nYes not having to wait for all tiles to be calculated means we can get started with rendering quicker.\nBut by waiting for all tiles to be calculated removing the duplicate tiles is easier.\nIf we can get the changed tiles calculation back to ~1 hour we can probably leave it like this with one big calculation of the tiles and then starting to render.\nIf it takes longer I want to try the approach getting faster tile feedback and already start rendering the dirty tiles.\n. Performance problem is solved when we solve the osm_unique problem #219 \n. > Tilelive (used by export-local.sh to export tiles) has an option to perform operations concurrently: https://github.com/mapbox/tilelive/blob/master/bin/tilelive-copy#L14\n\nThis option could be added to the export script (with a sane default) and configured via an environment variable.\n\nWe previously used tl instead of tilelive-copy which did this automatically. Thanks for pointing it out for tilelive-copy.\nWe have three levels of concurrent processing.\n1. At the machine level (5-6)\n2. At the worker level (worker processes per machine 4-5)\n3. At the process level (tilelive-copy and tl concurrency)\n. Just as update. Tweaking concurrency (from 10 to 20 for example) doesn't really effect performance.\nI get just as many tiles per second with 20 (or higher) copy concurrency as with 10 for example.\nI will close this as like always this is kind of a trial and error tweaking thing where I figure out the best values for the three concurrency levels (also depends on machines as well). I will post the settings used in #251 but tweaking the copy concurrency is not the silver bullet \ud83d\ude09 \nBut thanks again for raising attention for the concurrency option in tilelive copy.\n. One solution would be a single table for polygon and linestring and let imposm remove the duplicates with a joint mapping.\nI sketeched out something in https://github.com/osm2vectortiles/osm2vectortiles/commit/9c5ef3631c6bfe5abc5e249396ab1c7097e38eae\n. These performance issues were actually also the reason why the changed tiles calculation suddenly took so long :grin: \nGlad we stumbled across them.\n. Hmm now Schaffhausen is good again on the global map - and Ireland as well.\ndev.vectortiles.osm2vectortiles.org\n\n\n. These changes save hundreds of computing hours. :fireworks: \n. It is an error on the Mapnik team - we hoped they would fix it faster because their builds are also all broken. I will merge it if it is not fixed soon (don't want to merge and then forget about it after you guys spent much appreciated time figuring out in #161 that 0.10 is the best node version)\nIt is really hard to freeze dependencies in NodeJS for all involved packages... :cry: \n. Ah you know what it is more important that everything works again so we can continue work.\nWe just need to remember #161.\n. > Currently the names are included in the same set of languages as in the Mapbox Streets. It would be nice if you could configure what languages you want to have imported into the database and included in the tiles in the compose file.\nI understand the feature request completely. It is kind of a big deal however because for us language fields are just normal fields that we map and process.\nTo make this configurable we would need to make all of these parts dynamic or allow templating.\nProbably the easiest way for someone else add another language like Finnish is to replace a language like Russian with Finnish by doing a search and replace for name_ru with name_fi?.\nHowever multiple languages are probably most relevant for country names and place names imho. There are not as many data points for those labels like for example poi labels.\nSo we could theoretically add a lot more languages for countries and places.\n. > Currently the names are included in the same set of languages as in the Mapbox Streets. It would be nice if you could configure what languages you want to have imported into the database and included in the tiles in the compose file.\nSorry @hannesj. We discussed it again and this is not in our scope and would make the project a lot more complex. Mapzen for example makes heavy use of templating in their tm2source project and imho you can then no longer read it very well and also you are unable to fire up Mapbox Studio and work with it there.\nI really propose you use the search/replace approach if you create a finnish extract. \n\nProbably the easiest way for someone else add another language like Finnish is to replace a language like Russian with Finnish by doing a search and replace for name_ru with name_fi?.\n\nBTW. we would really be interested in seeing how it looks with two labels on one streets or how you create a style that supports that.\n. - [x] In #landuse_overlay the type field is missing.\n- [x] In #poi_label the fields address, website, network are no longer present in Mapbox v7\n- [ ] In #road the value for layer is only present in zoom levels greather or equal 13\n. Okay ready to merge.\n\nWould be glad if a second pair of eyes would look over the tables.yml @manuelroth.\nYou probably detect something immediately since you worked alot on the layers SQL.\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/feature/respect-buffer-in-dirty-tiles/src/import-sql/tables.yml\n. Ahh screwed up with pretty much all buffer values. Sorry.\n\nSurprisingly the buffer size of layer poi_label was incorrect in our source project, corrected it from 128 to 64\n\nOh yes see in Mapbox it is 64px.\n. > BTW Shall we not better test against the JSON GL styles now?\nYes it is with the JSON GL styles (latest Mapbox Studio version of OSM bright of today with the source replaced). We only test for GL styles for now - and put our focus there. Especially since people can serve raster styles with the tileserver-gl later on.\n. Reason is that there are too many road labels compared to Mapbox Streets.\n\nPerhaps we can order by the road length and only select the top 5 in a vector tile and drop the rest at lower zoom levels?\n. Put one hour into it. It is better we don't show suburbs at z10 than showing the wrong ones.\nI cannot filter by localrank because it is not really accurate (since most suburbs don't have a population assigned the localrank doesn't help in ranking and ranking by area also doesn't help).\n. Jup single table helps. But now the polygon points is now taken instead of the original point.\n\n. > Jup single table helps. But now the polygon points is now taken instead of the original point.\nNo not true made a mapping mistake. The points even occur twice if in the same table - which makes perfect sense because there is no way we can match the point and polygon by the osm id (this is a different case as with the roads where we can look at a polygon as a closed linestring).\nBecause we cannot match by the osm id we also cannot remove the duplicates.\nMy suggestion is now that we only match the residential landuse in the polygon part of the type_mappings. Could that work @manuelroth?\nOr we leave out the landuse=residential stuff and polygon matching altogether. \nDid that in commit https://github.com/osm2vectortiles/osm2vectortiles/commit/0edfaa70a928dd9364ae210cf7dc6333ecd5269f - and quality does look better that way and closer to Mapbox Streets.\nBecause it might always be that someone also tagged a neighbourhood with a point inside the residential polygon - and then we have the labels twice again. \nBetter to have good quality labels than too many ones imho.\nOr we do a distance-based name matching with looking for the same name within 10km to remove duplicates. But I don't really want to do that - as it is very vulnerable to false positives.\n. > I suggest the following mapping. islands, islets and archipelago are in polygon because the are most of the time mapped on the area.\nYes let's try this and compare again.\nThe only critical thing I see there is landuse=residential where people put a point with place=neighbourhood inside the polygon and then it will appear twice.\n. No bug actually. You just need to run the update-scaleranks container first and then they appear.\n\n. Actually most of this stuff is not even required. https://github.com/mapbox/mbtiles-spec/blob/master/1.2/spec.md\nSo I suggest we remove the metadata fields:\n- filesize (If you have the MBTiles you know the size)\n- id ?? (don't know which id of what is meant)\nWe also set the version in the name in the future as done in #215 and since the version field is not official we can remove it as well.\nThe basename field is probably the basename of the vector tile file.\n. Pushing the extracts now, this just takes very very long but after that all metadata will be up to date (except a few things that are always derived from the planet source like attribution - this will only change once we release the new planet file).\n. Had a bit problem with RabbitMQ. It actually has good support for long running tasks but requires something called heartbeats to continously send heartbeats during a long running task to tell that you are still ok (and especially to keep the TCP connections open which can sometimes be closed by network devices).\nI now disabled heartbeats since it works just fine without them (tasks max go 10minutes) - RabbitMQ detects when clients crash when they close the connection channel.\nHad to fork the rabbitmq Docker image to be able to configure heartbeats https://github.com/osm2vectortiles/rabbitmq.\nWas a bit trouble but still think it is totally worth it out of the single reason that anyone is theoretically able to run the clustered setup without relying on a AWS account.\n. Yes any queue qualifies that supports:\n- Persistent messages\n- Long running tasks\n- Some sort of ACK mechanism to prevent message loss\n- Plays nice with Docker\nAnd at osm2vectortiles we don't need a crazy enterprise message queue. I just want something simple decoupled from AWS - beanstalkd might fit perfect there.\nYou told about a wrapper around different message queue backends you use internally?\n:+1: if you ever get around releasing it as OSS.\nPioritizing would in our case be kind of a cool feature - we don't require FIFO.\nFrom making osm2vectortiles updateable we also gain the capability to fix local errors like #87 easily by just scheduling areas as new jobs.\n. Took 46h for rendering the 1024 pyramid tasks for the 4/2/3 tile for a single machine.\nDon't remember whether that is fast or slow compared to previously.\n\n. Doing another import and export to see whether it is faster now especially because of #261 and #257.\nSome pyramid tasks that took hours should now be much faster.\nI created a tag v1.4.1 just for rendering so I know what version I am rendering with.\nI hope this doesn't screw up your cool GitHub release script - if it does I can delete the tag later on.\n. Doing another import/export cycle since we met the other performance problems #275 and since the mapping has changed again. The place labels in #275 where making the export really really slow.\nWant to switch to beanstalkd some time in the future and working on https://github.com/lukasmartinelli/cloudwrapper to create a pip installable Python module that I can use in export_remote. But at the moment other prios and RabbitMQ works well enough for testing now.\n. Just want to note it down somewhere. World import with imposm3 in diff mode! with v1.4.2 takes 14hrs including creating the GIST indizes and clustering on geohash.\nAnd then we have our extra scripts that create some tables and additional indizes, update the timestamp that take up 1-2 additional hours.\nCalculating changed tiles took under 1hr and resulted in 21'979'016 changed tiles.\nSeems that #257 made an impact.\n. Just for future reference.\nThe limiting factor on worker machines is actually CPU. We long believed that we need high-memory machines (like you expect for PostgreSQL to keep all indizes in memory). But it turns out that the limiting factor for PostgreSQL in our use case is CPU. On the HSR dev server with 40 cores PostgreSQL can serve many more workers (and using the same memory) by using 12 cores to serve 4 workers (each one using one core fully). \nThis is good to know because until know we use 50GB memory and 8 core servers as workers we might better use 50GB memory and 16 core servers.\n. Using the HSR server we can approximately process 100 x z8 pyramids per hour (expect another speedup after #306. This means using just this server we can be done with the 65k pyramid jobs in 650 hrs (approx. 4 weeks). To get this down to a week we probably need 4 x (12 core, 50GB) machines which is doable. This also means that there is a chance that a single server can keep up with the updates (which would be a huge win and saves money).\n. Will continue in this issue rendering the planet (or at least starting now and check how it performs with several machines). Apart from #304 avoid changing the mapping now. We can still do another import if absolutely necessary but the time to freeze it has come now.\nSteps now.\n- [x] Download world PBF ab520bbadd3e80c07cd7bc2b761b654a from 2016-04-27 to shared disk\n- [x] Mount shared disk on all workers\n- [x] Import world PBF on each worker using the latest mapping from master  and using the newest id mapping from #304 - this will take a day.\nPreviously I imported only on one machine and then shared the entire database. But just importing on each machine is a bit more practical.\n- [x] Start up the RabbitMQ server on the master, open network ports (also that the management portal of RabbitMQ can be opened for tracking progress).\n- [x] Schedule jobs for the quarter planet at first\n- [x] Ensure workers are able to connect to RabbitMQ and S3\n- [x] Run export-worker and scale them so that all cores on the workers are maxed out\n- [x] On the master run the merge-jobs component to continously merge the completed jobs back into one large PBF\n- [x] Monitor progress on the RabbitMQ mgmt portal\nAfter this works nicely I will then remove the jobs /results/result PBF again, apply the latest changes from the PRs #311 #306 #304 and issues #307, reschedule the jobs and run workers again for real.\nWe should then runn import-diffs already the first time to keep up with the changes since 2016-04-27.\n. Started rendering - let's see how fast 4 workers crunch through the 1024 tiles example I used for europe.\nPerhaps we can even switch to high CPU machines instead of normal ones. The 16 cores are maxed out but memory not (the first machine CPU is only 50% on PostGIS but that was just bad timing/anomaly).\n\n. > Using the HSR server we can approximately process 100 x z8 pyramids per hour (expect another speedup after #306. This means using just this server we can be done with the 65k pyramid jobs in 650 hrs (approx. 4 weeks).\nThis still holds true for the Klokantech infra, actually better now with 120 z8 pyramids per hour so 480 z8 pyramids per hour for the 4 workers. \nA z8 pyramid has 4^0+4^1+4^2+4^3+4^5+4^6+4^7= 21589 tiles.\nI scheduled all 4^8 pyramid for the jobs now.\nFound very few z8 queries in road layer that are slow. They take 3.1s - but they are very rare and only for zoom level 8 (z(2.18392e+06)=8).\nAnd the slowest part is actually the Bitmap Index Scan on the road_class index which I am not sure whether we can make this faster.\nsql\nSELECT osm_ids2mbid(MAX(osm_id), false) AS osm_id, ST_CollectionExtract(ST_Collect(geometry), 2) AS geometry,\n  road_type(road_class(type, NULL, NULL), type, NULL, NULL, NULL) AS type,\n  road_class(type, NULL, NULL) AS class, road_oneway(0) AS oneway, 'none' AS structure, NULL AS z_order\n  FROM (\n    SELECT * FROM road_z5\n    WHERE z(2.18392e+06) = 5\n    UNION ALL\n    SELECT * FROM road_z6toz7\n    WHERE z(2.18392e+06) BETWEEN 6 AND 7\n    UNION ALL\n    SELECT * FROM road_z8toz9\n    WHERE z(2.18392e+06) BETWEEN 8 AND 9\n    UNION ALL\n    SELECT * FROM road_z10\n    WHERE z(2.18392e+06) = 10\n  ) AS road_grouped_zoom_levels\n  WHERE geometry && ST_SetSRID('BOX3D(3911129.863295898 4537301.999008063,4072564.867034191 4698737.002746355)'::box3d, 3857)\n  GROUP BY type\n\n. > Seems to me impossible to speed up a Bitmap Index Scan.\nThanks for the feedback. On z8 the queries cover very big areas.\n\nThe only thing which stroke my eyes is that you are generating a 3D(?) bbox like this\n\nThe geometry && ST_SetSRID('BOX3D(3911129.863295898 4537301.999008063,4072564.867034191 4698737.002746355)'::box3d, 3857)  part is actually inserted by Mapnik https://github.com/mapnik/mapnik/wiki/PostGIS.\nWe write our queries like this geometry && !bbox! and Mapnik will replace the bbox placehooder !bbox!, so this is out of our control. \nBut this affects only query parsing speed.\n. > It seems to me that the query you cited above does not correspond with the query shown in the EXPLAIN ANALYZE image you cite too\nExactly. This is because there is also the view road_z8toz9 involved which looks like this and is using the road_class index.\nPreviously this was horribly slow until we made an index on road_class(type, service, access).\nNow the query planner must decide how he is using the GIST index and road_class index to filter out the rows that are not relevant. In the case above he thinks road_class index is better applying before GIST (from what I guess).\nsql\nCREATE OR REPLACE VIEW road_z8toz9 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n    FROM osm_road_geometry\n    WHERE road_class(type, service, access) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'major_rail');\n. Okay dealing with the #314 does not have a straightforward solution. Since these are all edge cases I deal for now with them by putting timed out tilelive calls to a failed-jobs queue and deal with them later on. https://github.com/osm2vectortiles/osm2vectortiles/commit/4010e0c1921e6534d01830add8690d746ac40e8c\nThis way it least the workers are not stalled with the same failing message over and over again.\n\n. > my optimization idea ( need more research , and for just the v2.x iterations )\nLike always very nice proposition for the future. Mapping is already frozen now so we can support diff updates so a possible implementation of this is quite far in the future.\nIt's nice to see that imposm3 can be pushed in this direction!\nAt the moment the biggest problem is not the SQL speed with the current hardware (but I guess as OSM grows the problem will come) but the issue with the tiles that take so long (perhaps but not confirmed due to #314).\n. Murphys law happened. The SQLite database where the tile jobs continuously get merged into by the merge-jobs component got corrupted.\nThe green ones are the tiles that I could not recover and therefore need to rerender.\nLuckily I know which tiles.\n\n. Rendering the lost tiles continues.\n\nAnother cool map below. This shows all z10 tiles that changed over the course of the last ten days and have been detected. Seems admin boundaries are often affected. Not sure what the reason for the big blocks of tiles that are now dirty in Russia are. Also nice to see the big mapping activity in Africa.\n\n. > for example modifying small part of France - Schweiz border : http://www.openstreetmap.org/changeset/39252252\nThank @ImreSamu for that example. Cool to see that we exactly have the same changes for admin boundaries as your example.\n\nData updates / Update frequency based on Mapbox specification:\nV7 #admin irregular schedule; every 2-6 months\nV6 #admin irregular schedule; every 2-6 months\nV5 #admin every few months\n\nI guess Mapbox relates to the Natural Earth borders here not the OSM boundaries. But not sure.\nWould be good to measure the impact of such a decision - e.g. how many tiles we save from rerendering.\nBelow are the tiles that took longer than 5 min to render. Now we are back to Friday with the lost tiles recovered. Now we do a second run with 20min rendering time upper limit and then can investigate the tiles that still won't complete.\nGreenland is really not happy perhaps due to the glaciers #314 (but still only a hypothesis).\nThe tiles that take long on mainland are probably just data intensive tiles.\n\nFirst I will just render the tiles below and then progress to north and south pole.\n\n. Okay @manuelroth and me found one cause for the missing tiles (that is not even a problem) in the SQLite db.\nThis affects tiles on land where there is no data at z8.\nFor example here in Mali as you zoom in you will see a village on z10. But at z8 there is no data (0 bytes) because there is nothing to show at that zoom level. Therefore the tile pyramid is marked as missing when looking in the SQLite file (but it is not missing - there is just no data at z8 as you zoom in you will see data at z10).\nThis never occured before because tl copy does store tiles with 0 bytes in the MBTiles file while tilelive-copy does not.\ntldr: Empty z8 tiles on mainland are not a problem we need to solve. The behaviour of having no tiles is completly ok. The tileserver will just serve a 404 until you hit a tile where there is data.\nThis doesn't affect us it just skews the tools that verify the SQLite file.\nThis still leaves open the tiles in the USA on Delaware where tiles are also missing.\nBut now we have an explanation for missing tiles on empty mainland (same is valid for southpole).\n\n. \nThe problem in this part of the US is that they are just very data heavy tiles due to the landuse polygons. The data is already sliced in OSM itself which is weird.\nSolution here is to give the rendering more time 30 to 40min to complete.\n\n\n. Problem of these tiles here is one huge national park.\nThis can probably be solved with the approach mentioned by @ImreSamu.\n\nST_Subdivide() http://blog.cartodb.com/subdivide-all-things/ from the blog: \"Subdividing big things can make map drawing faster too, but beware: once your polygons are subdivided you\u2019ll have turn off the polygon outlines to avoid showing the funny square boundaries in your rendered map.\"\n\nHowever our Postgis database doesn't support the GEOS version that supports ST_Subdivide which is a problem because of the diffs. Need to investigate here. Subdivide looks quite comfortable since we can then just create new tables for the very large polygons.\n\n\n. > I will be doing a similar import for the planet. What sort of times are you looking at on S3 with how many cores for postgres and workers? Is this on multiple small machines (like one for Postgres and many for processing) or one large? How's the scaling to large CPU machines?\nHappy to answer the question.\nThe more cores the better (especially for import). Rendering as well.\nMake sure PostGIS has enough memory to keep the indizes in memory (32GB+ better 50GB).\nImport planet with diff and index etc: 12+ hrs\nImport diffs of 10 days: 8+hrs\nRender planet:  From 1 minute up to 30 minutes for one z8 down to z14 subpyramid with a single worker, so at the absolute minimum 45days for single renderer. For 32 workers it takes us about a week. But it is skewed I the very few minority of the tiles (5%?) of the tiles take most of the time (60%?) of the time.\nBut you can scale the rendering process on the machine (4 workers and one PostGIS on 16x core machine - PostGIS is using 12 cores and each worker one).\nAnd then you can scale to multiple hosts to bring down the time.\nOne large one is of course easier to operate (since you don't need to copy around the database).\nIf you use multiple hosts I recommend copying around the database files.\nS3 is usually not the problem. But as seen above you can face some problems with data that you don't expect since on the entire world there are many possibilities for weird data :)\nWe hope to outline the interesting parts in the thesis as well.\n. Created most of the extracts now. Theoretically ready to publish the new documentation (and all extracts) in #324 and finally publish vector tiles v2.0.\n@klokan can you update the CDN with a new version v2.0 (we will rename mileston v1.6 into v2.0 since according to semantic versioning we break changes by changing the data format of our provided data). Size is now ~50GB - vacuuming the db saved 4GBs.\nLinks for planet.mbtiles:\n- https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v2.0/planet.mbtiles\nWe will provide updates for the planet.mbtiles in a few days already again (rendering the changes from the last two weeks). But CDN is important for us to display the maps on the osm2vectortiles home page (alternatively we can also run the tileserver-gl jsut serving from the MBTiles file - will also perform well).\n. What are you planning to do? Adapting the workflow to scale the process for your own vector tiles?\nOr rendering osm2vectortiles yourself?\n\nIs there a natural limit you find to scaling to more cores? Do you expect the rendering would scale to much larger machines with more cores? From your first comment, it sounds like a single worker on the same machine will saturate a postgres instance? But you mention 4 workers and one postgis on a 16 core machine?\n\nScale the export-worker until all CPUs are used and as long not too many SQL connections are open :) It does scale as you add more cores.\n\nI haven't been able to get more than one worker busy on my 4 core workstation, I ran \"docker-compose scale export-worker=2; docker-compose up export-worker\" but I get errors related to cannot connect to S3. I saw that mock-s3 was installed/started, rabbitmq was installed/started and two workers were started by docker, however it doesn't seem to use mock-s3. I assume there's a step I am missing!\n\nOkay this means you got through the entire process of scheduling jobs as described here \ud83d\ude01 ?\nbash\ndocker-compose run generate-jobs python generate_jobs.py pyramid 5 5 8 --job-zoom=9 > jobs.json\nexport AMQP_URI=amqp://osm:osm@localhost:5672/ # replace localhost with docker host\ncat jobs.json | pipecat publish jobs\nSorry we don't have many docs there. It should work with mock-s3 just checked.\nYou can also peek in the s3 container to check that. \ndocker exec -it osm2vectortiles_mock-s3_1 bash\nls /data/osm2vectortiles-jobs/\nLast route is always to pull newest master and execute make fast to ensure you got latest containers.\n. BTW. about updated tiles.\nJust pulled in the latest dirty tiles of the last 10 days and merged those tiles with the tiles of the previous 10 days. It turns out that the unique changed tiles of 20 days is ~\u00a020million tiles while unique changed tiles of 10 days has ~18 million tiles.\nThis confirms the hypothesis that few tiles change very often.\nAnd more timing infos. Generating city extracts (using Python multiprocess pool to scale) takes only about 1 hour. Country extracts seem to take much longer.\n. World is rendered. I am now already in rendering the 20million dirty tiles.\nPerhaps we need to pull out some issues that have accumulated here and occur  later on.\n. > It seams Mapbox does not show tram stations at all. I think the tram stations are a good orientation point we should keep them. We don't have a localrank currently, how is the localrank calculated for the highway shields?\nLet's show trams only at z14 at least.\nWe can leave the localrank for now. z14 already helps a lot imho.\nA more complicated localrank example for road labels.\nsql\nrank() OVER (\n                PARTITION BY LabelGrid(geometry, (CASE WHEN z(!scale_denominator!) >= 11\n                                                       THEN 300\n                                                       ELSE 200 \n                                                   END) * !pixel_width!)\n                ORDER BY road_localrank(type) ASC, round(MercLength(geometry)) DESC\n            ) AS localrank\n...\n...sql\nWHERE (z(!scale_denominator!) BETWEEN 8 AND 10 AND localrank < 2)\n             OR (z(!scale_denominator!) BETWEEN 11 AND 12 AND localrank < 5)\n             OR (z(!scale_denominator!) BETWEEN 13 AND 14)\nSimpler example.\nsql\n        rank() OVER (PARTITION BY LabelGrid(geometry, 200 * !pixel_width!)\n                     ORDER BY scalerank ASC NULLS LAST,\n                              population DESC NULLS LAST\n        ) AS localrank\n. > Let's show trams only at z14 at least.\nThis is already done in rail_station_label.sql I see.\nFor z12toz13 only class rail is shown.\n. Is this even possible to solve @manuelroth? The current status is that Mapbox somehow does have different data for the \"green\" areas than we do right?\n. Great work @manuelroth!!!\n\nThe visual result is almost identical(I only imported the data of latvia to test)\n\nAwesome! This look really close!!\n. Buumm saves at least 308 lines of SQL inside the layers.\nBut now the generate_sql.py file has gotten complidated and ugly. \nWill try to clean it up and move the code generation over to dynamic SQL (like in https://github.com/osm2vectortiles/osm2vectortiles/commit/892cb323decbc994d71639b718f0178b22ab44d3) and have the generate_sql.py just create a static view.\nLooks like this. Quite readable imho.\n``` sql\nCREATE OR REPLACE FUNCTION update_timestamp(ts timestamp) RETURNS VOID AS $$\nDECLARE\n    t osm_tables%ROWTYPE;\nBEGIN\n    FOR t IN SELECT * FROM osm_tables\n    LOOP\n        EXECUTE format('UPDATE %I SET timestamp=%L WHERE timestamp IS NULL;',\n            t.table_name, ts\n        );\n    END LOOP;\nEND;\n$$ language plpgsql\n``\n. This is how the generatedchanged_tilesfunction looks like. The buffer, min_zoom and max_zoom\nare taken from the YAML file. Thechanged_tiles_tablefunction will then query all tiles for that table (usingoverlapping_tiles` with the specified buffer value) inside the valid min_zoom - max_zoom range.\nThe nice thing now is that we have a uniform approach for both deleted and inserted tiles. Correctness should still be the same - will need to check whether it results in more tiles to rerender.\n``` sql\nCREATE OR REPLACE FUNCTION changed_tiles(ts timestamp)\nRETURNS TABLE (x INTEGER, y INTEGER, z INTEGER) AS $$\nBEGIN\n    RETURN QUERY (\n        SELECT * FROM changed_tiles_table('osm_mountain_peak_point', ts, 64, 12, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_place_geometry', ts, 128, 3, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_water_linestring', ts, 4, 8, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_poi_point', ts, 128, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_barrier_linestring', ts, 4, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_admin_linestring', ts, 4, 2, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_barrier_polygon', ts, 4, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_poi_polygon', ts, 128, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_housenumber_point', ts, 64, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_landuse_polygon', ts, 4, 5, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_airport_polygon', ts, 64, 9, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_rail_station_point', ts, 64, 5, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_building_polygon', ts, 2, 13, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_housenumber_polygon', ts, 64, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_aero_polygon', ts, 4, 9, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_airport_point', ts, 64, 9, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_road_geometry', ts, 8, 5, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_aero_linestring', ts, 4, 9, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_water_polygon', ts, 64, 5, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_mountain_peak_point_delete', ts, 64, 12, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_place_geometry_delete', ts, 128, 3, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_water_linestring_delete', ts, 4, 8, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_poi_point_delete', ts, 128, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_barrier_linestring_delete', ts, 4, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_admin_linestring_delete', ts, 4, 2, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_barrier_polygon_delete', ts, 4, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_poi_polygon_delete', ts, 128, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_housenumber_point_delete', ts, 64, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_landuse_polygon_delete', ts, 4, 5, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_airport_polygon_delete', ts, 64, 9, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_rail_station_point_delete', ts, 64, 5, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_building_polygon_delete', ts, 2, 13, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_housenumber_polygon_delete', ts, 64, 14, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_aero_polygon_delete', ts, 4, 9, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_airport_point_delete', ts, 64, 9, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_road_geometry_delete', ts, 8, 5, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_aero_linestring_delete', ts, 4, 9, 14)\n        UNION\n        SELECT * FROM changed_tiles_table('osm_water_polygon_delete', ts, 64, 5, 14)\n    );\nEND;\n$$ language plpgsql;\n```\n. You're too fast @ImreSamu  ;)\n\nmy proposed solution: ( not tested yet! )\n\nExactly that is what we had before with the zoom level views. There we really only matched what really was in the tiles. With the delete and update tracking we could no longer do this this nice.\n\nThe approach is now that geometries that are in the DB and have changed will make the tile dirty (buffers are respected).\n\nI would love having the name <> '' filter already in imposm3. I can merge your patch into https://github.com/osm2vectortiles/imposm3 (we already have our custom imposm fork - takes a long time until imposm3 team merges changes back upstream https://github.com/omniscale/imposm3/pull/94)\nReally cool idea with https://gist.github.com/ImreSamu/fb1cf6f78226aefb16b671ebf071afeb#file-sql_output-txt. This shows exactly what is too much in the tables.\nSadly I just removed the layer views because we no longer need them but I should revert that just for the sake of this script. I'll run it on the server with world import.\nI can then use the script to check what features are additionally introduced.\nAlthough careful - many more features doesn't necessarily mean many more dirty tiles in the grand scale.\nBtw. do you know what use_single_id_space in imposm3 means?\nIs this the part that turns relations into negative osm ids?\nIt seems in the osm_admin_linestring we use only 7% of the imported data.\nAnd POI and waterway we could certainly improve as well.\nCool that we exactly have 100% for some layers.\n. We should move this discussion to another issue (like \"Remove unused data in mapping\"). \n. Great insights - so we leave it like it is now. Didn't find any docs on it.\n\nmain purpose is avoid conflicts of OSM_ID-s ; see RelIdOffset info:\n. Good - especially since it affects the mapping which we will need to freeze soon.\n\n. Okay our imposm3 fork now supports the advanced exclude tags.\nSo we can try to use filters: exclude_tags: - [ \"name\", \"nil\" ].\n. This is the report for the entire world (takes 1.5 hrs to run).\nPretty similar to the extracts actually. Also cool to see a feature count on each table!\nBuildings, housenumbers and roads are the largest tables.\n\n| tid | all_features | used_features | osmlist | layerlist | percent |\n| --- | --- | --- | --- | --- | --- |\n| osm_admin_linestring | 902065 | 66023 | {osm_admin_linestring} | {admin_layer} | 7.32 |\n| osm_aero_ | 189458 | 189458 | {osm_aero_linestring,osm_aero_polygon} | {aeroway_layer} | 100.00 |\n| osm_airport_ | 43661 | 43661 | {osm_airport_point,osm_airport_polygon} | {airport_label_layer} | 100.00 |\n| osm_barrier_ | 4824394 | 4824394 | {osm_barrier_linestring,osm_barrier_polygon} | {barrier_line_layer} | 100.00 |\n| osm_building_ | 178777539 | 178777539 | {osm_building_polygon_gen0,osm_building_polygon} | {building_layer} | 100.00 |\n| osm_housenumber_ | 60304686 | 60304686 | {osm_housenumber_point,osm_housenumber_polygon} | {housenum_label_layer} | 100.00 |\n| osm_landuse_ | 24037401 | 24037401 | {osm_landuse_polygon,osm_landuse_polygon_gen0,osm_landuse_polygon_gen1} | {landuse_overlay_layer,landuse_layer} | 100.00 |\n| osm_mountain_peak_point | 409599 | 409599 | {osm_mountain_peak_point} | {mountain_peak_label_layer} | 100.00 |\n| osm_place_ | 5561449 | 2458275 | {osm_place_geometry} | {place_label_layer} | 44.20 |\n| osm_poi_ | 15699606 | 7937380 | {osm_poi_point,osm_poi_polygon} | {poi_label_layer} | 50.56 |\n| osm_rail_station_point | 177970 | 177970 | {osm_rail_station_point} | {rail_station_label_layer} | 100.00 |\n| osm_road_geometry | 94030374 | 94030374 | {osm_road_geometry} | {road_layer,road_label_layer} | 100.00 |\n| osm_water_linestring | 11624368 | 10158677 | {osm_water_linestring} | {waterway_layer,waterway_label_layer} | 87.39 |\n| osm_water_polygon_* | 7888542 | 7888542 | {osm_water_polygon_gen1,osm_water_polygon} | {water_layer,water_label_layer} | 100.00 |\n. This imposm3 changes are so good @ImreSamu. Thanks. Hope they merge it upstream soon (PR take really long for imposm3 sadly).\nI now do the name filtering and admin_level_filtering (like you suggested in your commit).\nAnd that already helps a lot. Still need to find out what the reason for the many unused waterway_linestring features is. \nBefore:\n| tid | all_features | used_features | osmlist | layerlist | percent |\n| --- | --- | --- | --- | --- | --- |\n| osm_admin_linestring | 8896 | 1713 | {osm_admin_linestring} | {admin_layer} | 19.26 |\n| osm_aero_ | 927 | 927 | {osm_aero_linestring,osm_aero_polygon} | {aeroway_layer} | 100.00 |\n| osm_airport_ | 83 | 83 | {osm_airport_point,osm_airport_polygon} | {airport_label_layer} | 100.00 |\n| osm_barrier_ | 42754 | 42754 | {osm_barrier_linestring,osm_barrier_polygon} | {barrier_line_layer} | 100.00 |\n| osm_building_ | 1854655 | 1854655 | {osm_building_polygon_gen0,osm_building_polygon} | {building_layer} | 100.00 |\n| osm_housenumber_ | 586469 | 586469 | {osm_housenumber_point,osm_housenumber_polygon} | {housenum_label_layer} | 100.00 |\n| osm_landuse_ | 214806 | 214806 | {osm_landuse_polygon,osm_landuse_polygon_gen0,osm_landuse_polygon_gen1} | {landuse_overlay_layer,landuse_layer} | 100.00 |\n| osm_mountain_peak_point | 3742 | 3742 | {osm_mountain_peak_point} | {mountain_peak_label_layer} | 100.00 |\n| osm_place_ | 24552 | 12364 | {osm_place_geometry} | {place_label_layer} | 50.36 |\n| osm_poi_ | 183883 | 97283 | {osm_poi_point,osm_poi_polygon} | {poi_label_layer} | 52.90 |\n| osm_rail_station_point | 2805 | 2805 | {osm_rail_station_point} | {rail_station_label_layer} | 100.00 |\n| osm_road_geometry | 940892 | 940892 | {osm_road_geometry} | {road_layer,road_label_layer} | 100.00 |\n| osm_water_linestring | 53611 | 39837 | {osm_water_linestring} | {waterway_layer,waterway_label_layer} | 74.31 |\n| osm_water_polygon_* | 23652 | 23652 | {osm_water_polygon_gen1,osm_water_polygon} | {water_layer,water_label_layer} | 100.00 |\nAfter:\n| tid | all_features | used_features | osmlist | layerlist | percent |\n| --- | --- | --- | --- | --- | --- |\n| osm_admin_linestring | 1716 | 1716 | {osm_admin_linestring} | {admin_layer} | 100.00 |\n| osm_aero_ | 936 | 936 | {osm_aero_linestring,osm_aero_polygon} | {aeroway_layer} | 100.00 |\n| osm_airport_ | 81 | 81 | {osm_airport_point,osm_airport_polygon} | {airport_label_layer} | 100.00 |\n| osm_barrier_ | 44433 | 44433 | {osm_barrier_linestring,osm_barrier_polygon} | {barrier_line_layer} | 100.00 |\n| osm_building_ | 1903832 | 1903832 | {osm_building_polygon_gen0,osm_building_polygon} | {building_layer} | 100.00 |\n| osm_housenumber_ | 598921 | 598921 | {osm_housenumber_point,osm_housenumber_polygon} | {housenum_label_layer} | 100.00 |\n| osm_landuse_ | 218998 | 218998 | {osm_landuse_polygon,osm_landuse_polygon_gen0,osm_landuse_polygon_gen1} | {landuse_overlay_layer,landuse_layer} | 100.00 |\n| osm_mountain_peak_point | 3850 | 3850 | {osm_mountain_peak_point} | {mountain_peak_label_layer} | 100.00 |\n| osm_place_ | 12382 | 12382 | {osm_place_geometry} | {place_label_layer} | 100.00 |\n| osm_poi_ | 98304 | 98304 | {osm_poi_point,osm_poi_polygon} | {poi_label_layer} | 100.00 |\n| osm_rail_station_point | 2796 | 2796 | {osm_rail_station_point} | {rail_station_label_layer} | 100.00 |\n| osm_road_geometry | 954961 | 954961 | {osm_road_geometry} | {road_layer,road_label_layer} | 100.00 |\n| osm_water_linestring | 54837 | 40971 | {osm_water_linestring} | {waterway_layer,waterway_label_layer} | 74.71 |\n| osm_water_polygon_* | 24237 | 24237 | {osm_water_polygon_gen1,osm_water_polygon} | {water_layer,water_label_layer} | 100.00 |\n. @manuelroth The reason for the unused features in osm_water_linestring is that we map drain and ditch but do not use them in the layers (we exclude them).\nIs this on purpose? I suppose ditches and drains are shown at the highest zoom level?\n. > @manuelroth The reason for the unused features in osm_water_linestring is that we map drain and ditch but do not use them in the layers (we exclude them).\n\nIs this on purpose? I suppose ditches and drains are shown at the highest zoom level?\n\nAdded them in commit https://github.com/osm2vectortiles/osm2vectortiles/commit/1a4546274b3301107d9bcfb01c5afe5544f670e5. Mapbox shows them in waterway.\n. Yes now we have 100% usage in all tables. This is huge.\nWe now have only the values in the database that we really use in the vector tiles!\nNo space is wasted and that makes our dirty tile model much better because now we can operate on the tables #232 and not the layer views.\n| tid | all_features | used_features | osmlist | layerlist | percent |\n| --- | --- | --- | --- | --- | --- |\n| osm_admin_linestring | 1716 | 1716 | {osm_admin_linestring} | {admin_layer} | 100.00 |\n| osm_aero_ | 936 | 936 | {osm_aero_linestring,osm_aero_polygon} | {aeroway_layer} | 100.00 |\n| osm_airport_ | 81 | 81 | {osm_airport_point,osm_airport_polygon} | {airport_label_layer} | 100.00 |\n| osm_barrier_ | 44433 | 44433 | {osm_barrier_linestring,osm_barrier_polygon} | {barrier_line_layer} | 100.00 |\n| osm_building_ | 1903832 | 1903832 | {osm_building_polygon_gen0,osm_building_polygon} | {building_layer} | 100.00 |\n| osm_housenumber_ | 598921 | 598921 | {osm_housenumber_point,osm_housenumber_polygon} | {housenum_label_layer} | 100.00 |\n| osm_landuse_ | 218998 | 218998 | {osm_landuse_polygon,osm_landuse_polygon_gen0,osm_landuse_polygon_gen1} | {landuse_overlay_layer,landuse_layer} | 100.00 |\n| osm_mountain_peak_point | 3850 | 3850 | {osm_mountain_peak_point} | {mountain_peak_label_layer} | 100.00 |\n| osm_place_ | 12382 | 12382 | {osm_place_geometry} | {place_label_layer} | 100.00 |\n| osm_poi_ | 98304 | 98304 | {osm_poi_point,osm_poi_polygon} | {poi_label_layer} | 100.00 |\n| osm_rail_station_point | 2796 | 2796 | {osm_rail_station_point} | {rail_station_label_layer} | 100.00 |\n| osm_road_geometry | 954961 | 954961 | {osm_road_geometry} | {road_layer,road_label_layer} | 100.00 |\n| osm_water_linestring | 54837 | 54837 | {osm_water_linestring} | {waterway_layer,waterway_label_layer} | 100.00 |\n| osm_water_polygon_* | 24237 | 24237 | {osm_water_polygon_gen1,osm_water_polygon} | {water_layer,water_label_layer} | 100.00 |\n. Great progress on imposm3. Adding more filtering options will help more people than just us.\n\nNot critical, but I have created an extended filtering version , with the following new experimental syntax :\n\nJust my 2 cents. I would have expected that the filters work more like the mapping.\nThe include_tags will be included if it matches any of the criterias inside the include_tags not all of them.\nfilters:\n   exclude_tags\n   - [ key, val]                       // AND key != val\n   - [ key, __nil__]                   // AND key IS NOT NULL\n   - [ key, __any__]                   // AND key IS NULL\n   - [ key, val1,val2]                 // AND key not in ( val1,val2 )\n   - [ key, val1,val2,val3, ... valn]  // AND key not in ( val1,val2,val3, ... valn)\n   include_tags\n   - [ key, val]                       // OR key = val\n   - [ key, __nil__]                   // OR key IS NULL\n   - [ key, __any__]                   // OR key IS NOT NULL\n   - [ key, val1,val2]                 // OR key in ( val1, val2 )\n   - [ key, val1,val2,val3, ... valn]  // OR key in ( val1,val2,val3, ... valn)\n. > this is an easy hack, and the imposm3 algorithm in inside logical AND - and too big work to change that to OR\nSure makes sense.\n\nWhat about renaming include_tags to more precise name like:\n\nVery difficult thing to find a good name, I don't have a better one :/\nexclude_negated_tags is not perfect but ok for me.\n. Can you @ImreSamu just commit the SQL script to the folder /tools/mapping-qa-report (or something like this) since it is your code?\nhttps://gist.github.com/ImreSamu/fb1cf6f78226aefb16b671ebf071afeb#file-sql_output-txt\nI will then hack the bash script, Docker container and docker-compose definition around it. This will help.\n. These PRs constantly breaks because master changes since this morning :weary: . I will now just merge them into master and fix those integration issues there because they were green before other PRs got in.\n. Working on the diagram in Google Drive. I could generate them (last time I did but they usually are to ugly to use in a thesis).\nBarriers\nNothing special here. Except it is one of the only layers that doesn't have a label laayer.\n\nRoad\nWe do need the is_ford, construction, tracktype, service, access all for the type and class or structure values.\n\nWater and Waterways\nWow there goes a lot of thought into making water appear.\n- [x] Perhaps we can use the Natural Earth and OSM Water tables (that are not from imposm) in the same zoom level views (create new ones)? What do you think @manuelroth? Now we pull data in the tm2source file and in the zoom level views.\n\n. > Won't add the new views to the layer_* view as this view is used for the changed_tile process.\nChanged tile process does no longer work with the zoom level views but works with the tables directly since last PR.\nYou could safely extend the existing views.\n. I did remove them but readded them because we need them for the mapping-qa\nreport.\nOn Apr 21, 2016 6:22 PM, \"Manuel Roth\" notifications@github.com wrote:\n\nWon't add the new views to the layer_* view as this view is used for the\nchanged_tile process.\nChanged tile process does no longer work with the zoom level views but\nworks with the tables directly since last PR.\nYou could safely extend the existing views.\nOhh right, so we could actually remove the layer_* views?- Because these\nwere only needed for the changed_tile process\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/265#issuecomment-212993875\n. After #268 the water diagram looks like this.\n\n\n. ## Admin\nAdmin uses a complex combination of Natural Earth and OSM in order to give the best possible borders per zoom level.\n\nHousing\nWe once had the idea whether we could put housenumber_polygon and building_polygon into one table. But because we also have a point table it easier for the understanding to have two separate tables for housenumbers.\n\nPlaces\nWe still have some ranking problems. But I think we got all the fields that are relevant. Problem there is the scalerank matching.\n\nLanduse\n\n- [ ] landuse_overlay missing\nPOI\n\nMountain Peak Label\n\nRail Station Label\n\n. Okay looks promising @klokan that we can get under 60GB.\nA bit weird that the change is so different from extract to extract. But perhaps because tweaked so much at the mapping. \n| extract | v1.0 (MB) | v1.5 (MB) | change (%) |\n| --- | --- | --- | --- |\n| belgium | 943 | 696 | -26 |\n| czech_republic | 1107 | 904 | -18 |\n| denmark | 543 | 428 | -21 |\n| switzerland | 649 | 504 | -22 |\n| zurich | 34 | 31 | -10 |\n| paris | 144 | 106 | -26 |\n| berlin | 90 | 71 | -21 |\n. > Did you count the tiles on zoom 1-7 while comparing the extracts?\nThe lower zoom levels are merged into the v1.0 and v1.5 extracts.\n\nBTW how is it with the size of individual tiles (the 500K limit for upload to MapBox.com).\nIs it better now?\n\nHmm not really. Every extract has like 5-7 tiles that are too big (500-700kB).\nMost of them are on z5 and z6\nThis is kind of nasty for styling - this means people have to purge away the too large tiles for styling in Mapbox Studio.\n``` bash\npurge tiles larger than 500kb\nmboptimize size  -s 500000\n```\n. > The mapping-qa doesn't work anymore for the layer water and admin, because the zoom level views are now mixed with natural earth and openstreetmap data. Not sure what to do. We can remove them from mapping-qa or reference the tables directly in the layer view.\nJust checked out the features/refactor-water-admin-query branch. I get a mapping report and still 100% (even though there is osm_id 0..) - but had to drop the db.\n. I somehow don't understand it sorry :grin: \nWhat is wrong with https://github.com/osm2vectortiles/osm2vectortiles/pull/268/commits/5d884891d6983144265aaac68def64d5cf0eaf67?\nThe qa report does match the osm ids of all the layers (aka the vector tile content) and what is mapped in imposm. Now we have 1 feature too much in the layers - but this is correct. This is the unmapped osm id 0 which all external data has.\n| tid | db_features | vt_features | percent | tables | layers |\n| --- | --- | --- | --- | --- | --- |\n| osm_admin_linestring | 1716 | 1717 | 99.94 | {osm_admin_linestring} | {admin_layer} |\n| osm_aero_ | 936 | 936 | 100.00 | {osm_aero_linestring,osm_aero_polygon} | {aeroway_layer} |\n| osm_airport_ | 81 | 81 | 100.00 | {osm_airport_point,osm_airport_polygon} | {airport_label_layer} |\n| osm_barrier_ | 44433 | 44433 | 100.00 | {osm_barrier_linestring,osm_barrier_polygon} | {barrier_line_layer} |\n| osm_building_ | 1903832 | 1903832 | 100.00 | {osm_building_polygon_gen0,osm_building_polygon} | {building_layer} |\n| osm_housenumber_ | 598921 | 598921 | 100.00 | {osm_housenumber_point,osm_housenumber_polygon} | {housenum_label_layer} |\n| osm_landuse_ | 218998 | 218998 | 100.00 | {osm_landuse_polygon,osm_landuse_polygon_gen0,osm_landuse_polygon_gen1} | {landuse_overlay_layer,landuse_layer} |\n| osm_mountain_peak_point | 3850 | 3850 | 100.00 | {osm_mountain_peak_point} | {mountain_peak_label_layer} |\n| osm_place_ | 12382 | 12382 | 100.00 | {osm_place_geometry} | {place_label_layer} |\n| osm_poi_ | 98304 | 98304 | 100.00 | {osm_poi_point,osm_poi_polygon} | {poi_label_layer} |\n| osm_rail_station_point | 2796 | 2796 | 100.00 | {osm_rail_station_point} | {rail_station_label_layer} |\n| osm_road_geometry | 949125 | 949125 | 100.00 | {osm_road_geometry} | {road_layer,road_label_layer} |\n| osm_water_linestring | 54837 | 54837 | 100.00 | {osm_water_linestring} | {waterway_layer,waterway_label_layer} |\n| osm_water_polygon_* | 24237 | 24238 | 100.00 | {osm_water_polygon_gen1,osm_water_polygon} | {water_layer,water_label_layer} |\n. > That's alright for me, just thought if the purpose of the mapping-qa is to compare the mapped features with features in vector tiles, the external data shouldn't be counted.\nDone with commit https://github.com/osm2vectortiles/osm2vectortiles/commit/25ed82707986bb65bd4d9c621151d0d8135922af. This way osm_id 0 aka external data is not counted.\n. > @lukasmartinelli have you done a world import recently?\nI can execute this tomorrow. Latest import is using v1.4.1 mapping.\nBut I merge this now and then use this for the dev.vectortiles.osm2vectortiles.org. Also need to test my table creation script as well. My guess is it can take up to a hour...\nHmm how do we handle this table (and my water labels table as well) with diff updates?\nWe need to regenerate them.\n\n@lukasmartinelli Are both of this indexes needed?\n\nThe gist index is absolutely essential. The geohash index is only to cluster the data together within a tile.\n. > Used the tile-inspector of klokan for the analysis, was very helpful. Would love to do some analysis with the data of the entire world to detect the issues which create the >500 kbyte tiles.\nYou can already test this with Switzerland for example.\nThere are some extracts you can already test out now.\nWith mbtoolbox you can find out the too big tiles.\nhttps://github.com/lukasmartinelli/mbtoolbox\nbash\nmbverify size <mbtiles_file> -s 500000\n- https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.5/extracts/zurich.mbtiles\n- https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.5/extracts/paris.mbtiles\n- https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.5/extracts/switzerland.mbtiles\n- https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v1.5/extracts/czech_republic.mbtiles\n. Whooop astonishing. Only 23470 features are inserted.\nCreating the table takes only 123s. The GIST index 300ms. The geohash index takes 735ms.\nIs there something wrong or is ist just so fast.\n. http://dev.vectortiles.osm2vectortiles.org/#5.02/45.804/3.189\n\n. Btw. Mapbox does something really weird on the south pole area.\nBut I think we are the correct ones.\n\n. > I just pushed a commit to master, I forgot to add type forest to the clustered landuse table. Now it should look a bit greener.\nhttp://dev.vectortiles.osm2vectortiles.org/#5.32/47.588/2.787\nThats good enough for me. Much much better than before \ud83d\udc4d \n\n. > Missing housenum_label layer: I tried to style the layer housenum_label in mapbox studio, couldn't find it there. Either they removed it by intention and forgot to update the documentation or it is a mistake on their side. We should definitely consider removing it too, a lot of space could be saved.\nJust checked housenum label is still there but it appears only in z16. Mapbox has additional z15 and z16 where they can fit stuff in (that's why there are not many buildings in z14)\nhttps://www.mapbox.com/vector-tiles/mapbox-streets-v7/#housenum_label. \n\n. > To combine the roads/buildings to multiple bigger multilinestrings/multipolygons I could apply the same technique as for the landuse polygons. I will make a pull request with the implementation and investigate how this impacts the tile size.\nI think at least in z14 we want the real building polygons not an aggregation of them.\nAlso to make them clickable, interact with them.\nPerhaps for z13 we can do that (and then just set underground to false for the entire multipolygon).\nIf you just need to create one polygon per tile you can use ST_Collect only in the tm2source file (perhaps we don't need a separate table there).\nFor roads at z5, z6 it is okay to have just one multilinestring if it really does save space. Otherwise is just more complex. And if we do this we can also just st_collect all roads (since it is only motorways) and then set oneway=false and structure=none because at this low zoom level structure and oneway doesn't matter.\n\nAnd this must save a lot of space, otherwise they wouldn't do this. However I don't understand yet way this saves so much space.\n\nAre the vector tiles you compared from Mapbox actually smaller?\n. > We now have proof that combining many small geometries into mulitple bigger geometries does reduce the size of the vector tiles drastically. The data in the following table was collected from the same tile (6/22/33):\nWell this look so promising that it is probably worth doing it for all objects that don't have unique metadata or where we can group on reasonable number of attributes, so let's try this on roads, buildings, landuse, barrier_line?\nWhat you loose as well is the osm_id information (perhaps Mapbox does no longer include it as attribute because of this) but for this great benefit of size it is worth it.\nJust some worry as a side note, if we create the table before everything we now have multiple very large multipolygons in the table. Now for higher zoom levels each tile will match this geometry and then Mapnik will need to cut out the stuff in the geometry that does fit in the vector tile e.g. it will throw away a lot of data and put more strain on the PostgreSQL connection. But don't know whether that makes it slower.\nBTW. we have to test whether the queries got slower with the clustered tables. I just had some z5-z6 tile jobs that never finish - could perhaps be the landusage. Didn't look closer at it.\nI play around whether i can do the collection directly in the vector tile query because it also doesn't require updating the tables.\n\nThe table was created with the same technique as for the landuse polygons:\n\nTable creation is still reasonably fast (10 minutes).\n. > This would be great, I just worry that this makes the queries very slow. Because of this I created this a separate table after the import process.\nIn https://github.com/lukasmartinelli/osm-noise-pollution/blob/master/src/vector-datasource/data.yml\nI use simply st_collect to group all results together and make a GEOMETRYCOLLECTION. And I do this for all roads on the planet on my machine in less than an hour. So could be that is still fast enough.\nI know also understand why the tile size was so small there.. haha wondered back then why the size is so small.\nI want to try something similar here. If we just use st_collect and grouped by e.g. type we get only one geometrycollection per vector tile per type. And st_collect is really fast.\nsql\n SELECT st_collect(st_buffer(geometry, 30)) AS geometry, 1 AS noise_level\nFROM osm_railway\nWHERE geometry && !bbox!\nUNION ALL\nSELECT st_collect(st_buffer(geometry, 60)) AS geometry, 2 AS noise_level\nFROM osm_railway\nWHERE geometry && !bbox!\n. Whether you combine the building polygons or not does make a styling difference as you can see here.\n\nThe ST_CollectionExtract(unnest(ST_ClusterWithin(geometry, 5000)), 2) query doesn't produce the desired result: for Switzerland each row in the clustered table contains the entire Switzerland again.\nReplaced it with ST_Collect in the branch.\n\nTried out ST_Collect for roads, buildings and landusage. It get's slower for huge amounts of data like on z5 or z6. On z13, z14 (for buildings the queries are not remarkably slower).\nUPDATE:\nst_collect completely destroys performance on the world server. Just broke everything \ud83d\ude48 \nProbably need to revert that.\n. Render Switzerland again with geometry collections.  When we measure we cannot measure only one PBF we need to measure the entire rendered MBTiles file.\n| extract | With buildings,roads,landuse clustered | With roads,landuse clustered |\n| --- | --- | --- |\n| switzerland | 475MB | 454MB |\nActually for buildings it seems that aggregating the buildings does increase the filesize.\nWe need to measure again whether it really helps to aggregate.\nFor landuse and roads I would need to test a different extract since only the low zoom levels are affected.\n. > @lukasmartinelli did you have europa imported while doing the extracts?\nYep used europe. Therefore I have data for the full bbox.\n\nThe clustering does not have a big impact on the overall size of the mbtile file, but it reduces the size of individual big tiles (for example 6/33/22 went from 526 kbytes down to 161 kbytes). I would like to keep the clustering just to reach the goal of not having any tiles > 500 kbytes.\n\nDoes mbverify size -s 500000 show any tiles above 500KB now?\nAnd does using ST_CollectionExtract over ST_Collect yield better results?\n. > Oh wait, I can do that myself. Germany should be possible on my server.\n:grin:  If you start the import now :)\n\nmbverify does not show any tiles above 500KB with the clustered extracts.\n\nI am not the biggest fan of grouping the stuff together (just because we loose the osm id and make it more complicated) but the no tiles above 500KB argument is just very very important and trumps everything. :+1: \nWe need to cluster the buildings to get z14 under 500KB I guess.\n\n@lukasmartinelli would it be possible for you to create a bigger extract (maybe germany or france) and verify the size with/without clustering and also verify if the >500KB tiles disappear. With this we could cross check, if my hypothesis is correct for a bigger extract.\n\nI will run Europe anyway. Gladly these changes are in the tm2source only.\n. Really nice viz showing how the Protobuf drawing commands work.\nhttps://www.mapbox.com/vector-tiles/specification/\nSo perhaps since it is encoded as one geometry we save a lot of Move commands and therefore smaller file size?\n. > Came to the same conclusion as before, without clustering there are some tiles which are bigger than 500KB and with clustering these get smaller but it has no impact on the overall size of the mbtiles.\nThanks for the report!!\n\nI think we should stay with clustering for landuse and roads. Not sure if we need clustering for buildings(for germany it is not needed, as the >500KB tiles are on lower zoom levels). I will do a last test with london to find out whether there are tiles >500KB without clustering the buildings.\n\nI like this solution. Because we only loose the OSM id on low zoom levels but in the highest zoom level 14 the data is identifiable by OSM id.\nLet's do it like this.\n. Good stuff, you can still get the geometries if you want by joining the osm_id of the feature layers. So we don't loose anything.\n. Good.\nOSM ID is no longer really correct if we do clustering though anyway. But that is not a problem of this PR.\n. > Great work @lukasmartinelli.\nAhh no. Will break the build. Just found a bug. Will fix it in master.\nAlways bad if you can't trust travis. sorry.\n. Such a great report @ImreSamu!\n\n\nfor NO osm_id collision ( or not use type_mappings )\n\nWe use the type_mappings primarily for OSM roads because otherwise we had for example for plazas linestrings and polygons twice. When we put them into the same table with type_mappings the first geometry type in the type_mappings matches first which is the behavior we want.\nFor osm_place it actually not really necessary.\n\nMy suggestion: *use_single_id_space: true *\n\nIf we use the single id space and still want to use the Mapbox OSM ID format in the vector tiles\nwe could \"reproroject\" the imposm3 OSM IDs back into normal OSM ID format and then apply the Mapbox format?\nOr what about using the imposm3 id as ID for the vector tiles? There will be compression drawbacks?\nThis would be kind of the most comfortable option (even though we have to throw away some code) because sometimes then we don't have to worry whether the geometry is polygon, point or linestring when we output the OSM ID (which would help because we now start having tables with points that originated from polygons).\n. Stating the things below mostly for myself for future reference.\n\nSo if I understand it correctly - the use_single_id_space is an internal imposm3 implementation of the what Mapbox OSM ID does - just done differently.\n\nEveryone needs to solve the problem that each OSM object type has a separate ID space (bad decision imho):\n- Relation\n- Way\n- Node\nAnd then again imposm builds real PostGIS geometries out of this. And so in the end you have the following combinations that still need a unique ID.\n- Polygon\n- Way\n- Node\n- Polygon (from Relation)\n- Way (from Relation)\nImposm3 solves this by subtracting a huge number for all relations while Mapbox solves this with their (id * 10) + {0..5}. \n\nAccording to my understanding, both are convertable there and back and equal in semantic.\n\nGiven you now the geometry type of an object.\n\nImposm3 process the diffs correctly only if used with use_single_id_space.\n\nYes because we are using type_mappings for places and roads where we have both linestrings/polygons and points/polygons. If we would only use the normal mapping this wouldn't occur as different geometry types are then never in the same table.\nFor the use case of highlighting a object on a vector tile map.\nLet's say we want to highlight a distinct building polygon (from address) we know a building polygon can either be:\n- Polygon\n- Polygon (from Relation)\nSo we need to query the Mapbox API for features with the osm id  (osm_id * 10) + 2 and (osm_id * 1) + 4\n. > @lukasmartinelli what do you think about doing this optimization for poi_label, airport_label and housenum_label(all other layer which use topoint-function) as well?- The polygon geometry is also not needed for these layers.\nI think place_label was just a special case. The drawback of doing it for other layers is that a SQL UPDATE is slow on our dataset and also requires reclustering after that.\nThe special thing about place label is that it occurs on all zoom levels and has large buffer.\nThis means that a place_label can be rendered e.g. from z6 down to z14 (8x times) and then again it is perhaps in the buffer of another tiles as well (+ 8xtimes) so the topoint might be called 16x times and therefore it makes sense to amortize this cost already after import once.\nBut for housenum_labels the topoint will only be called once at z14, same goes for poi_labels. And there are not that many airport_labels.\nSo there it might be premature optimization.\nWould be cool if imposm could make points out of polygons at import step.\nLet's remember this and perhaps it will be the silver bullet to another query problem.\n. > imho - the correct :\nUps switched ways and relations in the written example.\nThanks for the review and detailed example.\nSo what the code now does is for relation it takes the relation and get's back the real OSM id (but still negated if it is a relation.\nAnd then our osm_id functions that already exist decide what the Mapbox OSM Id will be.\nRelation\n-10000000000000003 + 1e17 = -3\nIf it is a polygon for example the osm_id_polygon function will now do\n(abs(-3) * 10) + 4 = 34\nIf it would not have been negative it means it is a polygon was not made out of a relation\nand the osm id looks like this.\n(3 * 10) + 2 = 32\n. > my alternative solutions:\nThat's my dream scenario - having a osm_ids2mbid function.\nCan you push the osm_ids2mbid function to this branch?\nWe gave you contributor access on osm2vectortiles as we really appreciate your input and work.\n\nwith the #284 patch there will be a problem, because we will lost the geometry information (osm_id_geometry() ) [ this is polygon or not ? ]\n\nYes what happens there is that the Mapbox osm_id will be wrong for place points from polygons.\nWas already thinking about creating another table in the mapping so we can keep the information\nbut with the osm_ids2mbid the problem can be solved easily because there are only points and polygons in the table we can call osm_ids2mbid(osm_id, true) and it will choose the correct one.\n. With osm_ids2mbid it has gotten much easier.\nTransformed the tm2source project.\n1. Where we used osm_id_point we now use osm_ids2mbid(geom, true) since we only make points out of polygons\n2. Where we used osm_id_linestring we now use osm_ids2mbid(geom, false)\n3. Where we used osm_id_polygon we now use osm_ids2mbid(geom, true)\n4. Where we used osm_id_geometry and the possible geometries where only point and polygons we now use osm_ids2mbid(geom, true)\n5. Where we used osm_id_geometry and the possible geometries where ways and polygons (road, barrier_line) we now use osm_ids2mbid(geom, is_polygon(geom))\n. We highlighted what is important to improve on the docs website.\nWe want to simplify the docs. At the moment it is way too complicated.\nWe think the developer docs section can probably better be covered by having good docs on GitHub for the people that want to work with the project and focus on the user docs.\nThere we want to create one very good tutorial showing how to serve your on vector tiles (without Docker, just tileserver-gl if possible) and then use them in a site.\n\n. Our bachelor thesis tasks/discussions will continue in https://github.com/osm2vectortiles/bachelor-thesis so I will close this.\nThanks for setting it up.\n. > Budapest (Hungary) : http://www.openstreetmap.org/relation/1244004\nWould be nice to see something different than always Zurich in the examples as well :grin: \nIf we can get a big list of bounding boxes for city extracts we can also do the same as for countries. Extract 200 cities and list them as searchable extracts on the site.\n. > A possibility would be to use the list compiled by Mapzen for their metro extracts, which can be found here\nReady made bounding boxes as GeoJSON including the name. That's actually all we need.\n. Cities and countries TSV I can then later parse in #294 to create extracts.\n- https://github.com/osm2vectortiles/osm2vectortiles/blob/feature/mbtiles-extract-csv/src/create-extracts/country_extracts.tsv\n- https://github.com/osm2vectortiles/osm2vectortiles/blob/feature/mbtiles-extract-csv/src/create-extracts/city_extracts.tsv\n. Thanks for the really detailed comparison.\n\nI understand that data density and tile sizes are conflicting issues but I think that the data/feature density in osm2vectortiles is still too low. ZL = zoom level.\n\nHow did you do the screenshots? Are you comparing the http://dev.vectortiles.osm2vectortiles.org.\n. The good thing is that down to z8 or z9 we can easily rerender everything if we want to improve something since it is not that many tiles.\n\nZL 5 osm2vectortiles vs ZL 6 Google\n\nCannot see immediate differences on z5.\nhttp://dev.vectortiles.osm2vectortiles.org/#5.12/46.119/8.030\n\n\nZL 6 osm2vectortiles vs ZL 6 Mapbox Street v7\n\nThe problem here is that we tested too much with Switzerland where the scalerank is mostly set for the important places. We can add more place labels but then mostly the client is responsible for filtering them by localrank.\nWhat I do now in https://github.com/osm2vectortiles/osm2vectortiles/commit/807c7a986da46b1b51bc201dac32a6921d25b673 to improve density on z6 and z7 is to allow all town and city (even if no scalerank)\nbut I then limit the data to localrank < 40.\n\n\nZL 7 osm2vectortiles vs ZL 7 Mapbox Street v7\n\n\n\nZL14 House numbers (for use in ZL17+)\n\nWe have the house numbers. The style is just not displaying them.\n@manuelroth Want to talk a look at the other proposals?\n. There are two problems left here which is the city label density #308 and landuse residential #307 which will continue in separate issues since they are larger features.\nThe other things in this issue have already been resolved by @manuelroth (thanks!!).\nBTW @muesliq nice article about Google Maps label placement http://www.justinobeirne.com/essay/what-happened-to-google-maps.\n. Top. Good that you are using area from table column.\n. > When adding an outline for the water polygons, in order to draw an slight edge on the shore, we get lines where the water polygons are cut of in the OSM water polygons.\nYes the data from http://openstreetmapdata.com/data/water-polygons is cut into different parts so that we don't have to handle the ocean as one gigantic polygon (no performance problems).\nWhich data are you using. What is currently released on osm2vectortiles.org?\nIt might be possible that because we use the osm_id as vector tile key in the next version that the water is handled in the vector tile as one huge polygon even if it is not\nBut we don't have a fix for this. We need to use the water from OpenStreetMapData.\nI understand the need for having nice coastline styles for ocean polygons.\nCan you style the land instead of the water perhaps?\nBTW Are you using osm2vectortiles for http://dev.digitransit.fi/ as you told us in https://github.com/osm2vectortiles/osm2vectortiles/issues/114? We love to hear what people are using osm2vectortiles for and where we can help (with your permission we would like to list your project on http://osm2vectortiles.org/examples/ ?). We hope that the next version will resolve most issues and it will bring along many many quality improvements. \n. > There is no land to be styled, as the land consists of just the background, which is colored using a solid color, making the water polygons our only choice to get nice colored coastlines. Somehow Mapbox has gotten this working, since using the same style with their vector tiles doesn't render edges between tiles and only on the coastlines. You might want to check what osm_ids they use for their water polygons.\nYes we import the water not the land from OpenStreetMapData..\nSo the ideas that come to mind for fixing this problem:\n- Use a complete Water polygon: Would result in performance problems since the vector tile renderer needs to request too much data for rendering a small part of the world.\n- Vector Tile Key: How does Mapbox know what the polygon inside the vectortile is part of a bigger polygon? Perhaps since we use 0 as vector tile key then MapboxGL thinks that those are all part of the same polygon. I will have a look into this\n- Coastlines: Use coastline data and then style the line with an outer shadow.  http://openstreetmapdata.com/data/coastlines\nSince you are generating the osm2vectortiles vector tiles yourself (right?) you could import the coastlines with shp2pgsql and then style the coast line.\nI know that is not perfect but that would be one possible way how you can get this to look nice faster than waiting for us :)\n\nIn order to read more about our project, you can read more here\n\nOh will love digging into this. Nice docs!\nhttp://www.digitransit.fi/en/developers/service-catalogue/apis/map-api/\n. Problem still exists (even though water has the same key).\nYou can see the fine styled lines on the right.\n\n. > Would a similar approach to the one specified in #297 work with this. Especially if extending the polygons outside the expected buffer.\nYou can collect the ocean polygons and combine them together into one polygon.\nThis could be done if you want to produce only a local extract but not for the world due to performance resons.\n\nUse a complete Water polygon: Would result in performance problems since the vector tile renderer needs to request too much data for rendering a small part of the world when rendering water.\n\nIf you run osm2vectortiles yourself I can do a branch with coastlines import and coastline layer and publish it there - but I don't want to add coastlines to the main project.\nIt is a bug that you cannot style the water polygons because they are split but it is also a high-invest low-return bug that we cannot fix in the main project without many hours (that we need to invest otherwise due to rendering schedule).\nSorry, hope that's ok for you. \n. As discussed above there will be no general fix for this.\n\nIf I don't find a nice solution we can just import the coastlines as linestrings, which can be styled separately.\n\nIf you plan on doing that just post on this issue again here and I will create a separate branch with an extended import-external container and a new layer. Setting up a new layer takes us not much time.\n. > Thank you for your great project! If took me quite a while to locate this.\nThanks @ratrun. You want to provide a PR for that since you are already know the change?\n. Good work. You can see it in effect here: http://osm2vectortiles.org/maps/\n. Very good - now we have naming consistency. Also the SRID to 3857 change is huge. Bad that I forgot it until now. This meant that at time of query from Mapnik all water had to be reprojected every time since we use SRID 3857 in the tm2source.\n. > @lukasmartinelli Cool \"PostGIS Query Editor\" I was not aware of. Looks similar to those \"PostGIS Terminals\" like http://giswiki.hsr.ch/PostGIS_Terminal :-) . If the installation has as few dependencies as possible (did'nt check this), this tool could become widely used!\nThis is actually very much a clone/inspired by your PostGIS terminal just as local tool. So it is a crossover between Mapbox Studio and the PostGIS terminal.\nInstallation wise you can just download a ZIP file for Windows, OSX and Linux and run the exe.\nStill working on creating installers that's why I have not published it yet.\nYou can download the Windows EXE from here: https://github.com/lukasmartinelli/postgis-editor/releases\nOne of my use cases is actually the PostGIS part of the Informationssysteme lecture. Perhaps the students could use the PostGIS editor there for completing the exercises in a more fun way.\nLet's discuss this when I'm back from the military. Would love your input to building a PostGIS editor before I publish it.\n. Very good proposal. Does our imposm3 pro @ImreSamu  know whether the diff import still works with this?\nSince it seems that you already managed to rename it once would be cool if you could create a branch on the osm2vectortiles repo with those changes.\n\nEasiest would be to change the zoom level views of all layers to use id AS osm_id. With this you don't   have to touch the source project at all.\n\nGood idea we just have to rename the mapping and then all files inside src/import-sql/layers\nand probably some other SQL files in src/import-sql. We can do that after we have the branch for the mapping with what already works for importing. \n$ grep osm_id src/* -r | wc -l \n$ 630\n. I am running an import with the new mapping from this branch so we can then test this out globally.\nGreat work and very impressive QA with the tests - very glad to see it works with the diff updates.\nEDIT: PR seems good to me, everything worked smoothly on the world import and now exporting. You can merge it yourself when you think it is ready.\n. > for a Data-Based Decision Making :)\nYou sir, are awesome. Very good query idea.\nThose examples all would have pretty bad labels with ST_Centroid.\n\nWe cannot use the same trick as for place labels (where we turn all geometries into points before hand) without creating a new table just for housenum labels (which will also take a huge amount of time when importing).\n\nNot correct what I wrote earlier acout new tables. I can actually also use the same trick with UPDATE for housenumber_polygon and poi_polygon which will be a much more elegant solution.\nI will try how long this takes on the world dataset - would be a quick solution and better looking one.\n. Updating doesn't take too long approx. 1 hour. So precalculating the point is the better solution than ST_Centroid.\nThanks @ImreSamu for pushing us into the right direction once again.\n. Tweaked the city labels it is better now but still not perfect. But I'm gonna stop here.\nI am using a smaller labelgrid now for filtering the labels.\nBelow I document the status quo if we ever want to go over labels again. Label placement is the holy grail of web mapping and we still have room for improvement.\nz5\nThis is the best compromise with scalerank=7filter which comes almost close to Mapbox.scalerank=6will yield too few andscalerank=8` too many place labels.\n\nz6\nWe have approximately the same density. Mapbox still has a much better distribution and is filling empty areas bettter (but then again not showing some important cities).\nBut this is as far as I get with our simple label grid based approach.\n\n\nz7\nAgain still better distribution by Mapbox but at least similar density.\n\nz8\nFound some differences on z8 as well and improved it. Pretty happy with z8.\n\n\nz9\nWe now show some villages as well on z9.\n\nz10\nNow showing some suburbs on z10. But very difficult to know which suburbs are important as often they have no population data.\nOne of the layers where we can improve the most very later on to make cities look better.\n\nz11\nHappy with z11.\n\nz12\nNot a query problem but merely a mapping one. We are missing suburbs (e.g. in Leipzig).\nAt z12 all suburbs are displayed actually and selecting data is less of a problem.\n\nBecause in other places the place labels are the same.\n\n. Sorry for the inconvenience.\nThis issue is a very good example how we need to improve our public docs to be more straightforward and less complex. Thanks for handling @manuelroth \n. > Yes, definitely. Would it make sense to combine the 3 import steps(import-external -> import-osm -> import-sql) to one big import?- They are all depending on each other anyway.\nThese import steps are only detached so that we as developers can iterate on each container separately. For example import-external changes nearly never while import-osm now changed sometimes and import-sql will change very often. This makes it a bit impractical to always do the entire import again.\nAlso each container has different requirements to the image (ogr2ogr, imposm3 and psql).\nI think we don't need to combine it further (but I also played with the thought).\nI agree that it would make it easier for people to get started but as soon as you dig more into it it get's clearer why the separation makes sense. We just need to document it very well (started writing in the docs of each container about what requirements need to be met before it is run).\n. > Also had this error once, it is because bbox's starting with a negative number are not handled properly. I found a workaround, just add a space before the negative sign => \" -58.89,-34.96,-57.99,-34.29\"\nIt is exactly that. I think using the named parameter differently https://github.com/osm2vectortiles/osm2vectortiles/commit/01612da95fc31112df8c0183a0b73da373ac961b can fix it (doing something like this in the export Python script).\n. Assumption: Grouping the landuse stuff together might be the cause\nActually this is not the case. When I remove the grouping it still consumes 2.023 GB and times out.\nAssumption: Do the layer queries have a bug?\nThe queries look good imho.\nLet's find out at which zoom level this happens by limiting the tilelive copy command to certain zoom level ranges.\n- z8-z9 is fast.\n- z8-z12 is fast\n- z8-z13 is slow\nSo the problem happens at z13.\nAssumption: Are there very big landuse geometries?\nSo it might just be that there are huge landuse geometries that always need to be transferred.\nFor example the query below yields a 2.3MB glacier (which is not much but there are probably bigger ones) And 2.3 MB times 5000 is 14.828265 gigabytes\nTesting this with query.\nsql\nSELECT octet_length(ST_AsBinary(\"geometry\")) AS geom_byte_size,\"osm_id\",\"class\",\"type\" FROM (\n      SELECT osm_ids2mbid(osm_id, true) AS osm_id, geometry, landuse_class(type) AS class, type\n        FROM (\n        SELECT osm_id, geometry, type\n        FROM landuse_z5toz6\n        WHERE z(68247.3) BETWEEN 5 AND 6\n        UNION ALL\n        SELECT osm_id, geometry, type\n        FROM landuse_z7toz8\n        WHERE z(68247.3) BETWEEN 7 AND 8\n        UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z9\n          WHERE z(68247.3) = 9\n          UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z10\n          WHERE z(68247.3) = 10\n          UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z11\n          WHERE z(68247.3) = 11\n          UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z12\n          WHERE z(68247.3) = 12\n          UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z13toz14\n          WHERE z(68247.3) BETWEEN 13 AND 14\n        ) AS landuse_z9toz14\n        WHERE geometry && ST_SetSRID('BOX3D(-2426493.46291292 15414520.4350735,-2421448.619046099 15419565.27894032)'::box3d, 3857)\n    ) AS data\nBut how can we make this better? \nSome geometry function that can clip/cut out a smaller part (aka the bounding box + buffer) from a big geometry and just return that? Like ST_Intersection.\nSo if we try something like this (we need to add a buffer to ensure that the vector tile extent still works - so we just always take an entire tile as buffer - 256px).\nsql\nST_Intersection(geometry, ST_Buffer(!bbox!), !pixel_width! * 256)) AS geometry\nThe full query. It now just returns 9 bytes.\nBut whether that returns still useful data - have to test this with the postgis editor.\nsql\nSELECT octet_length(ST_AsBinary(\"geometry\")) AS geom,\"osm_id\",\"class\",\"type\" FROM (\n      SELECT osm_ids2mbid(osm_id, true) AS osm_id, \n      ST_Intersection(geometry, ST_Buffer(ST_SetSRID('BOX3D(-2426493.46291292 15414520.4350735,-2421448.619046099 15419565.27894032)'::box3d, 3857), 200)) AS geometry,\n      landuse_class(type) AS class, type\n        FROM (\n        SELECT osm_id, geometry, type\n        FROM landuse_z5toz6\n        WHERE z(68247.3) BETWEEN 5 AND 6\n        UNION ALL\n        SELECT osm_id, geometry, type\n        FROM landuse_z7toz8\n        WHERE z(68247.3) BETWEEN 7 AND 8\n        UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z9\n          WHERE z(68247.3) = 9\n          UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z10\n          WHERE z(68247.3) = 10\n          UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z11\n          WHERE z(68247.3) = 11\n          UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z12\n          WHERE z(68247.3) = 12\n          UNION ALL\n          SELECT osm_id, geometry, type\n          FROM landuse_z13toz14\n          WHERE z(68247.3) BETWEEN 13 AND 14\n        ) AS landuse_z9toz14\n        WHERE geometry && ST_SetSRID('BOX3D(-2426493.46291292 15414520.4350735,-2421448.619046099 15419565.27894032)'::box3d, 3857)\n    ) AS data\n. > Some geometry function that can clip/cut out a smaller part (aka the bounding box + buffer) from a big geometry and just return that? Like ST_Intersection.\nThis might work. Consumes way less input data but sadly still times out (I guess because the queries are now much more expensive?).\nDrawback is that PostGIS now is burning CPU (like 300% but that is the same CPU time Mapnik was wasting before). We now clip the data before we send it over the wire (aka the internal network interface). \n. Glaciers are bad boys. Some of those geoms are 2.9MB big (times 5k tiles..).\nsql\nselect avg(octet_length(st_asbinary(geometry)))\nfrom osm_landuse_polygon where st_area(geometry) > 10000000000\nI am doing a controversial hack now https://github.com/osm2vectortiles/osm2vectortiles/commit/55151a06d1f6eecf6205280dde0f05549e7488a5 that impacts correctness. At z13 and z14 I just exclude gigantic glaciers and parks. This means that if you zoom into all the way down to z14 into the glaciers you suddenly will no longer see the glaciers. But at the moment this is the only thing that looks promising at solving this weird problem. This also impacts #42 \nI am just rendering greenland now and this takes longer than the really data heavy Europe.\n\n. > one solution for big polygons ..\nMight be more performant to slice it up before hand into large tiles (like a z11 grid) than doing ST_Intersection on the query directly (z13-z14).\nI thought about slicing up the geometries, it is a good idea but I am a bit afraid of bugs like #300 occuring for landuse as well. Create a table like osm_landuse_sliced_polygon where we insert the landuse polygons with really large areas into (but then we also need to purge them from the source and generalized tables). \nBTW. also tried simplifying the large polygons but that doesn't really make them smaller.\n. This is a bit counter intuitive. The buffer is measured in px relative to a\n256px tile.\nWith a resolution of 4096 a buffer of 128px can stretch up to 2048 for\nexample.\nOn May 10, 2016 5:00 PM, \"fitsoft\" notifications@github.com wrote:\n\nHi Manuel, thanks for the quick reply! By looking at the file\nosm2vectortiles/osm2vectortiles.tm2source/data.yml where the buffer\nsettings seem to be, I don't see any buffer-size greater than 256 but in\nthe tile I showed before there are coordinates in the -2000 range for\nexample or above 5000, well above the 256 maximum.\nMaybe I should consider that the 256 may come from a lower zoom level and\nduplicate in size as I \"zoom in\"?\nThanks,\nClara\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/318#issuecomment-218185237\n. All great questions @fitsoft.\nThen in the esample you just gave I could have a coordinate take roughly values in the interval [-2048, 4096 + 2048] ?\n\nYes. Or with 256px even [-4096, 4096, 8192].\nI don't know what the max number (if you can have more than 256px buffer) for the tile coordinate system is (4096 suggests 12 bits but you also need one bit for minus and one for 8192 so perhaps 14bit if 256px is the max buffer).\n.  Our goal is to have this time a tutorial without using Docker since that confused many new users not familiar with it. And this PR is a good step in this direction. Forgive the minor complaints.\nWould be really cool if users can just npm install <tileserver> and then do something like tileserver afghanistan.mbtiles and that's it. No cloning a repo or something. Also while it is really cool to see how easy it is to serve MBTiles this doesn't deal with all the edge cases like requests that are out of bounds or filter zoom levels or PBFs that are not gzipped.\nSomething like tessera (tessera is not really intuitive however because you see a blank page when serving PBFs). We can merge it and discuss it further on friday or wait until then.\nI would like to use tileserver-gl but it could not npm install it due to build errors since (and for just serving PBFs we don't necessarily need mapbox-gl as dependency). And the config.json also makes it a bit complicated for new users again.\nThe rest I think is pretty solid (some style things but we can fix that later).\nAlso if we say\n\nWe have prepared a repository containing all the necessary files for you. Simply clone this repository, run npm install, download your desired extract and run node index.js and the vector tiles are getting served.\n\nWe should probably list the code for the lazy user not as text.\nsh\ngit clone https://github.comosm2vectortiles/...\nnpm install\nwget https://osm2vectortiles/downloads/zurich.mbtiles\nnode index.js\nSame here I guess.\n\nTo get you started quickly we have created a repository with the necessary files and assets. Clone this repository, start your favorite webserver(`npm install http-server -g) and you should see the map in your browser.\n- [x] Perhaps adapt the main page with the new links or change the texts?\n\n\n- [x] The stylesheet screws up code formatting\n\n. Discussed approach now.\nMaps\nOn the maps section on the homepage we want to show all Mapbox GL styles (modified to not needing Mapbox terrain and pointing to the vector tile CDN).\nAnd like the Mapbox GL examples page we want to provide the HTML code to embedd so you can copy and play with it. This is that the users can get started as quickly as possible.\nIn the tutorial we then to deeper and explain how to host the tiles yourself.\n\n\nGetting Started Tutorial\nPart 1\nFirst show the example with the CDN.\nTell the user to go to Maps choose an example, create a index.html page and use it there.\nBaam first success story.\nPart 2\nThen we show the second part that if you don't want to use a CDN how to serve your own tiles.\nThere we create a very simple MBTiles PBF serving tileserver based on what Manuel started (with no deps on MapboxGL or Mapnik) package the styles and fonts into it and publish it to npm.\nAnd @hyperknot is absolutely right there, it is important that this runs everywhere without compiling stuff  with node-gyp if possible. \nThen when you start the tileserver with something like tileserver afghanistan.mbtiles.\nWe display the same map section as on osm2vectortile including the copy example but there we replace the source in the styles with the url pointing to the local tileserver URL.\nThis tileserver is not meant for production but to get you serving your own tiles fast.\nAfter that we recommend switching to something like tileserver-gl, tessera or the other many options (like putting the PBFs on S3).\n. We once discussed putting the filesize into the CSV file as well.\nBut while adding the filesize to the CSV is doable maintaining later will be kind of a chore.\nWe then need to update the CSV weekly with the newest filesizes.\nCan we just leave out the filesize for city and country extracts?\n. Of course since the bucket is public you can do that.\nGood idea and initiative, thanks.\nThis way it is decoupled from the CSV which is perfect.\n. Thanks for noting the issue. This is a problem of the tm2source format.\n\nWhen e.g. running in the postgis docker container the database does not listen on port 5432.\n\nI am assuming you are using an external PostGIS database and trying out the tm2source with Mapbox Studio or tilelive-copy, tl copy?\nOr what is the use case when you want to modify the connection of the tm2source project?\nIf you are using the docker-compose workflow from osm2vectortiles the osm host will automatically resolve to the PostGIS container.\nDoes the setup your doing still work with mapbox studio?\nWhen working with the tm2source we usually work with Mapbox Studio not the YAML format directly.\nAnd then Mapbox Studio will just overwrite the YAML values again.\ndocker-compose up mapbox-studio\nAnd for exporting if you are using the export component for exporting PBFs this is actually already solved by a Bash script that replaced the connection options with the ones passed via env vars\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/export/utils.sh\n. Thanks again for making the PR appreciate that.\n\nI didn't want to work with MBTiles out of space and performance reasons when generating them, so I serve up the vector source directly from the database using Tessera (https://github.com/mojodna/tessera). \n\nThat's completely legit! We also use and recommend tessera for stuff like this.\nDidn't know about glug.\n\nBecause you have such a nice workflow for importing the data I'm using the postgis Docker container.\n\nThat's cool because most people don't modify our workflow. I guess you miss a lot of documentation there? We're working on that.\nYou are just using the workflow of importing water/natural earth/etc or the tm2source project as well?\n\nI could of course do some (automated) find/replace before using the vector source, so if you decide that this PR is out of scope for you I don't mind. Since I'm new to vector tiles, if you can think of some better way this could fit within your project I also appreciate any hints.\n\nI think we cannot fiddle with the tm2source on this project because it needs to work with the Mapbox Studio Classic. But this makes more sense in your personal project.\nHowever this made me realize that we have the same problem for env vars (like when you want to use a different PostgreSQL user). I want to solve that using environment files.\n\nI could of course do some (automated) find/replace before using the vector source\n\nHere you go if you want to use that in the personal project. For osm2vectortiles this is already implemented for export and you can use the same for your tessera Docker container for example.\n``` bash\nreplace database connection with postgis container connection\nfunction replace_db_connection() {\n    local replace_expr_1=\"s|host: .|host: \\\"$OSM_HOST\\\"|g\"\n    local replace_expr_2=\"s|port: .|port: \\\"$OSM_PORT\\\"|g\"\n    local replace_expr_3=\"s|dbname: .|dbname: \\\"$OSM_DB\\\"|g\"\n    local replace_expr_4=\"s|user: .|user: \\\"$OSM_USER\\\"|g\"\n    local replace_expr_5=\"s|password: .*|password: \\\"$OSM_PASSWORD\\\"|g\"\nsed -i \"$replace_expr_1\" \"$DEST_PROJECT_FILE\"\nsed -i \"$replace_expr_2\" \"$DEST_PROJECT_FILE\"\nsed -i \"$replace_expr_3\" \"$DEST_PROJECT_FILE\"\nsed -i \"$replace_expr_4\" \"$DEST_PROJECT_FILE\"\nsed -i \"$replace_expr_5\" \"$DEST_PROJECT_FILE\"\n\n}\n```\n. > P.S. I saw that you will be at FOSSGIS or at least @manuelroth will be, see you there.\n\n\ud83d\udc4d 1\n\nVery cool. @manuelroth and me will be there. Let's meet there!!\n. @aplimovil You created a index.html links to the style served tileserver-vector or just the style file in the mapbox-gl-styles repo?\n. @stirringhalo @aplimovil. With the release of v2.0 it should be much clearer what to use for what.\nAnd the roads problem does not occur in v2.0. Will reopen again if you think it is still not solved.\nCheck out the new downloads: http://osm2vectortiles.org/downloads/\nAnd the tutorial: http://osm2vectortiles.org/docs/getting-started/\n. > Think these changes are ready to be merged? I'm still running into timeout issues and for the purposes of performance, I'm thinking of subdividing those super-large polygons.\nYes will. Just have to decide whether to put it into import-osm or import-sql since it requires importing the XYZ_Extent SQL function first.\n. > Awesome, I grabbed the last changes. Looking great so far! Does this increase the DB size much?\nOn top of my head this only affects ~4k polygons.\n. > To confirm, the DB when imported is about 150 GB?\nAfter initial import, now after two diff imports it grew to 176 GB on BTRFS disk and Postgres tells 172GB.\nOn what kind of hardware are you running the DB?\n. Yes nothing more - won't help with the tineouts. Can you send the bbox,\ntile coordinates where the timeouts occur? I am also still hunting for\nother causes for the timeouts.\nOn Jun 13, 2016 5:17 PM, \"stirringhalo\" notifications@github.com wrote:\n\nQuestion, does aa5049d\nhttps://github.com/osm2vectortiles/osm2vectortiles/commit/aa5049d9d4410421be1c88f7684855ff1fbdd393\nsimply ensure that the osm_landuse_split_polygon table is created prior to\nmaking the landuse and landuse_overlay views? I have all the changes except\nfor aa5049d\nhttps://github.com/osm2vectortiles/osm2vectortiles/commit/aa5049d9d4410421be1c88f7684855ff1fbdd393\nand I'm still running into the issue of too large of geometries timing out.\nGoing to dig into it, and see if I can either fix for this processing run\nor dump the large areas.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/pull/324#issuecomment-225612804,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ABOokw0EO5qnfgFZ0ywm-XtsFxdzeeT9ks5qLXSKgaJpZM4IhYaw\n.\n. I think this works even when the mapping is not applied right?\nSo at least this change will then get into the updated tiles.\n. > This breaks rendering when using mapbox-gl-native.\n\nOh oh this is a big one. So as of no the vector tiles we generate are not compatible with v2?!\nI thought it is backwards compatible.\nThis is kind of a big one since would mean we need to rerender yet again which requires that @klokan would be willing to donate another infrastructure round.\nAt least it is now much faster thanks to #324.\nBut let' s not jump ahead. We will continue with what we have now so we can deliver.\n\nThis is due to mojodna/tilelive-tmsource#9. After forking the repository and adding tilelive-bridge@2.3.1 and corresponding mapnik version as dependencies the tiles render correctly.\n\nSo we need to install it from https://github.com/hannesj/tilelive-tmsource?\nPerhaps you can prepare a PR since you got it working \ud83d\ude01 \ud83d\ude47  ?\n. > This is kind of a big one since would mean we need to rerender yet again which requires that @klokan would be willing to donate another infrastructure round.\nJust discussed with @manuelroth. We don't want to render again before the bachelor thesis is finsihed (middle of June) since it is important that we don't have many more moving parts at this point in time.\nLet's for sure keep this open.\n. > I am keen to make one more complete world rendering, with diff updates turned on - and fixed this as well as other reported issues.\n\nWould it be doable in the first half of July at latest, @lukasmartinelli? Then we can manage the world USB sticks for FOSS4G.\n\nHappy you are willing to sponsor another run. I would love to do that. Thank you.\nI want to try and first integrate those few schema changes that were proposed and then start asap.\nDo we now that NOW we are compatible for sure? Or do we need to create test extract and test it again with native clients?\n. > Just a small note, as I don't know what hardware the initial import is done on, but these might be great budget-friendly dedicated servers for the osm2vectortiles project, as you can rent them for one week and they have 64 GB RAM:\n\nhttps://www.runabove.com/sandbox-servers.xml\nOr these ones with SSDs:\nhttps://www.runabove.com/i7-game-servers.xml\n\nWe are happy that @klokan is sponsoring the VMs needed for rendering OSM2VectorTiles.\nHowever thanks for the tip, this sounds like a great offer to try my personal data projects.\n\n@hyperknot I can't remember off-hand how many AWS VMs they are using, but I know they are all 8-core. I think it's 4 VMs.\nThe biggest issue is cores, and secondly storage. This is an embarrassingly parallel problem. You can scale this as large as you want to, but it is best to have a copy of the DB local to the workers (ie, on the same machine). The DBs need to be on SSD for good performance. RAM isn't a huge concern, I find 8GB is a decent sweet-spot for a few workers as Postgres is mostly using it for cache. The workers themselves use very little RAM.\nSo the most ideal setup would be many machines, lots and lots of cores, low RAM, and local SSD. You could do this easily with an adhoc cluster, but propagating the database to many machines could be a pain depending on your network and automation.\n\nAll correct assumptions @stirringhalo. We are using 16core - 64 GB machines (but RAM could be lower - we just want the 16 cores). And distribute it by copying the DB (also correct assumption) to a local attached SSD (no network filesystem).\nFor updating we only need 1 machine - for rendering we used 4 to 8 machines (depends how fast we want it rendered). For the next run I will probably scale it up to even more since we are a bit in a hurry.\n. > There are issues with the new planet MBTiles - missing bounds (!) + metadata contains SQL(!?) + name mentions version 1.4 not 2.\nThe SQL is weird but it still valid. Tilelive-copy and tl copy now add the tm2source content to the MBTiles metadata as well.\nI corrected the planet MBTiles and reuploaded.\nsql\nUPDATE metadata SET value='tms' WHERE name='scheme';\nUPDATE metadata SET value='pbf' WHERE name='format';\nUPDATE metadata SET value='<a href=\"http://www.openstreetmap.org/about/\" target=\"_blank\">&copy; OpenStreetMap contributors</a>' WHERE name='attribution';\nUPDATE metadata SET value='Free vector tiles from from http://osm2vectortiles.org' WHERE name='description';\nUPDATE metadata SET value='osm2vectortiles' WHERE name='id';\nUPDATE metadata SET value='osm2vectortiles' WHERE name='name';\nUPDATE metadata SET value='2.0' WHERE name='version';\nUPDATE metadata SET value='baselayer' WHERE name='type';\nINSERT INTO metadata VALUES ('bounds', '-180,-85.0511,180,85.0511');\n. Ocean no longer looks as nice as with NaturalEarth but then again we only have one source for ocean and Antarctica is finally fixed with  #401.\n\n. Solved in the newest planet release of 2016-06-13 thanks to the subdivide fix in #352. Thanks @stirringhalo.\n. > I assume we are to run the local Dockerfile for merge-jobs after to amalgamate the results? Assuming RabbitMQ installed from a docker container (docker-compose up rabbitmq and docker-compose up export-workers ), could you clarify how to run in docker the merge-jobs tool?\nSorry we haven't published this Docker image yet. Published it now.\nYou can build all Docker images locally with running make.\nhttps://hub.docker.com/r/osm2vectortiles/merge-jobs/\nIt should work with the local RabbitMQ.\n. Image exists now.\n. The script is used with the Docker image which uses Python:3.4.\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/merge-jobs/Dockerfile\nIt is possible to make the urllib call work with Python2 and Python3. I guess this is the only thing that makes it incompatible.\n. > The script is used with the Docker image which uses Python:3.4.\n\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/merge-jobs/Dockerfile\nIt is possible to make the urllib call work with Python2 and Python3. I guess this is the only thing that makes it incompatible.\n\nIt isn't worth it to spend time to make it compatible with Python 2 since it runs in a Docker container all the time anyway.\nBTW @stirringhalo i put up the ansible script i use to setup the cluster https://github.com/osm2vectortiles/distributed-deployment\n. Thank you for your patience.\n\n1) By default using mock-s3, once all the processing is complete and \"docker-compose run merge-jobs\" is executed, I can see the attempt made to grab the jobs from mock-s3. Same is noticed with the merge-jobs.py script in standalone. However, the URL is incorrect, it is \"http://mock-s3:8080\"... which of course fails. The net result is a blank planet.mbtiles.\n\nI guess you used the local Python script due to #331 not being available.\nWe don't use the mock-s3 in production but a hosted S3 provider.\nIf you run merge-jobs standalone this will not work but if you run it inside the merge-jobs container which is linked to the mock-s3 container the URL http://mock-s3:8080 will actually resolve to\nthe file (since Docker does host resolution).\n\n2) When it says \"Download http://....mbtiles (66.0 kB)\" and then \"Merge 10.2 kB from ....mbtiles\", is that there's duplication in the resultant mbtiles and that the merge is only take of course the new info?\n\nI download the MBTiles file and then check the size (66kb) then I merge it into the target file and show the difference before and after merge (10.2kB). This means that the merge source contained tiles that are already in the target file (and size therefore does not increase).\n\n3) I've also hardcoded the RabbitMQ URL for the merge-jobs.py script as it isn't clear what format the rabbitmq_url is to be. I tried \"amqp://osm:osm@localhost:5672/\" which didn't seem to be correctly parsed. Once I hard coded it with Pika, it seemed to work fine.\n\nIt is always the same AMQP URI format in the form you mentioned amqp://osm:osm@localhost:5672/.\nThe wrapper script in the docker container that calls the Python script looks like this. It takes the env var from the docker container if it is set otherwise the default.\n``` sh\nreadonly RABBITMQ_URI=${RABBITMQ_URI:-\"amqp://osm:osm@rabbitmq:5672/\"}\nfunction export_remote_mbtiles() {\n    exec python merge-jobs.py \"$RABBITMQ_URI\" \\\n        --merge-target=\"$MERGE_TARGET\"\n}\n```\nThis means you can set the RABBITMQ_URI in the docker-compose file as environment variable.\n\n4) Is the expection made that a blank planet.mbtiles is made first to append the merge to? Should this be integrated into the merge-jobs.py script?\n\nI was always using an older planet file I had before as merge target. But if you are starting from scratch that doesn't work as you said.\nI could copy an empty MBTiles file into the repo for example that can be used as merge target. Would that work?\n\nSorry for all the questions, I'm working on an entire planet import so I will be running into the same issues that are quietly handled in the background for the planet.mbtiles download you provode\n\nThanks for the patience for asking your way through. Never anticipated someone else would use the distributed workflow at big scale.\nWhat about a Skype call (my user id \"lukas.martinelli\") so we can perhaps play through your problems directly. Since we've seen them a lot that can be quite effective and for us the process is always really helpful since we see exactly with what problems people struggle or we left undocumented.\nI think a lot of this issue can be discoered if we put the entire process into the Travis build as well so it is always played through.\n. > As a followup, here's my approach for now instead of the docker merge-jobs. Plus, this doesn't take the messages out of the queue:\nThat's a good approach for doing initial renderings. Used this before for example to recover lost MBTiles.\nGood idea.\n. Mock S3 is no longer supported as of 1-2 months. But the discussion triggered here is still worth a lot. Thanks @stirringhalo.\nI know this makes it a bit trickier to test - but we only had problems with the mock server\n. Thanks for reporting. 1 hour ago I had the same error but now it seems to work again, this is sadly out of our control.\nBut from what I saw only the big planet files was down.. weird.\n. I guess this is map race tracks @hannesj?\nhttp://wiki.openstreetmap.org/wiki/Tag:leisure%3Dtrack\n\n\nThanks for this contribution, but you need to explain way you want to add this. We won't merge an uncommented PR.\n Show all checks\n\n@manuelroth I think GitHub supports issue and PR templates now. https://github.com/blog/2111-issue-and-pull-request-templates We could add one.\n. > Secondary roads (dutch N-roads) are not styled in tm2 OSM-Bright and street tiles with the new planet.mbtile (they did style correctly with the old world.mbtile)\nWe no longer support rendering raster tiles with the new planet or differently said we no longer tested whether it looks good.\nI know for some people this will be a drawback but you can continue using the old planet file.\n. > How can we serve on-premise mbtiles (no internet access), and use them as correctly styled tiles inside the ESRI JavaScript API?\nYes raster tiles still have their places! But with Mapbox GL it is now possible to generate raster tiles from Mapbox GL.\nYou could https://github.com/klokantech/tileserver-gl which @klokan is also using to provide raster tiles to  clients that do not support Mapbox GL. tileserver-gl is using an internal X-Server with Mapbox GL support to render raster images and deliver it to older clients.\nI don't know whether it is already possible to generate a raster tile MBTiles file with tileserver but if not you can also use tl copy to copy the images from the server into a MBTiles.\n. > 1) You're using AWS/some sort of cloud services to generate the first planet.mbtiles\n\n2) After that, you use \"docker-compose up changed-tiles\" to get a task list and only render those changed tiles\n3) You do rolling updates to keep up with OSM pbf\n4) Only if the base mapping changes do you redo the planet mbtiles\n\nYou got it on first try! That's exactly how it works.\nThat's also why there are two job types (pyramid for the world rendering, and list jobs containing list of dirty tiles grouped by proximity).\n\nWould now be a good time to semi-formally organize the documentation for the procedure for rendering the planet as well as the processing limitations?\n\nTotally. The repo is lacking them here. We do not have official documentation how this works so far.\nWould be very happy to accept documentation PRs. \nEDIT: Or perhaps adding it to the wiki is easier.. https://github.com/osm2vectortiles/osm2vectortiles/wiki\nWe explain the concepts in the thesis a bit but not on the level where you can execute it. On a much higher level to pick out only the academic interesting parts.\nMan thanks for your exploring and not giving up!!\n\n. We will try to work on all this issues you file. At the moment we are busy writing the thesis and try to not get distracted too much \ud83d\ude09  But after that we have more time for docs issues on the webpage itself.\n\nHey, see the wiki. I highlighted a bunch of things in bold that are specific to AWS or things I haven't run/tested yet or aren't documented enough for me to jump off from. Hope it's a good start!\n\nExcellent work there. We will extend it.\nI think another thing that stands out is that generating the jobs is too complicated and could be integrated directly into the generate jobs script for example (so you don't have to know about pipecat).\n\nAs I can see it now, I think you're missing the docker container on docker.io for diff updates (it's not documented) as well as for changed-tiles. Also, could you make a dockerfile available for import-osmupdate.sh as that would be the easiest way to keep a PBF updated?\n\nThe Docker import image is reused for all the things. To update the PBF I run docker-compose run import-osm bash import-osmupdate.sh after a successful diff import. You can run bash scripts inside a docker container.\nWe can add a separate docker compose entry so you can run docker-compose run update-osm-pbf or something like that.\n\nWhat are your thoughts on Docker swarm for orchestrating? I'm relatively new to Docker so I'm playing catchup.\n\nI wanted to use it but to managing the hosts was simple enough to do with plain SSH automation as you only have to execute a few docker compose commands to get the worker started and working through\n. Documentation about it is now captured in the  usage guide.\n@stirringhalo What do you think  about close down the initial \"next steps\" wiki page https://github.com/osm2vectortiles/osm2vectortiles/wiki/Next-Steps since all of it is captured in the usage guide?\n. First again thanks for digging into it and putting so much thought into it.\nWe really appreciate the effort. I usually want to merge PR's not decline them.\nAnd excuse the following personal opinions, don't take it personally.\ntldr: This is the wrong approach. \n\nLooking through the issues, I saw a few mentions for a desire to move away from docker due to newbie confusion (and perhaps difficulty in modifying and actually tracking what dependencies are needed for production installs).\n\nThis was always targeted at the tileserver or that people who are serving tiles don't have to use  Docker (since they don't know it).\nBut for the entire workflow we want to stay with Docker. And I know I am speaking on behalf of @manuelroth and @klokan as well.\nFor the entire workflow which consists of so many dependencies and programs Docker is the best thing that happened. Without Docker the installation would be a nightmare, it provides us the utilities to completly isolate the dependencies and makes it much easier to execute compared to Kartotherian or Mapzen Vector tiles where you need to write manual scripts.\nAnd the entire cloud computing space has moved so quickly in the in the last two years towards Docker that this is only confirmed.\n\nIt also doesn't make much sense having a postgres database in a docker container as it isn't something ephemeral and just obfuscates where the actual DB is.\n\nRunning the database in a Docker container is absolutely fine and it scales incredibly well and makes it very easy to scale to many hosts. So many cloud providers do this and at the last companies I worked with we did exactly the same at big scale. And the container might be ephemeral but the volumes mounted to the data directory is not.\nPerhaps some people want to reuse an existing PostGIS DB and I understand that and this is still possible with the workflow by replacing the OSM connection env vars.\n\nI'm not sure what you all prefer to make contributions and development with. Hopefully we switch or the changes are few enough that they can be separated into the standalone bash scripts. I don't mind track the changes and keeping up to date.\n\nI think this is the wrong approach to continue to work on this as part of osm2vectortiles.\nYou are however completely free to do this in a separate repo.\nAgain we appreciate the effort and thoughts here but it is the wrong direction for the osm2vectortiles flow since we are really happy in using Docker in the workflow in the last half year and were always confirmed that it is the right choice by our deployment experiences.\n\n. > What are your thoughts on using \"VOLUME /var/lib/postgresql\" (to have it on direct filesystem) or have some option to connect into an existing backend DB? I realized backups can still be done easily with pg_dump as it is now (thanks!) but in cases of mixed/specialty storage, you might want to put the DB elsewhere other than the container.\nYou're right.\nIn production I mount /var/lib/postgresql to an actual filesystem and separate partition.\nTo do that modify the docker-compose file at the pgdata data container.\nThis way I can do snapshot of disks etc. Working only with data containers can be cumbersome sometime. \n. Great. That slipped through.\nThanks for the PR.\n. Will be happy to do that.\nCan you add the bounding box of Udine to the CSV file and make a PR?\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/create-extracts/city_extracts.tsv \nYou can use this tool to find out the bounding box.\nhttp://tools.geofabrik.de/calc/#type=geofabrik_standard&bbox=5.538062,47.236312,15.371071,54.954937&tab=1&proj=EPSG:4326&places=2\n. > I'd like to see Udine, Italy in cites list. Just admin_level=8\nUdine works now @cascafico. Try it out :)\n. > I realized this may not be the place to ask about tilelive-copy but have you experienced issues with tilelive-copy timing out after 300s?\nThis can indeed happen (even though 300s is a very big timeout). #314 \nThis happens if in 10min zero progress in rendering tiles has been made.\nUsually this has to do with copy operations taking too long due to the sheer volume of queries.\nWhat also helps here is to run less workers sometimes.\nAlso PR #324  is not merged yet - this also helps.\n\nI suspect it's one of those \"complicated\" tiles?\n\nBut actually those are always very problematic areas that have a very specific reason that they timeout (polygons need to be split into smaller ones or other things).\nImage of \"complicated\" tiles (some of them have been solved):\n\n. Hi @cascafico. You should use a tab instead of a space.\n. Extracts uploading..works now with newest Udine upload.\n\n\n. Thanks a lot for this report!\nSince you already solved how about making a pull request to https://github.com/osm2vectortiles/tileserver-gl-light?\nWe would love that!!\n. Great. Thanks for your contribution Stefano.\n. I will use the approach of using a flag in import-sql to split the large polygons explicitly.\nI'll merge this first and then merge master back into #324 and make it work there.\nThanks for contributing \ud83d\ude01 \n. Thanks for digging in!! Great stuff.\n\nThe version of osm2vectortiles I used was a modified fork of your master and your split-polygons branch, ensuring indexes were created for the osm_landuse_split tables and osm_road tables. I had run into trouble getting the split to work properly, so I had manually apply landuse_split_polygon_table.sql, and ensured that landuse.sql and landuse_overlay.sql were correct. The only significant difference between your current master and my import is that I ran the split polygons operation after the layer creation in prepare.sh however that should be of little consequence as they are all views anyways.\n\nMakes sense, I get it.\n\nI've inspected the landusages views and they are all defined as expected. I have 56891 rows in my osm_landuse_split_polygon table using a planet pbf from March 28th.\n\nThat's correct.\n\nI'm not sure how to export all the messages to csv as I do know I have to non-destructively consume them first.\n\nLike this.\npipecat consume results --autoack --non-blocking > results_backup.json\ncat results_backup.json | pipecat publish results\n\nI currently have one worker ticking through the jobs, and it's simply timing out at 1/s, 6hours to completion on zoom level 7 jobs. At the end of export-workers messages mentioning deprecation of minzoom and maxzoom, it sits there as the progress is effectively nil.\n\nTo deal with these problems later one approach is to ensure that workers are timing out fast (this is not configurable yet however - I modified the Python export_remote script to do that). This way you can at least render all the tiles that don't have any problems.\n\nI suspect it's some issue with the intersection grid at the poles as there are substantial distortions at the poles. I think the quote from http://postgis.net/docs/ST_Area.html:\n\nHmm, yes ST_Area is inaccurate at the poles, so no wonder there are many split polygons there. I only had problems with the south pole by the way, north pole worked.\n\nis key and suggests that the geometries must be interpreted as a geography so that ST_AREA will be correctly determined. From what I can tell, doing an st_area(geography(st_transform(geometry,4326))) in landuse_split_polygon_table.sql on line 37 will do the trick but I will test it for you.\n\nSo with this we can avoid slicing polygons that are not huge actually?\nI guess it might be that we now have problems with rendering the poles since the polygon slicing is applied. Last time I rendered I applied the polygon slicing after the poles have been rendered for the most part.\nIf you can give me the tile index that is timing out I can hunt it down in the future.\nThe best way to test it as I found is to choose the local bbox where the problem is and then start figuring out which layer and then go to the cause. It is really nasty with these timeouts. \nThe next thing I will work on regarding timeouts will be #330, I guess there the problem is with the large lake bodies (completly different what we experience here).\n. Sorry for late answers. You're great man.\n\n\nYes! I tested it on features that we a high latitudes (using the y-coord of the centroid to identify them). At high latitudes, it was sometimes a factor of 25 different in the reported area between st_area(geometry) and st_area(geography(st_transform(geometry,4326))), which is extreme but expected. So I think there was substantial over-segmenting. I suspect the UNION ALL with all those features is what's killing it.\n\nUNION ALL should have no performance impact. UNION does.\n\nAs an aside, do you think using materialized views would make a difference and reduce some of the Postgres load? I haven't dug into the specific queries that are made against it but it might make a difference on the more complex layers such as landuse/overlay or roads.\n\nWe use precalculated tables (same as materialized views) to precalculate the centroid for labels.\nThis is worth it if the same geometry is requested over and over again. If it is only request once (when the tile is rendered then precalculating doesn' thelp).\n\nHere's all my failed jobs, almost entirely +/- 60 latitude. There's a few around 40-43 latitude but I suspect those are the known issue tiles from #330 . There also appears to be a failed tile in Mali. I'm using an extended timeout (100000) IIRC so I probably have fewer timed-out jobs.\ndied.txt\n\nThanks.\n\nI suspect it's the now too complicated landuse.sql and landuse_overlay.sql layers. I tested the old view and new view approach and found queries were taking significantly longer (<1s vs 30s or so).\n\nHmm the polygon splitting no longer seems like the silver bullet it once seems. At the moment it look like it makes everything even more complex. By introducing it we know have performance side effects.\nBest way would be to use ST_Subdivide https://blog.cartodb.com/subdivide-all-things/ as @ImreSamu  mentioned. However only works with PostGIS 9.5 - and we can only do this if we ever do a rerender since we need to stick with a DB format if we only want to work with updates.\n\nI identified one issue, the range query in the landuse and landuse_overlay layers is very expensive. If you drop all rows with the area st_area(geography(st_transform(geometry,4326)))>1000000000 from osm_landuse_polygon, osm_landuse_gen0, osm_landuse_gen1 and index on the remainder, you save a factor of 10 from select queries on those views. From 40s down to 4s. I think there could be some enhancements made to the create view selects, but they are unnecessary when the 1000000000 limit exists.\n\nAhh ok. We can get the area already precalculated from imposm3...to speed it up.\nI am open to a completly new approach for dealing with the large polygons (at the moment it feels hacky with this extra table that is only used for the large ones).\n. > Subdivide.sql . Run this after import-osm and before import-sql. A VACUUM ANALYZE is probably needed at the end.\n\nDockerfile for PostGIS 9.5 with GEOS3.5 version to provide ST_SUBDIVIDE . Pgtune was disabled for now.\nI think tuning can be done on how many points to subdivide to, might save some DB time, as well as size of indexes and tables. May influence the size of the MBtiles.\n\nGreat @stirringhalo. You are really digging into this.\nAlso thankful that you got the GEOS3.5 to work - I failed at that.\nThe good thing is that I can import my latest PBF (with the diffs applied) into the new PostGIS 9.5 container to try it out.\nDo you want to create a Pull request/branch then I can try out those changes there?\nAlso I don't want to copy your code and paste it in my name since you did it.\n. > If I ignore the progress reports however and look at the slow tiles as an indicator, I get a similar number of tiles \"processed\" as the inland region in the same ballpark time. So the mbtiles are being truncated somehow . I will parse the output slow tiles better, removing duplicates, so I get a more accurate number.\nSorry that phenomenon is known. In greenland and also at the south pole  certain tiles there is zero data.\nThis means in all layers there is not a single feature. In this case tilelive-copy does not store the tile. That is why you see a \"truncated\" MBTiles.\n\n. > facepalm\n\nMakes perfect sense!\n\nHey man I wasted so much time until I myself found this out.\nI apologize you had to go through the same hoops.\n. > @lukasmartinelli Could you fix my name to Hannes Junnila?\nFixed in https://github.com/osm2vectortiles/osm2vectortiles/commit/7743a9a94073d1555399c2194c71765ef6c684a0. Sorry\n. > From #354, tiles in Greenland process in ~35ms instead of 5s using ST_Subidivide!\n\n\ud83c\udf89 1\n Hide all checks\n\nGreat work @stirringhalo.\nWe made you a core member of OSM2VectorTiles and added you to the organization (you can decline of course). I think you would be a great addition. Welcome and thanks for your engagement.\n\n. > ne_10m_lakes, ne_50m_lakes and ne_110m_lakes don't need to be split. Largest feature is 2604 points at 10m. Also the NE lake tables has a name column which I think is being used, so subdividing may break labels\nGood that NE is not the problem. I guess in osm_water_polygon there might be huge areas as well.\n\nFurther benchmark numbers comparing ST_Subdivided to non, using a BBOX region with -25.5,79.6871841545,-21.09375,79.9359182463\", 0 -> 14. This is with \"slow\" on so I could track it's progress on individual tiles. Not quite a full oranges to oranges comparison as ST_Subdivide had Postgres 9.5 while non used 9.4. Timeouts were disabled.\n\nSeems like ST_Subdivide does have an impact. It is very good that we now have data to verify that.\nJust give me a go with this branch and I will do a world reimport.\n\nNote to self, need to SetSRID otherwise layer-specific views fail\n Hide all checks\n\nSo the SRID gets lost after subdividing?\n. > I see that #171 references a different PGTune approach that supports 9.5. Will look into this at some point.\n\nHide all checks\n\nFor me that is not necessary yet since I tune it for production anyways. We can merge it without. It was a nice to use though since most users wouldn't tune the DB otherwise.\nI am now testing this branch on https://github.com/osm2vectortiles/osm2vectortiles/tree/new-import-v3.\nDoing a new import and will try to render the recent changed tiles with this.\nHave a bit more time at hands to look at all the awesome stuff you were up to @stirringhalo (fell a bit short sorry).\n. > my proposal for the new pgtune : https://github.com/osm2vectortiles/pgtune\n\n( it is clean and simple code - for me )\nIf no other better solution - I will try to customize ..\n\nGood \ud83d\udc4d  If it works similar/same to https://github.com/osm2vectortiles/osm2vectortiles/pull/171/files that would be perfect.\n. Import takes 19hrs now with all the additional stuff we currently have. Quite increased since when we started.\nAnd import-sql with splitting and indizes takes another 0.5hr.\nWill export Greenland and Delaware (and the large national park at Chile) as test.\nOther problem areas for testing @stirringhalo?\n\nleft=-94.4 bottom=40.16 right=-77.61 top=49.45\n\nleft=-77.36 bottom=-56.78 right=-66 top=-45.45\n\nleft=-77.98 bottom=74.58 right=-2.89 top=84.3\n. Greenland export running since 21 hours without timeout (11hrs left)... good work @stirringhalo.\nOnce it is finished I need to examine it visually. Have you already checked how the tiles look @stirringhalo whether there are perhaps glitches due to subdividing ?\n. > Greenland export running since 21 hours without timeout (11hrs left)... good work @stirringhalo.\nNo was the Delaware export. This export previously always failed but now it ran through in 1d and 7h and exported 588.9k tiles. Thanks @stirringhalo this PR really seems to help a lot.\nThis means we now recovered the most important part of missing data in #330.\nSo performance wise this PR is absolutely fine! \ud83d\udc4d \n. > Awesome! Very thrilled to hear that. I should have a good chunk of my import completed Monday/Tuesday. Have you been able to do a visual inspection yet?\nYou can check it out here. (Just run docker-compose up -d compare-visual).\nLooks good to me.\nhttp://104.196.100.205/#13.97/42.3352/-83.0514\n. > @lukasmartinelli , question, any further timed out tiles or has this fix managed to remedy them all?\nThis was the uber fix. Changed some things however and made a new PR #367. Once this one is merged we can resolve this as well.\n. > If you grep the logs for slow tiles, you can see that nearly the same number of tiles are handled in the same amount of time. In-fact, if you raise the timeout threshold to allow the process to complete for the coastal region it will jump from ~2% to 100% after some time, exit cleanly and claim it successfully wrote to disk without actually doing so. Only the first 138 (~1-2%) tiles get written to MBTiles.\nDue to the reason with zero tiles mentioned in #350. Or at least I strongly suspect so.\n. > Yep, zero tiles still time it out as there's been no progress adding to mbtiles. Setting a slow timeout threshold, you can see if happen while tiles are still being processed as indicated by \"slow\".\nThat makes sense, no tiles recorded - no progress recorded and then a failure is reported even though everything is fine. Thanks for clarifying. It is kind of a weird edge case in tilelive-copy.\nIn earlier version we used tl copy from https://github.com/mojodna/tl which deals differently (it does store empty tiles and does not time out but seems to be slower). Perhaps I will do a switch back for pyramid jobs.\n\nSuggest the timeout gets axed for now unless we still run into the issue again later. Or at least set it very high.\n\nLet's set the timeout to something like 20 minutes.\n. > According to conventional common name of the US GENC and Unicode CLDR.\nOk I trust you in this.\n. > Currently shield seems always 'default', where mapbox has a detailed list of shield determined by some rules.\nYes we thought about that. @manuelroth has invested some time and decided that it was too resource intensive with too little gain for us to do it.\nHowever we are of course open to a PR.\nThe rules are actually quite obscure here from what I remember. But if you find a way to map these three attributes to shield-name please share. The only information we are lacking in the DB is the country information now (but we can pull this in from NaturalEarth if required).\n. Due to the licensing issues we'll not support the shield names. The shield thing is also something that is in Mapbox Streets style (not in necessarily in OSM Bright).\nHowever adding OSM iso field / or just the country the road is in to the vector schema is something i will consider for v3.\nHowever there is usually no iso value on the roads themselves directly right?\nThen we must do a query to check in which country the road is in and use the iso value of the country.\n. > POI labels: the name field of the poi_label layer may be null\n\n(in v6, nameless POIs were not included). \nNameless POIs will have never have a maki value of marker (the generic default).\n\nTrue.. size impact should be small since its only points (and names fields take usually space which are NULL now). Would also be included in the localrank algorithm (unnamed POIs are less important).\nI can remove it in the test import I'm doing for #352\n. Thanks for the detailed research. Ugly that we have to correct obsolete OSM mappings but ok.\nWe can do another schema import if we rerender for #326 so v1 is possible. \n\nimposm3 - capital string mapping [ type: string ]\nre-mapping : ~ IF capital='yes' THEN capital='2'\n\nWhat I don't like is that we then have to turn the string capital into a int for all other capital levels.\nWhat about this mapping?:\nyaml\n- name: capital\n  type: int\n  key: capital\n- name: is_capital\n  type: bool\n  key: capital\nAnd then do CASE WHEN is_capital THEN 2 ELSE capital\n. > Disabling normal-mode can save some significant time from imposm (13hrs vs 6.5hrs in one case). For some people who may not be following latest changesets (or do so irregularly where it might be best just to do a full reimport), this gives the option for a faster first import.\nYes having it explicitly is a fine idea @stirringhalo .\nWas afraid if I make it by default people will be confused when the entire part about the changed tiles doesn't work. But this way you can enable it explicitly.\nIf the Travis build succeeds you can merge it yourself into master. (Do you have access to do that yet?).\nBTW since you are a member of OSM2VectorTiles you can now create branches like this directly on the main repo (has the advantage that the other members can improve the proposed changes directly on the repo here).\n. > Not sure, as #352 fails Travis and this one hasn't completed yet!\nFine. Will fix it in post if it is something :)\n\nVery true, but I don't seem to be able to? First time part of a larger organization. Editing files on osm2vectortiles forces it to a branch of my own repository. I can create a repository as part of osm2vectortiles but I don't have write access to any existing repos.\n Hide all checks\n\nUuups didn't add you to the repo.\nYou now should have write access.\nOn your repo:\ngit remote remove origin\ngit remote add origin git@github.com:osm2vectortiles/osm2vectortiles.git\ngit push.. #the branch you want to push up\n. Huups that was a bit too fast :)\nImproved it in https://github.com/osm2vectortiles/osm2vectortiles/pull/362.  It shouldn't be part of the tool  but part of the process to generate the world job.\nThis way generate_jobs.py still can be used as standalone tool.\nNow if you execute docker-compose run generate-jobs the world tile is put into the job queue as well. (and as first job) \n. > I remember there was a mapping table showing which layers are included in Osm2vectortiles. I can't find it anymore. Does it still exist somewhere?\nJust one list with all the layers? Single source of truth would be to look in the tm2source.\nBut here you have what the TileJSON specifies (as seen by Mapbox Studio).\nBut there is also a chapter about layers in the bachelor thesis for example  (Chapter 8.2 Database and Layer Schema) https://github.com/osm2vectortiles/bachelor-thesis/blob/master/thesis.pdf\n\n\n\n\n\n. > That's where I looked (in Mapbox Studio) but I couldn't find landuse=residential, which should be available as of #307.\nIt should be in the landuse layer.\n\nOk, I understood now how this works. A little difficult to find out, the zoom levels for each layer.\n\nYes. A one size fits all diagram :/\n. I want this merged for the rerendering #368. Tested this on small scale.\n. > I have started analyze the new version:\nGreat\n\ndifferent numbers of (count( distinct osm_id )) / views ---> need more research:\n\nWe have a lot more unnamed POIs  now #357.\n\nexample landuse_z9\n\nThis makes sense due to the subdividing.\n. Good it is in z5 so it doesn't affect the worker rendering.\n. > proposed code .. and don't know the correct number ... so please replace the 20101001 value ...\nAddressed that in https://github.com/osm2vectortiles/osm2vectortiles/commit/9090f93a838e52f358daf4c9e5b9ce48f2a7dbc1\n\nDifferences exists , but, the new data is better and consistent.\n\nThanks for the grunt work to find that out!!\n. Don't quite understand it yet :)\nThis is primarily to compare how the DB contents change between two commits?\n\n(temporary) Added TEST reports for `switzerland-160601\n\nok good. but before we merge it we must do a history rewrite to remove the big text files again.\n. > @clintharris Thanks for the report, I am working on a fix for the bug. Also enabled the issues section on the tileserver-gl-light repository.\nFixed it @manuelroth. https://github.com/osm2vectortiles/tileserver-gl-light/commit/28112f01dc4e126340c49414d34f90a9bccde2bf\n. I get it now. Since we need to recreate the derived tables (like subdivided polygons) we need to drop the views that need them and that is why you have to recreate them with import-sql.\nHowever for me this does not pose a big problem and I would leave it like that - or the import step gets even more complicated as it is now.\n. Added it myself in https://github.com/osm2vectortiles/osm2vectortiles/commit/14afd398781aea3e92280a968aeaf2238c8cbcbb since and fixed the spaces/tabs thing. Hope that is ok.\n. If everything else fails.\n```\ndocker-compose stop\ndocker-compose rm -v\ndocker-compose pull\nthis ensures you have latest - even though you should already get them with pull\nmake\ncontinue import process from scratch\n```\n. > If you follow the getting started guide, you end up with a map which doesn't display anything. It shows 404s for all pbf requests.\nMissed the low zoom level extract in my recent #368 upload.\n\nOn my latest build (which I haven't confirmed visually), the lower jobs get added as a job to be processed\n\nThat's true but this jobs times out because it takes more than 2hrs.\nStill have to kick off the low zoom levels manually for the planet.\n. > In order of Importance I have added these cities to city_extracts.tsv\nThanks @mbrickn and congrats to your first PR!\nYou did spaces instead of tabs but I will correct this directly in master afterwards since this is the first PR.\n. > MD5 is not correct for planet.mbtiles, after/during update\nYeah always need to update the md5 in the future.\n\nUpdate of the planet is not atomic (link on the website points to a file which is being uploaded) so people downloading in the same moment never get a correct file\n\nPreserving old planets cost money but I think it is still worth the tradeoff.\nKeep old versions of the planet around (but not of the extracts).\nSo process for the future (sadly already didn't follow this when I was reuploading the missing 500 z8 pyramids from #380 before):\n1. Always give a distinct name of the planet file (add date?).\n2. Calc md5 - add to web page\n3. Regenerate extracts\n. > This way a user which has downloaded the planet file knows how current the planetfile is (date) and directly has the md5 hash to verify the file. Secondly, we don't have to update the md5 hash on the website on every upload anymore, because we can extract the hash programmatically based on the filename \ud83c\udf89\nGood idea for the planet. Will start using this.\n\nIs there a convention around using minus (-) or underline (_) as filename separator?- Thinking about harmonizing the filenames of the city and country extracts. Some of them use both (minus and underline) in their filename like the following: v2.0/extracts/mountain-view_california.mbtiles. I think we should decide on one.\n\n- means space (mountain-view -> Mountain View).\n_ is the separator that separates the city from the region/country (originating from Metro extracts)\n\n@lukasmartinelli what do you think about this?- The create-extract.py script would probably need to be modified to take the planet filename as argument. So that it is possible to assign a different filename on each upload of the planet file.\n\nI usually rename the file before doing it but adding a env var is easy.\n\nCouldn't find the code which uploads the planet file and planet zoom levels, is this done manually right now?\n\nOnly planet is uploaded manually. Low zoom level extracts are automated (https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/create-extracts/create-extracts.sh).\n. @ImreSamu The definition would be that when the planet file changes all extracts change as well. Cron script could actually detect the update date from the S3 bucket but that is not perfect.\nI now use the new naming schema https://github.com/osm2vectortiles/osm2vectortiles/commit/8b613f1b4709889cfdf26ef70fafd34ad76dbc5e (and date and md5sum are derived from it) on http://osm2vectortiles.org/downloads/.\n\nMD5 is not correct for planet.mbtiles, after/during update\nUpdate of the planet is not atomic (link on the website points to a file which is being uploaded) so people downloading in the same moment never get a correct file\n\nThis is now solved since the link is atomic now.\nLinks to the planet and low zoom level extracts.\nThe low zoom level extracts always contain the md5sum of the planet file they were derived form.\ns3://osm2vectortiles-downloads/v2.0/planet_2016-06-20_7088ce06a738dcb3104c769adc11ac2c_z0-z14.mbtiles\ns3://osm2vectortiles-downloads/v2.0/planet_2016-06-20_7088ce06a738dcb3104c769adc11ac2c_z0-z5.mbtiles\ns3://osm2vectortiles-downloads/v2.0/planet_2016-06-20_7088ce06a738dcb3104c769adc11ac2c_z0-z8.mbtiles\nI also deleted the previous planet file that has no md5sum in it (I know this now breaks the link for people but otherwise they would always get the old version).\n\nWe have 2 dates/timestamps\nosm planet last modifications timestamp ( this is sometimes important for debugging, because the osm database is changing , for example XXX POI is changed before or after ???? )\nit is like \"OSM Data from: 2016-07-27 00:58 UTC\"\nmbtiles generating date/timestamp ( = Last modified ) when the generating process finished, so this is a technical info - but also important for debugging\n\n@ImreSamu We should open a separate issue for that. I think adding metadata to the MBTiles is a good solution (we could even embed the information from the osm_timestamp table)\n. Will take care of it as soon as I get to it. Just have too many fires burning currently.\nWe had this problem too many times (my fault!). The process needs to change and improve that this doesn't happen again.\nWill verify the planet file for missing tiles and then regenerate them.\nThanks for the patience.\n. > Here's a quick and dirty checker of an mbtiles (https://github.com/stirringhalo/missingtiles).\nCool (good usage of Pythons sets)! Have something similar in mbtoolbox https://github.com/lukasmartinelli/mbtoolbox/blob/master/mbtoolbox/verify.py\nProblem is the merge process (the reduce step of 65k MBTiles)...\n. Ok primary reason was that the merge jobs didn't actually read all jobs from RabbitMQ. Missed those before the holidays.\nNow merged the 500 z8 pyramids into it. 200 z8 pyramids are still missing but this a improvement.\n\ntiling (but no optimize) -> merge -> test (re-tile missing if no) -> optimize -> planet.mbtiles\n\nMakes sense. A word about optimizing.. actually optimizing happens at the stage of one single z8 pyramid because optimizing the entire planet file takes too long (looking at 350m tiles in a sqlite db..).\nWill also regenerate the extracts now.\nI hope this will solve missing extracts problem like #385.\nI am now exporting the remaining 200 missing z8 pyramids.\n. I have updated the planet file (and now using the naming schema from #379). Already updated the city extracts - countries follow now.\nI rerendered all missing z8 jobs so there should be no data missing (most of it was in US/Canada). What is missing is that around 100 z8 tile pyramids (most of which are exactly the ones where data was missing) are still v1 MVT spec #388 (will be fixed in a later update).\nI no longer see errors for Stockholm and Amsterdam now. But I am not sure whether this had to do with this issue because they were z9 data and in Europe we never had data problems..\nA quick note however. That a z8 tile does not exist in the planet file does not necessarily mean that an error happened. There are like 10k tiles (at south pole) where there is simply zero data at zoom level 8 and that is why there is no tile.\n. > I wanna make an offline tile server for intranet and want tile of iran in 0 to 19 zooms\nI really like the idea!!! Hope you can make some progress.\nThanks @klokan for answering.\n. Thanks @stirringhalo @klokan \n\nIt seems that a fair number of messages are unacknowledged despite heartbeat being disabled.\n\nYes it is a real problem. And in the end causing missing tiles.\nIf you disable the heartbeat you have messages that are forever in the \"pending\" state if workers fail. Those are the \"fair number of messages are unacknowledged despite heartbeat being disabled.\"\nIf you enable it you will have jobs that time out and will never finish.\n\nI have recommended this to @lukasmartinelli as well, but it did not make it to the project before the bachelor thesis was finished. He started to work on it ...\n\nI actually had a branch with beanstalkd as message queue. Even tried it out but it didn't bring the immediate benefits i wanted (but probably fault on my side).\n\nWhat's the best way to requeue those unack'd messaged? Kill all the connections in RabbitMQ and startup the cluster again?\n\nTried that before.\n\nDon't use (patched) RabbitMQ - use instead a true job queue, like Beanstalkd - for example via https://github.com/klokantech/cloudwrapper\n\nIn the defense of RabbitMQ :) \nIt is actually a fault at application level (even though I think RabbitMQ shouldn't be so strict). The application level should continuously call the send_events call to confirm that is still working. Problem is that we call the tilelive subprocess and then just block.\nBetter would be to have the subprocess and consumer in different threads (but then it get's complicated again..).\nHow to proceed\n2 alternatives.\nFix RabbitMQ process\nPros:\n- Components still work\n- I really like working with the pipe tools to administer the jobs\nCons:\n- In the end it will be a hacky solution\n- A lot of time has already been spent solving this problem - perhaps dead end\nDifferent job queue -> beanstalkd\nPros:\n- Solving the timeout thing once and for all\nCons:\n- Rewrite merge-jobs, generate-jobs and export-worker\nOption 2  is more feasible now than earlier because now I have no deadline of finishing up the thesis. And can invest time in stuff like this.\nI know @klokan is for option 2 as well.\n. > It's working as expected, no unacknowledged messages generated. I'd typically see them when starting a new worker. At the end, there would always be one job missing for each worker on the (mock-)S3 storage.\nBut now we loose the job when for example a tile timeout happens (can still happen in tilelive from time to time even though we use your great subdivided polygons)?\nThat's what I am a bit afraid of.\n. Great. Reuploaded the countries from latest planet.\n. Fixed in https://github.com/osm2vectortiles/osm2vectortiles/commit/511add4a74278c52bf1f8e135743af998803c40e.\nThanks for the suggestion @ratrun.\n. We respect Mapbox and are very thankful for your open source projects that push mapping forward and make a project like OSM2VectorTiles possible. \nWe have pursued this Open Source university project as part of our degree with the high level goal to allow anyone to create his own beautiful base map.\nWe do not agree that our own implementation is a copy of Mapbox Streets.\nTo enable people to get started to design their own map we try to create vector tiles that make the BSD licensed OSM Bright look as good as possible, so people can start their own design on top of it. OSM2VectorTiles contains no copied data from Mapbox.\nPlease point us to the copyright infringing parts of the source code or copied parts of a vector tile and we will be happy to remove it.\n. We want to work together with Mapbox to find a solution since we really appreciate how Mapbox pushes mapping forward by releasing these amazing OSS and projects and don\u2019t want to be a bad example how OSS can end in conflicts.\nBut we absolutely need concrete technical details from Mapbox to implement changes on our side.\nWe propose an altered vector tile schema that makes OSM Bright look good but breaks compatibility with Mapbox Streets - see the ticket #393.\nPlease, could Mapbox outline what attributes are critical for the proposal to be accepted?\nWe will then fork OSM-Bright GL style and adapt it to the new proposed vector tile schema.\nWe don\u2019t plan to stay compatible with Mapbox Streets vector tiles in the future and with more and more feature requests coming from the community we are already drifting away from it. But we are also not willing to start from scratch again since our initial OSM Bright vector source implementation and the following changes is all our original work.\n. > I think that's the right direction. And then let's check in at State of the Map.\nYes let's definitely meet at State of the Map and talk in person. But I want to reach a solution before that, it is still not clear what needs to be done so we can resolve this discussion.\nAlso thanks for the intelligent problem summaries to @timdorr, @hyperknot, @pathmapper.\n\nThis goes beyond the schema though. For example, https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-external/seas.geojson appears largely copied from Mapbox Streets, including the choice of point vs. line features, the placement of label arcs, etc. Take a look at the file in geojson.io.\n\nThanks for this good example of an actionable concrete claim. I would like more claims like these since these are problems we can solve.\nHowever for the seas we took extra care to not violate copyrights, all the linestrings were drawn by myself in manual labor. More details in #394.\n\nThat said, I am appreciative of where you are headed (and I think several others on this thread have expressed support for or described the starts of similar efforts). So let me suggest the following:\n\nIf you ask for a change in future direction we are very glad to do that and will take care of denying feature requests that have to do with MB Streets like #359 and break compatibility in future schema changes. And by continuously improving OSM2VectorTiles we will move away from MB Streets naturally.\nI politely disagree with the painter analogy for vector tiles.\nFor actions right now we need concrete details (like for the seas). Neither an exact part of the source code nor exact part of a vector tiles or the schema has been identified yet.\n. ## Meeting Summary\nSummary of the meeting at SOTM with Michael Steffen (Mapbox), Stefan Keller (HSR), Lukas Martinelli (HSR) and Petr Pridal (Klokan Technologies)\nThe core of the problem is that OSM2VectorTiles replicates the cartographical decisions made in designing latest Mapbox vector tiles.\nThere is no problem with other parts of the project - such as use of Mapbox open-source software, Mapbox GL styling language, Mapbox Vector Tile format, use of openly licensed JSON styles (Bright and Basic) or openly licensed TM2 styles in this project.\nWe suggested to remove everything from our vector tiles that is not part of the openly licenced CartoCSS based OSM Bright and Natural Earth TM2.\nHowever we have been asked to start from scratch again instead of removing code. This approach doesn\u2019t bring any benefits for us and if we have to start from scratch we want to work on a cartography that has nothing to do with Mapbox to avoid future claims.\nNext Actions\nTherefore we are now evaluating existing open projects such as Mapzen Vector Tiles, Carto Basemaps and ClearTables to make the right decision for future - and continue to deliver to the community the downloadable and directly usable vector tiles from OpenStreetMap.\nCreating a new schema causes huge additional efforts for us and  forces us to put in many additional hours on top of the hundreds of hours we already put into this project for free.\nBut we are committed to work on a new v3.0 with new vector tile schema free of the legal issues and hope to publish it until the end of this year.\n. \nWe are closing the downloads and maintenance of OSM2VectorTiles to resolve the legal problems mentioned in this ticket.\nTo support existing OSM2VectorTiles users we collaborated with Klokan Technologies and Wikimedia to develop a new vector tile schema  called OpenMapTiles from the ground up.\nPlease switch to the successor project https://openmaptiles.org if you are using OSM2VectorTiles in production to resolve your legal issues.\nThanks for the patience and collaboration in this matter to both Mapbox and the community.. Thanks @efi and @iamvdo \nOk I found the reason.  The master node in the cluster didn't have the latest Docker image and therefore rendered the layers from z0 to z8 in v1 spec and all the jobs it got assigned.\nI wrote a script that iterated through all z8 tiles and checks whether it is v1 or v2 spec (if it is v1 spec this means the entire subpyramid is v1 and that it has been rendered by the bad node).\nI will now reschedule those jobs to rerender with the latest export image.\nBy replacing z0 to z8 with v2 spec most people will never see this warning but there are still 111 tiles that are in v1 spec if we don't take action.\nWill inform you guys back in this issue when the planet is available again.\nThe v1 111 tiles is the only thing missing now.\n. The new planet 3d4cb571d3d0d828d230aac185281e97 with replaced v1 spec pyramids is uploaded. We can also put this on the CDN.\nhttps://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v2.0/planet_2016-06-20_3d4cb571d3d0d828d230aac185281e97_z0-z14.mbtiles\nMore details about what was done to replace the v1 tiles can be found in #380.\n. > The new planet 3d4cb571d3d0d828d230aac185281e97 with replaced v1 spec pyramids is uploaded. We can also put this on the CDN.\nIs the CDN already updated @klokan ?\n. Thanks @resluc14. Pretty sure this is a style related thing though since parks are visible in both OSM Bright and OSM Liberty. What styles are you using.\n. Implemented - for the next release. Actually the landuse=reservoir should also be tagged natural=water then it would already be rendered. So it is a tagging mistake we need to handle (that happens pretty often).\n\nThe VectorTiles should reflect this tag usage and (maybe unless covered=yes is present) treat this similar to a normal lake.\n\nI exclude covered reservoirs.\n. > Just a quick follow-up: there is of course no flicker when landuse_overlay_national_park gets a fill-opacity of 1 - then all competing triangles result in the same color & no flickering occurs. - so this can be used as a hack to make things visually pleasing - but I guess the core issues of overlap in one and the same layers is more fundamental.\nThe problem is that some polygons are both in nature_reserve and in nature_reserve style layer in Mapbox GL OSM Bright? That can be solved by adjusting the filters in the style I guess.\nOr are some features like parks present both in landuse and landuse_overlay?\n. > Why the removal of the layers? Will those features be in a different layer?\ntldr: This is more about restructuring the data like we had it before Streets v7 (in release last december)\nWe could either go broad with the layers (and add many specialized ones) or have only a few and people can then do the filtering of the style (approach by MB Streets).\nFor example #airport_label is still very important but fits into the #poi_layer just as well (in fact half a year back we had it like that). And #rail_station_label is too limiting, the default imposm3 mapping for example contains a #transport_poi_label which would contain all transport POI for special styling (i like that idea).\n#motorway_junction is a special case. It was directly suggested in order because it is in Mapbox Streets and not in ours #359. That is really something that is not needed in OSM Bright and only there because of MB Streets. That's why remove it.\n#mountain_peak could move back into POI or we start thinking about a landmark layer (there are other special landmarks not only mountain peaks). No longer so sure about this one.\nThese are layers that are not yet widely used in styles so we have the flexibility to restructure them.\n. > The diff doesn't show plans to add airports to the #poi_layer. Can you add these details so we can evaluate the changes?\nYes you are right. I just created a map style and #railway_station_labeland #mountain_peak_label, #airport_label do make sense in their separate layers (although the could be more general, your landform_point suggestion is a very good idea and a layer like #transport_poi could be another idea).\nFor a real discussion what needs to be changed for actual improvement (not just artificial crippling of compatibility) we first need to look at the current schema.\nThe copyright claims we have from #387 are the following abstract terms.\n- multiple possible data sources for different features\n- the particular selection of elements to incorporate from those sources\n- our tagging schemes and arrangement of the data elements\n- label placement methods\n- decisions about prominence\n- use of features at different zoom levels\n- iconography decisions\n- ranking of features\nHowever I struggle to apply these as copyrightable problems to the schema and layers below...\nWe always iterated with a visual map of OSM Bright based on MB Streets and improved the OSM2VectorTiles schema until the map OSM Bright based on OSM2VectorTiles looked good compared to the original OSM bright.\nI would really like to have feedback in #387 what layers or attributes are a problem.\nCurrent Schema\nThe current schema look like this. The notation is invented and derived from CartoCSS (#layer and [attribute]. What I removed in the proposal above are layers and features that are not needed to display BSD OSM Bright style.\n``` css\nadmin\n[admin_level]\n  [disputed]\n  [maritime]\naeroway\n[type]\nairport_label\n[maki]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\n  [ref]\n  [scalerank]\nbarrier_line\n[class]\nbuilding\n[underground]\ncountry_label\n[code]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\n  [scalerank]\nhousenum_label\n[house_num]\nlanduse\n[class]\n  [type]\nlanduse_overlay\n[class]\n  [type]\nmarine_label\n[labelrank]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\n  [placement]\nmountain_peak_label\n[elevation_ft]\n  [elevation_m]\n  [maki]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\nplace_label\n[capital]\n  [ldir]\n  [localrank]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\n  [scalerank]\n  [type]\npoi_label\n[localrank]\n  [maki]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\n  [ref]\n  [scalerank]\n  [type]\nrail_station_label\n[maki]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\n  [network]\nroad\n[class]\n  [oneway]\n  [structure]\n  [type]\nroad_label\n[class]\n  [len]\n  [localrank]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\n  [ref]\n  [reflen]\n  [shield]\nstate_label\n[abbr]\n  [area]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\nwater_label\n[area]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\nwaterway\n[class]\n  [type]\nwaterway_label\n[class]\n  [name]\n  [name_de]\n  [name_en]\n  [name_es]\n  [name_fr]\n  [name_ru]\n  [name_zh]\n  [type]\n```\n. > seas.geojson was introduced in 3b1b4f9 by @lukasmartinelli and may be based on an earlier marine.sql file in 6531e88. The contents of this file appear to be OSM-derived, and there used to be code which used OSM data for marine labels.\nRegarding the claim of #387. This is how it was done.\n1. Overpass query\n```\n[out:json][timeout:25];\n// gather results\n(\n  node\"place\"=\"ocean\";\n  node\"place\"=\"sea\";\n);\n// print results\nout body;\n\n;\nout skel qt;\n```\n1. Export GeoJSON\n2. And then I sat down 3-4 hours and drew lines for the marine labels myself!!. That was really boring manual labor I did there just to have good marine lines without copying anything.\n3. I even hunted for some translations in Wikipedia for some of the seas/lakes\nseas.geojson being osm-derived and ODbL, its license needs to be stated somewhere. I recommend putting a file in src/import-external stating the license and source of all the files there.\n\nDon't you think that is already covered within Data Downloads? In the README\n\nThe project is under the MIT license while the data downloads use the Open Database License from OpenStreetMap.\n\nEDIT: Ah ok we also use openstreetmapdata.com which where we need to state the license.\n. Thanks @roblight . Okay that's a parsing fail. I actually try to parse the date from the file now.\nSometihng is wrong in the JS that replaces the date.\n``` javascript\nvar planetUrl = planetDownload.value;\nvar segments = planetUrl.split('_').reverse();\nvar hash = segments[1];\nvar date = segments[2];\nvar dateSegments = date.split('-');\nvar planetRenderDate = new Date(dateSegments[0], dateSegments[1], dateSegments[2]);\ndocument.querySelector(\"#md5sum\").innerHTML = hash;\ndocument.querySelector(\"#timestamp\").innerHTML = planetRenderDate.toLocaleDateString();\n```\n. > Does this mean the latest planet file is 6/20/2016? I seem to recall the last planet download I did had a date around 7/14/2016. Thanks again!\nIt displayed  7/14/2016 because it was reuploaded at that day (with MVT v2 support) - now we display the actual render date (well as reported it still has a big) which is 6/20/2016.\nWill soon render the updates for  the last 2 months. We were busy fixing MVT 2 problems so far.\n. > Cool, thanks for the info. Does the date in the filename correspond to the OSM source data as found on planet.openstreetmap.org?\nYes it is directly the date that is found in the PBF of the imported planet file (or the last diff that was applied).\n. Fixed. The month in a Javascript Date object is zero based \ud83d\udc4a \ud83d\ude06 \n\n. Thanks for the report @romanshuvalov. You start running into this when tweaking the imposm schema (I guess this is what you are doing?).\nBecause we create views in import-sql that depend on the table that are imported in import-osm then imposm3 can no longer delete the tables (it doesn't do a cascading delete).\nHow we solved that in the end is by deleting the tables with cascade before imposm3.\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-osm/import.sh#L139. The info for what tables to delete comes from here https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-sql/tables.yml.\nHowever i just patched imposm3 to do cascade deleting and let imposm3 do that in the new fix in #398. This should prevent similar problems in the future.\n. > ERROR:  invalid input syntax for type timestamp: \"(invalid timestamp)\"\n\nLINE 1: DELETE FROM osm_timestamps WHERE timestamp='(invalid timesta...\n\nI think this comes from a invalid timestamp in the PBF file you import.\ntimestamp=(invalid timestamp).\nWhat PBF file are you importing?\n. > GIS-Lab OSM Dumps (direct link to PBF I used: RU-SAM.osm.pbf). This is popular resource, it contains extracts of Russian regions and xUSSR countries. Reliable source, I used that dumps many times for rendering raster maps.\nI only know the planet and Geofabrik extracts have it set. I will test whether osmconvert \"RU-SAM.osm.pbf\" --out-timestamp will work.\n. > 've modified your draft-fix, instead of slow osmium fileinfo method I simply use current time:\n\nimport.sh, line 68\n\nYou need a correct timestamp if you ever want to apply diff updates (most people will never do however). \nI think this could be the last fallback - if the osmium fileinfo doesn't work. But if it is possible in a reasonable amount of time I would prefer osmium fileinfo. \nBut at least you have a workaround now until @ImreSamu will apply the osmium fileinfo patch (not urgent at all).\nThanks @ImreSamu  and @romanshuvalov for digging into it!! \u2764\ufe0f \n. > france-latest.osm.pbf (3.2 GB) ~ 6 minutes ( on my machine )\nCompared to an import of 1hour or so I guess? I think better it takes a bit longer but then is consistent at least.\nThis will scan through the entire PBF file right?\nYou can decide @ImreSamu whether you want to do osmium fileinfo or just the latest timestamp if we don't find one in the PBF. I'll reopen this issue for this problem.\n. BTW. @stirringhalo what was the reason that we subdivide the ocean polygons as well? (according to OpenStreetMap data they should already be split).\n. Perhaps it makes sense to have a separate vector tile set just for sea map data?\nYou also don't need to scale it across multiple hosts if you don't need the expensive queries we do and limit yourself to z13 - i did something similar here https://github.com/lukasmartinelli/osm-noise-pollution.\nOr if we want that in OSM2VectorTiles you first have to pick the tags that you want in the map.\nAnd then add those to the imposm3 mapping here:  https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-osm/mapping.yml\nAnd then you can use it in the tm2source. (or use zoom level views in import-sql).\n. > I am one of the developers of OpenSeaMap. We are currently working on a new map interface: https://github.com/aAXEe/online_chart_ol3\n\nIt uses OpenLayers3 and traditional raster tiles until now. But switching to vector tiles would be very nice.\n\nYou can also use it just as baselayer.\n\nI would prefer to add the seamark data in the main tiles .. the additional data is not that much as most of the seamarks are simple nodes with some tags. \nOn the other hand we love to deliver map updates within minutes ... it is great for (osm) contributors to see their changes quickly on the map. Having a separate set can enable that, can't it?\n\nIf you have a separate vector set and care about displaying immediate updates I suggest you render vector tiles on the fly.\nOr if you store the features on low enough zoom levels (<10) you can also regenerate all tiles each hour.\n\nThe hard part of the map is the rendering of the symbols. There are tons of different symbols. Especially the lights are hard to get right: https://alpha.openseamap.org/#/?lat=54.1820&lon=12.0808&zoom=15&layers=A10001\nHave a look at our current tile-renderer (written in C): https://github.com/OpenSeaMap/renderer/blob/master/searender/rules.c\nAs I am not familiar with the rendering I do not know how difficult it is to get this things rendered in OpenGL. Do you have an idea?\n\nBut these symbols are quite important for you right? More complicated symbols are tricky (and you  will need to draw SVGs). If you put a lot of time into making the symbols this is a bit sad.\n. I set up a starting point on this repo for you here: https://github.com/osm2vectortiles/openseamap-skeleton. This should all suffice to generate vector tiles.\nYou will need to begin with defining the OSM tags you want in your database (well you could also import every seamark anyway but explicit makes it easier later to create good layers).\nAnd then you can write the SQL queries in Mapbox Studio (also bundled in the skeleton).\nIf you want to work on your custom vector tiles we transfer that project over to your Open Sea Map organization and you can treat it as you like.\n. > I'm inspecting the code to understand how it works.\n\nEverything is quite clear, but I can't find line where geometry is cut (subdivided) into parts to fit tiles. I was looking for something like ST_Subdivide or ST_Split, but only found initial subdivisions of oceans. That's not that I was looking for.\ntm2source only contains WHERE geometry && !bbox! clause to pick only objects related to tile but it does not split lines and polygons by edges of tile.\nI'm assuming tilelive-copy do it internally, is that right?\n\nThis is all Mapnik. We just give it the geometries within the BBOX it requests (!bbox!).\nWhy we subdivide the tiles is that we don't ship gigabytes of data to Mapnik it does not need (because we always send back all polygons that touch the bounding box).\nYou can also return everything (by not having a WHERE bbox clause) and then Mapnik will just throw everything away that is not in that tile (inefficient but good as example).\n. > So, in this project, tilelive internally uses mapnik functionality to do this job, right?\nExactly. Tilelive is just a wrapper around Mapnik (well with a lot of less important steps between).\n. Thanks @pnorman. Forgot about it.\n. Thanks @efi.\n\nI have encountered a rather strange missing road here: http://www.openstreetmap.org/node/2365418708 near \"Esbach\", near \"Herrieden\", near \"Ansbach\", Germany. I have no idea if this occurs more often. Is this a data-conversion bug?\n\nNo idea. Need to investigate.\n. > For the styling in GL JSON - I am not sure into what extent you can really make \"every modulo 100 contour darker/thicker\" without having the relevant attributes precalculated in the vector tiles...\n\nSee: https://www.mapbox.com/mapbox-gl-style-spec/#types-filter\n\nFor a thicker index line every 100m you really would need to create 40+ layers.. if you don't want that data in the vector tiles.\nMakes sense to create a field containing this (not much extra space).\nInvent a good name for this and define nice intervals like mod 100m, mod 1000m.\n. Great @romanshuvalov. Really appreciate it. Most important thing is whether the tile size is still acceptable that we can merge it into the main vector tiles.\n- [x] I will test this out with Switzerland and generate MBTiles and then compare.\nAfter that is ok we can improve the PR or otherwise move it to the dem2vectorterrain project and create vector tiles just for the contour lines (copy the structure from https://github.com/osm2vectortiles/custom-vt-skeleton).\n\nAdded import-contour. Note that contour lines MUST be imported, otherwise export script may fail because of absence of contour-related tables.\n\nWe can fix that by just creating a empty table before hand. Then people without shape files just don't have contours.\nBTW. not your problem that the build is failing. I guess it doesn't add the secret AWS key because it is an external PR??!\n. Okay size impact seems okay on the individual tile level (of course the planet will be bigger).\nBut it won't do damage to the 500KB tile limit (additional 2-5KB per z14 tile).\nSpeed impact is bigger though -rendering is quite a bit slower.\nNext steps would be to test this on a bigger scale than Switzerland (and also check how big the PostGIS db get's with all those shapefiles).\nHmm thinking whether it belongs to OSM2VectorTiles or not. Your changes will be available as vector tiles for sure @romanshuvalov. It is so great!! But question is whether a separate vector tile set or not.\nThis is a vector tile set that actually only needs to be generated one time only (no update functionality as for OSM2VectorTiles). \nBut on the other hand integrating it into OSM2VectorTiles makes it immediately visible for the people and they will actually start using it.\n@klokan let's get together at FOSS4G and discuss it.\nI hope you don't mind @romanshuvalov if this takes some time to discuss.\nAnd also when we are going to render a global vector tile set this will also take some time but it is a huge benefit to everyone!\n. > If you decide to keep them in a separate set (which might not need to be updated for a long long time), I'd recommend merging them into published mbtiles databases, so clients would not need to use 2x requests for each tile.\n\nHide all checks\n\n@hyperknot you can also concat PBFs on the client side. Petr's https://github.com/klokantech/tileserver-gl does this (as does Mapbox).\nHowever not every tileserver can do that and als makes hosting from S3 more difficult.\nWhat are your thoughts on this @hyperknot ?\n. > I'd like to get your feedback on eventually integrating openstreetmap-mapboxgl into osm2vectortiles and maintaining it as a separate tile schema and style from the rest of osm2vectortiles? It doesn't even have to be part of official vector tiles you host, just have it part of master.\nI would actually prefer to see it in a seperate repository inside OSM2VectorTiles instead of of two ways go generate vector tiles in the master branch.\nI think it fits perfectly into the organization because it \"turns OSM into vector tiles\" but is a different approach (but one I really appreciate and am very happy to see realized!!).\nI would like to keep it under the OSM2VectorTiles umbrella but as you wish. You can also take it to your own repo if you want.\nWe can even promote it on the website etc. since I like it but it kind of a different project we started here although using the same approach.\nWhether we will prerender them and how to serve them will be a different topic \ud83d\ude01 \nBut perhaps we find someone to sponsor a rendering.\n. > @lukasmartinelli :)\n\nI will try to help in testing , \nbut please give me a litle time - for review , and creating a test scripts ... \nbecause this is a huge change !\n\nYes this is a huge change and you have been very helpful the last time and since you also know a lot about imposm3 - so I really appreciate it . But as always, this is OSS - do what you want :)\nI am currently testing this with a planet import and just will dump out the tiles with imposm3 expiration and our own method from OSM2VectorTiles.\nI think we can have a simpler tile expiration back in imposm3 upstream but more complicated things we probably need to implement in our fork (which already includes your advanced filter methods).\nThe tile expiration algorithms should work fine. So we can calculate expired tiles for linestrings, polygons and points.\nThe main part will be figuring out where in imposm3 to call what expiration or perhaps that is already perfect.\nThe biggest difference however is that we will can not support the vector tile buffering in the tile expiration scheme if it goes through imposm3. This was very straightforward to implement in PostgreSQL but I don't know whether in practice this made a difference.\n. > is it possible that the Imposm3 \" osmChange delete action\" --> TILELIST is not implemented yet ?\n\n( similar test/problem than : #183 )\n\nImposm3 has a deleter which is called on every delete action (so update and delete) which calls the expire method. So in theory this should correctly expire deleted nodes and ways.\n. > I am expecting the same tile number ... but now the _tiles_all_del.txt is empty ...\nThanks a lot for catching that.\nFound the reason: https://github.com/lukasmartinelli/imposm3/commit/dd80d60bcd7944fff2eb5f9787a56aed43e0ef8f\nThe expireor was not set for the deleter. However this now causes imposm3 to fail when parsing delete diffs - I guess because it was never run with a active expireor before.\nNeed to dig into that.\n. > The expireor was not set for the deleter. However this now causes imposm3 to fail when parsing delete diffs - I guess because it was never run with a active expireor before.\nStupid me. Fixed this before and then rewrote history. With this there are no more failures https://github.com/osm2vectortiles/imposm3/commit/dcf6a77f00d4f00fef9b9d0649237861a6ba1142\nBut one has to rebuild the Docker container so it pulls the newest branch (should add a git checkout  there).\nAlthough have to clarify whether i now not broke something by removing the FillWay calls.\nThe test script is very convenient - thanks.\nNow the new output looks better:\n-rw-r--r-- 1 root root 4195 Sep  2 17:16 _tiles_all_add.txt\n-rw-r--r-- 1 root root  137 Sep  2 17:16 _tiles_all_del.txt\nSo not all tiles don't get marked as expired.\nI think this is because we only expire the outline of a polygon now and not the entire poly.\n. > So not all tiles don't get marked as expired.\n\nI think this is because we only expire the outline of a polygon now and not the entire poly.\n\nFound this bug and fixed in https://github.com/omniscale/imposm3/pull/117/commits/54bcfedf72bd78f2c08387eb4570484bc8665bef\nIssues was that the deleter and writer called the expiration methods by default with different projections - had to fix that first. Now you get the same amount for delete/add.\n. May I ask why you want to render vector tiles until z20? Are you including a lot of extra data at high zoom levels?\nAre you running it on multiple machines or on a single one?\nIf you are running it on a single machine I suggest you use the local export.\ndocker-compose run \\\n   # bounding box of michigan\n  -e BBOX=\"19.6875,40.97989806962015,20.390625,41.50857729743933\" \\\n  -e MIN_ZOOM=\"14\" \\\n  -e MAX_ZOOM=\"20\" \\\n  export\nIf you are running on multiple machines we will further investigate.\nYour approach is correct, the Docker container does not pass on max zoom it seems so adding it is good.\nSo you want to create jobs at zoom level 14 that will render down from z14 to z20 for all z15 descendants from your z5 tile 8/11/5.\npython generate_jobs.py pyramid 8 11 5 --job-zoom=14 --max-zoom=20\nThis returns will return you 4^(15-5)= 1048576 jobs where each job renders 4^(20-14)=4096 tiles.\nSo you want to render 4 billion z20 tiles? Is that really what you want?\nYou get jobs like these. From a quick checks that seems correct.\njson\n{\"id\": \"322a315fa30c4a5925a422e6ef80e719d24e0bea\", \"pyramid\": {\"tile\": {\"max_zoom\": 20, \"y\": 11286, \"min_zoom\": 15, \"x\": 8296}, \"bounds\": {\"west\": -88.857421875, \"north\": 48.763431137917955, \"south\": 48.756188762805515, \"east\": -88.846435546875}}, \"type\": \"pyramid\"}\n\nAlso in my last try, the rabbitmq docker container restarted on it's own, once I got to the merge step. I was able to just loop through all the mbtiles in the AWS bucket, but any idea why the rabbitmq docker container restarted instead of just crashing, or better yet not crashing?\n\nNever had a RabbitMQ crash so far. We were running it for several weeks.\n. > @lukasmartinelli I'm sorry, I just had a fundamentally wrong approach to my problem. I don't need the extra data, I just needed higher zoom and I was using the mapbox gl style wrong, so it was just requesting higher zoom tiles, so I thought \"Well, better figure out how to make higher zoom tiles\"\n\nThat was a lot of time I didn't need to spend.\nI'll try to make a pull request for USAGE.md this evening.\nThanks for the quick response to my wrong approach.\n\nComing from raster tiles this is completely understandable. The overzooming is like magic with vector tiles the first time you see it. We should perhaps educate people better in our repo and on the website.\n. > Unfortunately the given link to the planet_z0-z5.mbtiles file is not available (https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v2.0/planet_z0-z5.mbtiles). Maybe you can update the link or provide the file again?\nWe now have stable planet links. I removed the old link so people switch to the new stable links that include render date and md5sum.\nThis is the new planet for z0-z5:\nhttps://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v2.0/planet_2016-06-20_7088ce06a738dcb3104c769adc11ac2c_z0-z5.mbtiles\n. > @lukasmartinelli - is it fine to link the mobile app from the main OSM2VectorTiles website?\nYup link it!\n. > 12th, 13th and 14th tiles are upscaled to 18th. Even 14th tile has a small gap in between polygons.\n\nAlso it looks like smaller zooms not only has less accuate coordinates, but also has simplified geometry. Simplification is not written in tm2source, so it's performed somewhere inside tile exporting mechanism.\nHow to adjust this parameters?\n\nWhat about going deeper with the zoom levels? That is not feasible if you do the entire planet but if you do only parts of the planet..\n. > SQL functions are faster to execute, can be inlined, and report more errors at compile time instead of run time.\n\n\ud83d\udc4d 1\n\nAlways wondered whether pgsql or SQL is faster...thanks for clearing this up.\nSo as rule of thumb - as long as you can get away with SQL don't resort the pgsql?\nWe also have a lot generated code of functions that just map many values to one that are all pgsql that I can easily switch over to SQL.\n. > I opened a mbtiles file with a SQLite Browser and I found a talbe like below.\n\nI wonder does the BLOB field tile_data store pbf format file? and if so , how can I deserialize it with python or js. thank you\n\nThe BLOB is a gzipped PBF file!\nTo work with it you first need to unzip it and then parse with a MVT parsing library.\nCheck https://github.com/osm2vectortiles/osm2vectortiles/blob/master/tools/compare/tileInfo.js for an example.\n. So these papers do get read :) Happy to hear.\n\n1\\ Like the picture below, there is a process called render in the workflow. In my mind,\"render\" means render data to a picture with mapnik. But I found the \"render\" here means make the data to a MVT format. Am I right? So what is the function of mapnik here? Does mapnik provide some method to generate MVT?\n\nRender is the wrong word. It is actually encoding the data. But everyone is using rendering.. so we stick with it.\nIt is an extension to Mapnik https://github.com/mapbox/mapnik-vector-tile that turns the data into vector tiles (MVT) and stores it in MBTiles.\n\n2\\ in page 29 of the bachelor thesis said\n\"In order to support the Mapbox vector tile 2.0 specification the entire planet needs to be rerendered. If time and resources allow the project maintainers intend to do this in the future.\"\ndoes this process begin? if not how could I do something helpful.\n\nWe already did that shortly afterwards (details in https://github.com/osm2vectortiles/osm2vectortiles/issues/368).\n\n3\\ what tools did you use to generate MVT from data in postgreDB?\n\nIt is using tilelive-copy (which in turns calls tilelive-bridge - which calls Mapnik).\nCode for running it locally here: https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/export/export-local.sh\n. > Thank you for your reply. To be honest the tow thesis is very helpful. I work in a top GIS study institution, I have not read any document such perfect these years. :)\nOh I love this. We spent so much time in writing this dead paper document so your compliment is really flattering to us :)\nYou think it makes sense to pull some content out of the thesis and put it on the project wiki or so?\n. > I am still puzzled - I was under the impression that some kind of simplification (per output tile) IS being made - but I haven't found any code that would do it ...\nWe missed the roads.. but other things are generalized.\nResolution is alway 4096 so you loose accuracy but it still has many vertices at low zooms - this is why we didn't notice for roads. \nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-osm/mapping.yml#L16-L32\nSadly we cannot call ST_Simplify while rendering - it kills the entire rendering performance (just as ST_Centroid does). It must be precalculated beforehand for global rendering (you save dozens of hours).\nFor local extracts it doesn't matter as much.\n. > I currently hosting OSM vector tiles on our mapping server (courtesy osm2vectortiles and tilesever-gl). Now I'm trying to convert my own shapefiles into the same Mapbox Vector Tile format so I can add them as an overlay to my maps.\nWe actually show a quick demo of that at our FOSS4G talk. https://www.youtube.com/watch?v=D7mmXonFIqA (just watch the demo part)\nYou can use Mapbox Studio Classic to do that. Probably the easiest way.\n. > I want to create my own vector tiles, for example where road types 'track', or 'path' appear sooner, at lower zoom levels. Or a set of vector tiles that only contains mountain peaks.\nDo you want to create your own basemap (or extend it) or just add overlays? Also check out this similar discussion: https://github.com/osm2vectortiles/osm2vectortiles/issues/402\nIf you just need a single set like the mountain peaks easiest way is to configure your own import/export with https://github.com/osm2vectortiles/custom-vt-skeleton.\nThere are actually quite suprising amount of these requests and we don't really have a very straightforward solution... we need to think about making it easier for people to fork and modify.\n. It's important to understand that here we don't have PNG files in the MBTiles.\nIt contains gzipped Protocol Buffer in the \"Mapbox Vector Tile Specification\" format (quite a mouth full).\n. > Is there a way to do it, provide those vector tiles as images on serverside?\nCheck out https://github.com/klokantech/tileserver-gl to render raster tiles from the vector tiles.\n. Thanks for this. Especially interested in the ST_Simplify values you chose.\nCurrently generalization happens either at import step (the imposm3 mapping file) or is already simplified (different NaturalEarth resolutions or OpenStreetMapData water polys).\nHowever there is some non generalized tables that you correctly noted (lake polys, roads, waterways). Thanks.\nWill hold back this PR for a while - we're currently in the middle of a road map planning due to the copyright claims. However the findings made here will definitely find their way in the project.\n. Thanks @vitalcrazz for fixing! \u2764\ufe0f \n. Cool. In the v3 we use the following approach of Paul Norman (OSM Clear to calculate render_height:\nsql\n-- 3.66 is obtained by correlating the heights and level data in OSM\n-- raising to a power < 1 reduces the height range displayed which looks better\nleast(greatest(3, COALESCE(height,levels*3.66,5)),400)^.7 AS render_height\n. > Have to figure out why building:part is missing, I'm not as familiar with imposm3 mapping as I am imposm2. Any thoughts @lukasmartinelli ?\nJust note here which OSM source data you require for the 3D buildings.\n\nDecided against rendering the materials as that would get extremely complicated and may not look very good with the limited pattern fill capabilities\n\nWow looks very nice \u2764\ufe0f \n. > Thank you for your responses. They have been very helpful. I see you are at 35% for the v3.0 milestone and have no due date. Is this something you expect to take weeks, months, or years? Just getting a ballpark estimate.\nRelease is end of 2016.\n. That must be something in imposm3 mapping - you could change the mapping.yml to accept all road tags for starting (https://imposm.org/docs/imposm3/latest/mapping.html):\nSomething like this..\ntables:\n  highway_linestring:\n    type: linestring\n    fields:\n    - name: osm_id\n      type: id\n    - name: geometry\n      type: geometry\n    - name: highway\n      key: highway\n      type: string\n    - key: oneway\n      name: oneway\n      type: direction\n    - key: layer\n      name: layer\n      type: integer\n    - name: z_order\n      type: wayzorder\n    - key: tunnel\n      name: is_tunnel\n      type: bool\n    - key: bridge\n      name: is_bridge\n      type: bool\n    - key: name\n      name: name\n      type: string\n    - name: name_en\n      key: name:en\n      type: string\n    mapping:\n      highway:\n      - __any__\n. > if i understand you correctly\nAh yes thanks @ImreSamu. So happy to have you helping on the issues :) \u2764\ufe0f \n. > Instead of generating all of the vector tiles for all of the osm, is it possible to just generate one vector tile at a specific x/y/zoom?\nDo you want on demand serving?\nThat is totally possible - instead of using something like tilelive-copy you can use a tileserver like tessera.\nhttps://github.com/mojodna/tessera\n. > Are there city boundary polygons/lines in the osm2vectortiles extracts? If so, what is the layer name? They do not seem to be in the mapbox streets extracts, however they are in the default OSM raster tiles. If they are not in the extracts I would like to see them added.\nIn version 3.0 i have the \"urban ares\" of Natural Earth if this is what you mean.\nYou want something to style the outline of a city? Or the actual city boundary?\n. > My questions is we need to generate level 14,15 ... 20 ? Because will take very long time to generate and a lot of space needing ?? I think?\nAll data for 15-22 is already contained within the z14 tile. You only needs to go as deep if you need to add even more detail. Mapbox GL can overzoom - so use features from z14 in a z16 tile.\n. Not like that (only works for TileJSON endpoints)\n\"sources\": {\n        \"mapbox\": {\n            \"url\": \"http://localhost:8080/data/osm2vectortiles/{z}/{x}/{y}.pbf\",\n            \"type\": \"vector\"\n        }\n    },\nbut like that (as in https://www.mapbox.com/mapbox-gl-style-spec/#sources-vector-tiles)\n\"sources\": {\n        \"mapbox\": {\n            \"tiles\": [\"http://localhost:8080/data/osm2vectortiles/{z}/{x}/{y}.pbf\"],\n            \"type\": \"vector\"\n        }\n    },\n. > now it effectively works ! I just get another problem : above a certain zoom level I get the following error in my navigator console : GET http://localhost:8080/data/osm2vectortiles/15/24148/13756.pbf 404 (Not Found)\nTo solve that set a minzoom and maxzoom in the vector tile source (as described in mapbox gl style spec referenced above).\n. > I followed the Detailed Usage Guide to apply and render diff updates (for my small region).\nYou can run docker-compose export-list to export whatever is in tiles.txt.\n. The specific tile at zoom level 7. The jobs component can bundle up tiles back into jobs (and looking after proximity).\n. Thanks for the extract definition. It will take quite a long time until this will end up in the extracts though.\n. > The extension suggests you are using a vector variant of MBTiles -- but this is not supported by the latest MBTiles specification...\nWhat parts of the spec is not fulfilled? Do we miss metadata in select * from metadata?\nYou will have problem inserting new tiles directly into tiles (since it is made up from views to save redundant PBFs) but from the reading perspective the MBTiles spec should be fulfilled.\n. > NB. I'm not trying to be pedantic; from reading your docs + the mbtiles docs, I don't have a clue how you are actually storing the vector data. My guess is that you are storing it in tile_data, but beyond that ...? Are you using some unpublished extension to MBtiles?\nIn tile_data it is a gzipped Mabpox Vector Tile Specification Protobuf as produced by https://github.com/mapbox/tilelive/blob/master/bin/tilelive-copy\n. @klokan has some ideas to remove PBF layers from MBTiles.\nBut I agree that the tiles are too fat right now!\n. > It wasn't a criticism -- I need particularly compact tiles as they will be used on tablets. Am I right in thinking that I can drop the filesize a lot by tinkering with https://github.com/osm2vectortiles/osm2vectortiles/tree/master/osm2vectortiles.tm2source/data.yml to remove the things I don't need? Is that the easiest approach?\nYes that will be easier in v3 where you can pick which layers you want. Sorry I always have to point to the future like a politician I hope we can soon release this finally public.\n. > I read the sql script in /src/import-sql/layers/poi_label.sql, but I can't find the function maki_label_class(type).\nThat code is generated from https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-sql/classes/maki_label.yml\n. Hmm that is interesting - but it is all overzooming.\nThe only things that can affect this on the vector tile side are buffers (which are quite large for POIs already) afaik and since we only render down to z14..not deeper.\n. > So when I zoom to level 12, the roads (road_label) are broken at the center of city and then continues at some area:\nHmm I wonder whether it has to do with the extracts - let me keep an eye on that for v3.. > Actually Country wise datasets are wonderful, but for some activities the datasets of the continents are required.\nOk that's a good request - adding these few points is easy and can help to make a better looking low  zoom map.. > What is the advantage of having the intermediate file osm2vectortiles.json, as opposed to simply having the style file point directly at the vector tiles?\nThis intermediary format is called TileJSON https://github.com/mapbox/tilejson-spec and has additional information about what is in the tiles. \nIt allows specifying multiple tileservers for example. But directly specifying x/y/z is fine as well.\n. > This was recently fixed in Mapzen tiles by tilezen/vector-datasource#1124\nBut in a post processing step we don't have here :(. > why the poi_label didn't display in the web browser? is it relative to the bright-v9.json?\nVery possible that I limited the POI appearance in the style JSON as well.. Perhaps it's late but can't you just return true here if classNamematches once and otherwise always false?\nAnd it can be sometimes dangerous to name a variable the same as the function because both are objects (containsClass).\n. Perhaps we can use the new Array.from https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/from for converting the Set into an Array and make it sortable.\n. Do we need the COALESCE calls in the FROM clause when we do COALESCE in the SELECT as well?\n. Is this already the generated version :grin: ?\n. We can remove queries that are for a zoom level bigger than 14.\n. Cool that we can solve the ranking on marine by simply checking the types.\n. > This will probably fail for files larger then 5GB.\nTrue but for z8 the largest MBTiles I've seen so far are below 150MB.\nThis will only matter if we have jobs for higher zoom levels.\n. Good we found out that type was missing. :+1: \n. We don't need scalerank for water labels.\n. No longer need the scalerank here.\n. Should it be type in ('wood', ..)  or landuse_class(type) in ('wood', ...) ?\nProbably doesn't matter just consistency.\nThe class wood already contains the types wood and forest.\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-sql/classes/landuse.yml.\n. This is already generalized by OpenStreetMap data or at import stage (hence the gen1 and gen0) in the tables.\n. Sorry this isn't so obvious ;)\nGeneralization should happen in the TM2Source file not in the view.\nThe reason for it is that otherwise you apply the !BBOX! && geometry WHERE clause AFTER the data has been generalized. Which means one will generalize millions of features just to throw them away afterwards.\nFirst GIST index - then generalize.\n. Probably better tweak the parameters of the osm_landuse_polygon_subdivided_gen0 table.\nOr introduce more gen tables.\n. ",
    "sfkeller": "Regarding Open Source Fonts: OSM main map took \"DejaVu Sans\" (http://dejavu-fonts.org ) because it's one of the few fonts which support non-european languages (like Hebrew). \nThen we could consider also:\n- \"Google Noto\": https://www.google.com/get/noto/\n- \"Source Han Sans\" and/or \"Sans Pro\" (panasiatic character set) http://blog.typekit.com/2014/07/15/introducing-source-han-sans/ and https://github.com/adobe-fonts/source-han-sans\n. Awesome work, guys!\n. We're using osm2pgsql. Did you evaluate that versus imposm3?\nIn case you stick with imposm3 I'd recommend to use option \"osm2pgsql schema compatibility\".\n. Getting out-of-memory is a typical problem when converting ways to lines, since all nodes (which are referred to from the ways and contain the coordinates) need to be loaded or at least queried.\nIn osm2pgsql we initially had similar problems before setting \"slim mode\":\nhttp://wiki.openstreetmap.org/wiki/Osm2pgsql#Slim_mode\n. Open Streets and open-streets (but not \"Openstreets\") sounds good to me.\n. Excellent work! I have small enhancement proposoal: It seems to me that at z14 the borders are way too much generalized. At z15 (and z13,12,11...) its looks good for me. I did not compare with Mapbox style but with OSM Swiss Style e.g. at http://www.nebelkarte.ch/#14/47.2237/8.8314 . See comparison image below.\nBTW @klokan : I had to guess the zoom level from the webpage http://osm.tileserver.com/open-streets/bright-v8ch.html you gave. Is it possible to show URL parameters like at Nebelkarte.ch and OSM.org?\n. \n. Putting a \"thematic\" layer on top of a \"base map\" is best practice in cartography/GIS.\nSince this project is about making map styling so easy (possibly worldwide), we probably have to decide about which users we want to address: Is it both, or the few but important base map stylers or is it the mass users doing thematic maps? If we have to choose, I would concentrate on \"base map\" stylers.\n. If this is feasible, try also to compare and evaluate the output. I've seen reports which indicate that there are differences, e.g. that osm2pgsql recognized more buildings than similar programs.\n. @klokan These are not yet specific issues in osm2pgsql or impost - just different interprations of how OSM data and its tags are being interpreted. \n. It was a comparison of osm2pgsql versus ogr2ogr:\nhttps://lists.osgeo.org/pipermail/qgis-user/2014-May/027473.html\nAnd ogr2ogr was slightly \"better\" in interpreting OSM data.\n. Just as an input: Did you see these slides/info from mapsquare.io? Website http://www.mapsquare.io/#/techres/openSource and http://fr.slideshare.net/LoicOrtola/openstreetmap-tileserver-in-one-minute ?\n. For the sake of minimizing resources (i.e. disk space and processing time) I just wanted to ask a similar question regarding tiles of a larger region provided either as boolean \"mask\" or even a mask with more than one value. This becomes virulent with vectors but could be applied also to raster tiles:\nHow are empty/missing tiles handled (at either server or client side) so that they are rendered with a dataset wide single value (like ocean blue) - or even rendered using an arbitrary value (like ocean/rain forest/ice) fetched from some \"meta tile/layer\")? \n. Ok. You say IP address are enough for serving these files.\nBut in order to \"sell\" this to the HSR-IT I still need a I still need a project name.\n- I've seen you call it \"OSM Vector Tiles\",\n- What about \"Open Streets Vector Tiles\"?\n. Little bit off topic: But \n1. how would point clustering fit into vector tiles format?\n2. and is there a fast query to count the total no. of features in a tile?\n. It was stalled around weeks but last week the responsable IT support guy got green light to investigate further. I think he has already a test account for us. I'll be back again soon...\nIn the meantime: These are the help pages of \"SWITCHengines\": https://help.switch.ch/engines\n. Just another 2 cents: Perhaps QGIS Browser https://www.qgis.org/en/site/about/features.html#qgis-browser would be an option when our Vector Tiles Reader Plugin is ready\nhttp://giswiki.hsr.ch/Vector_Tiles_Reader_QGIS_Plugin ? I don't have used yet this \"Browser\" variant of QGIS though.\n. Interesting project: https://github.com/mapbox/mapbox-gl-native\n. What a cool gadget!\n. PostgreSQL often can't optimize when there's a function in the query, \nEnhancement ideas: Is this function necessary? And should'nt you use GISt index?\n. This filtering obviously can be accomplished using ST_SimplifyPreserveTopology.\nQuestion: At \"Zoom Layer Reference\" http://osm2vectortiles.org/docs/layer-reference/ it's indicated that roads are included starting with zoom level 5. I think this could be true but at least in the raster version, roads are not shown: http://klokantech-3.tileserver.com/osm-bright/5/16/11.png . Why?\n. I'm aware that you don't have to show data when it is available. I was just wondering why that is the case here, since both stylings - raster/Mapnik-rendered and vector/MapboxGL rendered - are called \"OSM Bright\" and because I am looking for ways to reduce vector tile size.\n. I'm flabbergasted...\n. Why not also raising meta-tiles size? It seems to be close to 2 since there are also duplicate label issues.\n\n. I've analyzed \nLooking at the data I have some questions. Given tile 9/268/178 there's the place_label class which contains among others following label:\n{\n  \"geometry\": [[2673, 337]], \"type\": 1, \"id\": 18, \n  \"properties\": {\n    \"osm_id\": 1599381299,\n    \"name\": \"Frauenfeld\",\n    \"name_de\": \"Frauenfeld\",\n    \"name_en\": \"Frauenfeld\",\n    \"name_es\": \"Frauenfeld\",\n    \"name_fr\": \"Frauenfeld\",\n    \"name_ru\": \"\\u0424\\u0440\\u0430\\u0443\\u044d\\u043d\\u0444\\u0435\\u043b\\u044c\\u0434\",\n    \"name_zh\": \"Frauenfeld\"\n    \"type\": \"town\",\n    \"localrank\": 1,\n    \"scalerank\": 9,\n  }\n}\n1. Leaving out \"name_ru\" (and other name tags) would save space.\n2. I observed many place_labels in the tiles which are way outside the extent. That would perhaps save space too?\n3. Spec. says, \"A feature MAY contain an id field.\". Is the value of id (here 18) really \"unique among the features of the parent layer\"?\n. Their status does'nt mention problems currently https://twitter.com/switchdrive_op \nShould we send a mail to support?\n. Nice! This \"enable volume\" in Kitematic for export image could be added to the docs for Windows users.\n. Congrats! Actually you already tweeted about before :-O\n. Just as a side note: \nOne can apply for a scholarship at State of the Map 2016: https://blog.openstreetmap.org/2016/04/25/we-want-you-at-state-of-the-map-apply-for-a-scholarship/\nAnd at FOSS4G 2016 there is a studentship programme: http://2016.foss4g.org/attending.html#studentship\n. Good idea to talk and hack about OSM2VectorTiles. We can meet at Saturday after end of talks (5:40) or before.\nI'm actually not yet in Brussels before Saturday morning. \nThere are also BOF's scheduled (currently) at Sunday only and at Monday, September 26th there's a dedicated hack day.\nI've just now added a BOF proposal about \"Vector Tiles\" (in general) here http://wiki.openstreetmap.org/wiki/State_Of_The_Map_2016/Informal_Sessions#Vector_Tiles_.28and_a_free_base_map_style.29\n. Just to clarify the situation with labels: OSM collects the local situation, therefore tag name contains the local geographic name (=called \"endonym\" in toponymy). And there are very few objects which contain tag int_name, name_en, etc. Therefore, finnish geonames in Finland are not excluded!\nIn OSMaxx project we handle labelling and names like this: Attribute \"name\" (contains endonym), \"int_name\" (contains english geoname if any), \"label\" (contains \"transliterate(name)\" unless one of the following tag values exist...:), \"name_en\", \"name_fr\", \"name_es\", \"name_de\". \n. Ah ok. We have this situation of bilingual endonyms actually too in Switzerland (e.g. de/fr Biel/Bienne) and in Austria (South Tirol de/it). \nBut believe me, introducing templates (for names or other attributes) in a data model highly optimized for base maps like this, is a major enhancement and refactoring task.\nFor me it's more realistic for near future to combine base vector tiles like ours with other \"thematic\" vector tiles, coming from a generic vector tile generator. \n. You can also ask colleagues Heeb+Keller... :-)\nSee also http://wiki.openstreetmap.org/wiki/QuadTiles \n. @lukasmartinelli you are right regarding keys id and filesize. \nBut according to the spec. these five keys are required: name, type, version, description and format. Especially version is something a reader should check. \nThen these are keys are suggested by the spec. (and I would suggest it too): bounds and attribution.\n. Seems to me impossible to speed up a Bitmap Index Scan.\nThe only thing which stroke my eyes is that you are generating a 3D(?) bbox like this:\nWHERE geometry && ST_SetSRID('BOX3D(3911129.863295898 4537301.999008063, 4072564.867034191 4698737.002746355)'::box3d, 3857)\nWhat about this (box2d)?\nWHERE geometry && ST_SetSRID('BOX(3911129.863295898 4537301.999008063, 4072564.867034191 4698737.002746355)'::box2d, 3857)\n... or even this (no string parsing and casting needed)?\nWHERE geometry && ST_MakeEnvelope(3911129.863295898, 4537301.999008063, 4072564.867034191, 4698737.002746355, 3857)\n. Regarding Bitmap Index Scan just one question: It seems to me that the query you cited above does not correspond with the query shown in the EXPLAIN ANALYZE image you cite too: The Bitmap Index Scan in the EXPLAIN ANALYZE image shows \"= ANY ('{motorway,moto...\". What's about this ANY clause?\n. @lukasmartinelli wrote:\n\nSeems admin boundaries are often affected. Not sure what the reason for the big blocks \nof tiles that are now dirty in Russia are. \n\nWeird observations: You could make a blog post about this nice \"map of changes at z10\". Why so many changes at boundaries? Why no \"inner continental\" changes in the Americas and Russia? Why so many changes in northern Russia territory?\n. @manuelroth wrote:\n\nOr is there a PostGIS function which allows to combine multiple adjacent small geometries into big geometries? \n\nYes; since PostGIS version 2.2.0: http://postgis.net/docs/manual-dev/ST_ClusterWithin.html\n. Nice comparison (tool). This discussion shows to me why it's so important to distinguish \"data syle\" (= mapping OSM data to schema) and \"style\" (= mapping schema to symbols or vt, graphic oriented). \n=> Would'nt it be even more clear and self-documenting to rename \"all_features\" and \"used_features\" to - say - \"features_in_database\" and \"features_in_vector_tiles\" - or - \"db_features\" and \"vt_features\" ?\n. Nice! But why do you need to check geometry type? Can't you omit this? \nWHERE ST_Geometrytype(geometry) = 'ST_LineString'\n. So the GEOMETRY type must be COLLECTION. And this is fast? \nAnd if you are using Mapbox' osm_id generation mechanism (are you now?), you could extract geometry type from that (little hacky, though).\nAnyway; in this case you could also consider \"ST_CollectionExtract(geometry collection, integer type)\".\n. This would return (multi)linestrings only. See http://postgis.net/docs/ST_CollectionExtract.html . Not sure if this helps. \n. I announced an issue with some \"big challengese in digital cartography\". Now after some pondering, I think one of the enhancements worth to elaborate, are these issues of handling (schools/hospitals/aeroports/zoo/leisure parks/...) as one aggregated feature with a single name.\n. Howto get BBOX with online tools?\n1. Search location at http://osm.org, note relation OSM id (admin. boundaries always are r.).\n2. Given OSM id relation get polygon: http://polygons.openstreetmap.fr/\n3. On same site: If need a buffer, choose line. If need simplified polygon, generate simplified polygon.\n4. To get BBOX, paste result to http://geojson.io/ and choose menu \"Meta > Add bboxes\".\n. As soon as e.g. Havanna is showing up on http://osm2vectortiles.org/downloads/ we can tweet about supporting the Cuba Conference too :-) https://twitter.com/Mapbox/status/724616125301030913 \n. @lukasmartinelli Cool \"PostGIS Query Editor\" I was not aware of. Looks similar to those \"PostGIS Terminals\" like http://giswiki.hsr.ch/PostGIS_Terminal :-) . If the installation has as few dependencies as possible (did'nt check this), this tool could become widely used!\n. Good question. I'd like to close this ticket. It can be reopened later just in case (which I don't hope).\n. Hello again @michaelsteffen :-) This project is steadily moving into a direction we discussed and this kind of conversation is not a ball game. I'd like to point to the fact, that we already had three long conversations without any further clarification. So, unless you think you can answer those still open questions here, I'm in favour of closing this issue.\nP.S.: There is still this other issue to be clarified: https://github.com/mapbox/osm-bright/issues/116 \n. @pnorman wrote: \n\nGiven we're avoiding stuff we don't have to (e.g. openly licensed styles from MapBox) because of the legal chill, should we completely move away from MapBox GL?\n\nGood question! But given that OpenLayers and Esri also support Mapbox GL it's not easy to ignore it. \nMy idea is to seek and establish a Styling Language spec. on a higher level together with command line tools and GUI tools (like Maputnik). There could be JS libs that directly interpret it - and it could be possible to generate other styling languages including Mapbox GL.\n. Referring to @lukasmartinelli's comment above, I'd like to emphasize that neither his comment - nor any action from us - implies a confession of copyright infringement of OSM2VectorTiles. In fact, AFAIK there is none.\n@hyperknot: Regarding legal support for this project, there exists a limited one. But no one withholds any company to accuse somebody - especially in the US! Thing is, we're a small project and want to avoid this risk in order to focus on technical and organizational progress. \nIf something does not make sense to me (too), it's why Mapbox (MB) asked us to start from scratch, instead of \"allowing\" our vector tiles to become purely compatible with MB JSON style Bright (as described by Lukas above). \n@michaelsteffen: Pls. intervene here within days if you change your mind. \nI believe, MB really likes to release openly as much as possible. But MB obviously dislikes vector tiles which enable their customers and stakeholdes to switch to alternatives - especially if the maps look similar. This is where not only vector tiles but also styles come into play. Any map consists of 1. preprocessed data/vector tiles, 2. style and 3. rendering/client libs.\n@michaelsteffen: Can you clarify, that \"there is no problem with use\" of MB JSON styles (currently Bright and Basic) with vector tiles not coming from MB?\nI have also problems with the \"Design License\" section of MB JSON styles license; I cite: \"The visual design features of the Mapbox Open Styles (also known as the \"look and feel\" of the map) are licensed under CC-BY-SA.\". \n@michaelsteffen: Is this refering to the repo - or to the \"look and feel\" of the map? \nIf it's referring to the map, I don't think this is the right place. Anyway, pls. clarify!\n. +1\n. > Sorry I always have to point to the future like a politician. \n\nI hope we can soon release this finally public.\n\nLOL! This is not only a politicians attitude - but also part of \"definition of done\" - and a good practice for community moderation :-)\n. ",
    "manuelroth": "@petrsloup Thanks this helps a lot. I like that we can see the tileinfo with all the classes and types on the right side.\n. We decided to take a question based approach with the documentation. We write down the most common questions which will probably be asked, and answer them with tutorials and text. The separation between user and dev documentation will stay. \nUser Documentation\nThe user documentation describes how to get started with OSM Vector Tiles and how to create a custom style. \nDev Documentation\nWhereas the dev documentation focuses on which data is included, how to host them, creating own extract, adding own data.\n. This issues is not needed anymore as it is now implemented and the progress is documented many other issues.\n. - [x] Handle case when a directory with the tm2 project is mounted to the /data volume, but the directory still does not contain a tm2 project\n- Is it a convention that the mbtiles must have the same name as the tm2 project?- One could also have a mbtiles file called switzerland.mbtiles and a tm2 project called osm-bright.tm2. The mbtiles file is not always related to the style. \n- In a future iteration we could give the possibility of declaring the name of the mbtiles file or just take any file with the .mbtiles file extension. \n- What do you think about this?- I'm not quite sure what the best solution is. I think high usability should be the goal.\n. Created issues for ideas and added them as enhancements in milestone final. -> #23 #24\n. - Documentation is very clear and understandable\n- If the postgres user and osm user are the same, an sql error gets thrown \"role does already exist\". But this shouldn't be a problem. \n- [x] Are you sure that the default postgres user and password is osm?- Because in the docu of the official postgres container it says postgres.\n. - Import Container can't connect to database container because the database requires the password to be md5 hashed. \nFATAL:  password authentication failed for user \"osm\"\nDETAIL:  Connection matched pg_hba.conf line 95: \"host all all 0.0.0.0/0 md5\"\n- The base postgres dockerfile defines this in the docker-entrypoint.sh file (Postgres Base Dockerfile at the bottom)\n- Should we change this configuration?- I think it would be easier without hashing, md5 is anyways not really a security feature.\n. > If I follow the instructions on a clean machine I should be able to replicate this?\n\nIs this the osm user with a password differrent than osm?\n\nYes, you should be able to replicate this. Exactly, I used osm as user and password.\n. Created a bug for the mounting issue #22 and added it to milestone beta.\n. - Looks good so far, created an issue for generally making the source project more compatible to mapbox streets #25\n. I will take this approach for comparing two vector tiles. The vector-tile.js library provides ways to select all layers or count how many features are available in this layer. It is a bit easier than comparing the output of tile-info.\n\n\n. The first results of my analysis show that we got generally more features in our vector tile than the mapbox-streets tiles. \nI made a script which outputs each layer(landuse) with feature count, classes(agriculture) and types(farm) per class. Then I made a diff on the results of both vector tiles. I put the results into our Google Drive folder, if somebody is interested.\n@klokan Would you recommend to remove features which are not present in the streets vector tiles?\nThe advantage would be, that we get smaller vector tiles. But a style like OSM Carto wouldn't be possible anymore, because not all of the features which OSM Carto needs are present.\n. @klokan Thanks for your feedback, i tried to implement all of your suggestions. On my gist page(https://gist.github.com/manuelroth) you can find a comparison of the mapbox-streets-v5 style with our open-streets style of one tile on level 0-14. I also generated this output for the mapbox-streets-v6 style. It gets a bit messy if I put all into my gist page. I will probably create a separate repository, with comparison of mapbox-streets-v5 -> mapbox-streets-v6 and mapbox-streets-v5 -> our open-streets.\n. @klokan Oh that makes sense. I didn't realized that, was probably a bit late yesterday.\nI created a separate repository(https://github.com/geometalab/comparevectortiles) with branches as you suggested above. I'm not sure yet how to display the list of attributes of features. Would you suggest to output every feature with all of its attributes?- I worry that the output gets huge, because some layers have more than 6000 features.\n. @klokan I created an issue in the open-streets repository to track which layers are still missing.\nThe extract of bbbike does not have the lake, because the end of the lake is cut off. But I take it anyways because it is a bit bigger that the extract of mapzen.\n. > Can we manage all issues in one repo? It is just easier to keep track off.\nThe issues to improve the layers are not related to the content of the osm2vectortiles repository. I would like to have them in the open-streets.tm2source repo, because they are related to the style project. \n. @klokan You can find a new mbtiles of switzerland in the drive folder. It should now be very close to mapbox streets v5. @lukasmartinelli will generate a mbtiles for europe over the weekend, so that we can also see how it looks on the upper layers.\n. @sfkeller Thanks for your comment. For the water_polygons table we have two generalized tables the problem was, that we showed the data of the more generalized table(gen0) on the lower zoomlevel instead of the less generalized table(gen1). (have a look at my commit d8d5e62). @klokan I will add an updated mbtiles file to the drive folder. \n. \nI agree with @lukasmartinelli we probably could add some small improvements specially for Mapbox GL. \n. Discussion about v5 and v6 moved #71 \n. - The test results at first glance may look not very impressive. With 50 concurrent users, 50% of the request take longer than 1200 ms. But we have to keep in mind, that this tileserver consciously uses no caching and runs on a very small machine. \n- I'm probably going to test it on a bigger machine for comparison.\n- Thanks @lukasmartinelli I'll have a look at there load-tester, maybe we can integrate it. \n- @klokan loader.io looks nice, I'll try if the free plan is suitable for our usecase.\n. @lukasmartinelli yes, you are right, its too much data. I wonder, if there is an option for less verbose results. The global result output at the end of the test contains already all interesting information. I need to check on that.\n. Marine Labels:\n- Mapbox did certainly not just take the natural earth scaleranks for marine labels\n- But I just figured out, that if we add one to the natural earth scalerank of the marine labels we get very close to it.\n- There are still labels which have too high scalerank\n. I identified major problems on following layers:\n- [x] water polygons (lakes) look not good on level 0 to 5\n- [x] we show too many marine labels with wrong scalerank\n- [x] country labels need improvements on level 3\n- [x] in north america we show less place labels on level 4 to 5\n- [x] since we use osm data starting level 7 on the admin layer some borders are still broken\n. > water polygons (lakes) look not good on level 0 to 5\nWater polygons look now perfect, we use natural earth data from zoomlevel 0 - 5\n. > You mean OSM borders that are in the water but are not marked as maritime?\n\nCan we even solve this without fiddling with the data?\n\nYes, I can't see a straight forward way to solve this right now. \n. I finished the work you started with the natural earth scalerank for country labels and removed the population based calculation. \nBut I still don't know how they decide when to show the iso codes of the countries.\n\nIts not based on the length of the country name, it must have something to do with the density of labels around.\n. > Weird so the data of Mapbox has the iso_code set as name? In v6 they provide it as additional field.\nYes, they set the iso code as name also in the translation fields (name_en ect.). The scalerank is set, Mapbox sets scalerank for brazil and mexico to 1 and natural earth to 2.\n. Update on the marine labels:\n- Most of the things we show as polygons (left side) Mapbox shows as linestring. What confuses me, is that these seas are not even present as linestring (nor in osm data or natural earth).\n  - Example (Black Sea):\n    \n- Most of the bays we show, are not present in mapbox streets v5\n  \n. > Have you tried using the iso_code as name for countries with e.g. a scalerank > 3?\nI will try that, maybe we come close enough with this.\n\nAnd I saw you use the labelrank from Natural Earth instead of scalerank - you know what the difference is there?\n\nI suppose the labelrank is for labels, I don't now what the difference is. I choose it because in many cases it is similar to the scalerank of mapbox on the country label layer. \n. I tryed your idea ( showing iso_codes as name for countries with scalerank > 3). The problem is that not many countries have not set there iso code. Right now it looks like this:\n\nI will try to add the iso code of natural earth, and see if it looks better.\n. With mapbox streets v6 (right side) they moved back to the full country name. I tryed to come close to what they have, but it still needs some refinement. \n\n@lukasmartinelli I found some issues with the name comparison. \n- For example US:\n  - osm name: United States of America  and  natural earth name: United States\n- or Czech:\n  - osm name: Czech Republic and natural earth name: Czech Rep.\n    I updated the sql function with the necessary changes.\n. @lukasmartinelli Yes, you are right. It's really a pain to work with two branches on separate repositories. Let's merge the style project back in.\n. - Created an issues #49 for the final milestone to cleanup documentation\n. We move everything to http://osm2vectortiles.org\n. @lukasmartinelli I did the import and everything seams to be fine. Would you suggest to merge this already into master, and create a new branch for queries out of master?\n. @lukasmartinelli That's really awesome. I like it, it's so much easier to maintain.\n. @lukasmartinelli I'll test it tomorrow, while improving the queries. Maybe there is a case we didn't thought about yet. But then I think it can easily be added as an additional step in the Dockerfile of the prepare-open-streets container. We probably can just append the functions to the end of the functions.sql file. So that we are still able to add other sql functions like 'format_to_uppercase'\n. Okey, I agree as it has no clear perpose and we can save some data. I will remove the unused fields of the admin table in the imposm mapping and remove the layer of the source project\n. I really enjoy these graphs. As the source project an mapping get more complex. It is nice to have an overview over what is mapped to what.\n. > It has gotten out of control with all these layers and tables :grinning: Difficult to fit it all into the head.\nYes, definitely. Thanks for the improvements. \n. I didn't know that Switch also provides Cloud Services. Would be really nice, if we could have a public bucket.\n. I tried to create a bucket and upload a mbtiles to SWITCHengines S3 Object Store. The upload worked fine, but somehow I can't access the mbtiles file. On AWS S3, a bucket policy needs to be created to allow access to a bucket. But there is no word on that in the documentation. Because of that I created these two issues on their forum(issue1, issue2)\n. The support-team of SWITCHengines told me that they do not support bucket policies only acl's. I used the s3cmd tool to create a bucket and make it publicly accessible. \nThis command creates a bucket osm2vectortiles and makes it and everything inside the bucket public:\nbash\ns3cmd mb s3://osm2vectortiles/ --acl-public --recursive\nThe bucket can now be accessed from this url: https://osm2vectortiles.os.zhdk.cloud.switch.ch/\n. :smile: exactly. I want to try out mapbox tile copy, it takes a mbtiles, uploads it to S3 and extracts it to the format /{z}/{x}/{y}.\nbash\nmapbox-tile-copy ~/data/my-tiles.mbtiles s3://my-bucket/folder/mbtiles/{z}/{x}/{y}\nThen we could serve the vector tiles statically, like mapbox does it with mapbox streets. \n. I just think it would be nice, if we had an alternative to downloading the extract mbtiles. We could provide a Mapbox GL example which contains an url to the vector tiles. This would be way quicker than downloading the mbtiles file and starting our tile server container. It would be nice, if we could provide something for the people, which just want to have a quick look at our map. \nI uploaded the mbtiles file of switzerland to the bucket osm2vectortiles. It can be accessed on this link: https://osm2vectortiles.os.zhdk.cloud.switch.ch/switzerland.mbtiles\n. Gist with BBOXs of alle countries of the world: https://gist.github.com/manuelroth/0975c929afdce724d339\n. Command to upload to Google Drive:\nrclone config\nrclone --drive-chunk-size=128m copy world.mbtiles gd://\n. - I added generalization to the water layer (03d0da2) to solve the problem @klokan described in the last pull request. \n- Now we show the country labels with scalerank 1 starting zoomlevel 1 like streets v6 does (80f4692). \n- I couldn't find a solution for the overlapping place label problem, I tried to move the place_label layer up in the source project and increase the buffer size, but both approaches didn't worked.\n- I opened an issue in the mapbox gl js repository (https://github.com/mapbox/mapbox-gl-js/issues/1729), maybe they know what the problem could be.\n\n. Apparently the overlapping problem is a known issue of mapbox gl. They closed my issue because it is a duplicate of https://github.com/mapbox/mapbox-gl-js/issues/757. A fix is in the works.\n. I want to clarify the confusion around the OSM Bright style for Mapbox GL and the normal TM2-Style.\n\nOn the left side is the Mapbox GL version with this style https://github.com/mapbox/mapbox-gl-styles/blob/master/styles/bright-v8.json\nOn the right side is the normal raster tile version with this style https://github.com/mapbox/mapbox-studio-osm-bright.tm2.git\nThere is somehow a difference between the Mapbox GL OSM Bright and the TM2 OSM Bright style.\n. @klokan I created a repository with instructions to build an electron app for offline serving of our vector tiles. Right now I use tessera so no Mapbox GL. I couldn't get it to work with Mapbox GL. Would love to hear if you can get it to run with my instructions.\n. In order to wrap the app in an installer, the native node modules(node-mapnik) need to be rebuilt.\nHere a comment, which describes why the native modules need to be rebuilt:\n\nElectron is using the V8 shipped by Chromium, which is usually much newer than the V8 used by Node, and the differences are big enough to make native modules compiled for electron and Node not compatible. I'm afraid this incompatiblity is not going to change because we can not force Chromium to be built with older V8.\n\nThe documentation of electron describes how to do this. But unfortunately it always exited with an error. I don't think that we can do anything about this.\n. They are using Electron (previous atom-shell), but Dane Springmeyer explained in this issue that they are not using node modules in Mapbox Studio at all.\nHere his comment:\n\nMapbox studio is not using atom shell and node-sqlite3 in the same process. The lack of binary compatibility with node was a major deterant. Because we have multiple node c++ addons and support multiple platforms having to provide 2x the binaries for atom-shell is not viable for us at this point. So Mapbox Studio is only using atom shell for the browser and not taking advantage of the ability to call into node modules.\n\nBut how can they do the mbtiles export in Mapbox Studio if they are not using any node modules at all?\n. @klokan I uploaded a mbtiles of the world for z0 - z7. It looks the best with the newest OSM Bright style.\n. @klokan Right now we are not doing any generalization on the land shapes. It seams Mapbox GL can't handle all of these details we provide. I will have a look into this.\n. Identified same problem on layer poi_label:\nsql\nSELECT geometry, osm_id, ref, website,\n     poi_network(type) as network,\n     poi_address(housenumber, street, place, city, country, postcode) as address,\n     name,\n     coalesce(NULLIF(name_en, ''), name) AS name_en,\n     coalesce(NULLIF(name_es, ''), name) AS name_es,\n     coalesce(NULLIF(name_fr, ''), name) AS name_fr,\n     coalesce(NULLIF(name_de, ''), name) AS name_de,\n     coalesce(NULLIF(name_ru, ''), name) AS name_ru,\n     coalesce(NULLIF(name_zh, ''), name) AS name_zh,\n     format_type(type) AS type,\n     scalerank_poi(type, area) AS scalerank,\n     coalesce(classify_maki_label(type), 'marker') AS maki,\n     rank() OVER (PARTITION BY LabelGrid(geometry, 128 * 9.55463)\n                  ORDER BY localrank_poi(type) ASC) AS localrank\n   FROM (\n    SELECT * FROM (\n        SELECT geometry, osm_id, ref, website,\n            housenumber, street, place, city, country, postcode,\n            name, name_en, name_es, name_fr, name_de, name_ru, name_zh,\n            type, 0 AS area,\n            timestamp\n        FROM osm_poi_point\n        UNION ALL\n        SELECT topoint(geometry) as geometry, osm_id, ref, website,\n            housenumber, street, place, city, country, postcode,\n            name, name_en, name_es, name_fr, name_de, name_ru, name_zh,\n            type, area,\n            timestamp\n        FROM osm_poi_polygon\n    ) AS poi_geoms\n   ) as t\n   WHERE z(34123.7) = 14\n     AND geometry && ST_SetSRID('BOX3D(942927.1809259342 6018345.859061636,947819.1507361856 6023237.828871887)'::box3d, 3857);\nThe topoint function gets executed for each osm_poi_polygon even these which are not in the bbox. We solve it by taking the topoint function out of the view into the query. Result: 1913 ms to 31 ms\nsql\nSELECT topoint(geometry), osm_id, ref, website,\n     poi_network(type) as network,\n     poi_address(housenumber, street, place, city, country, postcode) as address,\n     name,\n     coalesce(NULLIF(name_en, ''), name) AS name_en,\n     coalesce(NULLIF(name_es, ''), name) AS name_es,\n     coalesce(NULLIF(name_fr, ''), name) AS name_fr,\n     coalesce(NULLIF(name_de, ''), name) AS name_de,\n     coalesce(NULLIF(name_ru, ''), name) AS name_ru,\n     coalesce(NULLIF(name_zh, ''), name) AS name_zh,\n     format_type(type) AS type,\n     scalerank_poi(type, area) AS scalerank,\n     coalesce(classify_maki_label(type), 'marker') AS maki,\n     rank() OVER (PARTITION BY LabelGrid(geometry, 128 * 9.55463)\n                  ORDER BY localrank_poi(type) ASC) AS localrank\n   FROM (\n    SELECT * FROM (\n        SELECT geometry, osm_id, ref, website,\n            housenumber, street, place, city, country, postcode,\n            name, name_en, name_es, name_fr, name_de, name_ru, name_zh,\n            type, 0 AS area,\n            timestamp\n        FROM osm_poi_point\n        UNION ALL\n        SELECT geometry as geometry, osm_id, ref, website,\n            housenumber, street, place, city, country, postcode,\n            name, name_en, name_es, name_fr, name_de, name_ru, name_zh,\n            type, area,\n            timestamp\n        FROM osm_poi_polygon\n    ) AS poi_geoms\n   ) as t\n   WHERE z(34123.7) = 14\n     AND geometry && ST_SetSRID('BOX3D(942927.1809259342 6018345.859061636,947819.1507361856 6023237.828871887)'::box3d, 3857);\nLearning: Views are good to make the queries more readable. Expensive functions like topoint should be executed on the smallest set of geometries possible. \n. We did some analysis of our vector tiles, therefore I created two gists one which compares the size of mapbox-streets-v6 with open-streets and another which compares the features.\nsize compare: https://gist.github.com/manuelroth/ae138de3155519512bd1/revisions\nfeature compare: https://gist.github.com/manuelroth/28fadbed722e3f1ce633/revisions\nResults:\n| Zoom level | Diffs (os: open-streets, v6: streets-v6) |\n| --- | :-- |\n| 5 | too many roads (open-streets: 41066 features / streets-v6: 6 features), don' show type trunk |\n| 6 | too many roads (os: 23221 / v6: 12), layer poi_label, road_label missing |\n| 7 | too many roads (os: 35185 / v6: 11), layer poi_label, road_label missing |\n| 8 | too many road_labels (os: 3575 / v6: 17), layer poi_label missing |\n| 9 | too many road_labels (os: 1611 / v6: 19) |\n| 10 | layer poi_label missing |\n| 11 | too many road_labels (os: 1936 / v6: 47) |\n| 12 | too many road_labels (os: 5191 / v6: 26) |\n| 13 | too many roads(os: 2986 / v6: 21), too many road_labels (os: 2027 / v6: 54) |\n| 14 | too many buildings (os: 3227 / v6: 1624), too many roads (os: 2343 / v6: 995), too many road_labels (os: 1637/ v6: 45) |\nIt seams that our main problems are the layers roads and road_labels, we show too many of them. Of course we can see a lot more differences in the gist, but I think these are the main reason for the bigger size of our vector tiles.\n. @leblowl The branch with the necessary changes is now merged. As proposed in #80 we have now a standalone export, it is called export-local. I would love to hear, if it works for you now.\n. haha yes I think so.\n. As #92 is closed, this issue can also be closed.\n. Thanks, we moved the maps example to http://klokantech-{s}.tileserver.com/ with access key. \n. - Style Buttons like mapzen https://mapzen.com/projects/vector-tiles\n- Height of map plus 100px\n. Added attribution \"OpenStreeMap contributors\"\nMoved Vector Tile maps and 3 Raster Tile maps to klokan tileserver (http://klokantech-{s}.tileserver.com/)\nThe maps demo should now be finished.\n. This is now solved.\n. @klokan I created a pull request for the reference to the getting started tutorial on the tileserver-mapnik repository https://github.com/klokantech/tileserver-mapnik/pull/5\n. Vector Tileserver link: http://klokantech.tileserver.com/v1/index.json?key=WQ5sRntXphOrWgesmtmU\n. Added check if mapboxgl is supported in ae471174088bab4e8b4d643cb4550bfbab5ab8af.\n. With the new website we don't have any dependancies on mapbox anymore all fonts and sprites are served from https://github.com/osm2vectortiles/mapbox-gl-styles repository\n. - Label rendering problems with mapbox gl is fixed since the following pull request https://github.com/mapbox/mapbox-gl-js/pull/1727\n- However label rendering issues can still be found with raster maps, we don't have a solution for this yet\n. The label rendering problem is fixed as of https://github.com/mapbox/mapbox-gl-js/pull/1727. So I think this issue can be closed.\n. As this empty tiles do not appear anymore, I will close this issue.\n. OSM2VectorTiles v2.0 looks now more like Mapbox.\n\n. @hannesj In Mapbox Streets v7 a new layer rail_station_label was introduced. It provides a field maki, which lets you distinguish between different types of stations (subway stations are called rail-light, rail station are called rail). Furthermore there is now a network field which reflectes the OSM network key. This makes it possible to assign more specific icons for rail stations that are part of specific local or regional transit systems. \nThe layer rail_station_label will be available in the next version of our vector tiles.\n. @lukasmartinelli Yes, the layer rail_station_label has been implemeted in #204, the more specific network field will be implemented in #229 \n. @lukasmartinelli I am totally okay with that. Since these new projects will evolve over time, we should just keep in mind that the osm2vectortiles project now depends on them.\n. - This helps to fix https://github.com/osm2vectortiles/osm2vectortiles/issues/74\n. @lukasmartinelli Thanks for the info. Added them with commit https://github.com/osm2vectortiles/osm2vectortiles/commit/9a2927d053273a10d0ff222b79666d3f61e89a7a\n. - Improved the documentation of own-vector-tiles to include instructions to modify the BBOX environment variable in the docker-compose.yml file https://github.com/osm2vectortiles/osm2vectortiles/commit/92f47d9beb81f691d006feeb08fae2b25a394cdf\n- Added optional instructions to merge lower zoom levels (z0 to z5) into extract https://github.com/osm2vectortiles/osm2vectortiles/commit/d39d57bb3164d9e725e3034313b61f3b4b47be12\n@stephankn Would appreciate your feedback on this. If you have further improvements, it would be nice if you could create a pull request on the gh-pages branch. You can find the own-vector-tiles documentation in the docs/own-vector-tiles.md file.\n. Looks good to me. Do you want to add the city extracts in a later pull request?\n. We could probably add the functionality to merging lower zoom levels (planet z0 to z5) into the extracts in a later pull request\n. Oke, I agree. Let's discuss it further on thursday.\n. Seeing this error also in the feature/detect-dirty-tiles branch, it occurs in the module mapnik. I will merge the feature/detect-dirty-tiles branch anyways. We have to fix this in a later pull request. Maybe it helps to upgrade the mapnik node module to the latest version. But this is a task in its own.\n\n. @ImreSamu fixed this issue with his pull request #160. Really appreciate your contribution, thank you.\n. Yes, thats a problem we need to find a stable link to an older pbf of lichtenstein.\n. Oh I just found out that they only keep the extracts of the last 5 days plus the extract of the second of each month.\nliechtenstein-151201.osm.pbf    2015-12-02 07:54\nliechtenstein-160101.osm.pbf    2016-01-02 05:26\nliechtenstein-160201.osm.pbf    2016-02-02 05:18\nliechtenstein-160301.osm.pbf    2016-03-02 06:45\nThis means we are save, if we choose the monthly extract.\n. Thank you very much for your contribution. Executing the queries as a batch is definitely more efficient. I saw that you are actually the maintainer of the pg-promise module. How did you find our repository?- I think this is a very interesting way of showing the users of your library how they can improve their code.\n. That's awesome, thank you for taking the time. I will definitely merge your contribution.\n. Thanks for your suggestion, was a bit too fast with the merging;) Pushed it to the master branch\n. That makes sense.\n. We discussed today, that we will submit two separat proposals for FOSS4G.\nFirst proposal:\n- Explaining the process of vector tile creation\n  - Import OSM, Natural Earth, Custom data\n  - Update scaleranks\n  - Export process\n- Step-by-Step instructions (from OSM data to vector tiles)\n- Demo: Vector Tiles creation of small extract\nWe will create a first draft this week.\n. FOSSGIS Proposal\nEinleitung:\nDas Projekt OSM2VectorTiles bietet einerseits einen Workflow um selbst Vektor Tiles aus OpenStreetMap zu erstellen und bietet diese andererseits gratis zum Download an.\nDer Workflow um die Vektor Tiles zu erstellen ist Open Source und kann verwendet werden um eigene Vektor Tiles zu erstellen. Dies erm\u00f6glicht jedem eine selbst gestaltete Karte der gesamten Welt zu erstellen und anzubieten, ohne Kenntnisse von PostGIS und Mapnik zu haben.\nInhalt:\nIn der Pr\u00e4sentation zeigen wir, wie man in wenigen Minuten seine eigene Karte designen und verwenden kann. Wir f\u00fchren zuerst durch ein simples Kartendesign in Mapbox Studio \nund zeigen wie man eine eigene Karte ohne Abh\u00e4ngigkeiten auf externe Anbieter zur Verf\u00fcgung stellt. Danach zeigen wir wie man das Gleiche mit einer lokalen Kopie der Daten erreichen kann.\nIm Gegensatz zu anderen Kartenanbietern sind die Daten frei verf\u00fcgbar, somit lassen sich auch Offline Applikationen auf Desktop und Mobile umsetzen. Mit dem Mapbox GL SDK k\u00f6nnen Vektor Tiles auch offline auf dem Smartphone mit einem eigenen Kartenstil verwendet werden.\nZiel:\nDie Zuh\u00f6rer wissen nach unserer Pr\u00e4sentation wie sie eine selbst gestaltete Karte erstellen und ver\u00f6ffentlichen k\u00f6nnen. Zudem k\u00f6nnen sie die vom OSM2VectorTiles Projekt zur Verf\u00fcgung gestellten Daten verwenden, um ihre Karte auch Offline anbieten zu k\u00f6nnen.\n. Thanks for your suggestion. We took the best of both proposal drafts and submitted the final proposal. \n. @klokan Added you as another speaker\nFollowing the proposal was submitted:\nThe OSM2VectorTiles project offers free downloadable vector tiles ready to use by people interested in hosting custom base maps on their own infrastructure. The whole world fits on a USB stick and can be served from an ordinary web hosting and styled and enriched to make beautiful and fast maps for web and mobile applications.\nThe advantages of vector tiles over traditional raster tiles are well known. There are already a handful of vector tile provider present, but they may not always serve your use case optimally. After this talk you will know how to create your own custom vector tiles based on OpenStreetMap and will know the tools and processes you need to use.\nThe talk will cover how to import OpenStreetMap data into PostGIS and then shows how to generate vector tiles using Tilelive and Mapnik. We will present the open source workflow we use at OSM2VectorTiles to prerender global vector tiles and instruct you how to adapt the workflow to create custom vector tiles. Thanks to Docker and tools such as Mapnik, PostGIS, Tilelive and Mapbox Studio Classic the process is straightforward and repeatable.\n. So, @lukasmartinelli and me are going to be at FOSS4G somewhere between 24th and 26th of August and at FOSSGIS on the 5th of July (9.30 AM GI Studio). @ImreSamu @hannesj @muesliq @hyperknot @numenor do you plan to attend one of these conferences, would be a great chance to meet you guys in person after all these great contributions, ideas and discussions.\n. - Add something to OSM and check if it appeares in our vector tiles\n. Will close this, as was already done during the implementation process.\n. ### Comparison Results:\nThe following measurements were made on the same data with the same machine\n```\nTraversing quadtree CTE query:\nz8 query: 239 rows: 63.467 ms\nz9 query: 350 rows: 152.138 ms\nz10 query: 526 rows: 411.682 ms\nz11 query: 770 rows: 1789.290 ms\nz12 query: 1372 rows: 8835.929 ms\nz13toz14 query: 7259 rows: 64910.485 ms\ntile-cover node module:\nz8 query: 239 rows: 2ms (31x faster)\nz9 query: 350 rows: 4ms (38x faster)\nz10 query: 526 rows: 5ms (82x faster)\nz11 query: 770 rows: 10ms (178x faster)\nz12 query: 1372 rows: 17ms (519x faster)\nz13toz14 query: 7259 rows: 392ms (165x faster)\n```\nIn conclusion the numbers tell us, that the traversing quadtree approach depends on the zoom level and the tile-cover approach depends on the amount of rows.\n. traversing quadtree approach:\nThe following query generates the dirty tiles for each changed feature separately:\nSELECT * \nFROM (\n  WITH RECURSIVE dirty_tiles(x, y, z, e) AS (\n  -- root node (0, 0, 0)\n  SELECT 0, 0, 0, EXISTS(\n    SELECT 1 FROM changed_poi_points WHERE geometry && CDB_XYZ_Extent(0, 0, 0)\n  )\n  UNION ALL\n  -- coordinate for the children\n  SELECT x*2 + xx, y*2 + yy, z+1, EXISTS(\n    SELECT 1 FROM changed_poi_points\n    WHERE geometry && CDB_XYZ_Extent(x*2 + xx, y*2 + yy, z+1)\n    ) FROM dirty_tiles,\n    -- iterate over 4 children\n    (VALUES (0, 0), (0, 1), (1, 1), (1, 0)) as c(xx, yy) \n    -- only for tiles with geometry and up to zoom level 14\n    WHERE e AND z < 7\n), changed_poi_points AS (\n  SELECT * FROM landuse_z7 WHERE timestamp = '2016-03-02 20:14:02'::timestamp\n)\nSELECT z, x, y FROM dirty_tiles where e\n) as a\nWHERE z BETWEEN 7 AND 7;\nThis query is executed for each zoom level view of the layer.\n. Non working example:\nCREATE OR REPLACE FUNCTION detect_dirty_tiles(\n    geometry_argument geometry\n) RETURNS TABLE (\n    z INTEGER,\n    x INTEGER,\n    y INTEGER\n) AS $$\nBEGIN\n    RETURN QUERY(\n        WITH RECURSIVE overlapping_tiles(x, y, z, overlaps) AS (\n        SELECT 0, 0, 0, geometry_argument && CDB_XYZ_Extent(0, 0, 0)\n        UNION ALL\n        SELECT x*2 + xx, y*2 + yy, z+1, geometry_argument && CDB_XYZ_Extent(x*2 + xx, y*2 + yy, z+1)   \n        (VALUES (0, 0), (0, 1), (1, 1), (1, 0)) as c(xx, yy) \n        WHERE overlaps AND z < 14\n        )\n        SELECT z, x, y FROM overlapping_tiles WHERE overlaps\n    );\nEND;\n$$ LANGUAGE plpgsql IMMUTABLE;\n. > List of all layers / tables which has \"name\", \"name_en\", etc. and whether we have bounding box: a) in the same table b) in a different table - and which one c) not imported by imposm3 mapping d) completely missing in OSM\na) layers / tables with bounding box (geometry) in the same table:\n- road / osm_roads (no polygon only linestring)\n- road_label / osm_roads (no polygon only linestring)\n- water / osm_water_polygons\n- water_label / osm_water_polygons\n- waterway / osm_water_lines (no polygon only linestring)\n- waterway_label / osm_water_lines (no polygon only linestring)\n- marine_label / custom_seas (no polygon only linestring and point)\nb) layers / tables with bounding box (geometry) in a different table:\n- poi_label / osm_poi_points => aeroway, landuse, landuse_overlay, building\nc) layers / tables with bounding box (geometry) not imported by imposm3 mapping:\n- place_label => admin\n- state_label / custom_states => admin\n- country_label / custom_countries=> admin*\nd) layers / tables with bounding box (geometry) completely missing in OSM:\n- (place_label, state_label, country_label)\n*Administrative boundaries are currently stored as linestrings to convert them to polygons a new mapping would be required.\nBoundaries are represented as linestrings in OSM that are linked together with a relation, therefore imposm3 would have to convert these relations to polygons.\nWe decided against this last year because not all linestrings could be converted to polygons, this resulted in missing boundaries for some countries and admin areas.\nThe open question c) and d) is still how to map the label to the polygon. See Stefan's post about relations => https://github.com/geometalab/OSMNames/issues/1\nConclusion\nBecause simply joining the tables is not possible in all cases, a new imposm mapping needs to be done for the layers place_label, country_label, poi_label.\n. Created basic export for table osm_roads as explained in https://github.com/geometalab/OSMNames/issues/1. I will let the code stay in branch feature/export-geonames until we decided how to organize the osmnames project.\n. Thank you very much for your patch @ImreSamu. We already created an issue to fix this bug, but with your great patch this issue is now fixed. The build runs now again without errors, so I will merge your pull request.\n. Looks good to me.\n. @numenor thanks again for your comprehensive list. Below you can find the list with referenced commits if added or an explanation if not added. All commits can be found on the mapping_improvements branch. \n1. https://github.com/osm2vectortiles/osm2vectortiles/commit/98b4047dfb0bb493c321c7f051edeecfc90f445e Temporarily added, we will evaluate how this will affect the tile size and decide later if we really keep them\n2. place={island, islet, isolated_dwelling} added with https://github.com/osm2vectortiles/osm2vectortiles/commit/2561827d71c1e8b75174530d2989660b99ffb5f1 .\n   place={country, continent, bay, ocean, sea, state} are not mapped, because we have custom lists for countries, states and seas, therefore they are not listed in our import mapping, but are already present in our vector tiles.\n3. Added the capital value with https://github.com/osm2vectortiles/osm2vectortiles/commit/2561827d71c1e8b75174530d2989660b99ffb5f1 place importance is distinguished with the scalerank and localrank, we will think about if we can incorporate this value into the scalerank calculation\n4. https://github.com/osm2vectortiles/osm2vectortiles/commit/1ecf0b9409bcb1bb01c1e784f0df4965a6fe07d2\n5. and 6. natural={peak, ridge, valley} will be part of new layer mountain_peak_label which is newly added by Mapbox Streets v7\n6. https://github.com/osm2vectortiles/osm2vectortiles/commit/2e2eba178147df4b04d58705156ad8fd45889e17\n7. https://github.com/osm2vectortiles/osm2vectortiles/commit/7cf2b128574df29b5f16f3c19ba60499a7704c1a and https://github.com/osm2vectortiles/osm2vectortiles/commit/62b589b74f1972cde524bed774ff4dacfa94fc7a\n8. https://github.com/osm2vectortiles/osm2vectortiles/commit/79925ca9ef177dc9d4c212e5e55fc3ab9fcb0a6a\n9. Mapbox Streets adds track:grade{1-5} as type for roads with class track\n10. highway=path add attribute bicycle=designated and bicycle=yes for complete cycleway map => Mapbox Streets has special type for cycleway (general many different types for class=path)\n11. https://github.com/osm2vectortiles/osm2vectortiles/commit/925e405c063c9911fcc3c94d3055c5e1dd66e4f9\n12. Added with https://github.com/osm2vectortiles/osm2vectortiles/commit/98b4047dfb0bb493c321c7f051edeecfc90f445e landuse=military to layer landuse with this tag military={airfield, naval_base, training_area, barracks} are all covered\n13. Add type for railways with usage(branch, highspeed, industrial, main, military, tourism) like for construction, track and service\n14. https://github.com/osm2vectortiles/osm2vectortiles/commit/48a9f10c27a7d95becaa5c714644fe708be6c31d\n15. https://github.com/osm2vectortiles/osm2vectortiles/commit/f26289c828fdc637bbf652c8706bc1c3318a52bc\nThe type classification in Mapbox Streets v7 has changed a lot. Applying the type classification will resolve section 9, 10 and 13. In a next step, I will align our current mapping and source-style to all the changes the new Mapbox Streets v7 brought.\nBefore we can rerender the world again, the work on OSM Diff updates and the work on the mapping, source-style needs to be finished. As soon as we are ready we will inform you. If something is not clear, don't hesitate to ask me.\n. The work on Mapbox Streets v7 is tracked in this issue #204 \n. Naming of summary views: layer_{layer name}\nExample: layer_admin, layer_landuse\nExplanation: The view returns all geometries which are shown an every zoom level combined.\n. - This was handled before directly in the source query https://github.com/osm2vectortiles/osm2vectortiles/blob/master/open-streets.tm2source/data.yml#L790 \n- https://github.com/osm2vectortiles/osm2vectortiles/commit/4366885440c42b41ce7b822415f1f731be6bb0ae moves conversion of polygon to point to the zoom level views\n. - The maki labels are provided by mapbox, since we used an old style version the specified maki labels in the old style are not served anymore by mapbox\n- The fix was to update the maki labels from {maki}-12 to {maki}-11 https://github.com/osm2vectortiles/osm2vectortiles/commit/e91fa07d016c1c149adec34ea72b18fec7ea81f6\n. Hi @brewin, thanks for your report. We have custom curated lists of states, seas and countries. You can simply add the missing items to the corresponding geojson and create a pull request. \n. @klokan The data like name, translations and geometry is based on OSM data. We extracted it with the overpass api. These custom geojson's were created because we wanted to add our own scalerank. Neither OSM nor Natural Earth provide a good scalerank, because of this we decided to do this solution.\n. I just figured out, that Alaska and Florida are not included because we did not extract them correctly. I will create a pull request and add them. \n. Added the missing states Alaska, Florida and Saskatchewan. I did not add Puerto Rica, because it is not a state of america\n. - Fix bugs in queries https://github.com/osm2vectortiles/osm2vectortiles/pull/192/commits/17c298f93052119e76f71c4553a45a647532ed12 https://github.com/osm2vectortiles/osm2vectortiles/pull/192/commits/cc72d1d672d806573a7a300cab3a81364873d0b2\n- But could not verify that the process works\n. This looks good to me.\n. https://osm.wno-edv-service.de/boundaries/ provides OSM boundaries \n. As the problems disappeared in our latest import this issue can be closed.\n. This patch probably saves thousands of computing hours :tada: \n. I tried to implement the shield and network fields based on the OSM network tag. The network tag for swiss railways contains the following values:\n``` sql\n         network          \n\nTarifverbund Zug\n ZVV;Tarifverbund Zug\n CFF\n ZVV;FlexTax\n libero\n Gotthard-Matterhorn Bahn\n tarifverbund schyz\n Jungfraubahnen\n FlexTax\nLibero\n AOMC\n Ostwind;VVV\n ZVV\n A-Welle\n Verticalp Emosson\n ZVV;tarifverbund schyz\n SAINT-BERNARD EXPRESS\n Verticalp\n Tarifverbund Schwyz\n Ostwind\n```\nIt is almost impossible to map these values to the appropriate value mapbox defines here, because the values do not contain any country ISO code. I decided to stay with the default values.\n. - Found some cases where the buffer size was \"not correct\" for example layer landuse and landuse_overlay both use the table landuse_polygon, landuse has buffer size of 4 and landuse_overlay a buffer size of 8 =>  In this case we should go for 8 (same for layer water/water_label and waterway/waterway_label)\n- Surprisingly the buffer size of layer poi_label was incorrect in our source project, corrected it from 128 to 64\n- Found a todo comment in the triggers.sql file, could you verify that the dynamic triggers make it slow?\nTODO: Perhaps a dynamic trigger is really slow\nif it is a performance problem we should generate static\ntriggers for each table\n. No not your fault just found out in Streets v6 the buffer value for layer poi_label was indeed 128px. Good that we found out now \ud83d\ude04 . But there was no word of this in the changelog.\n. Wow this is really great. Tested on the switch sever, worked fine.\n. This labels are of type suburb, I tried to describe to problem of showing the most important suburbs earlier in my pull request https://github.com/osm2vectortiles/osm2vectortiles/pull/248\n. I suggest the following mapping. islands, islets and archipelago are in polygon because the are most of the time mapped on the area. \nThe following are in my opinion not needed, can't remember why we added them to the mapping.\nregion\ncounty\ndistrict\nmunicipality\nlocality\nyaml\ntype_mappings:\n  point:\n    place:\n      city  \n      town  \n      village\n      hamlet\n      suburb\n      neighbourhood\n      isolated_dwelling         \n  polygon:\n    place:\n      island\n      islet\n      archipelago\n    landuse:\n      residential\n    boundary:\n      aboriginal_lands\n. Just tested it, looks good on first sight. Ouu didn't thought about that. Let's keep this in mind, if we discover duplicated place_labels again. I will commit the changes on your branch hotfix/single-place-label-table. I have also some additional improvements to the layer views.\n. Found a nasty problem, if the type_mapping types are not written in plural it won't import anything.\nyaml\ntype_mappings:\n  points:\n    place:\n      city  \n      town  \n      village\n      hamlet\n      suburb\n      neighbourhood\n      isolated_dwelling         \n  polygons:\n    place:\n      island\n      islet\n      archipelago\n    landuse:\n      residential\n    boundary:\n      aboriginal_lands\npolygons is correct, polygon not. @lukasmartinelli is this somewhere documented?\n. http://wiki.openstreetmap.org/wiki/DE:Tag:railway%3Dstation\n\nEs bietet sich an, einen Bahnhof als einen Punkt zu mappen. Bei einem Bahnhof mit nur einem Bahnsteiggleis kann es sinnvoll sein, diesen direkt auf den Schienenweg (railway=rail) zu setzen. Bei Bahnh\u00f6fen mit mehreren Gleisen bietet es sich an, diesen Punkt ungef\u00e4hr in der Mitte des f\u00fcr den Bahnkunden relevanten Bereichs (Empfangsgeb\u00e4ude, Bahnsteige) zu setzen. Keinesfalls sollte ein Bahnhof durch mehrere Punkte (z. B. an jedem Bahnsteiggleis) getagged werden\u01c3\n. Ok found out, why we have so many labels. We map railway=stop, which is why our labels are at the end of the platform. We should actually only map railway=station for the label.\n. Classification of street_limited was incorrect. Fixed in https://github.com/osm2vectortiles/osm2vectortiles/pull/286\n\n. I thinks we can ignore this for now, checked other junctions for wrong z-order. Could find any errors. \n. Thanks for asking, the new planet file with extracts and updated documentation should be available at the end of may.\n. It seams Mapbox does not show tram stations at all. I think the tram stations are a good orientation point we should keep them. We don't have a localrank currently, how is the localrank calculated for the highway shields?\n. Fixed by https://github.com/osm2vectortiles/osm2vectortiles/commit/06df45e5198ff9efcb14204f9e0358affa95a9e9 and https://github.com/osm2vectortiles/osm2vectortiles/commit/8a9036f7556275716caa0143a342dfb0db499d4c. Found out that in Streets v7 there are more landuse areas shown on lower zoom levels than in Streets v6. Need to adjust our generalized landuse tables in a follow up, would probably be better to test this on a bigger import (europe or world).\n\n\n. - @lukasmartinelli I don't see a straight forward solution for this. Tried to show more landuse on lower zoom levels, this resulted in way more features than Mapbox has. \n- Natural Earth does not provide a land cover table which we could use. \n- Generalization of the OSM landuse polygons with ST_SimplifyPreserveTopology does also not help much. The polygons get indeed simpler, but there are still too many of them.\n- @klokan @ImreSamu do you maybe know of a open dataset which provides land cover data for lower zoom levels (z5 to z9, does not need to be very detailed but for the whole world)\n- Or is there a PostGIS function which allows to combine multiple adjacent small geometries into big geometries? \n. > Yes; since PostGIS version 2.2.0: http://postgis.net/docs/manual-dev/ST_ClusterWithin.html\nOh nice, so this groups the geometries by a distance and then ST_Union can be used to combine them to one geometry. I will give this a try, we would probably have to do this in a preprocessing step. I will just check if can come visually and size-wise close to Mapbox.\n. ### Preparation\nThe following query creates a table containing the clustered landuse multipolygons. Detail explanation below:\nsql\nCREATE TABLE landuse_clustered AS \n    SELECT ST_CollectionExtract(unnest(ST_ClusterWithin(geometry, 4000)),3) AS geometry \n    FROM osm_landuse_polygon_gen0\n    WHERE type IN ('wood');\nST_ClusterWithin - Clusters the geometries within the distance of 4000, returns an array of GeometryCollections\nunnest - Expands the array to a set of rows\nST_CollectionExtract - Returns a single multipolygon geometry for each GeometryCollection\nMapbox Tile Analysis:\n| zoom level | landuse feature average |\n| --- | --- |\n| 5 | 6 |\n| 6 | 6 |\n| 7 | 6 |\n| 8 | 6 |\n| 9 | 64 - 385 |\n| 10 | 54 - 294 |\nThe analysis shows that from zoom level 5 to 8 there are constantly 6 landuse features present in the vector tiles. Hence the distance value of the ST_ClusterWithin function must be selected so that exactly 6 multipolygons result for this tile. \nResults\nAfter playing around with it, I found that a distance of 4000 seams to result in around 6 features per tile. Need to verify this on a bigger data set. The complete implementation can be found in this pull request => https://github.com/osm2vectortiles/osm2vectortiles/pull/269\nOSM2VectorTiles Tile Analysis:\n| zoom level | landuse feature average |\n| --- | --- |\n| 5 | 5 |\n| 6 | 8 |\n| 7 | 3 - 10 |\n| 8 | 1 - 2 |\n| 9 | 147 - 421 |\n| 10 | 17 - 75 |\nVisual Result:\nThe visual result is almost identical(I only imported the data of latvia to test)\n\n. Thanks, what would the gis community do without PostGIS. It's incredibly powerful.\n. @lukasmartinelli Oh no, forgot to include them in the waterway/waterway_label view. Should I make a commit on the improved_mapping branch?\n. This is a very powerful tool, now we have way better view on what data we actually use in the vector tiles.\n. Ok, thanks.\n. Nice, great work.\n. @lukasmartinelli thats a good idea will add it to the zoom level views, same for the admin layer. Won't add the new views to the layer_* view as this view is used for the changed_tile process.\n. > > Won't add the new views to the layer_* view as this view is used for the changed_tile process.\n\n\nChanged tile process does no longer work with the zoom level views but works with the tables directly since last PR.\n\nYou could safely extend the existing views.\n\nOhh right, so we could actually remove the layer_* views?- Because these were only needed for the changed_tile process\nI mean these ones with layer views\nsql\nCREATE OR REPLACE VIEW water_layer AS (\n    SELECT osm_id, timestamp, geometry FROM water_z5toz12\n    UNION\n    SELECT osm_id, timestamp, geometry FROM water_z13toz14\n);\n. That looks really good, so a 10 - 20% decrease should be possible.\n. The mapping-qa doesn't work anymore for the layer water and admin, because the zoom level views are now mixed with natural earth and openstreetmap data. Not sure what to do. We can remove them from mapping-qa or reference the tables directly in the layer view.\nsql\nCREATE OR REPLACE VIEW water_layer AS (\n    SELECT osm_id, timestamp, geometry FROM osm_water_polygon\n);\nBut this does not make much sense. @lukasmartinelli what do you suggest?- Would appreciate a review of the zoom level views, especially the admin views. They are really complex.\n. This is because the tables are referenced directly in the layer view. Otherwise it would not work.\nObviously the following results in 100%:\nsql\nCREATE OR REPLACE VIEW water_layer AS (\n    SELECT osm_id, timestamp, geometry FROM osm_water_polygon\n    UNION\n    SELECT osm_id, timestamp, geometry FROM osm_water_polygon_gen1\n);\nFollowing does not work, because there is data in the zoom level views which is not in the mapping (natural earth, water polygons):\nsql\nCREATE OR REPLACE VIEW water_layer AS (\n    SELECT osm_id, geometry FROM water_z0\n    UNION ALL\n    SELECT osm_id, geometry FROM water_z1\n    UNION ALL\n    SELECT osm_id, geometry FROM water_z2toz3\n    UNION ALL\n    SELECT osm_id, geometry FROM water_z4\n    UNION ALL\n    SELECT osm_id, geometry FROM water_z5toz7\n    UNION ALL\n    SELECT osm_id, geometry FROM water_z8toz12\n    UNION ALL\n    SELECT osm_id, geometry FROM water_z13toz14\n);\nIn my opinion, we can leave it like this.\n. That's alright for me, just thought if the purpose of the mapping-qa is to compare the mapped features with features in vector tiles, the external data shouldn't be counted. \n. As you said the mapping-qa logic makes a select count(distinct osm_id) so the external data counts as 1 and does not destroy the statistic.\n. @lukasmartinelli have you done a world import recently?- Can we maybe use it to test this, easiest would be to create the osm_landuse_clustered table and zoom level views by hand. I only testet this with the extracts of latvia. So I am interested in how long the creation of the osm_landuse_clustered table takes and how it looks like with a bigger dataset\n. > I can execute this tomorrow. Latest import is using v1.4.1 Also need to test my table creation script as well. My guess is it can take up to a hour...\nGreat, eager to hear about how long it takes.\n\nHmm how do we handle this table (and my water labels table as well) with diff updates?\nWe need to regenerate them.\n\nOh yes, we probably have to do that. Didn't thought about it yet.\nUsed the tile-inspector of klokan for the analysis, was very helpful. Would love to do some analysis with the data of the entire world to detect the issues which create the >500 kbyte tiles.\n. Ok, I will try to find the main cause of the > 500 kbyte tiles. \n. Good news, yes that is possible. Only the landuse of type wood is selected and these landuse geometries are then clustered and combined to large geometries. How does it look with compare-visual?\n. Just tested this again with switzerland, and it does not show any landuse at all. Need to refine the implementation a bit. Currently the table is created based on osm_landuse_polygon_gen0. This filters probably too many landuse polygons out.\n. I just pushed a commit to master, I forgot to add type forest to the clustered landuse table. Now it should look a bit greener.\n. > Btw. Mapbox does something really weird on the south pole area.\n\nBut I think we are the correct ones.\n\nYes, this is way too generalized.\n. Oh thats a nasty one.\n. To combine the roads/buildings to multiple bigger multilinestrings/multipolygons I could apply the same technique as for the landuse polygons. I will make a pull request with the implementation and investigate how this impacts the tile size. \n. > Just checked housenum label is still there but it appears only in z16. Mapbox has additional z15 and z16 where they can fit stuff in (that's why there are not many buildings in z14)\nOhh right, thank you. I can see them on z16. But the layer building has still just 1 feature per tile (from z13 up to z16). I definitely think that they combine the building polygons to multiple big mutlipolygons.\n. We now have proof that combining many small geometries into mulitple bigger geometries does reduce the size of the vector tiles drastically. The data in the following table was collected from the same tile (6/22/33): \n|  | with clustering | without clustering |\n| --- | --- | --- |\n| road features | 81 | 18895 |\n| pbf size | 161 kB | 526 kB |\nThe table was created with the same technique as for the landuse polygons:\nsql\nCREATE TABLE osm_road_clustered_z5 AS\nSELECT ST_CollectionExtract(unnest(ST_ClusterWithin(geometry, 5000)), 2) AS geometry, type              \nFROM osm_road_geometry                                                                     \nWHERE ST_Geometrytype(geometry) = 'ST_LineString' AND type IN ('motorway', 'trunk')\nGROUP BY type;\n. @sfkeller In the table osm_road_geometry are geometries of type ST_LineString, ST_MultiPolygon and ST_Polygon. When I create the table without filtering the polygons and mulipolygons(plazas) out, the visual result on the map was very wired looking. Performance-wise this is not a big problem, because this  table is created in a preprocessing step.\n. > Table creation is still reasonably fast (10 minutes).\nGood news.\n\nI play around whether i can do the collection directly in the vector tile query because it also doesn't require updating the tables.\n\nThis would be great, I just worry that this makes the queries very slow. Because of this I created it in a separate table after the import process.\n. > So the GEOMETRY type must be COLLECTION. And this is fast? Anyway; in this case you could also consider \"ST_CollectionExtract(geometry collection, integer type)\".\nTable creation is still reasonably fast (10 minutes). What do you mean by \"consider ST_CollectionExtract(geometry collection, integer type)\"?\n. > This would return (multi)linestrings only. See http://postgis.net/docs/ST_CollectionExtract.html . Not sure if this helps.\nIt is already used in the query ST_CollectionExtract(unnest(ST_ClusterWithin(geometry, 5000)), 2) AS geometry\n. > If we just use st_collect and grouped by e.g. type we get only one geometrycollection per vector tile per type\nSounds good, lets try this. Would be great if we could do this right inside the query.\n. @lukasmartinelli That is really wired. Could you test this already with an other extract?\n. Created extracts of switzerland(only switzerland imported) to test whether the clustering reduces the mbtiles filesize. @lukasmartinelli did you have europa imported while doing the extracts?- The extracts seams to be a lot smaller, probably this is the reason. However I come to the same conclusion as you, clustering does not save a lot of space(less than 1%). Clustering of buildings saves the most space. \n| extract | With road, landuse, building clustered | With road, landuse clustered | With road clustered | no clustering |\n| --- | --- | --- | --- | --- |\n| switzerland | 210 Mbyte | 223 Mbyte | 223 Mbyte | 225M |\nThe clustering does not have a big impact on the overall size of the mbtile file, but it reduces the size of individual big tiles (for example 6/33/22 went from 526 kbytes down to 161 kbytes). I would like to keep the clustering just to reach the goal of not having any tiles > 500 kbytes. \n. > Does mbverify size -s 500000 show any tiles above 500KB now?\nmbverify does not show any tiles above 500KB with the clustered extracts.\n\nAnd does using ST_CollectionExtract over ST_Collect yield better results?\n\nST_Collect does return a GEOMETRYCOLLECTION this collection must be transformed to a Multi_* geometry with ST_CollectionExtract. If ST_Collect is used without ST_CollectionExtract the mbtile size is the same as with no clustering (225 Mbytes).\n@lukasmartinelli would it be possible for you to create a bigger extract  (maybe germany or france) and verify the size with/without clustering and also verify if the >500KB tiles disappear. With this we could cross check, if my hypothesis is correct for a bigger extract.\n. Oh wait, I can do that myself. Germany should be possible on my server.\n. > :grin: If you start the import now :)\n\ud83d\ude04 \n\nI am not the biggest fan of grouping the stuff together (just because we loose the osm id and make it more complicated) but the no tiles above 500KB argument is just very very important and trumps everything. :+1:\n\nYes, I am with you. It really just makes it more complicated. Let's both cross check this and make a decision afterwords. \n. @lukasmartinelli Did create an extract of germany with and without clustering(road, landuse and buildings):\n| clustering | size | time to create extract | number of tiles >500KB |\n| --- | --- | --- | --- |\n| yes | 2489MB | 1h 34min | 0 |\n| no | 2511MB | 1h 32min | 3 |\nDetails about tiles >500KB:\nbash\n6/33/21 1.2 MB\n8/132/85    585.6 kB\n8/133/85    651.3 kB\nCame to the same conclusion as before, without clustering there are some tiles which are bigger than 500KB and with clustering these get smaller but it has no impact on the overall size of the mbtiles.\n. I think we should stay with clustering for landuse and roads. Not sure if we need clustering for buildings(for germany it is not needed, as the >500KB tiles are on lower zoom levels). I will do a last test with london to find out whether there are tiles >500KB without clustering the buildings.\n. > I like this solution. Because we only loose the OSM id on low zoom levels but in the highest zoom level 14 the data is identifiable by OSM id.\n\nLet's do it like this.\n\nOkay, the test with london also didn't showed any >500KB tiles without clustering of buildings. Just to write this down here for the future. Clustering the buildings also impacts the visual appearance.\nExample with osm2vectortiles with clustering of buildings:\n\nClustered building query:\nsql\nSELECT osm_id_polygon(max(osm_id)) as osm_id,\nST_CollectionExtract(ST_Collect(geometry), 3) AS geometry,\nbuilding_is_underground(underground) AS underground\nFROM (\n    SELECT osm_id, geometry, underground\n    FROM building_z13\n    WHERE z(!scale_denominator!) = 13\n    UNION ALL\n    SELECT osm_id, geometry, underground\n    FROM building_z14\n    WHERE z(!scale_denominator!) = 14\n) AS building\nWHERE geometry && !bbox!\nGROUP BY underground\n. Great work @lukasmartinelli.\n. @lukasmartinelli Could not reproduce it on the master branch, maybe has something to do with collecting of buildings on cluster_road branch?- Think we can close this for now, as we anyways do not plan to collect buildings to one geometry.\n\n. No, thats alright these are all issues which can be solved in less than an hour and have a big visual impact. Just keep them coming if you find more of them \ud83d\ude04  \n\nResult:\nfountains/wells are now mapped as poi's.\n\n. \nAll the issues described above are now fixed\n- Default value \"marker\" is now set correctly\n- Updated maki icons (mapbox did remove many of them)\n. @lukasmartinelli what do you think about doing this optimization for poi_label, airport_label and housenum_label(all other layer which use topoint-function) as well?- The polygon geometry is also not needed for these layers.\n. - [ ] Document additional data described in #307 and how it can be styled\n. - [ ] Document what kind of hardware is needed to render a bigger city/country/world (define a scenario)\n. Great idea @ImreSamu. The current selection is very random, just chosen well-know cities of every continent. Do you have other cities you miss?\n. ### ZL 5 osm2vectortiles vs ZL 6 Google\nRoads on z5 are fine now:\n\nZL 11 osm2vectortiles vs ZL 12 Google Maps\nThe rivers in Allmendingen are tagged as waterway=stream. Mapbox shows stream from zoom level 13 on. So we won't show them already from zoom level 11. However I found out that waterway=river are already shown from zoom level 7 on. Implemented this in the following pull request https://github.com/osm2vectortiles/osm2vectortiles/pull/298 . \nZL 12 osm2vectortiles vs ZL 12 Mapbox Street v7\nBigger water polygons are as of PR https://github.com/osm2vectortiles/osm2vectortiles/pull/299 show from zoom level 11 on. Minor roads are also visible.\n\n. Shows bigger water polygons already from z11. This issue was mentioned in #295 \n\n. > I will try analyze this in the next 24h ...\nOh, no hurry. Just thought if you maybe know that. I will test this out myself.\n. You are right. It is not needed for the filter to work. Just tested it without the column natural included and the filter worked.\n. @lukasmartinelli Actually your postgis-editor gave me a hint. When I was trying to have a look at the water polygon data, an error message popped up saying \"No SRID is set on the geometry column\". I think this happened because you transform everything to WGS84 https://github.com/lukasmartinelli/postgis-editor/blob/master/src/database.js#L49. And it couldn't because no SRID was set. \nBy the way I think the tool is very useful, do you think it is hard to add copy/paste support to the editor?- Maybe a setting in the react-codemirror component. Will try to add this.\n. I think this is worth the hastle. Would love to see a PR for this. Easiest would be to change the zoom level views of all layers to use id AS osm_id. With this you don't have to touch the source project at all.\n. @ImreSamu I think we forgot to give you write access. Can you see the merge button now?\n. @ImreSamu Oh, I have just a small non-technical improvement. We try to write all SQL upper-case to have a bit of consistency through the project. Would it be possible for you to make the as upper-case?\n. Don't have permission to push on the branch of your fork of osm2vectortiles. You will have to do this. No problem if it happens tomorrow.\n. > Can you re-check again ? I think - it was because a merge conflict - and not a 'permission' problem.\n\nI resolved the merge conflict & fixed travis error .\nIf the code looks good ( need a minimal code review ) - you can merge.\n\nOk, I am fine with this you can merge.\n. I think the speedup is worth it. Using ST_PointOnSurface also not always results in perfect placement. In the case below ST_Centroid would probably even give a better result. \n\n. I will have a look into this, landuse=residential is already included in our mapping, but it is currently only present on z14 in the vector tiles. Will create a style example. \n. The following style was used to style landuse=residential:\njson\n{\n            \"id\": \"landuse_residential\",\n            \"type\": \"fill\",\n            \"metadata\": {\n                \"mapbox:group\": \"1444849388993.3071\"\n            },\n            \"source\": \"mapbox\",\n            \"source-layer\": \"landuse\",\n            \"interactive\": true,\n            \"filter\": [\n                \"==\",\n                \"class\",\n                \"residential\"\n            ],\n            \"paint\": {\n                \"fill-color\": \"#d3d3d3\"\n            }\n        }\nz8:\n\nz10:\n\n@muesliq @numenor we have added landuse={residential, commercial, retail, military, railway} can you give a suggestion for each tag on which zoom levels do you think they are useful?\n. Do you think it is necessary to have landuse=residential all the way down to z14 in the vector tiles?- Is it still useful on z14?\nz14:\n\n. Thanks for your suggestions @numenor. Created a PR with the necessary changes (#312).\n- As suggested the additional landuse data is present in the vector tiles as following:\n  - z7-z14: residential\n  - z10-z14: commercial, retail, railway, industrial\n  - z11-z14: military\n- The data can be style either by filter with the class or type attribute, both have the same value (one of residential, commercial, retail, railway, industrial, military)\n- style example:\n{\n    \"id\": \"landuse_residential\",\n    \"type\": \"fill\",\n    \"metadata\": {\n        \"mapbox:group\": \"1444849388993.3071\"\n    },\n    \"source\": \"mapbox\",\n    \"source-layer\": \"landuse\",\n    \"interactive\": true,\n    \"filter\": [\n        \"==\",\n        \"class\",\n        \"residential\"\n    ],\n    \"paint\": {\n        \"fill-color\": \"#d3d3d3\"\n    }\n}\n- The impact on size is minimal, as the data gets filtered by area like forest and wood. Check it with the tile-inspector.\n- We also have to find a good place to document this, so other people know that there is additional data in our vector tiles which are not included in Mapbox Streets v7\n. @mr Yes, you are right the documentation is out of date. We will fix that in #291. Sorry for the inconvenience. I give you the instructions here and fix it in our website.\n1. Run docker-compose run import-external - Imports external data (natrual earth)\n2. cd import && wget https://s3.amazonaws.com/metro-extracts.mapzen.com/zurich_switzerland.osm.pbf - Download some OSM data and put it in the import directory\n3. Run docker-compose run import-osm - Imports the OSM data\n4. Run docker-compose run import-sql - Imports SQL Utilities\n5. Run docker-compose run export - Creates the vector tiles and puts an MBTiles file in the export folder\n6. Run docker-compose run serve - Starts a webserver and serves from the MBTiles file\nPlease don't hesitate to write again if you experience another problem.\n. @mr Just updated the documentation for creating your own vector tiles. A more comprehensive update of your documentation will follow with #291.\n. Not yet, but this will be the server we suggest and use in our updated tutorial. Did the instructions work for you?\n. You mean black like the following?\n\nFor the data to be styled you need to download a style project and add it to the export folder.\n1. git clone https://github.com/mapbox/mapbox-studio-osm-bright.tm2.git\n2. Now run docker-compose up serve again and you should see your map with the bright style\n\n. Did you update the BBOX environment variable to fit the extract?\nIn the export part of the docker-compose.yml file there is a BBOX variable this variable defines which area should be rendered during the export process.\nexport:\n  image: \"osm2vectortiles/export\"\n  command: ./export-local.sh\n  volumes:\n   - ./export:/data/export\n   - ./osm2vectortiles.tm2source:/data/tm2source\n  links:\n   - postgis:db\n  environment:\n    BBOX: \"8.34,47.27,8.75,47.53\"\n    MIN_ZOOM: \"8\"\n    MAX_ZOOM: \"14\"\n. Also if the MIN_ZOOM variable is set to 8, the above zoom levels (0-7) won't be rendered. So if you request a tile on zoom level 0 (/0/0/0.png) like you did, you will get a black square. Probably this is the problem.\n. Not a very good default value, should definitely be 0.\n. Yes, definitely. Would it make sense to combine the 3 import steps(import-external -> import-osm -> import-sql) to one big import?- They are all depending on each other anyway.\n. @mr Would you be up to give us feedback again once we prepared the new documentation?\n. Thats good to hear. Our project site is running on gh-pages which is essentially just another branch (gh-pages) in this repository.\nHm, have you tried requesting a tile on a higher zoom level(z8 or z14). What is the extract/city you are trying to look at?- By the way xyz coordinate can very easily be retrieved with this website\n. > Is there an way I can easily zoom one of the maps to this area?\nApparently there is not an easy way to do this. \nWhat you can do is click on source code of leaflet and copy the source code into an index.html file.\n\nNow you need to alter the parameters of the setView([long, lat], zoom_level) method, for zurich this would be setView([47.3754914,8.5451405], 10):\n\nNow click on the index.html file and you should see your map zoomed in to zurich.\n. Thats great, finally more city extracts \ud83c\udf89 \n. Also had this error once, it is because bbox's starting with a negative number are not handled properly. I found a workaround, just add a space before the negative sign => \" -58.89,-34.96,-57.99,-34.29\"\n. We have to investigate, what causes this error.\n. > It is exactly that. I think using the named parameter differently 01612da can fix it (doing something like this in the export Python script).\nThat was quick \ud83d\udc4d \n. You have to run docker-compose run import-sql\n. Oh, now I get it. Can you make a git pull on the master branch?- This is a very recent change. As of https://github.com/osm2vectortiles/osm2vectortiles/commit/9649e62081b7ad71cf34cb56f6e0c6f4a56e6dcc the SQL view landuse_z5toz8 does not exist anymore, but you probably have an older version of the source-project which still references it. So pulling the latest changes and run docker-compose run export should work.\n. Just repeating the export step should work.\n. Would you be up to do a quick skype call?- It is probably easier to troubleshoot. You should find me on skype with this email adresse: manuelroth@hotmail.ch\n. Did the git pull command fetch any new changes?- It's wired that the process worked for the Zurich PBF and now this error comes up.\n. Great to hear. So is this issue resolved for you?\n. > I have a short question: if I want to add new regions can I just repeat the steps from import-osm on?\nNo the process is not intended to add multiple independent regions. The idea is to import a pbf-extract and export as vector tiles. If you want to have multiple regions this is the way to do it.\n. Hi Sergey, thanks for you feedback. \n\n\nIs it doable at all by a complete stranger? :)\n\n\nYes, we want that the process is doable by other people\n\n\nWhat branch/tag should one currently use?\n\n\nDuring the last weeks we made a lot of changes to the project, the master branch should be stable now.\n\n\nIf one is to use docs from the website, then to which version does it correspond, if that even matters?\n\n\nThe documentation will get an overhaul soon (#291), but the documentation about creating your own vector tiles is current.\n\n\nMaybe specify what type of hardware (server specs) one needs to do some useful stuff.\n\n\nThats a good idea. We can give an approximation about how long the process takes for a give type of hardware for the entire planet. What do you mean by do some useful stuff (render the entire planet?)\nWould you be up for a chat on skype?- Its probably the easiest way to troubleshoot the problems you experience. You can find me on skype with the following email address: manuelroth@hotmail.ch\n. Hi Clara,\nthis is a result of the buffer. A buffer on a layer allows you to include extra data around the outside of each tile. Depending on the data and desired styles this can be necessary to ensure seamless rendering across tile boundaries. More detailed documentation can be found here.\n. Thanks for your suggestions, updated main page, fixed wired code formatting, replace instructions with code instructions, disabled rotator function on map and update all maps to latest mapbox gl js version.\n\nWould be really cool if users can just npm install  and then do something like tileserver afghanistan.mbtiles and that's it. No cloning a repo or something. Also while it is really cool to see how easy it is to serve MBTiles this doesn't deal with all the edge cases like requests that are out of bounds or filter zoom levels or PBFs that are not gzipped.\n\nYes, this should be very easy. I like that in this example people can actually understand what happens and that there is no magic behind serving vector tiles. But it would be much easier to just do something like npm install  && tileserver zurich.mbtiles. Maybe we can have an easy example in the tutorial and additionally say something like \"we have packaged this into an npm module just run npm install tileserver\". Let's further discuss this tomorrow. \n. I'm glad you like it \ud83d\ude04  Added some nice icons, updated the description and fixed the bug where the placeholder text was oddly misaligned in Safari. \n\n. > We once discussed putting the filesize into the CSV file as well.\n\nBut while adding the filesize to the CSV is doable maintaining later will be kind of a chore.\nWe then need to update the CSV weekly with the newest filesizes.\nCan we just leave out the filesize for city and country extracts?\n\nI agree, maintaining this would be a pain. Found out that it is pretty easy to get the metadata of a bucket. One can just make a GET request on the bucket and it will return metadata about all of its objects. Just pushed a commit which retrieves the file size for each object of this metadata. \nThis way we don't have to maintain the size value, the draw back is that we need to do an extra ajax call. But I think it's worth it, it is an important information to decide whether you want to download it or not.\n. Yes, you are right this is probably a style problem. \nAs I can see in the dev tools, you are working with the bright-v9 style of mapbox. This style was created with Mapbox Streets v7 in mind. However the vector tiles that are downloadable from our website are only compatible with Mapbox Streets v6. This is why these style errors appear. \nWe are currently working on the next release of OSM2VectorTiles which will be compatible with Mapbox Streets v7. We will soon release the updated vector tiles. In the meantime you can use the bright-v7 style which was built for Mapbox Streets v6 vector tiles. It should look way better with our vector tiles.\n\n. > I'm not sure if this is an issue, but I cloned the mapbox-gl-styles repo fresh from Github to follow the readme instructions, installed tileserver-vector and downloaded the .mbtiles for my country, started tileserver-vector fine, created an index.html in the repo folder pointing to the bright-v9 style, but the map appears empty and no tiles are being served:\nThis is not ready to be used yet. We will provide better documentation on how to use this in the coming weeks. \n. Thanks for your contribution. This looks great.\n. @lukasmartinelli this PR https://github.com/osm2vectortiles/osm2vectortiles/pull/366 needs to be merged first before we are able to create MVT v2 compatible vector tiles. But it would definitely be a good idea to test first if these rendering artifacts now disappear.\n. I think this is resolved now. Seams to work properly again. Will close this issue.\n. Thanks for this contribution, but you need to explain way you want to add this. We won't merge an uncommented PR. \n. > Secondary roads (dutch N-roads) are not styled in tm2 OSM-Bright and street tiles with the new planet.mbtile (they did style correctly with the old world.mbtile)\nI want to give a bit of background on this decision. We set the target to be compatible with the Mapbox Streets tileset, this has the benefit that people can create styles with Mapbox Studio and use them together with OSM2VectorTiles. So we implemented all layers and attributes according to the documentation of Mapbox Streets.\nWhen we started to work on OSM2VectorTiles last September the current version of Mapbox Streets was version 5. This tileset was meant to be used together with the TM2-Style projects such as osm-bright.tm2. \nSince then the Mapbox Streets tileset has evolved a lot. Two new version(v6 and v7) where released since then, which are meant to be used with the new Mapbox GL Style the style which can be downloaded from Mapbox Studio. When we started to work on the second version of OSM2VectorTiles it was clear that we want to support the newest version(v7). \nSo we recommend using the Mapbox GL Styles together with Mapbox GL JS. As Lukas already mentioned we won't support using the TM2-Styles anymore and therefore also won't release updated TM2-Styles. \n. Please check out our new tutorial. It explaines how to set up a basic tileserver which serves the vector tiles, mapbox gl styles(bright, streets, basic, dark, light), fonts, sprites and renders the map inside your browser using Mapbox GL JS.\n. Thanks mickael, this is very motivating. It is great to see more and more people getting interested in our project. It confirms the need for a free and open vector tile set.\n. > Finding better word than those from Mickael is hard,\n\nI also tried to express my appreciation for all your work, see #327 (comment)\nSo what do you think about an announcement in any form you like and want about release progress?\nOr are things still to early?\n\nSorry for not replying to your comment stephan, we appreciate all the interest. We would love to announce the second version of the OSM2VectorTiles tile set in some way. I will write to the people at OSMBlog and WeeklyOSM, maybe they can mention us in their next post. Thanks for the hint.\n. @clintharris Thanks for the report, I am working on a fix for the bug. Also enabled the issues section on the tileserver-gl-light repository. \n. @lukasmartinelli nice, thank you.\n. Great, that you enjoyed our talk at FOSSGIS. tileserver-gl-light is not meant for production use cases, therefore there is and will be no option to configure the port. We only built it to get people started quickly. \nIf you intend to create a production ready vector map, please consider building your own tileserver. The mbtiles files available on the downloads section are basically only a sqlite database (with columns x,y,z, tile), this means you can build a server which reads of this sqlite database. Tobin Bradley has created a great example based on NodeJS. Check it out here. \nWe are not interested in helping people to build there own tileserver, as the intention of this project is to create vector tiles based on OpenStreetMap.\n. We have recently moved from Postgres 9.4 to 9.5. I suppose that you need to delete the pgdata container as well. As the error message notes that the database was initialized by PostgreSQL 9.4. \n. ### Planet filename proposal\nschema: planet-{date}-{md5-hash}.mbtiles\nexample: planet-270716-a426f297c4936f97f2a14fc5a386e3dd.mbtiles\nThis way a user which has downloaded the planet file knows how current the planetfile is (date) and directly has the md5 hash to verify the file. Secondly, we don't have to update the md5 hash on the website on every upload anymore, because we can extract the hash programmatically based on the filename \ud83c\udf89 \nIs there a convention around using minus (-) or underline (_) as filename separator?- Thinking about harmonizing the filenames of the city and country extracts. Some of them use both (minus and underline) in their filename like the following: v2.0/extracts/mountain-view_california.mbtiles. I think we should decide on one.\n@lukasmartinelli what do you think about this?- The create-extract.py script would probably need to be modified to take the planet filename as argument. So that it is possible to assign a different filename on each upload of the planet file. Couldn't find the code which uploads the planet file and planet zoom levels, is this done manually right now?\n. > Good idea for the planet. Will start using this.\nCool.\n\n- means space (mountain-view -> Mountain View).\n_ is the separator that separates the city from the region/country (originating from Metro extracts)\n\nAlright, now I understand. We will let it how it is right now. \n\nI usually rename the file before doing it but adding a env var is easy.\n\nSo no code changes need to be made, great. \n. Thanks @pendolf. \n. > I have got some information like picture below, but I still want to know the detail information in the [object] list. and How can I resolve them. thank you :)\nAs lukas suggested to read the detail information you need to parse this with a MVT parsing library:\nMVT Library for Python\nMVT Library for JavaScript\nExample of MVT JavaScript library which outputs all layers in a vector tile:\njavascript\nzlib.unzip(tile, function(err, tile) {\n        if (!err) {\n            var rawTile = new VectorTile(new Protobuf(tile))\n            var tileLayers = rawTile.layers;\n            console.log(tileLayers);\n        }\n});\nIn the example above you can see that the tile gets unzipped, read with the Protobuf library, and then with the MVT Javascript Library. Mapbox Vector Tiles are stored in a highly optimized way. So the representation in your picture above is not suitable to work with. It is necessary to use the MVT Library in order to correctly read an Mapbox Vector Tile.\n. You are totally right. I will remove them.\n. Would be nice, if it was that easy. It is just a workaround for now. It works for the oceans, but not for seas and bays(the labelranks varys between 2-5)\n. Not yet, but I added the additional mappings to the classify.yml file in the generate-sql branch. We can merge this tomorrow.\n. Just pushed a commit to master https://github.com/osm2vectortiles/osm2vectortiles/commit/03d81ecefec7687485d5a716a6c7f1890c68628e . Yes, landuse_class(type) should be used. Removed forest as it is already included in the class wood.\n. This function is redundant.\n. ",
    "ImreSamu": "Hi! \nsome side notes based on my research in this topic:\n- I agree:  The quick (&dirty)  way now to detect changes \n  - the postgresql side with: insert , delete trigger  ( As I know not need update trigger,  - but please verify ! )  and save  the old and the new   -  geom \n  - the delete trigger is also important!  ( you only mentioned the  a INSERT trigger )\n- I have created some experimental imposm3 mapping types - like :   jobstart_datetimeutc timestamp , maybe you can use!\n  important: this code not working with the current imposm3 version,  need adapting.  If you need help : ping me - and I will create a patch.\n- There is an interesting project : https://github.com/mapbox/tile-cover\n  - maybe some ideas can be reused,\n  - or temporary used in the toolchain\n  - or implement the algorithm in the imposm3 side ( golang )\n. Thanks! \n. http://taginfo.openstreetmap.org/projects/osm2vectortiles#overview\n. > Because when we tested this we saw that imposm3 takes care \n\nof avoiding duplicate ids when you use a geometry table containing both linestrings and polygons.\n\nbefore #305  -  2 ids  were in the table..\n- id  :  artificial \"Id\"   -  this was always unique - because of the QGIS\n  - generated by:   nextval('osm_admin_linestring_id_seq'::regclass)\n  - http://www.postgresql.org/docs/9.5/static/functions-sequence.html\n- osm_id :  the osm natural key\nso my guess -  this type of problem has existed before #305  \nI tested with the mapzen extract ( with the latest osmium tool )\nrm -f helsinki_finland.osm.pbf\nwget https://s3.amazonaws.com/metro-extracts.mapzen.com/helsinki_finland.osm.pbf\nosmium getid helsinki_finland.osm.pbf w33085001 -r -o helsinkitest.osm.pbf\nosmium cat helsinkitest.osm.pbf -f opl\nwith the current Imposm3 version and with  following current osm2vectortiles mapping modifications:\ncp ../mapping.yml ../o2vm.yml\nsed -i \"s/pbf_timestamp/string/g\"   ../o2vm.yml\nsed -i \"s/name: id/name: osm_id/g\"  ../o2vm.yml\nAnd I got: \nsql\n+ psql -d imposm3dev -c 'select id, osm_id, type, ST_GeometryType(geometry) as geometryType from osm_road_geometry'\n id |  osm_id   |    type    | geometrytype  \n----+-----------+------------+---------------\n  1 | -33085001 | pedestrian | ST_LineString\n  2 | -33085001 | pedestrian | ST_Polygon\n(2 rows)\nplease  somebody verify my test ...\n. > What do you think about removing duplicates via a SQL query?\nIn theory this is an easy task, \nIF  we have \n-   area=yes  information \n-  and areaKeys metadata [ whitelist, blacklist ]\n  -  based on this :  https://github.com/osmlab/id-area-keys \nbut in practice ... \n. > a really huge diagram where almost too much is displayed.\nI agree, usability is important.\nFor me a simple xref table is perfect in the future.  ( individual osm key ->  sql tables -> layers )\nThank you in advance!\n. > What would like to hear in a FOSS4G talk about OSM2VectorTiles\nmy list:\nUsed open source technologies & projects.\nBenchmarks and data sizes :\n- planet\n- big country (  osm pbf extract size:  1-5 GB )\n- small country (  < 500Mb )\nFuture roadmap \nExtending the data modell & customisation:\n- How to add new language code \n- How to add new osm keys ( like whllechair= )\n- How to add new layers \nComparing the Alternative solutions with osm2vectortiles\n- Mapzen ,  Kartotherian, ...\n. other conference for presenting: \n\"Propose your session to State of the Map 2016!  ( The deadline is May 21, 2016. )\"\nhttp://2016.stateofthemap.org/   [ September 23 - 25, 2016 ;  Brussels ]\n. FOSSGIS 2016 \n2016 - Manuel Roth: Vector Tiles from OpenStreetMap\nhttps://www.youtube.com/watch?v=lG7atynI8Pk\n. Probably this is not the optimal patch  \ndisclaimer:\n- I am not a java expert \n- I used the  \"trial and error method\"\n. I will make some tests ..\nplease do not merge yet \n. > It look okay, shall we merge it?\nIt is okay,   \nGood but not perfect solution.\nThe only problem,  that this solution  is not support PG 9.5 yet.  :(\nYou can merge if you want ...  but no problem if you rework or replace with a better solution.\nThanks!\n. Other solution is using  https://github.com/le0pard/pgtune main calculation logic\nIt has a PG 9.5 support.\n. Thank you! \n. In the   src/import-osm/import.sh code,  the function exec_sql()  always return  true.   ( || true )\nSo maybe this is the reason , that travis not detect the SQL errors.\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-osm/import.sh#L161\n. > We also don't know how imposm3 reacts\nI will analyze the imposm3 diff part...\nprobably a simple   delete trigger  is enough to catch this information.\nAs I remember Imposm3 diff use : \n-  sql delete \n-  sql insert   ( now this is ok - with timestamp )\n\nGeometries that are deleted will vanish over time \n\nsometimes geometries modified, and POIs moved to the other part of the Earth\nMy other extreme test is the node  number 1\nhttp://www.openstreetmap.org/api/0.6/node/1/history\nSame node & different tiles  : \n- version=5 :   lat=\"51.249182\" lon=\"9.4316934\"\n- version=11:  lat=\"-31.638757\" lon=\"-60.693853\"\n- version=13:  lat=\"48.566985\" lon=\"13.4465242\"\n. yes ..\na simple Delete trigger enough to catch the old records \nmy draft code:\n``` SQL\nDROP TABLE IF EXISTS changed_osm_poi_point; \nCREATE TABLE changed_osm_poi_point(\n   id        SERIAL\n  ,osm_id    bigint\n  ,name      character varying \n  ,timestamp timestamp not null default current_timestamp\n  ,geometry  geometry(Geometry,3857) \n);\nALTER TABLE changed_osm_poi_point\n  OWNER TO osm;\nCREATE OR REPLACE FUNCTION osm_poi_point_del_trigger()\n  RETURNS trigger AS\n$BODY$\nBEGIN\n     IF (TG_OP = 'DELETE') THEN\n        INSERT INTO changed_osm_poi_point(\n                    osm_id\n                   ,name \n                   ,geometry     \n                   )\n        VALUES(\n                   OLD.osm_id\n                  ,OLD.name \n                  ,OLD.geometry\n        );\n        RETURN OLD;\n      END IF;\nEND ;\n$BODY$ language plpgsql;\n;\nDROP TRIGGER IF EXISTS o2v_del_trigger ON osm_poi_point; \nCREATE TRIGGER o2v_del_trigger\n  BEFORE DELETE\n  ON osm_poi_point\n  FOR EACH ROW\n  EXECUTE PROCEDURE osm_poi_point_del_trigger();\n```\n. > Is it perhaps better to explicitly let the user put a changes file\n\nin the import folder themselves and just apply the changes file.\n\nin my  dev machine the osmupdate  sometimes is not working   :(  \nAnd sometimes I reach the geofabric download limit.\nI would like if  import_pbf_diffs()  will be separated smaller callable  functions\nnow\ndocker-compose run import-osm-diff\nideal for me \ndocker-compose run import-osm-diff  ./import-osmupdate.sh\ndocker-compose run import-osm-diff  ./import-imposm3diff.sh\ndocker-compose run import-osm-diff  ./import-updatetimestamp.sh\ndocker-compose run import-osm-diff  ./import-merge_latest_diffs.sh\n. optimalisation is not easy  :) \n\nchanged tiles detection is now running since 14 hrs instead of one.\n\nimho:  it  can be more parallel  \nmy tips:\n-  forcing an extreme parallelism in the postprocessing part  (  by imposm3 tables ) \n  -   now only 1 osm_delete  table  ->  why not for every imposm3 tables? my guess: it can be a bottleneck,  because of the parallel trigger insert.\n    - osm_admin_linestring_delete\n    - osm_aero_linestring_delete\n    - osm_aero_polygon_delete\n    - ...\n  - using  'unlogged' or 'temp'    *_delete tables\n    - CREATE UNLOGGED TABLE  osm_admin_linestring_delete AS ...\n  - parallel generation of  changed tiles\n    -  ->  ./export/admin_z2toz6_tiles.txt \n    -  ->  ./export/admin_z7toz14_tiles.txt\n    -  ->  ./export/aeroway_z12toz14_tiles.txt\n    -  ....\nand at the end   -  fast linux postprocessing  ( or using a `process  queue` .. )\n-  cat ./export/admin_z2toz6_tiles.txt  ./export/admin_z7toz14_tiles.txt  ... | sort -u > ./export/tiles.txt\n\n\nchanged tiles detection is now running since 14 hrs instead of one.\n\nwith more optimalisation we can create an intelligent  changed tile processing queue \nlike ..\n- if the ./export/admin_z2toz6_tiles.txt   generation is the fastest ( 30 min)  then we can add to the processing queue  for generating tiles \n-  later the ./export/admin_z7toz14_tiles.txt  is finished , so we can add this tiles for processing ( but adding only the new tiles!\n  similar than :  diff  admin_z2toz6_tiles.txt admin_z7toz14_tiles.txt   )\n. > Regarding Bitmap Index Scan ..\nmy optimization idea  ( need more research , and for  just the v2.x iterations  ) \nIDEA:   Data processing optimized imposm3 mappings ( = more logical partitions )\nThe current design is  one database table per layer sometimes not optimal,\nbut we can split the big  massive tables  into many smaller tables ( called partitions or child tables)\nso, Instead of one big osm_road_geometrytable and a complex filtering \n- there will be   6 road child tables  +  simple SQL type in filtering\n- OR there will be ~25  road  child tables and optimal solutions for the 'road_label' and 'road' layers.\nfor example the  ~25   road  child tables example :\n- road_z10 layer will be the SQL UNION of the following new child tables\n  - road_motorway\n  - road_trunk\n  - road_primary\n  - road_secondary\n  - road_motorway_link\n  - road_major_rail\n  - road_major_rail_light\n  - road_tertiary\nPRO:\n- optimized tables for rendering - performance gain\nCON:\n- to complex design , lot of tables\n  - need some hand made design tools,  meta tables , ....\n- We need to add some clever post-processing and/or some advanced filtering :\n  - for example the mis-tagged osm objects with:  railway=rail AND golf=hole  \nRISK:\n- The current (nonofficial and not final and not matured ) advanced filtering  -> work in progress  \nSTATUS:\n-  only draft design:   xls \n  - 6 road child tables\n  - 25 road child tables  \nMORE IMPROVED IDEA:\n- the  ( next generation)  imposm3 will have an  Auto-partitioning  support.\n  - and will  be automatically  generating  PG Master and Child Tables  from the mapping definitions.\n    -  by  type  ( = mapping_value )\n    -  and/or  by QuadTiles\n. > Why so many changes at boundaries? \nmy2c:  OSM butterfly effect :  https://en.wikipedia.org/wiki/Butterfly_effect\nThe butterfly effect refers to a concept that small causes can have large effects.\nfor example modifying small part of France - Schweiz border : http://www.openstreetmap.org/changeset/39252252\nHas an effect of other part of the  French-administered territories ...\n\n- Wikipedia: Overseas departments and territories of France\n- Map of  French Overseas Departments and Territories\n\nSeems admin boundaries are often affected\n\nprobably the 10day refresh rate for  #admin    to short  \nData updates / Update frequency   based on Mapbox specification:\n- V7 #admin irregular schedule; every 2-6 months\n- V6 #admin irregular schedule; every 2-6 months\n- V5 #admin every few months\n. > Correctness should still be the same - will need to check whether it results in more tiles to rerender\nMy guess, that there will be some difference - at least with this tables:\nosm_admin_linestring\nosm_place_geometry\nosm_poi_point,\nosm_poi_polygon\n*osm_water_linestring\nI have created a simple QA sql scipt -to detect  imposm3 mapping problem.\nthe current problem:  the imposm3 tables have more record than needs for layers.\nsee output for hungary osm extract and code \nhttps://gist.github.com/ImreSamu/fb1cf6f78226aefb16b671ebf071afeb#file-sql_output-txt\nmy proposed solution: ( not tested yet! )\n- osm_admin_linestring  : filtering with admin_level 2 and 4  ( need more modification ) \n  - alternative solutions: create 2 table  osm_admin2_linestring and osm_admin4_linestring \n- osm_place_geometry    : add filtering    name <> ''\n- osm_poi_point,        : add filtering    name <> ''\n- osm_poi_polygon       : add filtering    name <> ''\n- osm_water_linestring  : add filtering    name <> ''\nAs I know it is not easy filtering  name <> ''  with imposm3\nI have tested few solutions - probably the imposm3 patching the best:\nhttps://github.com/ImreSamu/imposm3/commit/f1401d1fa2cb0114e010089a0c39b1bcdb71013f\nso probably the following will work ( but I am not fully tested! )\nfilters:\n      exclude_tags:\n      - [ \"name\", \"__nil__\" ]\nthe second best solution : normal SQL delete \non the other side:\nI don't like the current v7 version, because don't show the some important POI-s without name tags.  for example  the amenity=pharmacy : \n- Wordwide    : 78% has a name ( http://taginfo.openstreetmap.org/tags/amenity=pharmacy#combinations )\n- Switzerland : 86% has a name ( http://taginfo.openstreetmap.ch/tags/amenity=pharmacy#combinations )\n- Hungary     : 66% has a name ( http://taginfo.openstreetmap.hu/tags/amenity=pharmacy#combinations )\n  Probably I need create more QA report in this topics.\n. > Btw. do you know what use_single_id_space in imposm3 means?\nmain purpose is avoid conflicts of OSM_ID-s   ; see RelIdOffset info:\n- https://github.com/omniscale/imposm3/blob/master/element/element.go#L113\n- https://github.com/omniscale/imposm3/search?utf8=%E2%9C%93&q=RelIdOffset&type=Code\nthis is similar function like  new   OSM ID Transformation \u00e0 la Mapbox  (  see #212 )\nmy opinion : \n- The Mapbox solution is better for the  zigzag encoded  vectortiles compression.\n. > Great insights - so we leave it like it is now. Didn't find any docs on it.\nmy research based opinion:\n- the The Mapbox solution is perfect for  Vectortiles \n  - theoretically no osm_id collision.\n  - and perfect for compressing\nBut now for imposm3 processing  need use_single_id_space: true\n- for   NO  osm_id collision       (  or not use  type_mappings )\nsee more:\n- https://github.com/osm2vectortiles/osm2vectortiles/issues/281\n. The osm_admin_linestring  perfect filtering is not so easy. \nso I would like extending the imposm3 filtering more   -  in the next 48hours\n and create 100% filtering for every table.\n. otherside: Quest for unused database columns :)\n- osm_admin_linestring - area       ?\n- osm_airport_point    - name_int   ?\n- ...\n. FYI \n\nThe osm_admin_linestring perfect filtering is not so easy.\n\nThe current version is very good, but not perfect for osm_admin_linestring\nyml\n    filters:\n      exclude_tags:\n      - [ \"admin_level\", \"__nil__\" ]\n      - [ \"admin_level\", \"3\" ]\n      - [ \"admin_level\", \"5\" ]\n      - [ \"admin_level\", \"6\" ]\n      - [ \"admin_level\", \"7\" ]\n      - [ \"admin_level\", \"8\" ]\n      - [ \"admin_level\", \"9\" ]\n      - [ \"admin_level\", \"10\" ]\n    mapping:\n      boundary:\n      - administrative\n      - maritime\nfor example:    admin_level=11   and boundary=administrative\nand very hard to add all exceptions, typos ...\nNot critical, but I have created an extended filtering version ,  with the following new experimental syntax : \nfilters:\n   exclude_tags\n   - [ key, val]                       // AND key != val\n   - [ key, __nil__]                   // AND key IS NOT NULL\n   - [ key, __any__]                   // AND key IS NULL\n   - [ key, val1,val2]                 // AND key not in ( val1,val2 )\n   - [ key, val1,val2,val3, ... valn]  // AND key not in ( val1,val2,val3, ... valn)\n   include_tags\n   - [ key, val]                       // AND key = val\n   - [ key, __nil__]                   // AND key IS NULL\n   - [ key, __any__]                   // AND key IS NOT NULL\n   - [ key, val1,val2]                 // AND key in ( val1, val2 )\n   - [ key, val1,val2,val3, ... valn]  // AND key in ( val1,val2,val3, ... valn)\nhttps://github.com/ImreSamu/imposm3/commit/0df03ae6a535271686e22326790e6010f2a8d249\nthis is allow much perfect mapping, like : \nyml\n    filters:\n       include_tags:\n       - [\"admin_level\", \"2\",\"4\"]                            \n    mapping:\n       boundary:\n       - administrative\n       - maritime\n( need more test )\n. > Just my 2 cents. I would have expected that the filters work more like the mapping.\nagree ..\nthe include_tags not a perfect name.\nthis is an easy hack, and the imposm3 algorithm  in inside  logical AND - and to big work to change that to OR\nWhat about renaming include_tags  to more precise name like:\n-   exclude_negated_tags\n-  exclude_negate_tags\n-  negate_exclude_tags\n-  and_exclude_negated_tags      ( contains the and word )\n-   ....\nso a little better  ... \nfilters:\n   exclude_tags\n   - [ key, val]                       // AND key != val\n   - [ key, __nil__]                   // AND key IS NOT NULL\n   - [ key, __any__]                   // AND key IS NULL\n   - [ key, val1,val2]                 // AND key not in ( val1,val2 )\n   - [ key, val1,val2,val3, ... valn]  // AND key not in ( val1,val2,val3, ... valn)\n   exclude_negated_tags\n   - [ key, val]                       // AND key = val\n   - [ key, __nil__]                   // AND key IS NULL\n   - [ key, __any__]                   // AND key IS NOT NULL\n   - [ key, val1,val2]                 // AND key in ( val1, val2 )\n   - [ key, val1,val2,val3, ... valn]  // AND key in ( val1,val2,val3, ... valn)\n. Done ..   see  #259 \nModify , adapt or drop   as you like :)\nI would like to create other QA scripts,\n- so it would be better if there will be some  meta tables   for the views \n. imho:\n\nSo if I understand it correctly - the use_single_id_space is an internal imposm3 implementation \nof the what Mapbox OSM ID does - just done differently.\n\nfrom a bird's\u2013eye view:   yes\n\nAccording to my understanding, both are convertable there and back and equal in semantic.\n\nas I know the MapboxV7id containing more information\n- [ this is_polygon or NOT ? ]\n  see my proposed function\n  https://github.com/osm2vectortiles/osm2vectortiles/pull/287#issuecomment-214432750\n\nImposm3 process the diffs correctly only if used with use_single_id_space.\n\nmy current understanding:\n- with type_mappings    - this is a MUST have parameter.\n- without type_mappings - this is useful ( but diff will work without use_single_id_space )\nFrom QA view : use_single_id_space:true  is ideal for clean database design\n( in the future )   I will re-check again, and I will try to create a patch for imposm3 - for warning other users! \nSummary:\n- The 'no brainer' - safest settings for every case:  use_single_id_space:true \n. > Or what about using the imposm3 id as ID for the vector tiles? \n\nThere will be compression drawbacks?\n\nThe compression drawbacks is my speculation - not fact or test based.\nOn the other hand - I will be interested the real size numbers .. \n. just 1 quick comment:\n- your graph is correct, \nbut here  need reverse  ways <-> Relations :   \nid < - 1e17: Ways\n0 < id > - 1e17: Relations\nimho - the correct :\nid < - 1e17: Relations \n0 < id > - 1e17: Ways\nsee my examples - from the test data #281 \nrealtions\nsql\n -100000000000000003 | archipelago       | r3-place-archipelago-UPDATED!!!!!\n -100000000000000002 | island            | r2-place-island\n -100000000000000001 | residential       | r1-landuse-residential\nways\nsql\n                  -3 | aboriginal_lands  | w3-boundary-aboriginal_lands-inner\n                  -2 | islet             | w2-place-islet-inner\nnodes\nsql\n                   1 | neighbourhood     | n1-place-neighbourhood\n                   2 | hamlet            | n2-place-hamlet\n                   3 | isolated_dwelling | n3-place-isolated_dwelling\n. as usual ..  it is a matter of taste .. \nbut \n- with the #284  patch there will be a problem, because we will lost the geometry information (osm_id_geometry() )   [ this is polygon or not ? ]\n  so there will be a problem with the proposed  2 step conversion , without redesign.\nmy alternative solutions:\n``` sql\n-- specification : https://www.mapbox.com/vector-tiles/mapbox-streets-v7/\n-- osm_ids :  imposm3 single space id\nCREATE OR REPLACE FUNCTION osm_ids2mbid (osm_ids BIGINT, is_polygon bool ) RETURNS BIGINT AS $$\nBEGIN\n RETURN CASE\n   WHEN                      (osm_ids >=    0  )                    THEN (       osm_ids          * 10)       -- +0 point \n   WHEN (NOT is_polygon) AND (osm_ids >= -1e17 ) AND (osm_ids < 0 ) THEN ( (abs( osm_ids)       ) * 10) + 1   -- +1 way linestring\n   WHEN (    is_polygon) AND (osm_ids >= -1e17 ) AND (osm_ids < 0 ) THEN ( (abs( osm_ids)       ) * 10) + 2   -- +2 way poly\n   WHEN (NOT is_polygon) AND (osm_ids <  -1e17 )                    THEN ( (abs( osm_ids) -1e17 ) * 10) + 3   -- +3 relations linestring\n   WHEN (    is_polygon) AND (osm_ids <  -1e17 )                    THEN ( (abs( osm_ids) -1e17 ) * 10) + 4   -- +3 relations poly                   \n   ELSE 0\n END;\nEND;\n$$ LANGUAGE plpgsql IMMUTABLE;\nCREATE OR REPLACE FUNCTION is_polygon( geom geometry) RETURNS bool AS $$\nBEGIN RETURN CASE\n        WHEN ST_GeometryType(geom) IN ('ST_Polygon', 'ST_MultiPolygon') THEN true\n        ELSE false\n      END;\nEND;\n$$ LANGUAGE plpgsql IMMUTABLE;\nselect osm_id\n      ,osm_ids2mbid ( osm_id,   is_polygon( geometry ) )  as from_real_geom\n      ,osm_ids2mbid ( osm_id,   false                  )  as from_fake_geom_false \n      ,osm_ids2mbid ( osm_id,   true                   )  as from_fake_geom_true     \nfrom osm_place_geometry ;\n   osm_id        | from_real_geom | from_fake_geom_false | from_fake_geom_true\n\n---------------------+----------------+----------------------+---------------------\n -100000000000000003 |             34 |                   33 |                  34\n -100000000000000002 |             24 |                   23 |                  24\n -100000000000000001 |             14 |                   13 |                  14\n                   1 |             10 |                   10 |                  10\n                  -3 |             32 |                   31 |                  32\n                  -2 |             22 |                   21 |                  22\n                   2 |             20 |                   20 |                  20\n                   3 |             30 |                   30 |                  30\n(8 rows)\n```\nand carefully - we can use the  is_polygon parameter for tables - without checking real geometry. \nnow\nsql\n SELECT osm_id_geometry(osm_id, geometry) as osm_id\n             , geometry\n              , barrier_line_class(type) AS class\n          FROM barrier_line_z14\nBut if we knows that barrier_line_z14  is not contains polygons,\nthen we can use the 'false' constant - to the 'is_polygon' information.\n[  and  we can add a Check Constraints for safer implementation ]\nso the optimal will be:\nsql\n SELECT osm_ids2mbid ( osm_id,   false  )  as osm_id\n             , geometry\n              , barrier_line_class(type) AS class\n          FROM barrier_line_z14\nThis is not perfect yet ,   but  maybe you can reuse some ideas ..\n. whatever you choose  please double check the  id: place_label  - osm_id conversion,\n- because everything will be a node. (  after this change:  #284  )\nhttps://github.com/osm2vectortiles/osm2vectortiles/blob/436c1b028276a7fc5edff2519be871bcd6108582/osm2vectortiles.tm2source/data.yml#L645\n. added the functions : https://github.com/osm2vectortiles/osm2vectortiles/pull/290\n\nWe gave you contributor access on osm2vectortiles as we really appreciate your input and work.\n\nThank you! :) \n. I propose a new tradition :)\n- Every new OSM2Vectortiles member has to be a right to propose a new city extracts.\nMy choose : \n-  Budapest (Hungary) : http://www.openstreetmap.org/relation/1244004\nRationale: \n- the ideal for testing maps   -> always on the contributor  neighborhood \n- ( and )  a little reward  :)\n. automatic selection is a good idea. \nmy first  proposal  -  for fine customization:\n- with a basic filter  -\n  -  for capital cities \n    - [ population  >  0.5M AND  capital=yes  AND   [ area(city) / area(country) < 0,3 ] ]\n  -  and  for  the big cities .\n    -  [  population >  2M    AND   [ area(city) / area(country) < 0,3 ] ]\n- with\n  - include(city list )\n  - exclude(city list) \nthe [ area(city) / area(country) < 0,3 ]  for  excluding   ( like Singapore,  Vatican )\nfor example - now there are 2 versions in the downloading:\n-  Singapore as a City \n-  Singapore as a Country\n  see  create-extracts.sh\ncreate_extract \"singapore.mbtiles\" \"103.4666667\" \"1.0303611\" \"104.6706735\" \"1.6130449\"\ncreate_extract \"singapore.mbtiles\" \"103.84417\"   \"1.28469\"   \"103.86235\"   \"1.30287\"\nEDITED:\nThe suggested  Mapzen for their metro extracts - is much better and easier ..\nbut there will be a some overlapping with city-states\n-  but this is not a big problem yet  (a little more more cpu, more disk )\n. I will try analyze this in the next 24h ... \n. thanks,\naccording to my knowledge - I am 95%  sure, that not need to add, because the natural key is already in the mapping file \n- natural=cliff\n- natural=earth_bank\nso it will be in the imposm3 cache file.\nand probably the imposm3 is adding the excluded keys to the imported tag list.\n( but I will re-check this deeply - because this validated info is needed my advanced filtering patch )\n. Thank you! \nI will try to research more deeply - and I will create a new branch  with a proposed new changes \n[  in a next few days ] \n. Code merged.  -  Mission completed.\n. @lukasmartinelli  - I can't see, the Merge button ..\nso please DO !     :) \n. -  Merge button OK :)\n-  as upper-case :    Yes , but only tomorrow ..\n( But no problem If you do this yourself   ...     )\n. @manuelroth \n\nDon't have permission to push on the branch of your fork of osm2vectortiles.\n\nCan you re-check again ?  I think -  it was because a merge conflict - and not a 'permission' problem.\nI resolved the merge conflict & fixed travis error .\nIf the code looks good ( need a minimal code review ) -  you can merge. \n. thanks. done! \n. for a Data-Based Decision Making   :) \nwhat is the Word/Europe TOP  3  max  distance ?  ( if possible with osm link )\nsql\nselect\n   St_distance ( geometry, St_Centroid(geometry       )) as centroid_distance\n , osm_id   \n , name\n , type\nfrom osm_poi_polygon\norder by centroid_distance  desc\nlimit 10\nsql\nselect\n   St_distance ( geometry, St_Centroid(geometry       )) as centroid_distance\n , osm_id   \nfrom osm_housenumber_polygon\norder by centroid_distance  desc\nlimit 100\n. my quick example: Iceland  TOP5 \ngolf_course  http://www.openstreetmap.org/way/241775051\ngolf_course  http://www.openstreetmap.org/way/241777061\ngolf_course  http://www.openstreetmap.org/way/241699781\ngolf_course  http://www.openstreetmap.org/way/27813922\nhotel http://www.openstreetmap.org/way/227004878\n. one solution for big polygons .. \n-  https://github.com/mapzen/vector-datasource/blob/master/data/split_to_tiles.sql\n. Good performance vs. The polygon outlines  ...  you have to choose one ! \nother method  ( adding ; just for a documenting purpose ) :\n- ST_Subdivide()    http://blog.cartodb.com/subdivide-all-things/\n  from the blog: \"Subdividing big things can make map drawing faster too, but beware: once your polygons are subdivided you\u2019ll have turn off the polygon outlines to avoid showing the funny square boundaries in your rendered map.\"\n. > But for the entire workflow we want to stay with Docker\n+1  \n\nRunning the database in a Docker container is absolutely fine\n\nin the PGConf EU 2016 at least 2 presentation were about Database Containerization:\n- Mladen Marinovi\u0107 :  \"Dockerizing a Larger PostgreSQL Installation: What could possibly go wrong?\"\n- Honza Horak:  \"Database containers in enterprise world\"\nAnd Docker is a good way to improve reproducibility in software engineering research:\n- https://scholar.google.com/scholar?q=Docker+containers+repeatability+reproducibility+science\n. my proposal for the new pgtune :  https://github.com/osm2vectortiles/pgtune\n( it is clean and simple code - for me )\nIf no other better solution - I will try to customize ..\n. > What about this mapping?\nperfect.  ( but later we can create a special imposm3 mapping - for this case ) \nWe can also use the  \"admin_centre\" information  to add missing capital infos.    For example: http://www.openstreetmap.org/node/35295150 ( name=Lausanne,  place=city )\nis  part of:\n- Relation Vaud r1702421 (as admin_centre)\n  - admin_level=4  and boundary=administrative\n- Relation Ancien district de Lausanne r6205453 (as admin_centre)\n  - admin_level=6 and boundary=historic\n- Relation Lausanne r1685018 (as admin_centre)\n  - admin_level=8  and  boundary=administrative\ncurrently no capital osm key for \"Lausanne\", \nbut we can assign \"capital\"=\"4\"   (  from the  parent Relation Vaud : admin_level=4 )\n. I have started analyze the new version:\n- created a new test method  https://github.com/osm2vectortiles/osm2vectortiles/pull/370\n- selectedswitzerland-160601data from Geofabrik \n- and generated 2 versions  (old: 443c7a5   vs. new: 2904e5a )\n- compared the output with simpletextfile compare` tools.\nWhat I found \n-  different numbers of  (count( distinct osm_id ))  / views    --->   need more research:\n  - 443c7a5-22a1861e2b0e30364306763178356fd4-switzerland-160601--R001.txt  uniq_id col\n  - 2904e5a-22a1861e2b0e30364306763178356fd4-switzerland-160601--R001.txt  uniq_id col\n- example landuse_z9\n  - old  443c7a5   uniq_id=    7831       (count( distinct osm_id ))\n  - new 2904e5a  uniq_id=    8230       (count( distinct osm_id ))\nNOW :\n- I am checking my test code ...\n- and thinking what is changed ...\n. @lukasmartinelli \nnot easy to debug ...\nbut I have found a strange thing:\nLanduse problem  :\n- osm_id: -8818325 \n  -  in the landuse_z5toz6\n  -   missing from  the landuse_z7toz8 \n  -  in the landuse_z9\n  -  in the landuse_z10 \n  -  ...\nsql\n  osm_id  |            t             |     st_area()    |  area  \n----------+--------------------------+------------------+--------\n -8818325 | osm_landuse_polygon      | 502549.741585023 | 502550\n -8818325 | osm_landuse_polygon_gen1 | 492359.970306903 | 502550\n -8818325 | osm_landuse_polygon_gen0 | 550089.108481817 | 502550\n -8818325 | landuse_z5toz6           | 550089.108481817 |       \n -8818325 | landuse_z9               | 550089.108481817 |       \n -8818325 | landuse_z10              | 550089.108481817 |       \n -8818325 | landuse_z11              | 492359.970306903 |       \n -8818325 | landuse_z12              | 502549.741585023 |       \n -8818325 | landuse_z13toz14         | 502549.741585023 |\ncurrent code  ; probably an area filter is missing from the landuse_z5toz6\n``` sql\nCREATE OR REPLACE VIEW landuse_z5toz6 AS\n    SELECT id AS osm_id, geometry, type\n    FROM osm_landuse_polygon_subdivided_gen0\n    WHERE landuse_class(type) = 'wood';\nCREATE OR REPLACE VIEW landuse_z7toz8 AS\n    SELECT id AS osm_id, geometry, type\n    FROM osm_landuse_polygon_subdivided_gen0\n    WHERE landuse_class(type) IN ('wood', 'residential')\n      AND area > 1000000;\n```\nproposed code ..    and don't know the correct number ...  so please replace the 20101001 value ...  \n``` sql\nCREATE OR REPLACE VIEW landuse_z5toz6 AS\n    SELECT id AS osm_id, geometry, type\n    FROM osm_landuse_polygon_subdivided_gen0\n    WHERE landuse_class(type) = 'wood'\n        AND area > 20101001;    --- ??? just a big random number ,  please replace ...  \nCREATE OR REPLACE VIEW landuse_z7toz8 AS\n    SELECT id AS osm_id, geometry, type\n    FROM osm_landuse_polygon_subdivided_gen0\n    WHERE landuse_class(type) IN ('wood', 'residential')\n      AND area > 1000000;\n```\n. ### V2 vs. V3   landuse_z9\nSometimes, \n- the ST_Area( ST_SimplifyPreserveTopology(..)) is less than the original area -and this made a lot of differences ..   in the FILTERS ... \nExample\nOLD   (  not in the  osm_landuse_polygon_gen0 ,  landuse_z9 , landuse_z10  )\n-  IF  ( (ST_Area( ST_SimplifyPreserveTopology(. ,50 )))   )   >  500000         ??\n-  IF   499821.313229277   >  500000      ====>  FALSE\nsql\n  osm_id   |            t             |     st_area      \n-----------+--------------------------+------------------\n -24456875 | osm_landuse_polygon      |  518755.58416851\n -24456875 | osm_landuse_polygon_gen1 | 499821.313229277\n -24456875 | landuse_z11              | 499821.313229277\n -24456875 | landuse_z12              |  518755.58416851\n -24456875 | landuse_z13toz14         |  518755.58416851\n(5 rows)\nNEW   and the correct !\n-  IF   area    >  500000     ??\n-  IF 518756    >  500000   ====> TRUE\nsql\n  osm_id   |            t             |  area  |     st_area      \n-----------+--------------------------+--------+------------------\n -24456875 | osm_landuse_polygon      | 518756 |  518755.58416851\n -24456875 | osm_landuse_polygon_gen1 | 518756 | 499821.313229277\n -24456875 | osm_landuse_polygon_gen0 | 518756 | 373871.896598971\n -24456875 | landuse_z9               |        | 373871.896598971\n -24456875 | landuse_z10              |        | 373871.896598971\n -24456875 | landuse_z11              |        | 499821.313229277\n -24456875 | landuse_z12              |        |  518755.58416851\n -24456875 | landuse_z13toz14         |        |  518755.58416851\n(8 rows)\nSummary: \n-  Differences exists , \n  - but, the new data is better  and consistent. \n. probably the most of the differences caused by the  ST_Area( ST_SimplifyPreserveTopology(..))\nand sometimes it is added more layers  ( new_more  ), and  sometimes the opposite ( new_less  ) ..  \nsql\n         new_more         |         new_less         | count |    avg_oldsumarea    |   avg_newsumarea    \n--------------------------+--------------------------+-------+----------------------+---------------------\n {landuse_z10}            |                          |     2 |  494673.185000000000 | 506308.425000000000\n {landuse_z10,landuse_z9} |                          |    77 |  503636.569480519481 | 499136.174805194805\n {landuse_z11}            |                          |  1286 |   54571.799813374806 |  51437.336967340591\n {landuse_z7toz8}         |                          |   156 | 1006398.427179487179 | 992488.533333333333\n {landuse_z9}             |                          |   349 |  532264.967191977077 | 515288.751977077364\n                          | {landuse_z10}            |    38 |  489284.804736842105 | 496802.466578947368\n                          | {landuse_z10,landuse_z9} |    28 |  552432.312500000000 | 492980.784642857143\n                          | {landuse_z7toz8}         |   105 |  991525.200666666667 | 975871.633238095238\n(8 rows)\nAnd the average area ( 'avg_oldsumarea', 'avg_newsumarea' )  is similar than in the filters ..\n-   50000 ,  99000,  500000 ,  1000000\n'\n*  'landuse_z7toz8'    ,  'osm_landuse_polygon_subdivided_gen0;   area > 1000000   '\n*  'landuse_z9'        ,  'osm_landuse_polygon_subdivided_gen0;   area > 500000    '\n*  'landuse_z10'       ,  'osm_landuse_polygon_subdivided_gen0;   area > 99000     '\n*  'landuse_z11'       ,  'osm_landuse_polygon_subdivided_gen1;   area > 50000     '\n*  'landuse_z12'       ,  'osm_landuse_polygon_subdivided     ;   area > 10000     '\n*  'landuse_z13toz14'  ,  'osm_landuse_polygon_subdivided     ;\n. > Don't quite understand it yet :)\nsorry ..  it is a very early & draft version ...  and some part is too complex ..\nbut as I read -  we have a NEW deadline (Full reload ), and I would like to detect the new problems as early as possible.  \n\nThis is primarily to compare how the DB contents change between two commits?\n\nyes.\nLater maybe we can store the calculated  table fingerprints on a  QA database ..\nand we can create fancy QA charts  ( or  automated comparison ) \n\nbut before we merge it we must do a history rewrite to remove the big text files again.\n\nsorry,  you can remove the reports - any time ..\n. Lot of improvements :)  \nMy question about the new download schemas :\n- in the future ...  I would like to write a daily cron script  for detecting the new (Planet/Hungary/Budapest)  extract exists  or not\n  - and if  the new version is exists -  I would like to automatically download ,  check the md5 and refresh my local copy. \nWhat is the suggested method to implement this? This is a typical question we need to add to the FAQ.\nother ..\nWe have 2 dates/timestamps \n- osm planet last modifications timestamp ( this is sometimes important for debugging, because the osm database is changing ,   for example  XXX POI is changed before or after ????  )\n  it is like \"OSM Data from: 2016-07-27 00:58 UTC\"\n- mbtiles generating date/timestamp ( =  Last modified )  when the generating process finished, so this is a technical info - but also important for debugging\nIs it possible to add both timestamp somewhere ? \n- now only - I can see this on the download page ...\n\"Full Planet and extracts were last updated on Tuesday, 26 July 2016 at 19:24 UTC\"\n. @brianshaler \n\nIs there anything else I can provide to help?\nZoom 10 @ Stockholm\n/data/planet/10/560/300.pbf\n\nCan you  re-test with sweden.mbtiles ?  :   \n- download  country =  Sweden  ( 1.1 Gb )  from   http://osm2vectortiles.org/downloads/\n-  start :\n  -  tileserver-gl-light  sweden.mbtiles\n  - and on the other terminal : \n    -  wget  http://localhost:8080/data/osm2vectortiles/10/560/300.pbf\nmy log:\nlog\n$ tileserver-gl-light  sweden.mbtiles\nListening at http://:::8080/\nGET /data/osm2vectortiles/10/560/300.pbf 200 15.547 ms - 17280\nGET /data/osm2vectortiles/10/560/300.pbf 200 2.167 ms - 17280\nmy version\nlog\n$ tileserver-gl-light  -v\nversion 1.0.4\nmy tileserver-gl-light  log\nlog\n$ tileserver-gl-light  sweden.mbtiles\nListening at http://:::8080/\nGET /data/osm2vectortiles/10/560/300.pbf 200 15.547 ms - 17280\nGET /data/osm2vectortiles/10/560/300.pbf 200 2.167 ms - 17280\nmd5sum  sweden.mbtiles\nlog\n$ md5sum  sweden.mbtiles\n1fe3916fd919c4172d8a026669037679  sweden.mbtiles\nmd5sum 300.pbf\nlog\n$ md5sum 300.pbf\nf402c256708cfb0182231d27646f0367  300.pbf\n. imho: maybe it is worth to wait a few weeks more. ( and re-check after the State of the Map  )\ncontext: \n\nI think that's the right direction. And then let's check in at State of the Map.\n. my proposal :\n-  Add wheelchair  info to the POI-s or #poi_label \n\nproposed values:\n- 'yes' / 'no' / 'limited' / 'designated'   : according to the  osm wiki \n-  ' '  :  ( empty )  :   no info ;  no osm wheelchair key\n-   '.'  (dot)            :  bad/other info :   osm wheelchair key exists , but the value NOT IN [ 'yes' / 'no' / 'limited' / 'designated'  ]  so maybe other value or  tagging error!    This is  for  minimal  QA purpose , if somebody want to add link to edit this type of  POIs  then this will be so much  easier ! \n  ( see taginfo for the long tail values  : http://taginfo.openstreetmap.org/keys/wheelchair#values )\nThe '2 missing  values'   [ 'no info' and 'bad code'  ] is new concept in osm2vectortiles , but in the statistics it is very common, and in the future I would like to create some QA report ( charts, reports, based on osm2vectortiles v3 schema. ) \nSo my proposal for the long term:    Moving the project to more general use case : \n- adding minimal humanitarian(wheelchair)  info \n- adding minimal QA info  ( if possible )\n. > Especially remove database.\ntry :\n- https://github.com/osm2vectortiles/osm2vectortiles/issues/376#issuecomment-235356217\nDocumentation:\n- https://docs.docker.com/compose/reference/rm/\n. I have re-tested GIS-Lab OSM Dumps ... \n-  and they don't contains the timestamp info in the pbf header.\n  - osmconvert TM.osm.pbf  --out-timestamp    --> (invalid timestamp)\nmy simple test with a smallest extract ( \u0422\u0443\u0440\u043a\u043c\u0435\u043d\u0438\u044f /  Turkmenistan ) ~ 5-6 MB\nbash\nwget http://data.gis-lab.info/osm_dump/dump/latest/TM.osm.pbf\nwget http://download.geofabrik.de/asia/turkmenistan-latest.osm.pbf\nosmconvert   xxxxxx.osm.pbf             --out-timestamp\nbash\nroot@8e47e5241acf:/tmp/tm# osmconvert TM.osm.pbf                  --out-timestamp\n(invalid timestamp)\nroot@8e47e5241acf:/tmp/tm# osmconvert turkmenistan-latest.osm.pbf --out-timestamp\n2016-08-11T19:29:03Z\nosmium fileinfo  xxxxxx.osm.pbf\n``` bash\nroot@8e47e5241acf:/tmp/tm# osmium fileinfo TM.osm.pbf\nFile:\n  Name: TM.osm.pbf\n  Format: PBF\n  Compression: none\n  Size: 6643114\nHeader:\n  Bounding boxes:\n    (52.192,34.9805,66.8402,42.9915)\n  With history: no\n  Options:\n    generator=0.44.1\n    pbf_dense_nodes=true\nroot@8e47e5241acf:/tmp/tm# osmium fileinfo turkmenistan-latest.osm.pbf\nFile:\n  Name: turkmenistan-latest.osm.pbf\n  Format: PBF\n  Compression: none\n  Size: 5788342\nHeader:\n  Bounding boxes:\n    (51.8327,35.1236,66.7089,42.8608)\n  With history: no\n  Options:\n    generator=Osmium (http://wiki.openstreetmap.org/wiki/Osmium)\n    osmosis_replication_timestamp=2016-08-11T19:29:03Z\n    pbf_dense_nodes=true\n    timestamp=2016-08-11T19:29:03Z\nroot@8e47e5241acf:/tmp/tm# \n```\nthe osmium  Extended output  mode is working - but it needs to scan the full pbf - and it takes a few time with a full planet file   \nbash\nroot@8e47e5241acf:/tmp/tm# osmium fileinfo -e TM.osm.pbf\nFile:\n  Name: TM.osm.pbf\n  Format: PBF\n  Compression: none\n  Size: 6643114\nHeader:\n  Bounding boxes:\n    (52.192,34.9805,66.8402,42.9915)\n  With history: no\n  Options:\n    generator=0.44.1\n    pbf_dense_nodes=true\nData:\n  Bounding box: (47.5238,34.984,67.9209,46.9977)\n  Timestamps:\n    First: 2008-02-04T11:50:43Z\n    Last: 2016-08-11T17:09:55Z\n  Objects ordered (by type and id): yes\n  Multiple versions of same object: no\n  CRC32: 3eb12c5b\n  Number of changesets: 0\n  Number of nodes: 783492\n  Number of ways: 76995\n  Number of relations: 500\n  Largest changeset ID: 0\n  Largest node ID: 4346217589\n  Largest way ID: 436185999\n  Largest relation ID: 6464889\nroot@8e47e5241acf:/tmp/tm#\nor a sort mode\nbash\nroot@8e47e5241acf:/tmp/tm# osmium fileinfo TM.osm.pbf  -e --get=data.timestamp.last\n2016-08-11T17:09:55Z\nSo my suggestion:\n- quick fix:\n  -  (@romanshuvalov) try  geofabrik extract \n  -  we need to add this info about GIS-Lab OSM Dumps  to the FAQ\n- long term fix  ..  probably we need double check\n  - first the fast osmconvert  ...  --out-timestamp method\n  - and if the return value not start with '2' then the slow method with osmium fileinfo\ndraft algorithm:\n``` bash\nroot@8e47e5241acf:/tmp/tm# cat z.sh\ninput_osm_pbf=$1\nLASTOSMTIMESTAMP=$(osmconvert $input_osm_pbf --out-timestamp)\necho   LASTOSMTIMESTAMP=$LASTOSMTIMESTAMP\nif [[ ${LASTOSMTIMESTAMP:0:1} != \\2 ]] ; then\n   echo  \" Slow method started \" \n   LASTOSMTIMESTAMP=$(osmium fileinfo $input_osm_pbf  -e --get=data.timestamp.last)\nfi\necho   LASTOSMTIMESTAMP=$LASTOSMTIMESTAMP\n```\n@romanshuvalov : can you re-test my hypothesis ? \n@lukasmartinelli :  if you want -  I can create a similar fix  ( probably in a next 2 weeks) \n. > if it is possible in a reasonable amount of time I would prefer osmium fileinfo. \ntime of osmium fileinfo -e  ... \n-  france-latest.osm.pbf  (3.2 GB)  ~   6 minutes ( on my machine )\n```\n$ time osmium fileinfo france-latest.osm.pbf  -e --get=data.timestamp.last\n2016-08-19T19:27:46Z\nreal    2m4.921s\nuser    5m49.072s\nsys 0m5.276s\n```\n. > This will scan through the entire PBF file right?\nyes ..\n\nYou can decide ...\n\nI will do my best ...\n( I have started working on )\n. Hi @e11137 ,\n\nERROR: invalid input syntax for type timestamp: \"(invalid timestamp)\"\n\nYour problem maybe related to https://github.com/osm2vectortiles/osm2vectortiles/issues/397\nAre you unsing  http://download.geofabrik.de/europe/france.html extract ?\nCan you post the output of the : \n-  osmium fileinfo  france.osm.pbf \n-   osmconvert france.osm.pbf   --out-timestamp \n//   replace  france.osm.pbf  with your input osm pbf file ;\n. Hi!\nThe example tutorial - with zurich_switzerland.osm.pbf  is working ?\n- see:  http://osm2vectortiles.org/docs/own-vector-tiles/\n. @bearnxx \nCan you post the output of the following commands?\n- cat /etc/*-release\n- cat /proc/version\n- docker version\n- docker info\n- docker-compose version\n- docker run debian:jessie /bin/echo 'Hello world'\nmy quess\n-   maybe this can be  a Docker problems ..  see similar errors: \n  - https://github.com/docker/docker/search?utf8=%E2%9C%93&q=%22Error+resolving+syscall+name%22+&type=Issues\nIf you don't using the latest docker  and docker-compose - can you upgrade and check again?\n- https://github.com/docker/docker/releases  ( v1.12.1 )\n- https://github.com/docker/compose/releases  ( 1.8.0 )\n. @bearnxx \n\nI think it should be some config problem not a lower version docker problem\n- maybe this is a [ seccomp ]  security problem ? \n  - https://github.com/docker/docker/blob/master/docs/security/seccomp.md\n  - docker v12 has a centos seccomp patch:  https://github.com/docker/docker/pull/22344  ( but i am not a centos user ..  so this is only a guess .. )\n\nyou can test your docker configurations .\n-  if the simple  docker  volume ( '-v   Bind mount a volume')   is not  working , then the osm2vectortiles also not working ...\nthe vt.sh  should list your ./import directory   ( and the pbf file ! )\n```\ncat vt.sh\n!/bin/bash\nvimport=$(pwd)/import \ndocker run -it --rm -v $vimport:/data/import debian:jessie ls -la /data/import\n```\n. @bearnxx :\n\nI think it must be the ContOS7 Problem.\n\nsometimes a simple Docker reinstall ( or upgrade )  helps  ( but sometimes not )\nhttps://docs.docker.com/engine/installation/linux/centos/\n\nSo which one are you using now?\n\nI am using Ubuntu 16.04\nand\n- docker version : 1.12.1\n- docker-compose version: 1.8.0\n. @lukasmartinelli   :)\nI will try to help in testing , \nbut please give me a litle time  - for review ,   and creating a test scripts ... \nbecause this is a huge change ! \n. is it possible that the Imposm3 \" osmChange delete action\" --> TILELIST  is not implemented yet ?\n( similar test/problem than :  https://github.com/osm2vectortiles/osm2vectortiles/issues/183 )\nI try to create a minimal test code  ...\n. > So in theory this should correctly expire deleted nodes and ways.\nmy test script : https://gist.github.com/ImreSamu/770b6a15d8a882a2ab72bd12e9e405e4\nmy test method ( after the make & build the containers )\nbash\ncd import\nwget https://gist.githubusercontent.com/ImreSamu/770b6a15d8a882a2ab72bd12e9e405e4/raw/1c33d024be21b78ecfe870a2f0fdcb5cbc46e9ef/o2tilelist_test01.sh\nchmod +x o2tilelist_test01.sh\ndocker-compose run import-osm /data/import/o2tilelist_test01.sh\nls _tiles*.txt -la\nbash\n-rw-r--r-- 1 root root 4195 szept  2 15:45 _tiles_all_add.txt\n-rw-r--r-- 1 root root    0 szept  2 15:44 _tiles_all_del.txt\nI am expecting the same tile number ...  but now the _tiles_all_del.txt is empty ...\n. @mtfurlan :   for the ZOOM > 14 topic ..\nProbably you have  to modify the  osm2vectortiles.tm2source/data.yml  meta file ... because the current implementation  max zoom level = 14  ;\nso you have to modify  and adapt every SQL WHERE filters ( near z(!scale_denominator!) ); \nfor example\nWHERE z(!scale_denominator!) BETWEEN 13 AND 14\nto\nWHERE z(!scale_denominator!) >= 13\n. @bearnxx \n\nbut there are still some little problems some labels in Europ or USA \nare still English and some are chinese.\n\nprobably - this is data ( OpenStreetMap ) related problem. \nthe current 'draft' ( SQL)   algorithm: \nsql\n          coalesce(NULLIF(name_zh, ''), name) AS name_zh,\nAnd not to many \"name:zh\" keys in   Europe -  so we will have to show the default \"name\" key. \n-  in Hungary ( Europe)  we have only  34 !!  name:zh key tags : http://taginfo.openstreetmap.hu/keys/name%3Azh \n- in Swiss  : http://taginfo.openstreetmap.ch/keys/name%3Azh\n. @bearnxx :  ( part 2 )\nMore info about  OpenStreetMap names: \n- http://wiki.openstreetmap.org/wiki/Names\n- http://wiki.openstreetmap.org/wiki/Multilingual_names\nThe Mapbox definition for name_zh:\n- \"name_zh : Chinese* (if available, otherwise same as name)\"\n  - https://www.mapbox.com/vector-tiles/mapbox-streets-v7/\nWordwide OSM Taginfo stat for  name:zh :\n-  http://taginfo.openstreetmap.org/search?q=name%3Azh\n- map : http://taginfo.openstreetmap.org/keys/name%3Azh#map\n. @bearnxx\n\nSome labels in Europ or USA are still English and some are chinese. like the pcitcure below\nhow to fix this? thank you very much! \n\nprobably - this is data ( OpenStreetMap ) related problem. \nthe current 'draft' ( SQL) algorithm for 'chinese labels' / 'name_zh'\nsql\n          coalesce(NULLIF(name_zh, ''), name) AS name_zh,\nAnd not to many \"name:zh\" keys in Europe - so we will have to show the default \"name\" key.\n- in Hungary ( Europe) we have only 34 !! name:zh key tags : http://taginfo.openstreetmap.hu/keys/name%3Azh\n- in Switzerland : http://taginfo.openstreetmap.ch/keys/name%3Azh\n- Wordwide OSM Taginfo stat for name:zh : http://taginfo.openstreetmap.org/search?q=name%3Azh\n- Wordwide map : http://taginfo.openstreetmap.org/keys/name%3Azh#map\nMore info about OpenStreetMap names:\n- http://wiki.openstreetmap.org/wiki/Names\n- http://wiki.openstreetmap.org/wiki/Multilingual_names\nThe Mapbox definition for name_zh:\n- \"name_zh : Chinese* (if available, otherwise same as name)\"\n  - https://www.mapbox.com/vector-tiles/mapbox-streets-v7/\n. > how to fix this?\n'Fresno'  - chinese labels\n( possible solution ) \nwe can merge the OpenStreetMap data with the Wikidata information. \n- (osm) Fresno - http://www.openstreetmap.org/node/1956099531\n  -  Missing  \"name:zh\"  key\nBut \n- (wikidata) Fresno \n  -  https://www.wikidata.org/wiki/Q43301\n  -  exist  ->  zh  \u5f17\u96f7\u65af\u8bfa\n    - -->  https://zh.wikipedia.org/wiki/\u5f17\u96f7\u65af\u8bfa\n//  wikidata integration is in my long term roadmap\n. @xingdavis \nThank you for the bug reporting ..    I am working on the fix #429 \n. @xingdavis \nReady for testing !   ( Travis test OK ) \n- go to the project directory\n  - cd ./osm2vectortiles\n- you have to stop the running osm2vectortiles containers\n  - docker-compose down\n  - docker-compose rm -f -v -a\n- download the new version from the github repo \n  -  git pull\n- Please ->  rebuild the containers : \n  -  make fast \nAnd now you can start the tutorial:\n- http://osm2vectortiles.org/docs/own-vector-tiles/\n. fixed the Export npm error .. 2b1ed5f\nthe error message was:\nStarting osm2vectortiles_pgdata_1\n/usr/local/lib/node_modules/tilelive/bin/tilelive-copy:100\n        if (err) throw err;\n                 ^\nError: Invalid tilesource protocol: tmsource:\n    at Object.tilelive.load (/usr/local/lib/node_modules/tilelive/lib/tilelive.js:92:25)\n    at /usr/local/lib/node_modules/tilelive/lib/tilelive.js:333:18\n    at pop (/usr/local/lib/node_modules/tilelive/node_modules/queue-async/queue.js:24:14)\n    at Object.q.defer (/usr/local/lib/node_modules/tilelive/node_modules/queue-async/queue.js:55:11)\n    at Object.tilelive.copy (/usr/local/lib/node_modules/tilelive/lib/tilelive.js:331:36)\n    at copy (/usr/local/lib/node_modules/tilelive/bin/tilelive-copy:99:14)\n    at Object.<anonymous> (/usr/local/lib/node_modules/tilelive/bin/tilelive-copy:69:1)\n    at Module._compile (module.js:413:34)\n    at Object.Module._extensions..js (module.js:422:10)\n    at Module.load (module.js:357:32)\n!!!!!!!!!!!!!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!!!!!!!!!!!!\nStatus :\ntools/integration-test/integration_test.py::test_postgis_startup PASSED\ntools/integration-test/integration_test.py::test_import_external PASSED\ntools/integration-test/integration_test.py::test_import_osm PASSED\ntools/integration-test/integration_test.py::test_import_sql PASSED\ntools/integration-test/integration_test.py::test_local_export PASSED\ntools/integration-test/integration_test.py::test_distributed_worker PASSED\ntools/integration-test/integration_test.py::test_diff_update FAILED\nprobably - We need a local  osm testdata mirror ...\nosmupdate Error: Could not download sporadic changefile 1189\nosmupdate: wget Error message:\nhttp://download.geofabrik.de/europe/albania-updates/000/001/189.osc.gz:\n2016-09-15 13:57:20 ERROR 429: Too Many Requests.\n. ok ..  all test looks good ..\ntools/integration-test/integration_test.py::test_postgis_startup PASSED\ntools/integration-test/integration_test.py::test_import_external PASSED\ntools/integration-test/integration_test.py::test_import_osm PASSED\ntools/integration-test/integration_test.py::test_import_sql PASSED\ntools/integration-test/integration_test.py::test_local_export PASSED\ntools/integration-test/integration_test.py::test_distributed_worker PASSED\ntools/integration-test/integration_test.py::test_diff_update PASSED\ntools/integration-test/integration_test.py::test_diff_jobs PASSED\nReady for review & merge\n. imho : the patch ready for review / merge ...  \n@lukasmartinelli -  PTAL ( please take a look )  and if it looks good - please merge ... \n. > how I can debug the procedure, so I do not know, \n\nwhether the problems happen during the import or during the export.\n\nmy best practice : \n- If I have similar problems -  I am connecting to the postgis DB  - and run some SQL query, and checking some table is not empty , exists , ...\n  -   but this is only for the hacker style people with minimal  SQL/PostGIS knowledge ;\n  - and you have to check the tm2source/data.yml file - and you have to find the related SQL tables ;\nSometimes this is not help,\nAnd if I got some strange error :  I am re-starting from the clean environment ... \n- I am removing the  stopped service containers !  ( need for clean PostGIS ) \n  - docker-compose rm -f -v\n- Sometimes I am  removing the all osm2vectortiles related  images, \n  - so this command output should be empty : \n    - docker images  | grep osm2vector \n  - and re-build with \n    -   make fast\n    -   make import-external\n- And sometimes I am cleaning  the ./import  directory ...\n  -  rm -f ./import/*.pbf\n. @mr \n\nI was following instructions from here: http://osm2vectortiles.org/docs/own-vector-tiles/\n- I have rechecked the - exact test with zurich_switzerland.osm.pbf - and it is OK -for me ..\n- the Travis test for the last 30 days is OK \n\nQuestion:\n- the exact test with :  zurich_switzerland.osm.pbf is working for you ?\nMy advice :  please clean everything, before the re-testing:\n- Please remove  stopped service containers !  ( need for clean PostGIS ) \n  - docker-compose rm -f -v\n- Please remove the all osm2vectortiles related  images, this command output should be empty : \n  - docker images  | grep osm2vector \n    -  This is important if you want to test different versions! ( like:  v2.3 and master )\n- Clean the ./import  directory ...\n  -  rm -f ./import/*.pbf\n- And Now -  re-test :  http://osm2vectortiles.org/docs/own-vector-tiles/\n\nERROR:  relation \"admin_z1toz2\" does not exist\n\nAs I know - the admin_z1toz2 is created in the docker-compose up import-sql step !!!\n- Please re-check this step is not missed !! \n  - -->   docker-compose up import-sql\n- If you got a similar error message, please re-start - from the beginning !\n  - remove - the  old PostGIS container, with:\n    - docker-compose down\n    - docker-compose rm -f -v\n@pendolf      \n\n-e MAX_ZOOM=\"22\" export\n\nThe current implementation is only support the max zoom level = 14 !\nThe  MAX_ZOOM=\"22\" is probably  incorrect! \n@mr \n\nBBOX=\"-75.7177734375,38.8600282742,-73.8803100586,41.4787468887\"\n\nIf the zurich_switzerland example is working - and this is not, \n- can you give me the all steps to replicate ?\n  -   (  wget  ..../...osm.pbf   ; .....   )\n- please attach the logs - with all previous steps!\n. @mr \nthanks,\n-  I prefer the logs - without color code :)   easier to read \n  -    you can create a gist  [ https://gist.github.com/ ] and just link the log ...  \nmy problem :\n-  I am using :  Ubuntu  + simple terminal  -  and I can't replicate\n-  I don't know Kitematic  ( Are you using the latest version? ) \nCan you access a Linux machine  ( with the latest docker + docker-compose  inside )  - and re-test ?\n-   ( I need to know - this is a Kitematic problem - or general  )\nI will try to create some debugging test case ...  but need a little time ...\n. @mr\n\nI switched to a new CentOS 7 machine and did a fresh install of docker and\nit ended up working fine on master.\n\ngood news !   And it is an important step to find  root causes of a problem !    :) \n- for the other users:  I added #Kitematic  -   to the issue title.\n@pendolf \nAre you using :\n-  Kitematic  ( or other non linux based solutions )  ?\n-  or you have a different problem ?  ( If yes, please create a new issue ) , thanks!\n. > Is mbtiles contain street name, and other tags?\nyou can find the vector tiles meta definitions in the osm2vectortiles.tm2source/data.yml\nsee : [ -fields ]\nfor example  id: road_label   ( But this will be change !!! )  \n```\n - id: road_label\n  fields: \n      class: \"One of: motorway, motorway_link, 'trunk', 'primary', 'secondary', 'tertiary', 'link', 'street', 'street_limited', 'pedestrian', 'construction', 'track', 'service', 'ferry', 'path', 'golf'\"\n      len: Number. Approximate length of the road segment in Mercator meters.\n      localrank: Number. Used for shield points only. Priority relative to nearby shields. Useful for limiting shield density.\n      name: Local name of the road\n      name_de: German name of the road\n      name_en: English name of the road\n      name_es: Spanish name of the road\n      name_fr: French name of the road\n      name_ru: Russian name of the road\n      name_zh: Chinese name of the road\n      ref: Route number of the road\n      reflen: Number. How many characters long the ref tag is. Useful for shield styling.\n      shield: \"The shield style to use. One of: default, mx-federal, mx-state, us-highway, us-highway-alternate, us-highway-business, us-highway-duplex, us-interstate, us-interstate-business, us-interstate-duplex, us-interstate-truck, us-state\"\n```\nWarning :  The OSM2Vectortiles tile schema will be change\nSo If you want to use in production - please wait! \n. > It's any information about style that can display house number?\nSee the Liberty style - on  http://osm2vectortiles.org/maps/\n\nhttps://github.com/lukasmartinelli/osm-liberty\nhttp://osm-liberty.lukasmartinelli.ch/#18.22/47.07453/8.27978\n. > I want to generate my own countries.geojson file with custom languages.\n\nActually I've already done it, but I'm a little bit confused about the rank property.\n\nin the Bachelor Thesis   - there is some information: \n3.3.4 Place Label Rank Calculation\n\"Ranks are important for determining at which zoom level which places should be displayed.\nThe NaturalEarth database contains places with scaleranks assigned by humans and is the\nmost important source for better quality labels (historic places might be much more important\ndespite having a very small population). This dataset is merged with the imported OpenStreetMap\ndata. They can also be used to limit density at lower zoom levels to decrease data\ndensity. Using the scalerank and other information such as place type and population the\nactual rank called localrank is calculated. An example of localrank calculation can be seen in\nfigure Figure 13 (localrank is denoted as number inside circle).\"\nso my guess - this info from NaturalEarth\n. @noenandre : Thank you the report!  \nI see ! \n\n@mboeringa :\n\nLastly, this issue may actually be an osm2pgsql one, which you should report here:\nhttps://github.com/openstreetmap/osm2pgsql\n\nThe osm2vectortiles project currently using the imposm3 tool   ( not the osm2pgsql )\nBut we are in the  \"change / re-design phase\"    - so maybe the background tools and process  will be change.\n. I don't tested, but in theory -this quick & dirty solution - should work:  \n- you have to remove the unwanted layers / columns from the /osm2vectortiles.tm2source/data.yml\n   (please test  :  step by step - with small changes and with a minimal data ! )\nthis is not optimal, because you will load the all OpenStreetMap data to the PostgreSQL database! \n\nI only need landuse,water,roads \n\nyou have to keep - this layers in the yml configuration file\nLayer: \n  - id: landuse\n ...\nSide notes:\n-  probably  for the next version (V3)   - we need to create a \"tutorial\" or a  simple configuration/optimalisation\"   for this use case \n-  the data model ( the layers and the columns will be radically change  in the V3 ) \n. @longlostbro \n- \"Be aware of legal issues with deploying OSM2VectorTiles tiles\" #387\n\nHow do you create an mbtiles from a tm2 source?\n\nthe curent toolchain (V2)  ~  valid only for this year,    probably the V3 will be a little different.\nsome related documentations ( valid only for the V2 ): \n-  planet : https://github.com/osm2vectortiles/osm2vectortiles/blob/master/USAGE.md\n-  smaller extract :  http://osm2vectortiles.org/docs/own-vector-tiles/\n-  see the export modul: https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/export/README.md\nFor background informations:\n-  Check the Thesis\n\"The export component is responsible for rendering vector tiles using osm2vectortiles.tm2source\nand the postgis component. Exports can be run together with a message queue like RabbitMQ\nor standalone for smaller extracts where it is not necessary to divide the work into several\nparts.\"\nProbably you have to check the docker-compose.yml configurations\nto understand the tm2source configurations : https://github.com/osm2vectortiles/osm2vectortiles/search?l=YAML&q=tm2source&utf8=%E2%9C%93\nif you want to render the full planet - with a single renderer:    >= 45 days , so you have to setup a complex parallel render system. \n. @longlostbro \nI don't know your use case and technical background, and I am not a lawyer, ...\nimho ( my personal opinion )\n- If you want to use in production\n  -  it is better to wait to V3 schema that breaks compatibility with Mapbox Streets.\n    -  not only legal ( \"\"Be aware of legal issues ...\"\" )\n    -  but technical reasons, \n      -  because if you find a \"bug\"/\"problems\" , probably we don't patch the V2.\n- In the V3 - probably we have a new tm2source definitions ( with different layers ) \n  -   so you can practice -  \"removing layers\"- on the V2 , and you can learn some open source tools,\n    -   ( Maybe you can help us in the development or testing  )\n. > I have some shp data.\n\nshp data into bj_min.pbf \n\nif i understand you correctly\n-  you can import    shp to postgresql with  a simple tool, not need to convert to PBF\nsee code importing water_polygons.shp:  osm2vectortiles/src/import-external/import-water.sh\n. > .. tileserver-gl-light ...\nas I know \n-  64bit +  Amd64/Intel CPU a minimal (  32bit + ARM  not supported )\nmore information:\n- https://www.npmjs.com/package/tileserver-gl-light\n- https://github.com/klokantech/tileserver-gl\n- https://github.com/klokantech/tileserver-gl/issues\n- for example : https://github.com/klokantech/tileserver-gl/issues/9 ( \"Performance testing\" ) \n. @srinath155   \n\n\"New Map Datasets of Continents\" \nI request if you can provide the data in the form of continents.\n\nIf I understand you correctly,  do you want new  Vector Tiles extracts  to here?    http://osm2vectortiles.org/downloads/\n. >I'd be very grateful if anyone could tell me where the osm_road_geometry table comes from, so I can >track back the source of the label data.\nimposm3 default table name prefix is osm_  see https://imposm.org/docs/imposm3/latest/tutorial.html#writing\nso just look for road_geometry \n *   https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-osm/mapping.yml#L513\n. >Is it possible to import multiple osm files?\nsorry ... no\n\nI have tried to use osmconvert to merge them into one pbf\n\njust a guess:\n please use the latest osmconvert (>=\"0.8.5\") \n or  osmium tools. http://docs.osmcode.org/osmium/latest/\nor just filter the big  osm planet file  \n. Hi @hyperknot , \nThank you for the feedback!\nI have checked the release page: https://github.com/mapbox/tilelive-bridge/releases\nand now - the max version : v2.2.3\n. @hyperknot    Thanks!   ( I am not a nodejs expert )\n. ",
    "leblowl": "Works for me following instructions on the README\n. Sweet, thank you to all, everything works really well now, successfully finished export-local following the instructions in the README.md. Cheers! :beers:\n. ",
    "isimonescu": "Maybe this bug still alive? Please see https://github.com/osm2vectortiles/osm2vectortiles/issues/439.\n. Meanwhile this has been fixed by the mapbox team, although it turns out it is very probably a data issue, see https://github.com/osm2vectortiles/osm2vectortiles/issues/439.\n. I looked at this today and put a ST_Simplify here.\nHaven't had time to test it out as I have chosen a generous tolerance, will report tomorrow. But as I understand, tolerance is measured in meters, so you have to pass a reasonable value for every zoom level. Probably calculate width of one or a couple of pixels - in meters - and use that as tolerance?\n. No need for math, thanks. :+1: \nNote that these values need to be divided by 2, since the native tile dimension of a raster tile in a mapbox client is 512 px and this table assumes tile dim is 256 (even though the vector tile dim is actually 4096).\nWill look more into ST_Simplify as it seems to be fast enough, I except however to run into problems with geometries smaller than the tolerable resolution. Maybe ST_SimplifyPreserveTopology will be a better pick.\nI am still puzzled - I was under the impression that some kind of simplification (per output tile) IS being made - but I haven't found any code that would do it ...\n. ",
    "daliborjanak": "You can now crequest links for sample maps on http://maps.klokantech.com/. Key will be send by email\n. PR could be merged now. Preview is broken because baseurl param in _config.yaml has to be changed to osm2vectortiles.org domain\n.  Thanks. I forget .zip file :( I'm using {% highlight html %}{% endhighlight %} for syntax highlighting. I will send you another PR with retina image support during day.\n. ",
    "vramirez122000": "Thank you for the instructions for generating the tiles. If there is a way to setup the coordinate bounds for Puerto Rico and merge them into this project, so as make the Puerto Rico extract available in your site, I would gladly contribute such a patch.\n. Yes!!\nmin lat: 17.6701939\nmax lat: 18.7347042\nmin lon: -68.1976318\nmax lon: -65.088501\n. ",
    "hyperknot": "Did a python script which batch fixes fonts in projects. The lookup table can be extended/customized.\nhttps://gist.github.com/hyperknot/6106b253cfe852f84124\n. @klokan Sorry, I didn't mention I'm talking about docker. Sorry, the server supports it (I just found no mention about it anywhere, so I didn't check), it's just that the sources for Leaflet (and possibly OL, but I haven't used it), is not generating retina-aware code. \nThere is no support for autoscale. Leaflet 1.0 will have some retina autodetetion, but it's broken at the moment.\nThe right way to make Leaflet request the @2x tiles is this (works both in Leaflet 0.7 and 1.0 beta):\nL.tileLayer('http://192.168.99.100:8080/mapbox-studio-streets-basic/{z}/{x}/{y}' + (L.Browser.retina ? '@2x' : '') + '.png', {....});\n. Thanks, I can confirm it works well in both Leaflet and OL3. \n. @lukasmartinelli I'm downloading it to a server, so a single HTTP download is the most convenient. I believe with torrent the updates would be quite problematic (you'd need to ask all seeders to download a new torrent and stop seeding the old one when updating the file). I believe with MD5 it's perfect now.\n. @sfkeller yes, it'd also be a good idea. \nWould it be possible to configure the docker container's rendering with something like a config.json in the data folder?\n. It might be interesting to see how does Wikimedia / Kartotherian solve the issue, I haven't seen a broken label on their maps, it's even better than Mapbox. Their tm2source only has 64 buffers, so I believe it's related to the rasterising part.\nhttps://maps.wikimedia.org\nhttps://github.com/kartotherian/kartotherian\nhttps://github.com/kartotherian/osm-bright.tm2source\nYou can actually get their PBF info in JSON:\nhttps://maps.wikimedia.org/osm-intl/9/319/191.json\n@klokan I opened this issue as a discussion thread, not as a bug report, and I'll contribute whatever I can to this project.\nHere are the best resources about vector tile rendering I know about:\n- Dane Springmeyer - Vector Tiles for Distributed, High Performance Rendering of OSM\n- Dane Springmeyer - The State of Vector Tiles\n- Dane Springmeyer - Vector tiles for fast custom maps\n- Dane Springmeyer - Processing OpenStreetMap Into Vector Tiles\n- Advanced CartoCSS Techniques \u2014 Alan McConchie, Stamen Design, Seth Fitzsimmons\n- Andy Allan: Lightning Map Tiles\n- How Simplicity Will Save GIS - Vladimir Agafonkin\n- Mobile vector map rendering with Mapbox tools \u2014 Justin Miller, Mapbox\n- Running Your Own Rendering Infrastructure \u2014 Alan McConchie, Stamen Design, Seth Fitzsimmons, Stamen Design\np.s.: Can you enable the wiki? I'd be happy to put this one in there for example.\n. Thanks, I've collected all the relevant talks here:\nhttps://github.com/osm2vectortiles/osm2vectortiles/wiki/Resources\n. I think mapnik outputs logs, for example the missing markers are always visible in docker. The above tiles produce no warnings.\n. Two more missing tiles for reference:\n14/13386/7149\n14/13386/7148\n. @lukasmartinelli @klokan thanks for the detailed explanation.\nSince making vector based terrain seems to be quite a complicated and long term project, I might work on doing simple raster based hillshading first, without contour lines for a start. Could you give some guidance about what steps would be needed to integrate simple, raster based hillshading into osm2vectortiles? (I understand this would only work on the raster backend).\n. OpenTerrain is going to be an amazing project, but as far as I know the Stamen guys are still working on it. The best way to communicate with the developers is through the official Gitter channel:\nhttps://gitter.im/openterrain/openterrain\nFor raster tiles, they are using tessera for overlaying the rendered tiles via a 'hard-light' composition method, so I believe it would be a straightforward to port that to osm2vectortiles.\nHere is Stamen's \"Terrain Classic\" style, it might have some insights in how they are doing it.\nhttps://github.com/stamen/terrain-classic\n. Also there is something really interesting on Thunderforest / Andy Allan's page:\nhttp://www.thunderforest.com/maps/lightning/\n\nthunderforest.outdoors-v1\nContains data for contours, elevation and hillshading, and in fact all the data needed to power both the Outdoors and Landscape map layers - and the OpenCycleMap layer too!\n. @klokan this is amazing! Really like the soft, understated look!\n\nThis shading is probably tuned for the Alps though, 700 meter hills in Hungary are almost invisible. (Google, Thunderforest, osm2vectortiles):\n\n\n\n. @klokan thanks, with the opacity slider it's great!\n. Just one more resource, an older stamen post about terrain:\nhttp://content.stamen.com/terrain_process\n. I can agree with geocoding being a really really hard problem. Many open source and commercial players are trying to do geocoding on OSM data, with various degree of success.\nI think what makes osm2vectortiles special is that it's a high-quality, high-performance, easy-to-setup vector tile renderer / server. I would recommend staying on this path and ironing out all the bugs.\n. I think GeoNames comes closest to the offline processed gazetter data solution, but there the whole Lucene backend is proprietary. So you get the data (in text files), but not the backend needed to query it.\n. Here are the best documents optimising PostgreSQL for full planet OSM import, in case you haven't read them yet. Also, what helped me (strangely!) was to add a huge swap partition (like 60 GB), and just let it swap. In my case it meant using cache 26000 on a 32 GB server, but that was with osm2pgsql.\n2010-07-10-rendering-toolchain-performance.pdf\nramm-osm2pgsql-sotm-2012.pdf\nosm2pgsql-performance.pdf\n. I totally admire your work, and huge congrats for being accepted, but I'm\nafraid I won't be able to pay 590-750 EUR + travel + accommodation for the\n3 days of attending the conference (which started with Free in its name\nonce...), hopefully we can meet once in the future!\nOn 29 April 2016 at 14:02, Manuel Roth notifications@github.com wrote:\n\nSo, @lukasmartinelli https://github.com/lukasmartinelli and me are\ngoing to be at FOSS4G http://2016.foss4g.org/home.html somewhere\nbetween 24th and 26th of August and at FOSSGIS\nhttp://frab.fossgis-konferenz.de/de/2016/public/schedule/1 on the 5th\nof July (9.30 AM GI Studio). @ImreSamu https://github.com/ImreSamu\n@hannesj https://github.com/hannesj @muesliq\nhttps://github.com/muesliq @hyperknot https://github.com/hyperknot\n@numenor https://github.com/numenor do you plan to attend one of these\nconferences, would be a great chance to meet you guys in person after all\nthese great contributions, ideas and discussions.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/147#issuecomment-215693811\n. @lukasmartinelli #160 changed both the package versions and the node version. I'd guess it was the package versions which fixed the bug, and it'd work with node 0.10 as well. \n\nnode-mapnik says this on the homepage:\ndepends: Node v0.10.x or v0.12.x (v0.12.x support requires node-mapnik >= v3.1.6)\nhowever they do provide \"matrix\" builds (that's wheel / bundle for node AFAIK) for node 0.10, 4, 5:\nAfaik, mapnik is a pain to compile, and sticking with the matrix builds is a good idea (afaik we are getting those at the moment).\nMapbox seems to be using node 0.10 in production, as it seems from their travis.yml files:\nhttps://github.com/mapnik/node-mapnik/blob/master/.travis.yml\nhttps://github.com/mapbox/node-mbtiles/blob/master/.travis.yml\nhttps://github.com/mapbox/tilelive/blob/master/.travis.yml\nhttps://github.com/mapbox/tilelive-vector/blob/master/.travis.yml\nhttps://github.com/mapbox/tilelive-bridge/blob/master/.travis.yml\nhttps://github.com/mapbox/tilelive-mapnik/blob/master/.travis.yml\n. I updated all Dockerfiles to node 0.10 and bumped the packages in #168, waiting to see if build succeeds.\n. Sorry, I forgot to mention that this issue was only relevant to developers building the containers, for normal users the pre-built images are perfectly fine I believe.\nI don't think you can pin apt packages like you can with npm and pip packages, as apt repositories usually only serve the very latest version of each package. \nWhat you can do on apt is to hold an existing (installed) version, but since you are building Docker files from scratch it won't be an option either.\nBut don't worry, as Ubuntu LTS and Debian has a really conservative policy for packages, so you are guaranteed to be on the same minor version of a package for the lifetime of the OS. (Python 2.7 is for example from 2013): http://packages.ubuntu.com/trusty/python\n. No improvement / bug here, just wanted to raise the point that local builds and Travis build can be on different versions, so we might need to manually rebuild with --no-cache from time to time. I was surprised when I first understood this, might not be clear for others as well.\n. @klokan are you running a recent build on tileserver.com? To reproduce, just set up a VPS now and it'll produce the error.\n. The problem is clear, there are no such icons like \"leisure-12.svg\" in https://github.com/mapbox/mapbox-studio-osm-bright.tm2/tree/master/icon\nThe string \"leisure\" is not even present in mapbox-studio-osm-bright.tm2.\nHowever Mapnik still gives this error message and breaks rendering.\n. +1 for Budapest :-)\nOn 26 April 2016 at 15:06, Stefan notifications@github.com wrote:\n\nHowto get BBOX with online tools?\n1. Search location at http://osm.org, note relation OSM id (admin.\nboundaries always are r.).\n2. Given OSM id relation get polygon: http://polygons.openstreetmap.fr/\n3. On same site: If need a buffer, choose line. If need simplified\npolygon, generate simplified polygon.\n4. To get BBOX, paste result to http://geojson.io/ and choose menu \"Meta\n\nAdd bboxes\".\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/293#issuecomment-214734655\n. This approach would limit you to setups which doesn't need mapnik in any of the dependencies, as compiling mapnik is seriously voodoo and it's only been offered in binary form on a very limited set of OS-es (like Ubuntu 14.04 + node 0.10). Pretty much a random user has no chance of being on a system for which mapnik is binary supplied via npm.\n. Just a small note, as I don't know what hardware the initial import is done on, but these might be great budget-friendly dedicated servers for the osm2vectortiles project, as you can rent them for one week and they have 64 GB RAM:\nhttps://www.runabove.com/sandbox-servers.xml\n\nOr these ones with SSDs:\nhttps://www.runabove.com/i7-game-servers.xml\n. @stirringhalo I wasn't rendering those myself, for this bug I just followed the getting started instructions, which involves downloading the latest extracts from the website.\n. OK I tested with more zoom levels:\n- \"Morocco\" title only appears on level 5, when you are only seeing part of the country, not the whole.\n- The dashed line appears on level 7, when you cannot see anything at all, except the line.\n  \n- The \"Western Sahara\" title doesn't appear at all, no matter what zoom level\n- Moreover the internal border with \"Sahrawi Arab Democratic Republic\" disappears at level 7, leaving only the \"Sahrawi...\" title text visible for the whole region.\n  \n. As far as understand OSM2VectorTiles can be regarded a clean room implementation of the missing piece in the OSM dataset -> [?] -> MapBox vector styles pipeline. \nBoth OSM dataset and MapBox vector styles are open source, while the missing piece [?] has been implemented without any access to MapBox sources, with a year long trial-and-error task of developers trying to create a fitting dataset for the open source vector styles.\n. MapBox decided to open source their map style, that is their cartography design. These are found in the mapbox-gl-styles GitHub project, whose license you can read there: https://github.com/mapbox/mapbox-gl-styles. \nPreviously, they offered open source design like osm-bright for non-GL workflows, which was widely used in open source workflows, like in switch2osm.org guides.\nNow, back to today, these open source GL styles are like a CSS stylesheet without the matching HTML document, they are not usable at all. Now this project and others like Wikimedia Maps (https://github.com/kartotherian/osm-bright.tm2source) has taken the hard work of producing a HTML document which is compatible with Mapbox's CSS styles.\nIf you render a map using Wikimedia source or osm2vectortyles source styled with Mapbox style, you end up with a map which is cartographically similar to the ones by Mapbox, by definition. That's what a CartoCSS or GL style does.\nThey will never be the same, as Mapbox's data is years ahead, as well as using proprietary data, like the elevation in Mapbox maps. But it's a good enough alternative for some smaller scope projects, like my MapHub website, which wouldn't have been possible had I not had the option of serving my own tiles (http://maphub.net/).\nTalking about uncoolness, Mapbox is literally in monopoly situation in the tile serving business today. MapQuest, one of the earliest innovators in tile serving just switched their whole infrastructure over to Mapbox hosted tiles. If a company in such a monopoly situation decides to go after tiny open source projects making a compatible style based on OSM data, then it is the definition uncool, in my opinion. \n. This just makes no sense. Both @lukasmartinelli and @michaelsteffen confirms that \"Use of openly licensed JSON styles (Bright and Basic), or openly licensed TM2 styles\" is OK.\nYet, it is not allowed(!?) for this project to use a Bright/Basic based style? And the asking of \"have been asked to start from scratch again instead of removing code\". What does this mean in terms of software development? Makes no sense at all. This doesn't specify any specific issue which should be removed. The only point of asking this is to essentially kill a tiny project by requiring them to trash what they have done during the last year+! I don't know of any big company which ever asked a tiny GitHub project to \"start from scratch\". If legal support would exist for this project, it could easily be won, as there is no such thing of requiring anyone to start from scratch without specifying what exactly are violating copyright / licensing issues.\nFinally, does Mapbox not realise / not care at all about what message they are shouting at the developer community? It is a company where many of the most respected cartographers / software developers / illustrators work, which exists because it could build on the shoulder of OSM and it's open source software stack. Yet, somehow after $63 million capital now the right thing seems to be to send lawyers after tiny GitHub projects where many core OSM contributors are helping in their free-time, and asking them to do things that doesn't make any sense for many of the contributors. Yet, since a tiny GitHub project has no chance against any Goliath, the only likely outcome would seem to totally abandon ship and leave anything Mapbox related behind.\nThis would only be a bit sad if we were to talk about traditional closed source companies, like Microsoft or Oracle doing this. But to see this behaviour from a company which only exists because it built on the work of the very same community it is now hurting is quite depressing. \n. @sfkeller I think at this point it's best to ask some legal expert's help.\nI think the best one is EFF (https://www.eff.org/pages/legal-assistance) but also there is SFLC (https://www.softwarefreedom.org/about/contact/), both which provide free legal assistance to open source projects.\n. Wow this dataset looks amazing! I'm happy to contribute towards a high quality terrain rendering in osm2vt.\nSo are there plans to also include raster hillshading with the vector contours? In my opinion raster hillshading is required for high quality visual style, probably that's why Google is still using them (I kind of remember that about a year or two ago they might have switched to vector hillshading and at that time everything looked super triangulated, but now they are back to raster).\nSo what kind of source do we have? Both preprocessed DEM files and vector contour lines? How can we serve them to MapboxGL? Combining the contour in the dataset, and serving the hillshades in separate PNGs/JPEGs?\nWhat Google seems to be doing is pre-rendering all the terrain-like data on a separate raster layer and serving them from JPEGs.\nFor example:\n\nuses:\n\n. @yvecai also, if hosting is a problem, I'd be happy to provide hosting on a small Kimsufi server.\n. If you decide to keep them in a separate set (which might not need to be updated for a long long time), I'd recommend merging them into published mbtiles databases, so clients would not need to use 2x requests for each tile.\n. I was referring clients as in browsers and mobile devices. When mobile devices need to make 2x (or 3x for hillshading) requests, that gives a visible latency especially on mobile networks. HTTP2 can help a bit, but it's not yet common.\nI've just checked Mapbox outdoors, and they only serve a single 512x512 PBF which has both vector data, contour lines, and triangulated hillshading all combined. Thus even a desktop browser only does 6 requests for a single map view, which is quite fast.\nIf this can be done on-the-fly via TileServer GL without any performance penalties, then I guess it's a good solution. If this means much higher system requirements / slower serving performance, then I believe an offline processing step would be better.\n. I think the #1 os for Docker host is Ubuntu LTS, that is 16.04 today.\nOn Tuesday, 30 August 2016, bearnxx notifications@github.com wrote:\n\n[root@localhost osm2vectortiles]# docker run -it --rm -v\n$vimport:/data/import debian:jessie ls -la /data/import\nUnable to find image 'debian:jessie' locally\nTrying to pull repository docker.io/library/debian ...\njessie: Pulling from docker.io/library/debian\n357ea8c3d80b: Already exists\nDigest: sha256:ffb60fdbc401b2a692eef8d04616fc\na15905dce259d1499d96521970ed0bec36\nStatus: Downloaded newer image for docker.io/debian:jessie\n2016/08/30 13:29:22 Error resolving syscall name execveat: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name getrandom: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name memfd_create: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name renameat2: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name sched_getattr: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name sched_setattr: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name seccomp: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name breakpoint: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name cacheflush: could not\nresolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name set_tls: could not\nresolve name to syscall - ignoring syscall.\nls: cannot open directory /data/import: Permission denied\nI have disabled the selinux. it did'tn work too.\nI think it must be the ContOS7 Problem. I decide to change to your Linux\ndistributions. So which one are you using now?\n@ImreSamu https://github.com/ImreSamu\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/410#issuecomment-243439852,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAeKj-B7rrLShTyOq8GhZP7qggtBYLT1ks5qlDFCgaJpZM4JsH6l\n.\n. I was serving full planet v1 on a 10 EUR per month VPS from Scaleway. The\nkey is to use nginx proxy with at least a month of caching time. You'll\nneed at least 4 GB ram.\n\nOn Thursday, 20 October 2016, gisgraphy notifications@github.com wrote:\n\nI have googled it and look at the documentation but I can not find the\nhardware requirements to host tileserver-gl-light for all the planet. RAM,\nCPU, hard drive, bandwith...\nIs there some advices on the number of CPU to handle something like ~1600\ntiles per seconds (100 maps of 16 tiles) .\nIs it better to have a loadbalancer with several small servers or one big ?\nIs it CPU bound ? is http://ark.intel.com/products/88173/ a good choice?\nhow many request can we handle with this\nMany thanks\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/457, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAeKj2cpFxHBWUNGFSMvfaVu9Qp3mJlXks5q14JHgaJpZM4KcO-Z\n.\n. I had so much trouble exactly with this on FreeBSD that I migrated to\nUbuntu where everything is supported. Your easiest choice would be Linux in\nDocker in FreeBSD.\n\nOn 2017. Jan 31., Tue at 8:22, Pavel Minaev notifications@github.com\nwrote:\n\nClosing it here and opening in tileserver-php instead.\nklokantech/tileserver-php#95\nhttps://github.com/klokantech/tileserver-php/issues/95\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/505#issuecomment-276292545,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAeKj6gPQ0mW0IRbnH28db2jkYWBtCCpks5rXuEZgaJpZM4Ljxv5\n.\n. It takes a few hundred MBs, which compared to GBs of map data is quite\nnothing.\n\nI've literally wasted a month of my time trying to set up a full tile\ngeneration environment on FreeBSD. After I've given up it pretty much got\nreplaced with a 1 minute docker pull.\nIt's up to you what do you choose.\nOn 31 January 2017 at 09:11, Pavel Minaev notifications@github.com wrote:\n\nFWIW, I'm having the same exact problem on Windows.\nI'd like to avoid Linux in Docker if at all possible, because it consumes\nquite a lot of space (which, when maps are involved, is already precious).\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/505#issuecomment-276300285,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAeKj6R4Q1QatdG6A0TWQuFZ7IwPZ1hcks5rXuzAgaJpZM4Ljxv5\n.\n. I've just checked these packages and tilelive-bridge says in the changelog that it supports mapnik 3.5 since 2.3.0:\nhttps://github.com/mapbox/tilelive-bridge/blob/master/CHANGELOG.md\n. Hi @ImreSamu, that's strange. However what matters is that npm is on 2.3.0:\nhttps://www.npmjs.com/package/tilelive-bridge\n. I opened an issue: https://github.com/mapbox/tilelive-bridge/issues/78\n. \n",
    "stephankn": "was there any fix applied  or is there additional checks in the build scripts? I am under the impression it was mentioned to add additional checks. I didn't see any referenced commit. Or is it pure luck that the issue is no longer observed? In this case closing the issue is probably a bad idea. \n. Is it possible to replicate the generation process on my side? Are all required scripts/input files available? If so I can test to create tiles here to verify. Is this the process you also followed internally? http://osm2vectortiles.org/docs/own-vector-tiles/\n. I did run it on my machine. Your documentation misses to mention that you need to adjust the bounding box. My first try does have no gaps. Missing lowzoom data, but maybe this is related to not touching min/max zoom settings. So can't say why your setup misses tiles.\n. ",
    "muesliq": "Thanks @lukasmartinelli for checking! \n. IMHO the issues in the \"important\" sections are so essential that all points below pale in comparison. \nRegarding future directions:\n- Mapbox' geocoding is opensource as well afaik: https://github.com/mapbox/carmen However geocoding is a really really hard thing that many opensource and even commercial projects fail to do properly. That would be project of its own altogether.\n- Offline use is just a label, right? Using the Mapbox GL SDKs and osm2vectortiles an offline usecase on iOS and Android can already be implemented today. (+1 for the label.) \n. Any estimation when the next release will happen?\n. Cool! Looking forward to the results of the roadmap meeting. \nGreat project by the way! :+1:\n. Horray!\n. Nope, unfortunately neither of the two. Maybe Brussels, will see.\n. Thanks! Differences in the style sheets explain everything. (They shouldn't use the same name for both..)\n. Great list! For prioritization purposes here the tags that are in my opinion missing most:\n- landuse / residential\n- place / * (to give islands, bays, etc. names)\n- natural / peak\n- natural / ridge, natural / valley\n- route / ferry\n- waterway / dock\n. Same for S\u00e3o Paulo - 12 million inhabitants. The shown town of Sorocaba has 0,6 million inhabitants.\n\n. Any forecast on when the next rendering will happen, btw?\n. Hey guys, seems you are well in time for v1.6. Any idea when a new planet download will be available?\n. Great! I didn't know http://dev.vectortiles.osm2vectortiles.org/ - I had used our own styling plus http://osm2vectortiles.org/maps/ to check data density. \nSeems that you have solved most of the issues already. I have updated the list accordingly. Mainly in ZL7, 9 and 12 I still see problems.\n. Great that you are caring about these details, guys! \nOne thing mentioned in a checkbox but not illustrated yet: I think landuse=residential is important (even if Mapbox doesn't seem to agree). Two screenshots from http://Maptoolkit.net (our old raster rendering), look at the grey areas:\nZL8 Vector (= ZL 9 Raster):\n\nZL10 Vector (= ZL11 Raster):\n\n. See https://github.com/mapbox/mapbox-gl-js/issues/769#issuecomment-197496089\n. Great! I'd say the feature can be put in one large multipolygon, regardless of zoom level, to save space. \n. Sure. \n- Residential, commercial, retail, railway: Z8 (=vector zoom level)\n- Military: Z7\nBut I only know precise reasons for Residential, @numenor will be able to explain the other features (and if they are actually important).\n. Is it useful in high zoom levels? Yes. Is it absolutely necessary? I guess not.\n\n. I doubt that this is a vector tile problem as the streets are visible in http://osm2vectortiles.org/maps/. I guess the problem is in your stylesheet.\nHere's a screenshot of Toronto (your last link):\n\n. That's where I looked (in Mapbox Studio) but I couldn't find landuse=residential, which should be available as of #307. \n. Ok, I understood now how this works. A little difficult to find out, the zoom levels for each layer.\n. I guess this is a bug in OSM. \nIn my rendering some parks in Graz indeed are missing (POI data is there but not landuse data - see screenshot) but in Vienna all parks work fine.\n\n. Thanks, I'm closing this, duplicate & won't fix.. ",
    "numenor": "I have made the experience (for Andorra, Monaco, Vatican City), that the bounds actually seem correct, but as reported by the Mapbox Studio importer, the center coordinates are wrong. If I modify the mbtiles sqlite \"metadata\" table, row \"center\" with the averaged min/max lon and min/max lat coordinates taken from the \"bounds\" row (and select an appropriately high center zoom level, and remove lower zoom level tile mappings from the mappings table, to circumvent the 500KB limit by accepting missing low zoom level tiles), then I have success with the upload (tested for Monaco).\n. I am really sorry, but no attandence by me. But congratulations to you for getting accepted and the chance to make your great work even better known!\n. @lukasmartinelli : Thanks for your feedback! Regarding your questions:\n- Did you previously base your Mapnik stylesheet on Mapbox Streets?\nNo, I have a completely custom made style as mapnik xml, which I am trying to match as closely as possible with vector tile styling (taking advantage of their possibilities and Mapbox GL styling, of course). I do not have an \"intermediate\" version direcctly for Mapbox Streets. Thus, I cannot tell about whether/which of my suggestions are covered by Mapbox Streets. I was unsure of how much you want to diverge from / improve on Mapbox Streets, and thus how appropriate my suggestions are. I am glad though that you are considering these!\n- Did you find the no. of occurrences with taginfo?\nExactly, the statistics by taginfo have been very valuable for prioritizing my suggestions ...\nJust for completeness, another very important issue for me is already covered by #114 . I want to render pedestrian areas (a lot of central city areas are tagged highway=pedestrian, area=yes), but currently can only get the circumference instead of a fill (or alternatively, also all linear pedestrian ways are also artificially closed and filled, which would be worse).\n. Regarding tiles maybe getting too large when adding further mappings/features:\nDid you consider creating more than one set of tiles for more specialized purposes (more diverse landcovers, or sports, or detailed POIs, or hiking/biking/skiing routes/pistes, ...)? In Mapbox Studio it is possible to add several sets of tiles, and depending on the purpose of a map, the appropriate ones could be chosen as data source. Such a modularized approach would thus still give reasonable amounts of data, while allowing more flexibility for map design. The cost, I guess, would be higher amounts of tile generation time and storage space ...\n. @klokan : Thanks to your publishing this project and the really nice documentation, I am aware of this possibility, and I am happy to have this as a fallback. On the other hand, I want to avoid duplicating effort for whatever of the mentioned mappings/features you consider useful for the tiles you generate. So I would like to clarify which of these could/should be incorporated into osm2vectortiles, and which you deem too specific and I will have to deal with in an additional own tileset.\n. In our style, the following turned out to be sensible:\n- residential: Z7 (=vector) all the way down to Z14 (in OSM landuse=residential is mapped to a high level of detail in several cities, blending well with parks, commercials, forests, ...; so it is beneficial having the ability to style it separately from a general background which would also be used outside towns/villages/...). Z8 would still provide good rendering potential, if Z7 would be oversized by residential.\n  - For low zoom levels (e.g. < Z10), generalized polygons aggregating neighboring residential areas and eliminating out small holes/\"bays\"/\"peninsulas\" might be even better, but I gess that would be an own issue ...\n  - in case of size problems: smaller areas could be filtered in ZL <=9 without much impact, I think, while having residential areas of larger cities even in ZL7 is quite important (problem might be if they are split into many individual pieces in OSM).\n- commercial, retail, railway: similar to residential, although less important at smaller ZLs (usually areas are smaller and will appear in visible sizes later anyway). I guess, ZL>=10 would work fine.\n- military: so far we are rendering them in ZL>=11, but for really large areas, availability in smaller levels would probably be good. I guess, these will pose less of a size problem, because they are not that abundant?\n. ",
    "hannesj": "Hi,\nYou can compare your source with our old source and see that there are two areas missing. It seems we have previously fixed this in our own source with this commit.\n. As we provide most of the transit-specific information from another vector tile source, it is not a problem for us (except #115).\nWhat we feel should be improved is mainly details such as this one, as well as trying to provide better localrank results for POIs. We feel that this source excels in some aspects, such as having railroads visible on higher zoom levels, which is something Mapbox currently doesn't do.\n. Temporary fix can be found in https://github.com/osm2vectortiles/osm2vectortiles/commit/3e58298c49f0258bb13fb27b1614cd15e3d6f11b\n. Pull request can be found in #134\nUh that was strange, the commits are on my fork and it seems GitHub syncs commits between different forks? \n. @lukasmartinelli It seems this is broken again. I regenerated our vector tiles using the current master and can see the bug hitting us again.\nWhen querying the database I get the following response\nosm=# select osm_id, type, ST_GeometryType(geometry) as geometryType from road_z14 where osm_id = -33085001 ;\n  osm_id   |    type    | geometrytype  \n-----------+------------+---------------\n -33085001 | pedestrian | ST_LineString\n -33085001 | pedestrian | ST_Polygon\n(2 rows)\n. Just noticed that we should probably add maki classification to these amenities.\n. An example is http://www.openstreetmap.org/way/27597658 which is not explicitly tagged as an area.\n. @lukasmartinelli thanks. I added a second commit which removes the parking areas from the road linestrings. As per OSM wiki it is used only for areas.\n. Thanks, updated the original PR with your changes added.\n. Also labels for road polygons need to be thought of\n. Yes, it is possible to just search and replace another language, but my wish was (for some time in the future), to be allowed to e.g. generate the yaml files by using some kind of templating where the required languages could specified. The generation is not a big priority for us, but I just wanted to document it somewhere. \nJust a couple words about the background. There exists four types of municipalities, monolingual and bilingual, both with Finnish and Swedish as the majority languages in Finland. In OSM the tag name is based on the majority language and both name:fi and name:sv exists for streets in bilingual municipalities. We would like to have street names rendered in both in Finnish and Swedish, as they can be quite different from each other. There is quite good data coverage, since the national road database has been imported with both names in place into OSM.\n. A possibility would be to use the list compiled by Mapzen for their metro extracts, which can be found here\n. They have it available also as plain JSON, which should be simpler to import at https://github.com/mapzen/metroextractor-cities/blob/master/cities.json\n. > Which data are you using. What is currently released on osm2vectortiles.org?\n\nIt might be possible that because we use the osm_id as vector tile key in the next version that the water is handled in the vector tile as one huge polygon even if it is not\nBut we don't have a fix for this. We need to use the water from OpenStreetMapData.\n\nWe are currently using a self-generated tileset based on your Docker images just prior to merging #222.\n\nI understand the need for having nice coastline styles for ocean polygons.\nCan you style the land instead of the water perhaps?\n\nThere is no land to be styled, as the land consists of just the background, which is colored using a solid color, making the water polygons our only choice to get nice colored coastlines. Somehow Mapbox has gotten this working, since using the same style with their vector tiles doesn't render edges between tiles and only on the coastlines. You might want to check what osm_ids they use for their water polygons.\n\nBTW Are you using osm2vectortiles for http://dev.digitransit.fi/ as you told us in #114? We love to hear what people are using osm2vectortiles for and where we can help. We hope that the next version will resolve most issues and it will bring along many many quality improvements.\n\nYes, we have been following your progress. We are currently using a self-generated tileset based on your Docker images just prior to merging #222. We have previously been using a different vector map style, which can be found here, but found your project to be much more complete.\nIn order to read more about our project, you can read more here\n. Would a similar approach to the one specified in #297 work with this. Especially if extending the polygons outside the expected buffer.\n. Thanks for your effort. I'll look what I can do locally for this. It's not a high priority bug for us either, I just wanted to document this somewhere.\nIf I don't find a nice solution we can just import the coastlines as linestrings, which can be styled separately.\n. > Something like tessera (tessera is not really intuitive however because you see a blank page when serving PBFs). We can merge it and discuss it further on friday or wait until then.\nIt should show a visualization of the vector tiles as long as you have tilelive-xray and all of its peer dependencies installed along with mbtiles.\n. Yes, it will just change the keys to correct when the tiles are updated.\n. They are mostly compatible, only some elements aren't rendered or look strange. This is due the more stringent validity requirements by v2. (changes are described here)\nAlso, I created mojodna/tilelive-tmsource#10 in order to get this fixed. Currently I'm just replacing tilelive-tmsource@0.4.x with git+https://github.com/hannesj/tilelive-tmsource.git in src/export/Dockerfile\n. Sorry for the lack of explanation. I found that one feature lacking in osm2vectortiles compared to mapbox vector tiles is the track areas at sports stadiums. The pull request is to mitigate this issue. See the comparison below for the streets style.\nOsm2vectortiles:\n\nMapbox: \n\n. @lukasmartinelli Could you fix my name to Hannes Junnila?\n. I'm not a lawyer, but it sounds to me like it is not clear if Mapbox is allowed to make such claims on the vector tiles, as to me they look to fall under derivative databse implicating a share-alike licensing in the ODbl 1.0 used by OSM.\n. You can do data-driven styles with mapbox-gl today using property functions\n. Duplicate of #300?\n. This was recently fixed in Mapzen tiles by https://github.com/tilezen/vector-datasource/pull/1124. ",
    "dfdietrick": "Thanks Lukas, that was the thing I was missing, to explicitly decompress as gzip.  I used a GZIPInputStream and can now parse the tile features successfully.\n. ",
    "miccferr": "Incidentally, there's been a recent post on Mapzen's blog about terrain styling:\nhttps://mapzen.com/blog/mapping-mountains/\nTechnically It deals with WebGL, but it also explains some basic concepts that I think might be interesting for a programmer with no \"geo\" background.\n. Hey there,\nThanks for the super-fast answer!\nUnfortunately I'm still getting the same error:\nWARNING: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nWARNING: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\nCreating osm2vect_cache_1\nStarting osm2vect_pgdata_1\nosm2vect_postgis_1 is up-to-date\nCreating osm2vect_import-osm_1\nAttaching to osm2vect_import-osm_1\nimport-osm_1 | No PBF files for import found.\nimport-osm_1 | Please mount the /data/import volume to a folder containing OSM PBF files.\nosm2vect_import-osm_1 exited with code 148\nIn addition to your input, I tried to recreate the folder structure with data/import as specified in  the import.sh script in the root of osm2vectortiles folder. \nMaybe I'm missing something with docker? \nMy steps so far:\n- I've downloaded Docker Compose\n- cloned this repo/ cd'd into it\n- run docker-compose up -d postgis\n- downloaded .pbf data wget https://s3.amazonaws.com/metro-extracts.mapzen.com/zurich_switzerland.osm.pbf\n- run docker-compose up import-osm\nI'm on a mac with:\n- OSX 10.11.1\n- docker-compose version 1.6.0, build d99cad6\n- Docker version 1.10.2, build c3959b1\n. Aha! I see..this is much clearer now. \nStill it gives me the same error :(\nIt behaves like there's either no .pbf file, nor the mapping works as expected.\nJust to be sure, once I download and cd into the repo, I also need to run make to setup all of Docker's images etc, right?\n. ",
    "stirringhalo": "I'll be digging into this issue, not immediately but after the final merge of ST_Subdivide and presumably 2.2 release.\n. @klokan Sounds good, I'll send you an email in a bit as I'm pretty busy today. I would love to hear what you have and what your challenges are. I'm considering getting the complete ASTER DEM to have even better coverage/resolution. I do have access to global contours but they are pretty coarse and not very pretty.\n. @lukasmartinelli \nLooks great, I saw this repository yesterday! I too will be having more time available as my project deadlines are soon past so I can dive into this again.\n. I will be doing a similar import for the planet. What sort of times are you looking at on S3 with how many cores for postgres and workers? Is this on multiple small machines (like one for Postgres and many for processing) or one large? How's the scaling to large CPU machines?\n. Sounds great! Sorry for all the questions!\nJust digging in with docker stats to better understand the architecture. I see one worker is fired up per machine (with the default docker-compose up export), and in fact you're limited by postgis performance. \nIs there a natural limit you find to scaling to more cores? Do you expect the rendering would scale to much larger machines with more cores? From your first comment, it sounds like a single worker on the same machine will saturate a postgres instance? But you mention 4 workers and one postgis on a 16 core machine?\nI haven't been able to get more than one worker busy on my 4 core workstation, I ran \"docker-compose scale export-worker=2; docker-compose up export-worker\" but I get errors related to cannot connect to S3. I saw that mock-s3 was installed/started, rabbitmq was installed/started and two workers were started by docker, however it doesn't seem to use mock-s3. I assume there's a step I am missing!\n. Awesome progress! Could you confirm which exact style works? I can't find any reference to streets-v6.json. Bright-v7 won't work as I get complaints in the console that \"constants are deprecated\", so I'm rather stumped on which style to use. I have partial display using bright-v8-original.json from https://github.com/osm2vectortiles/osm2vectortiles/blob/master/tools/compare-visual/bright-v8.json. Should I be using streets-v8.json?\n. Think these changes are ready to be merged? I'm still running into timeout issues and for the purposes of performance, I'm thinking of subdividing those super-large polygons.\n. Awesome, I grabbed the last changes. Looking great so far! Does this increase the DB size much?\n. To confirm, the DB when imported is about 150 GB?\n. > On what kind of hardware are you running the DB?\nI installed a 250 GB SSD as I knew the HDD would be sluggish for DB. I've successfully done an import with the pre-split code where it was ~150 GB but I was getting a bit concerned about the total disk space size after this second import.\n. Testing the changes now (I had misunderstood and accidentally merged your split-polygons and master branch so the first import failed due to that XYZ function missing). But you're missing landuse_split_polygon_table.sql from src/import-sql/ !\nEdit: I successfully got it working saving my current planet.osm.pbf import by manually running the split sql functions and create table operation. There was was an issue where there was a typmod on the landuse_split_polygon table that led to a mismatch but I managed to manually fix that. Not sure if that happened due to my manual rescue. I will run with this import for now, testing the rendering process and hopefully avoid another reimport till later.\nEdit2: Yep, the typmod issue was because not everything after the create landuse_split_polygon got run like indexes. Noticed after the abysmal tiling performance that something was fishy.\n. Question, does aa5049d simply ensure that the osm_landuse_split_polygon table is created prior to making the landuse and landuse_overlay views? I have all the changes except for  aa5049d and I'm still running into the issue of too large of geometries timing out. Going to dig into it, and see if I can either fix for this processing run or dump the extreme geometries\n. I'll hold off sending any bboxes. I suspect it's because I didn't set the index flag in docker-compose.yml but manually indexed landuse on area so any complex road networks (a good chunk of the planet) were timing out\n. @hyperknot I can't remember off-hand how many AWS VMs they are using, but I know they are all 8-core. I think it's 4 VMs.\nThe biggest issue is cores, and secondly storage. This is an embarrassingly parallel problem. You can scale this as large as you want to, but it is best to have a copy of the DB local to the workers (ie, on the same machine). The DBs need to be on SSD for good performance. RAM isn't a huge concern, I find 8GB is a decent sweet-spot for a few workers as Postgres is mostly using it for cache. The workers themselves use very little RAM.\nSo the most ideal setup would be many machines, lots and lots of cores, low RAM, and local SSD. You could do this easily with an adhoc cluster, but propagating the database to many machines could be a pain depending on your network and automation.\n. That is indeed where I was seeing it too. I had one failed tile around Lake Michigan (and the rest over Antarctica due to zero tiles bug with tilelive-copy #350). I don't have the job handy anymore as I decided to just run with increased timeouts to fix Antarctica. I will check my second run through.\n. I will be running a new import in the next few days where I've again bumped up the timeouts even further for that one Michigan tile. Hopefully that will resolve this final one.\nThat one lakes table (I believe it's the Natural-Earth IIRC) wasn't split with the subdivide fix #352 as there were labels in that table that I didn't want to possibly break. So that one table with large features may be to blame.\n. Nice, I saw that. Something else to learn!\n. > I guess you used the local Python script due to #331 not being available.\n\nWe don't use the mock-s3 in production but a hosted S3 provider.\nIf you run merge-jobs standalone this will not work but if you run it inside the merge-jobs container which is linked to the mock-s3 container the URL http://mock-s3:8080 will actually resolve to\nthe file (since Docker does host resolution).\n\nOdd, when using the merge-jobs docker container, it didn't seem to properly do host resolution. merge-jobs.py knew the .mbtiles were on the mock-s3 store but when the attempt was made to download it, all the sizes were 0 kB. Granted my tiling area is larger than my test pbf import (small city) so some 0kB .mbtiles are expected. With it hard-coded, I had some .mbtiles as expected >0 kB. I will see if I can diagnose this a bit further. Don't sweat this as the workaround is easy.\n\nIt is always the same AMQP URI format in the form you mentioned amqp://osm:osm@localhost:5672/. The wrapper script in the docker container that calls the Python script looks like this. It takes the env var from the docker container if it is set otherwise the default.\n\nThat may be it. I was running the merge-jobs.py script directly, so it wasn't picking up the AMQP_URI variable correctly. Will report back!\n\nI could copy an empty MBTiles file into the repo for example that can be used as merge target. Would that work?\n\nSounds like a good solution. What is the advantage for using a merge target? Does it take less time to merge as you only merge in the tiles which have changed?\nOdd, I haven't had any success even with the mock-s3 container with host resolution. I haven't pulled it apart yet, but it appears the merge-jobs script knows the .mbtiles are there, but when the attempt is made to download, no .mbtiles are successfully retrieved and merged. With the hard-coded mock-s3, it works fine and generates a nice .mbtiles (working on a small city now to confirm the process)\n. Oh, and thanks for the Skype call offer. At this point I really only have questions when I come across them, so not worth it. And it's probably best to have the conversation here so that there's a log of it for others! Most of my questions will probably resolve around tuning and optimizing, especially with regards to job sizing.\n. Looks like I'm still facing the same issues. I'm not sure if the issue is arising from domain resolution, but each merge line of known good data looks like:\nDownload \"http://mock-s3:8080/osm2vectortiles-jobs/{string}.mbtiles ({some amount greater than 66kB})\nMerge 0 Bytes from {string}.mbtiles into /data/export/planet.mbtiles\nThe planet.mbtiles in ~/osm2vectortiles-2.0/export never seems to grow with the additional data. I had it working on a different test VM briefly, but I can't seem to duplicate. After the Download/Merge lines, does it merge almost immediately?\nIf I do merge two mbtiles manually with say https://pypi.python.org/pypi/umimbutil, it works just fine.\nI will make one last attempt at this with an already existing .mbtiles of some random area in export. It appears as the merging task is failing as the planet.mbtiles is empty?\n. As a followup, here's my approach for now instead of the docker merge-jobs. Plus, this doesn't take the messages out of the queue:\nsudo apt-get install sqlite3\nexport MOCKS3_URI=http://localhost:[port]/osm2vectortiles-jobs\ncurl $MOCKS3_URI| grep Key | cut -d \u201c>\u201d -f 2 | cut -d \u201c<\u201d -f 1 | grep mbtiles > mbtiles\n<mbtiles xargs -I % wget $MOCKS3_URI/% -O ~/mbtiles/%\nwget https://raw.githubusercontent.com/mapbox/mbutil/master/patch\nchmod +x patch\nmkdir output\nmv $(ls | sort -n | head -1) output/planet.mbtiles\nfor i in *.mbtiles; do ./patch $i output/planet.mbtiles; done\n. Hey, see the wiki. I highlighted a bunch of things in bold that are specific to AWS or things I haven't run/tested yet or aren't documented enough for me to jump off from. Hope it's a good start!\nAs I can see it now, I think you're missing the docker container on docker.io for diff updates (it's not documented) as well as for changed-tiles. Also, could you make a dockerfile available for import-osmupdate.sh as that would be the easiest way to keep a PBF updated?\nWhat are your thoughts on Docker swarm for orchestrating? I'm relatively new to Docker so I'm playing catchup.\n. > We will try to work on all this issues you file. At the moment we are busy writing the thesis and try to not get distracted too much :wink: But after that we have more time for docs issues on the webpage itself.\nNo worries, been there, done that. Good luck!\n\nExcellent work there. We will extend it.\n\nAwesome :)\n\nI think another thing that stands out is that generating the jobs is too complicated and could be integrated directly into the generate jobs script for example (so you don't have to know about pipecat).\n\nMakes sense.\n\nThe Docker import image is reused for all the things. To update the PBF I run docker-compose run import-osm bash import-osmupdate.sh after a successful diff import. You can run bash scripts inside a docker container. We can add a separate docker compose entry so you can run docker-compose run update-osm-pbf or something like that.\n\nAh I had trouble getting the docker-compose run import-osm bash import-osmupdate.sh (or something similar). But I'm learning lots about this whole docker thing so something not working is probably me not understanding how it works.\n\nI wanted to use it but to managing the hosts was simple enough to do with plain SSH automation as you only have to execute a few docker compose commands to get the worker started and working through\n\nHave you heard of the GNU Parallel tool? It's a cheap and dirty way to automated SSH logins across the cluster. I've used it extensively to treat both local machines and networked machines as nodes on a cluster. With shared storage (S3/mock-s3/NFS), it's a handy way to login and execute some script and get the results back on the shared storage. Key-based logins can be a chore however to setup but it makes sense where you have many cloud instances and don't necessarily want the complexity of a full docker swarm or something else.\n. Done\n. Ha! Fair enough :)\nAnd I understand from the perspective of the tileserver. I do see some of the advantages of docker but also some painful points, especially w.r.t. the DB.\nKeep in mind I'm coming from a mostly GIS perspective, with some CS but not necessarily heavily into development/deployment.\nWhat are your thoughts on using \"VOLUME /var/lib/postgresql\" (to have it on direct filesystem) or have some option to connect into an existing backend DB? I realized backups can still be done easily with pg_dump as it is now (thanks!) but in cases of mixed/specialty storage, you might want to put the DB elsewhere other than the container.\n. Here's the traceback:\n\nexport-worker_3         | Traceback (most recent call last):\nexport-worker_3         |   File \"export_remote.py\", line 233, in \nexport-worker_3         |     main(args)\nexport-worker_3         |   File \"export_remote.py\", line 227, in main\nexport-worker_3         |     args['--bucket'],\nexport-worker_3         |   File \"export_remote.py\", line 185, in export_remote\nexport-worker_3         |     channel.start_consuming()\nexport-worker_3         |   File \"/usr/local/lib/python2.7/dist-packages/pika/adapters/blocking_connection.py\", line 1681, in start_consuming\nexport-worker_3         |     self.connection.process_data_events(time_limit=None)\nexport-worker_3         |   File \"/usr/local/lib/python2.7/dist-packages/pika/adapters/blocking_connection.py\", line 656, in process_data_events\nexport-worker_3         |     self._dispatch_channel_events()\nexport-worker_3         |   File \"/usr/local/lib/python2.7/dist-packages/pika/adapters/blocking_connection.py\", line 469, in _dispatch_channel_events\nexport-worker_3         |     impl_channel._get_cookie()._dispatch_events()\nexport-worker_3         |   File \"/usr/local/lib/python2.7/dist-packages/pika/adapters/blocking_connection.py\", line 1310, in _dispatch_events\nexport-worker_3         |     evt.body)\nexport-worker_3         |   File \"export_remote.py\", line 181, in callback\nexport-worker_3         |     raise e\nexport-worker_3         | subprocess32.TimeoutExpired: Command '['tilelive-copy', '--scheme', 'pyramid', '--minzoom', '6', '--maxzoom', '14', '--bounds=-180.0,83.9792594989,-174.375,84.5413610731', '--timeout=40000', 'tmsource:///tmp/project', u'mbtiles:///usr/src/app/6301c97fbd0bd8bd085787a79a7e602d08757e31.mbtiles']' timed out after 300 seconds\nosm2vectortiles20_export-worker_3 exited with code 1\n\nEdit: I see that it's quitting as tilelive-copy is taking 5min (300s). Sounds like you use much smaller jobs so you don't hit the limit? \nEdit2: Diagnosed as being a specified timeout in subprocess, is there a specific reason why it's set so low? Trying to getting around some geometries which just seem to hang it up?\n. Ahh, fair enough! I use smaller job-zooms (8 IIRC) and upped the maximum timeout. I wonder why the middle of the Indian ocean.. Might be that French island with a glacier.\n. Totally agree with Mickael, this project has been awesome to follow and even better to setup and use with the great help you've all been providing!\n. > Thanks for digging in!! Great stuff.\nNo prob, this is when the GIS nerd kicks in!\n\nLike this.\n\nAwesome, thanks!\n\nTo deal with these problems later one approach is to ensure that workers are timing out fast (this is not configurable yet however - I modified the Python export_remote script to do that). This way you can at least render all the tiles that don't have any problems.\n\nYep, I added the shovel plugin to RabbitMQ so I could automatically move failed-jobs to the back of the jobs queue. That way I run through all of them, and even handle other errors that might've crept in. Works well.\n\nHmm, yes ST_Area is inaccurate at the poles, so no wonder there are many split polygons there. I only had problems with the south pole by the way, north pole worked.\n\nI saw a couple of northern latitudes. I suspect that was the big glacier feature over Greenland.\n\n\nst_area(geography(st_transform(geometry,4326)))\n\nSo with this we can avoid slicing polygons that are not huge actually?\n\nYes! I tested it on features that we a high latitudes (using the y-coord of the centroid to identify them). At high latitudes, it was sometimes a factor of 25 different in the reported area between st_area(geometry) and st_area(geography(st_transform(geometry,4326))), which is extreme but expected. So I think there was substantial over-segmenting. I suspect the UNION ALL with all those features is what's killing it.\nDo you think there's any timeouts due to overly large line features? That's one of the other advantages of the st_npoints approach, it handles lines and points too. Choose a reasonable number of points to handle and split anything above it on the z9 grid you have.\nAs an aside, do you think using materialized views would make a difference and reduce some of the Postgres load? I haven't dug into the specific queries that are made against it but it might make a difference on the more complex layers such as landuse/overlay or roads.\nIf I get a chance tomorrow, I'll send you the bboxes and see if the redoing of the splitting with the fix worked. I suspect it will make a huge difference.\n. Okay, got the changes to osm_landuse_split_polygons made. I've modified the views now to reflect the new way to calculate area, and I will do a run through with the st_area(geography(st_transform(geometry,4326))) approach.\nOnce I tried the new way, the number of rows in osm_landuse_split_polygon dropped from 56891 to 48870.\nStill testing this, looks like export-workers is still timing out but I might've missed something.\n. Here's all my failed jobs, almost entirely +/- 60 latitude. There's a few around 40-43 latitude but I suspect those are the known issue tiles from #330 . There also appears to be a failed tile in Mali. I'm using an extended timeout (100000) IIRC so I probably have fewer timed-out jobs.\ndied.txt\n. I can't seem to get the rendering going again, it's hung-up on export-worker at 1/s. I can see the queries going to PostGIS.\nI suspect it's the now too complicated landuse.sql and landuse_overlay.sql layers. I tested the old view and new view approach and found queries were taking significantly longer (<1s vs 30s or so).\nI'll see if I can optimize the queries. I will put the area into a new column, use that for the views and investigate if I can where the sluggishness comes from. \n. I identified one issue, the range query in the landuse and landuse_overlay layers is very expensive. If you drop all rows with the area st_area(geography(st_transform(geometry,4326)))>1000000000 from osm_landuse_polygon, osm_landuse_gen0, osm_landuse_gen1 and index on the remainder, you save a factor of 10 from select queries on those views. From 40s down to 4s. I think there could be some enhancements made to the create view selects, but they are unnecessary when the 1000000000 limit exists.\nExport-workers is still slow.\n. Ha, no worries!\n\nUNION ALL should have no performance impact. UNION does.\n\nCame to the same conclusion, the difference was negligible. If there was many landuse polygons at the poles it may have been  significant, guess not.\n\nWe use precalculated tables (same as materialized views) to precalculate the centroid for labels.\nThis is worth it if the same geometry is requested over and over again. If it is only request once (when the tile is rendered then precalculating doesn' thelp).\n\nYep, realized the same. I added some indexes to landuse_class to try to narrow down the performance issue. No dice, definitely the only solution was the removal of the large features from the gen0,gen1, etc tables.\n\nAhh ok. We can get the area already precalculated from imposm3...to speed it up.\nI am open to a completly new approach for dealing with the large polygons (at the moment it feels hacky with this extra table that is only used for the large ones).\n\nI wonder what imposm3 uses to calculate area and how well it works at the poles. Though at this point it's irrelevant.\n\nBest way would be to use ST_Subdivide https://blog.cartodb.com/subdivide-all-things/ as @ImreSamu mentioned. However only works with PostGIS 9.5 - and we can only do this if we ever do a rerender since we need to stick with a DB format if we only want to work with updates.\n\nSeeing as we can fairly easily upgrade to Postgres9.5/Postgis2.2 with docker (I see the elegance now!) and changing it appears to be fairly trivial (my hack will simply make a new table with st_subdivide geometry), I will in the next day or two, depending on my free time, test it out on Greenland. I have enough mbtiles to test the later stages of import, so I can move on for now and come back to this later.\n. Just as a follow up, I've been testing with ST_Subdivide with a custom docker image. So far the results aren't definite, but I'm running another test to hopefully identify whether render performance has improved. I'm using the same AOI of -22.5,79.6871841545,-21.09375,79.9359182463 from #314 . My OSM pbf is solely of Greenland.\nI've been testing by renaming osm_landuse_polygon, osm_landuse_polygon_gen1, osm_landuse_polygon_gen0 to a temporary name and then doing a \"CREATE TABLE  AS SELECT id,timestamp,type,stsubdivide(geometry) as geometry from _\". I do notice with this operation that the number of features increases greatly, and the max(st_npoints(geometry)) is never higher than the limit in st_subdivide.\nWithout ST_Subdivide, it times out. With ST_Subdivide(geometry,128) on osm_landuse_polygon, osm_landuse_polygon_gen0 and osm_landuse_polygon_gen1, it usually completes with no timeout but still occasionally does with the default timeout settings. It is still slow as instead of one ginormous feature to open, there's many small ones. I didn't do any new indexing on the ST_Subdivided tables just yet (well I did in early tests but still wasn't conclusive) but I will in the next more formalized test. Though it may not matter much on the small tables.\nI've noticed my generated .mbtile for that area (zoom 0-14) is blank however, with no contents. I'm not sure where that issue may be coming from but this is a somewhat promising start. Is there some limit to number of features in a single tile? I imagine doing the same operation on ne_*m_lakes may help too.\n. Subdivide.sql . Run this after import-osm and before import-sql. A VACUUM ANALYZE is probably needed at the end.\nDockerfile for PostGIS 9.5 with GEOS3.5 version to provide ST_SUBDIVIDE . Pgtune was disabled for now.\nI think tuning can be done on how many points to subdivide to, might save some DB time, as well as size of indexes and tables. May influence the size of the MBtiles.\n. You know what, I suspect it might be a bug in tilelive-copy. Something is mis-calculating the jobs/progress in a region and truncating the .mbtiles.\nHere's why:\n1. I continued testing the st_subdivide branch and noticed no difference in timeouts. They were still occurring.\n2. I decided to focus down on zoom level 14, so I set min_zoom and max_zoom to 14.\n2. I decided to start digging into the other options for tilelive-copy like concurrency, parts, slow, etc. With slow, I could watch the progress and saw with the Greenland. I compared the following two bboxes:\n-22.5,79.6871841545,-21.09375,79.9359182463 (Original Greenland tile, it times out normally)\n-25.5,79.6871841545,-24.09375,79.9359182463 (Slightly further inland, same longitude dimensions at the same latitude so should be same number of tiles, doesn't seem to timeout normally and generated a complete mbtile)\nWith \"slow\" set to 10 in export-local.sh, I could track the actual tiles being processed. I noticed both bboxes seemed to progress and not hang-up. But, if you track the official progress messages, the coastline bbox stops at 103-139 \"jobs\" (or checkpoints, that seems to be when it dumps to mbtiles). After about 30s, it then jumps to 100% completion if the timeout time isn't too low. The output mbtile is truncated to that last job and is nowhere near the proper size.\nIf I ignore the progress reports however and look at the slow tiles as an indicator, I get a similar number of tiles \"processed\" as the inland region in the same ballpark time. So the mbtiles are being truncated somehow . I will parse the output slow tiles better, removing duplicates, so I get a more accurate number.\nGranted, both tests were with st_subdivide. Later I will generate a PR without st_subdivide with some basic diagnostics. Once we narrow down the issue further and if the issue is still apparent in tilelive-copy, then I'll submit an issue to them.\n. facepalm\nMakes perfect sense!\n. > @stirringhalo It is based on your wiki entry. Based on the superbe docs written by you I saw that it is way to complicated. I simplified some components so that users no longer have to use pipecat etc. This happens in the containers now. It is still not perfect, want to extend it with the things you have written in the wiki.\nExcellent, been buried with split-polygons and subdivide so I just had a good look at this now. Looks fantastic and really helps! At some point I'll point the wiki at your USAGE.md document\n\nI nkow you use this component @stirringhalo in testing. But I tested with the mock-s3 and it just doesn't work very well - it cannot substitute a real S3 setup (sometimes exceptions happen in the mock-s3 container when replacing files) and especially when rendering it for real this does not really work with the mock-s3.\n\nNot a problem, I saw some of the same issues. Like, you can't have much more than 20,000 files in mock-s3 or it gets buried and is very slow. So I stick with zoom-job level 7. I'll keep using it for now as it's handled my previous planet render relatively well. But I'm starting to consider other options down the road.\n. My thoughts for other tables that may need to be subdivided if this works:\n- [x] osm_ocean_polygon\n- [x] osm_ocean_polygon_gen0 \n- [ ] ne_10m_lakes\n- [x] ne_10m_ocean\n- [ ] ne_110m_lakes\n- [x] ne_110m_ocean\n- [ ] ne_50m_lakes\n- [x] ne_50m_ocean\nThis is based on my planet mbtiles where the lakes, low zoom ocean and landuses seems to timeout rendering. Styles may need to be tweaked as there's a subtle outline on water in at least the streets style.\n. From #354, tiles in Greenland process in ~35ms instead of 5s using ST_Subdivide!\n(Edit from the future: Not quite 35ms as those were blank tiles, but still a significant improvement)\n. > We made you a core member of OSM2VectorTiles and added you to the organization (you can decline of course). I think you would be a great addition. Welcome and thanks for your engagement.\nThank-you, I gratefully accept the offer!\nI will do some further testing of ST_Subdivide on the full planet then I'll give the thumbs up on merging.\n. ne_10m_lakes, ne_50m_lakes and ne_110m_lakes don't need to be split. Largest feature is 2604 points at 10m. Also the NE lake tables has a name column which I think is being used, so subdividing may break labels\n. Further benchmark numbers comparing ST_Subdivided to non, using a BBOX region with -25.5,79.6871841545,-21.09375,79.9359182463\", 0 -> 14. This is with \"slow\" on so I could track it's progress on individual tiles. Not quite a full oranges to oranges comparison as ST_Subdivide had Postgres 9.5 while non used 9.4. Timeouts were disabled.\nUsing 1024 vertices to split.\nNumbers are rather higher as this is on slow HDD for now as my SSD is full of the planet DB. So I expect the performance to be even better.\nST_Subdivide: 2m 23s, averaged about 40/s at the final close. MBTiles is 576.5 kB. 5529 tiles.\nNon: 13m 56s, averaged 7/s. MBTiles is 577.5 kB. 5529 tiles.\nI'm surprised it's actually slightly smaller....\nNext step is a full planet run from the import-sql stage onwards with timeouts disabled.\n. Note to self, need to SetSRID otherwise layer-specific views fail\nNeeds to be done for:\n- [x] osm_water_polygon\n- [x] osm_water_polygon_gen1\n- [x] osm_landuse_polygon_gen0\n- [x] osm_landuse_polygon_gen1\n- [x] osm_landuse_polygon\n- [x] osm_ocean_polygon\n- [x] osm_ocean_polygon_gen0\n- [x] ne_m_lakes\n- [x] ne_m_ocean\n\nSo the SRID gets lost after subdividing?\n\nLooks like it does. I could do it in one step in the subdivide.sql ALTER TABLE, didn't realize it was going to be an issue.\nAny layer where two mismatched geometry columns are unioned, this needs to be fixed. Should be done with ST_SetSRID so it doesn't need to be done on the fly in views.\n. Please test now! I decided to redo my world import as it wasn't a clean slate after my previous split_polygon hacking. I can't confirm the SetSRID fixes beyond the fact they are syntactically correct and work on smaller Greenland imports. One or two of the SetSRIDs may be unnecessary as I was changing the geometry column types and manipulated SetSRID on my previous planet import.\nI forced build on the necessary docker images (import-sql, export, export-remote, postgis) in docker-compose.yml just to ease the first run. I also made fixes for the timeouts issue and I set 30 minutes for the tilelive-copy timeout and 1 hour to complete one job (5 minutes was too short for zoom-level 7 jobs)\nI will be following soon with my own planet import and render once it completes again.\n. I see that #171 references a different PGTune approach that supports 9.5. Will look into this at some point.\n. > For me that is not necessary yet since I tune it for production anyways. We can merge it without. It was a nice to use though since most users wouldn't tune the DB otherwise.\nYep, and I've always been unsure if I'm making things better or worse by tuning! Max_connections and a few others will definitely be something to tune\n\nI am now testing this branch on https://github.com/osm2vectortiles/osm2vectortiles/tree/new-import-v3. Doing a new import and will try to render the recent changed tiles with this.\n\nSounds great, just saw the branch. I ran out of disk on my SSD as I forgot about the cache that was taking a fair bit of space already so I had to redo the import. Hence the no-diff option!\n\nHave a bit more time at hands to look at all the awesome stuff you were up to @stirringhalo (fell a bit short sorry).\n\nNo worries, I've enjoyed digging into timeout stuff over the weekend. I'm curious what other performance tweaks can be made to import-osm as very little of the time is spent actually writing OSM vs all the generalization/indexing tasks.\nOnce the ST_Subdivide gets merged, I will get it working more in parallel so it doesn't take so long on the create table, etc operations. But from my testing before I reimported, it wasn't taking too long, perhaps an hour or two. Much faster than split_polygon. \n. @lukasmartinelli \n\nImport takes 19hrs now with all the additional stuff we currently have. Quite increased since when we started.\n\n19 hours? Is this for the import-external, import-osm, import-sql steps? I do know import-osm is slow once the actual OSM data has been dumped to DB. In non-diff mode, the writing of OSM without indexing took about half the time as diff mode!\n\nAnd import-sql with splitting and indizes takes another 0.5hr.\n\nThat's not too bad, and inline with what I was seeing.\nOnce my import catches up, probably by tomorrow, I will start my own export. If you focus on Delaware, Greenland and Chile, I will get the southern ontario region exported.\n. @lukasmartinelli\nI didn't check just yet with a visual side-by-side comparison as I imagine many of the glitches would be due to styling and outlines (we won't be 100% compatible with Mapbox styles for oceans), but I did an ST_IsValid check for invalid features. I did see a few invalid features and dropped those on one of my tests. I don't remember the exact number but it wasn't a significant number. I will investigate how some of those invalid features are handled by the rendering.\nThere might be a small faint gap between subdivided features, perhaps from rounding issues internal to PostGIS. This is where an outline of 1 pixel might be necessary.\nLooking at the buglist for ST_Subdivide, thankfully there hasn't been a rash of anything. Though we may have to be careful if we use ST_Subdivide in a more generic way on more tables like points: https://trac.osgeo.org/postgis/ticket/3522 . But I don't imagine there's a need to.\n. > No was the Delaware export. This export previously always failed but now it ran through in 1d and 7h and exported 588.9k tiles.\nAwesome! Very thrilled to hear that. I should have a good chunk of my import completed Monday/Tuesday. Have you been able to do a visual inspection yet?\n. @lukasmartinelli , question, any further timed out tiles or has this fix managed to remedy them all?\n. > This was the uber fix. Changed some things however and made a new PR #367. Once this one is merged we can resolve this as well.\nExtremely happy to hear that. My render stalled over the weekend (or so I thought) and despite restarting it Monday, did so again. I thought it was still a timeout issue on a bunch of large undivided features but I found it was due to the re-enabled RabbitMQ heartbeat in commit a62509. So my rendering continued to Mock-S3, but the jobs weren't being passed back to the \"finished\" queue. Solved that, hopefully mine will complete shortly too.\n. Which osm.pbf are you using?\n. > I downloaded a pbf around  my city\nWhere from? If you provide a link to it, we can potentially test it. Perhaps it's a bad pbf. Also, which operating system are you using (though it shouldn't matter)?\n. Yes, depending on your OS you will need to modify the below:\ndocker ps -a  , you will see a pile of rows, where you should see something like 0.0.0.0:[NUMBER]->5432/TCP\nUse that number to connect with psql like so: psql -h localhost -p [NUMBER] -U osm -d osm . If you type \\dt+, you should see many tables with a size greater than a few thousand bytes.\nNext time you run everything, run docker-compose up postgis without \"-d\". That way you can see the status messages for Postgres and identify any problems.\n. Makes sense, I think that also messed with the split_polygon benchmark as I expected those tasks to complete successfully!\nNot sure at this point but the timeout may still need to be increased as with the default, it was timing out on the zero feature tiles even with the speedy st_subdivide. Not critical and easy to fix. I'll have a look into it.\n. Yep, zero tiles still time it out as there's been no progress adding to mbtiles. Setting a slow timeout threshold, you can see if happen while tiles are still being processed as indicated by \"slow\".\nSuggest the timeout gets axed for now unless we still run into the issue again later. Or at least set it very high.\n. > That makes sense, no tiles recorded - no progress recorded and then a failure is reported even though everything is fine. Thanks for clarifying. It is kind of a weird edge case in tilelive-copy.\n\nIn earlier version we used tl copy from https://github.com/mojodna/tl which deals differently (it does store empty tiles and does not time out but seems to be slower). Perhaps I will do a switch back for pyramid jobs.\n\nDon't really need to as the fix is so easy. Bumping up the timeout works well. I'll put together a PR with 20min timeouts. Do you think that will still work for Antarctica well as if it's 90% empty it will still timeout on large jobs?\n. @lukasmartinelli \n\nIf the Travis build succeeds you can merge it yourself into master. (Do you have access to do that yet?).\n\nNot sure, as #352 fails Travis and this one hasn't completed yet!\n\nBTW since you are a member of OSM2VectorTiles you can now create branches like this directly on the main repo (has the advantage that the other members can improve the proposed changes directly on the repo here).\n\nVery true, but I don't seem to be able to? First time part of a larger organization. Editing files on osm2vectortiles forces it to a branch of my own repository. I can create a repository as part of osm2vectortiles but I don't have write access to any existing repos.\n. > Uuups didn't add you to the repo. You now should have write access.\nNo prob, thanks! I will be keeping most of the PRs very small and non-breaking for now until I learn a bit more about Travis build checks and get a bit better environment setup for dev.\n. No prob, makes sense! I'll let you merge when #362 is ready.\n. Yes, that was a problem with the old generate_jobs docker images. Now, with 246f85855f4c3e4054bc33, the lower zooms get added as jobs by default.\nOn my latest build (which I haven't confirmed visually), the lower jobs get added as a job to be processed\nAre you still seeing an issue? Are you rendering only small extracts?\n. > That's true but this jobs times out because it takes more than 2hrs.\n\nStill have to kick off the low zoom levels manually for the planet.\n\nAhh, makes sense. I had to up the timeouts for mine, latest seemed to go through entirely successfully.\n. I know as part of the optimize step it drops a lot of the pbfs from the MBTiles. Any ideas on how to test whether an MBTiles is complete?\n. @osm2vectortiles/lukasmartinelli \n@osm2vectortiles/manuelroth \nMy proposal is this:\nLeave all optimizing to the end, as a final step. This way, once all the merging has been performed, a run through can be done identifying all missing tiles. If there is any, build a new jobs list, re-export and re-test. If none are missing, optimize and complete.\nNot sure if this works with the diffs that you guys are running?\nThoughts?\n. @lukasmartinelli \nHere's a quick and dirty checker of an mbtiles (https://github.com/stirringhalo/missingtiles). Could be improved by not generating a set for a big comparison but this works, especially if you are confident the pyramid has been build completely and are just checking at the job-level. Can be easily hacked to spit out the tiles to a file so they can be re-run. Of course this assumes the mbtiles hasn't been optimized!\n. Blargh, hate reinventing the wheel!\nSo we have multiple numbers of tiles expected depending on optimization:\nplanet expected (full size)\nplanet minimum (deduped and optimized)\nplanet missing\nI figure the best bet is:\ntiling (but no optimize) -> merge -> test (re-tile missing if no) -> optimize -> planet.mbtiles\n. @lukasmartinelli \nAhh, that's because you have some added complexity with the merge docker container using RabbitMQ, not the file listing from S3. Do your merge tools still consume the jobs from RabbitMQ without republishing them back into the queue?\n. Yep, I remember that. For now rabbitmq works mostly fine but I understand some of the advantage for beanstalk.\nFor now (and for others to see), my fix is when only unacknowledged messages are left, kill all the connections and restart all the workers.\nBut it's a pain without a script to kill all connections.\n. Testing here: #383\n. > How to proceed\n\n2 alternatives.\nFix RabbitMQ process\nPros:\nComponents still work\nI really like working with the pipe tools to administer the jobs\nCons:\nIn the end it will be a hacky solution\nA lot of time has already been spent solving this problem - perhaps dead end\nDifferent job queue -> beanstalkd\nPros:\nSolving the timeout thing once and for all\nCons:\nRewrite merge-jobs, generate-jobs and export-worker\nOption 2 is more feasible now than earlier because now I have no deadline of finishing up the thesis. And can invest time in stuff like this.\nI know @klokan is for option 2 as well.\n\nWithout knowing much about beanstalkd, I'm personally in favour of RabbitMQ as its a known quantity with known issues. We also have less breaking commits. \n. It's working as expected, no unacknowledged messages generated. I'd typically see them when starting a new worker. At the end, there would always be one job missing for each worker on the (mock-)S3 storage.\nHowever, and this was was somewhat expected, Ctrl+C on the worker will effectively lose the job. To get around this, should we have a 4th queue \"in-progress\", where current jobs are sent to and immediately acknowledged? That way if there's an interruption, we know exactly where it was left off. Plus, with the \"shovel\" plugin, the in-progress messages can easily be put back into the jobs queue.\n. Well I'm now officially stumped. You can't just put it to a \"in-progress\" queue and move it off because you can't guarantee message order. Unless you hackishly have a queue for each worker so you can monitor which exact one it crashes on.\n:confounded: \n. @timdorr and others, I'm in the early stages of putting together an OpenStreetMap based styling using the same tile schema which is in MapboxGL style spec. It has the same license as openstreetmap-carto, CC0.\nIt uses the work by https://github.com/geofabrik/openstreetmap-carto-vector-tiles with a small tweak to allow for the development of https://github.com/stirringhalo/openstreetmap-mapboxgl.\nWhat's currently styled? Landusages are mostly done, roads are at an early stage as I haven't grappled with road layering/bridges/or tunnels. Tracks are done. Buildings are done. Amenities need the icons ported over from openstreetmap-carto. I need to figure out what fonts in PBF form I can openly use. Most water features and background shapefiles are done. See https://github.com/stirringhalo/openstreetmap-mapboxgl/issues/1 for the issue tracking the approximate state of where styling is at.\nOver the weekend, I plan on putting up a public, collaborative style portal which uses https://github.com/erikandre/mapbox-gl-style-editor to provide online editing capability. It will have a smaller extract, like Switzerland or something.\n. Dropping this here, https://github.com/stirringhalo/openstreetmap-mapboxgl (http://45.56.99.211/) . It's my exploration of using https://github.com/geofabrik/openstreetmap-carto-vector-tiles to get a schema matching that of CartoCSS.\nI haven't touched it in a bit, stepped back to work on another project. One of the major steps left is to do width dependence on roads and road stacking for railroads. Proper road stacking with tunnels, bridges, casings and fills is complete.\nMajor issues I see with it are it's difficult to handle stacking properly with casings+fills. For example for roads, I use property based line attributes (a beta feature in Mapbox GL JS) and ordering of the db to properly order casings+fills for tunnels, bridges, and ground level so they are seen correctly by the renderer.\nMajor benefit to this approach, it's already a familiar schema to hundreds of OSM stylers.\nIf you want, I'd be happy to give a fuller description.\n. Is https://github.com/ClearTables/osm-clear the base for all tm2source styling direction? I'm happy to move my 3D building stuff over there or to a fork of it if yes.\n. @lukasmartinelli , I went through and checked the vertex counts in some of the tables which I suspected had large features. Oceans was one of them. I noticed in https://github.com/stirringhalo/openstreetmap-mapboxgl that Oceans were already subdivided thoroughly. \nYou can also see that in an \"official\" openstreetmap import, glaciers are also split too (http://45.56.99.211/)\n. @lukasmartinelli @romanshuvalov \nMy personal preference is to have both Contours alone and OSM+Contours. With https://github.com/stirringhalo/openstreetmap-mapboxgl coming along well (waiting on property functions for line features so I can render all roads in one go), I'd like to merge in the contours there too. \n. It should be docker-compose up import-osm!\n. Odd, how is your import directory structured (is there only one osm2vectortiles folder you are using) and is your docker-compose.yml file unmodified?\n. Yep, to confirm I used 16.04 and it works perfectly!\n. > Abandon all hope before looking at the roads code ;) The roads MSS is about 40% of osm-carto, and a significant portion of the SQL. It tries to get everything right, more so than any other style out there. There are a grand total of approximately zero people who fully understand it.\nHa! I've been diving into how osm-carto interacts with the SQL selections. I think I get it, sorta...ish. :confused: \nI have a plan for getting it to work, most of the hiccups are with Mapbox Style Spec. There's some new property functions that are in the works for lines. Just waiting for line-dasharray to be supported for property functions. The roads SQL will be majorly hacked up from the original, it's the only one that needs to be.\n\nI would add that I think the osm-carto queries are badly suited for server-side vector tile rendering and worse for client-side vector tile rendering, but if you can get it working well I applaud your work.\n\nThey aren't actually half bad. Speeds for one worker are about 50-60 tiles per second for Switzerland. IIRC that's in the range of my planet builds using OSM2VectorTiles. \n. @mboeringa \nWow, very nice looking. I agree 100% it's a pain in the ... . I actually just got it working properly with Mapbox GL JS and Openstreetmap tile schema.\nStill lots of work to be done to make it zoom dependent widths and including railroads+paths (which at this point don't work the best with the approach I have) but stacking works 100%, even when it gets really hairy in the stacking!! \nKeep an eye on http://45.56.99.211/ in the next day or two for the latest developments.\n. > I would actually prefer to see it in a seperate repository inside OSM2VectorTiles instead of of two ways go generate vector tiles in the master branch.\nOkie dokes!\n\nI think it fits perfectly into the organization because it \"turns OSM into vector tiles\" but is a different approach (but one I really appreciate and am very happy to see realized!!).\nI would like to keep it under the OSM2VectorTiles umbrella but as you wish. You can also take it to your own repo if you want.\n\nI'm very happy to move it into the OSM2VectorTiles organization. I will do so once I have the road styling more complete. I have just figured out how to do proper road stacking, still need to figure out tracks but that should be mostly straight-forward!\n\nWe can even promote it on the website etc. since I like it but it kind of a different project we started here although using the same approach.\nWhether we will prerender them and how to serve them will be a different topic :grin: \nBut perhaps we find someone to sponsor a rendering.\n\nI can do the rendering :smile: I have a machine to do it on. I can upload a rendering, probably on a monthly interval.\nAt this stage I am using the line2 branch of mapbox-gl-js as I need the data property functions for lines so I can properly do roads. \n. @kekscom \nYep, I could definitely include more attributes like roofshapes, though they won't be rendered as complex rooftops! I could also add in materials so that color choices can be made by the style.\nWith regards to 3D and MapboxGL, I'm not sure it's 100% at the point where it replaces something like Cesium in capability. I have a working offline demo that uses OSM2World and 3DCityDB to fill a database with buildings and dump them to tiles to view in Cesium. It's a powerful solution for handling lots of buildings with the full capabilities of drawing complex rooftops as opposed to basic extrusions. Only hurdle is hardware needs to view lots of buildings in a downtown area when in KML formats.\n. Okay, I did the first demos last night. I got it to draw in 3D, but I don't have any proper height dependent 3D drawing yet. Might be an issue that I did Switzerland, mostly centered over Zurich so not much in the way of complex buildings. I will try New York next. Unfortunately the fill-extrude-height and fill-extrude-base requires \"stops\", adding a layer of complexity to my demo style.\nSecond issue that I may face, what \"order\" do I do in the tm2source for buildings? Right now, it's ORDER BY ST_YMin(ST_Envelope(geometry)) DESC. But thinking about it now, I may need to change this to be height dependent, drawing the lowest layers first, potentially sorting on min_level/min_height. Hmmm.\n. @kekscom I have no problem adding more tag information.\n. Oop, better image:\n\nHave to figure out why building:part is missing, I'm not as familiar with imposm3 mapping as I am imposm2. Any thoughts @lukasmartinelli ?\nI'd like to put forward a tm2source eventually with all the tags, but it will explicitly not be compatible with Streets as much as reasonably possible.\n. I figured out the bug, it was a missing set of keys in mapping.yml!\nLooking great so far, I'm adding the additional features and I'm testing data-driven colouring using the colour functionality. I would love for Mapbox to add support for fallback values in the \"identity\" function when a value does not exist. For now, I'm just fill with default values in DB but it's definitely ugly.\n. More progress,\n\nDecided against rendering the materials as that would get extremely complicated and may not look very good with the limited pattern fill capabilities\n. @lukasmartinelli\nFor all, see the enhancement/add_height branch. It's got all the current progress for this.\nI'm waiting on https://github.com/mapbox/mapbox-gl-style-spec/issues/480 to see how default fall-back styles will be handled for the identity function.\nFeel free to rip these out and put them into the open tm2source and associated import workflow.\n. Integrated with OpenMapTiles....\nhttps://openmaptiles.github.io/klokantech-3d-gl-style/#14.47/40.7086/-74.0049/16/56. @nicooprat The 3D is formed by straight extrusion in the z-direction with no complex roof shapes or diagonals in the z-direction possible. So all building/building:parts are rectangular!\nWithout any further awesomeness in Mapbox-gl-js, this is as far as we can go.. @klokan Hmmm, I wonder if it's an issue with units/stories/feet in the base feature of OSM that caused that as I've seen nothing elsewhere (especially over NY) to suggest there's a widespread issue. I have seen some super impossibly tall towers in Mumbai, suggesting it's an issue with how imposm3 imports/converts it.\nI will dig into this! https://github.com/openmaptiles/openmaptiles/issues/128. Cool, thanks for the link to serialtiles. @klokan Is the work on github?\n. Oh cool, I figured out how to get tilelive-copy to serialize the mbtiles. So this should be easy to adapt the export-worker to send out the stream. You probably know this, but to do so, just leave off the destination for tilelive-copy and it will stream it.\n. There are no pngs... the mbtiles are vector tiles. See \"format\": \"pbf\".. What do you mean corrupted?\nThe stored tiles are actually gzipped in the the mbtiles. You will have to extract each before you can decode it with some pbf library.. Lookup gzip, there's plenty of ways to do so in just about any language.\nBe aware of legal issues with deploying OSM2VectorTiles tiles #387. I don't know the exact rationale but I think it goes along these lines:\n1) Spatial operations are expensive, it's usually cheaper to load features that intersect the tile than to clip them. Sure for line segments it doesn't seem so bad. But, consider complicated coastlines with 100s of vertices. Clipping is slow and has a risk of generating bad geometries. Sending the entire feature is safer, and although larger, is should be faster.\n2) Drawing is cleaner as you don't have sharp cuts that follow exactly on tile extents.. You could always reverse proxy: https://www.digitalocean.com/community/tutorials/how-to-use-apache-http-server-as-reverse-proxy-using-mod_proxy-extension. That's very curious, are you only seeing that with your own mbtiles or is that visible on osm2vectortiles.org?\nThis repo is superceded by https://github.com/openmaptiles/openmaptiles due to https://github.com/osm2vectortiles/osm2vectortiles/issues/387 but I'm curious about this as it may popup elsewhere.. Looks good, I like this!\n. :+1:  Glad this is exposed in docker-compose.yml for tweaking\n. ",
    "stephan75": "See the OSM wiki about http://wiki.openstreetmap.org/wiki/Search_engines\nas a collection of all geocoders working with OSM data.\nI have no clue about offline features, but generally don't forget about Photon by komoot.de ... mentioned there.\n. Hi, I am watching your everyday work and efforts about this project via github watchlist ... Thanks a lot!\nWill there be any announcement or blog posting when version 2 is \"really\" released?\nMaybe then can then report about it in\nhttp://wiki.openstreetmap.org/wiki/Wochennotiz and \nhttp://wiki.openstreetmap.org/wiki/WeeklyOSM\nif you want?\n. Finding better word than those from Mickael is hard,\nI also tried to express my appreciation for all your work, see https://github.com/osm2vectortiles/osm2vectortiles/issues/327#issuecomment-221549370\nSo what do you think about an announcement in any form you like and want about release progress?\nOr are things still to early?\n. > You can also try to filter it from the http://OSMNames.org/ data.\n@klokan \nWhat about adding that database source the the OSM wiki at Search Engines?\n. ",
    "yohanboniface": "\nWell - tiles are not requested on zoom level 18 - as metadata tells maxzoom 14.\n\nAh, oops, missed that, thanks. A 404 will be clearer though, indeed :)\nI'll let you close or not the issue given that you assigned a task.\nThanks for your answer :)\n. ",
    "nitinlkoin1984": "I am having the same issue. Can you elaborate how this issue was resolved.\n. I am using windows 7. The problem I am facing is that docker virtual folder is not being mapped to a physical folder. I did place the .pbf file in ./import folder at the root.\n. I am doing is that way. Opening Kitematic and mapping the folders to physical folders. At the end of the process I get a very small file. For example the houston extract on your website is 55mb. My houston extract following the process outlined is 155 kb\n. I got it to work. I created an Austin extract which was 25mb. I think the problem is with the folder and volumes permissions on windows. I had to \"enable volume\" in Kitematic for export image.\nEverything is working now. Thanks for your help. These tools are amazing and much quicker and easier to deploy then other solutions. \n. ",
    "beikehanbao23": "maybe u have me the  permission of the folder\nor the SE of linux  \njust rum cmd:         setenforce 0. ",
    "vitaly-t": "GitHub search engine can show you the most recent usage of your library, provided that its name is unique enough.\nYou are welcome!\n. The code could be improved further, by replacing this code:\njs\n return result.max;\n                })\n                .then(function (timestamp) {\nwith this one:\njs\nvar timestamp = result.max;\ni..e there is no need for an extra .then there ;)\n. Throwing another one back at ya ;) \nhttps://github.com/osm2vectortiles/osm2vectortiles/pull/143\n. @manuelroth I can see you reversed most of the changes there, and for the worse, because now it again tries to allocate a virtual connection for every single request, instead of doing it once, inside a task.\nSee this post: Tasks versus root/direct queries\n. ",
    "brewin": "Washington, DC also. The nearby city of Alexandria, VA shows up instead.\nWashington, DC population: 658,893\nAlexandria, VA population: 148,892\n. ",
    "pnorman": "\nOne thing mentioned in a checkbox but not illustrated yet: I think landuse=residential is important (even if Mapbox doesn't seem to agree).\n\nat z8 what you generally want is built up place polygons, not landuse=residential. Re: https://github.com/osm2vectortiles/osm2vectortiles/issues/387#issuecomment-237739891\n\nMapbox's toolset is based around that data stored in an MBTiles database\n\nI'd say that mbtiles is just a storage container which MB uses - they store more in S3.\n\nThe big thing here is that OSM2VectorTiles has cloned (presumably through inference and reverse engineering, not actual direct copying) how Mapbox generates those layers from the OSM data. For instance, this is how they query the OSM data (stored in an interim PostgreSQL PostGIS database) for the roads layer.\n\nIt's better to say that osm2vectortiles has developed a process which results in approximately the same schema. The technical details of how they do that are substantially different. [1]\nI don't think MB is claiming that there is a copyright violation in any of the code in this repository, but that the vector tiles that result from running the code violate Mapbox's IP. @michaelsteffen, can you confirm? If I am incorrect and MB believes there is a copyright violation in the code, can you provide reference to some copied lines. Also, are you claiming that the IP is copyright over the tile schema, database rights, trade secrets, or something else?\n[1]: https://github.com/osm2vectortiles/osm2vectortiles/issues/387#issuecomment-235922149 is a good summary of it, and the current MB streets vector tile generation uses closed source components like DynamoDB, which osm2vectortiles doesn't.\n\nRe https://github.com/osm2vectortiles/osm2vectortiles/issues/387#issuecomment-237813141\n\nNow this project and others like Wikimedia Maps (https://github.com/kartotherian/osm-bright.tm2source) has taken the hard work of producing a HTML document which is compatible with Mapbox's CSS styles\n\nTwo other projects which have created partially compatible schemas are https://github.com/ClearTables/mbs-compatible.tm2source and a tilemaker transform, which RichardF has removed.\n. > For example, https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-external/seas.geojson appears largely copied from Mapbox Streets, including the choice of point vs. line features, the placement of label arcs, etc. Take a look at the file in geojson.io.\nFor the record, this file was introduced in 3b1b4f9c13d684f432ae2ff0d73ade3ec39d0984 by @lukasmartinelli and may be based on an earlier marine.sql file in 6531e887a1828b0106787508796f1f84d2c6dabb.\nAre you claiming that the seas.geojson file is a derivative work of Mapbox Streets and is a copyright violation? Or if not copyright, a database rights violation?\nTo me looking at the file on geojson.io shows that the origin of the file is different than mapbox streets, and they have selected different features to label. Looking through the code history, seas.geojson seems to come from Natural Earth's ne_10m_geography_marine_polys and OSM data[1]. You can see this heritage in seas like Flores Sea, which is in as Laut Flores on MB Streets and Flores Sea (en)/Floressee (de) in OSM.\n@michaelsteffen, I believe you missed this question:\n\nAlso, are you claiming that the IP is copyright over the tile schema, database rights, trade secrets, or something else?\n\n[1]: https://github.com/osm2vectortiles/osm2vectortiles/commit/2c08b6d4aaee542989b70f57ef3f7f1360f2ff9f#diff-de2ee30f49dce057f96d01693fce4e8f among other sources show that NE data was combined with OSM data, matching on case-insensitive name and distance.\n\n\n\nI am not a lawyer, but it sounds to me like it is not clear if Mapbox is allowed to make such claims on the vector tiles, as to me they look to fall under derivative databse\n\nThe Mapbox Streets tiles are cartographic tiles developed and optimized for visual display, not a database. \n\nIf MB Streets vector tiles are a produced work the ODbL still requires that you offer the derivative database or an alteration file (ODbL 4.6)\n. With no details or reply in over a month, is it worth keeping this ticket open?\n. > Hey @pnorman - Let's leave this open for now. Looking forward to some good conversations at SOTM to move the ball forward.\nWithout any updates or preliminary discussions, this isn't on my agenda for SOTM.\n. > However we have been asked to start from scratch again instead of removing code. This approach doesn\u2019t bring any benefits for us and if we have to start from scratch we want to work on a cartography that has nothing to do with Mapbox to avoid future claims.\nGiven we're avoiding stuff we don't have to (e.g. openly licensed styles from MapBox) because of the legal chill, should we completely move away from MapBox GL?\n. Why the removal of the layers? Will those features be in a different layer?\n. > For example #airport_label is still very important but fits into the #poi_layer just as well (in fact half a year back we had it like that). And #rail_station_label is too limiting, the default imposm3 mapping for example contains a #transport_poi_label which would contain all transport POI for special styling (i like that idea).\nThe diff doesn't show plans to add airports to the #poi_layer. Can you add these details so we can evaluate the changes?\n\n#mountain_peak could move back into POI or we start thinking about a landmark layer (there are other special landmarks not only mountain peaks). No longer so sure about this one.\n\nfwiw, in ClearTables I have a landform_point table which has natural=peak and similar tags\n. The linestrings in seas.geojson are different from MB Streets\n. Repeating an an analysis from https://github.com/osm2vectortiles/osm2vectortiles/issues/387#issuecomment-238060253...\nseas.geojson was introduced in 3b1b4f9 by @lukasmartinelli and may be based on an earlier marine.sql file in 6531e88. The contents of this file appear to be OSM-derived, and there used to be code which used OSM data for marine labels.\n. seas.geojson being osm-derived and ODbL, its license needs to be stated somewhere. I recommend putting a file in src/import-external stating the license and source of all the files there.\n. > Don't you think that is already covered within Data Downloads? In the README\n\n\nThe project is under the MIT license while the data downloads use the Open Database License from OpenStreetMap.\n\n\nLegally? Maybe. It's not clear that a file in the repo is a data download. If all the stuff in import-external is a data download, the text is wrong since Natural Earth is used.\nThe reason I'd like to see it stated there is it is\n1. Makes it clear what is from where\n2. Documents the source and how the files were created\nThat seas.geojson is OpenStreetMap ocean and sea nodes with hand-drawn lines for some labels is useful information if you ever want to modify the file or track down a bug.\n. If you have a container-based infrastructure and sufficient capacity I'd just import a new database every 6 months.\n. > My next major focus is proper road stacking, which is non-trivial (and in fact not even Mapbox itself gets 100% correct at times esp. on tunnels).\nAbandon all hope before looking at the roads code ;) The roads MSS is about 40% of osm-carto, and a significant portion of the SQL. It tries to get everything right, more so than any other style out there. There are a grand total of approximately zero people who fully understand it.\nI would add that I think the osm-carto queries are badly suited for server-side vector tile rendering and worse for client-side vector tile rendering, but if you can get it working well I applaud your work.\n. > So as rule of thumb - as long as you can get away with SQL don't resort the pgsql\nAs a general rule, use SQL when possible, not just for execution cost, but you tend to write in a way better suited for SQL. There are exceptions to this when a plpgsql function that consists only of a single SQL statement is faster.\nFor function calling costs, c < plpgsql < other languages\n. ",
    "ratrun": "Thank you for your great project! If took me quite a while to locate this.\nAs a consequence of the \"wontfix\" decision the style at \nhttps://github.com/osm2vectortiles/mapbox-gl-styles/blob/master/styles/bright-v9-cdn.json\nshould be better changed and the following part removed:\n{\n            \"id\": \"water_offset\",\n            \"paint\": {\n                \"fill-color\": \"white\",\n                \"fill-opacity\": 0.3,\n                \"fill-translate\": [\n                    0,\n                    2.5\n                ]\n            },\n            \"metadata\": {\n                \"mapbox:group\": \"1444849382550.77\"\n            },\n            \"interactive\": true,\n            \"ref\": \"water\"\n        },\n        {\n            \"id\": \"water_pattern\",\n            \"paint\": {\n                \"fill-translate\": [\n                    0,\n                    2.5\n                ],\n                \"fill-pattern\": \"wave\"\n            },\n            \"metadata\": {\n                \"mapbox:group\": \"1444849382550.77\"\n            },\n            \"interactive\": true,\n            \"ref\": \"water\"\n        }\nThis would prevent others from having the same problem with visible water tile edges.\n. @michaelsteffen: Please explain and correct me. \nAs far as I understand the first provided link https://www.mapbox.com/about/maps/ is not relevant for the osm2vectortiles project at all as this describes the terms of service for various data provided by Mapbox only. I do not see any relevance for data provided by other parties.\nThe second provided link https://www.mapbox.com/tos/#%5BYmaMYmns%5D describes the terms for accessing Mapbox services and therefore I again do not see any relevance for the osm2vectortiles project. \nhttps://www.mapbox.com/vector-tiles/mapbox-streets-v7/ does not show up any terms of usage and therefore I really do not see the legal statements which would encourage your arguments.\n. ",
    "mr": "Thank you! Is there any documentation on how to serve with tileserver-gl instead of the normal tileserver?\n. Ok, I will keep an eye out for that while I try to get tileserver-gl to work.\nOh, also all of my tiles render as completely black when i go to the test page from docker-compose run serve. Do you know if this is a problem with the mbtiles export or something with tileserver-mapnik? The other docker commands didn't throw errors.\n. No I mean it is entirely black. I thought it was a problem with the viewer,\nbut when I download /0/0/0.png the file is a 100% black square. Same for\nzooming in or panning.\nOn Mon, May 2, 2016, 4:32 PM Manuel Roth notifications@github.com wrote:\n\nYou mean black like the following?\n[image: bildschirmfoto 2016-05-02 um 22 26 49]\nhttps://cloud.githubusercontent.com/assets/1810384/14966924/00a0cabe-10b5-11e6-9b5b-e96f1773f63a.png\nFor the data to be styled you need to download a style project and add it\nto the export folder.\n1. git clone https://github.com/mapbox/mapbox-studio-osm-bright.tm2.git\n2. Now run docker-compose up serve again and you should see your map with\nthe bright style\n[image: bildschirmfoto 2016-05-02 um 22 32 23]\nhttps://cloud.githubusercontent.com/assets/1810384/14967065/c9773662-10b5-11e6-8c28-def439560b81.png\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/309#issuecomment-216354469\n. I will gladly give feedback on new documentation. I'm very interested in getting this to work, so I'll be reading as much as I can. Is there a repo associated with the web documentation? If I ever manage to get tileserver-gl working I'd be willing to contribute.\n\nI've changed MIN_ZOOM to 0, yet I'm still getting only black tiles. I've followed all the other instructions and they haven't thrown any errors. I also have not done the optional merging of lower zoom levels.\n. I've tried zooming in and I can see in the docker-compose up serve output returning 200 for higher zoom levels, but I don't think that's where the extract is. I'm using the extract at https://s3.amazonaws.com/metro-extracts.mapzen.com/zurich_switzerland.osm.pbf, so I think the bbox for the default export is correct. Is there a way to have the server center on that bbox and zoom higher by default?\nAlso if I set MIN_ZOOM to 0, shouldn't I get at least one tile at z0 or z1 no matter where the extract is located? It should also be pretty obvious because of the external imports of water, labels, natural earth, etc.\n. \n10/536/358.png looks like this, so apparently it is rendering something. Is there an way I can easily zoom one of the maps to this area?\n. Thanks, looks like everything is generating correctly. If I ever manage to figure it out, I'll try to write a serve-gl, or something like that for tileserver-gl.\n. Putting a space before the BBOX throws a different \"relation does not exist\" error:\n```\nmattro@Matts-Mac-mini ~/workspace/osm2vectortiles [master]\n\u00b1 % docker-compose run -e BBOX=\" -75.7177734375,38.8600282742,-73.8803100586,41.4787468887\" -e MIN_ZOOM=\"0\" -e MAX_ZOOM=\"14\" export\nWARNING: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\nWARNING: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\nWARNING: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\n/usr/local/lib/node_modules/tilelive/bin/tilelive-copy:100\n        if (err) throw err;\n                 ^\nError: Postgis Plugin: ERROR:  relation \"admin_z1toz2\" does not exist\nLINE 9:     FROM admin_z1toz2\n                 ^\nin executeQuery Full sql was: 'SELECT * FROM (\n  SELECT osm_ids2mbid(osm_id, false) AS osm_id, geometry, admin_level, disputed, maritime\n  FROM (\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z0\n    WHERE z(3.40282e+38) = 0\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z1toz2\n    WHERE z(3.40282e+38) BETWEEN 1 AND 2\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z3\n    WHERE z(3.40282e+38) = 3\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z4toz5\n    WHERE z(3.40282e+38) BETWEEN 4 AND 5\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z6\n    WHERE z(3.40282e+38) = 6\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z7toz14\n    WHERE z(3.40282e+38) BETWEEN 7 AND 14\n  ) AS admin\n  WHERE geometry && ST_SetSRID('BOX3D(-3.402823466385289e+38 -3.402823466385289e+38,3.402823466385289e+38 3.402823466385289e+38)'::box3d, 3857)\n) AS data LIMIT 0'\nat Error (native)\nat /usr/local/lib/node_modules/tilelive-tmsource/index.js:111:18\nat Array.map (native)\nat normalize (/usr/local/lib/node_modules/tilelive-tmsource/index.js:100:35)\nat /usr/local/lib/node_modules/tilelive-tmsource/index.js:185:19\nat tryToString (fs.js:414:3)\nat FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:401:12)\n\n``\n. Problem is persisting, here is a script of me attempting to do everything from the beginning. I removed all containers withdocker-compose rm -f -v` and recloned the repo. I also killed everything in kitematic.\nThe script has some color information, but it's still readable.\n```\nScript started on Tue Oct 18 10:39:09 2016\n\u001b[?25h\u001b[0G\u001b[K\u001b[?25h\u001b[0G\u001b[K\u001b[1m\u001b[3m%\u001b[23m\u001b[1m\u001b[0m                                                                                                                                                                                                                                                                               \n\u001bk..m2vectortiles\u001b\\\n\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[262C!\u001b[1m\u001b[36m8750\u001b[39m\u001b[49m\u001b[0m\u001b[267D\n\u001bM\u001bM\u001b[?2004h\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\u001b[3mdocker-compose up -d postgis\u001b[23m\u001b[28D\u001b[23md\u001b[23mo\u001b[23mc\u001b[23mk\u001b[23me\u001b[23mr\u001b[23m-\u001b[23mc\u001b[23mo\u001b[23mm\u001b[23mp\u001b[23mo\u001b[23ms\u001b[23me\u001b[23m \u001b[23mu\u001b[23mp\u001b[23m \u001b[23m-\u001b[23md\u001b[23m \u001b[23mp\u001b[23mo\u001b[23ms\u001b[23mt\u001b[23mg\u001b[23mi\u001b[23ms\u001b[?1l\u001b>\u001b[?2004l\n\u001bkdocker-compose\u001b\\\u001b[33mWARNING\u001b[0m: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nCreating osm2vectortiles_pgdata_1\nCreating osm2vectortiles_postgis_1\n\u001b[1m\u001b[3m%\u001b[23m\u001b[1m\u001b[0m                                                                                                                                                                                                                                                                               \n\u001bk..m2vectortiles\u001b\\\n\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\n\u001bM\u001bM\u001b[?2004h\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\u001b[3mdocker-compose up import-external\u001b[23m\u001b[33D\u001b[23md\u001b[23mo\u001b[23mc\u001b[23mk\u001b[23me\u001b[23mr\u001b[23m-\u001b[23mc\u001b[23mo\u001b[23mm\u001b[23mp\u001b[23mo\u001b[23ms\u001b[23me\u001b[23m \u001b[23mu\u001b[23mp\u001b[23m \u001b[23mi\u001b[23mm\u001b[23mp\u001b[23mo\u001b[23mr\u001b[23mt\u001b[23m-\u001b[23me\u001b[23mx\u001b[23mt\u001b[23me\u001b[23mr\u001b[23mn\u001b[23ma\u001b[23ml\u001b[?1l\u001b>\u001b[?2004l\n\u001bkdocker-compose\u001b\\\u001b[33mWARNING\u001b[0m: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\nosm2vectortiles_postgis_1 is up-to-date\nCreating osm2vectortiles_import-external_1\nAttaching to osm2vectortiles_import-external_1\n\u001b[36mimport-external_1       |\u001b[0m Importing Natural Earth to PostGIS\n\u001b[36mimport-external_1       |\u001b[0m 0...10...20...30...40...50...60...70...80...90...100 - done.\n\u001b[36mimport-external_1       |\u001b[0m NOTICE:  table \"osm_ocean_polygon\" does not exist, skipping\n\u001b[36mimport-external_1       |\u001b[0m DROP TABLE\n\u001b[36mimport-external_1       |\u001b[0m Shapefile type: Polygon\n\u001b[36mimport-external_1       |\u001b[0m Postgis type: MULTIPOLYGON[2]\n\u001b[36mimport-external_1       |\u001b[0m SET\n\u001b[36mimport-external_1       |\u001b[0m SET\n\u001b[36mimport-external_1       |\u001b[0m BEGIN\n\u001b[36mimport-external_1       |\u001b[0m CREATE TABLE\n\u001b[36mimport-external_1       |\u001b[0m ALTER TABLE\n\u001b[36mimport-external_1       |\u001b[0m                            addgeometrycolumn                         \n\u001b[36mimport-external_1       |\u001b[0m -----------------------------------------------------------------------\n\u001b[36mimport-external_1       |\u001b[0m  public.osm_ocean_polygon.geometry SRID:3857 TYPE:MULTIPOLYGON DIMS:2 \n\u001b[36mimport-external_1       |\u001b[0m (1 row)\n\u001b[36mimport-external_1       |\u001b[0m \n\u001b[36mimport-external_1       |\u001b[0m CREATE INDEX\n\u001b[36mimport-external_1       |\u001b[0m COMMIT\n\u001b[36mimport-external_1       |\u001b[0m ANALYZE\n\u001b[36mimport-external_1       |\u001b[0m NOTICE:  table \"osm_ocean_polygon_gen0\" does not exist, skipping\n\u001b[36mimport-external_1       |\u001b[0m DROP TABLE\n\u001b[36mimport-external_1       |\u001b[0m Shapefile type: Polygon\n\u001b[36mimport-external_1       |\u001b[0m Postgis type: MULTIPOLYGON[2]\n\u001b[36mimport-external_1       |\u001b[0m SET\n\u001b[36mimport-external_1       |\u001b[0m SET\n\u001b[36mimport-external_1       |\u001b[0m BEGIN\n\u001b[36mimport-external_1       |\u001b[0m CREATE TABLE\n\u001b[36mimport-external_1       |\u001b[0m ALTER TABLE\n\u001b[36mimport-external_1       |\u001b[0m                              addgeometrycolumn                            \n\u001b[36mimport-external_1       |\u001b[0m ----------------------------------------------------------------------------\n\u001b[36mimport-external_1       |\u001b[0m  public.osm_ocean_polygon_gen0.geometry SRID:3857 TYPE:MULTIPOLYGON DIMS:2 \n\u001b[36mimport-external_1       |\u001b[0m (1 row)\n\u001b[36mimport-external_1       |\u001b[0m \n\u001b[36mimport-external_1       |\u001b[0m CREATE INDEX\n\u001b[36mimport-external_1       |\u001b[0m COMMIT\n\u001b[36mimport-external_1       |\u001b[0m ANALYZE\n\u001b[36mimport-external_1       |\u001b[0m Inserting labels into osm\n\u001b[36mimport-external_1       |\u001b[0m NOTICE:  table \"custom_seas\" does not exist, skipping\n\u001b[36mimport-external_1       |\u001b[0m DROP TABLE\n\u001b[36mimport-external_1       |\u001b[0m seas.geojson\n\u001b[36mimport-external_1       |\u001b[0m NOTICE:  table \"custom_states\" does not exist, skipping\n\u001b[36mimport-external_1       |\u001b[0m DROP TABLE\n\u001b[36mimport-external_1       |\u001b[0m states.geojson\n\u001b[36mimport-external_1       |\u001b[0m NOTICE:  table \"custom_countries\" does not exist, skipping\n\u001b[36mimport-external_1       |\u001b[0m DROP TABLE\n\u001b[36mimport-external_1       |\u001b[0m countries.geojson\n\u001b[36mosm2vectortiles_import-external_1 exited with code 0\n\u001b[0m\u001b[1m\u001b[3m%\u001b[23m\u001b[1m\u001b[0m                                                                                                                                                                                                                                                                               \n\u001bk..m2vectortiles\u001b\\\n\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\n\u001bM\u001bM\u001b[?2004h\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\u001b[3mdocker-compose up import-osm\u001b[23m\u001b[28D\u001b[23md\u001b[23mo\u001b[23mc\u001b[23mk\u001b[23me\u001b[23mr\u001b[23m-\u001b[23mc\u001b[23mo\u001b[23mm\u001b[23mp\u001b[23mo\u001b[23ms\u001b[23me\u001b[23m \u001b[23mu\u001b[23mp\u001b[23m \u001b[23mi\u001b[23mm\u001b[23mp\u001b[23mo\u001b[23mr\u001b[23mt\u001b[23m-\u001b[23mo\u001b[23ms\u001b[23mm\u001b[?1l\u001b>\u001b[?2004l\n\u001bkdocker-compose\u001b\\\u001b[33mWARNING\u001b[0m: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\nCreating osm2vectortiles_cache_1\nosm2vectortiles_postgis_1 is up-to-date\nCreating osm2vectortiles_import-osm_1\nAttaching to osm2vectortiles_import-osm_1\n\u001b[36mimport-osm_1            |\u001b[0m ERROR:  function drop_tables() does not exist\n\u001b[36mimport-osm_1            |\u001b[0m LINE 1: SELECT drop_tables()\n\u001b[36mimport-osm_1            |\u001b[0m                ^\n\u001b[36mimport-osm_1            |\u001b[0m HINT:  No function matches the given name and argument types. You might need to add explicit type casts.\n\u001b[36mimport-osm_1            |\u001b[0m NOTICE:  table \"osm_timestamps\" does not exist, skipping\n\u001b[36mimport-osm_1            |\u001b[0m DROP TABLE\n\u001b[36mimport-osm_1            |\u001b[0m CREATE TABLE\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:41:40] Imposm\n[Oct 18 14:41:40] Reading OSM data\n\u001b[2K[Oct 18 14:41:40] [INFO] [reader] reading /data/import/zurich_switzerland.osm.pbf with data till 2016-10-17 15:04:02 +0000 UTC\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:41:40] Reading OSM data\n[Oct 18 14:41:40] [     0] C:       0/s       0/s (0) N:       0/s       0/s (0) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:41] [    1s] C:       0/s       0/s (0) N:       0/s       0/s (0) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:41] [    1s] C:       0/s       0/s (0) N:       0/s       0/s (0) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:42] [    2s] C:       0/s       0/s (0) N:       0/s       0/s (0) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:42] [    2s] C:       0/s       0/s (0) N:       0/s       0/s (0) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:43] [    3s] C:       0/s       0/s (0) N:       0/s       0/s (0) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:43] [    3s] C:       0/s       0/s (0) N:       0/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:44] [    4s] C:       0/s       0/s (0) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:44] [    4s] C:       0/s       0/s (0) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:45] [    5s] C:       0/s       0/s (0) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:45] [    5s] C:       0/s       0/s (2136403) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:46] [    6s] C: 10532000/s 1988000/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:46] [    6s] C: 5091000/s       0/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:47] [    7s] C: 5091000/s       0/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:47] [    7s] C: 5091000/s       0/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:48] [    8s] C: 5091000/s       0/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:48] [    8s] C: 5091000/s       0/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:49] [    9s] C: 5091000/s       0/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n[Oct 18 14:41:49] [    9s] C: 5091000/s       0/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n\u001b[2K[Oct 18 14:41:49] [INFO] [    9s] C: 5091000/s (2676133) N:  108100/s (47550) W:       0/s (425957) R:      0/s (1602)\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:41:49] [    9s] C: 5091000/s       0/s (2676133) N:  108100/s       0/s (47550) W:       0/s       0/s (0) R:      0/s      0/s (0)\n\u001b[2K[Oct 18 14:41:50] [INFO] Reading OSM data took: 9.853784831s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:41:50] Importing OSM data\n[Oct 18 14:41:50] Writing OSM data\n[Oct 18 14:41:50] [     0] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:       0/s       0/s ( 0.0%) R:      0/s      0/s ( 0.0%)\n[Oct 18 14:41:51] [    1s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:       0/s       0/s ( 0.0%) R:      0/s      0/s ( 0.0%)\n[Oct 18 14:41:51] [    1s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:       0/s       0/s ( 0.0%) R:      0/s      0/s ( 0.0%)\n[Oct 18 14:41:52] [    2s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:       0/s       0/s ( 0.0%) R:      0/s      0/s ( 4.3%)\n[Oct 18 14:41:52] [    2s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:       0/s       0/s ( 0.0%) R:   2540/s   1190/s (42.8%)\n[Oct 18 14:41:53] [    3s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:       0/s       0/s ( 0.0%) R:   1390/s    830/s (68.0%)\n[Oct 18 14:41:53] [    3s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:       0/s       0/s ( 0.0%) R:   1180/s    820/s (93.9%)\n[Oct 18 14:41:54] [    4s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:       0/s       0/s ( 0.7%) R:    900/s    180/s (100.0%)\n[Oct 18 14:41:54] [    4s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:   15800/s    6500/s ( 1.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:55] [    5s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:   10800/s    6500/s ( 2.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:55] [    5s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    9300/s    7700/s ( 3.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:56] [    6s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    8900/s    7200/s ( 3.9%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:56] [    6s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    8600/s    7100/s ( 4.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:57] [    7s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    8400/s    7800/s ( 5.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:57] [    7s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    8200/s    6000/s ( 6.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:58] [    8s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    8000/s    7600/s ( 7.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:58] [    8s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7700/s    6000/s ( 8.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:59] [    9s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    5400/s ( 8.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:41:59] [    9s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7600/s    7100/s ( 9.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:00] [   10s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    6500/s (10.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:00] [   10s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    7000/s (11.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:01] [   11s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    7000/s (12.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:01] [   11s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    6500/s (12.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:02] [   12s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    7600/s (13.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:02] [   12s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    7800/s (14.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:03] [   13s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    7500/s (15.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:03] [   13s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    6900/s (16.2%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:04] [   14s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    7100/s (17.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:04] [   14s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    5600/s (17.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:05] [   15s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    3100/s (18.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:05] [   15s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    5000/s (18.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:06] [   16s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6900/s    5200/s (19.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:06] [   16s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6700/s    3500/s (19.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:07] [   17s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6600/s    3700/s (20.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:07] [   17s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6700/s    7300/s (21.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:08] [   18s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6600/s    7000/s (21.9%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:08] [   18s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6700/s    7900/s (22.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:09] [   19s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6800/s    9000/s (23.9%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:09] [   19s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6800/s    7800/s (24.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:10] [   20s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6900/s    7900/s (25.9%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:10] [   20s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6900/s    8800/s (26.9%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:11] [   21s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    6900/s    7300/s (27.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:11] [   21s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    8700/s (28.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:12] [   22s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    8500/s (29.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:12] [   22s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    7500/s (30.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:13] [   23s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    8200/s (31.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:13] [   23s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    8100/s (32.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:14] [   24s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    6700/s (33.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:14] [   24s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    8400/s (34.2%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:15] [   25s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    4700/s (34.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:15] [   25s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    6300/s (35.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:16] [   26s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    7900/s (36.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:16] [   26s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    7300/s (37.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:17] [   27s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s   11000/s (38.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:17] [   27s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    7600/s (39.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:18] [   28s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    8700/s (40.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:18] [   28s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    5900/s (41.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:19] [   29s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    6200/s (42.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:19] [   29s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    6000/s (42.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:20] [   30s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    4900/s (43.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:20] [   30s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    6500/s (44.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:21] [   31s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    6400/s (44.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:21] [   31s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    4600/s (45.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:22] [   32s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    7900/s (46.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:22] [   32s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    7400/s (47.2%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:23] [   33s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7000/s    7500/s (48.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:23] [   33s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    8100/s (49.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:24] [   34s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    7300/s (49.9%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:24] [   34s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    9200/s (51.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:25] [   35s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    7100/s (51.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:25] [   35s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    8700/s (52.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:26] [   36s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    6800/s (53.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:26] [   36s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    8900/s (54.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:27] [   37s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7100/s    6600/s (55.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:27] [   37s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    8900/s (56.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:28] [   38s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    6700/s (57.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:28] [   38s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    9100/s (58.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:29] [   39s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    8000/s (59.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:29] [   39s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    8700/s (60.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:30] [   40s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    9600/s (61.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:30] [   40s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    6600/s (62.2%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:31] [   41s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    9000/s (63.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:31] [   41s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    5600/s (64.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:32] [   42s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    7800/s (64.9%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:32] [   42s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    6500/s (65.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:33] [   43s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    5600/s (66.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:33] [   43s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    6300/s (67.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:34] [   44s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    7000/s (67.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:34] [   44s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    4100/s (68.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:35] [   45s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    8800/s (69.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:35] [   45s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    8700/s (70.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:36] [   46s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    7900/s (71.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:36] [   46s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    9800/s (72.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:37] [   47s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7200/s    8900/s (73.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:37] [   47s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    7600/s (74.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:38] [   48s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    8800/s (75.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:38] [   48s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    8500/s (76.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:39] [   49s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    8700/s (77.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:39] [   49s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    7900/s (78.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:40] [   50s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    9300/s (79.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:40] [   50s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7300/s    7400/s (80.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:41] [   51s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    9900/s (81.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:41] [   51s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    8000/s (82.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:42] [   52s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    8500/s (83.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:42] [   52s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    9400/s (84.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:43] [   53s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    7600/s (85.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:43] [   53s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    8500/s (86.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:44] [   54s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    8200/s (87.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:44] [   54s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7400/s    9500/s (88.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:45] [   55s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    8300/s (89.8%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:45] [   55s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    9000/s (90.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:46] [   56s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    8100/s (91.6%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:46] [   56s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    6100/s (92.4%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:47] [   57s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    7200/s (93.2%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:47] [   57s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    7100/s (94.2%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:48] [   58s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    9000/s (95.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:48] [   58s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s   10000/s (96.3%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:49] [   59s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    6600/s (97.1%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:49] [   59s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    5700/s (97.7%) R:    700/s      0/s (100.0%)\n\u001b[2K[Oct 18 14:42:50] [INFO] [  1m0s] C:       0/s ( 0.0%) N:       0/s ( 0.0%) W:    7500/s (98.5%) R:    700/s (100.0%)\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:50] [   59s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    5700/s (97.7%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:50] [  1m0s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    5900/s (98.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:50] [  1m0s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s ( 0.0%) W:    7500/s    9300/s (99.5%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:51] [  1m1s] C:       0/s       0/s ( 0.0%) N:       0/s       0/s (19.7%) W:    7400/s    4200/s (100.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:51] [  1m1s] C:       0/s       0/s ( 0.0%) N:   94100/s   33100/s (54.7%) W:    7400/s       0/s (100.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:52] [  1m2s] C:       0/s       0/s ( 0.0%) N:   55700/s   34300/s (91.4%) W:    7400/s       0/s (100.0%) R:    700/s      0/s (100.0%)\n[Oct 18 14:42:52] [  1m2s] C:       0/s       0/s ( 0.0%) N:   36900/s    8300/s (100.0%) W:    7400/s       0/s (100.0%) R:    700/s      0/s (100.0%)\n\u001b[2K[Oct 18 14:42:52] [INFO] [  1m2s] C:       0/s ( 0.0%) N:   26700/s (100.0%) W:    7400/s (100.0%) R:    700/s (100.0%)\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:52] [  1m2s] C:       0/s       0/s ( 0.0%) N:   36900/s    8300/s (100.0%) W:    7400/s       0/s (100.0%) R:    700/s      0/s (100.0%)\n\u001b[2K[Oct 18 14:42:53] [INFO] Writing OSM data took: 1m2.922193064s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:53] Creating generalized tables\n[Oct 18 14:42:53] Generalizing osm_building_polygon into osm_building_polygon_gen0\n\u001b[2K[Oct 18 14:42:54] [INFO] [PostGIS] Generalizing osm_building_polygon into osm_building_polygon_gen0 took: 947.363954ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:54] Generalizing osm_landuse_polygon into osm_landuse_polygon_gen1\n\u001b[2K[Oct 18 14:42:55] [INFO] [PostGIS] Generalizing osm_landuse_polygon into osm_landuse_polygon_gen1 took: 1.180676237s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:55] Generalizing osm_water_polygon into osm_water_polygon_gen1\n\u001b[2K[Oct 18 14:42:55] [INFO] [PostGIS] Generalizing osm_water_polygon into osm_water_polygon_gen1 took: 34.408877ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:55] Generalizing osm_landuse_polygon into osm_landuse_polygon_gen0\n\u001b[2K[Oct 18 14:42:55] [INFO] [PostGIS] Generalizing osm_landuse_polygon into osm_landuse_polygon_gen0 took: 175.567838ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:55] [INFO] [PostGIS] Creating generalized tables took: 2.345092027s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:55] Creating geometry indices\n[Oct 18 14:42:55] Creating OSM id index on osm_road_geometry\n\u001b[2K[Oct 18 14:42:55] [INFO] [PostGIS] Creating OSM id index on osm_road_geometry took: 137.956799ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:55] Creating geometry index on osm_road_geometry\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating geometry index on osm_road_geometry took: 1.362609851s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating OSM id index on osm_airport_point\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating OSM id index on osm_airport_point took: 6.609703ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating geometry index on osm_airport_point\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating geometry index on osm_airport_point took: 2.309786ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating OSM id index on osm_airport_polygon\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating OSM id index on osm_airport_polygon took: 3.457251ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating geometry index on osm_airport_polygon\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating geometry index on osm_airport_polygon took: 2.146879ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating OSM id index on osm_place_point\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating OSM id index on osm_place_point took: 4.61085ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating geometry index on osm_place_point\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating geometry index on osm_place_point took: 5.235082ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating OSM id index on osm_aero_linestring\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating OSM id index on osm_aero_linestring took: 3.486534ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating geometry index on osm_aero_linestring\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating geometry index on osm_aero_linestring took: 3.645439ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating OSM id index on osm_admin_linestring\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating OSM id index on osm_admin_linestring took: 4.298849ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating geometry index on osm_admin_linestring\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating geometry index on osm_admin_linestring took: 2.531376ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating OSM id index on osm_barrier_linestring\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating OSM id index on osm_barrier_linestring took: 9.757344ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating geometry index on osm_barrier_linestring\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating geometry index on osm_barrier_linestring took: 36.366848ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating OSM id index on osm_water_linestring\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating OSM id index on osm_water_linestring took: 16.594478ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating geometry index on osm_water_linestring\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating geometry index on osm_water_linestring took: 30.450013ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating OSM id index on osm_building_polygon\n\u001b[2K[Oct 18 14:42:57] [INFO] [PostGIS] Creating OSM id index on osm_building_polygon took: 197.35448ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:42:57] Creating geometry index on osm_building_polygon\n\u001b[2K[Oct 18 14:43:00] [INFO] [PostGIS] Creating geometry index on osm_building_polygon took: 3.236403556s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:00] Creating OSM id index on osm_poi_polygon\n\u001b[2K[Oct 18 14:43:00] [INFO] [PostGIS] Creating OSM id index on osm_poi_polygon took: 7.053337ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:00] Creating geometry index on osm_poi_polygon\n\u001b[2K[Oct 18 14:43:00] [INFO] [PostGIS] Creating geometry index on osm_poi_polygon took: 40.53999ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:00] Creating OSM id index on osm_housenumber_polygon\n\u001b[2K[Oct 18 14:43:00] [INFO] [PostGIS] Creating OSM id index on osm_housenumber_polygon took: 220.202063ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:00] Creating geometry index on osm_housenumber_polygon\n\u001b[2K[Oct 18 14:43:02] [INFO] [PostGIS] Creating geometry index on osm_housenumber_polygon took: 1.328166435s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:02] Creating OSM id index on osm_mountain_peak_point\n\u001b[2K[Oct 18 14:43:02] [INFO] [PostGIS] Creating OSM id index on osm_mountain_peak_point took: 5.193377ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:02] Creating geometry index on osm_mountain_peak_point\n\u001b[2K[Oct 18 14:43:02] [INFO] [PostGIS] Creating geometry index on osm_mountain_peak_point took: 1.345333ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:02] Creating OSM id index on osm_barrier_polygon\n\u001b[2K[Oct 18 14:43:02] [INFO] [PostGIS] Creating OSM id index on osm_barrier_polygon took: 2.888829ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:02] Creating geometry index on osm_barrier_polygon\n\u001b[2K[Oct 18 14:43:02] [INFO] [PostGIS] Creating geometry index on osm_barrier_polygon took: 2.292241ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:02] Creating OSM id index on osm_landuse_polygon\n\u001b[2K[Oct 18 14:43:02] [INFO] [PostGIS] Creating OSM id index on osm_landuse_polygon took: 402.364382ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:02] Creating geometry index on osm_landuse_polygon\n\u001b[2K[Oct 18 14:43:02] [INFO] [PostGIS] Creating geometry index on osm_landuse_polygon took: 206.919619ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:02] Creating OSM id index on osm_housenumber_point\n\u001b[2K[Oct 18 14:43:03] [INFO] [PostGIS] Creating OSM id index on osm_housenumber_point took: 860.071443ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:03] Creating geometry index on osm_housenumber_point\n\u001b[2K[Oct 18 14:43:03] [INFO] [PostGIS] Creating geometry index on osm_housenumber_point took: 207.230838ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:03] Creating OSM id index on osm_poi_point\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating OSM id index on osm_poi_point took: 645.062548ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating geometry index on osm_poi_point\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry index on osm_poi_point took: 98.879523ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating OSM id index on osm_rail_station_point\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating OSM id index on osm_rail_station_point took: 6.069876ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating geometry index on osm_rail_station_point\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry index on osm_rail_station_point took: 4.363591ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating OSM id index on osm_water_polygon\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating OSM id index on osm_water_polygon took: 3.750692ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating geometry index on osm_water_polygon\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry index on osm_water_polygon took: 7.007182ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating OSM id index on osm_aero_polygon\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating OSM id index on osm_aero_polygon took: 3.294649ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating geometry index on osm_aero_polygon\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry index on osm_aero_polygon took: 2.300971ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating OSM id index on osm_landuse_polygon_gen1\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating OSM id index on osm_landuse_polygon_gen1 took: 18.189682ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating geometry index on osm_landuse_polygon_gen1\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry index on osm_landuse_polygon_gen1 took: 49.536535ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating OSM id index on osm_water_polygon_gen1\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating OSM id index on osm_water_polygon_gen1 took: 8.65337ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating geometry index on osm_water_polygon_gen1\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry index on osm_water_polygon_gen1 took: 6.075896ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating OSM id index on osm_building_polygon_gen0\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating OSM id index on osm_building_polygon_gen0 took: 19.06478ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating geometry index on osm_building_polygon_gen0\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry index on osm_building_polygon_gen0 took: 57.547793ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating OSM id index on osm_landuse_polygon_gen0\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating OSM id index on osm_landuse_polygon_gen0 took: 7.068931ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Creating geometry index on osm_landuse_polygon_gen0\n\u001b[2K[Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry index on osm_landuse_polygon_gen0 took: 10.310828ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] [INFO] [PostGIS] Creating geometry indices took: 9.363039063s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] [INFO] Importing OSM data took: 1m14.636374647s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:04] Clustering on geometry\n[Oct 18 14:43:04] Indexing osm_housenumber_point on geohash\n\u001b[2K[Oct 18 14:43:05] [INFO] [PostGIS] Indexing osm_housenumber_point on geohash took: 266.488488ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:05] Clustering osm_housenumber_point on geohash\n\u001b[2K[Oct 18 14:43:05] [INFO] [PostGIS] Clustering osm_housenumber_point on geohash took: 392.664443ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:05] Analysing osm_housenumber_point\n\u001b[2K[Oct 18 14:43:05] [INFO] [PostGIS] Analysing osm_housenumber_point took: 219.023737ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:05] Indexing osm_poi_point on geohash\n\u001b[2K[Oct 18 14:43:05] [INFO] [PostGIS] Indexing osm_poi_point on geohash took: 125.983628ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:05] Clustering osm_poi_point on geohash\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Clustering osm_poi_point on geohash took: 203.179798ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Analysing osm_poi_point\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Analysing osm_poi_point took: 331.48706ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Indexing osm_rail_station_point on geohash\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Indexing osm_rail_station_point on geohash took: 9.963336ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Clustering osm_rail_station_point on geohash\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Clustering osm_rail_station_point on geohash took: 15.455779ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Analysing osm_rail_station_point\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Analysing osm_rail_station_point took: 10.806866ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Indexing osm_water_polygon on geohash\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Indexing osm_water_polygon on geohash took: 25.461437ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Clustering osm_water_polygon on geohash\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Clustering osm_water_polygon on geohash took: 44.109431ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Analysing osm_water_polygon\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Analysing osm_water_polygon took: 20.2071ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Indexing osm_aero_polygon on geohash\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Indexing osm_aero_polygon on geohash took: 9.719581ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Clustering osm_aero_polygon on geohash\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Clustering osm_aero_polygon on geohash took: 15.16167ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Analysing osm_aero_polygon\n\u001b[2K[Oct 18 14:43:06] [INFO] [PostGIS] Analysing osm_aero_polygon took: 3.201175ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:06] Indexing osm_road_geometry on geohash\n\u001b[2K[Oct 18 14:43:09] [INFO] [PostGIS] Indexing osm_road_geometry on geohash took: 2.910880173s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:09] Clustering osm_road_geometry on geohash\n\u001b[2K[Oct 18 14:43:12] [INFO] [PostGIS] Clustering osm_road_geometry on geohash took: 2.998326106s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:12] Analysing osm_road_geometry\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Analysing osm_road_geometry took: 978.606314ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Indexing osm_airport_point on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Indexing osm_airport_point on geohash took: 5.95808ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Clustering osm_airport_point on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Clustering osm_airport_point on geohash took: 12.804068ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Analysing osm_airport_point\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Analysing osm_airport_point took: 3.990485ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Indexing osm_airport_polygon on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Indexing osm_airport_polygon on geohash took: 4.951439ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Clustering osm_airport_polygon on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Clustering osm_airport_polygon on geohash took: 11.004745ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Analysing osm_airport_polygon\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Analysing osm_airport_polygon took: 4.206689ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Indexing osm_place_point on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Indexing osm_place_point on geohash took: 11.944038ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Clustering osm_place_point on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Clustering osm_place_point on geohash took: 32.997299ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Analysing osm_place_point\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Analysing osm_place_point took: 32.270694ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Indexing osm_aero_linestring on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Indexing osm_aero_linestring on geohash took: 8.658964ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Clustering osm_aero_linestring on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Clustering osm_aero_linestring on geohash took: 18.945872ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Analysing osm_aero_linestring\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Analysing osm_aero_linestring took: 11.12618ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Indexing osm_admin_linestring on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Indexing osm_admin_linestring on geohash took: 5.974196ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Clustering osm_admin_linestring on geohash\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Clustering osm_admin_linestring on geohash took: 19.01631ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Analysing osm_admin_linestring\n\u001b[2K[Oct 18 14:43:13] [INFO] [PostGIS] Analysing osm_admin_linestring took: 9.630439ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:13] Indexing osm_barrier_linestring on geohash\n\u001b[2K[Oct 18 14:43:14] [INFO] [PostGIS] Indexing osm_barrier_linestring on geohash took: 580.05317ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:14] Clustering osm_barrier_linestring on geohash\n\u001b[2K[Oct 18 14:43:14] [INFO] [PostGIS] Clustering osm_barrier_linestring on geohash took: 92.485438ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:14] Analysing osm_barrier_linestring\n\u001b[2K[Oct 18 14:43:14] [INFO] [PostGIS] Analysing osm_barrier_linestring took: 96.577241ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:14] Indexing osm_water_linestring on geohash\n\u001b[2K[Oct 18 14:43:14] [INFO] [PostGIS] Indexing osm_water_linestring on geohash took: 57.786965ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:14] Clustering osm_water_linestring on geohash\n\u001b[2K[Oct 18 14:43:14] [INFO] [PostGIS] Clustering osm_water_linestring on geohash took: 85.639557ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:14] Analysing osm_water_linestring\n\u001b[2K[Oct 18 14:43:14] [INFO] [PostGIS] Analysing osm_water_linestring took: 128.774932ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:14] Indexing osm_building_polygon on geohash\n\u001b[2K[Oct 18 14:43:18] [INFO] [PostGIS] Indexing osm_building_polygon on geohash took: 3.380141236s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:18] Clustering osm_building_polygon on geohash\n\u001b[2K[Oct 18 14:43:25] [INFO] [PostGIS] Clustering osm_building_polygon on geohash took: 7.292923262s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:25] Analysing osm_building_polygon\n\u001b[2K[Oct 18 14:43:25] [INFO] [PostGIS] Analysing osm_building_polygon took: 284.010886ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:25] Indexing osm_poi_polygon on geohash\n\u001b[2K[Oct 18 14:43:25] [INFO] [PostGIS] Indexing osm_poi_polygon on geohash took: 49.651488ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:25] Clustering osm_poi_polygon on geohash\n\u001b[2K[Oct 18 14:43:25] [INFO] [PostGIS] Clustering osm_poi_polygon on geohash took: 73.106966ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:25] Analysing osm_poi_polygon\n\u001b[2K[Oct 18 14:43:26] [INFO] [PostGIS] Analysing osm_poi_polygon took: 103.969348ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:26] Indexing osm_housenumber_polygon on geohash\n\u001b[2K[Oct 18 14:43:27] [INFO] [PostGIS] Indexing osm_housenumber_polygon on geohash took: 1.547066531s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:27] Clustering osm_housenumber_polygon on geohash\n\u001b[2K[Oct 18 14:43:29] [INFO] [PostGIS] Clustering osm_housenumber_polygon on geohash took: 2.310914089s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:29] Analysing osm_housenumber_polygon\n\u001b[2K[Oct 18 14:43:30] [INFO] [PostGIS] Analysing osm_housenumber_polygon took: 358.667708ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:30] Indexing osm_mountain_peak_point on geohash\n\u001b[2K[Oct 18 14:43:30] [INFO] [PostGIS] Indexing osm_mountain_peak_point on geohash took: 6.854129ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:30] Clustering osm_mountain_peak_point on geohash\n\u001b[2K[Oct 18 14:43:30] [INFO] [PostGIS] Clustering osm_mountain_peak_point on geohash took: 14.119795ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:30] Analysing osm_mountain_peak_point\n\u001b[2K[Oct 18 14:43:30] [INFO] [PostGIS] Analysing osm_mountain_peak_point took: 3.353466ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:30] Indexing osm_barrier_polygon on geohash\n\u001b[2K[Oct 18 14:43:30] [INFO] [PostGIS] Indexing osm_barrier_polygon on geohash took: 16.370111ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:30] Clustering osm_barrier_polygon on geohash\n\u001b[2K[Oct 18 14:43:30] [INFO] [PostGIS] Clustering osm_barrier_polygon on geohash took: 31.722425ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:30] Analysing osm_barrier_polygon\n\u001b[2K[Oct 18 14:43:30] [INFO] [PostGIS] Analysing osm_barrier_polygon took: 11.908459ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:30] Indexing osm_landuse_polygon on geohash\n\u001b[2K[Oct 18 14:43:30] [INFO] [PostGIS] Indexing osm_landuse_polygon on geohash took: 268.920944ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:30] Clustering osm_landuse_polygon on geohash\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Clustering osm_landuse_polygon on geohash took: 467.989407ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Analysing osm_landuse_polygon\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Analysing osm_landuse_polygon took: 344.787247ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Indexing osm_landuse_polygon_gen0 on geohash\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Indexing osm_landuse_polygon_gen0 on geohash took: 13.807858ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Clustering osm_landuse_polygon_gen0 on geohash\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Clustering osm_landuse_polygon_gen0 on geohash took: 21.079375ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Analysing osm_landuse_polygon_gen0\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Analysing osm_landuse_polygon_gen0 took: 15.18175ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Indexing osm_landuse_polygon_gen1 on geohash\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Indexing osm_landuse_polygon_gen1 on geohash took: 65.336846ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Clustering osm_landuse_polygon_gen1 on geohash\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Clustering osm_landuse_polygon_gen1 on geohash took: 84.343884ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Analysing osm_landuse_polygon_gen1\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Analysing osm_landuse_polygon_gen1 took: 77.188308ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Indexing osm_water_polygon_gen1 on geohash\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Indexing osm_water_polygon_gen1 on geohash took: 6.317468ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Clustering osm_water_polygon_gen1 on geohash\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Clustering osm_water_polygon_gen1 on geohash took: 15.712273ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Analysing osm_water_polygon_gen1\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Analysing osm_water_polygon_gen1 took: 4.745642ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Indexing osm_building_polygon_gen0 on geohash\n\u001b[2K[Oct 18 14:43:31] [INFO] [PostGIS] Indexing osm_building_polygon_gen0 on geohash took: 124.866614ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:31] Clustering osm_building_polygon_gen0 on geohash\n\u001b[2K[Oct 18 14:43:32] [INFO] [PostGIS] Clustering osm_building_polygon_gen0 on geohash took: 156.262375ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:32] Analysing osm_building_polygon_gen0\n\u001b[2K[Oct 18 14:43:32] [INFO] [PostGIS] Analysing osm_building_polygon_gen0 took: 65.950973ms\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:32] [INFO] [PostGIS] Clustering on geometry took: 27.153379793s\n\u001b[36mimport-osm_1            |\u001b[0m [Oct 18 14:43:32] [INFO] Imposm took: 1m51.948546622s\n\u001b[36mimport-osm_1            |\u001b[0m Create osm_water_point table with precalculated centroids\n\u001b[36mimport-osm_1            |\u001b[0m DROP TABLE IF EXISTS osm_water_point CASCADE;\n\u001b[36mimport-osm_1            |\u001b[0m psql:water_point_table.sql:1: NOTICE:  table \"osm_water_point\" does not exist, skipping\n\u001b[36mimport-osm_1            |\u001b[0m DROP TABLE\n\u001b[36mimport-osm_1            |\u001b[0m CREATE TABLE osm_water_point AS\n\u001b[36mimport-osm_1            |\u001b[0m SELECT id,\n\u001b[36mimport-osm_1            |\u001b[0m        topoint(geometry) AS geometry,\n\u001b[36mimport-osm_1            |\u001b[0m        timestamp,\n\u001b[36mimport-osm_1            |\u001b[0m        name, name_fr, name_en, name_de,\n\u001b[36mimport-osm_1            |\u001b[0m        name_es, name_ru, name_zh,\n\u001b[36mimport-osm_1            |\u001b[0m        area\n\u001b[36mimport-osm_1            |\u001b[0m FROM osm_water_polygon;\n\u001b[36mimport-osm_1            |\u001b[0m SELECT 1280\n\u001b[36mimport-osm_1            |\u001b[0m CREATE INDEX ON osm_water_point USING gist (geometry);\n\u001b[36mimport-osm_1            |\u001b[0m CREATE INDEX\n\u001b[36mimport-osm_1            |\u001b[0m CREATE INDEX ON osm_water_point\n\u001b[36mimport-osm_1            |\u001b[0m USING btree (st_geohash(st_transform(st_setsrid(box2d(geometry)::geometry, 3857), 4326)));\n\u001b[36mimport-osm_1            |\u001b[0m CREATE INDEX\n\u001b[36mimport-osm_1            |\u001b[0m Update osm_place_polygon with point geometry\n\u001b[36mimport-osm_1            |\u001b[0m UPDATE osm_place_point\n\u001b[36mimport-osm_1            |\u001b[0m SET geometry = topoint(geometry)\n\u001b[36mimport-osm_1            |\u001b[0m WHERE ST_GeometryType(geometry) <> 'ST_Point';\n\u001b[36mimport-osm_1            |\u001b[0m UPDATE 74\n\u001b[36mimport-osm_1            |\u001b[0m UPDATE osm_poi_polygon\n\u001b[36mimport-osm_1            |\u001b[0m SET geometry = topoint(geometry)\n\u001b[36mimport-osm_1            |\u001b[0m WHERE ST_GeometryType(geometry) <> 'ST_Point';\n\u001b[36mimport-osm_1            |\u001b[0m UPDATE 3812\n\u001b[36mimport-osm_1            |\u001b[0m UPDATE osm_housenumber_polygon\n\u001b[36mimport-osm_1            |\u001b[0m SET geometry = topoint(geometry)\n\u001b[36mimport-osm_1            |\u001b[0m WHERE ST_GeometryType(geometry) <> 'ST_Point';\n\u001b[36mimport-osm_1            |\u001b[0m UPDATE 119289\n\u001b[36mimport-osm_1            |\u001b[0m Update scaleranks from Natural Earth data\n\u001b[36mimport-osm_1            |\u001b[0m UPDATE osm_place_point\n\u001b[36mimport-osm_1            |\u001b[0m SET scalerank = improved_places.scalerank\n\u001b[36mimport-osm_1            |\u001b[0m FROM\n\u001b[36mimport-osm_1            |\u001b[0m (\n\u001b[36mimport-osm_1            |\u001b[0m     SELECT osm.id, ne.scalerank\n\u001b[36mimport-osm_1            |\u001b[0m     FROM ne_10m_populated_places AS ne, osm_place_point AS osm\n\u001b[36mimport-osm_1            |\u001b[0m     WHERE\n\u001b[36mimport-osm_1            |\u001b[0m     (\n\u001b[36mimport-osm_1            |\u001b[0m         ne.name ILIKE osm.name OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.name ILIKE osm.name_en OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.namealt ILIKE osm.name OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.namealt ILIKE osm.name_en OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.meganame ILIKE osm.name OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.meganame ILIKE osm.name_en OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.gn_ascii ILIKE osm.name OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.gn_ascii ILIKE osm.name_en OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.nameascii ILIKE osm.name OR\n\u001b[36mimport-osm_1            |\u001b[0m         ne.nameascii ILIKE osm.name_en\n\u001b[36mimport-osm_1            |\u001b[0m     )\n\u001b[36mimport-osm_1            |\u001b[0m     AND (osm.type = 'city' OR osm.type = 'town' OR osm.type = 'village')\n\u001b[36mimport-osm_1            |\u001b[0m     AND st_dwithin(ne.geom, osm.geometry, 50000)\n\u001b[36mimport-osm_1            |\u001b[0m     ) AS improved_places\n\u001b[36mimport-osm_1            |\u001b[0m WHERE osm_place_point.id = improved_places.id;\n\u001b[36mimport-osm_1            |\u001b[0m UPDATE 1\n\u001b[36mimport-osm_1            |\u001b[0m DELETE 0\n\u001b[36mimport-osm_1            |\u001b[0m INSERT 0 1\n\u001b[36mosm2vectortiles_import-osm_1 exited with code 0\n\u001b[0m\u001b[1m\u001b[3m%\u001b[23m\u001b[1m\u001b[0m                                                                                                                                                                                                                                                                               \n\u001bk..m2vectortiles\u001b\\\n\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\n\u001bM\u001bM\u001b[?2004h\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\u001b[3mdocker-compose up import-sql\u001b[23m\u001b[28D\u001b[23md\u001b[23mo\u001b[23mc\u001b[23mk\u001b[23me\u001b[23mr\u001b[23m-\u001b[23mc\u001b[23mo\u001b[23mm\u001b[23mp\u001b[23mo\u001b[23ms\u001b[23me\u001b[23m \u001b[23mu\u001b[23mp\u001b[23m \u001b[23mi\u001b[23mm\u001b[23mp\u001b[23mo\u001b[23mr\u001b[23mt\u001b[23m-\u001b[23ms\u001b[23mq\u001b[23ml\u001b[?1l\u001b>\u001b[?2004l\n\u001bkdocker-compose\u001b\\\u001b[33mWARNING\u001b[0m: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\nosm2vectortiles_postgis_1 is up-to-date\nCreating osm2vectortiles_import-sql_1\nAttaching to osm2vectortiles_import-sql_1\n\u001b[36mimport-sql_1            |\u001b[0m Creating functions in osm\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION overlapping_tiles(\n\u001b[36mimport-sql_1            |\u001b[0m     geom geometry,\n\u001b[36mimport-sql_1            |\u001b[0m     max_zoom_level INTEGER,\n\u001b[36mimport-sql_1            |\u001b[0m     buffer_size INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m ) RETURNS TABLE (\n\u001b[36mimport-sql_1            |\u001b[0m     tile_z INTEGER,\n\u001b[36mimport-sql_1            |\u001b[0m     tile_x INTEGER,\n\u001b[36mimport-sql_1            |\u001b[0m     tile_y INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m ) AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN QUERY\n\u001b[36mimport-sql_1            |\u001b[0m         WITH RECURSIVE tiles(x, y, z, e) AS (\n\u001b[36mimport-sql_1            |\u001b[0m             SELECT 0, 0, 0, geom && XYZ_Extent(0, 0, 0, buffer_size)\n\u001b[36mimport-sql_1            |\u001b[0m             UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m             SELECT x2 + xx, y2 + yy, z+1,\n\u001b[36mimport-sql_1            |\u001b[0m                    geom && XYZ_Extent(x2 + xx, y2 + yy, z+1, buffer_size)\n\u001b[36mimport-sql_1            |\u001b[0m             FROM tiles,\n\u001b[36mimport-sql_1            |\u001b[0m             (VALUES (0, 0), (0, 1), (1, 1), (1, 0)) as c(xx, yy)\n\u001b[36mimport-sql_1            |\u001b[0m             WHERE e AND z < max_zoom_level\n\u001b[36mimport-sql_1            |\u001b[0m         )\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT z, x, y FROM tiles WHERE e;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION changed_tiles_latest_timestamp()\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS TABLE (x INTEGER, y INTEGER, z INTEGER) AS $$\n\u001b[36mimport-sql_1            |\u001b[0m DECLARE\n\u001b[36mimport-sql_1            |\u001b[0m  latest_ts timestamp;\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m  SELECT MAX(timestamp) INTO latest_ts FROM osm_timestamps;\n\u001b[36mimport-sql_1            |\u001b[0m  RETURN QUERY SELECT * FROM changed_tiles(latest_ts);\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION changed_tiles_table(\n\u001b[36mimport-sql_1            |\u001b[0m     table_name TEXT,\n\u001b[36mimport-sql_1            |\u001b[0m     ts TIMESTAMP,\n\u001b[36mimport-sql_1            |\u001b[0m     buffer_size INTEGER,\n\u001b[36mimport-sql_1            |\u001b[0m     min_zoom INTEGER,\n\u001b[36mimport-sql_1            |\u001b[0m     max_zoom INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m ) RETURNS TABLE (x INTEGER, y INTEGER, z INTEGER) AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN QUERY EXECUTE format('\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT DISTINCT t.tile_x AS x, t.tile_y AS y, t.tile_z AS z\n\u001b[36mimport-sql_1            |\u001b[0m         FROM %I AS g\n\u001b[36mimport-sql_1            |\u001b[0m         INNER JOIN LATERAL overlapping_tiles(g.geometry, $2, $3)\n\u001b[36mimport-sql_1            |\u001b[0m                            AS t ON g.timestamp = $4\n\u001b[36mimport-sql_1            |\u001b[0m         WHERE 3 BETWEEN $1 AND $2\n\u001b[36mimport-sql_1            |\u001b[0m     ', table_name) USING min_zoom, max_zoom, buffer_size, ts;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m -- OSM ID transformations\n\u001b[36mimport-sql_1            |\u001b[0m -- specification : https://www.mapbox.com/vector-tiles/mapbox-streets-v7/\n\u001b[36mimport-sql_1            |\u001b[0m -- osm_ids :  imposm3 with use_single_id_space:true\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION osm_ids2mbid (osm_ids BIGINT, is_polygon bool ) RETURNS BIGINT AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m  RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m    WHEN                      (osm_ids >=     0 )                    THEN (      osm_ids         * 10)       -- +0 point\n\u001b[36mimport-sql_1            |\u001b[0m    WHEN (NOT is_polygon) AND (osm_ids >= -1e17 ) AND (osm_ids < 0 ) THEN ( (abs(osm_ids)      ) * 10) + 1   -- +1 way linestring\n\u001b[36mimport-sql_1            |\u001b[0m    WHEN (    is_polygon) AND (osm_ids >= -1e17 ) AND (osm_ids < 0 ) THEN ( (abs(osm_ids)      ) * 10) + 2   -- +2 way poly\n\u001b[36mimport-sql_1            |\u001b[0m    WHEN (NOT is_polygon) AND (osm_ids <  -1e17 )                    THEN ( (abs(osm_ids) -1e17) * 10) + 3   -- +3 relations linestring\n\u001b[36mimport-sql_1            |\u001b[0m    WHEN (    is_polygon) AND (osm_ids <  -1e17 )                    THEN ( (abs(osm_ids) -1e17) * 10) + 4   -- +4 relations poly\n\u001b[36mimport-sql_1            |\u001b[0m    ELSE 0\n\u001b[36mimport-sql_1            |\u001b[0m  END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION is_polygon( geom geometry) RETURNS bool AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN ST_GeometryType(geom) IN ('ST_Polygon', 'ST_MultiPolygon');\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m /\n\u001b[36mimport-sql_1            |\u001b[0m -- example call for osm_ids2mbid\n\u001b[36mimport-sql_1            |\u001b[0m select id\n\u001b[36mimport-sql_1            |\u001b[0m       ,osm_ids2mbid ( id,   is_polygon( geometry ) )  as from_real_geom\n\u001b[36mimport-sql_1            |\u001b[0m       ,osm_ids2mbid ( id,   false                  )  as from_fake_geom_false\n\u001b[36mimport-sql_1            |\u001b[0m       ,osm_ids2mbid ( id,   true                   )  as from_fake_geom_true\n\u001b[36mimport-sql_1            |\u001b[0m from osm_place_geometry ;\n\u001b[36mimport-sql_1            |\u001b[0m /\n\u001b[36mimport-sql_1            |\u001b[0m -- Return pixel resolution at the given zoom level\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION XYZ_Resolution(z INTEGER)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS FLOAT8\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m   -- circumference divided by 256 is z0 resolution, then divide by 2^z\n\u001b[36mimport-sql_1            |\u001b[0m   SELECT 40075017.0 / 256 / power(2, z);\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE SQL IMMUTABLE STRICT;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m -- Returns a polygon representing the bounding box of a given XYZ tile\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION XYZ_Extent(x INTEGER, y INTEGER, z INTEGER, buffer INTEGER)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS GEOMETRY\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m DECLARE\n\u001b[36mimport-sql_1            |\u001b[0m   origin_shift FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   initial_resolution FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   tile_geo_size FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   pixres FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   xmin FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   ymin FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   xmax FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   ymax FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   earth_circumference FLOAT8;\n\u001b[36mimport-sql_1            |\u001b[0m   tile_size INTEGER;\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m   -- Size of each tile in pixels (1:1 aspect ratio)\n\u001b[36mimport-sql_1            |\u001b[0m   tile_size := 256 + (2 * buffer);\n\u001b[36mimport-sql_1            |\u001b[0m \n\u001b[36mimport-sql_1            |\u001b[0m   initial_resolution := XYZ_Resolution(0);\n\u001b[36mimport-sql_1            |\u001b[0m \n\u001b[36mimport-sql_1            |\u001b[0m   origin_shift := (initial_resolution * tile_size) / 2.0;\n\u001b[36mimport-sql_1            |\u001b[0m \n\u001b[36mimport-sql_1            |\u001b[0m   pixres := initial_resolution / (power(2,z));\n\u001b[36mimport-sql_1            |\u001b[0m \n\u001b[36mimport-sql_1            |\u001b[0m   tile_geo_size = tile_size * pixres;\n\u001b[36mimport-sql_1            |\u001b[0m \n\u001b[36mimport-sql_1            |\u001b[0m   xmin := -origin_shift + xtile_geo_size;\n\u001b[36mimport-sql_1            |\u001b[0m   xmax := -origin_shift + (x+1)tile_geo_size;\n\u001b[36mimport-sql_1            |\u001b[0m \n\u001b[36mimport-sql_1            |\u001b[0m   ymin := origin_shift - ytile_geo_size;\n\u001b[36mimport-sql_1            |\u001b[0m   ymax := origin_shift - (y+1)tile_geo_size;\n\u001b[36mimport-sql_1            |\u001b[0m \n\u001b[36mimport-sql_1            |\u001b[0m   RETURN ST_MakeEnvelope(xmin, ymin, xmax, ymax, 3857);\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE STRICT;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m Creating generated functions in osm\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION barrier_line_class(type VARCHAR)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS VARCHAR AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('gate','entrance','spikes','bollard','lift_gate','kissing_gate','stile') THEN 'gate'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('cliff','earth_bank') THEN 'cliff'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('city_wall','fence','retaining_wall','wall','wire_fence','True','embankment','cable_barrier','jersey_barrier') THEN 'fence'\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m   \n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION landuse_overlay_class(type VARCHAR)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS VARCHAR AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('national_park','nature_reserve','protected_area') THEN 'national_park'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('wetland','marsh','swamp','bog') THEN 'wetland'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('mud','tidalflat') THEN 'wetland_noveg'\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m   \n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION landuse_class(type VARCHAR)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS VARCHAR AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('residential') THEN 'residential'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('scrub') THEN 'scrub'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('sand','beach') THEN 'sand'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('retail') THEN 'retail'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('military') THEN 'military'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('greenfield') THEN 'greenfield'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('park','dog_park','common','garden','golf_course','playground','recreation_ground','village_green','zoo','sports_centre','camp_site') THEN 'park'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('hospital') THEN 'hospital'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('railway') THEN 'railway'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('grass','grassland','meadow','heath','fell') THEN 'grass'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('commercial') THEN 'commercial'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('rock','bare_rock','scree','quarry') THEN 'rock'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('winter_sports') THEN 'winter_sports'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('aboriginal_lands') THEN 'aboriginal_lands'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('school','college','university') THEN 'school'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('glacier') THEN 'glacier'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('orchard','farm','farmland','farmyard','allotments','vineyard','plant_nursery') THEN 'agriculture'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('cemetery','christian','jewish') THEN 'cemetery'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('athletics','chess','pitch') THEN 'pitch'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('salt_pond') THEN 'salt_pond'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('industrial') THEN 'industrial'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('wood','forest') THEN 'wood'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('landfill') THEN 'landfill'\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m   \n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION road_type_class(type VARCHAR)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS VARCHAR AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('secondary') THEN 'secondary'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('service') THEN 'service'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('cable_car','gondola','mixed_lift','chair_lift','drag_lift','t-bar','j-bar','platter','rope_tow','zip_line','magic_carpet','canopy') THEN 'aerialway'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('rail','light_rail','subway') THEN 'major_rail'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('pedestrian') THEN 'pedestrian'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('steps','corridor','crossing','piste','mtb','hiking','cycleway','footway','path','bridleway') THEN 'path'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('tertiary') THEN 'tertiary'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('unclassified','residential','road','living_street','raceway') THEN 'street'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('motorway_link') THEN 'motorway_link'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('primary') THEN 'primary'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('hole') THEN 'golf'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('ferry') THEN 'ferry'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('motorway') THEN 'motorway'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('trunk_link','primary_link','secondary_link','tertiary_link') THEN 'link'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('construction') THEN 'construction'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('trunk') THEN 'trunk'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('track') THEN 'track'\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m   \n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION rail_station_class(type VARCHAR)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS VARCHAR AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('station') THEN 'rail'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('stop','subway','tram_stop') THEN 'rail-metro'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('light_rail','halt') THEN 'rail-light'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('subway_entrance') THEN 'entrance'\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m   \n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION maki_label_class(type VARCHAR)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS VARCHAR AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('bag','clothes') THEN 'clothing-store'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('theater') THEN 'theater'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('grave_yard','cemetery') THEN 'cemetery'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('zoo') THEN 'zoo'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('hospital','nursing_home') THEN 'hospital'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('accessories','antiques','art','artwork','gallery','arts_centre') THEN 'art-gallery'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('bicycle_rental') THEN 'bicycle-share'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('subway_entrance') THEN 'entrance'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('car','car_repair','taxi') THEN 'car'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('park','bbq') THEN 'park'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('information') THEN 'information'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('helipad') THEN 'heliport'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('school','kindergarten') THEN 'school'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('fast_food','food_court') THEN 'fast-food'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('garden') THEN 'garden'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('biergarten','pub') THEN 'beer'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('veterinary') THEN 'veterinary'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('bar','nightclub') THEN 'bar'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('townhall','public_building','courthouse','community_centre') THEN 'town-hall'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('prison') THEN 'prison'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('golf','golf_course','miniature_golf') THEN 'golf'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('bicycle') THEN 'bicycle'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('picnic-site') THEN 'picnic-site'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('camp_site','caravan_site') THEN 'campsite'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('theme_park') THEN 'amusement-park'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('alcohol','beverages','wine') THEN 'alcohol-shop'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('bus_stop','bus_station') THEN 'bus'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('american_football','stadium','soccer','pitch') THEN 'stadium'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('dog_park') THEN 'dog-park'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('embassy') THEN 'embassy'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('attraction','viewpoint') THEN 'attraction'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('books','library') THEN 'library'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('cinema') THEN 'cinema'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('marina','dock') THEN 'harbor'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('place_of_worship') THEN 'place-of-worship'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('swimming_area','swimming') THEN 'swimming'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('police') THEN 'police'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('pharmacy') THEN 'pharmacy'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('fuel') THEN 'fuel'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('university','college') THEN 'college'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('butcher') THEN 'slaughterhouse'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('doctor') THEN 'doctor'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('ferry_terminal') THEN 'ferry'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('accessories','antiques','art','beauty','bed','boutique','camera','carpet','charity','chemist','chocolate','coffee','computer','confectionery','convenience','copyshop','cosmetics','garden_centre','doityourself','erotic','electronics','fabric','florist','furniture','video_games','video','general','gift','hardware','hearing_aids','hifi','ice_cream','interior_decoration','jewelry','kiosk','lamps','mall','massage','motorcycle','mobile_phone','newsagent','optician','outdoor','perfumery','perfume','pet','photo','second_hand','shoes','sports','stationery','tailor','tattoo','ticket','tobacco','toys','travel_agency','watches','weapons','wholesale') THEN 'shop'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('restaurant') THEN 'restaurant'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('chocolate','confectionery') THEN 'ice-cream'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('dentist') THEN 'dentist'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('playground') THEN 'playground'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('cricket') THEN 'cricket'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('cafe') THEN 'cafe'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('bank') THEN 'bank'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('fire_station') THEN 'fire-station'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('supermarket','deli','delicatessen','department_store','greengrocer','marketplace') THEN 'grocery'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('music','musical_instrument') THEN 'music'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('monument') THEN 'monument'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('toilets') THEN 'toilet'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('post_box','post_office') THEN 'post'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('museum') THEN 'museum'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('bakery') THEN 'bakery'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('station') THEN 'airfield'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('laundry','dry_cleaning') THEN 'laundry'\n\u001b[36mimport-sql_1            |\u001b[0m             WHEN type IN ('hotel','motel','bed_and_breakfast','guest_house','hostel','chalet','alpine_hut','camp_site') THEN 'lodging'\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m   \n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION changed_tiles(ts timestamp)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS TABLE (x INTEGER, y INTEGER, z INTEGER) AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN QUERY (\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_airport_polygon', ts, 64, 9, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_barrier_linestring', ts, 4, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_aero_polygon', ts, 4, 9, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_barrier_polygon', ts, 4, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_admin_linestring', ts, 4, 2, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_poi_point', ts, 64, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_water_polygon', ts, 64, 5, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_place_point', ts, 128, 3, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_rail_station_point', ts, 64, 12, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_water_linestring', ts, 8, 8, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_road_geometry', ts, 8, 5, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_landuse_polygon', ts, 8, 5, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_building_polygon', ts, 2, 13, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_poi_polygon', ts, 64, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_airport_point', ts, 64, 9, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_housenumber_point', ts, 64, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_aero_linestring', ts, 4, 9, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_housenumber_polygon', ts, 64, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_mountain_peak_point', ts, 64, 12, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_airport_polygon_delete', ts, 64, 9, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_barrier_linestring_delete', ts, 4, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_aero_polygon_delete', ts, 4, 9, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_barrier_polygon_delete', ts, 4, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_admin_linestring_delete', ts, 4, 2, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_poi_point_delete', ts, 64, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_water_polygon_delete', ts, 64, 5, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_place_point_delete', ts, 128, 3, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_rail_station_point_delete', ts, 64, 12, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_water_linestring_delete', ts, 8, 8, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_road_geometry_delete', ts, 8, 5, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_landuse_polygon_delete', ts, 8, 5, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_building_polygon_delete', ts, 2, 13, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_poi_polygon_delete', ts, 64, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_airport_point_delete', ts, 64, 9, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_housenumber_point_delete', ts, 64, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_aero_linestring_delete', ts, 4, 9, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_housenumber_polygon_delete', ts, 64, 14, 14)\n\u001b[36mimport-sql_1            |\u001b[0m                 UNION\n\u001b[36mimport-sql_1            |\u001b[0m                 SELECT * FROM changed_tiles_table('osm_mountain_peak_point_delete', ts, 64, 12, 14)\n\u001b[36mimport-sql_1            |\u001b[0m     );\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m   \n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW osm_tables AS (\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_housenumber_point' AS table_name,64 AS buffer_size,14 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_poi_polygon' AS table_name,64 AS buffer_size,14 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_building_polygon' AS table_name,2 AS buffer_size,13 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_housenumber_polygon' AS table_name,64 AS buffer_size,14 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_barrier_polygon' AS table_name,4 AS buffer_size,14 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_airport_polygon' AS table_name,64 AS buffer_size,9 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_aero_polygon' AS table_name,4 AS buffer_size,9 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_water_linestring' AS table_name,8 AS buffer_size,8 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_landuse_polygon' AS table_name,8 AS buffer_size,5 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_water_polygon' AS table_name,64 AS buffer_size,5 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_road_geometry' AS table_name,8 AS buffer_size,5 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_place_point' AS table_name,128 AS buffer_size,3 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_barrier_linestring' AS table_name,4 AS buffer_size,14 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_poi_point' AS table_name,64 AS buffer_size,14 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_mountain_peak_point' AS table_name,64 AS buffer_size,12 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_airport_point' AS table_name,64 AS buffer_size,9 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_rail_station_point' AS table_name,64 AS buffer_size,12 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_admin_linestring' AS table_name,4 AS buffer_size,2 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT 'osm_aero_linestring' AS table_name,4 AS buffer_size,9 AS min_zoom,14 AS max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m Creating triggers in osm\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION drop_osm_delete_index(table_name TEXT) returns VOID\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     EXECUTE format('DROP INDEX IF EXISTS %I', table_name || 'geom');\n\u001b[36mimport-sql_1            |\u001b[0m     EXECUTE format('DROP INDEX IF EXISTS %I', table_name || '_geom_geohash');\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION drop_osm_delete_indizes() RETURNS VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     PERFORM drop_osm_delete_index(table_name)\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_tables_delete;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION create_osm_delete_index(table_name TEXT) returns VOID\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     EXECUTE format('CREATE INDEX %I ON %I USING gist (geometry)', table_name || '_geom', table_name);\n\u001b[36mimport-sql_1            |\u001b[0m     EXECUTE format('CREATE INDEX %I ON %I\n\u001b[36mimport-sql_1            |\u001b[0m     USING btree (st_geohash(st_transform(st_setsrid(box2d(geometry)::geometry, 3857), 4326)))',\n\u001b[36mimport-sql_1            |\u001b[0m     table_name || '_geom_geohash', table_name);\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION cleanup_osm_tracking_tables() returns VOID\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m DECLARE\n\u001b[36mimport-sql_1            |\u001b[0m     latest_ts timestamp;\n\u001b[36mimport-sql_1            |\u001b[0m     t osm_tables%ROWTYPE;\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT MAX(timestamp) INTO latest_ts FROM osm_timestamps;\n\u001b[36mimport-sql_1            |\u001b[0m     FOR t IN SELECT * FROM osm_tables_delete LOOP\n\u001b[36mimport-sql_1            |\u001b[0m         EXECUTE format('DELETE FROM %I WHERE timestamp <> $1', t.table_name) USING latest_ts;\n\u001b[36mimport-sql_1            |\u001b[0m     END LOOP;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m -- TODO: Perhaps a dynamic trigger is really slow\n\u001b[36mimport-sql_1            |\u001b[0m -- if it is a performance problem we should generate static\n\u001b[36mimport-sql_1            |\u001b[0m -- triggers for each table\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION track_osm_delete() returns TRIGGER\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m      IF (TG_OP = 'DELETE') THEN\n\u001b[36mimport-sql_1            |\u001b[0m         EXECUTE format('\n\u001b[36mimport-sql_1            |\u001b[0m             INSERT INTO %I(id, geometry)\n\u001b[36mimport-sql_1            |\u001b[0m             VALUES($1, $2)', TG_TABLE_NAME::TEXT || '_delete')\n\u001b[36mimport-sql_1            |\u001b[0m             USING OLD.id, OLD.geometry;\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN OLD;\n\u001b[36mimport-sql_1            |\u001b[0m      END IF;\n\u001b[36mimport-sql_1            |\u001b[0m \n\u001b[36mimport-sql_1            |\u001b[0m      RETURN NULL;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION create_delete_table(table_name TEXT) returns VOID\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     EXECUTE format('CREATE TABLE IF NOT EXISTS %I (\n\u001b[36mimport-sql_1            |\u001b[0m         id bigint,\n\u001b[36mimport-sql_1            |\u001b[0m         geometry geometry,\n\u001b[36mimport-sql_1            |\u001b[0m         timestamp timestamp\n\u001b[36mimport-sql_1            |\u001b[0m     )', table_name);\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m -- Trigger utilities\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION recreate_osm_delete_tracking(table_name text) returns VOID\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     EXECUTE format(\n\u001b[36mimport-sql_1            |\u001b[0m         'DROP TRIGGER IF EXISTS %I_track_delete ON %I;\n\u001b[36mimport-sql_1            |\u001b[0m         CREATE TRIGGER %I_track_delete\n\u001b[36mimport-sql_1            |\u001b[0m         BEFORE DELETE ON %I\n\u001b[36mimport-sql_1            |\u001b[0m         FOR EACH ROW EXECUTE PROCEDURE track_osm_delete()',\n\u001b[36mimport-sql_1            |\u001b[0m         table_name, table_name, table_name, table_name\n\u001b[36mimport-sql_1            |\u001b[0m     );\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION modify_delete_tracking(table_name TEXT, enable BOOLEAN)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     EXECUTE format('ALTER TABLE %I %s TRIGGER USER', table_name,\n\u001b[36mimport-sql_1            |\u001b[0m                    CASE WHEN enable THEN 'ENABLE' ELSE 'DISABLE' END);\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION enable_delete_tracking() RETURNS VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     PERFORM modify_delete_tracking(table_name, true)\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_tables;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION disable_delete_tracking() RETURNS VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     PERFORM modify_delete_tracking(table_name, false)\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_tables;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION create_osm_delete_indizes() RETURNS VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     PERFORM create_osm_delete_index(table_name)\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_tables_delete;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION create_delete_tables() RETURNS VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     PERFORM create_delete_table(table_name)\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_tables_delete;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION create_tracking_triggers() RETURNS VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     PERFORM recreate_osm_delete_tracking(table_name)\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_tables;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW osm_tables_delete AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT table_name || '_delete' AS table_name, buffer_size, min_zoom, max_zoom\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_tables\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION update_timestamp(ts timestamp) RETURNS VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m DECLARE t osm_tables%ROWTYPE;\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     FOR t IN SELECT * FROM osm_tables LOOP\n\u001b[36mimport-sql_1            |\u001b[0m         EXECUTE format('UPDATE %I SET timestamp=$1 WHERE timestamp IS NULL;',\n\u001b[36mimport-sql_1            |\u001b[0m                        t.table_name) USING ts;\n\u001b[36mimport-sql_1            |\u001b[0m     END LOOP;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION drop_tables() returns VOID AS $$\n\u001b[36mimport-sql_1            |\u001b[0m DECLARE t osm_tables%ROWTYPE;\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     FOR t IN\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT * FROM osm_tables\n\u001b[36mimport-sql_1            |\u001b[0m         UNION\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT * FROM osm_tables_delete\n\u001b[36mimport-sql_1            |\u001b[0m     LOOP\n\u001b[36mimport-sql_1            |\u001b[0m         EXECUTE format('DROP TABLE %I CASCADE', t.table_name);\n\u001b[36mimport-sql_1            |\u001b[0m     END LOOP;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ language plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m Creating layers in osm\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW admin_z0 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 2 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_110m_admin_0_boundary_lines_land;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW admin_z1 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 2 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_110m_admin_0_boundary_lines_land\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 4 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_50m_admin_1_states_provinces_lines\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE scalerank = 2;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW admin_z2 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 2 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_110m_admin_0_boundary_lines_land\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, admin_level, 0 AS disputed, maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_admin_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE maritime = 1 AND admin_level = 2\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 4 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_admin_1_states_provinces_lines_shp\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE scalerank = 2;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW admin_z3 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 2 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_50m_admin_0_boundary_lines_land\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, admin_level, 0 AS disputed, maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_admin_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE maritime = 1 AND admin_level = 2\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 4 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_admin_1_states_provinces_lines_shp\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE scalerank = 2;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW admin_z4toz5 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 2 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_admin_0_boundary_lines_land\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, admin_level, 0 AS disputed, maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_admin_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE maritime = 1 AND admin_level = 2\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 4 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_admin_1_states_provinces_lines_shp\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE scalerank BETWEEN 2 AND 6;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW admin_z6 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 2 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_admin_0_boundary_lines_land\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, admin_level, 0 AS disputed, maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_admin_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE maritime = 1 AND admin_level = 2\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 4 AS admin_level, 0 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_admin_1_states_provinces_lines_shp\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE scalerank BETWEEN 2 AND 9;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW admin_z7toz14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, admin_level, 0 AS disputed, maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_admin_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE admin_level = 2 OR admin_level = 4\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry, 2 AS admin_level, 1 AS disputed, 0 AS maritime\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_admin_0_boundary_lines_disputed_areas;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW admin_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM admin_z0\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM admin_z1\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM admin_z2\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM admin_z3\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM admin_z4toz5\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM admin_z7toz14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW aeroway_z9 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_aero_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type = 'runway'\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_aero_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type = 'runway';\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW aeroway_z10toz14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_aero_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_aero_polygon;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW aeroway_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM aeroway_z9\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM aeroway_z10toz14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW barrier_line_z14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_barrier_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_barrier_polygon;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW barrier_line_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM barrier_line_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW building_z13 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, underground, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_building_polygon_gen0;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW building_z14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, underground, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_building_polygon;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW building_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM building_z13\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM building_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION building_is_underground(level INTEGER) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     IF level >= 1 THEN\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'true';\n\u001b[36mimport-sql_1            |\u001b[0m     ELSE\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'false';\n\u001b[36mimport-sql_1            |\u001b[0m     END IF;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW housenum_label_z14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, house_num\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_housenumber_point\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, house_num\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_housenumber_polygon;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW housenum_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM housenum_label_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_z5toz6 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE landuse_class(type) = 'wood';\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_z7toz8 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE landuse_class(type) IN ('wood', 'residential')\n\u001b[36mimport-sql_1            |\u001b[0m       AND st_area(geometry) > 1000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_z9 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE landuse_class(type) IN ('wood', 'residential', 'grass', 'cemetery', 'park', 'school')\n\u001b[36mimport-sql_1            |\u001b[0m       AND st_area(geometry) > 500000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_z10 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE landuse_class(type) IN ('wood', 'residential', 'commercial', 'retail', 'railway', 'industrial', 'grass', 'cemetery', 'park', 'school')\n\u001b[36mimport-sql_1            |\u001b[0m       AND st_area(geometry) > 99000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_z11 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen1\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE landuse_class(type) IN ('wood', 'residential','commercial', 'retail', 'railway', 'industrial', 'military', 'grass', 'cemetery', 'park', 'school', 'hospital')\n\u001b[36mimport-sql_1            |\u001b[0m       AND st_area(geometry) > 50000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_z12 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE landuse_class(type) IN ('wood', 'residential', 'grass','retail', 'railway', 'industrial', 'military', 'cemetery', 'park', 'school', 'hospital')\n\u001b[36mimport-sql_1            |\u001b[0m       AND st_area(geometry) > 10000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_z13toz14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type NOT IN ('wetland', 'marsh', 'swamp', 'bog', 'mud', 'tidalflat', 'national_park', 'nature_reserve', 'protected_area');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_z5toz6\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_z7toz8\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_z9\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_z10\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_z11\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_z12\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_z13toz14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION is_landuse_overlay(type TEXT)\n\u001b[36mimport-sql_1            |\u001b[0m RETURNS BOOLEAN AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m  RETURN type IN ('wetland', 'marsh', 'swamp', 'bog', 'mud', 'tidalflat', 'national_park', 'nature_reserve', 'protected_area');\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_z5 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE is_landuse_overlay(type) AND st_area(geometry) > 300000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_z6 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE is_landuse_overlay(type) AND st_area(geometry) > 100000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_z7 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE is_landuse_overlay(type) AND st_area(geometry) > 20000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_z8 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE is_landuse_overlay(type) AND st_area(geometry) > 6000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_z9 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE is_landuse_overlay(type) AND st_area(geometry) > 2000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_z10 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE is_landuse_overlay(type) AND st_area(geometry) > 500000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_z11toz12 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon_gen1\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE is_landuse_overlay(type);\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_z13toz14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_landuse_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE is_landuse_overlay(type);\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW landuse_overlay_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_overlay_z5\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_overlay_z6\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_overlay_z7\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_overlay_z8\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_overlay_z9\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_overlay_z10\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_overlay_z11toz12\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM landuse_overlay_z13toz14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z3 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry \n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND scalerank IS NOT NULL\n\u001b[36mimport-sql_1            |\u001b[0m       AND scalerank BETWEEN 0 AND 2\n\u001b[36mimport-sql_1            |\u001b[0m       AND type = 'city'\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z4 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry \n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND scalerank IS NOT NULL\n\u001b[36mimport-sql_1            |\u001b[0m       AND scalerank BETWEEN 0 AND 4\n\u001b[36mimport-sql_1            |\u001b[0m       AND type = 'city'\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z5 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND scalerank IS NOT NULL\n\u001b[36mimport-sql_1            |\u001b[0m       AND scalerank BETWEEN 0 AND 7\n\u001b[36mimport-sql_1            |\u001b[0m       AND type = 'city'\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z6toz7 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND type IN ('city', 'town')\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z8 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND type IN ('city', 'town')\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z9 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND type IN ('island', 'aboriginal_lands', 'city', 'town', 'village')\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z10 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND type IN ('island', 'aboriginal_lands', 'city', 'town', 'village', 'suburb')\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z11toz12 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND type IN ('island', 'aboriginal_lands', 'city', 'town', 'village', 'suburb')\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z13 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m       AND type IN ('island', 'islet', 'aboriginal_lands', 'city', 'town', 'village', 'suburb', 'hamlet')\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_z14 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m            type, population, capital, admin_level, scalerank, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_place_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW place_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z4\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z5\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z6toz7\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z8\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z9\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z10\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z11toz12\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z13\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM place_label_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION normalize_scalerank(scalerank INTEGER) RETURNS INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN scalerank >= 9 THEN 9\n\u001b[36mimport-sql_1            |\u001b[0m         ELSE scalerank\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW poi_label_z14 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT * FROM (\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT geometry, id AS osm_id, ref, name, name_en, name_es, name_fr,\n\u001b[36mimport-sql_1            |\u001b[0m         name_de, name_ru, name_zh, type, 0 AS area\n\u001b[36mimport-sql_1            |\u001b[0m         FROM osm_poi_point\n\u001b[36mimport-sql_1            |\u001b[0m         UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m         SELECT geometry, id AS osm_id, ref, name, name_en, name_es, name_fr,\n\u001b[36mimport-sql_1            |\u001b[0m         name_de, name_ru, name_zh, type, area\n\u001b[36mimport-sql_1            |\u001b[0m         FROM osm_poi_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     ) AS poi_geoms\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE name IS NOT NULL AND name <> ''\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW poi_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM poi_label_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION poi_label_localrank(type VARCHAR) RETURNS INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('station', 'subway_entrance', 'park', 'cemetery', 'bank', 'supermarket', 'car', 'library', 'university', 'college', 'police', 'townhall', 'courthouse') THEN 2\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('nature_reserve', 'garden', 'public_building') THEN 3\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('stadium') THEN 90\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('hospital') THEN 100\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('zoo') THEN 200\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('university', 'school', 'college', 'kindergarten') THEN 300\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('supermarket', 'department_store') THEN 400\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('nature_reserve', 'swimming_area') THEN 500\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('attraction') THEN 600\n\u001b[36mimport-sql_1            |\u001b[0m         ELSE 1000\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION poi_label_scalerank(type VARCHAR, area REAL) RETURNS INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN area > 145000 THEN 1\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN area > 12780 THEN 2\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN area > 2960 THEN 3\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('station') THEN 1\n\u001b[36mimport-sql_1            |\u001b[0m         ELSE 4\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION format_type(class VARCHAR) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN REPLACE(INITCAP(class), '', ' ');\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION road_structure(is_tunnel BOOLEAN, is_bridge BOOLEAN, is_ford BOOLEAN) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     IF is_tunnel THEN\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'tunnel';\n\u001b[36mimport-sql_1            |\u001b[0m     ELSIF is_bridge THEN\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'bridge';\n\u001b[36mimport-sql_1            |\u001b[0m     ELSIF is_ford THEN\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'ford';\n\u001b[36mimport-sql_1            |\u001b[0m     ELSE\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'none';\n\u001b[36mimport-sql_1            |\u001b[0m     END IF;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION road_class(type VARCHAR, service VARCHAR, access VARCHAR) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN road_type_class(type) = 'major_rail' AND service IN ('yard', 'siding', 'spur', 'crossover') THEN 'minor_rail'\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN road_type_class(type) = 'street' AND access IN ('no', 'private') THEN 'street_limited'\n\u001b[36mimport-sql_1            |\u001b[0m         ELSE road_type_class(type)\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_z5 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE road_class(type, service, access) IN ('motorway', 'trunk');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_z6toz7 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE road_class(type, service, access) IN ('motorway', 'trunk', 'primary');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_z8toz9 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE road_class(type, service, access) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'major_rail');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_z10 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE road_class(type, service, access) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'tertiary', 'major_rail');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_z11 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE road_class(type, service, access) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'tertiary', 'major_rail', 'street', 'ferry');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_z12 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE road_type_class(type) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'tertiary', 'major_rail', 'street', 'ferry', 'pedestrian', 'service', 'link', 'construction', 'street_limited', 'aerialway');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_z13 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, road_structure(is_tunnel, is_bridge, is_ford) AS structure, z_order\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE road_type_class(type) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'tertiary', 'major_rail', 'street', 'ferry', 'pedestrian', 'service', 'link', 'construction', 'street_limited', 'aerialway', 'track');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_z14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, road_structure(is_tunnel, is_bridge, is_ford) AS structure, z_order\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_z5\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_z6toz7\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_z8toz9\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_z10\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_z11\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_z12\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_z13\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION road_localrank(type VARCHAR) RETURNS INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('motorway') THEN 10\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('trunk') THEN 20\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('primary') THEN 30\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('secondary') THEN 40\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN type IN ('tertiary') THEN 50\n\u001b[36mimport-sql_1            |\u001b[0m         ELSE 100\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION road_type(class VARCHAR, type VARCHAR, construction VARCHAR, tracktype VARCHAR, service VARCHAR) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'construction' THEN road_type_value(class, construction)\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'track' THEN road_type_value(class, tracktype)\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'service' THEN road_type_value(class, service)\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'golf' THEN 'golf'\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class IN ('major_rail', 'minor_rail') THEN 'rail'\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'mtb' THEN 'mountain_bike'\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'aerialway' AND type IN ('gondola', 'mixed_lift', 'chair_lift') THEN road_type_value(class, type)\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'aerialway' AND type = 'cable_car' THEN 'aerialway:cablecar'\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'aerialway' AND type IN ('drag_lift', 't-bar', 'j-bar', 'platter', 'rope_tow', 'zip_line') THEN 'aerialway:drag_lift'\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN class = 'aerialway' AND type IN ('magic_carpet', 'canopy') THEN 'aerialway:magic_carpet'\n\u001b[36mimport-sql_1            |\u001b[0m         ELSE type\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION road_type_value(left_value VARCHAR, right_value VARCHAR) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     IF right_value = '' OR right_value IS NULL THEN\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN left_value;\n\u001b[36mimport-sql_1            |\u001b[0m     ELSE\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN left_value || ':' || right_value;\n\u001b[36mimport-sql_1            |\u001b[0m     END IF;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION road_oneway(oneway INTEGER) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     IF oneway = 1 THEN\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'true';\n\u001b[36mimport-sql_1            |\u001b[0m     ELSE\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'false';\n\u001b[36mimport-sql_1            |\u001b[0m     END IF;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_label_z8toz10 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, oneway, ref, layer, z_order,\n\u001b[36mimport-sql_1            |\u001b[0m            is_tunnel, is_bridge, is_ford, construction, tracktype, service, access,\n\u001b[36mimport-sql_1            |\u001b[0m            name, name_fr, name_en, name_de, name_es, name_ru, name_zh, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type IN ('motorway')\n\u001b[36mimport-sql_1            |\u001b[0m       AND ref <> '';\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_label_z11 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, oneway, ref, layer, z_order,\n\u001b[36mimport-sql_1            |\u001b[0m            is_tunnel, is_bridge, is_ford, construction, tracktype, service, access,\n\u001b[36mimport-sql_1            |\u001b[0m            name, name_fr, name_en, name_de, name_es, name_ru, name_zh, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type IN ('motorway', 'motorway_link', 'primary', 'primary_link', 'trunk', 'trunk_link', 'secondary', 'secondary_link')\n\u001b[36mimport-sql_1            |\u001b[0m       AND (name <> '' OR ref <> '');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_label_z12toz13 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, oneway, ref, layer, z_order,\n\u001b[36mimport-sql_1            |\u001b[0m            is_tunnel, is_bridge, is_ford, construction, tracktype, service, access,\n\u001b[36mimport-sql_1            |\u001b[0m            name, name_fr, name_en, name_de, name_es, name_ru, name_zh, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type IN ('motorway', 'motorway_link', 'primary', 'primary_link', 'trunk', 'trunk_link', 'secondary', 'secondary_link',\n\u001b[36mimport-sql_1            |\u001b[0m         'tertiary', 'tertiary_link', 'residential', 'unclassified', 'living_street', 'construction', 'rail', 'monorail', 'narrow_gauge', 'subway', 'tram')\n\u001b[36mimport-sql_1            |\u001b[0m       AND name <> '';\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_label_z14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, type, oneway, ref, layer, z_order,\n\u001b[36mimport-sql_1            |\u001b[0m            is_tunnel, is_bridge, is_ford, construction, tracktype, service, access,\n\u001b[36mimport-sql_1            |\u001b[0m            name, name_fr, name_en, name_de, name_es, name_ru, name_zh, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_road_geometry\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type IN ('motorway', 'motorway_link', 'primary', 'primary_link', 'trunk', 'trunk_link', 'secondary', 'secondary_link',\n\u001b[36mimport-sql_1            |\u001b[0m         'tertiary', 'tertiary_link', 'residential', 'unclassified', 'living_street', 'construction', 'rail', 'monorail',\n\u001b[36mimport-sql_1            |\u001b[0m         'narrow_gauge', 'subway', 'tram', 'service', 'track', 'driveway', 'path', 'cycleway', 'ski', 'steps', 'bridleway', 'footway', 'funicular', 'light_rail', 'preserved')\n\u001b[36mimport-sql_1            |\u001b[0m       AND name <> '';\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW road_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_label_z8toz10\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_label_z11\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_label_z12toz13\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM road_label_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_z0 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_110m_ocean\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_110m_lakes;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_z1 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_50m_ocean\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_110m_lakes;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_z2toz3 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_ocean\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_50m_lakes;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_z4 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_ocean_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geom AS geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM ne_10m_lakes;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_z5toz7 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_ocean_polygon_gen0\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_polygon_gen1;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_z8toz10 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_ocean_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_polygon_gen1;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_z11toz12 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geometry, 0 AS area\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_ocean_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, area\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE area >= 15000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_z13toz14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT 0 AS osm_id, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_ocean_polygon\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_polygon;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_z0\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_z1\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_z2toz3\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_z4\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_z5toz7\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_z8toz10\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_z11toz12\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_z13toz14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_label_z10 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, area, name, name_en, name_es, name_fr, name_de, name_ru, name_zh\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE area >= 100000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_label_z11 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, area, name, name_en, name_es, name_fr, name_de, name_ru, name_zh\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE area >= 40000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_label_z12 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, area, name, name_en, name_es, name_fr, name_de, name_ru, name_zh\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE area >= 20000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_label_z13 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, area, name, name_en, name_es, name_fr, name_de, name_ru, name_zh\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE area >= 10000000;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_label_z14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, area, name, name_en, name_es, name_fr, name_de, name_ru, name_zh\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_point;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW water_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_label_z10\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_label_z11\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_label_z12\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_label_z13\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM water_label_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW waterway_z7toz9 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry  \n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type = 'river';\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW waterway_z10toz12 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type IN ('river', 'canal');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW waterway_z13 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type IN ('river', 'canal', 'stream', 'drain');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW waterway_z14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_linestring;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW waterway_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM waterway_z7toz9\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM waterway_z10toz12\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM waterway_z13\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM waterway_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW waterway_label_z13 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_linestring\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE type IN ('river', 'canal');\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW waterway_label_z14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_water_linestring;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW waterway_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM waterway_label_z13\n\u001b[36mimport-sql_1            |\u001b[0m     UNION\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM waterway_label_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW mountain_peak_label_z12toz14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, elevation_m, \n\u001b[36mimport-sql_1            |\u001b[0m            name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_mountain_peak_point;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW mountain_peak_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM mountain_peak_label_z12toz14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION meter_to_feet(meter INTEGER) RETURNS INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN round(meter * 3.28084);\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION mountain_peak_type(type VARCHAR) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     IF type = 'volcano' THEN\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN type;\n\u001b[36mimport-sql_1            |\u001b[0m     ELSE\n\u001b[36mimport-sql_1            |\u001b[0m         RETURN 'mountain';\n\u001b[36mimport-sql_1            |\u001b[0m     END IF;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW airport_label_z9toz14 AS\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, name, name_en, name_es, name_fr, name_de, name_ru, name_zh, \n\u001b[36mimport-sql_1            |\u001b[0m         iata, ref, icao, faa, aerodrome, type, kind, 0 AS area\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_airport_point\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, geometry, name, name_en, name_es, name_fr, name_de,\n\u001b[36mimport-sql_1            |\u001b[0m         name_ru, name_zh, iata, ref, icao, faa, aerodrome, type, kind, area\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_airport_polygon;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW airport_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM airport_label_z9toz14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION airport_label_scalerank(maki VARCHAR, area REAL, aerodrome VARCHAR) RETURNS INTEGER\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN (maki = 'airport' AND area >= 300000) OR aerodrome = 'international' THEN 1\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN maki = 'airport' AND area < 300000 THEN 2\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN maki = 'airfield' AND area >= 145000 THEN 3\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN maki = 'airfield' AND area < 145000 THEN 4\n\u001b[36mimport-sql_1            |\u001b[0m         ELSE 4\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE FUNCTION airport_label_class(kind VARCHAR, type VARCHAR) RETURNS VARCHAR\n\u001b[36mimport-sql_1            |\u001b[0m AS $$\n\u001b[36mimport-sql_1            |\u001b[0m BEGIN\n\u001b[36mimport-sql_1            |\u001b[0m     RETURN CASE\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN kind = 'heliport' THEN 'heliport'\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN kind = 'aerodrome' AND type IN ('public', 'Public') THEN 'airport'\n\u001b[36mimport-sql_1            |\u001b[0m         WHEN kind = 'aerodrome' AND type IN ('private', 'Private', 'military/public', 'Military/Public') THEN 'airfield'\n\u001b[36mimport-sql_1            |\u001b[0m         ELSE 'airfield'\n\u001b[36mimport-sql_1            |\u001b[0m     END;\n\u001b[36mimport-sql_1            |\u001b[0m END;\n\u001b[36mimport-sql_1            |\u001b[0m $$ LANGUAGE plpgsql IMMUTABLE;\n\u001b[36mimport-sql_1            |\u001b[0m CREATE FUNCTION\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW rail_station_label_z14 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_rail_station_point\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW rail_station_label_z13 AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT id AS osm_id, name, name_fr, name_en, name_de, name_es, name_ru, name_zh, type, geometry\n\u001b[36mimport-sql_1            |\u001b[0m     FROM osm_rail_station_point\n\u001b[36mimport-sql_1            |\u001b[0m     WHERE rail_station_class(type) = 'rail'\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m CREATE OR REPLACE VIEW rail_station_label_layer AS (\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM rail_station_label_z13\n\u001b[36mimport-sql_1            |\u001b[0m     UNION ALL\n\u001b[36mimport-sql_1            |\u001b[0m     SELECT osm_id FROM rail_station_label_z14\n\u001b[36mimport-sql_1            |\u001b[0m );\n\u001b[36mimport-sql_1            |\u001b[0m CREATE VIEW\n\u001b[36mimport-sql_1            |\u001b[0m Omitting index creation in osm\n\u001b[36mosm2vectortiles_import-sql_1 exited with code 0\n\u001b[0m\u001b[1m\u001b[3m%\u001b[23m\u001b[1m\u001b[0m                                                                                                                                                                                                                                                                               \n\u001bk..m2vectortiles\u001b\\\n\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\n\u001bM\u001bM\u001b[?2004h\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\u001b[3mdocker-compose run \\\u001b[23m\n\u001b[3m  -e BBOX=\"8.34,47.27,8.75,47.53\" \\\u001b[23m\u001b[K\n\u001b[3m  -e MIN_ZOOM=\"8\" \\\u001b[23m\u001b[K\n\u001b[3m  -e MAX_ZOOM=\"14\" \\\u001b[23m\u001b[K\n\u001b[3m  export\u001b[23m\u001b[K\u001b[4A\b\b\b\b\u001b[23md\u001b[23mo\u001b[23mc\u001b[23mk\u001b[23me\u001b[23mr\u001b[23m-\u001b[23mc\u001b[23mo\u001b[23mm\u001b[23mp\u001b[23mo\u001b[23ms\u001b[23me\u001b[23m \u001b[23mr\u001b[23mu\u001b[23mn\u001b[23m \u001b[23m\\\u001b[1B\n\u001b[23m \u001b[23m \u001b[23m-\u001b[23me\u001b[23m \u001b[23mB\u001b[23mB\u001b[23mO\u001b[23mX\u001b[23m=\u001b[23m\"\u001b[23m8\u001b[23m.\u001b[23m3\u001b[23m4\u001b[23m,\u001b[23m4\u001b[23m7\u001b[23m.\u001b[23m2\u001b[23m7\u001b[23m,\u001b[23m8\u001b[23m.\u001b[23m7\u001b[23m5\u001b[23m,\u001b[23m4\u001b[23m7\u001b[23m.\u001b[23m5\u001b[23m3\u001b[23m\"\u001b[23m \u001b[23m\\\u001b[1B\n\u001b[23m \u001b[23m \u001b[23m-\u001b[23me\u001b[23m \u001b[23mM\u001b[23mI\u001b[23mN\u001b[23m_\u001b[23mZ\u001b[23mO\u001b[23mO\u001b[23mM\u001b[23m=\u001b[23m\"\u001b[23m8\u001b[23m\"\u001b[23m \u001b[23m\\\u001b[1B\n\u001b[23m \u001b[23m \u001b[23m-\u001b[23me\u001b[23m \u001b[23mM\u001b[23mA\u001b[23mX\u001b[23m_\u001b[23mZ\u001b[23mO\u001b[23mO\u001b[23mM\u001b[23m=\u001b[23m\"\u001b[23m1\u001b[23m4\u001b[23m\"\u001b[23m \u001b[23m\\\u001b[1B\n\u001b[23m \u001b[23m \u001b[23me\u001b[23mx\u001b[23mp\u001b[23mo\u001b[23mr\u001b[23mt\u001b[?1l\u001b>\u001b[?2004l\n\u001bkdocker-compose\u001b\\\u001b[33mWARNING\u001b[0m: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\n/usr/local/lib/node_modules/tilelive/bin/tilelive-copy:100\n        if (err) throw err;\n                 ^\nError: Postgis Plugin: ERROR:  relation \"admin_z1toz2\" does not exist\nLINE 9:     FROM admin_z1toz2\n                 ^\nin executeQuery Full sql was: 'SELECT * FROM (\n  SELECT osm_ids2mbid(osm_id, false) AS osm_id, geometry, admin_level, disputed, maritime\n  FROM (\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z0\n    WHERE z(3.40282e+38) = 0\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z1toz2\n    WHERE z(3.40282e+38) BETWEEN 1 AND 2\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z3\n    WHERE z(3.40282e+38) = 3\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z4toz5\n    WHERE z(3.40282e+38) BETWEEN 4 AND 5\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z6\n    WHERE z(3.40282e+38) = 6\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z7toz14\n    WHERE z(3.40282e+38) BETWEEN 7 AND 14\n  ) AS admin\n  WHERE geometry && ST_SetSRID('BOX3D(-3.402823466385289e+38 -3.402823466385289e+38,3.402823466385289e+38 3.402823466385289e+38)'::box3d, 3857)\n) AS data LIMIT 0'\nat Error (native)\nat /usr/local/lib/node_modules/tilelive-tmsource/index.js:111:18\nat Array.map (native)\nat normalize (/usr/local/lib/node_modules/tilelive-tmsource/index.js:100:35)\nat /usr/local/lib/node_modules/tilelive-tmsource/index.js:185:19\nat tryToString (fs.js:414:3)\nat FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:401:12)\n\n\u001b[1m\u001b[3m%\u001b[23m\u001b[1m\u001b[0m                                                                                                                                                                                                                                                                               \n\u001bk..m2vectortiles\u001b\\\n\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\n\u001bM\u001bM\u001b[?2004h\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267Dd\bdocker-compose up export\u001b[?1l\u001b>\u001b[?2004l\n\u001bkdocker-compose\u001b\\\u001b[33mWARNING\u001b[0m: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\nosm2vectortiles_postgis_1 is up-to-date\nCreating osm2vectortiles_export_1\nAttaching to osm2vectortiles_export_1\n\u001b[36mexport_1                |\u001b[0m /usr/local/lib/node_modules/tilelive/bin/tilelive-copy:47\n\u001b[36mexport_1                |\u001b[0m argv.bounds = argv.bounds !== undefined ? argv.bounds.split(',').map(function(v) { return parseFloat(v); }) : undefined;\n\u001b[36mexport_1                |\u001b[0m                                                       ^\n\u001b[36mexport_1                |\u001b[0m \n\u001b[36mexport_1                |\u001b[0m TypeError: argv.bounds.split is not a function\n\u001b[36mexport_1                |\u001b[0m     at Object. (/usr/local/lib/node_modules/tilelive/bin/tilelive-copy:47:55)\n\u001b[36mexport_1                |\u001b[0m     at Module._compile (module.js:413:34)\n\u001b[36mexport_1                |\u001b[0m     at Object.Module._extensions..js (module.js:422:10)\n\u001b[36mexport_1                |\u001b[0m     at Module.load (module.js:357:32)\n\u001b[36mexport_1                |\u001b[0m     at Function.Module._load (module.js:314:12)\n\u001b[36mexport_1                |\u001b[0m     at Function.Module.runMain (module.js:447:10)\n\u001b[36mexport_1                |\u001b[0m     at startup (node.js:146:18)\n\u001b[36mexport_1                |\u001b[0m     at node.js:404:3\n\u001b[36mosm2vectortiles_export_1 exited with code 1\n\u001b[0m\u001b[1m\u001b[3m%\u001b[23m\u001b[1m\u001b[0m                                                                                                                                                                                                                                                                               \n\u001bk..m2vectortiles\u001b\\\n\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\n\u001bM\u001bM\u001b[?2004h\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267Dd\bdocker \b-compose up export\u001b[?1l\u001b>\u001b[?2004l\n\u001bkdocker-compose\u001b\\\u001b[33mWARNING\u001b[0m: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\n\u001b[33mWARNING\u001b[0m: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\nosm2vectortiles_postgis_1 is up-to-date\nRecreating osm2vectortiles_export_1\nAttaching to osm2vectortiles_export_1\n\u001b[36mexport_1                |\u001b[0m /usr/local/lib/node_modules/tilelive/bin/tilelive-copy:100\n\u001b[36mexport_1                |\u001b[0m         if (err) throw err;\n\u001b[36mexport_1                |\u001b[0m                  ^\n\u001b[36mexport_1                |\u001b[0m \n\u001b[36mexport_1                |\u001b[0m Error: Postgis Plugin: ERROR:  relation \"admin_z1toz2\" does not exist\n\u001b[36mexport_1                |\u001b[0m LINE 9:     FROM admin_z1toz2\n\u001b[36mexport_1                |\u001b[0m                  ^\n\u001b[36mexport_1                |\u001b[0m in executeQuery Full sql was: 'SELECT * FROM (\n\u001b[36mexport_1                |\u001b[0m   SELECT osm_ids2mbid(osm_id, false) AS osm_id, geometry, admin_level, disputed, maritime\n\u001b[36mexport_1                |\u001b[0m   FROM (\n\u001b[36mexport_1                |\u001b[0m     SELECT osm_id, geometry, admin_level, disputed, maritime\n\u001b[36mexport_1                |\u001b[0m     FROM admin_z0\n\u001b[36mexport_1                |\u001b[0m     WHERE z(3.40282e+38) = 0\n\u001b[36mexport_1                |\u001b[0m     UNION ALL\n\u001b[36mexport_1                |\u001b[0m     SELECT osm_id, geometry, admin_level, disputed, maritime\n\u001b[36mexport_1                |\u001b[0m     FROM admin_z1toz2\n\u001b[36mexport_1                |\u001b[0m     WHERE z(3.40282e+38) BETWEEN 1 AND 2\n\u001b[36mexport_1                |\u001b[0m     UNION ALL\n\u001b[36mexport_1                |\u001b[0m     SELECT osm_id, geometry, admin_level, disputed, maritime\n\u001b[36mexport_1                |\u001b[0m     FROM admin_z3\n\u001b[36mexport_1                |\u001b[0m     WHERE z(3.40282e+38) = 3\n\u001b[36mexport_1                |\u001b[0m     UNION ALL\n\u001b[36mexport_1                |\u001b[0m     SELECT osm_id, geometry, admin_level, disputed, maritime\n\u001b[36mexport_1                |\u001b[0m     FROM admin_z4toz5\n\u001b[36mexport_1                |\u001b[0m     WHERE z(3.40282e+38) BETWEEN 4 AND 5\n\u001b[36mexport_1                |\u001b[0m     UNION ALL\n\u001b[36mexport_1                |\u001b[0m     SELECT osm_id, geometry, admin_level, disputed, maritime\n\u001b[36mexport_1                |\u001b[0m     FROM admin_z6\n\u001b[36mexport_1                |\u001b[0m     WHERE z(3.40282e+38) = 6\n\u001b[36mexport_1                |\u001b[0m     UNION ALL\n\u001b[36mexport_1                |\u001b[0m     SELECT osm_id, geometry, admin_level, disputed, maritime\n\u001b[36mexport_1                |\u001b[0m     FROM admin_z7toz14\n\u001b[36mexport_1                |\u001b[0m     WHERE z(3.40282e+38) BETWEEN 7 AND 14\n\u001b[36mexport_1                |\u001b[0m   ) AS admin\n\u001b[36mexport_1                |\u001b[0m   WHERE geometry && ST_SetSRID('BOX3D(-3.402823466385289e+38 -3.402823466385289e+38,3.402823466385289e+38 3.402823466385289e+38)'::box3d, 3857)\n\u001b[36mexport_1                |\u001b[0m ) AS data LIMIT 0'\n\u001b[36mexport_1                |\u001b[0m \n\u001b[36mexport_1                |\u001b[0m     at Error (native)\n\u001b[36mexport_1                |\u001b[0m     at /usr/local/lib/node_modules/tilelive-tmsource/index.js:111:18\n\u001b[36mexport_1                |\u001b[0m     at Array.map (native)\n\u001b[36mexport_1                |\u001b[0m     at normalize (/usr/local/lib/node_modules/tilelive-tmsource/index.js:100:35)\n\u001b[36mexport_1                |\u001b[0m     at /usr/local/lib/node_modules/tilelive-tmsource/index.js:185:19\n\u001b[36mexport_1                |\u001b[0m     at tryToString (fs.js:414:3)\n\u001b[36mexport_1                |\u001b[0m     at FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:401:12)\n\u001b[36mosm2vectortiles_export_1 exited with code 1\n\u001b[0m\u001b[1m\u001b[3m%\u001b[23m\u001b[1m\u001b[0m                                                                                                                                                                                                                                                                               \n\u001bk..m2vectortiles\u001b\\\n\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\n\u001bM\u001bM\u001b[?2004h\u001b[0m\u001b[23m\u001b[24m\u001b[J\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[1m\u001b[32mmattro\u001b[1m\u001b[34m@\u001b[1m\u001b[36mMatts-Mac-mini\u001b[1m\u001b[32m \u001b[0m\u001b[33m\u001b[40m~/workspace/osm2vectortiles\u001b[1m\u001b[32m [\u001b[1m\u001b[34mmaster \u001b[31m*\u001b[39m\u001b[49m\u001b[0m\u001b[39m\u001b[49m\u001b[0m\u001b[40m\u001b[1m\u001b[32m]\u001b[K\u001b[39m\u001b[49m\u001b[0m\n\u001b[40m\u001b[34m\u00b1\u001b[39m\u001b[49m\u001b[0m\u001b[40m %\u001b[39m\u001b[49m\u001b[0m \u001b[K\u001b[255C-- INSERT --\u001b[267D\u001b[?2004l\nScript done on Tue Oct 18 10:45:47 2016\n``\n. And for the record this is on master and I definitely ranimport-sql`. It didn't look like it had any errors.\n. If that script is too hard to read, I can do it again in a different terminal that has less fancy color stuff.\n. I switched to a new CentOS 7 machine and did a fresh install of docker and\nit ended up working fine on master. My guess right now is that I've got\nsome installation issue on Mac OS, so I'm going to try to fix that and get\nback to you.\nOn Tue, Oct 18, 2016, 11:23 AM ImreSamu notifications@github.com wrote:\n\n@mr https://github.com/mr\nthanks,\n- I prefer the logs - without color code :) easier to read\n  - you can create a gist [ https://gist.github.com/ ] and just link\n    the log ...\nmy problem :\n- I am using : Ubuntu + simple terminal - and I can't replicate\n- I don't know Kitematic ( Are you using the latest version? )\nCan you access a Linux machine ( with the latest docker + docker-compose\ninside ) - and re-test ?\n- ( I need to know - this is a Kitematic problem - or general )\nI will try to create some debugging test case ... but need a little time\n...\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/443#issuecomment-254542495,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACqSgDvMT4OykK-M5CkD0LQTNZqgc8zsks5q1ORjgaJpZM4KLTn-\n.\n. I'd like to +1 this issue. I've been trying to do almost the exact same thing. I put a normal osmchange file in the import directory and just ran import-osm-diff. If there's more that I should do to pull in changes, please let me know and we can maybe write some documentation on it.\n\nEDIT: Also if you could explain how to apply your fix here (and what that does exactly) that would be awesome!. ",
    "fitsoft": "Hi Lukas, Manuel,\nThanks for the quick turnaround!\nNow I passed that but even if I have a zoom range of 8 to 14, I get a PostGIS error: \"relation \"landuse_z5toz8\" does not exist\"\nAny hint on this!?\nThanks!\n. I've done that already with exit code 0 ...\n. doing it right now\n. Should I just repeat the export step or I would need to start from the beginning?\n. Ops! Same error:\nError: Postgis Plugin: ERROR:  relation \"landuse_z5toz8\" does not exist\n. Hello Manuel, \nIt did bring about 33 files changed. It did work now! Awesome! Thanks!\n. I have a short question: if I want to add new regions can I just repeat the steps from import-osm on?\n. Hi Manuel, thanks for the quick reply! By looking at the file osm2vectortiles/osm2vectortiles.tm2source/data.yml where the buffer settings seem to be, I don't see any buffer-size greater than 256 but in the tile I showed before there are coordinates in the -2000 range for example or above 5000, well above the 256 maximum. \nMaybe I should consider that the 256 may come from a lower zoom level and duplicate in size as I \"zoom in\"? \nThanks,\nClara\n. Hello Lukas, \nThen in the esample you just gave I could have a coordinate take roughly values in the interval [-2048, 4096 + 2048] ?\nThanks,\nClara\n. ",
    "burmisov": "@manuelroth Many thanks for clarification!\nThen maybe I'll try the process once again and come up with specific issues if they still arise.\nRegarding the hardware thing - I guess maybe the entire planet is somewhat too large a task for an unexperienced stranger, but a city similar to Zurich would be a good place to start for hardware spec estimation.\n. ",
    "nebulon42": "\nWhen working with the tm2source we usually work with Mapbox Studio not the YAML format directly.\nAnd then Mapbox Studio will just overwrite the YAML values again.\n\nAh yes, I thought that there might be a catch regarding Mapbox Studio. No, my setup will very likely not include Mapbox Studio. While I appreciate all the FOSS efforts of Mapbox and think that building a SaaS platform is a legitimate business decision I'm not in favour of using a design tool for which I need a Mapbox account.\nI didn't want to work with MBTiles out of space and performance reasons when generating them, so I serve up the vector source directly from the database using Tessera (https://github.com/mojodna/tessera). Because you have such a nice workflow for importing the data I'm using the postgis Docker container. I then connect the vector tiles to Mapbox GL JS. For styling I will likely use Glug (https://github.com/systemed/glug), but I'm just getting started on it.\nI could of course do some (automated) find/replace before using the vector source, so if you decide that this PR is out of scope for you I don't mind. Since I'm new to vector tiles, if you can think of some better way this could fit within your project I also appreciate any hints.\n. > I guess you miss a lot of documentation there?\nYou have actually already more documentation than most other projects. :)\n\nYou are just using the workflow of importing water/natural earth/etc or the tm2source project as well?\n\nI'm using everything. It looks like you have put a lot of work and thought into that and I'm looking forward to work with it. Especially since I had in mind creating a custom database backend for my raster styling work since quite some time now.\n\nHere you go if you want to use that in the personal project. For osm2vectortiles this is already implemented for export and you can use the same for your tessera Docker container for example.\n\nCool, thanks! Will try that.\nP.S. I saw that you will be at FOSSGIS or at least @manuelroth will be, see you there.\n. ",
    "AbrahamLopez10": "You're right, I copied the bright-v8 style from your website and it's now working:\nhttp://dev.aplimovil.net/osm2vt/#13.96/25.6791/-100.3050\nThe issue was that I took the example from the mapbox-gl-styles repo:\nhttps://github.com/osm2vectortiles/mapbox-gl-styles\n...and it seems it's missing the v8 style.\nIf I can be of help, let me know if I should create a PR for that repo with the v8 style added and a sample index.html file using it.\nThanks!\n. I'm not sure if this is an issue, but I cloned the mapbox-gl-styles repo fresh from Github to follow the readme instructions, installed tileserver-vector and downloaded the .mbtiles for my country, started tileserver-vector fine, created an index.html in the repo folder pointing to the bright-v9 style, but the map appears empty and no tiles are being served:\n\nChecked tileserver-vector console output and it's clean (no activity or errors). Maybe my browser (Firefox Mac) isn't recognizing the mbtiles:// protocol?\nWhat else could be preventing the map from rendering locally?\n. @manuelroth OK, will stay tuned, thanks.\n@lukasmartinelli I pointed it to the streets-v9.json style, which has the mbtiles:// URL, but it showed blank with no errors. I then changed the URL to http://localhost:8080/index.json, but it seems the JSON file is incomplete (at least compared to the index.json file served by klokantech.tileserver.com) and then it did throw some errors in the browser console, and the map was neither shown.\nWhat's the easiest way I can start serving tiles? Just with TileServer-PHP? I'm primarily a PHP developer and I love the language, but I know it's limits, hence why I was looking to use tileserver-vector, as Node.js is much better suited for this task.\nThanks in advance, and great work!\n-- Abraham\n. @stirringhalo the streets-v8.json and bright-v8.json styles worked for me perfectly, here's an example:\nStreets: http://dev.aplimovil.net/mapbox-gl-styles/\nBright: http://dev.aplimovil.net/osm2vt/\nI created a temporary fork with a sample index.html and just the v8 styles as per Manuel's notes regarding the incompatibility with v9 styles (Mapbox Streets 7), this is what I have running in the first link:\nhttps://github.com/aplimovil/mapbox-gl-styles\nIt's using the vector tiles CDN provided by KlokanTech, haven't tried it yet with TileServer-PHP component though, but will do so in order to deploy the maps in my production project.\nHopefully when these repos get updated with the latest Mapbox Streets 7 compatible vector tiles and the tilevector-server (Node.js) instructions, I'll discard this fork.\n. ",
    "mojodna": "tilelive-tmsource@0.5.0 now generates v2 vector tiles. Thanks @hannesj for the PR (and apologies for not merging it sooner).\n. ",
    "davidar": "This also causes some rendering artefacts with recent versions of mapbox-gl-js (mapbox/mapbox-gl-js#1606)\n. Is this rendering available to download yet? http://osm2vectortiles.org/downloads/ still seems to link to the old MVTv1 tiles.\n. @hannesj This clause is also interesting:\n\n4.6 Access to Derivative Databases. If You Publicly Use a Derivative\nDatabase or a Produced Work from a Derivative Database, You must also\noffer to recipients of the Derivative Database or Produced Work a copy\nin a machine readable form of:\na. The entire Derivative Database; or\nb. A file containing all of the alterations made to the Database or\nthe method of making the alterations to the Database (such as an\nalgorithm), including any additional Contents, that make up all the\ndifferences between the Database and the Derivative Database.\nThe Derivative Database (under a.) or alteration file (under b.) must be\navailable at no more than a reasonable production cost for physical\ndistributions and free of charge if distributed over the internet.\n\n@michaelsteffen What if I were to request a copy of the entire Mapbox Streets database (in particular, the collection of vector tiles) or a machine readable form of the method of making the alterations to the OSM database (to produce the collection of vector tiles)?\n. It's interesting that Mapbox would be claiming copyright over \"look and feel\", given the history of such claims.\n. FWIW, I don't mind if this PR is closed, but I agree with @pnorman that it would probably be helpful to be more explicit about data provenance given that mapbox has decided to start spreading legal FUD.\n. \"Please copy our data model!\" - https://mapzen.com/blog/v1-vector-tile-service/\n. ",
    "mnutt": "I'm still seeing this in the 2016-06-26 update:\n\n(this map is -83.003556,42.27467,10)\n. @lukasmartinelli just wanted to make sure you saw this. Is there a potential fix that I can explore, or is it a matter of extending the timeout?\n. ",
    "revenger73": "The old file had it's own issue's like not styling airports nicely.\nCan we somehow change the styling and have it render correctly. I don't know with type the roads are and therefore unable to change the style (if possible anyway).\nRemko\n\nOp 26 mei 2016 om 16:30 heeft Lukas Martinelli notifications@github.com het volgende geschreven:\nSecondary roads (dutch N-roads) are not styled in tm2 OSM-Bright and street tiles with the new planet.mbtile (they did style correctly with the old world.mbtile)\nWe no longer support rendering raster tiles with the new planet or differently said we no longer tested whether it looks good.\nI know for some people this will be a drawback but you can continue using the old planet file.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. We have several web applications build with ESRI JavaScript API. So using a different client library is not a solution.\n\nHow can we serve on-premise mbtiles (no internet access), and use them as correctly styled tiles inside the ESRI JavaScript API?\n\nOp 26 mei 2016 om 17:23 heeft Manuel Roth notifications@github.com het volgende geschreven:\nPlease check out our new tutorial. It explaines how to set up a basic tileserver which serves the vector tiles, mapbox gl styles(bright, streets, basic, dark, light), fonts, sprites and renders the map inside your browser with Mapbox GL JS.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Thanks for the background information on the decision, and the links.\n. \n",
    "sabas": "I'll try, I'm not so good in NodeJS :-)\n. ",
    "pertile": "I downloaded a pbf around  my city\nYou are right, my problem is the pbf, I tried with the pbf suggested in the page and it works, thanks!\nEl jun. 17, 2016 17:28, \"stirringhalo\" notifications@github.com escribi\u00f3:\n\nWhich osm.pbf are you using?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/353#issuecomment-226873516,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AEPjonZu4Sc8NZTTILncAGP8aXg60sWzks5qMwNxgaJpZM4I4qKG\n.\n. I will try with http://download.geofabrik.de/south-america/argentina-latest.osm.pbf. When import-osm ends, is there a database I should see in my postgresql?\n. Output is exactly the same after I run\nsudo docker-compose rm pgdata\n\nI tried removing postgreSQL, PostGIS, data directory, cloning again this project but when I run_sudo docker-compose up postgis_ it throws the same error.\n. ",
    "clkao": "@lukasmartinelli It seems the extracts here for Taiwan is empty: https://osm2vectortiles-downloads.os.zhdk.cloud.switch.ch/v2.0/extracts/taiwan.mbtiles\n. I just noticed that mapbox provides undocumented iso_3166_2 which can be used in cartocss to match and provide custom shield.\nSo instead of a cumbersome plpgsql function to derive the sheild-name, we can start with providing the iso_3166_2 and iso_3166_1 field, and additionally the network field from the highway relation.\n. @lukasmartinelli did mapbox say something about the licensing issues?  I thought they are rather liberal on their works.\nre iso value: yes, it's to be derived from country or admin boundary that the roads are within.\n. This is apparently fixed now.\n. ",
    "clintharris": "Update: streets-v9.json can be found here: https://github.com/mapbox/mapbox-gl-styles/tree/v9/styles\n. Ah, I see now that these files were removed due to copyright issues as part of this commit.\nNot sure if the preferred resolution is to modify the code to no longer reference those styles or to add documentation with info about about the need to independently retrieve those styles...\n. @lukasmartinelli Thanks for the quick fix!\n. ",
    "karussell": "Now I got a bit further via downloading the bright.json and directly specifying the https URL there (three changes necessary) and furthermore changing the nginx config to:\nlocation /tiles-test {\n                proxy_pass      http://localhost:8080;\n                index index.html;\n                proxy_redirect  off;\n                rewrite ^/tiles-test(.*) $1 break;\n        }\nStill it says 'Blocked loading mixed active content \"http://localhost:8080/data/osm2vectortiles/0/0/0.pbf\"'. Where can I change this URL?\n. ",
    "KoAi": "I have some rendering problem too with last planet extract v2.0/planet.mbtiles of Monday, 11 July 2016 at 20:5 UTC\nI use previous one and it works again (file is greater)\n. ",
    "hellkama": "I downloaded the latest planet file a couple of times, but every download seems to be missing parts of maps. At least deeper zoom levels around Saint Peters are missing, the server returns 404.\n. As I am more interested in trying to use the tileset in a project than the actual process of generating the tiles I feel this would be nice way to proceed.\n. As far as i know the drawn view depends on zoom level and used style. If you zoom closer maybe you get the dashes and the country name?\nIts possible to generate custom styles which draw some elements of map differently or leave stuff not rendered.\n. I am not associated with the project nor do I have any legal degree, but I have to agree with Lukas.\nFrom my understanding the project implements the conversion of OpenStreetMap data to MBTiles format. The MBTiles format by license allows this type of use.\n. ",
    "mbrickn": "Thank you very much! I will be sure to use proper tabs next time.\n. ",
    "brianshaler": "For what it's worth, I downloaded planet.mbtiles that day, am experiencing the same issue described in the email, 404s in northern Europe starting at zoom level >10. Interestingly, my checksum matches above ('9821f7be1100f730165c6b394327ae46').\n. Waiting on md5sum on the new download, but what I downloaded last night appears to the same as what I downloaded on the 14th (both files show same number of bytes and date modified matches upload date)\n57184074752 Jul 14 14:57 planet.mbtiles\n. ",
    "FernsPaanakker": "I tested the Full Planet generated on Tuesday, 26 July 2016 at 19:24 UTC.\nBut the md5sum is still 9821f7be1100f730165c6b394327ae46 so I guess the planet.mbtiles isn't really updated yet.\nJust for reference some examples from the tileserver-gl-light logging:\nGET /data/osm2vectortiles/9/262/168.pbf 404 10.164 ms - 19\nGET /data/osm2vectortiles/9/263/168.pbf 404 10.459 ms - 19\nGET /data/osm2vectortiles/9/263/167.pbf 200 48.751 ms - 44976\nGET /data/osm2vectortiles/9/262/167.pbf 200 49.017 ms - 41364\nGET /data/osm2vectortiles/10/525/336.pbf 404 10.535 ms - 19\nGET /data/osm2vectortiles/10/526/336.pbf 404 13.894 ms - 19\nGET /data/osm2vectortiles/10/526/337.pbf 404 13.877 ms - 19\nGET /data/osm2vectortiles/10/525/337.pbf 404 13.666 ms - 19\nGET /data/osm2vectortiles/10/524/336.pbf 404 3.172 ms - 19\nGET /data/osm2vectortiles/10/524/337.pbf 404 4.373 ms - 19\n. ",
    "daniyel": "Hi. Today I downloaded switzerland.mbtiles and I am using it with tileserver-gl, I am getting only 200 and 304 responses, but I am getting funny rendering:\n\n\n\n. ",
    "ayratinirani": "Is there any way to serve vector or png maps by php and js completely\noffline?\n\u062f\u0631 \u062a\u0627\u0631\u06cc\u062e \u06f2\u06f5 \u0698\u0648\u0626\u06cc\u0647\u0654 \u06f2\u06f0\u06f1\u06f6 \u06f1\u06f2:\u06f2\u06f2 \u0628.\u0638\u060c \"Petr Pridal\" notifications@github.com\n\u0646\u0648\u0634\u062a:\n\nClosed #381\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/381.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/381#event-733177671,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIDn6szRaeQq_ubREjwHW9hZl4Zi8mPmks5qZGs8gaJpZM4JT2QG\n.\n. \n",
    "florianf": "Mhmm, interesting move from MapBox. As far as I can see, the only thing that osm2vectortiles right now uses is the MapBox Streets v7 vector tile format. This format is by large derived of the underlying OSM structure (ODBL licensed) and openly documented by MapBox themselves [1].\nIf your are based in the EU it's even allowed to reverse engineer binaries for interoperability reasons, see Article 6 of the EU directive on the legal protection of computer programs [2].\n[1] https://www.mapbox.com/vector-tiles/mapbox-streets-v7/ \n[2] http://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32009L0024&from=EN\n. @michaelsteffen thank you for your explanation, but some things still aren't clear to me. Please note, I'm not associated directly with this project and do not speak on behalf of any project member. I'm an interested third party and the issue has consequences for me as well.\nYou mention \"tagging schemes and arrangement of the data elements, label placement methods, decisions about prominence and use of features at different zoom levels, iconography decisions, ranking of features\". A good portion of those things are openly documented under https://www.mapbox.com/vector-tiles/mapbox-streets-v7, or directly derived from the underlying OSM database. \nSo from your legal POV third parties are not allowed to produce vector tiles in this exact format (mapbox-streets-v7 vector tiles)?\n. ",
    "michaelsteffen": "@lukasmartinelli - Thanks for prioritizing this.\nOur concern comes from the fact that the project copies (or has attempted to copy) the cartography in the Mapbox Streets vector tiles. This includes choices from among multiple possible data sources for different features, the particular selection of  elements to incorporate from those sources, our tagging schemes and arrangement of the data elements, label placement methods, decisions about prominence and use of features at different zoom levels, iconography decisions, ranking of features, and more.  These are all design decisions that our cartographers have made and refined over the years.\nAs you know, the license we've provided for OSM Bright (BSD for the code, CC-BY SA for the design elements) expressly excludes the Mapbox Streets Vector Tiles and the cartography they contain. We open-licensed OSM Bright to give people who are developing their own vector tiles a simple, a high quality, starting point to build styles for those tiles. The idea has never been a backdoor license to copy our vector tiles.\nIn terms of whether or not this project does copy Mapbox Streets, here are a couple example descriptions from the thesis:\n\n[A] lot of time has been spent making the vector tiles as similar as possible to the ones of Mapbox.\nIn an iterative and time consuming process the mapping and queries were continuously improved until the vector tile output matches the data from Mapbox Streets very closely.\n\nI'm being direct here. But I want to be as clear as possible for your benefit and for that of others who are interested in this project.\nBut let me reiterate that we're impressed by the technical work you've done, and are very supportive of you creating your own cartography and corresponding vector tile pipeline. \n. @lukasmartinelli - :bow:\nReally appreciate the spirit of this comment. \n\nPlease, could Mapbox outline what attributes are critical for the proposal to be accepted?\n\nI know we have a bit of a differing perspective here, but perhaps you can see the challenging nature of this request from my perspective. \nIt as if someone came to an author or a painter or a designer and said \"Hey look, I copied your thing! What -- specifically -- do I need to change to make it my original creation?\"\nThat said, I am appreciative of where you are headed (and I think several others on this thread have expressed support for or described the starts of similar efforts). So let me suggest the following:\n\nWe don\u2019t plan to stay compatible with Mapbox Streets vector tiles in the future and with more and more feature requests coming from the community we are already drifting away from it.\n\nI think that's the right direction. And then let's check in at State of the Map.\n. Hi all - I wanted to take some time this weekend to post a few additional notes on this ticket in response to some of the other folks who've weighed in. Thank you all for your interest. \nGitHub -- despite its many virtues -- is not the best place for serious, nuanced legal conversations. So I won't necessarily be responding to every comment. But I also didn't want folks to think I'm ignoring them, so here are at least a few notes.\n@pnorman -\nYou're basically correct -- as I said above \"Our concern comes from the fact that the project copies (or has attempted to copy) the cartography in the Mapbox Streets vector tiles.\"\nThis goes beyond the schema though. For example, https://github.com/osm2vectortiles/osm2vectortiles/blob/master/src/import-external/seas.geojson appears largely copied from Mapbox Streets, including the choice of point vs. line features, the placement of label arcs, etc. Take a look at the file in geojson.io.\n@klokan -\nHi again :) You're right that Mapbox open sources many, many things. And we're delighted to see others build with those tools, and to help them do so. But none of those other things grant a license to our Streets vector tiles.\nIn terms of the history, you've got it backwards. When we added https://github.com/mapbox/mapbox-studio-osm-bright.tm2/blob/master/LICENSE.txt to the OSM Bright repo, it was to add a design license. I did this at the request of a friend of Mapbox who wanted to build on this work (for their own vector tiles), and asked us for a license beyond the basic BSD code license. The carveout makes clear that the newly added design license excludes the cartography in the Mapbox Streets vector tiles. In short, the license you're now trying to hold up as us pulling back rights is actually my effort to make our work more open, while at the same time making clear the few things we do view as part of the Mapbox brand and IP.\n@hannesj - \n\nI am not a lawyer, but it sounds to me like it is not clear if Mapbox is allowed to make such claims on the vector tiles, as to me they look to fall under derivative databse\n\nThe Mapbox Streets tiles are cartographic tiles developed and optimized for visual display, not a database. Check out https://wiki.osmfoundation.org/wiki/Licence/Community_Guidelines/Produced_Work_-_Guideline. Of course, we're very grateful to be able to build upon the incredible resource that OSM represents. We contribute back heavily, and acknowledge OSM on all Mapbox Streets-based maps (and require our customers to do the same).\n@hyperknot -\n\nTalking about uncoolness, Mapbox is literally in monopoly situation in the tile serving business today\n\n:) Not so much. We do think our cartography team's excellent work is one of the things that separates us, though, which is why I opened this ticket. (Of course, there are also many other brilliant cartographers out there who have developed their own map tiles).\nTo those who have started to talk about how to move this project to its own cartography, thank you. :bow: As I said in my original post, we're excited to see this team build its own vector tile product and very glad to see the vector tile ecosystem continue to grow. \nWe are also, as I said, quite impressed by the technical work, especially as part of a student project, and nothing I've said here is meant to detract from that.\n. Hey @pnorman - Let's leave this open for now. Looking forward to some good conversations at SOTM to move the ball forward. \n. Thanks @lukasmartinelli. I enjoyed meeting with you and the team in Brussels. I'm sorry we couldn't figure out an approach using the openly licensed OSM Bright and Natural Earth styles that worked for you, but we support and appreciate the new direction.\nYou're correct that there is no problem with use of Mapbox open-source software, the Mapbox GL styling language, the Mapbox vector tile spec, use of openly licensed JSON styles (Bright and Basic), or openly licensed TM2 styles. We're glad to see those all being used.\nAnd as I said at the outset, we're excited to see the vector tile ecosystem continue to grow through this project and others, and happy to support as we can.\n. Hi @sfkeller - \n\n@michaelsteffen: Can you clarify, that \"there is no problem with use\" of MB JSON styles (currently Bright and Basic) with vector tiles not coming from MB?\n\nCorrect: Bright and Basic may be used with other tile sources. This is the main thing we've enabled by open licensing these styles. It will generally require some significant modification of the styles to use them with other vector tiles, but the styles are designed to provide a couple high quality starting points for the community.\n\n[T]he \"Design License\" section of MB JSON styles license . . . [i]s this referring to the repo - or to the \"look and feel\" of the map?\n\nThe license covers the design elements expressed in the open styles (e.g. fonts, colors, patterns) to allow others to make maps using these styles. The next section of the design license makes clear that the license is only for the visual elements contributed by things in the repository: in particular, it does not extend to the cartography choices in the Mapbox Streets vector tiles. Per my comment above, this allows the styles to be used with other people's vector tiles, without providing a broader license to the cartography in Mapbox Streets.\n(A couple commenters have expressed skepticism that there is creativity and cartography in vector tiles so I'll just briefly add: The detailed design involved is a large part of why it's actually quite hard to produce high-quality display tiles, as several other commenters here have noted. The historical issues in this repo are a good catalog of some of the decisions and attention to detail that go into vector tile cartography, separate from the choices in any particular style.)\n@sfkeller, per our discussion in Brussels, I've taken note that this section of the license may benefit from some expansion or examples. Your notes are understood and appreciated.\nRegarding some of the broader comments: \nThe OpenStreetMap and broader open source communities are vital to Mapbox -- we're made up of members of those communities, and we care deeply about them. The power of open source licensing is something that we've fought for and remain deeply committed to, and it's why we grant liberal open source licenses to so much of our output.  \nAt a high level:\n- Mapbox open sources the majority of our software. We publish open source code on GitHub with explicit open source licenses.\n- Like most entities, we don't open source art by default. Sometimes we do, like Maki, and in that case, we also publish it on GitHub with an explicit open license.\nIn this case, Mapbox Streets has not been open licensed. Like other cartography, it's art - the product of cartographers careful, opinionated decisions.\nPeople will sometimes disagree with the licensing decisions we make -- sometimes in strong terms. I'm sure that disagreement will continue to include feedback on this ticket. What I can say is we take this all seriously, and we're committed to continuing to contribute to building the overall ecosystem.\n. ",
    "kannes": "@michaelsteffen please be specific.\n\nThis includes choices from among multiple possible data sources for different features, the particular selection of elements to incorporate from those sources, our tagging schemes and arrangement of the data elements, label placement methods, decisions about prominence and use of features at different zoom levels, iconography decisions, ranking of features, and more.\n\nLink us to examples please.\n. ",
    "systemed": "Neither \"openly documented\" nor \"does not show up any terms of usage\" imply \"openly licensed\".\nTo be honest I find the responses to @michaelsteffen's polite request a little uncool. Mapbox license 90% of what they do openly, not least the components that your project links together via shell scripts, and the Mapbox GL viewers that you recommend for rendering the resulting vector tiles. They don't have to make any of this open, but they do, and the OSM ecosystem is much better for it.\nThe work under discussion here is essentially reverse engineered from some of the few things that Mapbox do not license openly. I don't intend here to go into whether the Mapbox tile schema is copyrightable or the legality of reverse engineering: both are complex issues and, though I have my own opinions on both, I recognise that others may disagree.\nWhat is unarguable is that Mapbox believe they have a copyright; they have chosen not to license this copyright openly; and that Mapbox voluntarily provide a huge amount to the community, not least almost all the technologies that underlie your project.\nWith that in mind, the decent thing for you would be to drop this aspect of the project and to concentrate on building up an unambiguously open vector tile design and cartography stack.\n-- Richard, author of tilemaker and glug\n. @madjam002 Tilemaker is a standalone command-line utility to take a .pbf and make vector tiles from it. OSM2VT is a repackaging and joining together of the full Mapbox database-backed vector tile stack. OSM2VT is more complex under the hood but may be easier to set up if you're familiar with Docker etc., and has the ability to update your vector tiles from OSM diffs which Tilemaker doesn't. Tilemaker is \"lighter\" in terms of complexity (though not in RAM requirements!) and doesn't do diffs. \n. ",
    "madjam002": "@systemed Excuse my ignorance, I'm only just getting to grips with the vector tile stack.\nHow does this tool differ from yours (tilemaker)? I used the OSM2VectorTiles website to download a mbtiles file which is openly licensed, and tilemaker is also used for generating a mbtiles file from a PBF extract.\nFrom my understanding of this thread, the part of this codebase which is the problem is https://github.com/osm2vectortiles/osm2vectortiles/blob/master/osm2vectortiles.tm2source/data.yml ? It appears that the Mapbox Streets vector tiles format described here can only be used in conjunction with the Mapbox API and tile server.\nPlease correct me if I am wrong!\n. ",
    "timdorr": "@madjam002 \nOSM (OpenStreetMap) provides their data in a big XML bundle and smaller differential updates over time. Mapbox's toolset is based around that data stored in an MBTiles database, which is just a SQLite database file that follows the MBTiles spec and separates out things in tiles, which can be raster images or vector tiles. OSM2VectorTiles essentially converts from the raw XML data to those vector tiles and stores everything in an MBTiles database so that you can use the open source Mapbox toolset (which is totally OK with Mapbox, since they have graciously open sourced almost all of their tools).\nThe part that is of contention here is how the various \"layers\" of the map are created in the vector tiles. The OSM data contains many different types of map features (e.g., highways, parks, mountains, city boundaries, etc. etc.). You can similarly define layers in your vector tiles to represent map features. Something like Mapbox GL reads these layers and styles them according to a style specification. The default one is Mapbox's Mapbox Streets style, which OSM2VectorTiles generates vector tiles with the appropriate layers to match up with the Streets v7 set of styles and have things like highways show up in orange and lakes in blue. \nThe big thing here is that OSM2VectorTiles has cloned (presumably through inference and reverse engineering, not actual direct copying) how Mapbox generates those layers from the OSM data. For instance, this is how they query the OSM data (stored in an interim PostgreSQL PostGIS database) for the roads layer. \nMapbox believes this work represents IP they own and have a right to prevent duplication of that work. They've invested years of work and the end result is being duplicated/emulated by this project. Are they in the right to make that claim? I'm personally not sure which way I lean, but I do appreciate them reaching out openly like this, rather than filing a C&D directly with the team here or submitting a DMCA takedown request to Github. I think others should too.\nThe best way forward I see here for someone to develop their own style in the Mapbox GL Style spec that differs significantly from Mapbox Streets and is put in the public domain. I've had a hard time finding anyone that offers an alternative to Mapbox's own styles (which are not openly licensed for vector tiles). Then a corresponding set of layers can be extracted from the OSM data that differ from the Mapbox Streets set. Of course, the problem is that Mapbox has shown this isn't a particularly easy feat to accomplish (it's taken them years and they do it full time with a team of cartographers!), so I don't know how feasible this is for the open source community to tackle. \nThe only other option for this project is to stop providing the MBTiles files and simply provided this toolchain for converting OSM data yourself, according to whatever layer specification you want to use. I don't know how feasible that is for most folks, since they currently rely on a costly set of AWS instances to do all this processing on a distributed system. I dunno, maybe that's the best way to go and the focus can shift to getting this toolchain as fast and efficient as possible. Less duct taped together tools and more of a proper processing pipeline. \nEither way, it really comes down to how you view Mapbox's IP validity. Again, I'm still undecided since this falls under the category of \"reverse engineering\" and I happen to think it's a right we should all have. Also, this is a non-commercial project, so it may even be considered Fair Use. IANAL. The EFF has some documentation on the subject, if you're not sure about it.\nIn any case, I hope this can all be worked out amicably. \n. ",
    "pathmapper": "If we speak about cartography as a science, there are a lot of do's and don'ts regarding map design, e.g. how labels should be placed or which colors should be used.\nCartography provides a set of guidelines for map design which are reflecting the state of the art of this science.\nAs a cartographer you follow these guidelines. Therefore you are limited in a lot of design decisions and in some cases the state of the art in cartography advocates a certain approach.\nWe would have a first-come, first-served situation if map design as a result of the appliance of cartography guidelines represents IP and grants the right to prevent duplication of that work.\nIf you create your own map design different from Mapbox Streets while following the cartography guidelines, you may end up with something that looks like Google Maps, Bing Maps, \u2026 .\nIn other words: \nThe use of all the OSM data published under ODbL for maps would be limited, if this discussion leads to the point, that map design based on cartography guidelines represents IP.\n. ",
    "bearnxx": "I will support you and use your solution in my project continuously. The complain from mapbox is so impenetrable! \n. it did not work neither :( @ImreSamu \n. it turns out the same result. any other ways?  @stirringhalo \n. thank you for your reply\nI have only one osm2vectortiles folder. (/home/bear/osm2vectortiles)   and I have put the pbf file in /home/bear/osm2vectortiles/import.  I didn't modified my docker-compose.yml . how should it go? @stirringhalo \nthe error is like belowe\n[localhost osm2vectortiles]# docker-compose up import-osm\nWARNING: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\nWARNING: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\nWARNING: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_cache_1\nStarting osm2vectortiles_pgdata_1\nosm2vectortiles_postgis_1 is up-to-date\nStarting osm2vectortiles_import-osm_1\nAttaching to osm2vectortiles_import-osm_1\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name execveat: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name getrandom: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name memfd_create: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name renameat2: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name sched_getattr: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name sched_setattr: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name seccomp: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name breakpoint: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name cacheflush: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | 2016/08/28 09:53:44 Error resolving syscall name set_tls: could not resolve name to syscall - ignoring syscall.\nimport-osm_1            | No PBF files for import found.\nimport-osm_1            | Please mount the /data/import volume to a folder containing OSM PBF files.\nosm2vectortiles_import-osm_1 exited with code 148\n. [root@localhost osm2vectortiles]# cat /etc/*-release\nCentOS Linux release 7.1.1503 (Core) \nNAME=\"CentOS Linux\"\nVERSION=\"7 (Core)\"\nID=\"centos\"\nID_LIKE=\"rhel fedora\"\nVERSION_ID=\"7\"\nPRETTY_NAME=\"CentOS Linux 7 (Core)\"\nANSI_COLOR=\"0;31\"\nCPE_NAME=\"cpe:/o:centos:centos:7\"\nHOME_URL=\"https://www.centos.org/\"\nBUG_REPORT_URL=\"https://bugs.centos.org/\"\nCENTOS_MANTISBT_PROJECT=\"CentOS-7\"\nCENTOS_MANTISBT_PROJECT_VERSION=\"7\"\nREDHAT_SUPPORT_PRODUCT=\"centos\"\nREDHAT_SUPPORT_PRODUCT_VERSION=\"7\"\nCentOS Linux release 7.1.1503 (Core) \nCentOS Linux release 7.1.1503 (Core) \n\n[root@localhost osm2vectortiles]# cat /proc/version\nLinux version 3.10.0-229.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) ) #1 SMP Fri Mar 6 11:36:42 UTC 2015\n\n[root@localhost osm2vectortiles]# docker version\nClient:\n Version:         1.10.3\n API version:     1.22\n Package version: docker-common-1.10.3-46.el7.centos.10.x86_64\n Go version:      go1.6.3\n Git commit:      d381c64-unsupported\n Built:           Thu Aug  4 13:21:17 2016\n OS/Arch:         linux/amd64\nServer:\n Version:         1.10.3\n API version:     1.22\n Package version: docker-common-1.10.3-46.el7.centos.10.x86_64\n Go version:      go1.6.3\n Git commit:      d381c64-unsupported\n Built:           Thu Aug  4 13:21:17 2016\n OS/Arch:         linux/amd64\n\n[root@localhost osm2vectortiles]# docker info\nContainers: 22\n Running: 1\n Paused: 0\n Stopped: 21\nImages: 6\nServer Version: 1.10.3\nStorage Driver: devicemapper\n Pool Name: docker-8:3-137629586-pool\n Pool Blocksize: 65.54 kB\n Base Device Size: 10.74 GB\n Backing Filesystem: xfs\n Data file: /dev/loop0\n Metadata file: /dev/loop1\n Data Space Used: 4.961 GB\n Data Space Total: 107.4 GB\n Data Space Available: 13.76 GB\n Metadata Space Used: 9.404 MB\n Metadata Space Total: 2.147 GB\n Metadata Space Available: 2.138 GB\n Udev Sync Supported: true\n Deferred Removal Enabled: false\n Deferred Deletion Enabled: false\n Deferred Deleted Device Count: 0\n Data loop file: /var/lib/docker/devicemapper/devicemapper/data\n WARNING: Usage of loopback devices is strongly discouraged for production use. Either use --storage-opt dm.thinpooldev or use --storage-opt dm.no_warn_on_loop_devices=true to suppress this warning.\n Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata\n Library Version: 1.02.107-RHEL7 (2016-06-09)\nExecution Driver: native-0.2\nLogging Driver: journald\nPlugins: \n Volume: local\n Network: host bridge null\nKernel Version: 3.10.0-229.el7.x86_64\nOperating System: CentOS Linux 7 (Core)\nOSType: linux\nArchitecture: x86_64\nNumber of Docker Hooks: 2\nCPUs: 1\nTotal Memory: 7.627 GiB\nName: localhost\nID: Y3AP:WBOT:JNR6:DUIF:JHIF:G4Z6:UENO:U6PB:HNDB:TRGW:TBST:UGOC\nWARNING: bridge-nf-call-iptables is disabled\nWARNING: bridge-nf-call-ip6tables is disabled\nRegistries: docker.io (secure)\n\n[root@localhost osm2vectortiles]# docker-compose version\ndocker-compose version 1.8.0, build 94f7016\ndocker-py version: 1.9.0\nCPython version: 2.7.5\nOpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013\n\n@stirringhalo   @ImreSamu \nAnd I think it should be some config problem not a lower version docker problem\n. [root@localhost osm2vectortiles]# docker run -it --rm -v $vimport:/data/import debian:jessie ls -la /data/import\nUnable to find image 'debian:jessie' locally\nTrying to pull repository docker.io/library/debian ... \njessie: Pulling from docker.io/library/debian\n357ea8c3d80b: Already exists \nDigest: sha256:ffb60fdbc401b2a692eef8d04616fca15905dce259d1499d96521970ed0bec36\nStatus: Downloaded newer image for docker.io/debian:jessie\n2016/08/30 13:29:22 Error resolving syscall name execveat: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name getrandom: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name memfd_create: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name renameat2: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name sched_getattr: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name sched_setattr: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name seccomp: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name breakpoint: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name cacheflush: could not resolve name to syscall - ignoring syscall.\n2016/08/30 13:29:22 Error resolving syscall name set_tls: could not resolve name to syscall - ignoring syscall.\nls: cannot open directory /data/import: Permission denied\nI have disabled the selinux. it did'tn work too.\nI think it must be the ContOS7 Problem.  I decide to change to your  Linux distributions. So which one are you using now? \n@ImreSamu \n. I change my OS to Ubuntu16.04 . All is well~~~  :) @ImreSamu  @stirringhalo   thank you for your help\n. Ok  I'll try it later\nThank you very much. \n@klokan \n. it worked !  thank you very much.\nbut there are still some little problems some labels in Europ or USA are still English and some are chinese.\nhow to fix this? thank you for your patience.\n. I have got some information like picture below, but I still want to know the detail information in the [object] list. and How can I resolve them. thank you :)\n\n. Thank you for your reply. To be honest the tow thesis is very helpful. I work in a top GIS study institution of my country, I have not read any document such perfect these years. :)\n. I think it is necessary, especially for the new user of this project. \nand also if some question can be indexed by google. It will bring some new user.\n. yes I edited the style json and it worked! thank you !. default password is osm user is osm too. I think it's imposm3 drop tables each time. ",
    "lossyrob": "For Next Actions, if a new OSM vector tile schema is to be invented, I believe it would be best to try and find a set of collaborators in the community interested in an open schema. This could mitigate the hugeness of the effort, and also give to the community a schema on which designers could produce designs that will style vector tiles generated with any compliant source. An \"Open Streets v1\" if you will.\nAre you in talks with potential collaborators around a standard schema already? If not, do you think this type of collaboration would be useful to osm2vectortiles, and how can we make that happen? If so, are there ways in which interested community members can get involved?\n. ",
    "raku": "What you think about mapsforge https://github.com/mapsforge/mapsforge and mapsforge vtm https://github.com/mapsforge/vtm ? I think you can colaborate with them and provide maps for their render engine.\n. ",
    "efi": "\nGiven we're avoiding stuff we don't have to (e.g. openly licensed styles from MapBox) because of the legal chill, should we completely move away from MapBox GL?\n\nHow can a project in the database layer move away from a presentation layer? If you wanted to intentionally make things incompatible you would have to ditch the https://github.com/mapbox/vector-tile-spec as protocol layer alltogether. That would hurt everyone, I guess.\n. For me it's the same with the newest mapbox-gl-js version and germany.mbtiles. \nAnd it does not just report the \"admin\" layer, the browser console says:\nVector tile source \"mapbox\" layer \"landuse\" does not use vector tile spec v2 and therefore may have some rendering errors.\nVector tile source \"mapbox\" layer \"water\" does not use vector tile spec v2 and therefore may have some rendering errors.\nVector tile source \"mapbox\" layer \"road\" does not use vector tile spec v2 and therefore may have some rendering errors.\nVector tile source \"mapbox\" layer \"admin\" does not use vector tile spec v2 and therefore may have some rendering errors.\nVector tile source \"mapbox\" layer \"place_label\" does not use vector tile spec v2 and therefore may have some rendering errors.\nVector tile source \"mapbox\" layer \"country_label\" does not use vector tile spec v2 and therefore may have some rendering errors.\nVector tile source \"mapbox\" layer \"waterway\" does not use vector tile spec v2 and therefore may have some rendering errors.\nsporadically as I zoom and pan (in the area covered by the dataset).\nBut so far no strange rendering bugs occured.\n. duplicate of #364\n. Just a quick follow-up: there is of course no flicker when landuse_overlay_national_park gets a fill-opacity of 1  - then all competing triangles result in the same color & no flickering occurs. - so this can be used as a hack to make things visually pleasing - but I guess the core issues of overlap in one and the same layers is more fundamental.\n. The issue causing the flickering is indeed that two polygon-areas in the same layer (landuse_overlay_national_park) are overlapping. OSM Bright (but surely also some user-defined styles) assign them a fill-opacity of <1. Since they have the same \"z-index\", with the Pitch-rendering triangualtion, some triangles from the one and some from the other polygon are hit/used. They all say \"I am paintig the map below me a bit greener\" - but what is \"below\" them changes - either the other area's polygon (which adds a bit more green) or not.\nSo the problem is: Some areas in the same layer overlap. If we set their fill-opacity to fractions of 1, there may be flickering in the \"reference renderer\" of Mapbox-gl-js, when Pitch is used. It doesn't do so with the mapbox tiles. But I don't want to 'reverse engineer' why this is the case.\nQuestion are:\n- Should a tile provider care at all?\n- Should / can such areas of identical semantics be merged on a polygon level?\n- Would it be useful to have separate layers of national park overlays for both aspects (nature_reserve and protected_area)?\n- Could one of them just be dropped?\n- Can other polygons \"overlap\"? Lakes? Buildings?\n- ...\n. ",
    "vitalcrazz": "So to be clear.\nUsing OSM Bright is legal.\nUsing OSM data is legal.\nSelecting OSM data in a way to fit OSM Bright is illegal.\nSounds like nonsense.\n. Thank you, @ImreSamu \n. I think you could use export-list component from this repository.\nIt uses export/tiles.txt file containing a list of specific tiles.\nAnd it runs like that: docker-compose run export-list\n. I just try to understand the changed-tiles command output.\nWe have a list of tiles. For example, line 7/68/52. Does it mean that we should rerender all nested tiles from zoom 7 to zoom 14?  Or just one specific tile at zoom 7?\n. ",
    "gisgraphy": "hi all,\nI am a software engineer and not a lawyer, and would like to be pragmatic as possible.\nyesterday I ask a question on hardware requirements #457 and @klokan told : \n\nBe aware of legal issues with deploying OSM2VectorTiles tiles #387\n\nOK understood :). I have carefuly read this thread and think I understand that Mapbox complains about the style of OSM2VT that is closest from their style (right?). Unfortunately, I don't know when the style come in the oftware stack : \nwhen rendering ? when I specify the json file in the style attribute as describe in the  get started documentation. Can I use the right-v9-cdn.json file\nwhen generating tiles ? does the zurich.MBtiles that will be downloaded, already contains the style ?\nfinally, my question is simple, and in a goal to be pragmatic and don't have to change lot of things on my own server :\n- If there is something 'illegal' or does not fit a license (don't enter the polemic), am I legally ok if I follow the get started guide (in other words, at this step, if there something legally wrong, am I ok ?)\n- Same question with Generate your own vector tiles.\n- Can I use a project like maputnik even if the style will be close to Mapbox one ?\nMany thanks\n. ",
    "severak": "I think somebody should develop MapBox \u00bb OSM2VectorTiles style migration script. Then OSM2VectorTiles will be innocent project and all the hate from MapBox will go to this script.\n. @klokan \nNew OSM2VectorTiles will be compatible with MapBox? So If I have MapBox style I will be able to use custom tiles by simply changing a source of tiles? (aka no needs to redefine IFs and selectors in my style)\n. ",
    "reyemtm": "Wow this whole thing is so confusing. I have just deployed a test vector tile server following some of the examples here using an extract of the usa osm2vectortiles download. I could simply switch the tiles to mapbox styles until this is resolved, but am not too keen on that option. Am I correct in understanding that it is the tiles themselves that are at issue here, or actually the choice and makeup of the layers in the tiles, aka the tile schema? How 'different' do the schemas have to be to be legal? If the cartography is at issue, it would make more sense to copyright the styles, but those are open. That said, I already see some changes I would like to make to this schema and am more than willing to participate in helping in this regard.\n. ",
    "briancalvium": "Thanks for the quick reply! I'm using the mapbox SDK on iOS/Android, and it seems like overzoom isn't fully supported. The tiles that are already loaded look great over-zoomed, but it doesn't load new tiles when panning once over-zoomed (it looks for, and cannot find, tiles at zoom 15+ for instance). It's a little hard to tell what exactly is in the data from GISgraphy - if I wanted to try changing the schema, would I essentially modify data.yml and add SELECT clauses for the higher zoom levels to all of those UNION ALLS?\n. Looks good! But, is that using MapTiler behind the scenes, or is there just some style.json flag I don't know about? (maybe this now is a mapbox question... but as you guys seem to have it going... )\nEdit: nevermind maxzoom in styles does the trick (had it camel-cased...sigh). Thank you for your help!\n. ",
    "roblight": "@lukasmartinelli you're welcome!  Thank you for the prompt response.\n. Does this mean the latest planet file is 6/20/2016?  I seem to recall the last planet download I did had a date around 7/14/2016.  Thanks again!\n. Cool, thanks for the info.  Does the date in the filename correspond to the OSM source data as found on planet.openstreetmap.org?\n. ",
    "romanshuvalov": "Thank you for replies. \nYes, I modified import-osm/mapping.yml to add new OSM tags for my purposes and that was result. Thank you for your fix. \nBut it looks like #398 have added new bug.\nWhen executing docker-compose run import-osm I got this:\n```\n...\nSELECT UpdateGeometrySRID('osm_water_polygon_gen1','geometry',3857);\n                     updategeometrysrid                      \n\npublic.osm_water_polygon_gen1.geometry SRID changed to 3857\n(1 row)\nUpdate scaleranks from Natural Earth data\nUPDATE osm_place_point\nSET scalerank = improved_places.scalerank\nFROM\n(\n    SELECT osm.id, ne.scalerank\n    FROM ne_10m_populated_places AS ne, osm_place_point AS osm\n    WHERE\n    (\n        ne.name ILIKE osm.name OR\n        ne.name ILIKE osm.name_en OR\n        ne.namealt ILIKE osm.name OR\n        ne.namealt ILIKE osm.name_en OR\n        ne.meganame ILIKE osm.name OR\n        ne.meganame ILIKE osm.name_en OR\n        ne.gn_ascii ILIKE osm.name OR\n        ne.gn_ascii ILIKE osm.name_en OR\n        ne.nameascii ILIKE osm.name OR\n        ne.nameascii ILIKE osm.name_en\n    )\n    AND (osm.type = 'city' OR osm.type = 'town' OR osm.type = 'village')\n    AND st_dwithin(ne.geom, osm.geometry, 50000)\n    ) AS improved_places\nWHERE osm_place_point.id = improved_places.id;\nUPDATE 4\nERROR:  invalid input syntax for type timestamp: \"(invalid timestamp)\"\nLINE 1: DELETE FROM osm_timestamps WHERE timestamp='(invalid timesta...\n```\nTo ensure it's not my fault I ran it on fresh new docker image without modifying anything. Previous version didn't have that bug. \nFor information: I didn't build whole project and only executed make for postgis, import-external, import-osm and import-sql because as I understand only these four parts are needed for generating tiles according to USAGE.md (and export too but I have caught a bug before dealing with export). \n. GIS-Lab OSM Dumps (direct link to PBF I used: RU-SAM.osm.pbf). This is popular resource, it contains extracts of Russian regions and xUSSR countries. Reliable source, I used that dumps many times for rendering raster maps. \n. Thank you. By the way, yesterday I used that PBF and it was imported without problems. (Before I started tweaking mapping.yml.) I'm assuming PBF is valid. \n. @ImreSamu : YES, confirmed, GIS-Lab PBFs surprisely doesn't contain timestamps. I have contacted GIS-Lab developer about that. After his reply we will know if we need to write FAQ or he will just add timestamps to all dumps.\nI've modified your draft-fix, instead of slow osmium fileinfo method I simply use current time:\nimport.sh, line 68\n```\nfunction extract_timestamp() {\n    local file=\"$1\"\nLASTOSMTIMESTAMP=$(osmconvert $file --out-timestamp)\nif [[ ${LASTOSMTIMESTAMP:0:1} != \\2 ]] ; then\n   # PBF doesn't contain timestamp, using current time\n   LASTOSMTIMESTAMP=`date -u +%Y-%m-%dT%H:%M:%SZ`\nfi\n\necho $LASTOSMTIMESTAMP\n\n}\n```\nAnd it worked fine for that dumps. Many thanks. \nIf this fix is okay (I'm not sure if using current time is right, but at least it works), I'll try to commit it to osm2vectortiles. \n. So, in this project, tilelive internally uses mapnik functionality to do this job, right? \n. I've created import-contour but designed it for OpenDEM contourlines, in order to test it with more precise OpenSnowMap data I need sample of N53E049 and N53E050 segments, can you share them? (It's my region when I'm testing anything.)\nAfter testing I will create pull request. \n. > Could you please run the tests on the provided sample?\nOkay, but I don't know what region is covered by that sample. Please give me a link to any online map so I will see coordinates. (You said \"zoom into the Zurich area\" but I can't visually find place where you have taken your preview screenshot).\nupdate My bad, file name \"contours_48-8\" means N48 E008. Found. Testing. \nAbout assigning attributes. Well, the only attribute we need is elevation. OpenDEM has \"elevation\" attribute, OpenSnowMap has \"height\". At this moment I edit it manually at import-sql/layers/contour.sql. Probably it's better to determine attribute name from shapefile but I don't know how to do it so temporary I set it to \"height\". \nAnd I've chosen ele attribute name for final tiles in order to make them compatible with MapBox styles.\nI used osm2vectortiles.tm2source for contours. But separating them to other tile set is probably good idea. \nAnd yes, we need generalization/simplification of geometry for lower zoom levels. I didn't make it yet and honestly I don't know how. (I just start learning PostgreSQL/PostGIS recently.)\n. Success. \n\nOpenSnowMap contour sample imported to osm2vectortiles via my import-contour docker container. \nI will send pull request today. \n. But we can't set ele % 100 expression as property. Listing any values from 0 to Everest height is not look as good approach. \n. Contour lines is now generalized for lower zoom levels. \nEnough development for today, now preparing for pull request.\n\n. Created pull request: #409 \n. @yvecai, thank you for dataset, as I understand this dataset is not available to download publicly. And it can cause potential problems for people who want to fork osm2vectortiles project and work on it. Maybe it's better to share it like OpenDEM did that? \n. Best solution is render two types of vector tiles: with contours and without them. So probably we should add options to  export: render only osm data, render osm data + contour layer, render both. \nContours as separate tile set is not good because of 2x HTTP queries and in most cases they don't need without OSM data tiles. But it require more drive space because of doubling OSM data. It can be solved by adding third option contours-only. So it could be configured by administrator.\nWhich tile set - pure OSM or OSM+contours - should be given on osm2vectortiles website, it's for you to decide. I think OSM+contours are better. \nAbout me: for my purposes (3D rendering) I need custom tiles with a lot of other fields and calculations so I forked the project and I will continue developing in separated branch. So, of course, I don't mind if you need time to deal with that questions. Do whatever you want, I just needed contour layer and I added it and shared the code in order to be useful for community. \nIf you decide something and you think I could help implementing it, I will participate. Meanwhile I continue working on my own project. \n. Update: Fixed Makefile. And added empty tables in case of no contour files in import/contour folder.\nSo, contour files are not necessary now, but import-contour still must be called for creating that empty tables.\nAnd I don't know how to create empty import/contour/ folder on github. It's listed in .gitignore file and I can't add it to commit. \nP.S. I know nothing about checks and I have no idea why they are failed. \n. Look at this.\n\n12th, 13th and 14th tiles are upscaled to 18th. Even 14th tile has a small gap in between polygons. \nAlso it looks like smaller zooms not only has less accuate coordinates, but also has simplified geometry. Simplification is not written in tm2source, so it's performed somewhere inside tile exporting mechanism. \nHow to adjust this parameters? \n. Found!\nTile object is created In tilelive-bridge/index.js:243. There is no 'tile_size' parameter so default value of 4096 is used. \nParameter can be added easly:\nvar tile_size_value = 65536;\n// ...\nvar vtile = new mapnik.VectorTile(+z,+x,+y, {tile_size:tile_size_value, buffer_size:tile_size_value});\nAfter that, vector tile will be created with 65536x65536 integer grid and extent parameter will be set to 65536 (or whatever you choose). It's accurate enough for overzooming. I've just tested - no gaps, no geometry simplifications. Brilliant. \nI modified tilelive-bridge/index.js for my purposes but generally this is not the best solution, it's better to store this tile_size value somewhere in tm2source file and read it while processing tm2source. \n. Important notice.\nMapBox GL JS library seems to have accuracy limitations. Even if tile itself have coordinates with enough resolution, highly overtiled rendering (for example, 12th tile upscaled up to zoom level 17 and higher) with MapBox GL JS can cause clearly visible skewing of geometry. Keep it in mind. \n. GIS-Lab provides that extracts:\nhttp://be.gis-lab.info/data/osm_dump/dump/latest/ \nAnd diffs too. More information (Russian only): http://gis-lab.info/projects/osm_dump/ \nWarning: GIS-Lab extracts doesn't contain timestamp which can cause (invalid timestamp) bug. See #397 for more details and workaround. \n. ",
    "aAXEe": "I am one of the developers of OpenSeaMap. We are currently working on a new map interface: https://github.com/aAXEe/online_chart_ol3\nIt uses OpenLayers3 and traditional raster tiles until now. But switching to vector tiles would be very nice.\nI would prefer to add the seamark data in the main tiles .. the additional data is not that much as most of the seamarks are simple nodes with some tags. \nOn the other hand we love to deliver map updates within minutes ... it is great for (osm) contributors to see their changes quickly on the map. Having a separate set can enable that, can't it?\nWe have a server for rendering tiles and other things: http://wiki.openseamap.org/wiki/OpenSeaMap-dev:Server_Bravo\nI am sure you can get some resources on this machine.\nThe hard part of the map is the rendering of the symbols. There are tons of different symbols. Especially the lights are hard to get right: https://alpha.openseamap.org/#/?lat=54.1820&lon=12.0808&zoom=15&layers=A10001\nHave a look at our current tile-renderer (written in C): https://github.com/OpenSeaMap/renderer/blob/master/searender/rules.c\nAs I am not familiar with the rendering I do not know how difficult it is to get this things rendered in OpenGL. Do you have an idea?\n. I think the SVGs are ment to draw complex things like sectored lights: http://wiki.openstreetmap.org/wiki/Seamarks/Sectored_and_Directional_Lights\nWe will need some kind of dynamic picture for that.\nYou can find the existing SVG files here: https://github.com/OpenSeaMap/renderer/tree/master/searender/symbols\nEdit: I did some first steps with osm2vectortiles, osm-liberty and the seamark tiles: https://aaxee.github.io/openseamap-gl/\n. >  There is not a set of all possible symbols but your set contains fragments that get combined and colored dynamically; e.g. pillars and barrels\nCorrect ;)\nBut these symbols can be combined from a predefined set. I think it should not be too hard to render this kind of things.\nFor the complex symbols like sectored lights: They are not like POIs or point symbols but like a street etc. They can cover a greater area. I thing converting them into real map objects is a better way. Something like @lukasmartinelli did with the noise map: https://github.com/lukasmartinelli/osm-noise-pollution\nThis would also fix a common problem: Parts from a light can be visible on the map while the point itself is not. Rendering on the client side would mean that the client has to look ahead of the current view.\n. @lukasmartinelli: I copied the repo: https://github.com/OpenSeaMap/vectortiles-generator\nI already added a simple \"all seamarks\" layer and exported the vector tiles.\nSome issues outline the needed work. Is there something missing?\nAn instance of the tile server: http://vectortiles.195.37.132.70.xip.io/\nI use only a small extract around our \"map base\" Warnem\u00fcnde (DE) (It was the starting point of OpenSeaMap some years ago)\nYou can use http://vectortiles.195.37.132.70.xip.io/data/oseam.json as a tile source.\nI updated my example to use the vector tiles from above and display them as red dots. \n(Note: the tile server is http only. In firefox you can disable the security warnings and see the map)\n@indus: Your demo already looks great! Do you continue to work on this? Do you need something?\n. >  I think it would be best to directly use your tile-server and concentrate on POIs first; what do you think?\nYes of course. I document the tile server here: https://github.com/OpenSeaMap/vectortiles-generator/wiki\nDo you already have a repo for the style?\nI would like to have it separated from the rest for the first time. It might be a good idea to add it to OpenSeaMap/vectortiles-generator later on because the style will only work with the tiles provided by this toolset (and settings).\nI think lukasmartinelli/osm-liberty could be a good base for the base structure.\n. > For now I will use your geojson; but without a property \"category\" it is hard to test varying styles of a type.\nI added a new layer for the vector tiles: buoy_cardinal\nThese entires have all attributes documented here: http://wiki.openstreetmap.org/wiki/Seamarks/Seamark_Objects\nI tweaked the tile server ... you can now use the x-ray view from the tile server to see the available data: \neg: http://vectortiles.195.37.132.70.xip.io/data/oseam/#13.22/54.1860/12.0490\nThe map is already centered at a cardinal buoy.\nI am working on a system to automatically map all nodes documented in the osm wiki into the database and the vector tiles.\n. The tile server now has the complete seamark mapping available:\nhttps://github.com/OpenSeaMap/vectortiles-generator/issues/1#issuecomment-242985393\n. > Maybe we need some specification how to transpile from the database to a style-friendly dataset. But I have to say I\u00b4m not shure if I can keep pace with you ;-)\nYes we will need this .. and I am aware of this ;)\nThe current 1:1 mapping between tagging scheme to postgres tables and vector-layers is only intented as a first try to be able to find such issues ;)\nFollow up: https://github.com/OpenSeaMap/vectortiles-generator/issues/5\n\nOne last thing that I miss in the moment is data for the \"top\" addon and the \"light-colour\". Would be nice to have them all in the properties in a single Point-Feature.\n\nI noticed that the osm-import does not fetch all data. It only takes the seamark:type object type from each node and parses all relevant attributes for that type. This way it ignores seamark:light:* if seamark:type is something different from light.\nThis should be addressed in https://github.com/OpenSeaMap/vectortiles-generator/issues/1\n\nBTW: Should we close this issue here with a last link to your repo and only continue there? And \n\nYes I think so.\nHaving the seamark data as a separate data source and a style for that seems to make sense.\n. ",
    "indus": "Why is there a need for SVGs? I think mapbox-gl-js uses a single PNG spritesheet referenced by a property so as long as the symbols come with tranparancy, it should be easy to stich them in a grid-layout in a single PNG.\nI would be happy to do that; it should be easier than any of the other tasks to do for me.\nThe special sea-mal style-sheet makes me think that it would be better to keep \"street\" and \"sea\" seperate layers. (maybe it is possible to merge them on the fly when requested, like it is eine by mapbox with \"street\" and \"terrain\"?\n. Sorry. I thought you where talking about the various point symbols. Would it ne possible to split these big \"symbols\" into a bunch of polygons and polylines that could get rendered clientside without a predefined asset?\nI would imagine it like a roundabout in the streets dataset: A point feature expanded to a complex shape.\n. And now I also understand the problem with the point symbols. There is not a set of all possible symbols but your set contains fragments that get combined and colored  dynamically; e.g. pillars and barrels:\n\n. I also set up a small Demo Page to get an idea what combining multiple icons actually means, and what the result could look like.\n(I\u00b4m sorry to say, but I don\u00b4t have time to work on this at this weekend)\n. @aAXEe Yes I'm going to continue this. Hard to say if I will find much time during the week. But I will have at least one day during the weekend. I think it would be best to directly use your tile-server and concentrate on POIs first; what do you think?\n. @aAXEe I will continue with the repo of the Demo. For now I will use your geojson; but without a property \"category\" it is hard to test varying styles of a type.\n. I\u00b4ve updated my Demo\n. @aAXEe  I started a small test on bringing the current style together with the data you provide: https://indus.github.io/OSeaM/oseam/\nIt seems to me that the data has to be structured a bit different. In the moment stuff that is almost the same (from a style perspective ;-) is spread over multiple source-layers: e. g.various \"pillar\"  shapes in \"buoy_lateral\", \"buoy_special_purpose\", etc.\nFrom my POV only the shape of a POI symbol matters, e.g. because it determinats the offset that is needed to place it in the right position and also to get the placement of combined Symbols correct; \"colour\" acts on top of \"shape\" as a modifier. It wouldnt change label placement for example. Splitting this property into \"colour\" and \"colour-pattern\" gives the need for a lot of duplicates in the style. A single modifier (e.g. \"vyby\" for vertical + yellow;black;yellow) would make things a lot easier.\nOne last thing that I miss in the moment is data for the \"top\" addon and the \"light-colour\". Would be nice to have them all in the properties in a single Point-Feature.\nMaybe we need some specification how to transpile from the database to a style-friendly dataset. But I have to say I\u00b4m not shure if I can keep pace with you ;-)\nBTW: Should we close this issue here  with a last link to your repo and only continue there? And \n. Jep! Thanks for the hint.\n. \"wonfix\" is a bummer\n. #300\n431\n. ",
    "xtompok": "Exactly the same problem, using osmosis cutted rectangle from geofabrik file. Outputs of osmconvert:\n$ osmconvert praha.osm.pbf --out-statistics\ntimestamp min: 2005-11-14T23:54:09Z\ntimestamp max: 2016-09-22T19:23:05Z\nlon min: 12.0905901\nlon max: 18.8592160\nlat min: 48.5518135\nlat max: 51.0557036\nnodes: 6462067\nways: 467282\nrelations: 27347\nnode id min: 172508\nnode id max: 4413814325\nway id min: 4947\nway id max: 443820391\nrelation id min: 2162\nrelation id max: 6597388\nkeyval pairs max: 279\nkeyval pairs max object: node 424313803\nnoderefs max: 1838\nnoderefs max object: way 149801414\nrelrefs max: 2895\nrelrefs max object: relation 2793464\n$ osmconvert praha.osm.pbf --out-timestamp\n(invalid timestamp)\nOriginal file\n$ osmconvert czech-republic-latest.osm.pbf --out-timestamp\n2016-09-22T19:28:03Z\nThe script should check this in the beginning not fail at the end of the processing\n. ",
    "yvecai": "Happy to see these datasets used and abused! \nYves\nLe 22 ao\u00fbt 2016 15:16:45 GMT+02:00, Roman Shuvalov notifications@github.com a \u00e9crit :\n\nContour lines is now generalized for lower zoom levels. \nEnough development for today, now preparing for pull request.\n\n\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/408#issuecomment-241409048\n\n\nEnvoy\u00e9 de mon appareil Android avec K-9 Mail. Veuillez excuser ma bri\u00e8vet\u00e9.\n. @petr : sure,  no problem.  \nLe 22 ao\u00fbt 2016 18:24:57 GMT+02:00, Petr Pridal notifications@github.com a \u00e9crit :\n\nI guess we could put all the individual Shape files on the\nOSM2VectorTiles\ndownload infrastructure, where we put the vector tiles with contours as\nwell...\nAre you fine with this @yvecai?\nOn Monday, 22 August 2016, Zsolt Ero notifications@github.com wrote:\n\n@yvecai https://github.com/yvecai also, if hosting is a problem,\nI'd be\nhappy to provide hosting on a small Kimsufi server.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/408#issuecomment-241452546,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADnlBlTNCUzr3G0hs54MfGQ-FliCVQ4ks5qicGNgaJpZM4JpqKt\n.\n\n\nPetr Pridal, Ph.D.\nCEO\nKlokan Technologies GmbH\nHofnerstrasse 98, 6314 Unterageri, Switzerland\nTel: +41 (0)41 511 26 12\nEmail: info@klokantech.com\nWeb: http://www.klokantech.com/\n\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/408#issuecomment-241468401\n\n\nEnvoy\u00e9 de mon appareil Android avec K-9 Mail. Veuillez excuser ma bri\u00e8vet\u00e9.\n. ",
    "jaskiratr": "I'm using docker on Windows machine and I get same error.\nReference: #499 \nShould I consider switching to Ubuntu instead?. Stuck here...\n$ docker-compose up import-osm\nWARNING: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\nWARNING: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\nWARNING: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\nStarting osm2vectortiles_cache_1\nosm2vectortiles_postgis_1 is up-to-date\nStarting osm2vectortiles_import-osm_1\nAttaching to osm2vectortiles_import-osm_1\nimport-osm_1            | No PBF files for import found.\nimport-osm_1            | Please mount the /data/import volume to a folder containing OSM PBF files.\nosm2vectortiles_import-osm_1 exited with code 148. Thanks @mkjaer . I think I had just set COMPOSE_CONVERT_WINDOWS_PATHS = \"true\"\nI don't think I've removed the mount. \n```\n$  docker-machine env --shell powershell\n$Env:DOCKER_TLS_VERIFY = \"1\"\n$Env:DOCKER_HOST = \"tcp://192.168.99.100:2376\"\n$Env:DOCKER_CERT_PATH = \"C:\\Users\\Jess.docker\\machine\\machines\\default\"\n$Env:DOCKER_MACHINE_NAME = \"default\"\n$Env:DOCKER_API_VERSION = \"1.24\"\n$Env:COMPOSE_CONVERT_WINDOWS_PATHS = \"true\"\nRun this command to configure your shell:\n& \"C:\\Program Files\\Docker Toolbox\\docker-machine.exe\" env --shell powershell | Invoke-Expression\n$ docker-compose --version\ndocker-compose version 1.9.0, build 2585387\nSorry for being a pain. Maybe this is a docker specific issue.... Figured it out.\nHere is the current output when I inspect the `import-osm`\n$  docker inspect import-osm\n.\n.\n.\n        \"Mounts\": [\n            {\n                \"Source\": \"/c/Users/Jess/Documents/Kitematic/osm2vectortiles/cache\",\n                \"Destination\": \"/data/cache\",\n                \"Mode\": \"\",\n                \"RW\": true,\n                \"Propagation\": \"rprivate\"\n            },\n            {\n                \"Source\": \"/c/Users/Jess/Documents/Kitematic/osm2vectortiles/import\",\n                \"Destination\": \"/data/import\",\n                \"Mode\": \"\",\n                \"RW\": true,\n                \"Propagation\": \"rprivate\"\n            }\n        ],\n.\n.\n.\n``\nSo I moved the osm2vectortiles git repo underC:/Users/Jess/Documents/Kitematic/. I ran theimport-osmcontainer using docker CLI fromKitematic/osm2vectortiles`. Worked like a charm.\nThanks again!\n. ",
    "mboeringa": "\nIt tries to get everything right, more so than any other style out there\n\nI politely disagree ;-)\nThere is at least one other style and renderer that gets about everything right, and that is the one I developed from the ground up for ArcGIS, and yes, there is a grand total of one person that understands it...\nBut there ends the joke, because I do share and understand your pain: it is hard! \nFor my ArcGIS renderer, I partly took the sting out of it, by making optimal use of ArcGIS's options like Symbol Level drawing to first stack the road types in a meaningful order, and then use the ability to re-order ArcGIS Table Of Contents thematic layers to fully automatically and dynamically stack them according to the OSM \"layer\" key.\nThis required some really hard thinking though, of what that program code should look like (which I developed in Python using ArcGIS's \"arcpy\" package), and a considerable amount of frustration to get it right and fix the bugs (and the logic). The final code stacks ArcGIS thematic layers, each representing a single OSM \"layer\" value, where each thematic layer defines all road types, and can even do this for multiple different thematic layers developed for different zoom levels (and even man_made=bridges).\nThe final ordering code that moves the thematic layers around in ArcGIS's TOC is quite elegant and not extremely long (but there is a more extensive framework behind it using ArcGIS Modelbuilder models to actually create the database tables / ArcGIS feature classes necessary as the source data for the layers)\nBelow is a nice - but special case! - example. It is special, because the same code that drives the stacking and ordering for normal linear ways, has been used here to additionally stack OSM's area:highway=x features, which are Polygon representations of road surfaces. You can even see it correctly stacking normal \"linear\" roads, and two tram ways (the thin black lines running below the viaduct) in a mix of these feature types.\nThe corresponding carto rendering (only based on linear way objects) - also looking good and technically correct by the way! - can you view via this link:\nhttps://www.openstreetmap.org/#map=17/53.42557/14.56583\n\n. While I agree there is probably an issue with the handling of the old style multipolygon based on the description you gave, the tagging of the feature is at least also bogus: there is nothing wrong with the boundary sharing nodes with a stream or river, if that stream or river is the natural but officially recognized boundary, but instead of adding the tags of the boundary to the stream, only the nodes should have been shared. This way, there would have been two linear way features with their own OSM ID, and not one, that gives rise to this issue.\nSo, my advice to solve this: remove the waterway (or boundary) tags from the feature, and draw a second feature in JOSM or iD and merge or share the nodes, and subsequently put the removed tags now on the new feature.\nAdvantage of the shared nodes is the position of the boundary and river will always be tied together. Disadvantage of sharing the nodes is of course that it will be more difficult to select or distinguish the different features in the OSM editor. Alternatively, a completely separate way spatially distinct, could be drawn, but then you don't have the advantage (or disadvantage?) of the exact shared nodes .\nNote: I am not involved in osm2vectortiles, just a general remark.\nLastly, this issue may actually be an osm2pgsql one, which you should report here:\nhttps://github.com/openstreetmap/osm2pgsql\n. ",
    "d1g": "\nthat are members of the European Union\n\nI think Geofabik definition of the Europe is more practical: 1 compared to the 2 - i.e. split by continents and historical relations, not by current alliances (Switzerland? Norway? Serbia? Turkey?).\n. ",
    "gustaflarsson": "Yes, Europe would be a great addition. Would be great.\n. ",
    "mtfurlan": "@lukasmartinelli  I'm sorry, I just had a fundamentally wrong approach to my problem. I don't need the extra data, I just needed higher zoom and I was using the mapbox gl style wrong, so it was just requesting higher zoom tiles, so I thought \"Well, better figure out how to make higher zoom tiles\"\nThat was a lot of time I didn't need to spend.\nI'll try to make a pull request for USAGE.md this evening.\nThanks for the quick response to my wrong approach.\n. ",
    "Baloobear": "Thank you for the quick response.\nJust a quick note: your project website http://osm2vectortiles.org/docs/own-vector-tiles/ still mentions the old link.\n. ",
    "xingdavis": "@ImreSamu Thank you.\n. ",
    "savvdm": "GIS-Lab provides extracts for OSM data, and I'm talking about vector tiles here. Sorry for not being clear. I mean prepared downloads like those available here: http://osm2vectortiles.org/downloads/\n. I think it also make sense to add tiles for these divisions: http://garmin.osm.rambler.ru/federal/\nI just don't know were to get their boundaries.\n. Found federal districts on geofabric.de, added to the first comment.\n. ",
    "vespakoen": "Should probably add some ST_Simplify's in here?\nChanging geometry in the SELECT clause to something like:\nsql\nST_Simplify(geometry, 0.5) AS geometry\nWhere 0.5 can be adjusted based on the zoom level.\nOr is this optimisation done elsewhere?\n. There is a table showing the m/pixel over here: http://wiki.openstreetmap.org/wiki/Zoom_levels\n. Interesting as well:\nhttps://carto.com/blog/speeding-up-tiles-rendering/\nAt the bottom of that page it links to a \"patch\" which is an interesting read as well...\n. Check my pull, I gave this a go, can you share your script to calculate layers / points in a tile?\n. I see, I am still experimenting with the tolerance values, it seems it could use some more detail at certain zoomlevels.\nSimplification\nAre you ok with duplicating data to have it optimized for all zoomlevels?\nFor example, I now changed the mapping to this:\nyaml\ngeneralized_tables:\n // ...\n  road_geometry_z13:\n    source: road_geometry\n    tolerance: 9\n  road_geometry_z12:\n    source: road_geometry_z13\n    tolerance: 19\n  road_geometry_z11:\n    source: road_geometry_z12\n    tolerance: 38\n  road_geometry_z10:\n    source: road_geometry_z11\n    tolerance: 77\n  road_geometry_z8toz9:\n    source: road_geometry_z10\n    tolerance: 229\n  road_geometry_z6toz7:\n    source: road_geometry_z8toz9\n    tolerance: 916\n  road_geometry_z5:\n    source: road_geometry_z6toz7\n    tolerance: 2444\nThen in roads.sql:\n``` sql\nDROP VIEW IF EXISTS road_z5 CASCADE;\nCREATE VIEW road_z5 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n    FROM osm_road_geometry_z5\n    WHERE road_class(type, service, access) IN ('motorway', 'trunk');\nDROP VIEW IF EXISTS road_z6toz7 CASCADE;\nCREATE VIEW road_z6toz7 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n    FROM osm_road_geometry_z6toz7\n    WHERE road_class(type, service, access) IN ('motorway', 'trunk', 'primary');\nDROP VIEW IF EXISTS road_z8toz9 CASCADE;\nCREATE VIEW road_z8toz9 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n    FROM osm_road_geometry_z8toz9\n    WHERE road_class(type, service, access) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'major_rail');\nDROP VIEW IF EXISTS road_z10 CASCADE;\nCREATE VIEW road_z10 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n    FROM osm_road_geometry_z10\n    WHERE road_class(type, service, access) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'tertiary', 'major_rail');\nDROP VIEW IF EXISTS road_z11 CASCADE;\nCREATE VIEW road_z11 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n    FROM osm_road_geometry_z11\n    WHERE road_class(type, service, access) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'tertiary', 'major_rail', 'street', 'ferry');\nDROP VIEW IF EXISTS road_z12 CASCADE;\nCREATE VIEW road_z12 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, 'none'::varchar(4) AS structure, z_order\n    FROM osm_road_geometry_z12\n    WHERE road_type_class(type) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'tertiary', 'major_rail', 'street', 'ferry', 'pedestrian', 'service', 'link', 'construction', 'street_limited', 'aerialway');\nDROP VIEW IF EXISTS road_z13 CASCADE;\nCREATE VIEW road_z13 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, road_structure(is_tunnel, is_bridge, is_ford) AS structure, z_order\n    FROM osm_road_geometry_z13\n    WHERE road_type_class(type) IN ('motorway', 'motorway_link', 'trunk', 'primary', 'secondary', 'tertiary', 'major_rail', 'street', 'ferry', 'pedestrian', 'service', 'link', 'construction', 'street_limited', 'aerialway', 'track');\nDROP VIEW IF EXISTS road_z14 CASCADE;\nCREATE OR REPLACE VIEW road_z14 AS\n    SELECT id AS osm_id, geometry, type, construction, tracktype, service, access, oneway, road_structure(is_tunnel, is_bridge, is_ford) AS structure, z_order\n    FROM osm_road_geometry;\n```\nPerhaps this kind of detail will come big DB size?\nZoomlevel grouping\nI also noticed some differences in grouping zoom levels, e.g.\nlanduse:\nlanduse_z5toz6\nlanduse_z7toz8\nlanduse_z9\nlanduse_z10\nlanduse_z11\nlanduse_z12\nlanduse_z13to14\nroad:\nroad_z5\nroad_z6toz7\nroad_z8toz9\nroad_z10\nroad_z11\nroad_z12\nroad_z13\nroad_z14\nShould we try to generalize those groupings or are they different for a reason?\nTests\nI changed the test, at least it continued further, but it fails when it tries to store stuff in a S3 bucket.\nShould we perhaps setup Travis to run a different pipeline for PR's?\nWould be nice to see some reports on file size, processing time etc when making changes.\n. ",
    "gkrathwohl": "Thanks for the response. I do think there should be an easier way to modify this. In the case of showing 'track's and 'path's at lower zoom levels it's extending the basemap. In the case of the mountain peaks it's more of an overlay. These are really cartographic choices - you can't say you have the ability to style your map if you can't choose when data appears and disappears. Maybe there's a way to separate this logic from the boilerplate of importing and exporting.\ncustom-vt-skeleton didn't work for me on first try, but I'll spend some more time trying. Thanks!\n. ",
    "roblabs": "I had a similar need for certain road types at lower zoom levels as @gkrathwohl. \nTo update roads at lower zoom levels can be done by updating the import-sql container.  It was not enough just to edit road.sql on my local hard drive, the import-sql container also needed a copy of the new SQL.\nThe Docker Image had the original SQL from the OSM2VectorTiles project.  Any changes to the SQL that you want to configure need to be in Docker Container before you run docker-compose.\nUpdate the SQL in the container import-sql\n```\nlist -all container ids\ndocker ps -a\nModify your src SQL\nexport CONTAINER_ID=c8211d1957bc   # your container id here\ndocker cp src/import-sql/layers/road.sql $CONTAINER_ID:/usr/src/app/layers\nrun import-sql & export as before\n```\nMore details and sample SQL at https://github.com/roblabs/osm2vectortiles/blob/master/examples/rhode-island.md. @joaokho, thanks for the notes, as it was helpful to me, as I was modifying the basic-v9.json style that was provided with tileserver-gl\nI've found that the value for \"url\" can be written as \"url\": \"mbtiles://{osm2vectortiles}\" so you can use the the style no matter which .mbtiles you serve up.\nThere also may be a template such as {style} that can be used in the \"sprite\" key, but I have not tried that.\njavascript\n    \"sources\": {\n        \"mapbox\": {\n            \"url\": \"mbtiles://{osm2vectortiles}\",\n            \"type\": \"vector\"\n        }\n    },\n    \"sprite\": \"sprites/bright-track\",\n    \"glyphs\": \"glyphs/{fontstack}/{range}.pbf\",\nAs you mentioned, the json and png files in the sprites folder need to be named correctly.\n. ",
    "pendolf": "Confirm, I am getting same error.\n```\n$ docker-compose run -e BBOX=\"69.265,39.1728,80.2296,43.2668\" -e MIN_ZOOM=\"0\"  -e MAX_ZOOM=\"22\" export\nWARNING: The AWS_S3_HOST variable is not set. Defaulting to a blank string.\nWARNING: The AWS_SECRET_ACCESS_KEY variable is not set. Defaulting to a blank string.\nWARNING: The AWS_ACCESS_KEY_ID variable is not set. Defaulting to a blank string.\nStarting osm2vectortiles_pgdata_1\n/usr/local/lib/node_modules/tilelive/bin/tilelive-copy:100\n        if (err) throw err;\n                 ^\nError: Postgis Plugin: ERROR:  relation \"admin_z1toz2\" does not exist\nLINE 9:     FROM admin_z1toz2\n                 ^\nin executeQuery Full sql was: 'SELECT * FROM (\n  SELECT osm_ids2mbid(osm_id, false) AS osm_id, geometry, admin_level, disputed, maritime\n  FROM (\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z0\n    WHERE z(3.40282e+38) = 0\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z1toz2\n    WHERE z(3.40282e+38) BETWEEN 1 AND 2\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z3\n    WHERE z(3.40282e+38) = 3\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z4toz5\n    WHERE z(3.40282e+38) BETWEEN 4 AND 5\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z6\n    WHERE z(3.40282e+38) = 6\n    UNION ALL\n    SELECT osm_id, geometry, admin_level, disputed, maritime\n    FROM admin_z7toz14\n    WHERE z(3.40282e+38) BETWEEN 7 AND 14\n  ) AS admin\n  WHERE geometry && ST_SetSRID('BOX3D(-3.402823466385289e+38 -3.402823466385289e+38,3.402823466385289e+38 3.402823466385289e+38)'::box3d, 3857)\n) AS data LIMIT 0'\nat Error (native)\nat /usr/local/lib/node_modules/tilelive-tmsource/index.js:111:18\nat Array.map (native)\nat normalize (/usr/local/lib/node_modules/tilelive-tmsource/index.js:100:35)\nat /usr/local/lib/node_modules/tilelive-tmsource/index.js:185:19\nat tryToString (fs.js:414:3)\nat FSReqWrap.readFileAfterClose [as oncomplete] (fs.js:401:12)\n\n```\n. ",
    "Eng3l": "my bad. My goal is to make a local server that provides information for two JavaScript libraries leaflets and openlayers so rendering images would was my first approach. \nIs there a way to do it, provide those vector tiles as images on serverside?\n. ",
    "joaokho": "Thanks for help...  :+1: \nEventually succeed, after many trying...\nMy \"config.json\" : (copy paste from http://tileserver.readthedocs.io/en/latest/config.html with little change:\n```\n{\n  \"options\": {\n    \"paths\": {\n      \"root\": \"\",\n      \"fonts\": \"glyphs\",\n      \"sprites\": \"sprites\",\n      \"styles\": \"styles\",\n      \"mbtiles\": \"\"\n    },\n    \"domains\": [\n      \"localhost:8080\",\n      \"127.0.0.1:8080\"\n    ],\n    \"formatQuality\": {\n      \"jpeg\": 80,\n      \"webp\": 90,\n      \"pngQuantization\": false,\n      \"png\": 90\n    },\n    \"maxSize\": 2048\n  },\n  \"styles\": {\n    \"basic-v9\": {\n      \"style\": \"basic-v9.json\",\n      \"tilejson\": {\n        \"type\": \"overlay\",\n        \"bounds\": [8.44806, 47.32023, 8.62537, 47.43468]\n      }\n    },\n    \"bright-v9\": {\n      \"style\": \"bright-v9.json\",\n      \"serve_rendered\": false,\n      \"tilejson\": {\n        \"type\": \"overlay\",\n        \"bounds\": [8.44806, 47.32023, 8.62537, 47.43468]\n      }\n    }\n  },\n  \"data\": {\n    \"indonesia_v2-vector\": {\n      \"mbtiles\": \"indonesia_v2.mbtiles\"\n    }\n  }\n}\n```\ncopy paste from installing .npm/tileserver-gl-styles/0.3.0/package/ folder:\n- glyphs\n- sprites\n- styles\ninto my tileserver-gl-light executed folder\nediting : basic-v9.json & bright-v9.json : \n```\n{\n    \"version\": 8,\n    \"name\": \"Basic\",\n    \"sources\": {\n        \"mapbox\": {\n            \"url\": \"mbtiles://indonesia_v2.mbtiles\",\n            \"type\": \"vector\"\n        }\n    },\n......\n```\n. Trying downloaded Mapbox Bright styles from Mapbox Studio:\nThings need changes/update  : \n\"sources\": {\n        \"mapbox\": {\n            \"url\": \"mapbox://mapbox.mapbox-streets-v7\",\n            \"type\": \"vector\"\n        }\n    }\n    \"sprite\": \"mapbox://sprites/joaokho386/citjhubx2004n2hrsylmtak55\",\n    \"glyphs\": \"mapbox://fonts/mapbox/{fontstack}/{range}.pbf\",\nto\n\"sources\": {\n        \"mapbox\": {\n          \"url\": \"mbtiles://indonesia_v2.mbtiles\",\n          \"type\": \"vector\"          \n        }\n    },\n    \"sprites\": \"sprites/bright-v9\",\n    \"glyphs\": \"glyphs/{fontstack}/{range}.pbf\",\nthen very important is you need to supply sprites.json & sprites.png same as the style filenames, example: \"mapbox_bright.json\"\nthen u need copy paste from sprites/ folder:\nbright-v9.json --> mapbox_bright.json\nbright-v9.png --> mapbox_bright.png\n. Ok. thank you very much @ImreSamu .\nI trying to convert my own raw vector map into osm format, using python programming and some osm tools like osmconvert, osmosis, and found osm2vectortiles is very helpful to change to vector format, that maybe could be implemented to help people to carthographic the tile display.\n. Thanks @ImreSamu.\nI also get from modified MapboxStreet-v7.\nEasily is add new sections on your stylesheet.json, example: my modified one:\n```\n        {\n            \"id\": \"housenum-label\",\n            \"type\": \"symbol\",\n            \"source\": \"mapbox\",\n            \"source-layer\": \"housenum_label\",\n            \"interactive\": true,\n            \"filter\": [\n                \"all\",\n                [\n                    \"has\",\n                    \"house_num\"\n                ],\n                [\n                    \"in\",\n                    \"$type\",\n                    \"Point\"\n                ]\n            ],\n            \"layout\": {\n                \"text-font\": [\n                    \"Open Sans Regular\"\n                ],\n                \"text-field\": \"{house_num}\",\n                \"text-size\": {\n                    \"base\": 0.8,\n                    \"stops\": [\n                        [\n                            18,\n                             8\n                        ],\n                        [\n                            20,\n                            10\n                        ]\n                    ]\n                }\n            },\n            \"paint\": {\n                \"text-color\": \"#633\",\n                \"text-halo-color\": \"rgba(255,255,255,0.8)\",\n                \"text-halo-width\": 1.2\n            }\n        },\n```\nhope that help others :-)\n. I look at data.yml all the query is limited to zoom level 14 only, so i think it's no need to docker-compose to assign generate vector tile more than zoom level 14, it is correct?\n. Thanks\n. ",
    "bertrandmd": "Hi,\nhave you planned an release of planet file with the fix of pedestrian roads label ?\nthks\n. for the now, if you want to recreate your own extract, you must add 'pedestrian' in sql view road_label_z12toz13 an road_label_z14 in src/import-sql/layers/road_label.sql\n and rebuild the docker image sql docker build -t osm2vectortiles/import-sql src/import-sql\nand reuse the documented process with docker.\n. ",
    "mariansedivy": "Hi,\nI'm also interested in this. Can you please tell me how to fix this if it is possible now, or when we can expect this to be fixed? \nI also want to tell you that this is a great project and I wish you good luck with future development.\nMapbox tiles\n\nOsm2vectortiles\n\n. ",
    "kekscom": "Hi,\nI'm considering to join your efforts and go for Vector Tile support in OSM Buildings.\nIs there a chance to include a lot more attributes, i.e. building levels, roof shapes etc.?\nPacking as JSON string would be fine.\nWith that, I could also imagine an extended version of MapboxGL in terms of 3D buildings.\n. @stirringhalo First I needed to know whether you would be interested in adding more information. As coverage with extended buildings tags varies a lot, it might not make sense to predefine e fixed attribute set.\nOnce there is an agreement about that, I'm fine to work on the renderer.\n. ",
    "nicooprat": "Amazing! Any idea what's happening with the Eiffel Tower though? https://openmaptiles.github.io/klokantech-3d-gl-style/#15.85/48.8593/2.2959/0/57. Oh too bad! Thanks for the explanation. And your work, of course :). ",
    "longlostbro": "How do you create an mbtiles from a tm2 source?\n. I'm not sure I understood your reference to \"Be aware of legal issues with deploying OSM2VectorTiles tiles\" #387\nWhat I understand is it is claimed to be illegal to \n\nto produce vector tiles which are reproducing their tile schema directly\nto distribute and use such map tiles\n\nIf so, then what you are saying is that although it is possible to do as I request, and create a mbtiles with only the selective layers I require, producing a smaller file, it is illegal.\nTo use something that has not been approved or rather that I create is the part that is illegal.\n. Thank you for your responses. They have been very helpful. I see you are at 35% for the v3.0 milestone and have no due date. Is this something you expect to take weeks, months, or years? Just getting a ballpark estimate.\n. Will v3 work with mapnik still?\nOn Thu, Oct 27, 2016, 3:31 AM Lukas Martinelli notifications@github.com\nwrote:\n\nThank you for your responses. They have been very helpful. I see you are\nat 35% for the v3.0 milestone and have no due date. Is this something you\nexpect to take weeks, months, or years? Just getting a ballpark estimate.\nRelease is end of 2016.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/osm2vectortiles/osm2vectortiles/issues/455#issuecomment-256593203,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AFgqBwuuzTPSOO5CK9cwv43ub32ZXjgoks5q4G9QgaJpZM4KbjLf\n.\n. I assume the new schema will be under the MIT license. In late November I may be able to help out in that regard. When the time comes, where would I look to get started on the port?\n. Similary, but I would like to do it with an osm or osm.pbf data file. Generate a vector tile for a specific x/y/z from an osm file.\n. it seems osmconvert only keeps the nodes,ways, and relations that they have in common when merging.. \n",
    "pokyah": "Thanks @lukasmartinelli,\nnow it effectively works ! I just get another problem : above a certain zoom level I get the following error in my navigator console : GET http://localhost:8080/data/osm2vectortiles/15/24148/13756.pbf 404 (Not Found)\nI'll check it by myself but if you have a quick suggestion ? \nThanks again \n. ",
    "TFreudi1": "I'm a bit further, I can put my style, fonts and icons in the assets folder and then use asset:// as style url.\nNow it loads the style and loads a map if put a online source in the style file like this sample \n\"sources\": {\n        \"osm2vt\": {\n            \"url\": \"http://osm2vectortiles.tileserver.com/v1.json\",\n            \"type\": \"vector\"\n        }\n    },\nBut it didn't work if I use \"url\":\"asset://planet.mbtiles\" or \"url\":\"mbtiles://planet.mbtiles\"\n. ",
    "AlexSheiko": "@klokan, does your setStyleUrl line look like asset://planet.mbtiles?\nIf so, what version of the library are you using, is it a recent one?\nPersonally, I'm trying to make offline tiles work on Mapbox 5.0.1, and it doesn't seem to read mbtiles from assets.. ",
    "mg262": "@lukasmartinelli The docs say \n\nThe image file format of the tile data: png or jpg\n\nwhich pretty clearly indicates that it's only meant for raster data.  Later it states:\n\nThe tile_data blob column contains raw image data in binary.\n\nAnd gives PNG and JPG as options. \nNB. I'm not trying to be pedantic; from reading your docs + the mbtiles docs, I don't have a clue how you are actually storing the vector data.  My guess is that you are storing it in tile_data, but beyond that ...?  Are you using some unpublished extension to MBtiles? \n. Thank you @lukasmartinelli !\n. It wasn't a criticism -- I need particularly compact tiles as they will be used on tablets.  Am I right in thinking that I can drop the filesize a lot by tinkering with https://github.com/osm2vectortiles/osm2vectortiles/tree/master/osm2vectortiles.tm2source/data.yml to remove the things I don't need?  Is that the easiest approach?\n. Thanks!. Thanks!. @gistack See http://gis.stackexchange.com/questions/217704/vector-tile-formats-vector-mbtiles-and-mvf .. It would be useful to know if this is unintended or whether there is some reason these ways need to be listed twice. Thanks!. ",
    "edpop": "Much better to make all layer generation scripts to be namespaced to let user copy folder mb_streets_v7_like to my_layer_scripts and change then.. ",
    "Komzpa": "@edpop what exactly would you like to get fixed to get this request merged upstream?. ",
    "ghost": "OK I understand your answer. \nWhat is the tool to ungzip the mbtiles ? I would like to see the data. Is it a Geojson, topojson or json ?\nThx. ",
    "Tom-Cuthill": "I found a clue here: http://gis.stackexchange.com/questions/127137/openlayers-3-scale-past-nativezoom-like-leaflet.  They claim that if the vector tile source has a zoom level set to the best resolution in the source (ie. 14) and the view has its maxZoom set to a bigger zoom number (eg. 19) that OpenLayers should extend past the native zoom level (14) and render all the way down to 19.  \nI tried this but didn't see any differences in the displayed map (making sure I flushed the cache in the browser).  \nHere is the revised code that I used:\n`private getMapOptions(OSMapURL: string): olx.MapOptions {\n            var layers: Array = new Array();\n            var OSMTileURL: string = OSMapURL + \"/{z}/{x}/{y}.pbf\";\n            var osmTileOptions: olx.source.VectorTileOptions =  {\n                attributions: '\u00a9  OpenStreetMap contributors',\n                format: olMVTFormat = new ol.format.MVT();\n                // projection: null,\n                maxZoom: 14,\n                tileGrid: ol.tilegrid.createXYZ({ minZoom: 4, maxZoom: 14 }),\n                tilePixelRatio: 16,\n                url: OSMTileURL\n            };\n            var OSMsource: ol.source.VectorTile = new ol.source.VectorTile(osmTileOptions);\n            var osmVectorLayerOptions: olx.layer.VectorTileOptions = {\n                source: OSMsource,\n                style:OperationsControllerModule.createMapboxStreetsV6Style(),\n                // renderMode: 'vector',\n                // renderOrder: this.defaultRenderOrder\n            }\n            var OSMLayer: ol.layer.VectorTile = new ol.layer.VectorTile(osmVectorLayerOptions);\n            layers.push(OSMLayer);\n        var initCenter = ol.proj.transform([133.9, -23.69], 'EPSG:4326', 'EPSG:3857');\n        var viewOptions: olx.ViewOptions = <olx.ViewOptions>{\n            // projection: ol.proj.get(\"EPSG:4326\"),\n            center: initCenter,\n            minZoom: 4,\n            maxZoom: 19,\n            zoom: 12\n        };\n\n        var view: ol.View = new ol.View(viewOptions);\n\n        return <olx.MapOptions>{\n            layers: layers,\n            target: 'map',\n            view: view\n        }\n    }`\n\nAgain, any hints or ideas would be most appreciated!\nCheers,\nTom. ",
    "rammi22": "Ok, \ncan close, it works with the right zoom and with a config.json. ",
    "mkjaer": "What did you change to get to the result in your second post?\nIt looks like you simply removed the mount, which will not work as intended.\nI think your original issue is because of this (original post):\n\nBreaking changes\nWhen using Compose with Docker Toolbox/Machine on Windows, volume paths are no longer converted from C:\\Users to /c/Users-style by default. To re-enable this conversion so that your volumes keep working, set the environment variable COMPOSE_CONVERT_WINDOWS_PATHS=1. Users of Docker for Windows are not affected and do not need to set the variable.. \n",
    "chrissng": "@klokan Thanks for reviewing my PR!\nOpenMapTiles looks cool and it is new to me, is this going to be the successor to OSM2VectorTiles?\nNevertheless, with the development of OSM2VectorTiles V3 in mind, this might still be a useful for users who have adopted V2 in their existing work.. ",
    "int19h": "Closing it here and opening in tileserver-php instead.\nhttps://github.com/klokantech/tileserver-php/issues/95. FWIW, I'm having the same exact problem on Windows.\nI'd like to avoid Linux in Docker if at all possible, because it consumes quite a lot of space (which, when maps are involved, is already precious).. This particular issue is not actually FreeBSD related - note that this is about serving premade tiles, not generating them. Turned out it was entirely a client-side issue: I just needed to set up the styles properly. This is discussed in the comments to the other issue linked above, for those hitting the same problem.. ",
    "ischas": "Maybe related to https://github.com/openlayers/openlayers/pull/6358. ",
    "jdeboer-geoplan": "If I use http://osm2vectortiles-2.tileserver.com/v1/{z}/{x}/{y}.pbf I still see the issue, That openlayers bug looks like it could be the problem I'll get the fix, try again and report back.. Ok, yes it was https://github.com/openlayers/openlayers/pull/6358 I fixed it by giving the water a stroke.\nThank you for the quick reply.. ",
    "scpeterson": "Sorry, this was meant for the tileserver-gl project.  Please close or delete.. "
}