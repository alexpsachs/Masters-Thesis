{
    "otoolep": "This has been started in system_test.go.\n. https://github.com/otoolep/rqlite/pull/91\n. Decent testing in place now.\n. All done for now.\n. This has been implemented, and master now supports it.\n. It would probably be better if the consistency level was actually a URL parameter.\n. Interesting @codahale -- I did read that article many months ago, but didn't realise the implication that queries through the log might be required to be 100% sure.\nThat said I did just add support for a verify URL param, which forces the system to call:\nhttps://godoc.org/github.com/hashicorp/raft#Raft.VerifyLeader\nNow that I think about it, there is probably still room for a race here. Very small, but still possible.\n. I'm sure I will. Thanks @aphyr \nI'll fix up verify to do it right so.\n. > For a read operation, the result is potentially stale as soon as the data is received by the client.\nAgreed. Once it hits the client, it could always be out-of-date regardless.\nWhat I thought my verify change had done was ensure 100% that the query was performed when the node was the leader. Of course, a little though showed this not to be the case. While I will add an option so that the client can be sure the node was the leader when the query executed (the query will be a no-op through the log) the data could be still out-of-date by the time client gets it. But this level of consistency may be useful to some people.\n. rqlite now supports 3 different levels of read consistency -- none, soft, and hard. The first just goes to the local SQLite file, soft does a local leader check before reading the local SQLite file, and hard sends the query request through the raft consensus mechanism. I think this addresses this issue, let me know if I am mistaken.\n. soft is the default.\n. Actually, moved to \"weak\" and \"strong\".\n. Yes, Go would be my first choice.\n. rqlite just launches the server. What I had in mind is something like this:\n$ rqlite-cli\nrqlite> SELECT * from foo\n.\n.\nwhich would take the input from the prompt, send to the API, read the results back, and render them nicely.\n. It would need to be launched something like so:\nrqlite-cli -h 127.0.0.1:8086\n. This is the difference between mysqld and mysql.\n. Closed in error.\n. See this commit: https://github.com/otoolep/rqlite/commit/649cef2adb4bc36585e3f798ee51bc697f9a7e1d\nThis would be the right place to add the CLI program. Once built, it would then appear in $GOPATH/bin.\n. And this: https://github.com/otoolep/rqlite/commit/0b528659494bcbd85baf3d0dbdb7f47276cf132e\nThis would be the program to work on.\n. https://github.com/rqlite/rqlite/pull/118\n. Yes, if you kill the leader of the cluster, one of the other nodes should take over and become leader. This functionality comes with the goraft implementation, not specifically rqlite.\nLet me double-check this is what happens.\n. I added a /raft endpoint, which dumps details of the underlying Raft node. When I killed the leader, one of the other nodes became the leader.\n$ curl localhost:4001/raft?pretty\n{\n    \"leader\": \"aba949b\",\n    \"name\": \"247f1b9\",\n    \"peers\": {\n        \"60042f5\": {\n            \"name\": \"60042f5\",\n            \"connectionString\": \"http://localhost:4003\"\n        },\n        \"aba949b\": {\n            \"name\": \"aba949b\",\n            \"connectionString\": \"http://localhost:4002\"\n        }\n    },\n    \"state\": \"follower\"\n}\nKill the leader, node aba949b, then issue the command again. Note how the node on port 4001 then becomes leader.\n$ curl localhost:4001/raft?pretty\n{\n    \"leader\": \"247f1b9\",\n    \"name\": \"247f1b9\",\n    \"peers\": {\n        \"60042f5\": {\n            \"name\": \"60042f5\",\n            \"connectionString\": \"http://localhost:4003\"\n        },\n        \"aba949b\": {\n            \"name\": \"aba949b\",\n            \"connectionString\": \"http://localhost:4002\"\n        }\n    },\n    \"state\": \"leader\"\n}\n. Code looks fine.\n$ go test -race ./...\n?       github/otoolep/rqlite   [no test files]\nok      github/otoolep/rqlite/command   0.006s\nok      github/otoolep/rqlite/db        1.045s\n?       github/otoolep/rqlite/interfaces        [no test files]\nok      github/otoolep/rqlite/server    1.214s\n. No, I didn't create anything like that. It does expose a HTTP API, so it would be easy to use from any language. Just create a HTTP client in your favorite language, and make the necessary GET and POST requests. \n. Thanks @ctrlrsf \n. I think you're passing -join again, when restarting the process. Don't do that -- simply start the process without the -join command, but be sure to still pass the \"node\" directory path. -join is only for one-time use.\nIf this addresses the issue, let me know. I can then clarify the documentation.\n. Pass nothing on restart except the path and the port. For example, if the node was restarted like so:\nrqlite -join localhost:4001 -p 4003 ~/node.3\nit should always be restarted like so:\nrqlite -p 4003  ~/node.3\nJoining is a special case, only executed once. Once joined, a node gets all else it needs on a restart from the data in its node directory.\nAs for the raft endpoint, that returns the nodes that are members of in the cluster, not which are actively up.\n. Sure definitely makes sense to me. I have opened a ticket:\nhttps://github.com/otoolep/rqlite/issues/13\nI am also going to update the README so restart is clarified.\n. No longer applicable.\n. OK, this is interesting. Let me see if I can repro your findings and see why this is happening.\n. Can you try something else? Instead of simply waiting 5 seconds, can you instead block from accessing the database until the /diagnostics endpoint returns with 200? Once that returns, then check if the local sqlite copy is readable.\nI am wondering if you're not waiting for the node to fully initialize, but the endpoint above should only return once the node is ready.\n. I can't repro this issue. I start rqlite and immediately have sqlite3 read the database. It has no problems doing so, and I don't need any delays.\nCan you produce a bash script that reproduce this? The simple script shown below tells me the database is available for reads once the HTTP endpoint is responsive:\n$ cat test.sh \n./rqlite -p 4002 ~/node.2 &\nwhile true; do\n    curl localhost:4002/diagnostics\n    if [ $? -eq 0 ]; then\n        break\n    fi\ndone\necho \"SELECT * from foo;\" | sqlite3 ~/node.2/db.sqlite\n. - Is all your testing with a single node right now?\n- How large is your database?\n- Have you tried reproducing read failures during this time by using sqlite?\n. How is the node being shut down, before the restart? Just killing the process? SIGTERM or SIGKILL?\n. Does this happen every time now? Any chance you could send me the database (by e-mail, perhaps?)\n. OK.\nSIGKILL should be OK, sqlite is meant to handle that fine. With your database, does this happen 100% of the time?\n. Hmm, OK. I can try to load in some records and see if I can repro it. How many records do you have? How many tables? Can you share your schema?\n. I think db.sqlite would be sufficient, once it's all settled. You can e-mail it to me if you like (address on my profile).\n. OK @tchoulihan -- I went back to the source, to remind myself about the start-up scenario. This is what is happening, and it's an intrinsic part of the way the system works.\nWhen a node is restarted, the Raft log is re-applied to the database so that the system returns to the state it was in before it was killed. This is the point of the Raft design, as it is based on a distributed log. Of course, over time this log would get very large as there is an entry in there for every change to the database that ever took place. That is why rqlite supports snapshotting -- snapshots make a copy of the database, and then truncate the log up that point. On start-up, if a snaphot exists, the database is recreated from the snapshot and only log entries (changes to the database) that took place after the snap was created are then applied. This means the system starts up much quicker when there is a snapshot available, relative to replaying the entire log from the start of time.\nrqlite, by default, creates a snapshot every 1,000 changes. This means on restart the node may need to re-apply up to 1,000 changes to get back to a consistent state. I didn't give 1,000 too much thought, and it seems too high for your system. Try changing it to 100, or even 50, which will mean quicker restart times. With a setting of 100, it means at most there will be 100 changes that need to be applied to the database, which should be much faster than 1,000. You might need to go lower. Snaps aren't free of course, as they consume processing power and disk IO (not too much in practise however). It's trade-off between the generating snaps and faster start-up times.\nTo control the snapshot threshold, pass -s at start-up to all your nodes. For example:\nrqlite -s 50\nSo try launching your nodes with this param (or lower) and see how long the database is locked on start up. Make sure performance isn't too badly affected for you. You may need to write another 50 changes to the database to get an actual snap to happen for an existing system. \nLet me know if you have any questions, and if this solves your issue.\n. I have also reduced the default snap setting to 100.\n. Great @tchoulihan -- systems like this sometimes take a non-trivial startup time as they recover state. It's a tradeoff between making those snapshots and start-up time. In a real system, nodes may not actually be started that often, so a longer start-up time every so often may not be a problem.\nI am looking into ways of making the startup even quicker without setting the snapshot threshold that low.  https://github.com/otoolep/rqlite/issues/19\n. When you say \"change the leader\" you mean the cluster elects a new leader, right? I just want to be sure.\nIf I understand this issue, it's basically the same as wanting redirects, right? If we had that, this wouldn't be an issue, correct?\n. The cluster now has basic leader redirection, though I have not performed extensive testing. I just checked that curl -L .... is redirected to the leader node. Let me know how it goes.\n. Let me look into the issue you mentioned above, but that is a good idea about adding -L to the README.\n. Ok, yeah, I only put leader redirection in place for the write endpoint. If you want stats, diags, etc, you need to go out and hit each node individually. Let me know if this is an issue.\n. This is actually a detail within the Raft implementation, so is not a trivial fix to my code. I would need to \"vendor\" the code to fix this. Not ruling it out, but it may not happen soon.\n. Fixed by https://github.com/otoolep/rqlite/commit/106296515fd393f1091130245f4b386c4f93fb78\n. Change https://github.com/otoolep/rqlite/commit/45fef88a7a16f299470e733a09d2e67183316cba means that if an attempt is made to join a node that is not the leader, the request will be redirected to the leader, and joining node will follow that redirect.\nThis should address your issue.\n. Using Raft to sync databases wouldn't really work because it assumes that the nodes are generally in communication, and a quorum can be established so that changes can be replicated across a cluster. That doesn't apply to devices at the edge of network like iPhones.\n. Thanks for your question though @mamcx .\n. This may, or may not, be an issue with the Hashicorp Raft module.\n. Some testing of the 2.0 system, which uses Hashicorp, shows that these startup delays are no longer an issue.\n. I cannot reproduce any build issues with rqlite.\n$ mkdir rqlite\n~ $ cd rqlite/\n~/rqlite $ export GOPATH=$PWD\n~/rqlite $ go get github.com/otoolep/rqlite\n~/rqlite $ go get gopkg.in/check.v1; go test github.com/otoolep/rqlite/...\n?       github.com/otoolep/rqlite       [no test files]\nok      github.com/otoolep/rqlite/command       0.002s\nok      github.com/otoolep/rqlite/db    1.215s\n?       github.com/otoolep/rqlite/interfaces    [no test files]\nok      github.com/otoolep/rqlite/server        1.213s\n~/rqlite $ $GOPATH/bin/rqlite ~/node.1\n[03/22/15 09:34:37] [INFO] Redirectoring logging to stdout\n[03/22/15 09:34:37] [INFO] Raft random seed initialized\n[03/22/15 09:34:37] [INFO] Raft commands registered\n[03/22/15 09:34:37] [INFO] Initializing Raft Server: /home/philip/node.1\n[03/22/15 09:34:37] [INFO] Loading latest snapshot, if any, from disk\n[03/22/15 09:34:37] [INFO] Recovered from log\n[03/22/15 09:34:37] [INFO] Initializing HTTP server                                                                              \n[03/22/15 09:34:37] [INFO] Listening at http://localhost:4001\nThe CI system also reports that it is fine: https://circleci.com/gh/otoolep/rqlite/tree/master\n. Try running go get -u from the same directory as that which you build rqlite, though the new change only pulls in standard packages, so I'm not actually sure what is going on.\nWhat version of Go are you running? \n. Great, I'll update the README to make this requirement clear.\n. Completely agree. We should pull log4go and use the standard log package that comes with Go. I used log4go, as I was following patterns in some other projects, but now know better.\nhttp://blog.gopheracademy.com/advent-2014/case-against-3pl/\n. There are two pieces of work I'd like to see done:\n-- make it possible to disable leader redirection, via a switch at the command line. This was introduced in https://github.com/otoolep/rqlite/commit/106296515fd393f1091130245f4b386c4f93fb78, but it should be controllable by a switch, since not everyone wants it.\n-- it would be nice to get https://github.com/otoolep/rqlite/issues/19 done.\n. This is done well enough now, now that rqlite has a changelog and uses the Github releases pages. We might do packages in the future.\n. No, I don't think there should be any problems, though this project does use some C code, so I can't be sure. I haven't tested cross-compilation.\nWhere would you store the debian and RPM packages? Are you thinking about a repo service?\n. Ah yes, I am  familiar with that service. It would be cool to get packages up there. \n. Well, that's the thing @tchoulihan -- unlike Java, one doesn't need Go to run Go programs. Since they are compiled as binaries without any external dependencies (not counting libc), it is of great value to have the binaries packaged as standalone programs. This is in contrast to Java, where even if you package up all the source and JAR files, one still needs the JVM installed. (Apologies if you know all this!)\n. Yeah, definitely up for fixing these. Since the project uses CircleCI, we could generate a custom circle.yml file, and add it to the repo. Then Circle could lint the code.\n. Any interest @fern4lvarez in generating a PR to fix these issues?\n. That makes sense to me. \n. Makes sense @fern4lvarez -- is there any copyright we need to include, since we may just be copying some of the log4go code? \n. I wanted to check that we were not copying and pasting. If we are not, great. \n. Is this still WIP? Build seems green now.\n. Thanks @fern4lvarez -- looks good. I have a few small questions.\n. Looks great @fern4lvarez -- if you squash as you see fit, I will then merge.\n. Thanks again @fern4lvarez \n. Unfortunately I had to revert this change as it causes rqlite to panic.\n```\n $ go get github.com/otoolep/rqlite\n~/r $ $GOPATH/bin/rqlite ~/node.1\n2015/03/28 11:24:59 [INFO ] Raft random seed initialized\n2015/03/28 11:24:59 [INFO ] Raft commands registered\npanic: open /home/philip/node.1/name: not a directory\ngoroutine 1 [running]:\ngithub.com/otoolep/rqlite/server.NewServer(0x7fff7ce15dff, 0x13, 0x8b8b30, 0x9, 0x64, 0x8bd090, 0x9, 0xfa1, 0x7f34929cbf58)\n        /home/philip/r/src/github.com/otoolep/rqlite/server/server.go:200 +0x90e\nmain.main()\n        /home/philip/r/src/github.com/otoolep/rqlite/main.go:97 +0x4c7\ngoroutine 6 [syscall]:\nos/signal.loop()\n        /home/philip/.gvm/gos/go1.4/src/os/signal/signal_unix.go:21 +0x1f\ncreated by os/signal.init\u00b71\n        /home/philip/.gvm/gos/go1.4/src/os/signal/signal_unix.go:27 +0x35\ngoroutine 17 [syscall, locked to thread]:\nruntime.goexit()\n        /home/philip/.gvm/gos/go1.4/src/runtime/asm_amd64.s:2232 +0x1\ngoroutine 7 [runnable]:\ndatabase/sql.(*DB).connectionOpener(0xc2080561e0)\n        /home/philip/.gvm/gos/go1.4/src/database/sql/sql.go:588\ncreated by database/sql.Open\n        /home/philip/.gvm/gos/go1.4/src/database/sql/sql.go:452 +0x31c\n```\nThis is on me really, as I need to improve the test code significantly so something like this is caught by the CI system. The first step in that is fixing issue #27 , which will make testing much easier. \n. The way of starting rqlite is described in the README, and is a valid thing to do.\n. No worries, it happens. I'll improve the unit test, so we can continue development and have the CI system help us catch this stuff earlier.\n. https://github.com/otoolep/rqlite/commit/45fef88a7a16f299470e733a09d2e67183316cba\nIt's only on join. Line 318 needs to be executed conditionally. \n. No longer valid.\n. Can you please show the entire sequence, including setting your GOPATH. \n\nhttp://www.philipotoole.com\n\nOn Apr 2, 2015, at 5:52 PM, bluesun08 notifications@github.com wrote:\nHi,\nwhen i execute \"go get github.com/otoolep/rqlite\" i get the following error:\nsrc/code.google.com/p/goprotobuf/proto/text.go:39:2: no Go source files in /usr/lib/go/src/pkg/encoding\nWhats the problem?\n\u2014\nReply to this email directly or view it on GitHub.\n. Have heard no more -- closing.\n. Well, it is legal JSON. :-)\n\nYeah, it does look a bit weird, I'll grant you that. It's what comes back from the go-raft module actually, but I don't mind changing it.\n. $ curl localhost:4001/raft?pretty\n{\n    \"leader\": \"14af844\",\n    \"name\": \"14af844\",\n    \"peers\": [\n        {\n            \"name\": \"5da4e34\",\n            \"connectionString\": \"http://localhost:4002\"\n        }\n    ],\n    \"state\": \"leader\"\n}\n. Fixed by https://github.com/otoolep/rqlite/commit/7a4c98f383b0721b0f6fc7c7d2f501352619446a\n. Thanks @tchoulihan -- that is eminently sensible. I changed it.\nhttps://github.com/otoolep/rqlite/commit/e51c9ef704635477203b6e29e8862959ca519dd0\n. Thanks @fern4lvarez \n. Yeah, restoring just the database file will not be sufficient. I haven't deeply tested restoring the entire data directory, but I believe that should work. \n. The IP addresses of the nodes in the cluster are contained within that directory. If you expect to be able to move the data directory to a new host with a new hostname, that won't work as far as I know. You could try re-writing the files in the data directory that store the hostname if you needed to -- you'd need to do this on every node.\n. Do any writes take place on the leader, before the attempted join, such that the leader snapshots and then blocks?\n. Do you still see this issue if the snapshot value is very large e.g. 1,000,000,000 -- I am trying to see if a snapshot actually needs to take place for this to happen.\n. Yeah, that sounds likely. I'll try to take a look soon.\n. I can't reproduce this.\nShell 1:\n$ ./rqlite -s 2 ~/node.1\n2015/04/15 00:09:51 [INFO ] Raft random seed initialized\n2015/04/15 00:09:51 [INFO ] Raft commands registered\n2015/04/15 00:09:51 [INFO ] Initializing Raft Server: /home/philip/node.1\n2015/04/15 00:09:51 [INFO ] Loading latest snapshot, if any, from disk\n2015/04/15 00:09:51 [INFO ] no snapshot found\n2015/04/15 00:09:51 [INFO ] Initializing new cluster\n2015/04/15 00:09:51 [INFO ] Initializing HTTP server\nShell 2:\n$ curl -L -XPOST localhost:4001/db?pretty -d 'CREATE TABLE foo1 (id integer not null primary key, name text)'                                                                                                    \n{\n    \"failures\": []\n}\n$ curl -L -XPOST localhost:4001/db?pretty -d 'CREATE TABLE foo2 (id integer not null primary key, name text)'                                                                                                    \n{\n    \"failures\": []\n}\nBack to shell 1, snapshot has taken place:\n2015/04/15 00:09:57 [INFO ] Committed log entries snapshot threshold reached, starting snapshot\n2015/04/15 00:09:57 [INFO ] http://localhost:4001: snapshot of 3 events at index 3 completed\nThen a successful join at shell 3:\n$ ./rqlite -join localhost:4001 -p 4002 ~/node.2\n2015/04/15 00:10:03 [INFO ] Raft random seed initialized\n2015/04/15 00:10:03 [INFO ] Raft commands registered\n2015/04/15 00:10:03 [INFO ] Initializing Raft Server: /home/philip/node.2\n2015/04/15 00:10:03 [INFO ] Loading latest snapshot, if any, from disk\n2015/04/15 00:10:03 [INFO ] no snapshot found\n2015/04/15 00:10:03 [INFO ] Attempting to join leader at localhost:4001\n2015/04/15 00:10:03 [INFO ] Initializing HTTP server\n2015/04/15 00:10:03 [INFO ] Listening at http://localhost:4002\n. @tchoulihan -- can you please post a session like above, showing the failure?\n. I'm going to close this, since it looks fine. Can you check your networking? And feel free to re-open (or create a new ticket) if you can produce a detailed trace.\n. They are not empty for me.\n\nOn Apr 15, 2015, at 6:04 AM, Tyler Houlihan notifications@github.com wrote:\nYep, leave this closed, I just tried to replicate this issue with hundreds of writes and couldn't get the same error I used to. I've noticed the snapshot directories are empty though even when using -s 2 or -s 50. Is this correct?\n\u2014\nReply to this email directly or view it on GitHub.\n. The build is red, so I'll take another look when it passes CI.\n. I'm not sure I follow you. There is nothing special about the \"internet\" per-se, but if the hostname automatically picked up by the software is not one that will allow other nodes to connect to it, then you may need to specify the hostname explicitly. When you say external address, what is an internal address? Are you trying this out on AWS?\n. Hmmm. That is strange. \n\nThere is nothing in rqlite that makes any assumptions about the hostname passed in. It'll either use the one it detects, or the one passed in, and doesn't do anything else special. This sounds more like something about your networking setup, how hostnames are resolved, etc etc., nothing to do with rqlite in particular.\n. I don't follow you. Bounty?\n. Nope, I didn't. That system is obviously auto-generating them.\n. I don't fully understand the issue. You want a non-leader node to rejoin using different hostname?\n. Right now I can't reproduce any issues with failure to join, but I don't load the nodes. I'd need some assistance with loading the server to bring this out. If you can provide a little script that loads the leader, and then shows joining fail, that would help.\n. Same thing. 2 nodes is not a valid configuration. \n. The Raft implementation has been changed, so this is moot.\n. Can you show this happen with curl and show the output from the Raft endpoint at each stage?\n. If you look at the code, it's this line that is the problem:\nhttps://github.com/otoolep/rqlite/blob/6f4a46937c7f213139b342ae244d22a2dda93255/server/server.go#L616\nThis tells me the cluster doesn't have a leader when this happens, it's pretty confused or an election may be taking place.\n. If you look at the reference implementation for systems based on go-raft, you'll see that leader-forwarding was not implemented:\nhttps://github.com/goraft/raftd#why-is-command-forwarding-not-implemented\nI added it, but it has not been tested deeply. I might need to add an option to disable leader redirection, and let client programs -- like yours -- manually redirect to the leader.\n. I pushed up a change: https://github.com/otoolep/rqlite/commit/4f9c12d2347a0e9bbca6aec6cd5b38c922c5e1d5\nThis changes means that if a node attempts leader redirection, but no leader is available, the node will return HTTP 503, and a message explaining what has happened will be in the body. This will prevent the panic you reported above.\nThe real question is why this happens. One explanation is that the node you access is no longer part of the cluster. Are you running this cluster over questionable network links?\n. This means an election is taking place. Let me look into why it keeps happening. It might be that generating snapshots makes the leader seem unresponsive, triggering an election. \nDo all these problems go away if the snapshot value is so high snapshots do not happen?\n. OK, so this is not driven by snapshots. I'll take a look, but I can't guess right now when this will be fixed. It may be difficult to repro on my side, and may be very dependant on the load and environment particular to you.\n. Yeah, a script would be helpful.\n. Thanks Tyler. \nA 2-node cluster is not a valid configuration. Once the leader fails, a new leader cannot be elected, since election would require 2 votes, which is impossible with 1 node gone. You must run at least 3 nodes to be able to withstand failure of a single node. \nPlease retest with 3 nodes. \n\nOn Apr 16, 2015, at 7:10 AM, Tyler Houlihan notifications@github.com wrote:\nOkay I've got it! I've reproduced it locally. A problem seems to be that when a node goes down, the others stay candidates for a really long time.\nHow it works is:\nStart up 2 nodes, do some writes to the leader\nTake down the leader node 1\nKeep writing to node 2 with leader redirection\nget the error message [ERROR] attempted leader redirection, but no leader available\nThis happens about half the time I run it.\nexport GOPATH=$PWD\nStartup 2 nodes\n$GOPATH/bin/rqlite node_1 &\nsleep 2s\n$GOPATH/bin/rqlite -join localhost:4001 -p 4002 node_2 &\nsleep 2s\nDo some big inserts to node 1\ncurl -L -XPOST localhost:4001/db?pretty -d 'CREATE TABLE \"user\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"email\" TEXT DEFAULT NULL,\"password_encrypted\" TEXT DEFAULT NULL,\"name\" TEXT DEFAULT NULL,\"authenticated\" INTEGER DEFAULT NULL,\"email_code\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (email));\nINSERT INTO \"user\" VALUES(1,\"happydooby@gmail.com\",\"zWyTu4eFKjXgNedQyjlA1WacfgcluFDGtxFmzU6iYL4G6jPXFqK1K3xuw+afjqzA\",NULL,\"true\",NULL,\"2015-04-14 00:29:16\");\nINSERT INTO \"user\" VALUES(2,\"tchoulihan@gmail.com\",\"mYmiuWZaS8bndTItTFYbe0lTbUOwoll1Vg23qtdBiEVSlQJpm7Ylqxk6kzptP1wh\",\"derp\",\"true\",NULL,\"2015-04-14 01:20:58\");\nCREATE TABLE \"seller\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"shop_name\" TEXT DEFAULT NULL,\"bitmerchant_address\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (user_id));\nINSERT INTO \"seller\" VALUES(1,1,\"garg\",\"http://96.28.13.51:4567/\",\"2015-04-14 00:29:16\");\nCREATE TABLE \"product\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"seller_id\" INTEGER NOT NULL  DEFAULT NULL REFERENCES \"seller\" (\"id\"),\"category_id\" INTEGER DEFAULT NULL REFERENCES \"category\" (\"id\"),\"buy\" INTEGER DEFAULT NULL,\"auction\" INTEGER DEFAULT NULL,\"quantity\" INTEGER DEFAULT NULL,\"title\" TEXT DEFAULT NULL,\"processing_time_span_id\" INTEGER DEFAULT NULL REFERENCES \"time_span\" (\"id\"),\"physical\" INTEGER DEFAULT 0,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product\" VALUES(1,1,3,NULL,NULL,NULL,\"test_item\",NULL,0,\"2015-04-14 00:30:45\");\nINSERT INTO \"product\" VALUES(2,1,19,NULL,0,10,\"Pink frosted sprinkled donut\",3,0,\"2015-04-14 01:02:24\");\nINSERT INTO \"product\" VALUES(3,1,NULL,NULL,NULL,NULL,NULL,NULL,0,\"2015-04-14 14:09:32\");\nINSERT INTO \"product\" VALUES(4,1,18,NULL,0,NULL,\"A tasty red donut\",NULL,0,\"2015-04-14 14:10:00\");\nINSERT INTO \"product\" VALUES(5,1,25,NULL,0,5,\"A Chocalatey donut\",3,0,\"2015-04-14 14:10:45\");\nCREATE TABLE \"shipment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"address_id\" INTEGER DEFAULT NULL REFERENCES \"address\" (\"id\"),\"tracking_url\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"shipment\" VALUES(1,1,NULL,\"2015-04-14 01:14:21\");\nINSERT INTO \"shipment\" VALUES(2,2,NULL,\"2015-04-14 01:22:16\");\nINSERT INTO \"shipment\" VALUES(3,2,NULL,\"2015-04-14 13:02:23\");\nCREATE TABLE \"review\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"stars\" INTEGER DEFAULT NULL,\"headline\" TEXT DEFAULT NULL,\"text_html\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id, user_id));\nINSERT INTO \"review\" VALUES(1,2,1,3,\"Great donut\",\"Would eat again. 10/10&ltsemicolonbr&gtsemicolon\",\"2015-04-14 14:19:43\");\nCREATE TABLE \"address\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"full_name\" TEXT DEFAULT NULL,\"address_line_1\" TEXT DEFAULT NULL,\"address_line_2\" TEXT DEFAULT NULL,\"city\" TEXT DEFAULT NULL,\"state\" TEXT DEFAULT NULL,\"zip\" INTEGER DEFAULT NULL,\"country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"default_\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"address\" VALUES(1,1,\"fsdafasdf\",\"asdf\",\"asdf\",\"asdf\",\"fdsa\",1235,7,0,\"2015-04-14 01:14:18\");\nINSERT INTO \"address\" VALUES(2,2,\"fdsafd\",\"asdf\",\"asdf\",\"asdf\",\"asdf\",123,8,0,\"2015-04-14 01:22:12\");\nCREATE TABLE \"feedback\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"cart_item_id\" INTEGER DEFAULT NULL REFERENCES \"cart_item\" (\"id\"),\"stars\" INTEGER DEFAULT NULL,\"arrived_on_time\" INTEGER DEFAULT NULL,\"correctly_described\" INTEGER DEFAULT NULL,\"prompt_service\" INTEGER DEFAULT NULL,\"comments\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"feedback\" VALUES(1,2,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 13:02:22\");\nCREATE TABLE \"cart_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"quantity\" INTEGER DEFAULT NULL,\"purchased\" INTEGER DEFAULT 0,\"shipment_id\" INTEGER DEFAULT NULL REFERENCES \"shipment\" (\"id\"),\"payment_id\" INTEGER DEFAULT NULL REFERENCES \"payment\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"cart_item\" VALUES(1,1,2,1,0,1,1,\"2015-04-14 01:11:49\");\nINSERT INTO \"cart_item\" VALUES(2,2,2,1,1,2,3,\"2015-04-14 01:21:52\");\nINSERT INTO \"cart_item\" VALUES(3,2,2,1,0,3,4,\"2015-04-14 13:02:22\");\nCREATE TABLE \"payment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"order_iframe\" TEXT DEFAULT NULL,\"completed\" INTEGER DEFAULT 0,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"payment\" VALUES(1,\"\",0,\"2015-04-14 01:13:57\");\nINSERT INTO \"payment\" VALUES(2,NULL,0,\"2015-04-14 01:22:01\");\nINSERT INTO \"payment\" VALUES(3,\"\",1,\"2015-04-14 01:23:05\");\nINSERT INTO \"payment\" VALUES(4,\"\",0,\"2015-04-14 12:48:01\");\nCREATE TABLE \"bid\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"auction_id\" INTEGER DEFAULT NULL REFERENCES \"auction\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"amount\" INTEGER DEFAULT NULL,\"time\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"auction\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"expire_time\" INTEGER DEFAULT NULL,\"start_amount\" NUMERIC DEFAULT NULL,\"currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"reserve_amount\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"auction\" VALUES(1,2,NULL,NULL,2,NULL,\"2015-04-14 01:09:43\");\n'\ncurl -L -XPOST localhost:4001/db?pretty -d 'INSERT INTO \"auction\" VALUES(2,4,NULL,NULL,2,NULL,\"2015-04-14 14:10:26\");\nINSERT INTO \"auction\" VALUES(3,5,NULL,NULL,3,NULL,\"2015-04-14 14:11:14\");\nCREATE TABLE \"currency\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"desc\" TEXT DEFAULT NULL,\"iso\" TEXT DEFAULT NULL,\"unicode\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"currency\" VALUES(1,\"Bitcoin\",\"BTC\",\"?\",\"2015-04-14 00:27:36\");\nINSERT INTO \"currency\" VALUES(2,\"United States Dollar\",\"USD\",\"$\",\"2015-04-14 00:27:36\");\nINSERT INTO \"currency\" VALUES(3,\"Euro\",\"EUR\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(4,\"British Pound Sterling\",\"GBP\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(5,\"Australian Dollar\",\"AUD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(6,\"Brazilian Real\",\"BRL\",\"R$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(7,\"Canadian Dollar\",\"CAD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(8,\"Swiss Franc\",\"CHF\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(9,\"Chinese Yuan\",\"CNY\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(10,\"Hong Kong Dollar\",\"HKD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(11,\"Indonesian Rupiah\",\"IDR\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(12,\"Israeli New Sheqel\",\"ILS\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(13,\"Mexican Peso\",\"MXN\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(14,\"Norwegian Krone\",\"NOK\",\"kr\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(15,\"New Zealand Dollar\",\"NZD\",\"$\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(16,\"Polish Zloty\",\"PLN\",\"z\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(17,\"Romanian Leu\",\"RON\",\"leu\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(18,\"Russian Ruble\",\"RUB\",\"?\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(19,\"Swedish Krona\",\"SEK\",\"kr\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(20,\"Singapore Dollar\",\"SGD\",\"$\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(21,\"Turkish Lira\",\"TRY\",\"?\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(22,\"South African Rand\",\"ZAR\",\"R\",\"2015-04-14 00:27:39\");\nCREATE TABLE \"country\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"country_code\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"country\" VALUES(1,\"United States\",\"US\",\"2015-04-14 00:27:39\");\nINSERT INTO \"country\" VALUES(2,\"Afghanistan\",\"AF\",\"2015-04-14 00:27:39\");\n'\nNow take down node 1, and write to node 2 only\nnode 2 seems to stay a candidate, making its writes fail and getting the\nno leader error message\nsleep 2s\nps aux | grep -ie node_1 | awk '{print $2}' | xargs kill -9\nrm -rf node_1\nsleep 2s\ncurl localhost:4002/raft?pretty\ncurl -L -XPOST localhost:4002/db?pretty -d 'INSERT INTO \"country\" VALUES(3,\"\ufffdland Islands\",\"AX\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(4,\"Albania\",\"AL\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(5,\"Algeria\",\"DZ\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(6,\"American Samoa\",\"AS\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(7,\"Andorra\",\"AD\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(8,\"Angola\",\"AO\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(9,\"Anguilla\",\"AI\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(10,\"Antarctica\",\"AQ\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(11,\"Antigua And Barbuda\",\"AG\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(12,\"Argentina\",\"AR\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(13,\"Armenia\",\"AM\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(14,\"Aruba\",\"AW\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(15,\"Australia\",\"AU\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(16,\"Austria\",\"AT\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(17,\"Azerbaijan\",\"AZ\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(18,\"Bahamas\",\"BS\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(19,\"Bahrain\",\"BH\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(20,\"Bangladesh\",\"BD\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(21,\"Barbados\",\"BB\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(22,\"Belarus\",\"BY\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(23,\"Belgium\",\"BE\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(24,\"Belize\",\"BZ\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(25,\"Benin\",\"BJ\",\"2015-04-14 00:27:42\");\nCREATE TABLE \"review_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"review_id\" INTEGER DEFAULT NULL REFERENCES \"review\" (\"id\"),\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (user_id, review_id));\nINSERT INTO \"review_vote\" VALUES(1,1,1,\"up\",\"2015-04-14 14:20:26\");\nCREATE TABLE \"review_comment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"review_id\" INTEGER DEFAULT NULL REFERENCES \"review\" (\"id\"),\"comment\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"question\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"answer\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"question_id\" INTEGER DEFAULT NULL REFERENCES \"question\" (\"id\"),\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"question_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"question_id\" INTEGER DEFAULT NULL REFERENCES \"question\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL,\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"answer_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"answer_id\" INTEGER DEFAULT NULL REFERENCES \"answer\" (\"id\"),\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"category\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"parent\" INTEGER DEFAULT NULL,\"is_physical\" INTEGER DEFAULT true,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"category\" VALUES(1,\"Animals & Pet Supplies\",NULL,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(2,\"Live Animals\",1,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(3,\"Pet Supplies\",1,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(4,\"Bird Supplies\",3,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(5,\"Bird Cage Accessories\",4,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(6,\"Bird Cage Food & Water Dishes\",5,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(7,\"Bird Cages & Stands\",4,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(8,\"Bird Food\",4,\"true\",\"2015-04-14 00:27:30\");\n'\ncurl -L -XPOST localhost:4002/db?pretty -d 'INSERT INTO \"category\" VALUES(9,\"Bird Gyms & Playstands\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(10,\"Bird Ladders & Perches\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(11,\"Bird Toys\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(12,\"Bird Treats\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(13,\"Cat Supplies\",3,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(14,\"Cat Apparel\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(15,\"Cat Beds\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(16,\"Cat Food\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(17,\"Cat Furniture\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(18,\"Cat Litter\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(19,\"Cat Litter Box Mats\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(20,\"Cat Litter Boxes\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(21,\"Cat Toys\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(22,\"Cat Treats\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(23,\"Dog Supplies\",3,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(24,\"Dog Apparel\",23,\"true\",\"2015-04-14 00:27:33\");\nINSERT INTO \"category\" VALUES(25,\"Dog Beds\",23,\"true\",\"2015-04-14 00:27:33\");\nCREATE TABLE \"wishlist_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"purchased\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"wishlist_item\" VALUES(1,1,2,0,\"2015-04-14 01:11:47\");\nCREATE TABLE \"login\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"session_id\" TEXT DEFAULT NULL,\"time_\" INTEGER DEFAULT NULL,\"expire_time\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"login\" VALUES(1,1,\"1sdfgs5kqivfofa2tum79g4301469s41h3e6d2qquntkf9umr2oh\",1428971430539,1428974638358,\"2015-04-14 00:30:30\");\nINSERT INTO \"login\" VALUES(2,1,\"1cmefbba3hk8kfbjl74kki02nav3h23fuj6jpod2sfp4ratjm9sp\",1428973901740,1428974447001,\"2015-04-14 01:11:42\");\nINSERT INTO \"login\" VALUES(3,2,\"1opvct1n4h7tlk8r1onpkoup8pi8b9duhfo3i8a4s7tcb6rtj38b\",1428974487159,1428978087159,\"2015-04-14 01:21:27\");\nINSERT INTO \"login\" VALUES(4,1,\"bhmv5etav7rbhhk3kur835u41hb2veg0av6gs00mqm964u90j5j\",1428974645457,1428978245457,\"2015-04-14 01:24:05\");\nINSERT INTO \"login\" VALUES(5,2,\"q0flrr0bvh7mkr8vnvktshj1ago6dsc7icdq25tdr0ok3kfrvhu\",1429015664731,1429019264731,\"2015-04-14 13:02:22\");\nINSERT INTO \"login\" VALUES(6,1,\"1cd6q1o14i65609a3dqr85kk1e91ulacj6l4b6di5tt5l8mfq84e\",1429015923407,1429016564440,\"2015-04-14 13:02:23\");\nINSERT INTO \"login\" VALUES(7,1,\"1g0jknpm2ad6n0skkjh9je6120qrogj4d5b88hvf5h9lt2go2pui\",1429016579502,1429020179502,\"2015-04-14 13:06:04\");\nINSERT INTO \"login\" VALUES(8,1,\"1v5fr7bm6c5dq5tahdujdon0u5ujpecft4ranpr8rml722ch9e1o\",1429016676795,1429016685373,\"2015-04-14 13:06:04\");\nINSERT INTO \"login\" VALUES(9,1,\"4vjp9v6qj14lpt4fitkg5vm5p72pvdn14hlp5m2s9ml8nka6lc0\",1429016793426,1429016802385,\"2015-04-14 13:06:33\");\nINSERT INTO \"login\" VALUES(10,1,\"ci0pm52vg36kat3p9821m51rptrbdi3lji2lg8a0u3audkc22r\",1429016822694,1429017095173,\"2015-04-14 13:38:54\");\nINSERT INTO \"login\" VALUES(11,1,\"1nt8r0qira5qvntv11iuc6udvjjtmitnbnuielmrouqabu7ua19m\",1429017113246,1429020713246,\"2015-04-14 13:38:54\");\nINSERT INTO \"login\" VALUES(12,1,\"1mcse38fgklq0odhus34e7g1gdbvu2rtpcivvu6k0f37vdsoo7oj\",1429021175749,1429024775749,\"2015-04-14 14:19:36\");\nCREATE TABLE \"product_price\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"price\" INTEGER DEFAULT NULL,\"native_currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"variable_price\" INTEGER DEFAULT NULL,\"price_select\" INTEGER DEFAULT NULL,\"price_1\" INTEGER DEFAULT NULL,\"price_2\" INTEGER DEFAULT NULL,\"price_3\" INTEGER DEFAULT NULL,\"price_4\" INTEGER DEFAULT NULL,\"price_5\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"product_price\" VALUES(1,2,2.5,2,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 01:07:20\");\nINSERT INTO \"product_price\" VALUES(2,4,1.99,2,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 14:10:26\");\nINSERT INTO \"product_price\" VALUES(3,5,1.96,3,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 14:11:14\");\nCREATE TABLE \"product_group\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_group_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_group\" INTEGER DEFAULT NULL REFERENCES \"product_group\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_page\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"product_html\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"product_page\" VALUES(1,2,\"&ltsemicolonh1 style=&quotsemicolontext-align: centersemicolon&quotsemicolon&gtsemicolonThe best donut ever made&ltsemicolon/h1&gtsemicolon&ltsemicolonblockquote&gtsemicolon&ltsemicolonp style=&quotsemicolon text-align: leftsemicolon&quotsemicolon&gtsemicolon&ltsemicolonspan style=&quotsemicolonfont-weight: boldsemicolon&quotsemicolon&gtsemicolonSaid everyone&ltsemicolon/span&gtsemicolon&ltsemicolonbr&gtsemicolon&ltsemicolon/p&gtsemicolon&ltsemicolon/blockquote&gtsemicolon\",\"2015-04-14 14:06:56\");\nCREATE TABLE \"product_picture\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"url\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product_picture\" VALUES(1,2,1,\"http://vignette1.wikia.nocookie.net/smosh/images/b/b2/Pink_frosted_sprinkled_donut.jpg/revision/latest?cb=20120101131536\",\"2015-04-14 14:06:16\");\nINSERT INTO \"product_picture\" VALUES(2,4,1,\"http://jennyfunderburke.com/blog/wp-content/uploads/2011/08/donut.jpg\",\"2015-04-14 14:10:07\");\nINSERT INTO \"product_picture\" VALUES(3,5,1,\"http://www.withsprinklesontop.net/wp-content/uploads/2012/01/DSC_0406x900.jpg\",\"2015-04-14 14:11:36\");\nCREATE TABLE \"tag\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"title\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_tag\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"tag_id\" INTEGER DEFAULT NULL REFERENCES \"tag\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"time_type\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"time_type\" VALUES(1,\"business days\",\"2015-04-14 00:27:35\");\nINSERT INTO \"time_type\" VALUES(2,\"weeks\",\"2015-04-14 00:27:35\");\nCREATE TABLE \"time_span\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"time_type_id\" INTEGER DEFAULT NULL REFERENCES \"time_type\" (\"id\"),\"min\" INTEGER DEFAULT NULL,\"max\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"time_span\" VALUES(1,1,1,2,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(2,1,1,3,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(3,1,3,5,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(4,2,1,2,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(5,2,2,3,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(6,2,3,4,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(7,2,4,6,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(8,2,6,8,\"2015-04-14 00:27:36\");\nCREATE TABLE \"shipping\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"from_country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nCREATE TABLE \"shipping_cost\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"shipping_id\" INTEGER DEFAULT NULL REFERENCES \"shipping\" (\"id\"),\"to_country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"price\" INTEGER DEFAULT NULL,\"native_currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_bullet\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product_bullet\" VALUES(1,2,1,\"This is a Pink frosted sprinkled donut\",\"2015-04-14 14:05:51\");\nINSERT INTO \"product_bullet\" VALUES(2,2,2,\"It has sprinkles\",\"2015-04-14 14:05:57\");\nINSERT INTO \"product_bullet\" VALUES(3,2,3,\"It has frosting\",\"2015-04-14 14:06:12\");\nCREATE TABLE \"payment_type\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"payment_info\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"seller_id\" INTEGER DEFAULT NULL REFERENCES \"seller\" (\"id\"),\"payment_type_id\" INTEGER DEFAULT NULL REFERENCES \"payment_type\" (\"id\"),\"payment_info_location\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"message\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"from_user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"to_user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"subject\" TEXT DEFAULT NULL,\"html\" TEXT DEFAULT NULL,\"message_status_id\" INTEGER DEFAULT NULL REFERENCES \"message_status\" (\"id\"),\"created_at\" INTEGER DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"message_status\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"title\" INTEGER DEFAULT NULL,\"created_at\" INTEGER DEFAULT CURRENT_TIMESTAMP);\nDELETE FROM sqlite_sequence;\nINSERT INTO \"sqlite_sequence\" VALUES(\"category\",25);\nINSERT INTO \"sqlite_sequence\" VALUES(\"time_type\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"time_span\",8);\nINSERT INTO \"sqlite_sequence\" VALUES(\"currency\",22);\nINSERT INTO \"sqlite_sequence\" VALUES(\"country\",25);\nINSERT INTO \"sqlite_sequence\" VALUES(\"user\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"seller\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"login\",12);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product\",5);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_price\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"auction\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"wishlist_item\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"cart_item\",3);\n'\ncurl -L -XPOST localhost:4002/db?pretty -d 'INSERT INTO \"sqlite_sequence\" VALUES(\"payment\",4);\nINSERT INTO \"sqlite_sequence\" VALUES(\"address\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"shipment\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"feedback\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_bullet\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_picture\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_page\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"review\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"review_vote\",1);\nCREATE VIEW time_span_view AS SELECT time_span.id, min || \"-\" || max || \" \" || name as time_span_string FROM time_span left join time_type on time_span.time_type_id = time_type.id;\nCREATE VIEW product_view AS SELECT product.id,seller_id,shop_name,category_id,buy,auction,quantity,title,processing_time_span_id,time_span_string,price,native_currency_id,currency.iso as price_iso,variable_price,price_select,price_1,price_2,price_3,price_4,price_5,expire_time,start_amount,reserve_amount,physical,currency_id as auction_currency_id,auction_currency.iso as auction_currency_iso,shipping.id as shipping_id, from_country_id, from_country.name as from_country, count(review.id) as number_of_reviews, ifnull(avg(review.stars),0) as review_avg, product_html FROM product left join time_span_view on product.processing_time_span_id = time_span_view.id left join product_page on product.id = product_page.product_id left join product_price on product.id = product_price.product_id left join auction on product.id = auction.product_id left join currency on product_price.native_currency_id = currency.id left join currency as auction_currency on auction.currency_id = auction_currency.id left join shipping on product.id = shipping.product_id left join country as from_country on shipping.from_country_id = from_country.id left join review on review.product_id = product.id left join seller on product.seller_id = seller.id  group by product.id;\nCREATE VIEW product_thumbnail_view AS SELECT product.id as product_id,title,seller_id,category_id,shop_name, count(review.id) as number_of_reviews, ifnull(avg(review.stars),0) as review_avg, auction,CASE WHEN auction=\"1\"    THEN (select max(bid.amount) from bid where bid.auction_id = auction.id)    ELSE max(price) END as price, currency.iso as price_iso FROM product inner join currency on product_price.native_currency_id = currency.id left join seller on product.seller_id = seller.id left join auction on product.id = auction.product_id left join review on review.product_id = product.id left join product_price on product_price.product_id = product.id group by product.id;\nCREATE VIEW category_tree_view AS  SELECT t1.name AS name_1, t1.id AS id_1,t2.name AS name_2, t2.id AS id_2,t3.name AS name_3, t3.id AS id_3,t4.name AS name_4, t4.id AS id_4,t5.name AS name_5, t5.id AS id_5,t6.name AS name_6, t6.id AS id_6,t7.name AS name_7, t7.id AS id_7 FROM category AS t1 LEFT JOIN category AS t2 ON t2.parent = t1.id LEFT JOIN category AS t3 ON t3.parent = t2.id LEFT JOIN category AS t4 ON t4.parent = t3.id LEFT JOIN category AS t5 ON t5.parent = t4.id LEFT JOIN category AS t6 ON t6.parent = t5.id LEFT JOIN category AS t7 ON t7.parent = t6.id where t1.parent IS NULL;\nCREATE VIEW browse_view AS select distinct id_1, id_2, name_1, name_2 from category_tree_view;\nCREATE VIEW review_view AS select review.id,product_id,review.user_id,user.name as user_name, stars,headline,text_html, review.created_at, SUM(vote) as votes_sum, count(review_vote.id) as votes_count from review left join review_vote on review.id = review_vote.review_id left join user on review.user_id = user.id group by review.id;\nCREATE VIEW feedback_view AS select feedback.id,cart_item_id,cart_item.product_id,cart_item.user_id,stars,arrived_on_time,correctly_described,prompt_service,comments,feedback.created_at from feedback left join cart_item on feedback.cart_item_id = cart_item.id;\nCREATE VIEW question_view AS select question.id, question.user_id, user.name as user_name, product_id, text, question.created_at, SUM(vote) as votes_sum, count(question_vote.id) as votes_count from question left join question_vote on question.id = question_vote.question_id left join user on question.user_id = user.id group by question.id;\nCREATE VIEW answer_view AS select answer.id, answer.user_id, user.name as user_name,question_id, text, answer.created_at, SUM(case when vote = 1 then 1 when vote = -1 then -1 else 0 end) as votes_sum, count(answer_vote.id) as votes_count from answer left join answer_vote on answer.id = answer_vote.answer_id left join user on answer.user_id = user.id group by answer.id;\nCREATE VIEW shipping_cost_view AS select shipping_cost.id,shipping_id, to_country_id, num_,price, name as to_country,iso as shipping_cost_iso from shipping_cost left join country on shipping_cost.to_country_id = country.id left join currency on shipping_cost.native_currency_id = currency.id;\nCREATE VIEW cart_view AS select cart_item.id,cart_item.user_id,product.seller_id,cart_item.product_id,cart_item.quantity,purchased,cart_item.created_at,title, url,product_price.price,iso ,cart_item.shipment_id,cart_item.payment_id from cart_item left join product_picture on cart_item.product_id = product_picture.product_id and num_ = 1 left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join currency on product_price.native_currency_id = currency.id where purchased = 0;\nCREATE VIEW cart_group AS select cart_item.user_id,seller_id, shop_name, max(time_span_string) as time_span_string, sum(product_price.price_cart_item.quantity) as cost,max(iso) as iso,IFNULL(max(shipping_cost.price),0) as shipping,sum(product_price.price_cart_item.quantity) + IFNULL(max(shipping_cost.price),0) as checkout_total ,shipment_id, address.full_name,address.address_line_1,address.address_line_2,address.city,address.state,address.zip,address.country_id,payment_id,purchased, bitmerchant_address,order_iframe, cart_item.created_at from cart_item left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join shipping on cart_item.product_id = shipping.product_id left join shipping_cost on shipping.id = shipping_cost.shipping_id left join seller on product.seller_id = seller.id left join time_span_view on product.processing_time_span_id = time_span_view.id left join currency on product_price.native_currency_id = currency.id left join shipment on cart_item.shipment_id = shipment.id left join address on shipment.address_id = address.id left join payment on cart_item.payment_id = payment.id where purchased = 0 group by cart_item.user_id, product.seller_id;\nCREATE VIEW order_group AS select cart_item.user_id,seller_id, shop_name, max(time_span_string) as time_span_string, sum(product_price.price_cart_item.quantity) as cost,max(iso) as iso,IFNULL(max(shipping_cost.price),0) as shipping,sum(product_price.price_cart_item.quantity) + IFNULL(max(shipping_cost.price),0) as checkout_total ,shipment_id, shipment.tracking_url, address.full_name,address.address_line_1,address.address_line_2,address.city,address.state,address.zip,address.country_id,payment_id,purchased, completed, order_iframe,payment.created_at from cart_item left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join shipping on cart_item.product_id = shipping.product_id left join shipping_cost on shipping.id = shipping_cost.shipping_id left join seller on product.seller_id = seller.id left join time_span_view on product.processing_time_span_id = time_span_view.id left join currency on product_price.native_currency_id = currency.id left join shipment on cart_item.shipment_id = shipment.id left join address on shipment.address_id = address.id left join payment on cart_item.payment_id = payment.id where purchased = 1 group by cart_item.user_id, payment_id;\nCREATE VIEW order_view AS select cart_item.id,cart_item.user_id,product.seller_id,cart_item.product_id,cart_item.quantity,purchased,cart_item.created_at,title, url,product_price.price,iso ,cart_item.shipment_id,cart_item.payment_id from cart_item left join product_picture on cart_item.product_id = product_picture.product_id and num_ = 1 left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join currency on product_price.native_currency_id = currency.id where purchased = 1;\nCREATE VIEW address_view AS select address.id,user_id,full_name,address_line_1,address_line_2,city,state,zip,country_id,default_,country.name as country_name,address.created_at from address left join country on address.country_id = country.id;\n'\ncurl localhost:4002/raft?pretty\nkills all the rqlite instances\nps aux | grep -ie rqlite | awk '{print $2}' | xargs kill -9\nrm -rf node_1 node_2\n\u2014\nReply to this email directly or view it on GitHub.\n. Is your network flaky?\n. As for the first case, not sure what happened there. I'd like to see if you can repro it.\n\nFor the second case, not sure, from glancing at the Raft code, there might have been a snapshot going on while you attempted to write a command. I'd say retry is the right approach for the second case. Check if that error comes back, and if it does, try again.\n. The Raft implementation has been replaced so this is now moot.\n. Thanks @mkorszun - I want to briefly try out Vagrant before merging. \n. Thanks @mkorszun \n. It means the cluster is in bad shape. :-) This is in the go-raft code - the code that implements the distributed consensus protocol.\nA fundamental invariant of the Raft protocol is that there can only ever be one 1 leader for a given term. The fact that there are two indicates that something very bad has gone wrong. Right now this looks like a bug in the raft code.\n. Unfortunately go-raft is not maintained anymore. If you can come up with a repro script, I can take a look, but I am not optimistic you'll have a fix anytime soon.\n. Thanks @tchoulihan -- at this time, it's unlikely I'll be swapping out the Raft implementation within rqlite anytime soon. Doing so would not be trivial so would take a little while.\n. To be clear, I do hope to fix these issues at some point, but I can't give you a timeframe, since these issues may not be trivial.\n. Leader \"election\", which I presume if what you mean, is not performed by code I wrote. It's performed by https://github.com/goraft/raft. That said, once you clone the entire repo, and build it, you'll have the go-raft source also locally, which you can edit and try out fixes.\n. Nothing in rqlite does any of that.\nThe way it works is that rqlite registers commands with the go-raft module (write, read, and shapshot), and then let's go-raft do its thing. go-raft then decides when those commands should be called in rqlite, when a new leader should be elected etc etc. It might help if you study the reference implementation here:\nhttps://github.com/goraft/raftd\n. I've swapped out the Raft implementation, so this is moot.\n. Looks like the best option may be https://github.com/hashicorp/raft.\n. I have decided to replace the Raft implementation with the one from Hashicorp. I have tagged the go-raft version as 1.0 here:\nhttps://github.com/otoolep/rqlite/releases/tag/v1.0\nAfter this the query API will remain the same, but metrics, diagnostics, and Raft information will be different. The system will also be launched differently.\n. Work taking place in this branch: https://github.com/otoolep/rqlite/tree/hrqlite\n. All done. Master is now using Hashicorp's Raft implementation.\n. Hello - no, I would consider network security outside the scope of rqlite. It is very unlikey I would implement something like this. \nThere are lots of other options. Firewalls, iptables, EC2 security groups, etc.\n. If that change works, do you want to generate a PR?\n. Fixed by https://github.com/otoolep/rqlite/commit/7f4105432fc37eca7a08da91f2ef6b874f660fab\n. It wasn't actually, I also had to update my fork of raft. Not a huge deal.\n. @Apercu -- sanitizing the queries is up to you. It's no different than if you were issuing SQLite queries directly. The best way to handle this is put something (your own little program, for example) in-front of rqlite, that sanitizes each query before passing it on. The same approach could be used to enforce authentication. \nThis is interesting functionality, and building it into rqlite would be a good idea though.\n. Thanks for your question @heckdevice -- no I don't have any plans for that, but it would be easy enough to code. PRs welcome. :-)\nIt would need to run as a second API server, or a switch the command line to invoke it, as some people rely on the current API.\n. Thanks for the PR.\n. I have feedback, but am up for merging this once some changes are made.\nOnce we're both happy, I will ask that you squash the commits into a single commit.\n. Thanks, let me see what I can do. I am re-working some rqlite (though the API should remain the same, I plan to just rework the distributed consensus part).\n. What do you see if you issue the query today? I have not tested it.\n. OK, I believe I know why this is -- it's because rqlite isn't built to support statements that mutate the database and return results, in the same POST body.\nI should be able to fix that, I've never been too happy about it, and know better now.\n. Let me try to fix it as part of the work I am doing in this branch: https://github.com/otoolep/rqlite/tree/hrqlite\n. This should now be fully supported on master. Please take a look @zmedico and let me know what you think.\n. @zmedico -- are you planning to make your Python driver generally available? If so, I'd be interested in seeing it.\n. I guess by \"release soon\" you do mean to make it available to general use.\n. Nice.\nDepending on your seriousness, we should agree to lock down the API pretty soon. I think it's close, but I'd be interested in any feedback.\n. I'm going to resist versioning the API for now, since the 1.0 API was badly done, and should never have existed in that form (after spending a couple of years building databases I know better now, you see). I think versioning might be overkill for my goals for rqlite.\nAs for the API, I've made some final changes. Check out the https://github.com/otoolep/rqlite/blob/master/README.md for full details. \n. You're right @zmedico -- this is a fundamental problem with the responses of rqlite, that I didn't appreciate at the time I first created the program.\nThis definitely needs to be fixed, and I know how to do it, but will result in the output format being changed a bit. I'll try to fix this shortly.\n. This is now fixed on master. Please check out the new API responses and tell me what you think @zmedico \nWhile master still needs more work, I am proposing the new API as final for 2.0. Let me know if you have any feedback.\n. Check the README for all the latest details.\n. Not committing to fixing this for v2.0, but might get to it.\n. OK @millken -- yeah that is an issue. The splitting is quite naive, as you have pointed out. \nThis would probably require some more sophisticated parsing of the query string. I can take a look -- PRs welcome too. \nYou could try a different delimiter, as a workaround. Or normalize the data with an upstream table. \n. I think probably the best way to fix this is that API should also support a JSON-formatted body for the query. That would make it easy to unambiguously send multiple INSERTS at once.\n. There is now an effective solution for this in master -- you can specify the multiple INSERTs as the body of the POST request.\nMaster is still in development, but you should be able to do what you need now. Please let me know if this doesn't work.\n. Check the README for all the latest details.\n. Good idea.\nThe DSNs supported by the Open called documented at https://godoc.org/github.com/mattn/go-sqlite3#SQLiteDriver.Open will be supported once https://github.com/otoolep/rqlite/pull/54 merges to master.\n. Master now supports this, though I have ideas for enhancing it further. You can now pass the \"query params\" via the dsn switch. E.g.\n./rqlited -dsn=\"cache=shared\" data\nLet me know what you think @millken.\n. I'd like to make this support even more general, so one could specify, say, a memory-only database.\n. All done for now.\n. The API now returns times to execute queries by default. Leaving this open for other ideas that could be enabled by explain.\n. I think we're good here.\n. I was thinking binary copy of the SQLite database file. With one you can always get the other yourself.\n. Actually, this is more complex. To completely back up a node, the system needs to backup the SQLite database and the associated Raft data. Only that way could a node be completely restored.\nThe backup of the database file can be achieved by using the backup call on the Go library, to copy the database file to a temp file. Then that temp file can be part of the backup.\nAlternatively, if backup is just going to lock the entire system (may necessary for full Raft backup) then we might as well just copy the database file directly since it won't be capable of being changed during the copying.\n. There is a backup endpoint in place, but it is not fully functional. The binary dump is not yet correct.\n. This is done. Check the README for details.\n. All done. Pass -mem to rqlited at startup.\nSee the README for more details.\n. A bit better now.\nhttps://github.com/otoolep/rqlite/commit/9b202c484a6e8e3c3d508effdb4a3904d4a7bbd8\n. Agreed @ddevienne -- fair point, and I had been considering it myself.\n. Fixed by https://github.com/otoolep/rqlite/commit/fac68c3cdd219e18d6c89972c25096a0f6e26d3f\n. OK, yeah, you're right @zmedico -- I thought that worked.\nI am open to the idea of making it a POST (though the URL param version would remain a GET). Let me take a look.\n. OK, the specific issue with the README has been fixed by this:\nhttps://github.com/otoolep/rqlite/commit/f38eaa16e566a460f4b4babc943a43fa37fc9dac\nI need to think more about GET vs. POST. I am ok with changing it to POST, it does seem more standard.\n. I've changed the API to POST for bulk queries. See the README for details.\nLet me know what you think @zmedico \n. Part of the fix for https://github.com/otoolep/rqlite/issues/57\n. Fixes: https://github.com/otoolep/rqlite/issues/61\nPartial solution for https://github.com/otoolep/rqlite/issues/57\n. Fixed.\n. This is probably gone as far as it will go right now.\n. You're right @prateek1306 -- the build instructions are incomplete. :-(\nThanks for your report. I actually fixed it slightly differently.\nhttps://github.com/otoolep/rqlite/commit/21952567b145a06f45ce867cc4595faad83da665\n. @prateek1306 -- I made the build instructions even shorter. Let me know if they don't work for you.\n. It's easy to do, I've started it here: https://github.com/otoolep/rqlite/pull/69\n. This is not actually as easy to do as initially thought, because it is not straightforward for a node to learn the query port of the leader. It's easy to find the Raft port, but that is not sufficient.\n. Until I get this in, you can learn the current leader by querying the status endpoint. The current leader will be listed in the section titled \"raft\".\n. One possible solution is: each node will have to send a message back down the Raft connection to the leader, with a special message in there telling the leader its HTTP address. On receipt of these messages the leader broadcasts the information (Raft address, HTTP address) to all other nodes. This could be done via a message through the Raft log -- a message that is not actually applied to the database. \nAlternatively, perhaps the leader broadcasts this out the Raft connection.\n. Basically, the key here is that each node should know how to map a Raft address of a node to the HTTP address of that node, so that HTTP redirection can be setup properly. This is because every node knows the Raft node of every other node in the cluster, but it needs to know corresponding HTTP addresses. \nPerhaps nodes could respond on the Raft connection to questions like \"what is your HTTP address\". This could be the other approach.\n. Just sending the HTTP(S) API address on join is not enough, as it could change on a node after a node is restarted. The follower node must actually ensure it is sent once to the leader after startup (and the leader broadcasts it out). Once sent, the sending can stop.\n. This is almost complete. The 307 is coming back from followers, but the returned address isn't quite right yet.\n```\n Hostname was NOT found in DNS cache\n   Trying 127.0.0.1...\n* Connected to localhost (127.0.0.1) port 4005 (#0)\n\nGET /db/query?pretty&timings&q=SELECT%20%2A%20FROM%20foo HTTP/1.1\nUser-Agent: curl/7.38.0\nHost: localhost:4005\nAccept: /\n< HTTP/1.1 307 Temporary Redirect\n< Location: /db/\n< Date: Sat, 30 Apr 2016 07:47:32 GMT\n< Content-Length: 40\n< Content-Type: text/html; charset=utf-8\n< \nTemporary Redirect.\n```\n. All done.\n. Much better, thanks @tcyrus \n. The priority of this issue is now much lower, with leader redirection now in place.\n. I'm not going to solve this. It's up to clients to follow the redirection header.. Cool, let's wait until that PR is merged and then I will take a closer look.\n. Selected \"rebuild without cache\".\n. As I thought -- you need to update the unit tests too.\n. Thanks @zmedico \n. Thanks @zmedico \n\nIf I make that change I need to change a lot of code, since the type returned by that Open call is different than what comes back from the current Open call.\nI agree current code is not great. Let me see if I can fix it up.\n. Yeah, more I think about this, the more I think I should go straight to the SQLite3 driver. It's not like there are plans for rqlite to support any other type of database.\nWhen I first created rqlite I deliberately used the general Go interface for accessing the SQLite database. There isn't any real need to do so.\n. This will be fixed by https://github.com/otoolep/rqlite/issues/73\n. No longer an issue, thanks to #74 \n. Fixed by #74 \n. Thanks for doing this @zmedico -- it's much better. I do have some feedback before I can merge however.\n. I also started a CHANGELOG. Can you update it?\nhttps://github.com/otoolep/rqlite/blob/master/CHANGELOG.md\nAdd the following line to the 2.0 section:\n- [PR 74](https://github.com/otoolep/rqlite/pull/74): Use SQLite3 connection directory\n. Thanks again. Minor feedback. If I don't see changes soon, I'll merge yours and make the changes.\n. Thanks @zmedico !\n. No worries @zmedico -- I updated the log for you.\n. Some of the work of adding this flag has been started.\n. All done.\n. You haven't given me enough context. I need to see your entire build session, because I have no idea if you actually followed the instructions in https://github.com/otoolep/rqlite/blob/master/CONTRIBUTING.md\n. I just checked the build instructions again. It all works fine. Please provide more context if you still can't build the code.\n. ~ $ mkdir rqlite # Or any directory of your choice.\n~ $ cd rqlite/\n~/rqlite $ export GOPATH=$PWD\n~/rqlite $ go get -t github.com/otoolep/rqlite/...\n~/rqlite $ $GOPATH/bin/rqlited ~/node.1\n[rqlited] 2016/04/09 18:37:48 rqlited starting, version 2.1, commit unknown, branch unknown\n[store] 2016/04/09 18:37:49 SQLite database opened at /home/philip/node.1/db.sqlite\n[store] 2016/04/09 18:37:49 enabling single-node mode\n2016/04/09 18:37:49 [INFO] raft: Node at 127.0.0.1:4002 [Follower] entering Follower state\n2016/04/09 18:37:50 [WARN] raft: Heartbeat timeout reached, starting election\n2016/04/09 18:37:50 [INFO] raft: Node at 127.0.0.1:4002 [Candidate] entering Candidate state\n2016/04/09 18:37:50 [DEBUG] raft: Votes needed: 1\n2016/04/09 18:37:50 [DEBUG] raft: Vote granted from 127.0.0.1:4002. Tally: 1\n2016/04/09 18:37:50 [INFO] raft: Election won. Tally: 1\n2016/04/09 18:37:50 [INFO] raft: Node at 127.0.0.1:4002 [Leader] entering Leader state\n2016/04/09 18:37:50 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n2016/04/09 18:37:50 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n^C[rqlited] 2016/04/09 18:37:51 rqlite server stopped\n. Something is up with your build of go-sqlite3. This is not a rqlite issue, but the error is blocking rqlited from being built. \nI suggest you visit https://github.com/mattn/go-sqlite3 and see if there is any help there. \n\nOn Apr 9, 2016, at 8:29 PM, Sooriya10 notifications@github.com wrote:\nThanks for checking!\nStill having issue on my system\ngo version xgcc (Ubuntu 4.9.3-0ubuntu4) 4.9.3 linux/amd64\nSooriya@AirP2P:~$ cd rqlite/Sooriya@AirP2P:~/rqlite$ export GOPATH=$PWDSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/...# github.com/mattn/go-sqlite3Go type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/.Sooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/..can't load package: package github.com/otoolep: no buildable Go source files in /home/Sooriya/rqlite/src/github.com/otoolepSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/...# github.com/mattn/go-sqlite3Go type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteSooriya@AirP2P:~/rqlite$ ls -ltotal 12drwxrwxr-x 2 Sooriya Sooriya 4096 Apr 10 03:19 bindrwxrwxr-x 3 Sooriya Sooriya 4096 Apr 10 03:19 pkgdrwxrwxr-x 3 Sooriya Sooriya 4096 Apr 10 03:16 srcSooriya@AirP2P:~/rqlite$ cd binSooriya@AirP2P:~/rqlite/bin$ ls -ltotal 24-rwxrwxr-x 1 Sooriya Sooriya 24000 Apr 10 03:19 rqlite\nThere is no rqlited file?\nDate: Sat, 9 Apr 2016 18:40:20 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\n~ $ mkdir rqlite # Or any directory of your choice.\n~ $ cd rqlite/\n~/rqlite $ export GOPATH=$PWD\n~/rqlite $ go get -t github.com/otoolep/rqlite/...\n~/rqlite $ $GOPATH/bin/rqlited ~/node.1\n[rqlited] 2016/04/09 18:37:48 rqlited starting, version 2.1, commit unknown, branch unknown\n[store] 2016/04/09 18:37:49 SQLite database opened at /home/philip/node.1/db.sqlite\n[store] 2016/04/09 18:37:49 enabling single-node mode\n2016/04/09 18:37:49 [INFO] raft: Node at 127.0.0.1:4002 [Follower] entering Follower state\n2016/04/09 18:37:50 [WARN] raft: Heartbeat timeout reached, starting election\n2016/04/09 18:37:50 [INFO] raft: Node at 127.0.0.1:4002 [Candidate] entering Candidate state\n2016/04/09 18:37:50 [DEBUG] raft: Votes needed: 1\n2016/04/09 18:37:50 [DEBUG] raft: Vote granted from 127.0.0.1:4002. Tally: 1\n2016/04/09 18:37:50 [INFO] raft: Election won. Tally: 1\n2016/04/09 18:37:50 [INFO] raft: Node at 127.0.0.1:4002 [Leader] entering Leader state\n2016/04/09 18:37:50 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n2016/04/09 18:37:50 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n^C[rqlited] 2016/04/09 18:37:51 rqlite server stopped\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly or view it on GitHub\n. @Sooriya10 -- what version of Go are you using? You must use at least version 1.4.\n. Yeah, OK, I think you need to check with the other repo, I'm not sure what is going on.\n. See https://github.com/mattn/go-sqlite3/issues/245\n. Show me the output of which go. Just because gvm shows those versions installed, that doesn't mean they are on the path. You must explicitly tell gvm to use them.\n. ~ $ which go\n/home/philip/.gvm/gos/go1.5/bin/go\n~ $\n. OK, I'm stumped. :-( \n. Perhaps you can use a pre-built binary, until you sort out the compilation issue. \n\nhttps://github.com/otoolep/rqlite/releases\n. The NetworkTransport implemented in rqlite does not support \"advertise\". It might be necessary to configure the mapping between IP addresses and routable IP addresses via a file, that is passed into rqlite on start-up. \n. Or, the dialer in the Mux, and its handler, could negotiate this exchange of non-routable to routable mapping when first connecting.\n. Actually, it might be even simpler. The Addr method on the multiplexed Layer might just need to return its configured \"advertise\" address.\n. You must run rqlited, not rqlite. I also do not have access to a Windows machine so can't help you there. I am open to changes to make it work on Windows though. \n\nhttp://www.philipotoole.com\n\nOn Apr 10, 2016, at 2:43 AM, ejzhang notifications@github.com wrote:\nThere are some redeclared warning when i build it.\nc:\\rqlite>go get -t github.com/otoolep/rqlite/...\ncompress/flate\nC:\\Program Files\\Go\\src\\compress\\flate\\inflate.go:30: fixedHuffmanDecoder redeclared in this block\nprevious declaration at C:\\Program Files\\Go\\src\\compress\\flate\\fixedhuff.go:78\nhash/crc32\nC:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64x.go:14: haveSSE42 redeclared in this block\nprevious declaration at C:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64.go:13\nC:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64x.go:18: castagnoliSSE42 redeclared in this block\nprevious declaration at C:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64.go:19\nC:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64x.go:20: sse42 redeclared in this block\nprevious declaration at C:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64.go:26\nC:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64x.go:22: updateCastagnoli redeclared in this block\nprevious declaration at C:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64.go:29\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\n. As explained in the README, please consult this:\n\nhttps://github.com/otoolep/rqlite/blob/master/CONTRIBUTING.md\n. I don't understand this bug. Can you please provide more details? I can't reproduce this issue, since you have not provided enough information.\nJust to be clear, writing to the SQLite file underneath a rqlite node is not supported.\n. > BTW: Can this \"writing to the SQLite file underneath an rqlite node\" be controlled, because someone might hack/accidentally do this.\nI am open to suggestions. But if you need a dump of the SQLite database, use the backup endpoint. Don't access the file directly.\n. > For us, would that be possible to configure the other Nodes that they never will be able Insert/Update or Delete. i.e. those operation only via the master database and only replicate to the other nodes...\nThe answer to your requirement is to only go through the HTTP API on the leader, and don't write to the SQLite file directly. I can't prevent you from doing this, so you shouldn't do it, as rqlite doesn't support this kind of operation.\nI'm closing this bug since it sounds like you're writing to the SQLite file directly and you're not supposed to do that. Let know if this is not what you're doing.\n. > Yes, I was writing directly a followers node to test it.  Your solution should \"not\" allow  that.  It is useless for us if it allows to do that.\nYou can't write to anything but the leader. The system explicitly prevents this is via the API and internal implementation. You can't write to a follower -- the request will be rejected by the HTTP API.\nAnd If you are writing to the SQLite file underneath a node, that is wrong. I've explicitly explained that the system does not support that.\n\nYour solution is vulnerable for hacking, and accidental writing to the followers.  Hence they not fall in this basic rule \" ensuring that each node in the cluster agrees upon the same series of state transitions\"\n\nrqlite does not enforce security at the HTTP API level. Use, say, nginx in front of the rqlite API to do this, or roll your own proxy. Or use an API Gateway.\nAnd if you're worried about people writing to the file on disk underneath a node, then don't allow people access to the file system. \n\nSorry to say this, because allowing this back door entries via the followers, I believe your Rqlite is not a RAFT implementation.\n\nI don't mean to be rude, but you don't appear to understand what rqlite is about, nor do you understand Raft.\n. Sorry @Sooriya10 -- you simply don't understand what you're talking about. I've continually asked for a clear explanation and demonstration of your issue, and you haven't provided any.\nAnd my name is Philip, by the way.\n. > Who is responsible for this?\nThe incompetent people running the systems, that's who.\n. All that is way beyond the scope of rqlite.\n. Fixed by #84 \n. @zmedico -- if you have any time, let me know what you think of the functionality added by this PR. You can read about it here:\nhttps://github.com/otoolep/rqlite/blob/basic_auth_support/SECURITY.md\n. OK, cool @zmedico -- merging now.\n. With a move to Go 1.6, \"vendoring\" would probably be best.\n. Yes, I'm considering doing this for v5.0.. Fixes https://github.com/otoolep/rqlite/issues/64\n. Part of the work for https://github.com/otoolep/rqlite/issues/3\n. https://github.com/otoolep/rqlite/issues/3\n. @mainframe --- correct, a new node joining the cluster is not authenticated by default though you can user-level permissions to exercise some control over this process:\nhttps://github.com/rqlite/rqlite/blob/master/doc/SECURITY.md#user-level-permissions\nYou can therefore pass a password to node when it starts up, which is required by other nodes before accepting the join request. There are many other ways to lock down your cluster too.\nAs for using serf, I don't have that much experience with it, and anyway one of the main points of rqlite is simplicity -- a single binary, that clusters easily. Requiring a second system like serf would be a major complication.. Top of tree now supports node-to-node encryption, and it will be part of the 4.0 release.. - http://www.refactorium.com/distributed_systems/Hacking-up-a-testing-environment-for-jepsen-and-influxdb/\n- http://www.refactorium.com/distributed_systems/InfluxDB-and-Jepsen-Chapter-II-Where-is-influxdb-on-the-cap-scale/\n- https://www.infoq.com/articles/jepsen\n- https://github.com/abailly/jepsen-vagrant\n- http://www.datastax.com/dev/blog/testing-apache-cassandra-with-jepsen\n. As far as I know, by using STRONG read consistency, rqlite should be ready for jepsen testing.\ncc @progamer71. Required to fix #67 \n. This package will interact with the Raft consensus module, and allow nodes in a cluster to set and get metadata about themselves, with the cluster, in a consistent manner. \nPart of the work for https://github.com/otoolep/rqlite/issues/67\n. Fixed. \n. Fix https://github.com/otoolep/rqlite/issues/103\n. Turns out it doesn't.. https://github.com/rqlite/rqlite/issues/67\n. Thanks @mkideal -- this looks very nice.\n. I will merge this, and will probably make some small tweaks to it.\n. I may just rename the cli tool to just rqlite, as that would follow the pattern of MySQL.\n. Thanks @mkideal \n. SQLite has pre-update and update hooks (seemingly). This could be interesting functionality too, that might make this easier.\n. Yes, I have considered having the system stream the Raft commands out over, say, a TCP connection. But I am thinking something more focused would be more useful.. Thanks @bkeroackdsc -- you are right. This is legacy stuff I need to fix, thanks for pointing it out.\n. PRs welcome. :-)\n. Thanks @bkeroackdsc \n. @bkeroackdsc - you may wish to verify your e-mail with GitHub so you get credit as an rqlite contributor.\nhttps://github.com/rqlite/rqlite/commit/3f064afc317a1776a209170126cb1d9b504d6911\n. - If a node is lost, then restart another one on a completely new IP address.\n- If this is not possible, don't pass -join.\n. https://github.com/rqlite/rqlite/blob/master/CLUSTER_MGMT.md\n. Yes, I should fix this. Now that someone has asked, I'll look into it within the next couple of weeks or so.. Didn't mean to close.. This might be better addressed in the move to Hashicorp Raft 1.0. That has even better support for dynamic environments, and is a better solution.\nhttps://github.com/rqlite/rqlite/pull/377\nDevelopment is currently paused on that PR, but I do plan to complete it over the next few weeks.. When implemented, this also needs to be tested when an existing node joins with new IP addresses. This operation will result in a node first being removed, and the peer mapping will need to be updated then too.. May be addressed once https://github.com/rqlite/rqlite/pull/424 is completed and merged.. Done in https://github.com/rqlite/rqlite/pull/434.. On second look, this is probably fine.\n. Thanks @rse \nI follow what you're suggesting, but I don't particularly think it would be much better. I wanted to rqlite to provide the thinnest possible layer between the user and the SQLite database, so the queries one sends to rqlite are exactly the same one would send to a SQLite database. There is nothing arbitrary about it.\nWhat you suggest, which would work, would still require the client to transform their requests into the JSON rqlite would expect, and it's somewhat arbitrary. Does the API use params, values, etc.  So rqlite leaves it entirely up to clients to generate the SQL commands, and pass them in fully-formed.\nI would certainly merge a patch that added something like the functionality you suggest (basically prepared statements), but it would be a different endpoint. I always want to support the current functionality.\n. I'm definitely interested in looking into this functionality, but would like more examples of use cases and further understand how this helps users write less code.\n. Looks good thanks @bkeroack \n. No plans to change API now.. No plans to do this.. Done in v3.3.0.\n. Use type 4 UUIDs, perhaps, for the query IDs.\n. I'm not a front-end person. This would be something I'd really like help with it.\nIt would be great to have a straightforward single-page app that would show each node in the cluster, the status of each, and diagnostic information.\nThere is lots of useful information available from rqlite, as explained here: \nhttps://github.com/rqlite/rqlite/blob/master/doc/DIAGNOSTICS.md\nFor example, one could imagine the information below being presented for each node graphically, icons indicating which node is leader, the cluster topology etc etc.\njson\n{\n    \"build\": {\n        \"branch\": \"unknown\",\n        \"build_time\": \"unknown\",\n        \"commit\": \"unknown\",\n        \"version\": \"3\"\n    },\n    \"http\": {\n        \"addr\": \"127.0.0.1:4001\",\n        \"auth\": \"disabled\",\n        \"redirect\": \"localhost:4001\"\n    },\n    \"node\": {\n        \"start_time\": \"2016-05-29T14:07:06.376018405-07:00\",\n        \"uptime\": \"377.641236ms\"\n    },\n    \"runtime\": {\n        \"GOARCH\": \"amd64\",\n        \"GOMAXPROCS\": 8,\n        \"GOOS\": \"linux\",\n        \"numCPU\": 8,\n        \"numGoroutine\": 12,\n        \"version\": \"go1.6\"\n    },\n    \"store\": {\n        \"addr\": \"127.0.0.1:4002\",\n        \"dir\": \"/home/philip/repos/rqlite/src/github.com/rqlite/rqlite/cmd/rqlited/data\",\n        \"leader\": \"127.0.0.1:4002\",\n        \"meta\": {\n            \"APIPeers\": {\n                \"127.0.0.1:4002\": \"localhost:4001\"\n            }\n        },\n        \"peers\": [\n            \"127.0.0.1:4002\"\n        ],\n        \"raft\": {\n            \"applied_index\": \"10\",\n            \"commit_index\": \"10\",\n            \"fsm_pending\": \"0\",\n            \"last_contact\": \"never\",\n            \"last_log_index\": \"10\",\n            \"last_log_term\": \"5\",\n            \"last_snapshot_index\": \"0\",\n            \"last_snapshot_term\": \"0\",\n            \"num_peers\": \"0\",\n            \"state\": \"Leader\",\n            \"term\": \"5\"\n        },\n        \"sqlite3\": {\n            \"dns\": \"\",\n            \"path\": \":memory:\",\n            \"version\": \"3.10.2\"\n        }\n    }\n}\n. Thanks Joe -- was thinking a basic query box, and something which returns the results. What would be also cool would be an interface that allows you to drill down into the diagnostic information document here:\nhttps://github.com/rqlite/rqlite/blob/master/doc/DIAGNOSTICS.md\nOne could imagine a single-page that hits these status and diagnostics endpoints, showing which node is the leader, cluster state, etc.\nIdeas include:\nhttps://github.com/lmenezes/elasticsearch-kopf\n. @joeblew99 -- don't have a strong preference for this area of work, since it's not an area I know too much about. Obviously I'll be looking for high quality Go code (if any changes) and that any 3rd party packages that we import are stable and well-maintained.\nIf you want to push up any early ideas as PRs, I'll definitely play with it and provide feedback.\n. A better approach would be to have the Go client library (which needs to be fully developed) implement this functionality. It should not be CLI-specific. Then the CLI would use the new client library.. Adding it the CLI is definitely an option though.. Thanks @millken and @zmedico.\n. New repo created at https://github.com/rqlite/rqlite-docker. The very first Docker image for rqlite is available via docker pull rqlite/rqlite. There is much to do, including documentation, but it's a start. Issues regarding the Docker image should be opened at https://github.com/rqlite/rqlite-docker. Yes, you can. See the blog post below:\nhttp://www.philipotoole.com/rqlite-v3-0-1-globally-replicating-sqlite/\nThe key is to use the '-httpadv' and -raftadv options so the nodes advertise a routable address over the WAN.\n. You can some very basic numbers here:\nhttp://www.philipotoole.com/rqlite-v3-0-1-globally-replicating-sqlite/\nrqlite is fully replicated, synchronous system. Transactions don't travel across the network, but the committed commands do. I haven't done any significant testing, but you should get a few changes a second. More if you batch up.\nhttps://github.com/rqlite/rqlite#performance\n. Oh, I closed this because I don't plan to do any benchmarking at this time. The numbers on README are up-to-date, but very basic. :-)\nIf you want more detailed benchmarks, feel to specify exactly what should be tested and I can open a new ticket.\n. On second thoughts, this might not be the best way to do this.\n. https://github.com/rqlite/rqlite/issues/166\n. Not going anywhere with this right now.. https://github.com/rqlite/rqlite/blob/master/doc/BACKUPS.md\n. It would not actually require erasing existing state. That could be left up the end-user, perhaps through a URL param if a dedicated endpoint was put in place.\nE.g. GET /sqlite could return the equivalent of .dump, POST /sqlite could erase and replace, and PUT /sqlite could attempt to merge. rqlite should also do as much as possible in transactions, to minimize restore time.\n. Related PRs:\nhttps://github.com/rqlite/rqlite/pull/206\nhttps://github.com/rqlite/rqlite/pull/217\n. This looks complete.\n. That said, it may be better to leave this to the user, through LIMIT and `SORT'. \n. https://blog.markvincze.com/setting-up-an-appveyor-pipeline-for-golang/\n. Trying to bring it online here:\nhttps://github.com/rqlite/rqlite/pull/181\nAny advice to solve the gcc issue is welcome. I'm not a Windows person.\n. https://github.com/mattn/go-sqlite3/issues/214 seems relevant.\nThis is not something I plan to work on any time soon, if at all. If anyone would like to create an appveyor.yml that works for rqlite, I'll definitely try it out.\n. The only way I'm going to get this to work is if someone forks rqlite, and generates an appveyor.yml file that actually works. I am unable to work on it personally, but would be happy to merge a working PR.\n. Thank you @lygstate \n. Seems like I need to configure a path to gcc or use an alternative for the C code.\nhttps://ci.appveyor.com/project/otoolep/rqlite/build/1.0.0.5\n. @lygstate -- do you know how to install mingw on appveyor?\n. OK, thanks @lygstate.  I tried something really dumb, for kicks. It didn't work, I didn't really expect it to.\nThe only way I'm going to get this to work is if someone forks rqlite, and generates an appveyor.yml file that actually works. I am unable to work on it personally, but would be happy to merge a working PR.\n. All done via https://github.com/rqlite/rqlite/pull/199\n. \"Spreading load around the cluster\" doesn't make a huge amount of sense to me. Since rqlite is a leader-type system, all traffic has to go through the leader. If a node does not have the resources (CPU, disk, RAM, etc) necessary to serve as a leader, it shouldn't be in the cluster. rqlite does not, as I am sure you understand, distribute for scale. It distributes for reliability.\nAs for an endpoint to force an election, I could think of ways to do it, but it would pollute the implementation of rqlite. As you've been doing, forcing these kind of failures yourself is the best approach.\nI'll leave this ticket open in case I am missing a good use case, but I don't see myself doing anything here.\n. Closing as I don't see this getting done.\n. Thanks very much @lygstate !\n. This doesn't appear to work. Probably need to some more here.\n. The \"dot\" commands are not supported, as per https://github.com/rqlite/rqlite/blob/master/README.md#limitations\nIt is not possible to open an pre-existing SQLite database, and make it fault tolerant. To bootstrap a system from an existing SQLite database you need to .dump the SQLite file and play back the commands into the rqlite. \nSee https://github.com/rqlite/rqlite/blob/master/doc/BACKUPS.md for more details\nFinally, I don't have a wiki. There is documentation in the doc directory however. Improvements are welcome.\n. This is complete.\n. Start of the work for https://github.com/rqlite/rqlite/issues/208\n. The code could check the encoding of the database, and perform the correct conversions.\nPRAGMA encoding;\nPRAGMA encoding = \"UTF-8\";\nPRAGMA encoding = \"UTF-16\";\nPRAGMA encoding = \"UTF-16le\";\nPRAGMA encoding = \"UTF-16be\";\n. I'm going to merge this, as I think it's a step in the right direction.. Somehow the node is wiping the SQLite database on startup. It's fine after the node is shutdown. This is happening on both in-memory and ondisk, after a load of a SQLite dump file.. This is missing because a foreign key constraint is violated during the load, and the error means the SQL command fails.. From looking at the system, the toggle of FK constraints on and off needs to go through the Raft log. That's the only way to ensure the nodes in the system are consistent.\nSetting FK constraints outside of distributed consensus is bug.. Fixed in 3.7.0.. After further thought, it is better to leave this control up to the user. Release 3.7.0 will contain instructions on how to control FK constraints.. Being a reflection of what is in the peers file, it's probably best to leave it actually.. The SQLite parser works fine.\nsqlite> SELECT * FROM \"foo;'barx\";\nError: no such table: foo;'barx\nsqlite>. Moot, after the simple loading of SQLite dump files.. Thanks very much for your contribution.. Thanks @tych0 -- I might tweak the help output slightly, but this does seem useful, particularly the TLS support.. Great, thanks.. I think this is a mistake. You need to generate a PR against your own repo.. I'll tweak it myself.. No worries. Small tweak. \n\nOn Dec 10, 2016, at 5:59 PM, Tycho Andersen notifications@github.com wrote:\nHey!\nApologies for the delay, I was traveling. Thanks for the merge though!\nTycho\nOn Sat, Dec 10, 2016 at 7:04 PM, otoolep notifications@github.com wrote:\n\nMerged #237 https://github.com/rqlite/rqlite/pull/237.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/pull/237#event-889364916, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AAv61_BnpyOzTB6qKiApKaPu2j0ZqqHKks5rGum9gaJpZM4LI174\n.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n. Yeah, if you squash I will then merge -- thanks!\n\nhttps://github.com/rqlite/rqlite/blob/master/CONTRIBUTING.md#clean-commit-histories. Thanks @gilwo for the report, rqlite doesn't look like it's doing the right thing, as you say. Using straight SQLite works fine:\nsqlite> CREATE TABLE foo (id integer not null primary key, name text);\nsqlite> INSERT INTO foo(name) VALUES(\"fiona\");\nsqlite> SELECT id,name FROM foo;\n1|fiona\nsqlite> SELECT id || \"_bar\", name FROM foo;\n1_bar|fiona\nThis may be solved by full handling of the underlying types -- I've actually started that work in https://github.com/rqlite/rqlite/pull/221, but that work stalled. Looks like I need to return to it ASAP.\n. https://github.com/rqlite/rqlite/pull/221 has now been updated so it handles this situation correctly. I need to do more research before merging it, as it may be a hack. I don't know for sure yet.\n@gilwo -- you could try building the handle_sqlite_datatypes branch, since the issue is practically addressed there, and let me know if it works for you.. Fixed by https://github.com/rqlite/rqlite/issues/240. @gilwo -- I suggest you read https://github.com/rqlite/rqlite/blob/master/CONTRIBUTING.md#building-rqlite which has full details on building rqlite. If you build master you should have a binary that addresses this issue. Otherwise you'll have to wait until the next release.. @gilwo -- I would be interested if you have any problems following the build instructions. They are meant to be foolproof.. This line:\ncopy(n, r[0].([]byte))\nof your previous code was already making an assumption that the value was of type []byte. If you were storing integers, for example, in the column, your code would have panicked.\nThe type for the values in question is interface{} which tells you nothing really. It would be nice to tighter, I am open to suggestions.\nBut the fact that it is interface{} already leaves the interface quite loose.. OK, perhaps the new code should be more explicit about the contract of this function, as put in place by the recent change.\nHowever, my point about your code (correct me if I am missing something) is that if you stored, say, integers in a column and attempted to type-assert them to []bytes, that too would have panicked, even with the previous version of rqlite code.. Right, I see. Let me allow you to control this.. OK, now that I look at it, this totally changed the contract. Bad on my part. Let me tweak the store now, so you have control over whether this conversion takes place. I do think the conversion is useful, but perhaps not to people who just care about the store package.\nI'l push up a PR, and you can tell me what you think.. Actually @tych0 -- can you tell me something else? Is the conversion to string when the underlying type is of TEXT affinity useful? If so, and it was an explicit part of the function's contract, would that be OK? I'm trying to determine if this conversion is actually useful at this layer.\nSo is the change in contract, or the conversion itself, that is awkward?. OK, I think it's fair to provide an option to get to the raw database underneath. It does no real harm.\nHowever, can you add a bool flag to the function signature, like so:\nfunc (s *Store) Database() ([]byte, bool leader, error)\nand add the check that you find in Backup()?  on the Store object.  I would feel better if this function explicitly forced the user to choose whether he wants a leader check or not, before returning the data of the underlying SQLite database.\nWhen calling Database() from within the Snapshot function, you can set leader check to false, since I assume the Raft infra knows what it is doing.\nWhat do you think?\n. Sorry, yeah @tych0 -- that's what I mean, thanks.. Thanks @tych0 . @tych0 -- with this PR you've got a new call on the Store type, QueryRaw. This acts the way Query did previously.\nAs far as I can see, the automatic conversion of TEXT affinity values to strings is useful to people, so I want to keep that they way it is. But QueryRaw might be better for you. Let me know what you think. . OK, I see what you mean @tych0 -- there are some ideas there.\nI need to think about this for a short while. This is the first grey area, where the goals of the Store type are not quite in line with the level of control you seek. I want this to work however, and see how it might work. There is no requirement that all methods added to the Store type have to be exposed by the HTTP service, so this does provide some flexibility around what it (Store) exposes.\nPresumably you're not blocked right now, and I won't change the behavior of Query again so you can continue to build on it.. Thanks for the report @gilwo -- I see what is going on. It's due to the very simple parser in the rqlite.\nIt might take a little while to fix this -- you should load triggers manually for now, as you are doing.. Actually, this looks easier to fix that I though. I'm working on it in https://github.com/rqlite/rqlite/pull/247. Fixed by https://github.com/rqlite/rqlite/pull/247. @gilwo -- try the latest build from master, and tell me if all looks good now.. Actually, this doesn't look quite right yet, re-opening.. It's all good, you must set the right Content-type header during the curl command. See https://github.com/rqlite/rqlite/blob/master/doc/RESTORE_FROM_SQLITE.md for more details.. It is possible @gilwo that very large dumps may not go through. \nCan you show me the syntax error?. There is no explicit debug mode, apart from what you see in the logs. If you wish to share you database dump file with just me, you could e-mail me a compressed file or link to it. . Yes @kikitux -- just speculating that there might be an internal Raft limit. I have not examined the code, nor run any tests, to know if this is the case however.. It's not a bad idea, though I am hesitant to add more functionality that drifts away from the core of rqlite. Field validation is a grey area, something that might be better in an ORM built on-top of rqlite.\nAs for the table ACL, I did consider something like that. It would be doable. How important or useful would it be? What is your application @anddimario ?. I somewhat follow you, but I still need a bit more detail on what you would like. An example (fake) API call showing me what you want to do would be helpful.. I see -- thanks for the extra detail @anddimario \nRight now I don't think validation is a compelling enhancement of rqlite, relative to the other work I want to do with it. Part of the goal of rqlite is simplicitly -- a solid distributed consensus layer on top of SQLite. I'd much rather see stuff like validation in an ORM, for example. I could re-factor the code to allow plugins in general of course, but that would be major work I'm not prepared to do at this moment.\nThe ACL might be useful, but I'll need to see more requests for that level of control before building it into rqlite.. Hi @fpoltronieri -- if you want to modify the SQLite files directly the answer is no. It's definitely not supported:\nhttps://github.com/rqlite/rqlite/blob/master/README.md#limitations\nIf you want to modify one SQLite database through the HTTP API, and then only read the SQLite files under other nodes, that might work but it's not really supported either.\nFeel free to ask more questions if you like on this ticket, but I am closing it for now. . It might be, but I need a bit more detail on what exactly you want to happen. A detailed scenario, explaining what happens at each step would be helpful.. Hello @alanjds -- I just looked up SAVEPOINT. Same thing applies, the behaviour is not defined.\nI have ideas about allowing it, but haven't tested it. If it's a real problem, I might see what I can do.. I closed the ticket, but feel free to ask more questions here. I'd also be interested in seeing your Django backend, if you open-source it.\n. Thanks for your report. As per https://github.com/rqlite/rqlite/blob/master/README.md#limitations commands like that are supported. It shouldn't panic however. I'll fix that.. Can you please show me the command that first triggered this? What sequence of queries did you pump in, from the very start?. How did you pump .table in?. OK, I can repo. It looks like something in the newer SQL code, 'cos older code is OK.. You could download a binary from https://github.com/rqlite/rqlite/releases or wait until I merge https://github.com/rqlite/rqlite/pull/254. Weird -- that is strange, since I didn't get it to happen locally at first (perhaps I was mistaken). I can repro it now though.. Thanks for the report. Top of tree should handle this now.. I still need to look into something similar for the query path, but it's more of an internal issue right now.. This is fixed now.. Looking into this now, I too am seeing some unexpected behaviour.. ```\n$ curl -v -XGET 'localhost:4001/db/query?pretty&timings' -H 'Content-Type: application/json' -d '[\n    \"with bar as (select * from test) select * from test where x = 1\"\n]'\n   Trying ::1...\n connect to ::1 port 4001 failed: Connection refused\n   Trying 127.0.0.1...\n Connected to localhost (127.0.0.1) port 4001 (#0)\n\nGET /db/query?pretty&timings HTTP/1.1\nHost: localhost:4001\nUser-Agent: curl/7.43.0\nAccept: /\nContent-Type: application/json\nContent-Length: 73\n\nupload completely sent off: 73 out of 73 bytes\n< HTTP/1.1 400 Bad Request\n< Content-Type: application/json; charset=utf-8\n< X-Rqlite-Version: 3\n< Date: Fri, 13 Jan 2017 22:19:25 GMT\n< Content-Length: 0\n< \nConnection #0 to host localhost left intact\n```\nDon't know why this is a bad request.. It's not an issue with the database or SQL layer, since this passes:\n\n\nhttps://github.com/rqlite/rqlite/pull/256\nContinuing to investigate.. Actually, I take it back, my curl request is wrong. rqlite supports this kind of thing fine:\n$ curl -G 'localhost:4001/db/query?pretty&timings' --data-urlencode 'q=with bar as (select * from test) select * from test where x = 1'\n{\n    \"results\": [\n        {\n            \"columns\": [\n                \"x\"\n            ],\n            \"types\": [\n                \"foo\"\n            ],\n            \"values\": [\n                [\n                    1\n                ]\n            ],\n            \"time\": 0.002032388\n        }\n    ],\n    \"time\": 0.0020779540000000003\n}\n$ curl -G 'localhost:4001/db/query?pretty&timings' --data-urlencode 'q=with bar as (select * from test) select * from test where x = 2'\n{\n    \"results\": [\n        {\n            \"columns\": [\n                \"x\"\n            ],\n            \"types\": [\n                \"foo\"\n            ],\n            \"time\": 0.00010383\n        }\n    ],\n    \"time\": 0.00012452\n}\nPerhaps you're building the request to rqlite incorrectly? As you can see, I can drive the HTTP API to get the right results -- you just need your Python library to do the same thing.. I am tempted to close this, as I now don't see anything wrong with rqlite. The CLI does not support it correctly, but that is a CLI issue, not a rqlite issue:\nhttps://github.com/rqlite/rqlite/issues/257. Here is more detail of the successful request:\n```\n$ curl -vv -G 'localhost:4001/db/query?pretty&timings' --data-urlencode 'q=with bar as (select * from test) select * from test where x = 1'\n   Trying ::1...\n connect to ::1 port 4001 failed: Connection refused\n   Trying 127.0.0.1...\n Connected to localhost (127.0.0.1) port 4001 (#0)\n\nGET /db/query?pretty&timings&q=with%20bar%20as%20%28select%20%2A%20from%20test%29%20select%20%2A%20from%20test%20where%20x%20%3D%201 HTTP/1.1\nHost: localhost:4001\nUser-Agent: curl/7.43.0\nAccept: /\n< HTTP/1.1 200 OK\n< Content-Type: application/json; charset=utf-8\n< X-Rqlite-Version: 3\n< Date: Fri, 13 Jan 2017 22:45:19 GMT\n< Content-Length: 342\n< \n{\n    \"results\": [\n        {\n            \"columns\": [\n                \"x\"\n            ],\n            \"types\": [\n                \"foo\"\n            ],\n            \"values\": [\n                [\n                    1\n                ]\n            ],\n            \"time\": 0.00012175100000000001\n        }\n    ],\n    \"time\": 0.00015008300000000002\n* Connection #0 to host localhost left intact\n}\n```. @alanjds -- I'm closing this issue since it does not appear to be an issue with rqlite. Please re-open if you believe I am incorrect. I am happy to answer more questions on this ticket however.. I simply built top of tree. There is only a small difference between top-of-tree and 3.9.1.. Oh, I forgot one key thing.\n\nDuring my testing I passed -nosel to rqlited on startup. This tells the system not to check that queries only start with SELECT. At the time I didn't realise queries could start with WITH.\nSo start rqlited like so: rqlited -nosel your_data_dir. I'm going to remove this restriction now, since it was never valid.. Fixed in 3.9.2.\nBy the way, you should have been getting HTTP 403 back from the HTTP API, if I believe what was going on was going on. . You're doing it wrong. \nMust send queries to the /query endpoint, and use GET. Please re-read the Data API documentation,  or check my example above.. It may actually be working. The behaviour is undefined. \n\nOn Jan 16, 2017, at 9:11 AM, Alan Justino da Silva notifications@github.com wrote:\nHum... So the issue cames from here? https://github.com/rqlite/pyrqlite/blob/master/src/pyrqlite/cursors.py#L98\nAnyway, I would expect that everything that works on /db/query to work on /db/execute too. Thanks for pointing the difference.\nNow I am thinking in how to detect on client side if some query alters data...\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I do agree that the next major enhancement to rqlite would be to have it do the right thing automatically. This would make it much easier to use. \n\nIt's a high-priority next task. \n\nOn Jan 16, 2017, at 9:11 AM, Alan Justino da Silva notifications@github.com wrote:\nHum... So the issue cames from here? https://github.com/rqlite/pyrqlite/blob/master/src/pyrqlite/cursors.py#L98\nAnyway, I would expect that everything that works on /db/query to work on /db/execute too. Thanks for pointing the difference.\nNow I am thinking in how to detect on client side if some query alters data...\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Fixes https://github.com/rqlite/rqlite/issues/255. No, I don't provide Windows builds on the release page. However I test the source each commit to make sure it's still buildable on Windows, so you can compile it yourself.. I don't have access to a Windows box, and haven't figured out cross-compiling yet. If you can provide me a build line I can run from Linux, I can do it.\n\nI do run all the code through appveyor CI, so it is buildable on Windows at all times.. https://github.com/rqlite/rqlite/blob/master/appveyor.yml\nhttps://ci.appveyor.com/project/otoolep/rqlite. Thanks for the report @omerkorenn -- I will take a look.. @omerkorenn -- did you load the your node via this technique?\nhttps://github.com/rqlite/rqlite/blob/master/doc/RESTORE_FROM_SQLITE.md. If you are loading from a SQLite dump, I would guess you're hitting the 10-second timeout at this line of code:\nhttps://github.com/rqlite/rqlite/blob/master/store/store.go#L441\nI can make this configurable, so you can increase it.. @omerkorenn -- can you build top of tree, as per these instructions:\nhttps://github.com/rqlite/rqlite/blob/master/CONTRIBUTING.md#building-rqlite\nIf so, please launch rqlite with a larger timeout like so:\nrqlited -raftapplytimeout 30s\n30 seconds is a suggestion, you might need to go higher. I'd be interested in knowing what value you need. v3.9.2 has a 10 second timeout.. OK, I'm going to assume this is solved.. Did you try any increasing the timeout at all?. OK, 120s is kinda long. I don't follow your suggestion about \"parallel\". Can you explain more?\nYou could split the file you're loading into multiple smaller files, which will help you keep your timeout setting low.. Interesting @omerkorenn -- you might be onto something there, though I would need to confirm that Open doesn't block until all Raft log messages have been applied.\nLet me re-open to investigate.. @omerkorenn -- I have confirmed that NewRaft does return before all the log entries have been applied. I'm trying to see if there is a way to allow it to block instead.. @omerkorenn -- top of tree solves this problem correctly. It waits, by default, up to 120 seconds for the initial state to be applied. You no longer need to set -raftapplytimeout. If 120 seconds is not sufficiently long, you can increase it.. May be a solution for https://github.com/rqlite/rqlite/issues/260. If a full SQLite parser was built in, rqlite could also support a streaming TCP connection for getting statements into the system. This might also improve throughput.\nAnyone know of SQLite command parsing code? Perhaps I could pull in the source code of the SQLite system itself, unless it's already in the library I am using.. \"cznic/ql have own lexer for SQL and it syntax very similar.\" -- from Go Google Group.. @kenshaw -- I think you meant to add this comment to the usql repo, not sure. No worries.\n\n\nAs far as I can tell, there's only about 8 or 9 different \"beginning\" words that should be one versus the other.\n\n\nI don't know for sure. You might be correct. It seems statements that begin with WITH may only have SELECT statements following. It looks like it, at least for SQLite: https://www.sqlite.org/lang_with.html. Actually, no that's not true -- it seems INSERT can use a WITH as well. So the idea that checking \"starting\" words will be enough doesn't seem right.\nhttps://www.sqlite.org/syntax/insert-stmt.html. In other words, look at these two statements:\nWith helper_table As (\nSelect * From dummy2\n)\nInsert Into dummy1 Values (Select t.a From helper_table t Where t.a = 'X' );\nWITH Employee_CTE (EmployeeNumber, Title)\nAS\n(SELECT NationalIDNumber,\n        JobTitle\n FROM   HumanResources.Employee)\nSELECT EmployeeNumber,\n       Title\nFROM   Employee_CTE\nEach should go to a different handler, even though both start with WITH.. A Pratt Parser might work well for this.. Basically rqlite needs a Go module that can robustly parse a single SQL command and tell whether it will modify the database or not. Currently the CLI just checks with the command starts with SELECT, an approach which covers most cases, but not all. \nThis Go module could then be integrated into the rqlite software itself.. This looks useful: https://github.com/xwb1989/sqlparser. Could be on the server @alanjds -- some of this conversion logic needs more work, to ensure it's doing the right thing.. Basically, it might have something to do with this area: https://github.com/rqlite/rqlite/pull/244, but I am not sure yet. I'm still researching what is the right thing to do here.. @zmedico -- I'm not fully following this. Can you give some examples of SQL statements that are failing on rqlite? Is this something that can be demonstrated purely with SQL?. In other words, is there is a sequence of SQL statements one could execute directly at the sqlite3 prompt that fail to produce the right results when sent to rqlite?. Interesting! I think it's safe, but there might be one problem.\nI do agree that if the leader only commits to the Raft log after successfully committing the transaction, it's pretty safe. Since, on start-up, the SQLite database is completely rebuilt from the Raft log any commits in the database, but not in the log, will not be applied to the newly-built database under the node.\nHowever, there is a concept of snapshotting the SQLite database, as a part of compacting the log (and this state is shipped to other nodes that join). I'm not sure what guarantees there are around when that snapshot is taken. If it was taken while the commits were in the database, but before the log was applied to the database, it would be trouble.\nPerhaps the Hashicorp Raft documentation can rule out this possibility? If so, I think your idea is really interesting, and could be quite useful.. Since you submitted a second PR, I just want to be sure I understand how you propose this should work.\nIf a client wants to get results of a query in the middle of a transaction (which is the example reason you give and a valid use case), the client must explicitly ask to start a transaction. All good, the node talks to the SQLite database directly without going through the log (which it never does today), and the client gets an ID back.\nNow, while this transaction is active, the client performs the execs and queries, and these queries are performed against the SQLite database directly -- not through the Raft log. Once the client is happy, it calls commit, the node takes the list of commands that were executed, wraps them up in a single log message, and attempts to send the log message through Raft. If it fails, it wipes the database directly and forces it to be rebuilt.\nSome things that occur to me: \n-- for the transaction situation, the rqlite state machine code would need to change such that it just commits those entries to the log, but doesn't apply the log to the database, but just on the leader (since the leader will have already modified its local SQLite database). But a follower would still need to apply the log messages to its local database since it would not be involved directly with the transaction handling. This makes me nervous -- to have a node handle messages differently depending on whether it is a leader or a follower. And the problem with a node checking if it's a leader is that leadership status can change at anytime. For a node to be absolutely sure it is the leader, it requires a round trip through the Raft consensus mechanism -- this means another message in the log. See strong read consistency to see this in action.\n-- what would happen if the leader handling the transaction was deposed? Due to a network fault? The call to Apply() would fail, which might seem OK. But what would happen if, during the transaction processing, the leader was deposed, was not the leader for a while, and then re-elected so the call to Apply() was successful? But the SQLite database under the leader may no longer be what is was before, since the other node that was leader for a short while may have made changes. Does that make sense? \n-- how will other nodes respond to a database being wiped? Will this need to be done via consensus? \nThese are just cases that I think are difficult to address. I think the change you're proposing is ambitious, but I think the edge cases are hard to reason and be sure they've been solved.\nLet me know what you think.. >>I don't understand what you mean here: why does the follower need to be aware of the transaction at all, until it is committed via raft log?\nLet me take a step back. Today, when any node has Apply() called on its fsmby the Raft consensus mechanism, the code unpacks the message in the Raft log entry -- one or more SQLite statements -- and applies them to the underlying database. Each node acts exactly the same way. Now, with this new design, it seems to me that the leader will have to act differently than the followers -- it can't apply the SQLite commands to the database contained in the Raft log entry, during the execution of Apply(), because it will have already applied them. Only followers would be safe applying the SQLite commands contained in the log entry.\nAssuming I am correct, this introduces a few issues. Fundamentally for a node to check that it is the leader (so that Apply() executes differently) it must perform a distributed consensus operation -- it much ask each other node if it's the leader in a very specific manner. It's not enough to just check some local state -- not if you want a 100% correct answer (which we do for any activity that may result in changes to the underlying SQLite database). All this is not trivial. Does this make sense? Or am I missing something?\n\n\nGreat question, and I hope this is addressed by this code:\n\n\nUnfortunately I don't think it does. I might be wrong, but it would need rigorous testing to be sure. The issue is that there is nothing preventing node A being the leader, node B suddenly being elected leader (network fault disconnects A from cluster), node B being deposed (network fault disconnects B, but A is back), and node A being elected leader again, any number of times, between these two lines of code:\nerr := t.tx.Commit()\nand\n_, err = t.store.Execute(t.stmts, false, true)\nAssuming that the node is leader during both of these lines of code, and that the Raft term has not changed, is an invalid assumption (as far as I know). Assuming I am correct, I have no idea how this change would interact with the system going through the election cycle described above.. @tych0 -- some of the ideas you raise might work. But I think you can see now that what you are suggesting is not trivial, and has lots of corner cases that need extensive testing. Without this kind of rigorous testing, I would be very hesitant to merge the proposed transaction support into the master. \nIn its current form rqlite provides very strong correctness guarantees due to the way it uses the Raft consensus module. But a system that attempts to provide transactions in the form you suggest would not do so. What we really need is something more like standard 2-phase commit.. >>then the store can look at its active transaction and not apply it if the uuids match?\nIt might, but it's starting to get complicated.\n\n\nI think the right thing to do here is simply to invalidate any active\ntransactions when a new leader is elected. Does that make sense?\n\n\nAssuming you can even hook into when this happens, in a way that guarantees you won't miss the election, and it's not racy.. >>I think you can: https://godoc.org/github.com/hashicorp/raft#LeaderObservation\nSince that's not part of the Raft core, but a convenience feature that Hashicorp built, I'm not sure what the guarantees are.\n\n\nOk. Do you have a suggestion for what that would look like?\n\n\nI know, at a high-level, what two-phase commit is -- Raft is sort of a 2PC system AFAIK, but I have never coded one, so you're running up against the limitation of my knowledge now.\nI have another idea, which I have never had the time to explore. Perhaps it would work? Let me explain, perhaps you can try coding it.\nA distributed transaction is started as follow -- the client requests to start a transaction, and the SQL statement BEGIN is sent through the Raft log in the normal way. Each node will get this statement per the usual methods, and open a transaction on each underlying database. Now each SQLite database is in the same state. The client sends further execs and queries as usual, all of which are taking place within the transaction. All these commands go through the log.\nFinally the client decides to commit, or rollback. Again, the system simply sends COMMIT or ROLLBACK through the log, and each node processes the command as usual. Each database ends up in the same state. If COMMIT fails, well, the transaction is aborted on each node as usual. The commands remain in the log, but it's not a problem. At the end of the day the database under each node is in the same state. In other words the system operates the same way as ever. \nThe README states that commands such as COMMIT are not supported by rqlite, but this is only because I never tested the above scenario and didn't want to make any promises. But perhaps it would all work nicely.\nThere are a few things to consider.\n-- a node crashes while holding a transaction. In this case the transaction will be aborted automatically. However, when the node restarts the database is wiped and rebuilt from what's in the logs. It will recover to the state it was, and pick up any commands that occurred while it was down. \n-- the entire cluster crashes during a transaction. In that case, the cluster will come back up in state that finds itself in the middle of a transaction. This could be rather strange, since one would imagine that a cluster restart should clear out any transaction. There might be case here for rolling back any transaction that system finds itself in, due to a replay of a log on restart. In other words, after the log is applied after starting up, issue an automatic ROLLBACK by default. If there is no transaction in progress, it's not a big deak.\n-- clients, other than the client that is using the transaction, should be allowed to read the database while a transaction is in place. However, those other clients should not be permitted to write to the database while a transaction is outstanding. So to prevent this, a transaction ID (or something) should be handed out to the client that starts the transaction, and that client should pass back the transaction ID. It might be possible to use the transaction ID returned by the command BEGIN. \nDoes this make sense? Do you want to see if sending BEGIN, COMMIT etc through the Raft system would actually work?\n. >What will automatically abort the transaction in this case? This seems\nquite hard to detect.\nSince the connection to SQLite will be dropped, I presume SQLite itself does it -- or handles it.\n\nSounds reasonable. Another problem is parallel transactions, which this\nwon't allow for. But perhaps we can work some magic around that.\n\nYeah, only one at a time.. >Hmm. But sqlite isn't a daemon or anything; if for example golang segfaults, sqlite isn't running any \nmore.\nObviously I know that. :-) What I mean is that any lingering transaction might be cleaned up the next time SQlite is accessed, or something. I have not pushed on this myself. Perhaps you will know better.. I don't know for a fact either, and I have not tested it. But I'd be shocked if the SQLite system had not been implemented to handle a client crashing in the middle of a transaction. Maybe that transaction is left dangling forever, but with zero practical impact on the system. When the node restarted, it would be starting a new transaction.. Sure. If you look back on what I wrote yesterday, I called this out:\n\"-- the entire cluster crashes during a transaction. In that case, the cluster will come back up in state that finds itself in the middle of a transaction. This could be rather strange, since one would imagine that a cluster restart should clear out any transaction. \"\nPerhaps I am missing your point. \n\nOn Feb 15, 2017, at 8:57 AM, Tycho Andersen notifications@github.com wrote:\nSure sqlite may have support for it, but we're not really dealing with sqlite, we're dealing with our own log of things. The problem here is that you can't nest transactions:\n$ sqlite3 :memory:\nSQLite version 3.11.0 2016-02-15 17:29:24\nEnter \".help\" for usage hints.\nsqlite> BEGIN;\nsqlite> BEGIN;\nError: cannot start a transaction within a transaction\nsqlite> \nSo consider:\nNode issues a BEGIN\nNode crashes\nNode restarts, and re-builds the sqlite3 database from the raft log.\nNobody can BEGIN, because nothing ROLLBACK'd the previous transaction.\nAll the sqlite3 intelligence about crashing doesn't help us here, because our basic primitive is not sqlite3, but statements in the raft log.\nI suppose we could look at the old sqlite DB from the last boot and see if it had a partially written transaction, but there's still no way to detect if that partial transaction was as a result of the crash, or if it crashed during the Apply() of a COMMIT from some raft neighbor.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. If there is a way to deal with this, it would be great. But it may be the user would have no choice but to issue an explicit ROLLBACK after a restart. Perhaps there is some way to handle it automatically. . If there is a way to deal with this, it would be great. But it may be the user would have no choice but to issue an explicit ROLLBACK after a restart. Perhaps there is some way to handle it automatically. . Closed the issue in error. . Yeah, this is not looking as easy as I first thought. I knew there was a reason the system didn't officially support BEGIN and friends. :-)\nOn Feb 15, 2017, at 9:24 AM, Tycho Andersen notifications@github.com wrote:\nRight, I guess I think it's possible if just one node crashes, not only the entire cluster. An explicit rollback after a single node failure would be unfortunate.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thanks, for your input, @MrHacky \nSpecifically, if there is a crash after sqlite BEGIN but before COMMIT, the next time you open the database it will be as if none of the statements after BEGIN ever happened. sqlite has its own log/journal and only a COMMIT will make a sqlite transaction permanent.\n\nI think everyone understood that. I certainly did\nYour suggestion is interesting however. It would require the node holding the transaction open to refuse all other statements, that are not part of the transaction. That's not a blocker. The real issue is when does the node give up waiting for the client to say it's done? I guess the client could specify a timeout, and if a request is not received within that time, abort it.\nI am also thinking about adding support for sending queries over TCP (as opposed to HTTP). This would allow the node to abort the operation is the TCP connection was closed.. @Esowteric -- to be clear, you can issue the BEGIN and COMMIT commands yourself if you wish. The point is that the behavior of rqlite under those circumstances is currently undefined. You risk leaving the system in a locked state if any problems (such as a crash) occur between BEGIN and COMMIT (or ROLLBACK).. Initiated a discussion of this issue here: https://groups.google.com/forum/#!topic/raft-dev/BaS5Z2NkDxA. Thanks -- I came across dqlite recently, interesting work. However it would require me to re-write the application layer since dqlite is a library that must be linked with other code (not a huge deal of course, it would just take time). I would also need a significant patch to the SQLite C source code, which would then mean rqlite could no longer claim it was built on production-grade SQLite. rqlite users couldn't have the same assurance about the database engine that they do now (though if the patch gets merged upstream it's a different story).\nLet me know if I am missing something.. The design I am proposing for transactions is as follows.\n\na new endpoint for starting a new transaction. A Client makes a HTTP POST request to /db/transaction to begin this transaction. This request will eventually get down to the SQLite layer as a BEGIN statement.\nfor the transaction a new, dedicated, connection to the SQLite database may need to be created. This allows statements not associated with the transaction (statements that come in the API without the transaction ID) to proceed over the connection in autocommit mode (what we have today). Effectively this means that each cursor in, say, the Python client library would result in a new connection to the SQLite database because each cursor might explicitly create a new transaction (if not in autocommit mode).\nthis latter point may not be what is expected by the Python PEP 249 spec. This states that cursors from the same connection are not isolated. This implies the creation of a connection object would result in a new database connection to SQLite inside the rqlite node.\nthis endpoint will accept an optional query param, indicating the type of SQLite transaction (DEFERRED, IMMEDIATE, or EXCLUSIVE). The default will be be DEFERRED.\nin response rqlite returns an opaque transaction ID.\nsubsequent SQL write statements that are to take place within this transaction must include this transaction ID in the request, as the query param txid.\nif rqlite receives any write statement that does not include this transaction ID, rqlite will return an error (with one possible exception -- see later). The error returned to the client is basically equivalent to the \"database locked\" response that a SQLite client can receive today.\nthe client can commit the transaction, or roll it back, by making HTTP requests to /db/transaction/<txid>. A PUT to this ID will commit it, a DELETE will roll it back.\na GET request to /db/transaction/<txid> will return various technical information about the transaction, if it is currently in progress.\nsavepoint functionality may also be implemented, via the endpoint db/transaction/<txid>/savepoint\n\nFailure scenarios are handled as follows:\n\nleader node, which is handling the transaction, crashes during transaction processing. In this case a new election will take place (as normal). The client must redirect its processing to the new leader, and it can continue where it left off. The node that crashed will come back up and rebuild its state from the Raft log as usual. It will apply any changes it missed while down, again as usual.\nleader node loses network connectivity to the cluster, due to a network partition, during transaction processing. A leader election will take place as described above, and the client must handle it accordingly.\nentire cluster goes down. When it's restarted the Raft log will be replayed and the transaction will be restarted. This means that restarting the cluster will not clear a transaction, which may be odd. However I see no way to avoid this outcome.\nthe client crashes during transaction processing, and never commits or rolls back the transaction. This can be handled by another client at anytime by explicitly rolling back the transaction, if that client is sure this it the right thing to do (not necessarily trivial to know if it is the right thing to do).\nrqlite will support associating an optional timeout with a transaction. Everytime rqlite receives a SQL statement while a transaction is active, and if this SQL statement does not include the correct transaction ID, it will check the time a SQL statement associated with the transaction was last received. If this time is more than \"timeout\" in the past, the rqlite system will rollback the transaction and then execute the latest SQL statement it just received. This timeout will be configurable at the server level, and clients will also be able to override it on a per-request basis (up to a max configured on the server). \nit may also make sense to for the leader to automatically rollback any transaction that has not received any associated statement within the timeout.\nbehavior of rqlite, due to a client sending BEGIN, COMMIT, ROLLBACK etc, will continue to be undefined.\n\nThis is the current design proposal. A key test of whether this will work will be if something that requires full transaction support can be supported by rqlite. For example, can the rqlite Python driver be made fully functional, such that something like Django can run on rqlite?\nFinally, the current use of the word \"transaction\" in rqlite docs and code will be replaced with the word \"atomic\" -- with one exception. The data API will silently support transaction as a query param, for the purposes of backward compatibility. This query param will be officially deprecated however.. The above design, along with some examination of Python PEP 249 seems to indicate that new endpoint is needed: /db/connection\nA POST to this endpoint would result in a new handle to the underlying SQLite file, and would return a connection ID. Many of these could exist, and would exist in a mapping on each rqlite node. This implies that connection-creation would go through the Raft consensus system. The SQLite handle that is created today would remain, for use. But complex drivers -- PEP249, JDBC, etc, would create an explicit connection using this endpoint.\nThis connection would have a timeout, on which if no activity was received, it would simply close aborting any transaction.\nThis does show that longer term adding a TCP (gRPC? JSON?)-based connection to rqlite would make sense. It may even be the best path, to make it easier to implement drivers. This may remove the need for transaction IDs, because the definition of connections means that statements are not isolated. If you want isolation, create a new connection.. It may be more standard to use the HTTP header Session-Id to return the connection ID, and support this as a way to return the connection ID in a request.. The latest design for this remains a new endpoint /db/connection -- this work has started in https://github.com/rqlite/rqlite/pull/466\nIsolated connections should make supporting transactions much easier. In fact, it may allow two modes of transactions:\n-- one where every command on the new transaction, on a given connection, go through Raft. This includes BEGIN, COMMIT and ROLLBACK (if executed). Call this strong transaction support. This would have the advantage that transaction state would carry over to every leader, if the current leader failed.\n-- one where the transaction is just opened on the local SQLite database directly, without going through the Raft log. Only if the transaction was committed would the entire set of queries be committed. This would be much faster, but the issue here is that the SQLite database could be left in a LOCKED state after a leader election. If an election occurred during a transaction, this now non-leader node might reject changes from the new leader because its database was LOCKED, whereas all other nodes were not. This might be handled by the the first node listening for leader changes and immediately rolling back any transaction, but this is racy.\n. Interesting...this commercial database has a similar transaction mechanism to one proposed above.\nhttps://docs.marklogic.com/guide/rest-dev/transactions. https://github.com/rqlite/rqlite/pull/493. Implemented.. Thanks -- it's a weakness, I can look into addressing.. Is it actually causing you an issue?\n\nOn Feb 14, 2017, at 11:46 AM, Ivan notifications@github.com wrote:\nHi again, Philip!\nDo you happen to know how to fix this problem? I guess it's a \"bug\" in hashicorp/raft implementation.\nBecause as far as I understood, hashicorp/raft doesn't call Snapshot() and Persist() concurrently, so I don't know of a way to communicate chunks of the database between Snapshot() and Persist() - do you have an idea how to do this?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I mean, are you actually encountering a problem in practice?\nOn Feb 14, 2017, at 11:46 AM, Ivan notifications@github.com wrote:\nHi again, Philip!\nDo you happen to know how to fix this problem? I guess it's a \"bug\" in hashicorp/raft implementation.\nBecause as far as I understood, hashicorp/raft doesn't call Snapshot() and Persist() concurrently, so I don't know of a way to communicate chunks of the database between Snapshot() and Persist() - do you have an idea how to do this?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thank you @JeanGolang -- I will look into using the new interface exposed by the Raft package.. Thanks @WanliTian !. Thanks for your note.\n\nThe commands you reference are not standard SQL, so are not yet supported. Those commands are part of the sqlite3 command, not SQLite itself.\nhttps://github.com/rqlite/rqlite/blob/master/README.md#limitations\nhttps://github.com/mattn/go-sqlite3/issues/305. I'll leave this issue open for now, because I agree it would be useful to support these commands. It's not trivial to do it the right way.. It was easy enough to add specific support for .tables and .schema to the rqlite CLI -- try it out. Top of tree supports it now. . Support for .tables and .schema is now available through the rqlite CLI, version 3.11.0 and later.. Targeted fix for https://github.com/rqlite/rqlite/issues/277. OK, let me take a look, but before I do, why is there an issue with in-memory databases? It's just a SQLite database as far as rqlite is concerned. Maybe it's obvious from your PR.\nIn-memory databases can provide a big speed-up, I'm hesitant to remove it without a big, big win in return.. Solving https://github.com/rqlite/rqlite/issues/270. UDP broadcast doesn't work in AWS, so I am not sure how much this would be used in practise.. @gedw99 -- can you provide a more precise reference? A URL?. Thanks for your report.\ncurl -G 'localhost:4003/db/query?pretty&timings' --data-urlencode 'q=.tables'\nMoved Permanently.\nSending dot-commands like .tables directly to the HTTP endpoint is not supported. Dot-commands are actually translated to a different query by the CLI. Check the source of the CLI for details. And otherwise what you are getting back from the node is correct -- you get a 301. Pass -v to curl to see more.\nAs for your other issue, I cannot reproduce it. I built the latest source on MacOX and repeated your steps of connecting to the leader, and then connecting to a different node. I also tested the latest release. It all works fine.\n$ ./rqlite \n127.0.0.1:4001> .schema\n+---------------------------------------------------------------+\n| sql                                                           |\n+---------------------------------------------------------------+\n| CREATE TABLE foo (id INTEGER NOT NULL PRIMARY KEY, name TEXT) |\n+---------------------------------------------------------------+\n127.0.0.1:4001> \nEOF (CTRL+D)\n$ ./rqlite -H localhost -p 4003\nlocalhost:4003> .schema\n+---------------------------------------------------------------+\n| sql                                                           |\n+---------------------------------------------------------------+\n| CREATE TABLE foo (id INTEGER NOT NULL PRIMARY KEY, name TEXT) |\n+---------------------------------------------------------------+\nlocalhost:4003>\n. Be sure you are running rqlite and rqlited from the same release. . Execute curl localhost:4001/status?pretty and paste your output here. You can run this command against post 4003 and 4005 to see what each node thinks about the cluster.. If I had to guess, I'd say you're not running the version of rqlited you think you're running. It almost looks like you're still running older software. The status commands will show you the version each node is running.. Nothing looks wrong with the output. I see you are running Linux, so perhaps you can rule out something wrong with your build by running a pre-built binary. You can download v3.12.1 at https://github.com/rqlite/rqlite/releases\nFollow the instructions for Linux, and show me exactly what you do. Right now I cannot repro this issue. https://gist.github.com/otoolep/80dd3ac5a53bc9ecc5acd91d45a67aa6 shows me running two v3.12.1 nodes, the nodes forming a cluster, and connecting to each node via the CLI and executing .schema without any trouble. . You will need to show me as detailed a sequence of events demonstrating the problem, as I showed on the gist link above (which shows everything to be fine). As far as I can see there is nothing wrong with the software.. Thanks. \nCan you please do it again, but with the prebuilt 3.12.1 release? You can download the binary and just run it without building anything. \n\nOn Mar 17, 2017, at 9:18 PM, anfho93 notifications@github.com wrote:\nOk i tried with a new docker and this is the full process\nhttps://gist.github.com/anfho93/fa6cbed9f56a61b9201e79c1d3dfec97\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I wonder if it's a Go version 1.8 thing, which you use to build it. Can you also rebuilding with Go 1.7. The prebuilt binaries are built with 1.7.1 so that is why I would like you to try them. \nOn Mar 17, 2017, at 9:18 PM, anfho93 notifications@github.com wrote:\nOk i tried with a new docker and this is the full process\nhttps://gist.github.com/anfho93/fa6cbed9f56a61b9201e79c1d3dfec97\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I will see if I can repro after building with 1.8.. There were changes in HTTP redirect handling between 1.7 and 1.8. I had to make one change to account for it: https://github.com/rqlite/rqlite/pull/289\n\nPerhaps there is another place that needs changing.. OK, I can repro this when I build the system with 1.8. I'm looking into a fix.\n. @anfho93 -- I believe this is now fixed on master. Do you want to pull down the latest code on master, build with Go 1.8, and see if it works now? If so, we can close this issue.. Thank you @anfho93 for the report -- there was a real bug here. Glad it's fixed.. OK, thanks @wil222 -- I'll take a look at top of tree, which is in active development.. Re-opening so I take a look for 5.0.. @little-pan -- I don't the problem with the code you point at. Exactly where is the reader called multiple times?. OK, I'll take look when I return to the code -- thanks.. Should fix https://github.com/rqlite/rqlite/issues/295. Got complete this work.. http://snapcraft.io/docs/build-snaps/ci-integration. Thanks for your report.\nYou are missing a key step in the restoration process. You must first convert the backup file to set of SQL commands. In your case do the following:\necho '.dump' | sqlite3 x1.dmp > restore.dump\nThen load restore.dump.\nI will make this clearer in the docs.. @WesleyRen -- the short answer is no.\nHowever if you can send a write request to a follower, the follower will return 301 and include in the response a HTTP header value, which shows the location of the leader.\nThis allows you to write code that transparently (to a user) sends write requests to any node in the cluster. The rqlite CLI does that, for example: https://github.com/rqlite/rqlite/blob/master/cmd/rqlite/main.go#L107\n. No. It's fundamentally at odds with the design. . You are not launching the first node correctly. And by default the first node will list on localhost, which is 127.0.0.1. That is not the same as the IP address of your machine (though the interface may be the same). You need to launch the first node as follows:\n$GOPATH/bin/rqlited ~/node1\nand launch the second node as:\n$GOPATH/bin/rqlited -http localhost:4001 -raft localhost:4002 -join http://localhost:4001 ~/node2\nSee https://github.com/rqlite/rqlite/blob/master/doc/CLUSTER_MGMT.md for more details.. Closing, please re-open if you still believe there is a problem.. And take a look at https://github.com/rqlite/rqlite/blob/master/system_test/end_to_end.sh for explicit  commands on running a cluster on a single machine.. Correct.  \n\nOn Apr 21, 2017, at 2:28 AM, Majonsi notifications@github.com wrote:\n@otoolep\nThanks for your response. It's now working! But is that normal that I have to type in the command the Ip adress of the machine instead of localhost? So my command become:\n$GOPATH/bin/rqlited -http IPOFTHEHOST:4001 -raft IPOFTHEHOST:4002 -join http://IPOFTHEANOTHERCOMPUTER:4001 ~/node2\nThis mean that I can't connect a computer to a node which have been launched with the command : $GOPATH/bin/rqlited ~/node1 ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. To address your issue would require changing the default listening IP addresses to 0.0.0.0. It's easy to do, but it wasn't the choice I went with. Perhaps I should have.. Should be fixed by https://github.com/mattn/go-sqlite3/pull/427. https://github.com/mattn/go-sqlite3/pull/427 instead.. If I understand your question, the answer is no. rqlite doesn't expose the C API directly. It only supports SQLite SQL commands.\n\nPlease check out the detailed API docs for more information:\nhttps://github.com/rqlite/rqlite/blob/master/doc/DATA_API.md\n. You mean, can you run a 2-node cluster? Sure. Just run two nodes, the second one joining to the first.\nYou will have no fault tolerance however, since if either nodes fails, your cluster will be down.. Re-open if I don't understand your question.. No, it can't since a 2-node cluster requires a majority of the nodes to be up. 1 out of 2 nodes is not a majority.. Not without killing the leader and restarting it. But that would not be sensible.\nrqlite is not a good match for a simple master-slave replicated system.. Yes, it is possible. See https://github.com/rqlite/rqlite/issues/259. You will need to follow the Appveyor build to understand how to build for Windows.\nhttps://github.com/rqlite/rqlite/blob/master/appveyor.yml. https://ci.appveyor.com/project/otoolep/rqlite. I doubt it. Have you some specific idea in mind?. rqlite doesn't sound like a good match for what you need. The system requires all nodes to remain in the cluster for best performance, and large clusters are not a good idea. Latency is not an issue per-se, but will affect throughput.\nhttps://github.com/rqlite/rqlite/blob/master/doc/CLUSTER_MGMT.md. After further consideration, this doesn't seem applicable to rqlite.. Yes, looks like it @chenziliang. It would be an easy fix however.. The performance degradation is measurable, due to the Raft layer, but probably not huge for a single node. For multi-node clusters it will be quite significant.\nhttps://github.com/rqlite/rqlite/blob/master/README.md#performance. I don't plan to fix this, since it's not really significant.. @raarts -- I'm not sure I really follow what you are proposing. I am very familiar with the \"Bottled Water\" system (and Kafka in general), and have built similar systems.\nBut it's not clear what kind of possibilities you have in mind. rqlite is built on SQLite. It has no access to its WAL. . OK, right. rqlite processes the changes before they go to SQLite:\nhttps://github.com/rqlite/rqlite/blob/master/doc/DESIGN.md\nSo it sits, logically, on top of SQLite. Sounds like you want something that streams changes out of SQLite after they have occurred. rqlite is not that thing.. Closing this because I believe I've answered your question, but let me know if not.. Google Group now available at https://groups.google.com/forum/#!forum/rqlite. Works fine for me.\n```\n~/r $ curl -sL https://github.com/rqlite/rqlite/releases/download/v4.0.0/rqlited-v4.0.0-linux-amd64.tar.gz -o rqlited-v4.0.0-linux-amd64.tar.gz\n~/r $ tar xvfz rqlited-v4.0.0-linux-amd64.tar.gz \nrqlited-v4.0.0-linux-amd64/\nrqlited-v4.0.0-linux-amd64/rqlite\nrqlited-v4.0.0-linux-amd64/rqlited\n~/r $ cd rqlited-v4.0.0-linux-amd64/\n~/r/rqlited-v4.0.0-linux-amd64 $ ls\nrqlite  rqlited\n~/r/rqlited-v4.0.0-linux-amd64 $ ./rqlited data &\n[1] 3146\n        _ _ _\n       | (_) |\n\n_   | || | \n | '_/ _  | | | / _ \\   The lightweight, distributed\n | | | (| | | | ||  /   relational database.\n ||  _, |||___|\n         | |\n         |_|\n[rqlited] 2017/07/23 19:24:10 rqlited starting, version v4.0.0, commit d782c46a6199eb8bbb77480a3470118dc9be85c8, branch master\n[rqlited] 2017/07/23 19:24:10 go1.8.1, target architecture is amd64, operating system target is linux\n~/r/rqlited-v4.0.0-linux-amd64 $ [mux] 2017/07/23 19:24:10 mux serving on 127.0.0.1:4002, advertising 127.0.0.1:4002\n[store] 2017/07/23 19:24:10 SQLite in-memory database opened\n[store] 2017/07/23 19:24:10 enabling single-node mode\n[store] 2017/07/23 19:24:11 waiting for up to 2m0s for application of initial logs\n2017/07/23 19:24:11 [INFO] raft: Node at 127.0.0.1:4002 [Follower] entering Follower state (Leader: \"\")\n[cluster] 2017/07/23 19:24:11 service listening on 127.0.0.1:4002\n[rqlited] 2017/07/23 19:24:11 no join addresses set\n[rqlited] 2017/07/23 19:24:12 failed to set peer for 127.0.0.1:4002 to localhost:4001: no leader available (retrying)\n~/r/rqlited-v4.0.0-linux-amd64 $ \n~/r/rqlited-v4.0.0-linux-amd64 $ \n~/r/rqlited-v4.0.0-linux-amd64 $ 2017/07/23 19:24:12 [WARN] raft: Heartbeat timeout from \"\" reached, starting election\n2017/07/23 19:24:12 [INFO] raft: Node at 127.0.0.1:4002 [Candidate] entering Candidate state\n2017/07/23 19:24:12 [DEBUG] raft: Votes needed: 1\n2017/07/23 19:24:12 [DEBUG] raft: Vote granted from 127.0.0.1:4002. Tally: 1\n2017/07/23 19:24:12 [INFO] raft: Election won. Tally: 1\n2017/07/23 19:24:12 [INFO] raft: Node at 127.0.0.1:4002 [Leader] entering Leader state\n2017/07/23 19:24:12 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n~/r/rqlited-v4.0.0-linux-amd64 $ [rqlited] 2017/07/23 19:24:13 set peer for 127.0.0.1:4002 to localhost:4001\n[http] 2017/07/23 19:24:13 service listening on localhost:4001\n~/r/rqlited-v4.0.0-linux-amd64 $ \n~/r/rqlited-v4.0.0-linux-amd64 $ ./rqlite\n127.0.0.1:4001> .schema\n+-----+\n| sql |\n+-----+\n127.0.0.1:4001> \n```\nWhat are you expecting to see? What version of OS are you running?. Just to be clear, unless you make some tables, there are no schema.. Looks like something on your end. I would need to know more about your terminal settings, because all works fine for me.. Thanks for your feedback @jack-y. What you are seeing is by design, so that clients have full control.\n\nBut the HTTP API does not have the same behavior:\n\nThis is how the CLI redirects. it uses the response from the HTTP API indicating where the leader is.  This is the same way browsers follow redirects.\nIt is up to clients to follow the redirects.  For example, here is the Python client following redirects:\nhttps://github.com/rqlite/pyrqlite/blob/master/src/pyrqlite/connections.py#L64\nIt would be possible to do as you say, and make it more transparent to clients, but I have chosen not to have rqlite do so at this time. \n. I am closing this for now, since this is by design.. https://github.com/rqlite/rqlite/issues/330 tracking this change request.. Unless @jack-y you mean the q part of the query is not included in the Location header? This may or may not be the right thing to do (not sure) but clients can easily handle the current response. since it contains sufficient information.. A note about the current design has been added here: https://github.com/rqlite/rqlite/blob/master/doc/DATA_API.md#sending-requests-to-followers\nIt should be noted that adding this feature introduces a lot of possible error cases, that need to be handled with timeouts. Not ruling it out, but it must be considered carefully before allowing it. At the very least, it must able to be disabled by the client if it chooses.. OK, presumably this is issue should be closed.. For general questions like this, you can now use the Google Group:\nhttps://groups.google.com/forum/#!forum/rqlite\nAs for your general question, it stores data right where you requested in /root/data/rqlite. rqlite uses an in-memory database by default:\nhttps://github.com/rqlite/rqlite/blob/master/README.md#in-memory-databases\nUntil you restart the rqlited process you won't see any changes due to deleted files.\n. Thanks @justinmorant -- real issue, but easy to fix. The main fix is in the PR above. \nWhat do you suggest as a Content-type for the backup response? I believe application/octet-stream is most sensible: https://www.iana.org/assignments/media-types/application/octet-stream. OK, octet-stream looks like the most meaningful MIME type. I'll merge @justinmorant if this works for you.. Decided to merge since the header type makes most sense to me. Easy to change if necessary.. Fixed in 4.0.1.. @zmedico @justinmorant @jack-y -- I think I should just merge this change. Every client library I've seen would be compatible with this since those libraries are either a) parsing the host and port from the Location header, or just assuming the Location header is of the form this PR would make it.\nIn other words this might be a breaking change in principle, but not in practise. And it is bug that should be fixed.. OK, I'm going to merge this and release a new build, for the reasons outlined above.. No plans to implement this.. It's something specific with your terminal. In any event, the UP button doesn't recall commands.. @julisch94 -- you have included zero details on the build error, and your build process. I don't know how you expect people to help if you don't include more information.\n. Unfortunately I have zero experience with Raspberry Pi, so I'm unlikely to be able to help. Once you provide more technical details, it might make sense to send a message to more general group, like the Go google group.. Actually there was a typo in the build directions -- thanks for pointing that out. I have fixed it here: https://github.com/rqlite/rqlite/commit/bb89117c7c4242446cfcc11f34fdf3b69f61b154\nDoes that help?. Those are build errors specific to the SQLite library. I suggest you open a ticket on https://github.com/mattn/go-sqlite3 and reference this ticket. I didn't write that software.. You might learn something from here: https://github.com/mattn/go-sqlite3/issues/242. Great, thanks for following up @julisch94 . OK, thanks for the update @wil222 . Thanks for your report. It's kinda difficult to know what is going on with the information you've provided. Is this 3rd node part of a cluster with the other two? Show me how each node is started.. Please do this for me -- let the node fully start up, and then show me the output of:\ncurl localhost:4001/status?pretty\nand:\ncurl localhost:4001/debug/vars. Any update here @lkxjtu ?.  No updates -- closing.. A second node, which joins a cluster through the disco service, does not suffer from this issue.. It should be noted that it's ok that the node does this, since the disco service is idempotent. This is about avoiding network calls unless necessary.. To answer your question, I need to know what you are trying to do.. I clarified some documentation around this, which may be relevant: https://github.com/rqlite/rqlite/blob/master/doc/DATA_API.md. OK.\nJust remember @wangke1970 -- by reading directly from a follower, you risk getting stale data back: https://github.com/rqlite/rqlite/blob/master/doc/CONSISTENCY.md\nrqlite is not about improving read and write performance. It's about reliability.. Not started.. More detail.\nThe format of the messages that would travel over gRPC has not yet been defined, though the requirements are clear -- those messages must have all the same control that the HTTP API has. Once defined, it's a matter of writing the protobuf files, generating the Go code, and integrating that with the existing rqlite source. This will require a new service within the rqlite system, and command line options to control its TCP port.. @meox -- why is it useful to you?. Well I am benchmarking in #365 and I am not seeing any real performance improvement with gRPC over HTTP, assuming a persistent HTTP connection. There may be bottlenecks elsewhere in rqlite that I need to improve.\nAnyway, you'll never get anywhere near 150k records/sec into rqlite, using single requests. I can get a ~250/sec on a 3-node cluster with good EC2 instances. If you want 150k, you'll need to use some other database system, or put 100s of requests into a single transaction to rqlite. Even then it may not perform at the rate you want.. I've worked with ZMQ before, but I don't believe it's going to make a difference relative to gRPC. Both are over a persistent TCP connection, and gRPC is designed to be a high-performance serialization protocol.\nWhen I run load tests I see the disks really busy. I do not believe performance is currently network-bound, but is instead IO bound. . rqlite uses the same consensus module as Consul. That system is also IO-bound, not network-bound:\nhttps://www.consul.io/docs/guides/performance.html. Linked is a profiling graph, as a result of 20,000 INSERTs into a single node, over HTTP. Unzip and load it into Chrome, or some other SVG viewer.\npprof002.svg.gz\n. Thanks for the report @varunudacity -- you are right, this is not working. Even passing -L to the command won't fix this, since the node to delete is listed in the body of the command, and the body is not included when curl redirects the request. Without a proper body, the Discovery service responds with 400.\nI need to think about this. In the meantime, if you need to delete a node you can go straight to the AWS Lambda gateway as follows:\ncurl -XDELETE -v 'https://k05nh959gb.execute-api.us-west-2.amazonaws.com \\\n/prod/rqliteDiscoHandler/<disco_id>' -H \"Content-Type: application/json\" \\\n-d '{\"addr\": \"localhost:4001\"}. >if I reconfigure the raft cluster, via the client, will that automatically update the discovery service?\nI don't really follow what you have in mind. Can you provide me with a concrete example?. @varunudacity -- please review the cluster management documentation, as I believe it will answer your question:\nhttps://github.com/rqlite/rqlite/blob/master/doc/CLUSTER_MGMT.md. So add your 3 bigger nodes, and once those are added, remove the smaller nodes one-by-one.. As for the original issue, the Disco Service API is a bit awkward to use by curl. I think it deserves a dedicated binary, for interacting with it. It would be quite easy to do.. @varunudacity -- I think you are right, and that the Discovery Service should return 307 or 308. If it did then curl would just work. However I am reluctant to do that just yet, as it would break older versions of rqlite. I'll may make it in the future though.\nIn the meantime I have updated the docs to deal with this. It turns out curl supports an option to tell it not to change the method, and to resend the body. With this in place the docs are now useful again.\nSee change: https://github.com/rqlite/rqlite/commit/506f6b73b7041d7e8d1bab2b59f800543def94a2\nThanks again for catching this.. New tool for https://github.com/rqlite/rqlite/issues/351. Would you mind sending this question to the Google Groups mailing list? https://groups.google.com/forum/#!forum/rqlite\nI'll be sure to answer there, and others can benefit from the response.. Answered at https://groups.google.com/d/msg/rqlite/6Fv9v2gcCSo/dqt7jyX6AwAJ. Partial fix for https://github.com/rqlite/rqlite/issues/87\nRequired due to the release of 1.0 Raft.. Fixed by https://github.com/rqlite/rqlite/pull/377.. A table dedicated to this would include, perhaps, an inode-like number, permissions, and a single column of binary values. Data could potentially be compressed. . This effort would probably benefit from a gRPC interface, as per https://github.com/rqlite/rqlite/issues/350. Please send a question like this to the rqlite Google group at https://groups.google.com/forum/#!forum/rqlite\nI will be sure to answer it there.. https://groups.google.com/d/msg/rqlite/XqoUhScLzhQ/Smy71qKjBgAJ. Thanks @turbo -- very helpful.. @turbo -- I tweaked the appveyor config slightly, so it used more suitable names. However I am not able to download from the URL:\nhttps://ci.appveyor.com/api/projects/rqlite/rqlite/artifacts/rqlite-latest-win64.zip?branch=master\nIt returns 404. Does one need to be logged in to appveyor for this to work?. Ah, yes -- good stuff. I'll include a reference to this link in the docs.\nThanks again.. Do you mean expose a TCP interface as opposed to HTTP (which, of course, runs on top of a once-off TCP connection)? If so, I agree and it will be done here: https://github.com/rqlite/rqlite/issues/350. Please re-open if I misunderstand your issue.. @turbo -- I am definitely interested in adding options that makes it easier to manage clusters. I had not heard of zeroconf before. Is it widely used? It doesn't seem too difficult to add this functionality to rqlite.. OK, let me look into it. I'll need to do some study, but a dedicated option seems best.\nCan I ask what you are using rqlite for? I am always keen to learn about its applications.. I can probably add the new gRPC functionality relatively easily, since it's an area I understand pretty well. However it would require that you use purpose-built libraries to access the node. It's easy to generate client libraries in various languages though.\nHow do you communicate with an rqlite node? Have you written your own code?. @turbo -- I am benchmarking the performance of this new interface, and the HTTP API is just as fast. I still plan to proceed with this work, and there are other optimizations that gRPC will bring, but I wonder if it's that significant relevant to the network round trips between the nodes.\nOne thing is important to get good performance out of the HTTP API. You should use persistent HTTP connections. Are you doing so?. Perhaps, but it's not high-priority. Subsequent testing showed that the performance bottleneck is in the Raft subsystem, not the HTTP interface, and trying to improve performance was an important goal of this work.\nI think the only way I'll get significantly better performance is via a different Raft implementation -- most likely the one from CoreOS (which is used by etc).. Closing for now.. It hasn't started. It's an easy issue, which I plan to leave to the community.. https://github.com/rqlite/rqlite/issues/375. This is still work-in-progress. https://github.com/otoolep/hraftd/pull/15 is my guide.. Replacing https://github.com/rqlite/rqlite/pull/376. Thanks for the report @rapoth -- the performance you see is similar to what I see. I do agree that 300ms looks rather long, but my testing shows it's the Raft use of the disks.\nIn my testing the bottlenecks are the disk, as the Raft system continually updates its log and fsyncs to disk after each change. You are also running in \"on disk\" mode which is causing more disk load. Unless you need that, you should use an in-memory SQLite database. Your data is still safe.\nAre you watching the CPU and disk load on your machine during your testing? You may see the disks being the bottleneck too. In that case I suggest you run a real 3-node cluster, because what you are doing during testing is causing 3x fsync traffic onto the single disk of the host machine. So for a more realistic performance test of a 3-node cluster I suggest you do the following:\n\ndo not enable \"on-disk\" mode.\nrun your 3 nodes across 3 different machines.\nrun the benchmarking tool from a 4th machine.\nhave the best network you can (low latency).\n\nThen see what kind of performance you get.. OK, definitely interesting data -- thank you. I agree those numbers look kinda low, but I haven't studied the throughput issue in great detail. There may be room for improvement. Since I see my multicore SSD 16GB RAM machine peg on IO, I left it at that. Perhaps there are other bottlenecks.\nAre you familiar with profiling Go programs? I also suggest you re-run all testing passing -cpu-profile to each node, running the benchmark, and then shutting the nodes down. There are details at https://blog.golang.org/profiling-go-programs that tell you what to do next. You could gather data and post it here.\nBasically you'll do something like this:\n.\\rqlited.exe -cpu-profile cpu.prof ~/node.1\nTerminate at the end of the test, and then execute:\ngo tool pprof rqlited cpu.prof\nand run some of the commands in the blog post. I would be particularly interested in a profiling graph. I have not run these commands on Windows however, only Linux, but they should work.. Another interesting tool that might help diagnose performance issues: https://making.pusher.com/go-tool-trace/. Related ideas in https://github.com/rqlite/rqlite/issues/469. A complaint about rqlite performance (which is due to BoltDB): https://medium.com/@ivanjaros/event-store-with-boltdb-is-a-no-go-664b4781250d\nThe suggested alternatives for storage may be valid, and worth checking out.. It might be time to try the Raft implementation from etcd: https://github.com/coreos/etcd/tree/master/raft\nPerhaps its performance is better -- particularly its IO load.. Thanks for your report. I just tried loading the dump file you supplied and cannot reproduce any problem. I am building top-of-tree on Ubuntu 16.10.\n~ $ curl -G 'localhost:4001/db/query?pretty&timings' --data-urlencode 'q=SELECT * FROM foo'\n{\n    \"results\": [\n        {\n            \"error\": \"no such table: foo\"\n        }\n    ],\n    \"time\": 0.000195412\n}\n~ $ cat b.dump \nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE foo (id INTEGER NOT NULL PRIMARY KEY, name TEXT);\nINSERT INTO \"foo\" VALUES(1,'fiona');\nINSERT INTO \"foo\" VALUES(2,'fiona2222');\nINSERT INTO \"foo\" VALUES(4,'cztest');\nINSERT INTO \"foo\" VALUES(5,'cztest7');\nCOMMIT;\n~ $ curl -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @b.dump\n{\"results\":[{\"last_insert_id\":5,\"rows_affected\":1}]}~ $ \n~ $ curl -G 'localhost:4001/db/query?pretty&timings' --data-urlencode 'q=SELECT * FROM foo'\n{\n    \"results\": [\n        {\n            \"columns\": [\n                \"id\",\n                \"name\"\n            ],\n            \"types\": [\n                \"integer\",\n                \"text\"\n            ],\n            \"values\": [\n                [\n                    1,\n                    \"fiona\"\n                ],\n                [\n                    2,\n                    \"fiona2222\"\n                ],\n                [\n                    4,\n                    \"cztest\"\n                ],\n                [\n                    5,\n                    \"cztest7\"\n                ]\n            ],\n            \"time\": 0.000106901\n        }\n    ],\n    \"time\": 0.000134945\n}\nThe SQLite details of rqlite are as follows:\nsqlite3:\n    dns: \n    fk_constraints: disabled\n    path: :memory:\n    version: 3.21.0\nAre you sure you're not generating any other queries to the system during the restore? Does it fail with a single node?\nDid you first delete all data in the system before restoring? You must do this to be sure it works, as per https://github.com/rqlite/rqlite/blob/master/DOC/RESTORE_FROM_SQLITE.md#caveats. To delete all data, shutdown the cluster and delete the data directory each node uses. Then restart the cluster.. Thank you @arstercz -- that is odd. I will look into why that is, it may be a bug in rqlite.. OK, I agree with your analysis -- the dump file starts a transaction, but doesn't roll it back in the event of an error. I would say, strictly speaking, that you're not clearing out the system fully before restoring though, so you're getting the \"undefined\" behavior I did warn about.\nBut I do think I can make the system more robust.. By more robust, I mean have it fully cleanup the transaction if the the restore operation fails, but ultimately it's best to remove all data under the system before doing a restore.. Closing in favour of https://github.com/rqlite/rqlite/issues/385. The underlying SQLite code would need to be recompiled to support Spatialite. It's beyond the scope of rqlite, and is something you should actually discuss on https://github.com/mattn/go-sqlite3. If it can be made to support it, then rqlite could do something.. To be honest, there are other higher-priority issues I need to deal with first. It's highly unlikely I'll add this to rqlite.. Please show me the full setup you and running, including how you launch each node and how you insert via a follower. I need much more information than this, to help you. I also need to know which version you are running, and the OS. You can get this information here: \nhttps://github.com/rqlite/rqlite/blob/master/DOC/DIAGNOSTICS.md\nPlease read this doc: https://github.com/rqlite/rqlite/blob/master/DOC/DATA_API.md#sending-requests-to-followers. OK, thanks for the diagnostics. I am going to need much more info though, particularly showing me how the system is failing.. Please show me how you start each node, and how you send the post request.\nI need details, just telling me what you do is not enough. I need to see the command you execute to start each node, and I need to see exactly what you mean by \"send a post request for a write to a follower\".. OK, thanks.\nI built top-of-tree and started 3 nodes on my Linux box. Unfortunately I do not have access to a Windows box, but I know of no reason it shouldn't work exactly the same there.\nIt all works fine for me, I cannot reproduce any issues.\nNode 1:\n```\n$ rqlited -http-addr localhost:4101 -raft-addr localhost:4102 d                                                                                            \n        _ _ _                                                                                               \n       | (_) |\n\n_   | || | \n | '_/ _  | | | / _ \\   The lightweight, distributed\n | | | (| | | | ||  /   relational database.\n ||  _, |||___|\n         | |\n         |_|\n[rqlited] 2018/01/08 21:52:18 rqlited starting, version 4, commit unknown, branch unknown\n[rqlited] 2018/01/08 21:52:18 go1.9.1, target architecture is amd64, operating system target is linux\n[mux] 2018/01/08 21:52:18 mux serving on 127.0.0.1:4102, advertising 127.0.0.1:4102\n[store] 2018/01/08 21:52:18 SQLite in-memory database opened\n[store] 2018/01/08 21:52:18 enabling single-node mode\n[store] 2018/01/08 21:52:18 waiting for up to 2m0s for application of initial logs\n2018/01/08 21:52:18 [INFO] raft: Node at 127.0.0.1:4102 [Follower] entering Follower state (Leader: \"\")\n[cluster] 2018/01/08 21:52:18 service listening on 127.0.0.1:4102\n[rqlited] 2018/01/08 21:52:18 no join addresses set\n[rqlited] 2018/01/08 21:52:19 failed to set peer for 127.0.0.1:4102 to localhost:4101: no leader available (retrying)\n2018/01/08 21:52:20 [WARN] raft: Heartbeat timeout from \"\" reached, starting election\n2018/01/08 21:52:20 [INFO] raft: Node at 127.0.0.1:4102 [Candidate] entering Candidate state\n2018/01/08 21:52:20 [DEBUG] raft: Votes needed: 1\n2018/01/08 21:52:20 [DEBUG] raft: Vote granted from 127.0.0.1:4102. Tally: 1\n2018/01/08 21:52:20 [INFO] raft: Election won. Tally: 1\n2018/01/08 21:52:20 [INFO] raft: Node at 127.0.0.1:4102 [Leader] entering Leader state\n2018/01/08 21:52:20 [DEBUG] raft: Node 127.0.0.1:4102 updated peer set (2): [127.0.0.1:4102]\n[rqlited] 2018/01/08 21:52:20 set peer for 127.0.0.1:4102 to localhost:4101\n[http] 2018/01/08 21:52:20 service listening on localhost:4101\n[store] 2018/01/08 21:52:29 received request to join node at 127.0.0.1:4104\n2018/01/08 21:52:29 [DEBUG] raft: Node 127.0.0.1:4102 updated peer set (2): [127.0.0.1:4104 127.0.0.1:4102]\n2018/01/08 21:52:29 [INFO] raft: Added peer 127.0.0.1:4104, starting replication\n2018/01/08 21:52:29 [WARN] raft: AppendEntries to 127.0.0.1:4104 rejected, sending older logs (next: 1)\n2018/01/08 21:52:29 [INFO] raft: pipelining replication to peer 127.0.0.1:4104\n2018/01/08 21:52:29 [DEBUG] raft: Node 127.0.0.1:4102 updated peer set (2): [127.0.0.1:4104 127.0.0.1:4102]\n[store] 2018/01/08 21:52:29 node at 127.0.0.1:4104 joined successfully\n[cluster] 2018/01/08 21:52:30 received connection from 127.0.0.1:50654\n[store] 2018/01/08 21:52:43 received request to join node at 127.0.0.1:4106\n2018/01/08 21:52:43 [DEBUG] raft: Node 127.0.0.1:4102 updated peer set (2): [127.0.0.1:4106 127.0.0.1:4102 127.0.0.1:4104]\n2018/01/08 21:52:43 [INFO] raft: Added peer 127.0.0.1:4106, starting replication\n2018/01/08 21:52:43 [WARN] raft: AppendEntries to 127.0.0.1:4106 rejected, sending older logs (next: 1)\n2018/01/08 21:52:43 [INFO] raft: pipelining replication to peer 127.0.0.1:4106\n2018/01/08 21:52:43 [DEBUG] raft: Node 127.0.0.1:4102 updated peer set (2): [127.0.0.1:4106 127.0.0.1:4102 127.0.0.1:4104]\n[store] 2018/01/08 21:52:43 node at 127.0.0.1:4106 joined successfully\n[cluster] 2018/01/08 21:52:44 received connection from 127.0.0.1:50662\n```\nNode 2:\n```\n$ rqlited -http-addr localhost:4103 -raft-addr localhost:4104 -join http://localhost:4101 e\n        _ _ _\n       | (_) |\n\n_   | || | \n | '_/ _  | | | / _ \\   The lightweight, distributed\n | | | (| | | | ||  /   relational database.\n ||  _, |||___|\n         | |\n         |_|\n[rqlited] 2018/01/08 21:52:29 rqlited starting, version 4, commit unknown, branch unknown\n[rqlited] 2018/01/08 21:52:29 go1.9.1, target architecture is amd64, operating system target is linux\n[mux] 2018/01/08 21:52:29 mux serving on 127.0.0.1:4104, advertising 127.0.0.1:4104\n[store] 2018/01/08 21:52:29 SQLite in-memory database opened\n[store] 2018/01/08 21:52:29 waiting for up to 2m0s for application of initial logs\n2018/01/08 21:52:29 [INFO] raft: Node at 127.0.0.1:4104 [Follower] entering Follower state (Leader: \"\")\n[cluster] 2018/01/08 21:52:29 service listening on 127.0.0.1:4104\n[rqlited] 2018/01/08 21:52:29 join addresses are: [http://localhost:4101]\n2018/01/08 21:52:29 [DEBUG] raft-net: 127.0.0.1:4104 accepted connection from: 127.0.0.1:49370\n2018/01/08 21:52:29 [WARN] raft: Failed to get previous log: 2 log not found (last: 0)\n2018/01/08 21:52:29 [DEBUG] raft: Node 127.0.0.1:4104 updated peer set (2): [127.0.0.1:4102]\n[rqlited] 2018/01/08 21:52:29 successfully joined cluster at http://localhost:4101/join\n2018/01/08 21:52:29 [DEBUG] raft: Node 127.0.0.1:4104 updated peer set (2): [127.0.0.1:4104 127.0.0.1:4102]\n2018/01/08 21:52:29 [DEBUG] raft-net: 127.0.0.1:4104 accepted connection from: 127.0.0.1:49372\n[rqlited] 2018/01/08 21:52:30 set peer for 127.0.0.1:4104 to localhost:4103\n[http] 2018/01/08 21:52:30 service listening on localhost:4103\n2018/01/08 21:52:43 [DEBUG] raft: Node 127.0.0.1:4104 updated peer set (2): [127.0.0.1:4106 127.0.0.1:4102 127.0.0.1:4104]\n```\nNode 3:\n```\n$ rqlited -http-addr localhost:4105 -raft-addr localhost:4106 -join http://localhost:4101 f\n        _ _ _\n       | (_) |\n\n_   | || | \n | '_/ _  | | | / _ \\   The lightweight, distributed\n | | | (| | | | ||  /   relational database.\n ||  _, |||___|\n         | |\n         |_|\n[rqlited] 2018/01/08 21:52:43 rqlited starting, version 4, commit unknown, branch unknown\n[rqlited] 2018/01/08 21:52:43 go1.9.1, target architecture is amd64, operating system target is linux\n[mux] 2018/01/08 21:52:43 mux serving on 127.0.0.1:4106, advertising 127.0.0.1:4106\n[store] 2018/01/08 21:52:43 SQLite in-memory database opened\n[store] 2018/01/08 21:52:43 waiting for up to 2m0s for application of initial logs\n2018/01/08 21:52:43 [INFO] raft: Node at 127.0.0.1:4106 [Follower] entering Follower state (Leader: \"\")\n[cluster] 2018/01/08 21:52:43 service listening on 127.0.0.1:4106\n[rqlited] 2018/01/08 21:52:43 join addresses are: [http://localhost:4101]\n2018/01/08 21:52:43 [DEBUG] raft-net: 127.0.0.1:4106 accepted connection from: 127.0.0.1:46844\n2018/01/08 21:52:43 [WARN] raft: Failed to get previous log: 4 log not found (last: 0)\n2018/01/08 21:52:43 [DEBUG] raft: Node 127.0.0.1:4106 updated peer set (2): [127.0.0.1:4102]\n2018/01/08 21:52:43 [DEBUG] raft: Node 127.0.0.1:4106 updated peer set (2): [127.0.0.1:4104 127.0.0.1:4102]\n[rqlited] 2018/01/08 21:52:43 successfully joined cluster at http://localhost:4101/join\n2018/01/08 21:52:43 [DEBUG] raft: Node 127.0.0.1:4106 updated peer set (2): [127.0.0.1:4106 127.0.0.1:4102 127.0.0.1:4104]\n2018/01/08 21:52:43 [DEBUG] raft-net: 127.0.0.1:4106 accepted connection from: 127.0.0.1:46846\n[rqlited] 2018/01/08 21:52:44 set peer for 127.0.0.1:4106 to localhost:4105\n[http] 2018/01/08 21:52:44 service listening on localhost:4105\n```\nI then send a request to the follower and get 301 back:\n```\n$ curl -v -XPOST 'localhost:4103/db/execute?pretty&timings' -H \"Content-Type: application/json\" -d '[\n    \"CREATE TABLE foo (id integer not null primary key, name text)\"\n]'\nNote: Unnecessary use of -X or --request, POST is already inferred.\n   Trying 127.0.0.1...\n Connected to localhost (127.0.0.1) port 4103 (#0)\n\nPOST /db/execute?pretty&timings HTTP/1.1\nHost: localhost:4103\nUser-Agent: curl/7.50.1\nAccept: /\nContent-Type: application/json\nContent-Length: 71\n\nupload completely sent off: 71 out of 71 bytes\n< HTTP/1.1 301 Moved Permanently\n< Content-Type: application/json; charset=utf-8\n< Location: http://localhost:4101/db/execute?pretty&timings\n< X-Rqlite-Version: 4\n< Date: Tue, 09 Jan 2018 05:53:52 GMT\n< Content-Length: 0\n< \nConnection #0 to host localhost left intact\n```\n\n\n. I suggest two things:\n\ncheck that Postman is doing what you think it's doing. The only place in the code that returns 405 for that endpoint is here: https://github.com/rqlite/rqlite/blob/master/http/service.go#L540. This implies you think you're sending a POST request, but you're actually not. I would guess you're actually sending GET.\ntry using curl, not Postman.. The Go client allows me to handle the 405 as I need (\"CheckRedirect\" in the Go HTTP client). You probably need to change your handler configuration somehow, or do some work yourself that the C# library is currently doing for you.. How I handle this in Go:\n\nhttps://github.com/rqlite/rqlite/blob/master/cmd/rqlite/main.go#L124. Thanks for the report.\nI'm not sure I see what the problem is in the short term. I have complete, quite simple, build instructions in CONTRIBUTING.md which works well. I chose only to vendor the Raft module since it changed recently.\nrqlite is easily built simply using go build -- you don't need to use any dependency tools. I don't have 100% repeatable builds yet, but have decided to focus on other issues for now.. Specifically here:\nhttps://github.com/rqlite/rqlite/blob/master/CONTRIBUTING.md#building-rqlite\nThis is how one builds rqlite at present. I make no promises about this project working with dependency management tools right now.. You don't get HTTP 301 redirect? How are you sending the request? . Thanks for your report. This issue has been fixed on master, so that the node will return HTTP 301 if the node is not the leader. It's up to your client code to read the location header and re-issue the request. . https://github.com/rqlite/rqlite/releases/tag/v4.2.3 contains the fix. Only the Linux build is available now, but I will post the OSX version soon.. This is how it's done by the standard Python sqlite3 module: https://github.com/ghaering/pysqlite/blob/master/lib/dump.py. Will be addressed by https://github.com/rqlite/rqlite/pull/451. https://github.com/rqlite/rqlite/pull/453 also part of this work.. Thanks for the question.\nThis is not possible without a (possibly very) large amount of work, since rqlite is built using Go and C. You'd also need the Raft layer available in Javascript too. It may not even be practical, since browser environments come and go, and distributed consensus doesn't really work in that sense.. Go for it @sum12  -- patches are welcome.. I'm not sure I follow you. Can you provide a concrete example of what the password would be, and what would be in the header, that wouldn't work?. You're right. :-( I lost access to the Mac I had and didn't get a chance to build it yet. Hope to do so within days. In the meantime you can find the build instructions here:\nhttps://github.com/rqlite/rqlite/blob/master/CONTRIBUTING.md#building-rqlite\n4.2.2 is very similar to 4.2.3, and I did upload 4.2.2 for OSX.. I have actually released a new version, v4.3.0, and it is available for OSX.. Thanks for your PR. The functionality looks useful. However I think it's more complicated than it needs to be. There are two ways I think it could be simpler.\n1) Instead of passing bcrypt-pass to rqlited when it starts up, just try the existing logic. If that doesn't work, then try the bcrypt hash check. Only if both fail is the access blocked.\n2) Add a new field to the Passwords file, named, say, password_bcrypt. If this field exists check that, otherwise do the existing check. This change would be backwards compatible with existing files. Again you wouldn't need to pass bcrypt-pass to the binary.\nThis minimize the changes and means the way rqlited is launched is not changed.. Thanks @sum12, implementation generally looks good to me. -- I will merge this, and make a couple of changes on top of it.. Thanks @sum12 . This dependency is due to the underlying use of https://github.com/mattn/go-sqlite3, which in turn uses cgo. Go does not, by default, statically link libc when cgo is used.\nI'm not sure I'm going to do anything about this.. Trivial program built on top of C code, and showing that the default output does not include a statically-linked libc. This is on Linux.\nhttps://play.golang.org/p/5RmU6qLvsbN\n$ go build main.go \n$ ./main \n42\n1804289383\n$ ldd main\n    linux-vdso.so.1 (0x00007fff009f2000)\n    libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007ff99d438000)\n    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007ff99d099000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007ff99d655000)\n$. Don't you have access to a box other than those behind your firewall? What you suggest may work, but unfortunately it's not something I going to look into anytime soon. . I'm not planning any work here.. Thanks for your question.\nThere is no support for setting that value directly and what you want is not compatible with the underlying Raft consensus mechanism. It will never work with rqlite, so I am closing this issue.. Short answer is yes, it should be, assuming you use STRONG read consistency. See https://github.com/rqlite/rqlite/issues/94. Thanks for your contribution @joaodrp -- happy to merge it once you make the change I requested.. Thank you @joaodrp . Just to be clear, this is not a regression. rqlite prior to the port to Hashicorp Raft v1 didn't support changing IP addresses. It should now however.. The solution to this issue is shown in this PR: https://github.com/otoolep/hraftd/pull/23\nThis change needs to be ported to rqlite.. Not fully functional yet.. All done.. Actually, this is a bad idea. It's too easy to restart a node and get a different ID, thereby messing up the cluster. Not going to do this.. Fixes https://github.com/rqlite/rqlite/issues/409. Further changes required to address https://github.com/rqlite/rqlite/issues/409. Looks good, I'll wait for your final changes and then merge.. Great, thanks.. This change appears to have introduced a bug into the execute path. The CLI always shows number of rows affected as 0. When I roll back the change, it shows non-zero rows affected when an INSERT is performed.. Found it, easy fix. https://github.com/rqlite/rqlite/pull/416. Done in https://github.com/rqlite/rqlite/pull/424. #424 may not merge now, re-opening.. Explicit inter-node comms are not necessary for peer API mappings, and make better use of the Raft consensus system itself. This change is being made in https://github.com/rqlite/rqlite/pull/424. On further examination it may actually be necessary, otherwise a new HTTP API endpoint would be needed to set peer mapping data. This would expose internals of the Store, which really should remain private.. Necessary for now.. Turns out it doesn't look necessary after all, see https://github.com/rqlite/rqlite/pull/434.. Not necessary as of https://github.com/rqlite/rqlite/pull/434.. I looked into this, and the systems does as much as possible. Some improvements will arrive in https://github.com/rqlite/rqlite/pull/457. Not going to work.. This can be done by binding the Raft system to 0.0.0.0 and setting the advertise address.. Thank you @eariassoto . Do you mean a Maven project for the Java client at https://github.com/rqlite/rqlite-java?. If you mean rqlite itself, I don't really follow what you want. A Maven project to pull down a release of the database and spin it up? In either case, I have little experience with Maven and would need someone else to work on this.\nFWIW, the unit testing I put together for the Java client pulls down a Docker container running rqlite.. OK, thanks for the clarification. You have two options instead of Maven.\n- Download and run the published docker container.\n- Download the prebuilt binary for your OS from GitHub (see https://github.com/rqlite/rqlite/releases). You don't need to compile anything.\nUnfortunately I don't see myself doing any Maven work -- it's not something I'm that familiar with, and I instead want to concentrate on the core database and client libraries. Help doing the Maven work is always welcome however.. I believe I've answered this question. It might be more fruitful for any further discussion to take place on the rqlite Google Group.. Thanks @eariassoto -- can you paste a session here of the new command in action?. Thanks @eariassoto . You can learn about FK control here: https://github.com/rqlite/rqlite/blob/master/DOC/FOREIGN_KEY_CONSTRAINTS.md. The output you suggest is fine, proceed. I might tighten it up later.\nAs for the transaction error you report, I don't understand how that is happening. You must be starting a transaction before loading the file. The rqlite doesn't do it itself. Can you check your work? Push up a PR with what you have, and I'll take a look?. I see don't anything wrong with your code, but the system is not doing anything with transactions during loading: https://github.com/rqlite/rqlite/blob/master/http/service.go#L417\nIf you run through the example here:\nhttps://github.com/rqlite/rqlite/blob/master/DOC/RESTORE_FROM_SQLITE.md\nand check the file you'll see it has BEGIN in there, but it loads fine.\n```\n~ $ sqlite3 restore.sqlite\nSQLite version 3.14.1 2016-08-11 18:53:32\nEnter \".help\" for usage hints.\nsqlite> CREATE TABLE foo (id integer not null primary key, name text);\nsqlite> INSERT INTO \"foo\" VALUES(1,'fiona');\nsqlite> \n~ $ echo '.dump' | sqlite3 restore.sqlite > restore.dump # Convery SQLite database file to set of SQL commands.\n~ $ cat restore.dump \nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE foo (id integer not null primary key, name text);\nINSERT INTO \"foo\" VALUES(1,'fiona');\nCOMMIT;\n~ $ curl -v -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @restore.dump\nNote: Unnecessary use of -X or --request, POST is already inferred.\n   Trying 127.0.0.1...\n Connected to localhost (127.0.0.1) port 4001 (#0)\n\nPOST /db/load HTTP/1.1\nHost: localhost:4001\nUser-Agent: curl/7.50.1\nAccept: /\nContent-type: text/plain\nContent-Length: 152\n\nupload completely sent off: 152 out of 152 bytes\n< HTTP/1.1 200 OK\n< X-Rqlite-Version: 5\n< Date: Tue, 24 Apr 2018 11:40:54 GMT\n< Content-Length: 52\n< Content-Type: text/plain; charset=utf-8\n< \nConnection #0 to host localhost left intact\n{\"results\":[{\"last_insert_id\":1,\"rows_affected\":1}]}\n~ $ curl -G 'localhost:4001/db/query?pretty&timings' --data-urlencode 'q=SELECT * FROM foo'\n{\n    \"results\": [\n        {\n            \"columns\": [                                                                                                                                                                    \n                \"id\",                                                                                                                                                                       \n                \"name\"                                                                                                                                                                      \n            ],                                                                                                                                                                              \n            \"types\": [                                                                                                                                                                      \n                \"integer\",                                                                                                                                                                  \n                \"text\"                                                                                                                                                                      \n            ],                                                                                                                                                                              \n            \"values\": [                                                                                                                                                                     \n                [                                                                                                                                                                           \n                    1,                                                                                                                                                                      \n                    \"fiona\"                                                                                                                                                                 \n                ]                                                                                                                                                                           \n            ],                                                                                                                                                                              \n            \"time\": 0.000121884                                                                                                                                                             \n        }                                                                                                                                                                                   \n    ],\n    \"time\": 0.000158319\n}\n```\nI also committed an end-to-end test that checks that restoring a file works fine: https://github.com/rqlite/rqlite/blob/master/system_test/full_system_test.py#L322\n\n\nYou say you are getting an error, but none of my testing reproduces it. Can you show me the error in action? Write a unit test that shows it happening?. I ran your code. It works for with me, and there are none of the errors you mention. There may be some difference between your environment and mine, which we need to understand before we merge the code.\n127.0.0.1:4001> .help\n.help                           Show this message\n.indexes                        Show names of all indexes\n.schema                         Show CREATE statements for all tables\n.status                         Show status and diagnostic information for connected node\n.expvar                         Show expvar (Go runtime) information for connected node\n.tables                         List names of tables\n.timer on|off                   Turn SQL timer on or off\n.backup <file>                  Create a backup file for the database\n.restore <file>                 Restore the database from a SQLite dump file\n127.0.0.1:4001> .restore /home/philip/restore.dump\nlast inserted Id: 1\nrows affected: 1\ndatabase restored successfully\n127.0.0.1:4001> select * from foo;\n+----+-------+\n| id | name  |\n+----+-------+\n| 1  | fiona |\n+----+-------+\n127.0.0.1:4001>. Ah yes, this is a known issue: https://github.com/rqlite/rqlite/issues/385\nI wasn't sure how much of an issue it would be in practice, but you hit it. I'll fix it up.. See https://github.com/rqlite/rqlite/pull/448. The issue you hit has been fixed, please feel free to confirm by running your test again against master.. Addressed by https://github.com/rqlite/rqlite/pull/450. Your PR doesn't look right, it should only show your changes. Can you rebase on top of master? git pull --rebase origin master, followed by a force push up to your branch)? Or just open a new PR, and copy your changes over.. Looks great -- thank you @eariassoto. I left some minor feedback regarding style.. Actually, git pull --rebase origin master will only work properly if your master if fully up-to-date with the upstream master. Since you can lose changes if you force push incorrectly, you may just wish to create a new PR.. Thank you for your contribution.. This is by design.. Yes, thanks @sum12 -- this looks like a good idea. I am definitely interested in this change.. Change looks great @sum12 -- let me know if it's ready to merge.. Thanks for your contribution @sum12 . Elasticsearch, when started, tries a range of ports. This does make it easier to launch multiple nodes on a single box.. I actually don't see any applications for this on a mobile platform, so am not planning any mobile work, but perhaps I am missing something. What do you have any mind?. Also more general discussions like this are better sent to the Google Group at https://groups.google.com/forum/#!forum/rqlite. If I can get around to implementing https://github.com/rqlite/rqlite/issues/470 it might help with this requirement. I am still dubious rqlite is a good match for mobile applications, but interested people can always try. :-). Performance testing should be carried out with the InMem store, just to see how much disk IO is the bottleneck. The MDB store could also be tested: https://github.com/hashicorp/raft-mdb. Consul also wraps its BoltDB-based store in a cache, rqlite should also try that.\nhttps://github.com/hashicorp/consul/blob/3c96d64eaa7e1650f3f117a128306a2cfa51b4b4/agent/consul/server.go#L502. Another idea is to change the storage engine used for Raft storage to an LSM, such as https://github.com/couchbase/moss. Caching of log entries completed here: https://github.com/rqlite/rqlite/pull/471. https://github.com/rqlite/rqlite/pull/493. Fixed.. https://github.com/rqlite/rqlite/pull/493. Fixed.. Added in https://github.com/rqlite/rqlite/pull/493/commits/9553ad402cd95ff54db90e085449fed54f7bec10. This is not trivial. The system should not disconnect on Close, as that would remove them from the system permanently. It just wants to shutdown connections to the SQLite file. However, it's not clear how to reopen again.. Not needed for 5.0 since production systems don't re-open closed Stores.. https://github.com/rqlite/rqlite/pull/485 partly addresses this. What remains is documentation.. Fixed in 98ed8cfe668a156e1a5a5ece4bafc74690bc8403.. Should be fixed by https://github.com/rqlite/rqlite/pull/511. Part of the work for https://github.com/rqlite/rqlite/issues/477. Just seeing this now, must have gone into my spam folder. Thanks for your report.\nrqlite does some hokey text handling and you may have hit a bug. Can you show me the simplest session, in both systems (rqlite and SQLite), so it's easier for me to work on it -- i.e create a 2-column table, one column for the ID, and one containing the problematic values. I'll then take a look.. Fixed, please build top-of-tree. The next official release with the change will 5.0.. Interesting post on building HTTP handlers, which may be of use: https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html. I'm happy to help, but would you mind posting your questions to the Google Group? That way everyone can benefit.\nhttps://groups.google.com/forum/#!forum/rqlite. Thanks for posting your question to the Google Group. I answered there.. ```\n[rqlited] 2018/05/30 10:19:11 rqlited starting, version 5, commit unknown, branch unknown\n[rqlited] 2018/05/30 10:19:11 go1.10.2, target architecture is amd64, operating system target is linux\n[store] 2018/05/30 10:19:11 opening store with node ID localhost:4002\n[store] 2018/05/30 10:19:11 ensuring directory at /usr/local/google/home/otoolep/coding/rqlite/src/github.com/rqlite/rqlite/cmd/rqlited/data exists\n[store] 2018/05/30 10:19:11 SQLite in-memory database opened\n[raft] 2018/05/30 10:19:11 [INFO] raft: Initial configuration (index=1): [{Suffrage:Voter ID:localhost:4002 Address:127.0.0.1:4002}]\n[store] 2018/05/30 10:19:11 no bootstrap needed\n[rqlited] 2018/05/30 10:19:11 no join addresses set\n[raft] 2018/05/30 10:19:11 [INFO] raft: Node at 127.0.0.1:4002 [Follower] entering Follower state (Leader: \"\")\n[raft] 2018/05/30 10:19:13 [WARN] raft: Heartbeat timeout from \"\" reached, starting election\n[raft] 2018/05/30 10:19:13 [INFO] raft: Node at 127.0.0.1:4002 [Candidate] entering Candidate state in term 7\n[raft] 2018/05/30 10:19:13 [DEBUG] raft: Votes needed: 1\n[raft] 2018/05/30 10:19:13 [DEBUG] raft: Vote granted from localhost:4002 in term 7. Tally: 1\n[raft] 2018/05/30 10:19:13 [INFO] raft: Election won. Tally: 1\n[raft] 2018/05/30 10:19:13 [INFO] raft: Node at 127.0.0.1:4002 [Leader] entering Leader state\nconnection made: 16596347714875767075\napplying disconnect: 16596347714875767075\nconnection made: 7571497329709358551\nconnection made: 9654183847763689129\napplying disconnect: 16596347714875767075\npanic: runtime error: invalid memory address or nil pointer dereference\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x20 pc=0x7b27e8]\ngoroutine 26 [running]:\ngithub.com/rqlite/rqlite/store.(Store).Apply(0xc4200d6fc0, 0xc42017d1d0, 0x0, 0x0)\n    /usr/local/google/home/otoolep/coding/rqlite/src/github.com/rqlite/rqlite/store/store.go:1095 +0xa08\ngithub.com/hashicorp/raft.(Raft).runFSM.func1(0xc4201c01b0)\n    /usr/local/google/home/otoolep/coding/rqlite/src/github.com/hashicorp/raft/fsm.go:57 +0x15a\ngithub.com/hashicorp/raft.(Raft).runFSM(0xc420101080)\n    /usr/local/google/home/otoolep/coding/rqlite/src/github.com/hashicorp/raft/fsm.go:120 +0x2fa\ngithub.com/hashicorp/raft.(Raft).(github.com/hashicorp/raft.runFSM)-fm()\n    /usr/local/google/home/otoolep/coding/rqlite/src/github.com/hashicorp/raft/api.go:506 +0x2a\ngithub.com/hashicorp/raft.(raftState).goFunc.func1(0xc420101080, 0xc4200a55b0)\n    /usr/local/google/home/otoolep/coding/rqlite/src/github.com/hashicorp/raft/state.go:146 +0x53\ncreated by github.com/hashicorp/raft.(raftState).goFunc\n    /usr/local/google/home/otoolep/coding/rqlite/src/github.com/hashicorp/raft/state.go:144 +\n``. Went with first option.. Another: https://circleci.com/gh/rqlite/rqlite/2002#tests/containers/2. Perhaps the code that picks a free port and returns that address to the test port (random_addr()) is not quite finished closing the port down when it returns it to the node, for use by that node. A less racy way of finding free ports is probably required.. It might be best to actually push port 0 into the test node, and let is open the port. Then interrogate the node for its actual port, in thestart()function, setting it on the node object. However there is a chicken-and-egg issue here -- can't interrogate unless you know the port.. Fixed.. This seems to be still failing becauseClose()can be explicitly called while therun()is running. The solution is probably to move connection manager to theStore` object and have it run the goroutine.. Tested and https://github.com/rqlite/rqlite/pull/510 resulted.. No, it does not.. There does not seem to be any way around this issue. For solid transaction support, even interaction with the system would need to go through Raft. This would impact query performance significantly (execute already has to go through Raft, so no change there) and make the log much bigger.\nTo mitigate this issue, rqlite performance generally needs to improve. The most effective approaches may be using a different storage system for Raft (see https://github.com/rqlite/rqlite/issues/469), using a different consensus implementation (https://github.com/rqlite/rqlite/issues/517), or both.. Thanks for your report.\nHow do you know rqlite doesn't support HTTP2? Can you be more precise?. From my reading of the docs, by using Go 1.6 or later, you pick up http2 support. This means rqlite supports it.. Couple of reasons: a) check if performance is any better, and b) as you say, CoreOS' implementation now seems to be more actively maintained and may be better in the longer term.. Thanks for that example -- it could be helpful. I agree that the example that comes with etcd's implementation is pretty complicated.. >>rqlite nodes use raft for reaching consensus. So all rqlite nodes will contain the same data and no data sharding, right?\nCorrect.\n. Not sure why you mentioned hraftd, since you also mention rqlite.\nSnapshotting within rqlite depends on two factors:\n-- the number of entries outstanding in the Raft log. This is a core part of Raft, and will not go away wit a different implementation. A different implementation may improve this time, but it will never go to zero.\n-- the size of the underlying SQLite database. This is specific to rqlite, since rqlite makes a copy of the SQLite database as part of the snapshot operation. It may simply be that rqlite can only practically support databases up to certain size, depending on your hardware. Every database has practical limits, and you may be hitting them. It may also be possible to speed up this phase, but it will require code changes.. I don't have absolute numbers, you may be hitting a practical limit for your particular application. \nAs for your suggestion, you basically described what a snapshot operation is, as far as the Raft system is. rqlite already truncates the log during a snapshot. But a copy of the SQLite database must also be made -- that is where the state represented by the committed log entries is.. Perhaps it's possible to modify the source code, such that the minimal amount of work is done during the snapshot, and more work is done in parallel, unblocking the system. I'd need to check.. No, those interfaces are not exposed. Only standard SQLite commands are available.\nIf this doesn't answer your question, please re-open this issue.. The Raft system calls fsync() every time it writes to the log (it is built on BoltDB), and before it responds -- what you are experiencing does not sound right. Two things to check:\n-- are you sure you're code is waiting for your insertions to return?\n-- when you restart the node, are you sure all the logs have been applied the underlying SQLite database? \nI suggest you get familiar with the status API, and examine that at each stage of your test. It will tell you many useful things about how many requests have been received, how many have been committed to the log, applied etc. \nhttps://github.com/rqlite/rqlite/blob/master/DOC/DIAGNOSTICS.md. That is helpful. You are doing 10K queries, which implies you're using the wrong endpoint. See https://github.com/rqlite/rqlite/blob/master/DOC/DATA_API.md\nSend your INSERTs to db/execute, not db/query.. >>makes sense that read-queries are not written to the log\nNot by default, no. But they may be, depending on read consistency levels: https://github.com/rqlite/rqlite/blob/v4.3.0/DOC/CONSISTENCY.md. I need more context here -- I don't really understand what this is about. \nAlso, I'm unlikely to add support for a particular ORM such as Django. Not ruling it out, but I prefer to keep rqlite focused.. What is a \"keg-leg\"?. OK, thanks @alanjds \nI am planning more major work on rqlite for 5.0 in a couple of weeks or so (busy with other stuff right now). So I am reluctant to merge anything that may not make sense (and this code change isn't ready yet). The changes could be significant, including a brand new consensus module.. I would be open to a contrib directory as you suggest. However any code in there would still need to be high-quality, and I would need an HTTP API exposed that would allow people explicitly hook the stuff in. \nThe connection model is changing is significantly in 5.0, and since this functionality is based on that, anything you do right now is liable to need serious rework. But the general idea you have should work.. OK, please generate a PR and I'll take a look -- thank you.. Thanks @sum12 \nBefore I merge anything (not sure if that's what you're suggesting now), a few more things need to happen. Commented-out code needs to be removed, tests need to be added, and a README needs to be added.\nAlternatively you can wait until I play with what you have now. However it's going to be 3-4 weeks because I have non-programming commitments right now that mean I don't have time for coding right now. :-/. I have no plans to merge this at the moment. Right now the goals for rqlite mean I want to keep it quite focused, and not have any ORM or web-framework -specific features. . Thank you for your contribution. Couple of questions:\n-- how is the image built automatically? Where is that hooked in?\n-- is this better done in https://github.com/rqlite/rqlite-docker (perhaps not, depending on the answer to the previous question).. @lalyos  -- thanks very much for this. This looks really helpful, as I hadn't been happy with the manual work involved with pushing up Docker images. I'm going to dig into this a little more, to ensure that I generally understand it, but your image is so much smaller than what I have pushing up until now that I think it makes sense just to drop the dockerfile here, and deprecate the other repo.. (Deprecate rqlite/rqlite-docker, that is.). Just an FYI: I am keen to merge this, but am away from rqlite development for a little while longer due to demands other than programming.. Can you please send your questions to the rqlite Google Group? https://groups.google.com/forum/#!forum/rqlite. The rqlite API is HTTP-based. You can access that API anyway you want.\nhttps://github.com/rqlite/rqlite/blob/master/DOC/DATA_API.md. So write your own HTTP client if you want.. This is great @rhnvrm -- thank you. I've wanted this functionality for a while, but didn't realise it was this easy to do.\nHowever, there are a couple of side-effects we need to clean up. 1) When enters .help, the output is now missing newlines. And 2) when you exit the CLI, the terminal is left in a mode that newlines are no longer handled correctly. \nIs there some exit code missing, which restores the terminal?. Yeah, basically the terminal is left in an unusable state after exiting rqlite with this change in place.. stty sane or reset at the shell after exit fixes it up.. Don't worry about the CI failure, looks like an unrelated race.\nThe code is working better for me now -- thanks. However, after I do SELECT * from foo the history is lost again. Do you know why?. BTW, I am fine with your \"hack\". The standards for the CLI are a bit lower than the database itself. Whatever works. :-)\nIf we can get history working even after the SELECT commands, I'll merge.. OK, thanks for your continued work on this feature.. This is great -- thank you. I just tested the changes, and it all looks good.\nCan I suggest one more change? Empty commands -- the commands you get if you just hit Enter -- are getting stored in the history. Can you prevent those from being added to history at all? Or strip them as they are added?\n. (We will also need to look into the build break.). Just to be clear, I'm happy to merge this, but wanted your feedback on this final piece before doing so. This functionality is definitely useful as is.. https://github.com/Bowery/prompt/issues/19. Thank you for your contribution @rhnvrm . Thank you @aembleton . Can you provide a little more detail? Have you messed up the configuration of your cluster? Can you provide step-by-step instructions on how to reproduce this issue?. There may be some sequencing issues that might be improved within the code, but fundamentally the reason is this:\n-- the node has joined a cluster, and now there are two nodes in the cluster.\n-- when the leader is taken down, the cluster cannot elect a new leader, since it can't reach quorum (2 nodes are required to elect a new leader).\n-- the node won't even start up properly, since it needs to contact a leader. This is due to the way Raft works.\nA cluster with two nodes doesn't make sense. It's too vulnerable to failures like this. Instead run 3 nodes, that way a new leader can be elected almost immediately if the first leader fails. \nYou can read https://github.com/rqlite/rqlite/blob/master/DOC/CLUSTER_MGMT.md for more details. \nI am not planning any code changes to address this particular failure, since running 2-node clusters doesn't make much sense if you truly want fault-tolerance. Please re-open if I am missing something.. Seems like a sensible thing to do -- thanks for your report. Let me look into this.. Thanks @runsisi -- this does seem necessary. Did you hit this during use, or you just noticed it?. Thank you @runsisi . Fixed by https://github.com/rqlite/rqlite/commit/6937a377aea577d87045c749778c5201a6532ce8. The issue here was that when a node was re-added to a cluster, from which it had been previously removed, it would shutdown Raft. This patch changes this behaviour, setting a flag to prevent this behavior. \nPre-4.3.1 behaviour can be re-enabled via a command-line switch.. >>nodes 1 and 2 succeed (therefore reaching Raft quorum), but node 3 had temporary I/O error, resulting in a rollback\nThis would be bad, and rqlite would not deal well with this, because each SQLite database would be in a different state. This is probably another reason to use an in-RAM database, since IO errors are (presumably) much, much less likely -- perhaps practically never going to happen. The good news is that you could recover by removing the node that suffered the IO error, and adding a new node, since the Raft log is the authoritative record.\n\n\nI'm just guessing but I think that Raft semantics mean that the only way for node 3 to recover is to retry the transaction to catch up with official Raft state\n\n\nYes, that would be the case, but rqlite does not do that right now. It could be coded to retry if the error is truly temporary, and is returned clearly as this. Do you know if this is the case?\n. Depending on whether the command could work on a retry, the node might be OK. But the node doesn't panic, it simply fails to apply the log entry. But it is possible to leave the SQLite database in the state you outline -- where the AUTOINCREMENT is now in a different state on 1 node out of 3, which would not be good. I don't have a good answer for you, but I agree it's an issue -- thanks for pointing out. I'll need to think about this, and see if there is a rock-solid answer.\nThe behaviour of the underlying SQLite source code might help, as you say, but I'd need to check.. Yeah, this is a known issue: https://github.com/rqlite/rqlite/issues/257\nIt's got to do with the very simple query parsing that rqlite is doing. I hope to fix it in time, but it won't be soon.. Thanks for your report. I've never heard of this type of issue before. I would do some research on SQLite, and learn about the circumstances in which it can go into read-only mode. Perhaps that would give us a clue.. Can I suggest you send longer discussions like this to the Google Group? GitHub issues are not the best for things like this.\nhttps://groups.google.com/forum/#!forum/rqlite\nThat way others may chime in too.. Thanks.. 1: I have -- see http://www.philipotoole.com/rqlite-v3-0-1-globally-replicating-sqlite/\n2: rqlite runs by default in RAM, but the log is stored on disk. Check the README for details.. Correction: see https://github.com/rqlite/rqlite/blob/master/DOC/IN_MEMORY_DB.md. Anywhere from 10 to 100 inserts a second. Depends a lot on your network and disks.\nI suggest further discussion should take place on the rqlite Google Group.. No, rqlite doesn't support anything like that right now. You mean something like:\nhttps://github.com/rqlite/rqlite/issues/127. What version are you running? Can you dump the diagnostic output from each node, when you hit this issue:\nhttps://github.com/rqlite/rqlite/blob/master/DOC/DIAGNOSTICS.md\nAlso, when you receive the 503, is there any message in the body of the response?. Can you send me the diagnostic output too?. As requested, I need this info from each node of your cluster, when your system gets into this state. You can do by via curl like so:\ncurl <node IP address>:4001/status?pretty. You're still not supplying me the information I need. I need it from all nodes in your cluster. You have to hit the diagnostic endpoint on each node.. This is the way Raft works. It must take a consistent snapshot of the log, so accesses to it are blocked during the snapshotting process.\nYou can play with the number of logs per snap, via a command line option. You can have more, shorter snapshots, or fewer, longer snapshots.. Without more information, this is impossible to debug. I need:\na) understand what happened before the machines got into this state.\nb) show the output of .status from each node.. Queries, except for the strong consistency level, are not blocked by a snapshot operation.. (I can confirm by checking the code.(. Yes, this is something I'm considering for v5. v5 development is proceeding slowly though, due to other commitments I have, but I think it's a good idea.. >> And I found many bugs in rqlite v5 http api implementation\nI commented on the single issue you raised with that code, but don't actually see any issue with it. Perhaps I am missing something.. Not a big deal, but really we want to check if the error is anything but \"not exists\". If so, then something has gone wrong, other we don't care.\n. So we just get the index, if we assign to only 1 variable?\n. If I recall correctly, this was done for a reason so that the strings are not actually created if logging is not in debug mode.\n. Is this a lint requirement?\n. Did you hit some issues that triggered creation of this function?\n. Nice, get rid of the Server.Server.....\n. So if we put loads and loads of debug statements in, performance wouldn't be affected by all the string creation when not in debug mode. It actually could be concern as we increase the debug logging.\n. This doesn't look right.\n. Nor this.\n. Is moving this to a separate function a lint thing?\n. D'oh. You're right.\n. I'd prefer if this check was moved outside of the function -- only call it if count is greater than the threshold. It's easier to follow the code that way, as well as explicitly uint-test the function.\n. You need to revert this change.\n. How about using /db/bulk instead? Both POST endpoints allow data to be \"ingested\".\n. Did you mean to change this?\n. I think this should be trace.\n. Why not log this at error lvel?\n. It's more Go-style to return from this clause, and have no else clause. Can you make that change? (And in other places where it matter)?\n. I don't think this will work because another call to Open could take place and set a new value for sqlite3conn. That said, I'm going to fix this connection handling in another PR so the issue will soon be moot.\n. Let's pick a different name for this. decltypes is too low-level. How about just types?\n. The error should be checked here.\n. Nit: please remove this blank line.\n. This mutex and all the comment above can be removed now, right?\n. Also, I don't think this is necessary. The directory tree will be created already, right? rqlite never had to do this before.\n. Why did you decide to name the error?\n. OK, I see what you're saying -- my mistake.\nThe directory creation should be performed up a level, which I've done here: https://github.com/otoolep/rqlite/commit/e7e212411a4831fa3b24aa3a02b102ad162ac431\nThat way you don't need to worry about it now.\n. Just to explain my reasoning. The directory is also needed by the Store, but the Store is more fundamental to the system than the SQLite file, hence have the Store create it.\n. OK, for the sake of consistency, how about just doing var err error here?\n. Yeah, you can delete this now, since it's done by the Store code.\n. What exactly is the point of this change? I don't follow what one would use this switch for.. Got it, thanks @tych0 . Can you add a GoDoc string? E.g. RegisterObserver registers an observer that ..... I think I prefer a simpler name for this call. How about just Database()?. The docstring for this function shouldn't contain any reference to Hashicorp Raft, it's not relevant in this context. This is function that is handing control over to the user, and they better be sure they know what they are doing.\nThere are multiple potential ways to shoot yourself in the foot here. There is no check that the store is the leader of the cluster, for example, and therefore no guarantee that the copy you get is up-to-date.. Docstring isn't quite right. Can you change it to read:\nDatabase() returns a copy of the underlying database. The caller should ensure that no transaction is taking place during this call, or an error may be returned.\nThen I'll merge.. Why the addition of the cache flag?. Is there no way to do this by re-opening the database connection? Such that you get a new lump of RAM?. I like this idea in principle. It's probably the interface I should have had the Store object implement in the first place. (Though how to do transactions is what you're trying to solve here0.. What is the idea behind these On functions?. I was thinking about this. I do want URL params to take precedence over any in the body and making that explicit in the documentation.\nReturning an error wouldn't be a bad idea, though the query endpoint (/db/query) doesn't do that in that case, it simply ignore any queries in the body. 400 Bad Request would probably make most sense.. This no longer seems correct, and needs work. What is the right way to form the cluster?. This seems relevant: https://www.consul.io/docs/guides/bootstrapping.html. While this works, SplitHostPort is not for splitting Basic Auth credentials. Instead please do:\ncreds := strings.Split(arg.Credentials, \":\")`\nif len(creds) != 2 || creds[0] == \"\" || creds[1] == \"\" {\n    return fmt.Errorf(\"invalid Basic Auth credentials format\")\n}\nreq.SetBasicAuth(creds[0], creds[1])\nor something to this effect.. If the RFC doesn't require it, then it's fine. . The help message looks like it needs to be pushed over move, so it lines up with the messages above.. This message doesn't make sense to me. Did you mean \"assuming on\"? If so, why not just do that, and not return error?. Yeah, probably change it.. Nit: this variable name is unwieldy. Go style dictates shorter variable names, especially since it's just used over as few lines. Please use a shorter name, like fkEnabled.. Nit: this line is too long. I don't have hard standards about line length, but this one is hard to read. I suggest a newline before restoreRet.... Or just code two calls to ctxString().\nAlso, can you change Id to ID -- Go style dictates that acronyms are fully capitalized.. Function GoDoc needs updating since it's no longer returning a byte slice. Instead \"Backup writes a backup of the node to dst.\" Or something.. Function GoDoc needs updating.. Function GoDoc needs updating, since this function no longer returns a byte slice.. How do I know I can trust this container?. I am assuming that this image forms the basis of the rqlite image. Let me know if I am missing something.. OK, thanks @lalyos for the extra information. Need to do a little bit more research. If you can provide any references to this glibc being used by others, that would be helpful. . Actually, this is probably why it fails to keep history after SELECT * FROM foo. I think you should recreate the terminal regardless of error.. ",
    "codahale": "If you haven't already seen it, Kyle Kingsbury's article on linearizability and stale reads in Raft systems is a good read on the consequences of relaxing read consistency in Raft-based systems. A single node's local opinion of whether or not it's the leader can and will be faulty during a partition, and check-then-act strategies will suffer from race conditions during partitions. The only way to ensure linearizability is to send queries through the Raft consensus process, where they will be totally ordered along with reads. Both Consul and etcd had issues with stale reads, and now both support strongly consistent queries via URL parameters.\n. ",
    "aphyr": "Yup. VerifyLeader is not sufficient. You need to wait for a noop op to be committed by the raft state machine, or block until some other operation commits.\n. (and since we found this issue experimentally in both etc and consul, I'm pretty confident you'll see it in rqlite as well)\n. You might find https://aphyr.com/posts/313-strong-consistency-models helpful.\n. You don't have to hold a lock to provide linearizability. Please see http://www.ics.forth.gr/tech-reports/2013/2013.TR439_Survey_on_Consistency_Conditions.pdf.\n. ",
    "zmedico": "\nA single node's local opinion of whether or not it's the leader can and will be faulty during a partition, and check-then-act strategies will suffer from race conditions during partitions.\n\nSure, but isn't any check-then-act strategy doomed to race conditions anyway, if the whole check-then-act operation is not atomic relative to the raft state machine?\nFor purposes of discussion, it's useful to have a practical example of how to accomplish a given task while avoiding a race. A transaction is a practical means to achieve an atomic operation relative to the raft state machine. For example, it's possible to use a transaction to implement a compare-and-swap operation with rqlite. Simply begin the transaction with an operation that is guaranteed to fail in the event of a race, like inserting a row into a table, such that the insert is guaranteed to fail if a competing transaction is processed first. The transaction will roll back if the if this first insert fails, guaranteeing that we'll have either a successful atomic operation, or a rollback.\n\nVerifyLeader is not sufficient. You need to wait for a noop op to be committed by the raft state machine, or block until some other operation commits.\n\nFor a read operation, the result is potentially stale as soon as the data is received by the client. So, I don't see any practically utility in having readers block on the raft state machine, unless they get to hold a lock on the state machine until they close their connection. Obviously, write transactions like in the example I've given must block on the raft state machine.\n. > But this level of consistency may be useful to some people.\nMaybe so, but there's an extra level of consistency available if the reader gets to hold a lock on the raft state until it closes its connection. Does that sound interesting @aphyr?\n. > You don't have to hold a lock to provide linearizability.\nThat's true. I was just thinking of practical uses that go beyond linearizability. I'm not so sure that read locks are really desirable anyway.\n. > The same approach could be used to enforce authentication.\nThat may work for the HTTP interface, but the RAFT connections will require authentication support directly in rqlited. Using the consul security model as an example, we might use symmetric key encryption for RAFT connections, and TLS for the HTTP interface.\n. The raft connections can be secured via a mesh vpn such as peervpn or meshbird.\n. > What do you see if you issue the query today? I have not tested it.\nThe last_insert_rowid() function works fine as it is, for example:\n$ curl -L -XPOST 'localhost:4001/db?pretty&explain&transaction' -d '\nCREATE TABLE foo (id integer not null primary key, name text);\nINSERT INTO foo(name) VALUES(\"fiona\");\nSELECT last_insert_rowid() as rowid;\n'\n{\n    \"time\": \"1.254978ms\",\n    \"failures\": []\n}\nSince the above doesn't return the row id, it has to be retrieved as a separate transaction:\n$ curl -L -G 'localhost:4001/db?pretty&explain' --data-urlencode 'q=SELECT last_insert_rowid() as rowid'\n{\n    \"time\": \"282.159\u00b5s\",\n    \"failures\": [],\n    \"rows\": [\n        {\n            \"rowid\": \"1\"\n        }\n    ]\n}\n. It's also useful to return number of rows affected by an UPDATE statement. This value can be queried using SELECT changes() as changes. If have tested this function with rqlite, and it also works:\n$  curl -L -G 'localhost:4001/db?pretty&explain' --data-urlencode 'q=\nSELECT changes() as changes, last_insert_rowid() as last_insert_rowid'\n{\n    \"time\": \"225.588\u00b5s\",\n    \"failures\": [],\n    \"rows\": [\n        {\n            \"changes\": \"1\",\n            \"last_insert_rowid\": \"1\"\n        }\n    ]\n}\nI can use this to implement python's Cursor.rowcount attribute.\nEDIT: Now I see https://github.com/otoolep/rqlite/issues/4.\n. It works great, thank you!\n. Yeah, I'm releasing it with MIT license:\nhttps://github.com/zmedico/pyrqlite\nLots of things can be simplified thanks to the rqlite-2.0 API.\n. I also made an sqlalchemy dialect that I used to test pyrqlite:\nhttps://github.com/zmedico/sqlalchemy-rqlite\n. I'm pretty happy with the 2.0 API as it currently is, but I think that ideally the URI would include a version component so that multiple versions can be supported simultaneously. Each version doesn't have to be supported forever. I'm not particularly invested in the 1.0 API, so I don't really care if it's dropped now (though it shouldn't be terribly difficult to continue supporting it).\nWhat are your thoughts on adding a version component to the URI?\n. > As for the API, I've made some final changes. \nLooks good.\n. Now pyrqlite uses the rqlite 2.0 API.\n. Looks good, thanks! It's a big improvement, and maybe https://github.com/otoolep/rqlite/issues/52 isn't really essential, so I'm happy the new API as is.\n. The relevant info is stored in the sqlite3.SQLiteRows.decltype field (which is currently inaccessible outside the sqlite3 package).\n. I have a branch containing a patch that changes DB.Query to bypass sql.DB, allowing for access to SQLiteRows instances. Now sqlite3.SQLiteRows just needs a method to export the declaration types.\n. Fixed by https://github.com/otoolep/rqlite/pull/71.\n. It's a problem with your usage of quotes in your shell, not a fault of rqlite. Here's an example of how to the the effect that you want (use echo to check correctness):\n$ echo ', '\\''{\"gzip\": 1, \"upstream\": \"server 127.0.0.1:81; server 127.0.0.1:82;\"}'\\'');'\n, '{\"gzip\": 1, \"upstream\": \"server 127.0.0.1:81; server 127.0.0.1:82;\"}');\n. Binary copy of sqlite database, or text sql dump? Maybe one endpoint for each?\n. A global lock makes sense. The length of time that the lock is held can be minimized to the time it takes to create a consistent copy of the whole state. The backup consumer can never assume that the backup it receives is entirely up-to-date, since changes can happen as soon as the backup completes (unless there is a procedure to put the whole system into an immutable mode).\n. Looks good, thank you!\n. The go-sqlite3 PR has been merged now. However, circleci still fails because apparently it still uses an older copy of go-sqlite3.\n. I didn't push the changelog entry before you merged it.\n. @Sooriya10: It sounds like maybe you're looking for something like blockchain, which is much different from RAFT.\n. > Thanks Zac, If you happened to know any blockchain implementation on SQLite3 or any other database. Please let me know.!\nI think what you want is rqlite with support for using public-key cryptography to sign all transactions. Each transaction must be signed with a private key that is not divulged to the read-only nodes. The read-only nodes can use the corresponding public key to verify the integrity of transactions, but they won't be able to create new transactions unless they have access to the private key.\nIn order to support something like this, you're probably need it to be built into the RAFT library.\n\nAll that is way beyond the scope of rqlite.\n\nIndeed, file level security is way out of scope, since it's a system administration issue. The cryptographic security is out of scope due to it being the domain of the RAFT library.\n. I've found an example for mutual authentication using tls.Config{ClientAuth: tls.RequireAndVerifyClientCert}:\nhttp://www.bite-code.com/2015/06/25/tls-mutual-auth-in-golang/\n. It looks very nice @otoolep, thanks for asking. I'd like to add support for these features to the python driver ASAP.\n. > I am using https://github.com/mysqljs/sqlstring for escaping, but mysql is a bit different from sqlite, is there something similar like this package, but for sqlite?\nFrom https://www.sqlite.org/lang_expr.html:\nA string constant is formed by enclosing the string in\nsingle quotes ('). A single quote within the string can\nbe encoded by putting two single quotes in a row - as in\nPascal. C-style escapes using the backslash character are\nnot supported because they are not standard SQL.\n\nBLOB literals are string literals containing hexadecimal\ndata and preceded by a single \"x\" or \"X\" character.\nExample: X'53514C697465'. You need a newer version of mattn/go-sqlite3. The go get -u flag should make it update the dependencies for you.\n\n. In order to handle binary data, there will have to be a way for the client to specify typed arguments for the SQLiteConn.Exec method. Since json can only contain text data, the client will have to encode binary data as base64, and rqlited will have to decode the base64 to []byte before it is passed as args to the SQLiteConn.Exec method.\nWhen returning binary data from select statement, rqlited will have to encode the binary data as base64, and the client will have to use the types of the columns as a hint that the values need to be decoded from base64 to binary data.. Actually, it might be possible to use BLOB literals containing hexadecimal data to insert binary data, which is how it can be done at the sqlite3 prompt. I'll test that, and see how rqlite returns the binary data in query results.\n. BLOB literals containing hexadecimal data do work with rqlite, and query results return the binary data with base64 encoding.. Unfortunately, I doubt that BLOB literals are helpful for this select 'other' as \"x [bar]\" thing. This is the result from rqlite if we encode 'other' as hex:\n127.0.0.1:4001>  create table test(x foo);\n0 row affected (0.000000 sec)\n127.0.0.1:4001>  insert into test(x) values ('xxx');\n1 row affected (0.000000 sec)\n127.0.0.1:4001>  select x as \"x [bar]\" from test;\n+---------+\n| x [bar] |\n+---------+\n| eHh4    |\n+---------+\n127.0.0.1:4001>  select X'6f74686572' as \"x [bar]\" from test;\n+---------+\n| x [bar] |\n+---------+\n| other   |\n+---------+. It looks like the relevant C functions are documented here:\nhttps://www.sqlite.org/c3ref/column_database_name.html\nIf go-sqlite3 doesn't provide some API to access these functions, then the API will have to be extended, like when I added the DeclTypes method in https://github.com/mattn/go-sqlite3/commit/10876d7dac65f02064c03d7372a2f1dfb90043fe.. Renamed to just types, and fixed tests.\n. Apparently sql.Open creates the directory. I just tested again, and this is the error if we don't create the directory:\n2016/03/14 21:05:39 failed to open store: unable to open database file\n. If I don't name the error, then I get this:\nsrc/github.com/otoolep/rqlite/db/db.go:126: undefined: err\nsrc/github.com/otoolep/rqlite/db/db.go:127: undefined: err\nsrc/github.com/otoolep/rqlite/db/db.go:128: undefined: err\nIf use := to try and fix the above problem, I get this:\nsrc/github.com/otoolep/rqlite/db/db.go:126: t declared and not used\nI'm open to suggestions if there is a better way to achieve the intended result.\n. Updated to check for MkdirAll error.\n. Done.\n. Yes, those are removed now.\n. Done.\n. Done.\n. This means that queries in the body will be ignored. Maybe return an error code if there are queries in both places?. ",
    "nodtem66": "Why it shouldn't be written in Go? \nIs the reason that Python is commonly installed on OS?\n. ",
    "fern4lvarez": "Isn't rqlite a command line tool itself? What should I expect from this tool you propose and what's the difference with the current one?\n. :+1: \n. https://packagecloud.io/ provides a very nice service. Projects like inspeqtor are using it.\n. I started working on this. Many of these issues come from log4go, which often forces programmer to ignore error checking when using log.Error. I'll see what I can I do, but I'd start with #21 first, and go cleaning issues along the way.\n. Hey, where are we copying log4go's code? Honestly I didn't take log4go code into account, the idea was to have a simple log package wrapper with a simple and intuitive interface.\n. No, not copying at all, take it for granted :wink: \n\nIs this still WIP? Build seems green now.\n\nI'd like to complete first the pending bullets in the PR description, so we'd reduce drastically the number of warnings raised by gometalinter.\n. OK, I skip the two last bullets for now. But this should fix #25 and #24. Please review and merge if looks good to you.\n. Updated after comments. Let me know your thoughts, so I can clean up the commit history, i.e. squash Fixup commits before merging.\n. Done!\n. Uhm, sorry to hear this. I'll try to reproduce this and apply a fix, if possible. Of course reverting it was the best choice!\n. Can you maybe link to the commit or code snippet where this was enabled? Thanks!\n. Closing for now, having some issues on running gometalinter on all subpackages.\n. Yes, it only works for indexes. For elements of the array, a for _, result := range ... notation is needed. This is something that gometalinter complained about. \n. Yeah, I see the point. I tried this, but somehow this internal log implementation failed to resolve the func() string when used as a parameter and I was getting a weird value (the func description). I can investigate deeper, there must be a walkaround... Please feel free to let me double check before merging, or go ahead and fix it afterwards.\n. Yep, it is, and it's usual with defer and go statements. It's pretty common that one ignores the response (and thus the error checking) when using this statements on functions that return values, and the linter in this case complains. Do you see some negative impact involved in this change?\n. See my comment above. defer and error checking ain't good friends, so I came up with this helper function.\n. Does it make sense to you? We can always create a new file in the root directory to store these helpers, e.g. helpers.go, and keep main.go cleaner. \n. Indeed, it's a pretty common mistake. This one was also warned by gometalinter.\n. kk, I can ignore this error using a _ = os.Remove(... notation, so the code reader knows that this function returns an error value, but it's unimportant, and make the linter happy.\n. Updated.\n. Nice, I found what the issue was. Just pushed a new commit with the fixup.\n. See commit message:\nsystem_test.go:75:3:warning: Shadowing variable `nodePath` (go-nyet)\n. See commit message:\nsystem_test.go:78:3:warning: Shadowing variable `s` (go-nyet)\n. See commit message:\nserver/server.go:469:1:warning: cyclomatic complexity 11 of\nfunction (*Server).writeHandler() is high (> 10) (gocyclo)\nIt's about the complexity of the function. Extracting this method reduces it under 10, but any kind of refactoring would have done the job as well.\n. sure thing!\n. ",
    "dessalines": "Hrm, if I leave off the '-join master_peer, it seems to load up fine, but I'm not sure if it attached to the master or is running on its own node now.\nThe raft admin query(curl localhost:4001/raft?pretty) seems to show the peers connected, even if they are actually disconnected.\nThis below is what happens if I run leave off only join, it I have to leave off the master_peer too.\n~/rqlite$ bin/rqlite localhost:4001 -p 4002 node.2\n[03/01/15 15:22:58] [INFO] Redirectoring logging to stdout\n[03/01/15 15:22:58] [INFO] Raft random seed initialized\n[03/01/15 15:22:58] [INFO] Raft commands registered\n[03/01/15 15:22:58] [INFO] Initializing Raft Server: localhost:4001\n[03/01/15 15:22:58] [INFO] Loading latest snapshot, if any, from disk\n[03/01/15 15:22:58] [INFO] Recovered from log\n[03/01/15 15:22:58] [INFO] Initializing HTTP server\n[03/01/15 15:22:58] [INFO] Listening at http://localhost:4001\n[03/01/15 15:22:58] [EROR] listen tcp :4001: bind: address already in use\n. Cool, thanks Philip, that makes things easy. Would it be possible to a 'isActive' or 'isConnected' field to that admin query? This would be really useful to me, rather than having to query individual nodes and see if they fail.\nSomething like:\n{\n    \"peers\": {\n        \"2456e8c\": {\n            \"name\": \"2456e8c\",\n            \"connectionString\": \"http://localhost:4002\",\n            \"isConnected\" : \"false\" \n       ...\nBTW I'm pretty excited about the results so far. Replication seems instant, on the localhost at least. \n. Thanks a ton man.\n. Update to this:\nI added a Thread.sleep to see if waiting after RQL has initialized would work.\nIt seems that waiting around 5 seconds after RQL has started seems to unlock the DB. It also seems that additional writes must not lock the DB for long periods of time at all, because I've done some stress testing, and I haven't run into another locking issue since.\nYou can close this out if you want, or add this bit about the locking into the documentation, or possibly see if there is any way to release the DB lock quickly after initializing. \nThanks.\n. Just tested this endpoint. Unfortunately the diagnostics endpoint is immediately available after startup, while there is still a DB lock.\nMy preference would be that there there be an indicator message like that below\n[03/03/15 08:43:03] [INFO] Raft random seed initialized\n[03/03/15 08:43:03] [INFO] Raft commands registered\n[03/03/15 08:43:03] [INFO] Initializing Raft Server: data\n[03/03/15 08:43:03] [INFO] Loading latest snapshot, if any, from disk\n[03/03/15 08:43:03] [INFO] Recovered from log\n[03/03/15 08:43:03] [INFO] Initializing HTTP server\n-- HERE Initializing DB/Filling DB......\n-- DB lock released.\n[03/03/15 08:43:03] [INFO] Listening at http://localhost:4001\n. You're right. I just tested this script myself and it works fine. Not sure whats going on with my end, but I can reopen this issue if I find more problems.\n. Hey @otoolep , I'm getting this issue again. As I've added more data to the rqlite DB, the locking issue when starting up is becoming worse. Now, after starting up rqlite, it seems to need about 2 minutes to unlock the database. \nWhen watching the folder after rqlite has already started up, it looks like a db.sqlite-journal keeps being altered/changed, for up to a few minutes, causing a lock. It can't be a syncing issue, because right now I'm only running 1 node.\n. > Is all your testing with a single node right now? \nYep.\n\nHow large is your database?\n\nAbout 80Kb.\n\nHave you tried reproducing read failures during this time by using sqlite?\n\nYep, running the sqlite3 .tables command won't show anything, and selects show the error 'database is locked'. using sqlitebrowser also shows it as locked.\n. Some other things I've noticed. \nWhen starting up rqlite, my DB drops a bunch in size, down to maybe 60kb. A db.sqlite-journal file appears to be altering the DB for the few minutes while its locked, growing it back up to the original size.\n. Using unix kill, so I think that's a SIGTERM. Is there a proper way to shut down rqlite?\n. Actually sorry, I'm using kill -9 , which is a sigkill.\n. Yep, every time it's restarted.\n. Sure, would just giving you the db.sqlite file be enough?\n. Or the whole directory?\n. k, done\n. This was easy for me to test because I have a setup where I can delete and regenerate rqlite quickly. \nI tried -s 50, and some lower values, and it does seem to create some snapshot files where I had none before. I notice that whereas the DB use to decrease to a far lower size, now it only decreases to around 75% of what it once was, taking a lot less time to build back up and release the lock.\nThat pretty much fixes my problem, thanks @otoolep . \n. > When you say \"change the leader\" you mean the cluster elects a new leader, right? I just want to be sure.\nYep that's correct. \nI just did some testing and it looks like things are okay! I set up the 3 node example, took down node.1(the first leader). And the outputs look good. \nNode 3 was arbitarily chosen as the new leader when I did this:\ncurl localhost:4002/raft?pretty\n{\n    \"leader\": \"1d4e168\",\n    \"name\": \"7d2502e\",\n    \"peers\": {\n        \"1b2bcd5\": {\n            \"name\": \"1b2bcd5\",\n            \"connectionString\": \"http://localhost:4001\"\n        },\n        \"1d4e168\": {\n            \"name\": \"1d4e168\",\n            \"connectionString\": \"http://localhost:4003\"\n        }\n    },\n    \"state\": \"follower\"\n}\n curl localhost:4003/raft?pretty\n{\n    \"leader\": \"1d4e168\",\n    \"name\": \"1d4e168\",\n    \"peers\": {\n        \"1b2bcd5\": {\n            \"name\": \"1b2bcd5\",\n            \"connectionString\": \"http://localhost:4001\"\n        },\n        \"7d2502e\": {\n            \"name\": \"7d2502e\",\n            \"connectionString\": \"http://localhost:4002\"\n        }\n    },\n    \"state\": \"leader\"\nOne minor issue though, it doesn't look like the -L parameter works with the raft endpoint. Node 3 is the leader in my case, but the raft endpoint for node 2 still shows node 2's data. \ncurl -L localhost:4002/raft?pretty\n{\n    \"leader\": \"1d4e168\",\n    \"name\": \"7d2502e\",\n    \"peers\": {\n        \"1b2bcd5\": {\n            \"name\": \"1b2bcd5\",\n            \"connectionString\": \"http://localhost:4001\"\n        },\n        \"1d4e168\": {\n            \"name\": \"1d4e168\",\n            \"connectionString\": \"http://localhost:4003\"\n        }\n    },\n    \"state\": \"follower\"\nIMO, this doesn't really matter because the same node's raft endpoint tells you enough data anyway. \nLooking back over my first post in this thread, I'm seeing that I made an error and that rqlite is actually doing the leader reselection perfectly. \nYou can close this out if you like. Remember to add the -L page to your Readme. Thanks a ton man, this stuff is pretty exciting for me.\n. Thanks @otoolep .  I'm not sure how go's builds/deployment works, is this commit included now in go get github.com/otoolep/rqlite ? Either way, I'll test this out.\n. Thanks, just tested this out and it works. Just for reference, I'd like to add that the curl -L is what does this. So an example command is:\ncurl -XPOST localhost:4002/db?pretty -L -d 'INSERT INTO foo(name) VALUES(\"fionaderp\")'\n. Just tested this out, and everything looks good. It gives these lines which are helpful:\n[03/05/15 11:01:31] [INFO] Attempting to join leader at localhost:5002\n[03/05/15 11:01:31] [INFO] Redirecting to leader at localhost:5001\nThanks a ton sir.\n. go version go1.2.1 linux/amd64\nYep, It was a version issue. I switched to go1.4.2, and am using GVM now, and it worked great. Sorry about that.\n. For my case, where I'm mainly interfacing with rqlite through curl, I make sure I have go installed, then run shell scripts to setup/rejoin rqlite. My program is written in java, but any language could pretty easily interface with rqlite since it uses curl. \nIMO, its not too much to ask that users have go installed to be able to run go programs.\n. Understood, its cool that its a possibility. I have to have ruby, python, java, and libc installed on my machine haha.\n. Damn you're fast! Thanks again good sir.\n. Thanks a ton man.\n. Gotcha, next time I update rqlite I'll test it out.\n. > Do any writes take place on the leader, before the attempted join, such that the leader snapshots and then blocks?\nYes, I did some writes(<100) before I had the 2nd node join.\n\nDo you still see this issue if the snapshot value is very large e.g. 1,000,000,000 -- I am trying to see if a snapshot actually needs to take place for this to happen.\n\nI just tested this with a -s 1000000 , and it joined correctly.\nSo maybe the bug is actually after a snapshot occurs, no joins are working?\n. Yep, leave this closed, I just tried to replicate this issue with hundreds of writes in several XPOST statements and couldn't get the same error I used to. Made sure there were snapshots in the directory too. Sorry for wasting time on this one.\n. @otoolep i updated my comment, the original email sent you a bad one, sorry about that.\n. I think I may have figured it out, I think I have to pass hostnames as -h params for both the follower and leader, I'll double check this a few times.\n. Yep that was the problem.\nBoth the follower and leader startups need -h xx.xx.xx.xx IP where the xx. is their own external ip address.\nBefore we close this out, it would be good to put this info on the rqlite readme.md under a heading of how to use rqlite over the internet . Let me know if you want me to do a pull request to do this.\n. This isn't on AWS, just regular servers.\n\nThere is nothing special about the \"internet\" per-se, but if the hostname automatically picked up by the software is not one that will allow other nodes to connect to it\n\nThis is the case. If you start up rqlite without a -h my_external_ip, it will only accept connections from localhost for some reason.\n\nWhen you say external address, what is an internal address?\n\nInternal address might be localhost, or a router given ip. External meaning internet ip.\n. It's very possible its got something to do with my network setup. It was just something I had to work through, I leave it to you to decide whether to add it to the readme.\n. Oh crap man, I didn't realize you have a bounty source set up! I'm pretty much ready to deploy a project of mine, once you sort out a few of these minor bugs. This won't be much, but its something.\n. You set up a bounty source for rqlite: https://www.bountysource.com/teams/rqlite/issues?tracker_ids=5423371\n. Oh hrm. Well anyways I contributed $50 to you on there for all these things you've been fixing/adding for me.\n. > You want a non-leader node to rejoin using different hostname?\nMaybe... If hostname means that 6 digit or so alphanumeric then yes.\nSo my problem is this. I start up node 1, and then node 2 tries to join it. Only sometimes, either because of the snapshot problem, or various other reasons, it stalls on Attempting to join node, and fails joining.\nWhen I look at the logs of node 1, and at its raft endpoint, it says that node 2 has connected, it even has the correct name and connection string. But node 2 has no db.sqlite, and its clear there was an error.\nNow I clear out rqlite for node 2, and try to join again(now it has a different rqlite name, but the same connection string as before). \nFor some reason, node 1 will not accept the new connection, probably because it sees that the same connection string is trying, but with a different name, etc. \nSo what I'm getting at is that rqlite should replace a peer that has a same connection string, removing the old one.\n. Here's a script I just worked up that replicates the error, you can test this. Be careful because it kills any running rql instance:\n``` sh\ninstall rqlite\ngo get github.com/otoolep/rqlite\nexport GOPATH=$PWD\nStartup 2 nodes\n$GOPATH/bin/rqlite node_1 &\nsleep 2s\n$GOPATH/bin/rqlite -join localhost:4001 -p 4002 node_2 &\nsleep 2s\nNow kill node 2 and clear it, assuming it has an error\nps aux | grep -ie node_2 | awk '{print $2}' | xargs kill -9\nrm -rf node_2\nNow try to rejoin node 1\n$GOPATH/bin/rqlite -join localhost:4001 -p 4002 node_2 &\nAnd you'll see that the error is that it stalls on attempting to join leader\n. The only way to get it working again is to delete node 1 completely!\nsleep 5s\nkills all the rqlite instances\nps aux | grep -ie rqlite | awk '{print $2}' | xargs kill -9\nrm -rf node_1 node_2\n```\n. Thanks @otoolep, I just altered this script above to 3 node configuration. For some reason it does work(although I'm not sure why). You can't rejoin a 2 node group, but you can rejoin a 3 node group.\nFor 2 nodes it will stall on Attempting to join leader, but with 3 it works fine.\nBTW claim the bounty here. Its my way of saying thanks for putting up with all my insane requests, haha.\nhttps://www.bountysource.com/issues/11052483-reconnecting-to-a-leader-fails-from-the-same-connection-string-ie-replacing-peers\n. I shouldn't have closed this. I kept having the same issue with my 3-node cluster in my production environment. Here's a script that shows it stalling again. Basically if a node needs to be cleared out twice, then it can't rejoin.\nMy guess is that the error has to come from the fact that the old peer isn't being replaced, but rather a new one is being added with that connection string.\nrqlite might also be trying to do a leader reselection from nodes that are potentially disconnected.\nIt basically works like this\n- Start up a 3 node cluster\n- Insert some data\n- Kill and delete Node 2, and then rejoin (this seems to work fine)\n- Kill and delete Node 2 again, (It stalls on attempting to join leader)\nHere's the script:\n``` sh\ninstall rqlite\ngo get github.com/otoolep/rqlite\nexport GOPATH=$PWD\nStartup 2 nodes\n$GOPATH/bin/rqlite -h localhost node_1 -p 4001 &\nsleep 2s\n$GOPATH/bin/rqlite -join localhost:4001 -p 4002 node_2 &\nsleep 2s\n$GOPATH/bin/rqlite -join localhost:4001 -p 4003 node_3 &\nsleep 2s\ncurl localhost:4001/raft?pretty\nDo some big inserts, alternating XPOSTS between the two nodes\ncurl -L -XPOST localhost:4001/db?pretty -d 'CREATE TABLE \"user\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"email\" TEXT DEFAULT NULL,\"password_encrypted\" TEXT DEFAULT NULL,\"name\" TEXT DEFAULT NULL,\"authenticated\" INTEGER DEFAULT NULL,\"email_code\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (email));\nINSERT INTO \"user\" VALUES(1,\"happydooby@gmail.com\",\"zWyTu4eFKjXgNedQyjlA1WacfgcluFDGtxFmzU6iYL4G6jPXFqK1K3xuw+afjqzA\",NULL,\"true\",NULL,\"2015-04-14 00:29:16\");\nINSERT INTO \"user\" VALUES(2,\"tchoulihan@gmail.com\",\"mYmiuWZaS8bndTItTFYbe0lTbUOwoll1Vg23qtdBiEVSlQJpm7Ylqxk6kzptP1wh\",\"derp\",\"true\",NULL,\"2015-04-14 01:20:58\");\nCREATE TABLE \"seller\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"shop_name\" TEXT DEFAULT NULL,\"bitmerchant_address\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (user_id));\nINSERT INTO \"seller\" VALUES(1,1,\"garg\",\"http://96.28.13.51:4567/\",\"2015-04-14 00:29:16\");\nCREATE TABLE \"product\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"seller_id\" INTEGER NOT NULL  DEFAULT NULL REFERENCES \"seller\" (\"id\"),\"category_id\" INTEGER DEFAULT NULL REFERENCES \"category\" (\"id\"),\"buy\" INTEGER DEFAULT NULL,\"auction\" INTEGER DEFAULT NULL,\"quantity\" INTEGER DEFAULT NULL,\"title\" TEXT DEFAULT NULL,\"processing_time_span_id\" INTEGER DEFAULT NULL REFERENCES \"time_span\" (\"id\"),\"physical\" INTEGER DEFAULT 0,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product\" VALUES(1,1,3,NULL,NULL,NULL,\"test_item\",NULL,0,\"2015-04-14 00:30:45\");\nINSERT INTO \"product\" VALUES(2,1,19,NULL,0,10,\"Pink frosted sprinkled donut\",3,0,\"2015-04-14 01:02:24\");\nINSERT INTO \"product\" VALUES(3,1,NULL,NULL,NULL,NULL,NULL,NULL,0,\"2015-04-14 14:09:32\");\nINSERT INTO \"product\" VALUES(4,1,18,NULL,0,NULL,\"A tasty red donut\",NULL,0,\"2015-04-14 14:10:00\");\nINSERT INTO \"product\" VALUES(5,1,25,NULL,0,5,\"A Chocalatey donut\",3,0,\"2015-04-14 14:10:45\");\nCREATE TABLE \"shipment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"address_id\" INTEGER DEFAULT NULL REFERENCES \"address\" (\"id\"),\"tracking_url\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"shipment\" VALUES(1,1,NULL,\"2015-04-14 01:14:21\");\nINSERT INTO \"shipment\" VALUES(2,2,NULL,\"2015-04-14 01:22:16\");\nINSERT INTO \"shipment\" VALUES(3,2,NULL,\"2015-04-14 13:02:23\");\nCREATE TABLE \"review\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"stars\" INTEGER DEFAULT NULL,\"headline\" TEXT DEFAULT NULL,\"text_html\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id, user_id));\nINSERT INTO \"review\" VALUES(1,2,1,3,\"Great donut\",\"Would eat again. 10/10&ltsemicolonbr&gtsemicolon\",\"2015-04-14 14:19:43\");\nCREATE TABLE \"address\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"full_name\" TEXT DEFAULT NULL,\"address_line_1\" TEXT DEFAULT NULL,\"address_line_2\" TEXT DEFAULT NULL,\"city\" TEXT DEFAULT NULL,\"state\" TEXT DEFAULT NULL,\"zip\" INTEGER DEFAULT NULL,\"country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"default_\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"address\" VALUES(1,1,\"fsdafasdf\",\"asdf\",\"asdf\",\"asdf\",\"fdsa\",1235,7,0,\"2015-04-14 01:14:18\");\nINSERT INTO \"address\" VALUES(2,2,\"fdsafd\",\"asdf\",\"asdf\",\"asdf\",\"asdf\",123,8,0,\"2015-04-14 01:22:12\");\nCREATE TABLE \"feedback\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"cart_item_id\" INTEGER DEFAULT NULL REFERENCES \"cart_item\" (\"id\"),\"stars\" INTEGER DEFAULT NULL,\"arrived_on_time\" INTEGER DEFAULT NULL,\"correctly_described\" INTEGER DEFAULT NULL,\"prompt_service\" INTEGER DEFAULT NULL,\"comments\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"feedback\" VALUES(1,2,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 13:02:22\");\nCREATE TABLE \"cart_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"quantity\" INTEGER DEFAULT NULL,\"purchased\" INTEGER DEFAULT 0,\"shipment_id\" INTEGER DEFAULT NULL REFERENCES \"shipment\" (\"id\"),\"payment_id\" INTEGER DEFAULT NULL REFERENCES \"payment\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"cart_item\" VALUES(1,1,2,1,0,1,1,\"2015-04-14 01:11:49\");\nINSERT INTO \"cart_item\" VALUES(2,2,2,1,1,2,3,\"2015-04-14 01:21:52\");\nINSERT INTO \"cart_item\" VALUES(3,2,2,1,0,3,4,\"2015-04-14 13:02:22\");\nCREATE TABLE \"payment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"order_iframe\" TEXT DEFAULT NULL,\"completed\" INTEGER DEFAULT 0,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"payment\" VALUES(1,\"\",0,\"2015-04-14 01:13:57\");\nINSERT INTO \"payment\" VALUES(2,NULL,0,\"2015-04-14 01:22:01\");\nINSERT INTO \"payment\" VALUES(3,\"\",1,\"2015-04-14 01:23:05\");\nINSERT INTO \"payment\" VALUES(4,\"\",0,\"2015-04-14 12:48:01\");\nCREATE TABLE \"bid\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"auction_id\" INTEGER DEFAULT NULL REFERENCES \"auction\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"amount\" INTEGER DEFAULT NULL,\"time\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"auction\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"expire_time\" INTEGER DEFAULT NULL,\"start_amount\" NUMERIC DEFAULT NULL,\"currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"reserve_amount\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"auction\" VALUES(1,2,NULL,NULL,2,NULL,\"2015-04-14 01:09:43\");\n'\nNow kill node 2 and clear it, assuming it has an error\nps aux | grep -ie node_2 | awk '{print $2}' | xargs kill -9\nrm -rf node_2\nsleep 2s\ncurl localhost:4001/raft?pretty\nNow try to rejoin node 1\n$GOPATH/bin/rqlite -join localhost:4001 -p 4002 node_2 &\nsleep 5s\ncurl localhost:4001/raft?pretty\nNow kill node 2 AGAIN and clear it, assuming it has an error\nps aux | grep -ie node_2 | awk '{print $2}' | xargs kill -9\nrm -rf node_2\nsleep 2s\ncurl localhost:4001/raft?pretty\nNow try to rejoin node 1\n$GOPATH/bin/rqlite -join localhost:4001 -p 4002 node_2 &\nsleep 5s\ncurl localhost:4001/raft?pretty\nAnd you'll see that the error is that it stalls on ATTEMPTING TO JOIN LEADER\n. The only way to get it working again is to delete node 1 completely!\nkills all the rqlite instances\nps aux | grep -ie rqlite | awk '{print $2}' | xargs kill -9\nrm -rf node_1 node_2 node_3\n```\n. I've been getting this error a lot, not sure what it means:\n2015/04/14 14:43:24 http: panic serving 127.0.0.1:53798: runtime error: invalid memory address or nil pointer dereference\ngoroutine 206 [running]:\nnet/http.func\u00b7011()\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1130 +0xbb\ngithub.com/otoolep/rqlite/server.(*Server).leaderRedirect(0xc20806c120, 0x7f3aae7a1bd0, 0xc208247c20, 0xc2082df040)\n    /root/.openmarket/testnet/db/src/github.com/otoolep/rqlite/server/server.go:616 +0x28b\ngithub.com/otoolep/rqlite/server.(*Server).writeHandler(0xc20806c120, 0x7f3aae7a1bd0, 0xc208247c20, 0xc2082df040)\n    /root/.openmarket/testnet/db/src/github.com/otoolep/rqlite/server/server.go:475 +0xe73\ngithub.com/otoolep/rqlite/server.*Server.(github.com/otoolep/rqlite/server.writeHandler)\u00b7fm(0x7f3aae7a1bd0, 0xc208247c20, 0xc2082df040)\n    /root/.openmarket/testnet/db/src/github.com/otoolep/rqlite/server/server.go:313 +0x45\nnet/http.HandlerFunc.ServeHTTP(0xc20802be20, 0x7f3aae7a1bd0, 0xc208247c20, 0xc2082df040)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1265 +0x41\ngithub.com/gorilla/mux.(*Router).ServeHTTP(0xc208032190, 0x7f3aae7a1bd0, 0xc208247c20, 0xc2082df040)\n    /root/.openmarket/testnet/db/src/github.com/gorilla/mux/mux.go:98 +0x297\nnet/http.serverHandler.ServeHTTP(0xc20800aea0, 0x7f3aae7a1bd0, 0xc208247c20, 0xc2082df040)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1703 +0x19a\nnet/http.(*conn).serve(0xc208247b80)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1204 +0xb57\ncreated by net/http.(*Server).Serve\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1751 +0x35e\norg.apache.http.NoHttpResponseException: localhost:4570 failed to respond\n. Thanks for pushing up this change @otoolep, it helps knowing that the leader was nil. \n\nquestionable network links\n\nMy current leader node is running off of time warner, so that could be the case, haha.\nI can definitely see how you could reach that nil-pointer reference though; if the leader is currently down(bad connection), and rqlite is smartly trying to do a leader reselection from candidates, it might not have chosen one yet, and thus the current leader during this period is nil, and no leader redirection works. Am I correct there? \nI'll make the leader one of my VPS nodes to try to avoid this problem.  I love the leader forwarding, it's extremely helpful btw.\nBefore we close this out, could you tell me, or direct me to some code, for how the leader reselection is done? Obviously the leader being nil means that there was some time gap between a leader going down, and one being reselected.\n. I now am getting your message based on your recent commit. \n2015/04/15 10:43:02 [ERROR] attempted leader redirection, but no leader available\nThis is what I see on the raft node when I get this message:\n\"leader\": \"\",\n    \"name\": \"5f28ee0\",\n    \"peers\": [\n        {\n            \"name\": \"1928598\",\n            \"connectionString\": \"\"\n        }\n    ],\n    \"state\": \"candidate\"\n. Unfortunately no, right now I have no -s parameters on any of the nodes. \n. Would it help if I made a script to try to reproduce the problem locally? \n. Here's another error I just got when trying to join: I'm just guessing its part of the same problem, but you could probably help me figure out whats going on.\n```\npanic: runtime error: slice bounds out of range\ngoroutine 10 [running]:\ngithub.com/goraft/raft.(Log).compact(0xc2080104d0, 0x7aa, 0x38d1, 0x0, 0x0)\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/log.go:592 +0x5a3\ngithub.com/goraft/raft.(server).processSnapshotRecoveryRequest(0xc208001c20, 0xc20826ca50, 0xc20826ca50)\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/server.go:1310 +0x3bc\ngithub.com/goraft/raft.(server).snapshotLoop(0xc208001c20)\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/server.go:881 +0x2c6\ngithub.com/goraft/raft.(server).loop(0xc208001c20)\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/server.go:611 +0x496\ngithub.com/goraft/raft.func\u00b7007()\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/server.go:470 +0x60\ncreated by github.com/goraft/raft.(*server).Start\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/server.go:471 +0x49e\ngoroutine 1 [chan receive]:\nmain.main()\n    /root/.openmarket/testnet/db/src/github.com/otoolep/rqlite/main.go:108 +0x62e\ngoroutine 6 [syscall]:\nos/signal.loop()\n    /root/.gvm/gos/go1.4.2/src/os/signal/signal_unix.go:21 +0x1f\ncreated by os/signal.init\u00b71\n    /root/.gvm/gos/go1.4.2/src/os/signal/signal_unix.go:27 +0x35\ngoroutine 7 [chan receive]:\ndatabase/sql.(*DB).connectionOpener(0xc208044000)\n    /root/.gvm/gos/go1.4.2/src/database/sql/sql.go:589 +0x4c\ncreated by database/sql.Open\n    /root/.gvm/gos/go1.4.2/src/database/sql/sql.go:452 +0x31c\ngoroutine 8 [IO wait]:\nnet.(pollDesc).Wait(0xc2080113a0, 0x72, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_poll_runtime.go:84 +0x47\nnet.(pollDesc).WaitRead(0xc2080113a0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_poll_runtime.go:89 +0x43\nnet.(netFD).accept(0xc208011340, 0x0, 0x7f39ef103a88, 0xc2082657c0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_unix.go:419 +0x40b\nnet.(TCPListener).AcceptTCP(0xc208038150, 0x51054e, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/tcpsock_posix.go:234 +0x4e\nnet/http.tcpKeepAliveListener.Accept(0xc208038150, 0x0, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1976 +0x4c\nnet/http.(Server).Serve(0xc20820a9c0, 0x7f39ef10a688, 0xc208038150, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1728 +0x92\nnet/http.(Server).ListenAndServe(0xc20820a9c0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1718 +0x154\ngithub.com/otoolep/rqlite/server.(*Server).ListenAndServe(0xc208066120, 0x7fff73e98531, 0x13, 0x0, 0x0)\n    /root/.openmarket/testnet/db/src/github.com/otoolep/rqlite/server/server.go:321 +0x145b\nmain.func\u00b7002()\n    /root/.openmarket/testnet/db/src/github.com/otoolep/rqlite/main.go:99 +0x42\ncreated by main.main\n    /root/.openmarket/testnet/db/src/github.com/otoolep/rqlite/main.go:100 +0x533\ngoroutine 23 [select]:\ngithub.com/goraft/raft.(server).send(0xc208001c20, 0x831ca0, 0xc20826ca50, 0x0, 0x0, 0x0, 0x0)\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/server.go:630 +0x327\ngithub.com/goraft/raft.(server).SnapshotRecoveryRequest(0xc208001c20, 0xc20826ca50, 0xc208262ec0)\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/server.go:1284 +0x48\ngithub.com/goraft/raft.func\u00b7004(0x7f39ef10a818, 0xc208268e60, 0xc208035ba0)\n    /root/.openmarket/testnet/db/src/github.com/goraft/raft/http_transporter.go:315 +0x2a1\nnet/http.HandlerFunc.ServeHTTP(0xc20802abf0, 0x7f39ef10a818, 0xc208268e60, 0xc208035ba0)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1265 +0x41\ngithub.com/gorilla/mux.(Router).ServeHTTP(0xc20803a190, 0x7f39ef10a818, 0xc208268e60, 0xc208035ba0)\n    /root/.openmarket/testnet/db/src/github.com/gorilla/mux/mux.go:98 +0x297\nnet/http.serverHandler.ServeHTTP(0xc20820a9c0, 0x7f39ef10a818, 0xc208268e60, 0xc208035ba0)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1703 +0x19a\nnet/http.(conn).serve(0xc208268d20)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1204 +0xb57\ncreated by net/http.(*Server).Serve\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1751 +0x35e\ngoroutine 24 [runnable]:\nnet.(pollDesc).Wait(0xc208011e90, 0x72, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_poll_runtime.go:84 +0x47\nnet.(pollDesc).WaitRead(0xc208011e90, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_poll_runtime.go:89 +0x43\nnet.(netFD).Read(0xc208011e30, 0xc2081cd000, 0x1000, 0x1000, 0x0, 0x7f39ef103a88, 0xc208252130)\n    /root/.gvm/gos/go1.4.2/src/net/fd_unix.go:242 +0x40f\nnet.(conn).Read(0xc208038180, 0xc2081cd000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/net.go:121 +0xdc\nnet/http.(liveSwitchReader).Read(0xc208268f48, 0xc2081cd000, 0x1000, 0x1000, 0xc00000000000000, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:214 +0xab\nio.(LimitedReader).Read(0xc208275c20, 0xc2081cd000, 0x1000, 0x1000, 0x95f600, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/io/io.go:408 +0xce\nbufio.(Reader).fill(0xc20820b140)\n    /root/.gvm/gos/go1.4.2/src/bufio/bufio.go:97 +0x1ce\nbufio.(Reader).ReadSlice(0xc20820b140, 0xa, 0x0, 0x0, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/bufio/bufio.go:295 +0x257\nbufio.(Reader).ReadLine(0xc20820b140, 0x0, 0x0, 0x0, 0xc207fdd100, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/bufio/bufio.go:324 +0x62\nnet/textproto.(Reader).readLineSlice(0xc20822e2a0, 0x0, 0x0, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/textproto/reader.go:55 +0x9e\nnet/textproto.(Reader).ReadLine(0xc20822e2a0, 0x0, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/textproto/reader.go:36 +0x4f\nnet/http.ReadRequest(0xc20820b140, 0xc208034750, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/http/request.go:598 +0xcb\nnet/http.(conn).readRequest(0xc208268f00, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:586 +0x26f\nnet/http.(conn).serve(0xc208268f00)\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1162 +0x69e\ncreated by net/http.(Server).Serve\n    /root/.gvm/gos/go1.4.2/src/net/http/server.go:1751 +0x35e\ngoroutine 21 [IO wait]:\nnet.(pollDesc).Wait(0xc208010ed0, 0x72, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_poll_runtime.go:84 +0x47\nnet.(pollDesc).WaitRead(0xc208010ed0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_poll_runtime.go:89 +0x43\nnet.(netFD).Read(0xc208010e70, 0xc20825e000, 0x1000, 0x1000, 0x0, 0x7f39ef103a88, 0xc2082647d8)\n    /root/.gvm/gos/go1.4.2/src/net/fd_unix.go:242 +0x40f\nnet.(conn).Read(0xc208038028, 0xc20825e000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/net.go:121 +0xdc\nnet/http.noteEOFReader.Read(0x7f39ef105740, 0xc208038028, 0xc2080465d8, 0xc20825e000, 0x1000, 0x1000, 0xc208030680, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:1270 +0x6e\nnet/http.(noteEOFReader).Read(0xc208275200, 0xc20825e000, 0x1000, 0x1000, 0xc208012000, 0x0, 0x0)\n    :125 +0xd4\nbufio.(Reader).fill(0xc20820a840)\n    /root/.gvm/gos/go1.4.2/src/bufio/bufio.go:97 +0x1ce\nbufio.(Reader).Peek(0xc20820a840, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/bufio/bufio.go:132 +0xf0\nnet/http.(persistConn).readLoop(0xc208046580)\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:842 +0xa4\ncreated by net/http.(*Transport).dialConn\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:660 +0xc9f\ngoroutine 19 [select]:\nnet/http.(persistConn).readLoop(0xc208046370)\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:928 +0x9ce\ncreated by net/http.(Transport).dialConn\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:660 +0xc9f\ngoroutine 17 [syscall, locked to thread]:\nruntime.goexit()\n    /root/.gvm/gos/go1.4.2/src/runtime/asm_amd64.s:2232 +0x1\ngoroutine 14 [IO wait]:\nnet.(pollDesc).Wait(0xc208010b50, 0x72, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_poll_runtime.go:84 +0x47\nnet.(pollDesc).WaitRead(0xc208010b50, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/fd_poll_runtime.go:89 +0x43\nnet.(netFD).Read(0xc208010af0, 0xc20800f000, 0x1000, 0x1000, 0x0, 0x7f39ef103a88, 0xc20802b3a8)\n    /root/.gvm/gos/go1.4.2/src/net/fd_unix.go:242 +0x40f\nnet.(conn).Read(0xc2080380d0, 0xc20800f000, 0x1000, 0x1000, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/net.go:121 +0xdc\nnet/http.noteEOFReader.Read(0x7f39ef105740, 0xc2080380d0, 0xc208046318, 0xc20800f000, 0x1000, 0x1000, 0xc208030640, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:1270 +0x6e\nnet/http.(noteEOFReader).Read(0xc20801eaa0, 0xc20800f000, 0x1000, 0x1000, 0xc208012000, 0x0, 0x0)\n    :125 +0xd4\nbufio.(Reader).fill(0xc208032c60)\n    /root/.gvm/gos/go1.4.2/src/bufio/bufio.go:97 +0x1ce\nbufio.(Reader).Peek(0xc208032c60, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0)\n    /root/.gvm/gos/go1.4.2/src/bufio/bufio.go:132 +0xf0\nnet/http.(persistConn).readLoop(0xc2080462c0)\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:842 +0xa4\ncreated by net/http.(*Transport).dialConn\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:660 +0xc9f\ngoroutine 15 [select]:\nnet/http.(persistConn).writeLoop(0xc2080462c0)\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:945 +0x41d\ncreated by net/http.(Transport).dialConn\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:661 +0xcbc\ngoroutine 20 [select]:\nnet/http.(persistConn).writeLoop(0xc208046370)\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:945 +0x41d\ncreated by net/http.(Transport).dialConn\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:661 +0xcbc\ngoroutine 22 [select]:\nnet/http.(persistConn).writeLoop(0xc208046580)\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:945 +0x41d\ncreated by net/http.(Transport).dialConn\n    /root/.gvm/gos/go1.4.2/src/net/http/transport.go:661 +0xcbc\n```\n. Damn, I've been unable to reproduce this locally, I'll keep trying a bit more.\nI was able to replicate the other other problem I've been having though, the  \"error\": \"raft.Server: Not current leader\" problem, #40 .\n. Okay I've got it! I've reproduced it locally. A problem seems to be that when a node goes down, the others stay candidates for a really long time.\nHow it works is:\n- Start up 2 nodes, do some writes to the leader\n- Take down the leader node 1\n- Keep writing to node 2 with leader redirection\n- get the error message [ERROR] attempted leader redirection, but no leader available\nThis happens about half the time I run it. \n``` sh\nexport GOPATH=$PWD\nStartup 2 nodes\n$GOPATH/bin/rqlite node_1 &\nsleep 2s\n$GOPATH/bin/rqlite -join localhost:4001 -p 4002 node_2 &\nsleep 2s\nDo some big inserts to node 1\ncurl -L -XPOST localhost:4001/db?pretty -d 'CREATE TABLE \"user\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"email\" TEXT DEFAULT NULL,\"password_encrypted\" TEXT DEFAULT NULL,\"name\" TEXT DEFAULT NULL,\"authenticated\" INTEGER DEFAULT NULL,\"email_code\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (email));\nINSERT INTO \"user\" VALUES(1,\"happydooby@gmail.com\",\"zWyTu4eFKjXgNedQyjlA1WacfgcluFDGtxFmzU6iYL4G6jPXFqK1K3xuw+afjqzA\",NULL,\"true\",NULL,\"2015-04-14 00:29:16\");\nINSERT INTO \"user\" VALUES(2,\"tchoulihan@gmail.com\",\"mYmiuWZaS8bndTItTFYbe0lTbUOwoll1Vg23qtdBiEVSlQJpm7Ylqxk6kzptP1wh\",\"derp\",\"true\",NULL,\"2015-04-14 01:20:58\");\nCREATE TABLE \"seller\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"shop_name\" TEXT DEFAULT NULL,\"bitmerchant_address\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (user_id));\nINSERT INTO \"seller\" VALUES(1,1,\"garg\",\"http://96.28.13.51:4567/\",\"2015-04-14 00:29:16\");\nCREATE TABLE \"product\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"seller_id\" INTEGER NOT NULL  DEFAULT NULL REFERENCES \"seller\" (\"id\"),\"category_id\" INTEGER DEFAULT NULL REFERENCES \"category\" (\"id\"),\"buy\" INTEGER DEFAULT NULL,\"auction\" INTEGER DEFAULT NULL,\"quantity\" INTEGER DEFAULT NULL,\"title\" TEXT DEFAULT NULL,\"processing_time_span_id\" INTEGER DEFAULT NULL REFERENCES \"time_span\" (\"id\"),\"physical\" INTEGER DEFAULT 0,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product\" VALUES(1,1,3,NULL,NULL,NULL,\"test_item\",NULL,0,\"2015-04-14 00:30:45\");\nINSERT INTO \"product\" VALUES(2,1,19,NULL,0,10,\"Pink frosted sprinkled donut\",3,0,\"2015-04-14 01:02:24\");\nINSERT INTO \"product\" VALUES(3,1,NULL,NULL,NULL,NULL,NULL,NULL,0,\"2015-04-14 14:09:32\");\nINSERT INTO \"product\" VALUES(4,1,18,NULL,0,NULL,\"A tasty red donut\",NULL,0,\"2015-04-14 14:10:00\");\nINSERT INTO \"product\" VALUES(5,1,25,NULL,0,5,\"A Chocalatey donut\",3,0,\"2015-04-14 14:10:45\");\nCREATE TABLE \"shipment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"address_id\" INTEGER DEFAULT NULL REFERENCES \"address\" (\"id\"),\"tracking_url\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"shipment\" VALUES(1,1,NULL,\"2015-04-14 01:14:21\");\nINSERT INTO \"shipment\" VALUES(2,2,NULL,\"2015-04-14 01:22:16\");\nINSERT INTO \"shipment\" VALUES(3,2,NULL,\"2015-04-14 13:02:23\");\nCREATE TABLE \"review\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"stars\" INTEGER DEFAULT NULL,\"headline\" TEXT DEFAULT NULL,\"text_html\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id, user_id));\nINSERT INTO \"review\" VALUES(1,2,1,3,\"Great donut\",\"Would eat again. 10/10&ltsemicolonbr&gtsemicolon\",\"2015-04-14 14:19:43\");\nCREATE TABLE \"address\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"full_name\" TEXT DEFAULT NULL,\"address_line_1\" TEXT DEFAULT NULL,\"address_line_2\" TEXT DEFAULT NULL,\"city\" TEXT DEFAULT NULL,\"state\" TEXT DEFAULT NULL,\"zip\" INTEGER DEFAULT NULL,\"country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"default_\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"address\" VALUES(1,1,\"fsdafasdf\",\"asdf\",\"asdf\",\"asdf\",\"fdsa\",1235,7,0,\"2015-04-14 01:14:18\");\nINSERT INTO \"address\" VALUES(2,2,\"fdsafd\",\"asdf\",\"asdf\",\"asdf\",\"asdf\",123,8,0,\"2015-04-14 01:22:12\");\nCREATE TABLE \"feedback\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"cart_item_id\" INTEGER DEFAULT NULL REFERENCES \"cart_item\" (\"id\"),\"stars\" INTEGER DEFAULT NULL,\"arrived_on_time\" INTEGER DEFAULT NULL,\"correctly_described\" INTEGER DEFAULT NULL,\"prompt_service\" INTEGER DEFAULT NULL,\"comments\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"feedback\" VALUES(1,2,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 13:02:22\");\nCREATE TABLE \"cart_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"quantity\" INTEGER DEFAULT NULL,\"purchased\" INTEGER DEFAULT 0,\"shipment_id\" INTEGER DEFAULT NULL REFERENCES \"shipment\" (\"id\"),\"payment_id\" INTEGER DEFAULT NULL REFERENCES \"payment\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"cart_item\" VALUES(1,1,2,1,0,1,1,\"2015-04-14 01:11:49\");\nINSERT INTO \"cart_item\" VALUES(2,2,2,1,1,2,3,\"2015-04-14 01:21:52\");\nINSERT INTO \"cart_item\" VALUES(3,2,2,1,0,3,4,\"2015-04-14 13:02:22\");\nCREATE TABLE \"payment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"order_iframe\" TEXT DEFAULT NULL,\"completed\" INTEGER DEFAULT 0,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"payment\" VALUES(1,\"\",0,\"2015-04-14 01:13:57\");\nINSERT INTO \"payment\" VALUES(2,NULL,0,\"2015-04-14 01:22:01\");\nINSERT INTO \"payment\" VALUES(3,\"\",1,\"2015-04-14 01:23:05\");\nINSERT INTO \"payment\" VALUES(4,\"\",0,\"2015-04-14 12:48:01\");\nCREATE TABLE \"bid\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"auction_id\" INTEGER DEFAULT NULL REFERENCES \"auction\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"amount\" INTEGER DEFAULT NULL,\"time\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"auction\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"expire_time\" INTEGER DEFAULT NULL,\"start_amount\" NUMERIC DEFAULT NULL,\"currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"reserve_amount\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"auction\" VALUES(1,2,NULL,NULL,2,NULL,\"2015-04-14 01:09:43\");\n'\ncurl -L -XPOST localhost:4001/db?pretty -d 'INSERT INTO \"auction\" VALUES(2,4,NULL,NULL,2,NULL,\"2015-04-14 14:10:26\");\nINSERT INTO \"auction\" VALUES(3,5,NULL,NULL,3,NULL,\"2015-04-14 14:11:14\");\nCREATE TABLE \"currency\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"desc\" TEXT DEFAULT NULL,\"iso\" TEXT DEFAULT NULL,\"unicode\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"currency\" VALUES(1,\"Bitcoin\",\"BTC\",\"?\",\"2015-04-14 00:27:36\");\nINSERT INTO \"currency\" VALUES(2,\"United States Dollar\",\"USD\",\"$\",\"2015-04-14 00:27:36\");\nINSERT INTO \"currency\" VALUES(3,\"Euro\",\"EUR\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(4,\"British Pound Sterling\",\"GBP\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(5,\"Australian Dollar\",\"AUD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(6,\"Brazilian Real\",\"BRL\",\"R$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(7,\"Canadian Dollar\",\"CAD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(8,\"Swiss Franc\",\"CHF\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(9,\"Chinese Yuan\",\"CNY\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(10,\"Hong Kong Dollar\",\"HKD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(11,\"Indonesian Rupiah\",\"IDR\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(12,\"Israeli New Sheqel\",\"ILS\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(13,\"Mexican Peso\",\"MXN\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(14,\"Norwegian Krone\",\"NOK\",\"kr\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(15,\"New Zealand Dollar\",\"NZD\",\"$\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(16,\"Polish Zloty\",\"PLN\",\"z\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(17,\"Romanian Leu\",\"RON\",\"leu\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(18,\"Russian Ruble\",\"RUB\",\"?\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(19,\"Swedish Krona\",\"SEK\",\"kr\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(20,\"Singapore Dollar\",\"SGD\",\"$\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(21,\"Turkish Lira\",\"TRY\",\"?\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(22,\"South African Rand\",\"ZAR\",\"R\",\"2015-04-14 00:27:39\");\nCREATE TABLE \"country\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"country_code\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"country\" VALUES(1,\"United States\",\"US\",\"2015-04-14 00:27:39\");\nINSERT INTO \"country\" VALUES(2,\"Afghanistan\",\"AF\",\"2015-04-14 00:27:39\");\n'\nNow take down node 1, and write to node 2 only\nnode 2 seems to stay a candidate, making its writes fail and getting the\nno leader error message\nsleep 2s\nps aux | grep -ie node_1 | awk '{print $2}' | xargs kill -9\nrm -rf node_1\nsleep 2s\ncurl localhost:4002/raft?pretty\ncurl -L -XPOST localhost:4002/db?pretty -d 'INSERT INTO \"country\" VALUES(3,\"\ufffdland Islands\",\"AX\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(4,\"Albania\",\"AL\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(5,\"Algeria\",\"DZ\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(6,\"American Samoa\",\"AS\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(7,\"Andorra\",\"AD\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(8,\"Angola\",\"AO\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(9,\"Anguilla\",\"AI\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(10,\"Antarctica\",\"AQ\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(11,\"Antigua And Barbuda\",\"AG\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(12,\"Argentina\",\"AR\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(13,\"Armenia\",\"AM\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(14,\"Aruba\",\"AW\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(15,\"Australia\",\"AU\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(16,\"Austria\",\"AT\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(17,\"Azerbaijan\",\"AZ\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(18,\"Bahamas\",\"BS\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(19,\"Bahrain\",\"BH\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(20,\"Bangladesh\",\"BD\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(21,\"Barbados\",\"BB\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(22,\"Belarus\",\"BY\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(23,\"Belgium\",\"BE\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(24,\"Belize\",\"BZ\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(25,\"Benin\",\"BJ\",\"2015-04-14 00:27:42\");\nCREATE TABLE \"review_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"review_id\" INTEGER DEFAULT NULL REFERENCES \"review\" (\"id\"),\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (user_id, review_id));\nINSERT INTO \"review_vote\" VALUES(1,1,1,\"up\",\"2015-04-14 14:20:26\");\nCREATE TABLE \"review_comment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"review_id\" INTEGER DEFAULT NULL REFERENCES \"review\" (\"id\"),\"comment\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"question\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"answer\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"question_id\" INTEGER DEFAULT NULL REFERENCES \"question\" (\"id\"),\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"question_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"question_id\" INTEGER DEFAULT NULL REFERENCES \"question\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL,\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"answer_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"answer_id\" INTEGER DEFAULT NULL REFERENCES \"answer\" (\"id\"),\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"category\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"parent\" INTEGER DEFAULT NULL,\"is_physical\" INTEGER DEFAULT true,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"category\" VALUES(1,\"Animals & Pet Supplies\",NULL,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(2,\"Live Animals\",1,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(3,\"Pet Supplies\",1,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(4,\"Bird Supplies\",3,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(5,\"Bird Cage Accessories\",4,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(6,\"Bird Cage Food & Water Dishes\",5,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(7,\"Bird Cages & Stands\",4,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(8,\"Bird Food\",4,\"true\",\"2015-04-14 00:27:30\");\n'\ncurl -L -XPOST localhost:4002/db?pretty -d 'INSERT INTO \"category\" VALUES(9,\"Bird Gyms & Playstands\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(10,\"Bird Ladders & Perches\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(11,\"Bird Toys\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(12,\"Bird Treats\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(13,\"Cat Supplies\",3,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(14,\"Cat Apparel\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(15,\"Cat Beds\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(16,\"Cat Food\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(17,\"Cat Furniture\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(18,\"Cat Litter\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(19,\"Cat Litter Box Mats\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(20,\"Cat Litter Boxes\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(21,\"Cat Toys\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(22,\"Cat Treats\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(23,\"Dog Supplies\",3,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(24,\"Dog Apparel\",23,\"true\",\"2015-04-14 00:27:33\");\nINSERT INTO \"category\" VALUES(25,\"Dog Beds\",23,\"true\",\"2015-04-14 00:27:33\");\nCREATE TABLE \"wishlist_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"purchased\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"wishlist_item\" VALUES(1,1,2,0,\"2015-04-14 01:11:47\");\nCREATE TABLE \"login\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"session_id\" TEXT DEFAULT NULL,\"time_\" INTEGER DEFAULT NULL,\"expire_time\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"login\" VALUES(1,1,\"1sdfgs5kqivfofa2tum79g4301469s41h3e6d2qquntkf9umr2oh\",1428971430539,1428974638358,\"2015-04-14 00:30:30\");\nINSERT INTO \"login\" VALUES(2,1,\"1cmefbba3hk8kfbjl74kki02nav3h23fuj6jpod2sfp4ratjm9sp\",1428973901740,1428974447001,\"2015-04-14 01:11:42\");\nINSERT INTO \"login\" VALUES(3,2,\"1opvct1n4h7tlk8r1onpkoup8pi8b9duhfo3i8a4s7tcb6rtj38b\",1428974487159,1428978087159,\"2015-04-14 01:21:27\");\nINSERT INTO \"login\" VALUES(4,1,\"bhmv5etav7rbhhk3kur835u41hb2veg0av6gs00mqm964u90j5j\",1428974645457,1428978245457,\"2015-04-14 01:24:05\");\nINSERT INTO \"login\" VALUES(5,2,\"q0flrr0bvh7mkr8vnvktshj1ago6dsc7icdq25tdr0ok3kfrvhu\",1429015664731,1429019264731,\"2015-04-14 13:02:22\");\nINSERT INTO \"login\" VALUES(6,1,\"1cd6q1o14i65609a3dqr85kk1e91ulacj6l4b6di5tt5l8mfq84e\",1429015923407,1429016564440,\"2015-04-14 13:02:23\");\nINSERT INTO \"login\" VALUES(7,1,\"1g0jknpm2ad6n0skkjh9je6120qrogj4d5b88hvf5h9lt2go2pui\",1429016579502,1429020179502,\"2015-04-14 13:06:04\");\nINSERT INTO \"login\" VALUES(8,1,\"1v5fr7bm6c5dq5tahdujdon0u5ujpecft4ranpr8rml722ch9e1o\",1429016676795,1429016685373,\"2015-04-14 13:06:04\");\nINSERT INTO \"login\" VALUES(9,1,\"4vjp9v6qj14lpt4fitkg5vm5p72pvdn14hlp5m2s9ml8nka6lc0\",1429016793426,1429016802385,\"2015-04-14 13:06:33\");\nINSERT INTO \"login\" VALUES(10,1,\"ci0pm52vg36kat3p9821m51rptrbdi3lji2lg8a0u3audkc22r\",1429016822694,1429017095173,\"2015-04-14 13:38:54\");\nINSERT INTO \"login\" VALUES(11,1,\"1nt8r0qira5qvntv11iuc6udvjjtmitnbnuielmrouqabu7ua19m\",1429017113246,1429020713246,\"2015-04-14 13:38:54\");\nINSERT INTO \"login\" VALUES(12,1,\"1mcse38fgklq0odhus34e7g1gdbvu2rtpcivvu6k0f37vdsoo7oj\",1429021175749,1429024775749,\"2015-04-14 14:19:36\");\nCREATE TABLE \"product_price\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"price\" INTEGER DEFAULT NULL,\"native_currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"variable_price\" INTEGER DEFAULT NULL,\"price_select\" INTEGER DEFAULT NULL,\"price_1\" INTEGER DEFAULT NULL,\"price_2\" INTEGER DEFAULT NULL,\"price_3\" INTEGER DEFAULT NULL,\"price_4\" INTEGER DEFAULT NULL,\"price_5\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"product_price\" VALUES(1,2,2.5,2,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 01:07:20\");\nINSERT INTO \"product_price\" VALUES(2,4,1.99,2,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 14:10:26\");\nINSERT INTO \"product_price\" VALUES(3,5,1.96,3,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 14:11:14\");\nCREATE TABLE \"product_group\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_group_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_group\" INTEGER DEFAULT NULL REFERENCES \"product_group\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_page\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"product_html\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"product_page\" VALUES(1,2,\"&ltsemicolonh1 style=&quotsemicolontext-align: centersemicolon&quotsemicolon&gtsemicolonThe best donut ever made&ltsemicolon/h1&gtsemicolon&ltsemicolonblockquote&gtsemicolon&ltsemicolonp style=&quotsemicolon text-align: leftsemicolon&quotsemicolon&gtsemicolon&ltsemicolonspan style=&quotsemicolonfont-weight: boldsemicolon&quotsemicolon&gtsemicolonSaid everyone&ltsemicolon/span&gtsemicolon&ltsemicolonbr&gtsemicolon&ltsemicolon/p&gtsemicolon&ltsemicolon/blockquote&gtsemicolon\",\"2015-04-14 14:06:56\");\nCREATE TABLE \"product_picture\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"url\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product_picture\" VALUES(1,2,1,\"http://vignette1.wikia.nocookie.net/smosh/images/b/b2/Pink_frosted_sprinkled_donut.jpg/revision/latest?cb=20120101131536\",\"2015-04-14 14:06:16\");\nINSERT INTO \"product_picture\" VALUES(2,4,1,\"http://jennyfunderburke.com/blog/wp-content/uploads/2011/08/donut.jpg\",\"2015-04-14 14:10:07\");\nINSERT INTO \"product_picture\" VALUES(3,5,1,\"http://www.withsprinklesontop.net/wp-content/uploads/2012/01/DSC_0406x900.jpg\",\"2015-04-14 14:11:36\");\nCREATE TABLE \"tag\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"title\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_tag\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"tag_id\" INTEGER DEFAULT NULL REFERENCES \"tag\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"time_type\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"time_type\" VALUES(1,\"business days\",\"2015-04-14 00:27:35\");\nINSERT INTO \"time_type\" VALUES(2,\"weeks\",\"2015-04-14 00:27:35\");\nCREATE TABLE \"time_span\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"time_type_id\" INTEGER DEFAULT NULL REFERENCES \"time_type\" (\"id\"),\"min\" INTEGER DEFAULT NULL,\"max\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"time_span\" VALUES(1,1,1,2,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(2,1,1,3,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(3,1,3,5,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(4,2,1,2,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(5,2,2,3,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(6,2,3,4,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(7,2,4,6,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(8,2,6,8,\"2015-04-14 00:27:36\");\nCREATE TABLE \"shipping\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"from_country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nCREATE TABLE \"shipping_cost\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"shipping_id\" INTEGER DEFAULT NULL REFERENCES \"shipping\" (\"id\"),\"to_country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"price\" INTEGER DEFAULT NULL,\"native_currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_bullet\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product_bullet\" VALUES(1,2,1,\"This is a Pink frosted sprinkled donut\",\"2015-04-14 14:05:51\");\nINSERT INTO \"product_bullet\" VALUES(2,2,2,\"It has sprinkles\",\"2015-04-14 14:05:57\");\nINSERT INTO \"product_bullet\" VALUES(3,2,3,\"It has frosting\",\"2015-04-14 14:06:12\");\nCREATE TABLE \"payment_type\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"payment_info\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"seller_id\" INTEGER DEFAULT NULL REFERENCES \"seller\" (\"id\"),\"payment_type_id\" INTEGER DEFAULT NULL REFERENCES \"payment_type\" (\"id\"),\"payment_info_location\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"message\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"from_user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"to_user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"subject\" TEXT DEFAULT NULL,\"html\" TEXT DEFAULT NULL,\"message_status_id\" INTEGER DEFAULT NULL REFERENCES \"message_status\" (\"id\"),\"created_at\" INTEGER DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"message_status\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"title\" INTEGER DEFAULT NULL,\"created_at\" INTEGER DEFAULT CURRENT_TIMESTAMP);\nDELETE FROM sqlite_sequence;\nINSERT INTO \"sqlite_sequence\" VALUES(\"category\",25);\nINSERT INTO \"sqlite_sequence\" VALUES(\"time_type\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"time_span\",8);\nINSERT INTO \"sqlite_sequence\" VALUES(\"currency\",22);\nINSERT INTO \"sqlite_sequence\" VALUES(\"country\",25);\nINSERT INTO \"sqlite_sequence\" VALUES(\"user\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"seller\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"login\",12);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product\",5);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_price\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"auction\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"wishlist_item\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"cart_item\",3);\n'\ncurl -L -XPOST localhost:4002/db?pretty -d 'INSERT INTO \"sqlite_sequence\" VALUES(\"payment\",4);\nINSERT INTO \"sqlite_sequence\" VALUES(\"address\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"shipment\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"feedback\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_bullet\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_picture\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_page\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"review\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"review_vote\",1);\nCREATE VIEW time_span_view AS SELECT time_span.id, min || \"-\" || max || \" \" || name as time_span_string FROM time_span left join time_type on time_span.time_type_id = time_type.id;\nCREATE VIEW product_view AS SELECT product.id,seller_id,shop_name,category_id,buy,auction,quantity,title,processing_time_span_id,time_span_string,price,native_currency_id,currency.iso as price_iso,variable_price,price_select,price_1,price_2,price_3,price_4,price_5,expire_time,start_amount,reserve_amount,physical,currency_id as auction_currency_id,auction_currency.iso as auction_currency_iso,shipping.id as shipping_id, from_country_id, from_country.name as from_country, count(review.id) as number_of_reviews, ifnull(avg(review.stars),0) as review_avg, product_html FROM product left join time_span_view on product.processing_time_span_id = time_span_view.id left join product_page on product.id = product_page.product_id left join product_price on product.id = product_price.product_id left join auction on product.id = auction.product_id left join currency on product_price.native_currency_id = currency.id left join currency as auction_currency on auction.currency_id = auction_currency.id left join shipping on product.id = shipping.product_id left join country as from_country on shipping.from_country_id = from_country.id left join review on review.product_id = product.id left join seller on product.seller_id = seller.id  group by product.id;\nCREATE VIEW product_thumbnail_view AS SELECT product.id as product_id,title,seller_id,category_id,shop_name, count(review.id) as number_of_reviews, ifnull(avg(review.stars),0) as review_avg, auction,CASE WHEN auction=\"1\"    THEN (select max(bid.amount) from bid where bid.auction_id = auction.id)    ELSE max(price) END as price, currency.iso as price_iso FROM product inner join currency on product_price.native_currency_id = currency.id left join seller on product.seller_id = seller.id left join auction on product.id = auction.product_id left join review on review.product_id = product.id left join product_price on product_price.product_id = product.id group by product.id;\nCREATE VIEW category_tree_view AS  SELECT t1.name AS name_1, t1.id AS id_1,t2.name AS name_2, t2.id AS id_2,t3.name AS name_3, t3.id AS id_3,t4.name AS name_4, t4.id AS id_4,t5.name AS name_5, t5.id AS id_5,t6.name AS name_6, t6.id AS id_6,t7.name AS name_7, t7.id AS id_7 FROM category AS t1 LEFT JOIN category AS t2 ON t2.parent = t1.id LEFT JOIN category AS t3 ON t3.parent = t2.id LEFT JOIN category AS t4 ON t4.parent = t3.id LEFT JOIN category AS t5 ON t5.parent = t4.id LEFT JOIN category AS t6 ON t6.parent = t5.id LEFT JOIN category AS t7 ON t7.parent = t6.id where t1.parent IS NULL;\nCREATE VIEW browse_view AS select distinct id_1, id_2, name_1, name_2 from category_tree_view;\nCREATE VIEW review_view AS select review.id,product_id,review.user_id,user.name as user_name, stars,headline,text_html, review.created_at, SUM(vote) as votes_sum, count(review_vote.id) as votes_count from review left join review_vote on review.id = review_vote.review_id left join user on review.user_id = user.id group by review.id;\nCREATE VIEW feedback_view AS select feedback.id,cart_item_id,cart_item.product_id,cart_item.user_id,stars,arrived_on_time,correctly_described,prompt_service,comments,feedback.created_at from feedback left join cart_item on feedback.cart_item_id = cart_item.id;\nCREATE VIEW question_view AS select question.id, question.user_id, user.name as user_name, product_id, text, question.created_at, SUM(vote) as votes_sum, count(question_vote.id) as votes_count from question left join question_vote on question.id = question_vote.question_id left join user on question.user_id = user.id group by question.id;\nCREATE VIEW answer_view AS select answer.id, answer.user_id, user.name as user_name,question_id, text, answer.created_at, SUM(case when vote = 1 then 1 when vote = -1 then -1 else 0 end) as votes_sum, count(answer_vote.id) as votes_count from answer left join answer_vote on answer.id = answer_vote.answer_id left join user on answer.user_id = user.id group by answer.id;\nCREATE VIEW shipping_cost_view AS select shipping_cost.id,shipping_id, to_country_id, num_,price, name as to_country,iso as shipping_cost_iso from shipping_cost left join country on shipping_cost.to_country_id = country.id left join currency on shipping_cost.native_currency_id = currency.id;\nCREATE VIEW cart_view AS select cart_item.id,cart_item.user_id,product.seller_id,cart_item.product_id,cart_item.quantity,purchased,cart_item.created_at,title, url,product_price.price,iso ,cart_item.shipment_id,cart_item.payment_id from cart_item left join product_picture on cart_item.product_id = product_picture.product_id and num_ = 1 left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join currency on product_price.native_currency_id = currency.id where purchased = 0;\nCREATE VIEW cart_group AS select cart_item.user_id,seller_id, shop_name, max(time_span_string) as time_span_string, sum(product_price.pricecart_item.quantity) as cost,max(iso) as iso,IFNULL(max(shipping_cost.price),0) as shipping,sum(product_price.pricecart_item.quantity) + IFNULL(max(shipping_cost.price),0) as checkout_total ,shipment_id, address.full_name,address.address_line_1,address.address_line_2,address.city,address.state,address.zip,address.country_id,payment_id,purchased, bitmerchant_address,order_iframe, cart_item.created_at from cart_item left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join shipping on cart_item.product_id = shipping.product_id left join shipping_cost on shipping.id = shipping_cost.shipping_id left join seller on product.seller_id = seller.id left join time_span_view on product.processing_time_span_id = time_span_view.id left join currency on product_price.native_currency_id = currency.id left join shipment on cart_item.shipment_id = shipment.id left join address on shipment.address_id = address.id left join payment on cart_item.payment_id = payment.id where purchased = 0 group by cart_item.user_id, product.seller_id;\nCREATE VIEW order_group AS select cart_item.user_id,seller_id, shop_name, max(time_span_string) as time_span_string, sum(product_price.pricecart_item.quantity) as cost,max(iso) as iso,IFNULL(max(shipping_cost.price),0) as shipping,sum(product_price.pricecart_item.quantity) + IFNULL(max(shipping_cost.price),0) as checkout_total ,shipment_id, shipment.tracking_url, address.full_name,address.address_line_1,address.address_line_2,address.city,address.state,address.zip,address.country_id,payment_id,purchased, completed, order_iframe,payment.created_at from cart_item left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join shipping on cart_item.product_id = shipping.product_id left join shipping_cost on shipping.id = shipping_cost.shipping_id left join seller on product.seller_id = seller.id left join time_span_view on product.processing_time_span_id = time_span_view.id left join currency on product_price.native_currency_id = currency.id left join shipment on cart_item.shipment_id = shipment.id left join address on shipment.address_id = address.id left join payment on cart_item.payment_id = payment.id where purchased = 1 group by cart_item.user_id, payment_id;\nCREATE VIEW order_view AS select cart_item.id,cart_item.user_id,product.seller_id,cart_item.product_id,cart_item.quantity,purchased,cart_item.created_at,title, url,product_price.price,iso ,cart_item.shipment_id,cart_item.payment_id from cart_item left join product_picture on cart_item.product_id = product_picture.product_id and num_ = 1 left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join currency on product_price.native_currency_id = currency.id where purchased = 1;\nCREATE VIEW address_view AS select address.id,user_id,full_name,address_line_1,address_line_2,city,state,zip,country_id,default_,country.name as country_name,address.created_at from address left join country on address.country_id = country.id;\n'\ncurl localhost:4002/raft?pretty\nkills all the rqlite instances\nps aux | grep -ie rqlite | awk '{print $2}' | xargs kill -9\nrm -rf node_1 node_2\n```\n. Thanks a ton @otoolep , I checked this one as well, and I don't have the candidate problem in a 3 node cluster. It correctly shows my 2nd node as the leader when I take the 1st one down.\n. Another different error message I just got:\n\"failures\": [\n        {\n            \"sql\": \"INSERT INTO Cart_item...\",\n            \"error\": \"command failed to be committed due to node failure\"\n        }\n    ]\nI tried the action a second time, directly after, and it went through smoothly.\n. It might be a network issue as I said in another post. I'll move my leader to a more reliable node and see if I run into the error again. That's obviously not any problem with rqlite.\nIf no writes can be made while snapshotting though, that might be a problem for me. I have user interface elements in my project that make it necessary that those writes go through. Would it be possible to stall any writes made while snapshotting, and write them after the snapshot is made?\n. I'm also getting the \"error\": \"raft.Server: Not current leader\"  message sometimes when using -L, and both connections are solid.\n. Here's a script that replicates this problem. The explanation for what it does is in the comments. Basically it just alternates XPOSTS -L between two nodes. \nThe relevant error message is: \"error\": \"raft.Server: Not current leader\"\nI ran this script 10 times, and it gets this error about 75% of the time.\n``` sh\ninstall rqlite\ngo get github.com/otoolep/rqlite\nexport GOPATH=$PWD\nStartup 2 nodes\n$GOPATH/bin/rqlite node_1 &\nsleep 2s\n$GOPATH/bin/rqlite -join localhost:4001 -p 4002 node_2 &\nsleep 2s\nDo some big inserts, alternating XPOSTS between the two nodes\ncurl -L -XPOST localhost:4001/db?pretty -d 'CREATE TABLE \"user\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"email\" TEXT DEFAULT NULL,\"password_encrypted\" TEXT DEFAULT NULL,\"name\" TEXT DEFAULT NULL,\"authenticated\" INTEGER DEFAULT NULL,\"email_code\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (email));\nINSERT INTO \"user\" VALUES(1,\"happydooby@gmail.com\",\"zWyTu4eFKjXgNedQyjlA1WacfgcluFDGtxFmzU6iYL4G6jPXFqK1K3xuw+afjqzA\",NULL,\"true\",NULL,\"2015-04-14 00:29:16\");\nINSERT INTO \"user\" VALUES(2,\"tchoulihan@gmail.com\",\"mYmiuWZaS8bndTItTFYbe0lTbUOwoll1Vg23qtdBiEVSlQJpm7Ylqxk6kzptP1wh\",\"derp\",\"true\",NULL,\"2015-04-14 01:20:58\");\nCREATE TABLE \"seller\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"shop_name\" TEXT DEFAULT NULL,\"bitmerchant_address\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (user_id));\nINSERT INTO \"seller\" VALUES(1,1,\"garg\",\"http://96.28.13.51:4567/\",\"2015-04-14 00:29:16\");\nCREATE TABLE \"product\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"seller_id\" INTEGER NOT NULL  DEFAULT NULL REFERENCES \"seller\" (\"id\"),\"category_id\" INTEGER DEFAULT NULL REFERENCES \"category\" (\"id\"),\"buy\" INTEGER DEFAULT NULL,\"auction\" INTEGER DEFAULT NULL,\"quantity\" INTEGER DEFAULT NULL,\"title\" TEXT DEFAULT NULL,\"processing_time_span_id\" INTEGER DEFAULT NULL REFERENCES \"time_span\" (\"id\"),\"physical\" INTEGER DEFAULT 0,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product\" VALUES(1,1,3,NULL,NULL,NULL,\"test_item\",NULL,0,\"2015-04-14 00:30:45\");\nINSERT INTO \"product\" VALUES(2,1,19,NULL,0,10,\"Pink frosted sprinkled donut\",3,0,\"2015-04-14 01:02:24\");\nINSERT INTO \"product\" VALUES(3,1,NULL,NULL,NULL,NULL,NULL,NULL,0,\"2015-04-14 14:09:32\");\nINSERT INTO \"product\" VALUES(4,1,18,NULL,0,NULL,\"A tasty red donut\",NULL,0,\"2015-04-14 14:10:00\");\nINSERT INTO \"product\" VALUES(5,1,25,NULL,0,5,\"A Chocalatey donut\",3,0,\"2015-04-14 14:10:45\");\nCREATE TABLE \"shipment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"address_id\" INTEGER DEFAULT NULL REFERENCES \"address\" (\"id\"),\"tracking_url\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"shipment\" VALUES(1,1,NULL,\"2015-04-14 01:14:21\");\nINSERT INTO \"shipment\" VALUES(2,2,NULL,\"2015-04-14 01:22:16\");\nINSERT INTO \"shipment\" VALUES(3,2,NULL,\"2015-04-14 13:02:23\");\nCREATE TABLE \"review\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"stars\" INTEGER DEFAULT NULL,\"headline\" TEXT DEFAULT NULL,\"text_html\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id, user_id));\nINSERT INTO \"review\" VALUES(1,2,1,3,\"Great donut\",\"Would eat again. 10/10&ltsemicolonbr&gtsemicolon\",\"2015-04-14 14:19:43\");\nCREATE TABLE \"address\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"full_name\" TEXT DEFAULT NULL,\"address_line_1\" TEXT DEFAULT NULL,\"address_line_2\" TEXT DEFAULT NULL,\"city\" TEXT DEFAULT NULL,\"state\" TEXT DEFAULT NULL,\"zip\" INTEGER DEFAULT NULL,\"country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"default_\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"address\" VALUES(1,1,\"fsdafasdf\",\"asdf\",\"asdf\",\"asdf\",\"fdsa\",1235,7,0,\"2015-04-14 01:14:18\");\nINSERT INTO \"address\" VALUES(2,2,\"fdsafd\",\"asdf\",\"asdf\",\"asdf\",\"asdf\",123,8,0,\"2015-04-14 01:22:12\");\nCREATE TABLE \"feedback\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"cart_item_id\" INTEGER DEFAULT NULL REFERENCES \"cart_item\" (\"id\"),\"stars\" INTEGER DEFAULT NULL,\"arrived_on_time\" INTEGER DEFAULT NULL,\"correctly_described\" INTEGER DEFAULT NULL,\"prompt_service\" INTEGER DEFAULT NULL,\"comments\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"feedback\" VALUES(1,2,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 13:02:22\");\nCREATE TABLE \"cart_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"quantity\" INTEGER DEFAULT NULL,\"purchased\" INTEGER DEFAULT 0,\"shipment_id\" INTEGER DEFAULT NULL REFERENCES \"shipment\" (\"id\"),\"payment_id\" INTEGER DEFAULT NULL REFERENCES \"payment\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"cart_item\" VALUES(1,1,2,1,0,1,1,\"2015-04-14 01:11:49\");\nINSERT INTO \"cart_item\" VALUES(2,2,2,1,1,2,3,\"2015-04-14 01:21:52\");\nINSERT INTO \"cart_item\" VALUES(3,2,2,1,0,3,4,\"2015-04-14 13:02:22\");\nCREATE TABLE \"payment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"order_iframe\" TEXT DEFAULT NULL,\"completed\" INTEGER DEFAULT 0,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"payment\" VALUES(1,\"\",0,\"2015-04-14 01:13:57\");\nINSERT INTO \"payment\" VALUES(2,NULL,0,\"2015-04-14 01:22:01\");\nINSERT INTO \"payment\" VALUES(3,\"\",1,\"2015-04-14 01:23:05\");\nINSERT INTO \"payment\" VALUES(4,\"\",0,\"2015-04-14 12:48:01\");\nCREATE TABLE \"bid\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"auction_id\" INTEGER DEFAULT NULL REFERENCES \"auction\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"amount\" INTEGER DEFAULT NULL,\"time\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"auction\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"expire_time\" INTEGER DEFAULT NULL,\"start_amount\" NUMERIC DEFAULT NULL,\"currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"reserve_amount\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"auction\" VALUES(1,2,NULL,NULL,2,NULL,\"2015-04-14 01:09:43\");\n'\ncurl -L -XPOST localhost:4002/db?pretty -d 'INSERT INTO \"auction\" VALUES(2,4,NULL,NULL,2,NULL,\"2015-04-14 14:10:26\");\nINSERT INTO \"auction\" VALUES(3,5,NULL,NULL,3,NULL,\"2015-04-14 14:11:14\");\nCREATE TABLE \"currency\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"desc\" TEXT DEFAULT NULL,\"iso\" TEXT DEFAULT NULL,\"unicode\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"currency\" VALUES(1,\"Bitcoin\",\"BTC\",\"?\",\"2015-04-14 00:27:36\");\nINSERT INTO \"currency\" VALUES(2,\"United States Dollar\",\"USD\",\"$\",\"2015-04-14 00:27:36\");\nINSERT INTO \"currency\" VALUES(3,\"Euro\",\"EUR\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(4,\"British Pound Sterling\",\"GBP\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(5,\"Australian Dollar\",\"AUD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(6,\"Brazilian Real\",\"BRL\",\"R$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(7,\"Canadian Dollar\",\"CAD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(8,\"Swiss Franc\",\"CHF\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(9,\"Chinese Yuan\",\"CNY\",\"?\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(10,\"Hong Kong Dollar\",\"HKD\",\"$\",\"2015-04-14 00:27:37\");\nINSERT INTO \"currency\" VALUES(11,\"Indonesian Rupiah\",\"IDR\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(12,\"Israeli New Sheqel\",\"ILS\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(13,\"Mexican Peso\",\"MXN\",\"?\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(14,\"Norwegian Krone\",\"NOK\",\"kr\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(15,\"New Zealand Dollar\",\"NZD\",\"$\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(16,\"Polish Zloty\",\"PLN\",\"z\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(17,\"Romanian Leu\",\"RON\",\"leu\",\"2015-04-14 00:27:38\");\nINSERT INTO \"currency\" VALUES(18,\"Russian Ruble\",\"RUB\",\"?\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(19,\"Swedish Krona\",\"SEK\",\"kr\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(20,\"Singapore Dollar\",\"SGD\",\"$\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(21,\"Turkish Lira\",\"TRY\",\"?\",\"2015-04-14 00:27:39\");\nINSERT INTO \"currency\" VALUES(22,\"South African Rand\",\"ZAR\",\"R\",\"2015-04-14 00:27:39\");\nCREATE TABLE \"country\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"country_code\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"country\" VALUES(1,\"United States\",\"US\",\"2015-04-14 00:27:39\");\nINSERT INTO \"country\" VALUES(2,\"Afghanistan\",\"AF\",\"2015-04-14 00:27:39\");\n'\ncurl -L -XPOST localhost:4001/db?pretty -d 'INSERT INTO \"country\" VALUES(3,\"\ufffdland Islands\",\"AX\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(4,\"Albania\",\"AL\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(5,\"Algeria\",\"DZ\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(6,\"American Samoa\",\"AS\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(7,\"Andorra\",\"AD\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(8,\"Angola\",\"AO\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(9,\"Anguilla\",\"AI\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(10,\"Antarctica\",\"AQ\",\"2015-04-14 00:27:40\");\nINSERT INTO \"country\" VALUES(11,\"Antigua And Barbuda\",\"AG\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(12,\"Argentina\",\"AR\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(13,\"Armenia\",\"AM\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(14,\"Aruba\",\"AW\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(15,\"Australia\",\"AU\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(16,\"Austria\",\"AT\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(17,\"Azerbaijan\",\"AZ\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(18,\"Bahamas\",\"BS\",\"2015-04-14 00:27:41\");\nINSERT INTO \"country\" VALUES(19,\"Bahrain\",\"BH\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(20,\"Bangladesh\",\"BD\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(21,\"Barbados\",\"BB\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(22,\"Belarus\",\"BY\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(23,\"Belgium\",\"BE\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(24,\"Belize\",\"BZ\",\"2015-04-14 00:27:42\");\nINSERT INTO \"country\" VALUES(25,\"Benin\",\"BJ\",\"2015-04-14 00:27:42\");\nCREATE TABLE \"review_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"review_id\" INTEGER DEFAULT NULL REFERENCES \"review\" (\"id\"),\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (user_id, review_id));\nINSERT INTO \"review_vote\" VALUES(1,1,1,\"up\",\"2015-04-14 14:20:26\");\nCREATE TABLE \"review_comment\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"review_id\" INTEGER DEFAULT NULL REFERENCES \"review\" (\"id\"),\"comment\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"question\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"answer\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"question_id\" INTEGER DEFAULT NULL REFERENCES \"question\" (\"id\"),\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"question_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"question_id\" INTEGER DEFAULT NULL REFERENCES \"question\" (\"id\"),\"user_id\" INTEGER DEFAULT NULL,\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"answer_vote\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"answer_id\" INTEGER DEFAULT NULL REFERENCES \"answer\" (\"id\"),\"vote\" NUMERIC DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"category\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"parent\" INTEGER DEFAULT NULL,\"is_physical\" INTEGER DEFAULT true,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"category\" VALUES(1,\"Animals & Pet Supplies\",NULL,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(2,\"Live Animals\",1,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(3,\"Pet Supplies\",1,\"true\",\"2015-04-14 00:27:29\");\nINSERT INTO \"category\" VALUES(4,\"Bird Supplies\",3,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(5,\"Bird Cage Accessories\",4,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(6,\"Bird Cage Food & Water Dishes\",5,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(7,\"Bird Cages & Stands\",4,\"true\",\"2015-04-14 00:27:30\");\nINSERT INTO \"category\" VALUES(8,\"Bird Food\",4,\"true\",\"2015-04-14 00:27:30\");\n'\ncurl -L -XPOST localhost:4002/db?pretty -d 'INSERT INTO \"category\" VALUES(9,\"Bird Gyms & Playstands\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(10,\"Bird Ladders & Perches\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(11,\"Bird Toys\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(12,\"Bird Treats\",4,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(13,\"Cat Supplies\",3,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(14,\"Cat Apparel\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(15,\"Cat Beds\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(16,\"Cat Food\",13,\"true\",\"2015-04-14 00:27:31\");\nINSERT INTO \"category\" VALUES(17,\"Cat Furniture\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(18,\"Cat Litter\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(19,\"Cat Litter Box Mats\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(20,\"Cat Litter Boxes\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(21,\"Cat Toys\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(22,\"Cat Treats\",13,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(23,\"Dog Supplies\",3,\"true\",\"2015-04-14 00:27:32\");\nINSERT INTO \"category\" VALUES(24,\"Dog Apparel\",23,\"true\",\"2015-04-14 00:27:33\");\nINSERT INTO \"category\" VALUES(25,\"Dog Beds\",23,\"true\",\"2015-04-14 00:27:33\");\nCREATE TABLE \"wishlist_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"purchased\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"wishlist_item\" VALUES(1,1,2,0,\"2015-04-14 01:11:47\");\nCREATE TABLE \"login\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"session_id\" TEXT DEFAULT NULL,\"time_\" INTEGER DEFAULT NULL,\"expire_time\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"login\" VALUES(1,1,\"1sdfgs5kqivfofa2tum79g4301469s41h3e6d2qquntkf9umr2oh\",1428971430539,1428974638358,\"2015-04-14 00:30:30\");\nINSERT INTO \"login\" VALUES(2,1,\"1cmefbba3hk8kfbjl74kki02nav3h23fuj6jpod2sfp4ratjm9sp\",1428973901740,1428974447001,\"2015-04-14 01:11:42\");\nINSERT INTO \"login\" VALUES(3,2,\"1opvct1n4h7tlk8r1onpkoup8pi8b9duhfo3i8a4s7tcb6rtj38b\",1428974487159,1428978087159,\"2015-04-14 01:21:27\");\nINSERT INTO \"login\" VALUES(4,1,\"bhmv5etav7rbhhk3kur835u41hb2veg0av6gs00mqm964u90j5j\",1428974645457,1428978245457,\"2015-04-14 01:24:05\");\nINSERT INTO \"login\" VALUES(5,2,\"q0flrr0bvh7mkr8vnvktshj1ago6dsc7icdq25tdr0ok3kfrvhu\",1429015664731,1429019264731,\"2015-04-14 13:02:22\");\nINSERT INTO \"login\" VALUES(6,1,\"1cd6q1o14i65609a3dqr85kk1e91ulacj6l4b6di5tt5l8mfq84e\",1429015923407,1429016564440,\"2015-04-14 13:02:23\");\nINSERT INTO \"login\" VALUES(7,1,\"1g0jknpm2ad6n0skkjh9je6120qrogj4d5b88hvf5h9lt2go2pui\",1429016579502,1429020179502,\"2015-04-14 13:06:04\");\nINSERT INTO \"login\" VALUES(8,1,\"1v5fr7bm6c5dq5tahdujdon0u5ujpecft4ranpr8rml722ch9e1o\",1429016676795,1429016685373,\"2015-04-14 13:06:04\");\nINSERT INTO \"login\" VALUES(9,1,\"4vjp9v6qj14lpt4fitkg5vm5p72pvdn14hlp5m2s9ml8nka6lc0\",1429016793426,1429016802385,\"2015-04-14 13:06:33\");\nINSERT INTO \"login\" VALUES(10,1,\"ci0pm52vg36kat3p9821m51rptrbdi3lji2lg8a0u3audkc22r\",1429016822694,1429017095173,\"2015-04-14 13:38:54\");\nINSERT INTO \"login\" VALUES(11,1,\"1nt8r0qira5qvntv11iuc6udvjjtmitnbnuielmrouqabu7ua19m\",1429017113246,1429020713246,\"2015-04-14 13:38:54\");\nINSERT INTO \"login\" VALUES(12,1,\"1mcse38fgklq0odhus34e7g1gdbvu2rtpcivvu6k0f37vdsoo7oj\",1429021175749,1429024775749,\"2015-04-14 14:19:36\");\nCREATE TABLE \"product_price\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"price\" INTEGER DEFAULT NULL,\"native_currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"variable_price\" INTEGER DEFAULT NULL,\"price_select\" INTEGER DEFAULT NULL,\"price_1\" INTEGER DEFAULT NULL,\"price_2\" INTEGER DEFAULT NULL,\"price_3\" INTEGER DEFAULT NULL,\"price_4\" INTEGER DEFAULT NULL,\"price_5\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"product_price\" VALUES(1,2,2.5,2,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 01:07:20\");\nINSERT INTO \"product_price\" VALUES(2,4,1.99,2,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 14:10:26\");\nINSERT INTO \"product_price\" VALUES(3,5,1.96,3,0,0,NULL,NULL,NULL,NULL,NULL,\"2015-04-14 14:11:14\");\nCREATE TABLE \"product_group\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_group_item\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_group\" INTEGER DEFAULT NULL REFERENCES \"product_group\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_page\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"product_html\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nINSERT INTO \"product_page\" VALUES(1,2,\"&ltsemicolonh1 style=&quotsemicolontext-align: centersemicolon&quotsemicolon&gtsemicolonThe best donut ever made&ltsemicolon/h1&gtsemicolon&ltsemicolonblockquote&gtsemicolon&ltsemicolonp style=&quotsemicolon text-align: leftsemicolon&quotsemicolon&gtsemicolon&ltsemicolonspan style=&quotsemicolonfont-weight: boldsemicolon&quotsemicolon&gtsemicolonSaid everyone&ltsemicolon/span&gtsemicolon&ltsemicolonbr&gtsemicolon&ltsemicolon/p&gtsemicolon&ltsemicolon/blockquote&gtsemicolon\",\"2015-04-14 14:06:56\");\nCREATE TABLE \"product_picture\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"url\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product_picture\" VALUES(1,2,1,\"http://vignette1.wikia.nocookie.net/smosh/images/b/b2/Pink_frosted_sprinkled_donut.jpg/revision/latest?cb=20120101131536\",\"2015-04-14 14:06:16\");\nINSERT INTO \"product_picture\" VALUES(2,4,1,\"http://jennyfunderburke.com/blog/wp-content/uploads/2011/08/donut.jpg\",\"2015-04-14 14:10:07\");\nINSERT INTO \"product_picture\" VALUES(3,5,1,\"http://www.withsprinklesontop.net/wp-content/uploads/2012/01/DSC_0406x900.jpg\",\"2015-04-14 14:11:36\");\nCREATE TABLE \"tag\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"title\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_tag\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"tag_id\" INTEGER DEFAULT NULL REFERENCES \"tag\" (\"id\"),\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"time_type\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"time_type\" VALUES(1,\"business days\",\"2015-04-14 00:27:35\");\nINSERT INTO \"time_type\" VALUES(2,\"weeks\",\"2015-04-14 00:27:35\");\nCREATE TABLE \"time_span\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"time_type_id\" INTEGER DEFAULT NULL REFERENCES \"time_type\" (\"id\"),\"min\" INTEGER DEFAULT NULL,\"max\" INTEGER DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"time_span\" VALUES(1,1,1,2,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(2,1,1,3,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(3,1,3,5,\"2015-04-14 00:27:35\");\nINSERT INTO \"time_span\" VALUES(4,2,1,2,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(5,2,2,3,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(6,2,3,4,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(7,2,4,6,\"2015-04-14 00:27:36\");\nINSERT INTO \"time_span\" VALUES(8,2,6,8,\"2015-04-14 00:27:36\");\nCREATE TABLE \"shipping\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"from_country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP,UNIQUE (product_id));\nCREATE TABLE \"shipping_cost\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"shipping_id\" INTEGER DEFAULT NULL REFERENCES \"shipping\" (\"id\"),\"to_country_id\" INTEGER DEFAULT NULL REFERENCES \"country\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"price\" INTEGER DEFAULT NULL,\"native_currency_id\" INTEGER DEFAULT NULL REFERENCES \"currency\" (\"id\"),\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"product_bullet\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"product_id\" INTEGER DEFAULT NULL REFERENCES \"product\" (\"id\"),\"num_\" INTEGER DEFAULT NULL,\"text\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nINSERT INTO \"product_bullet\" VALUES(1,2,1,\"This is a Pink frosted sprinkled donut\",\"2015-04-14 14:05:51\");\nINSERT INTO \"product_bullet\" VALUES(2,2,2,\"It has sprinkles\",\"2015-04-14 14:05:57\");\nINSERT INTO \"product_bullet\" VALUES(3,2,3,\"It has frosting\",\"2015-04-14 14:06:12\");\nCREATE TABLE \"payment_type\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"name\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"payment_info\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"seller_id\" INTEGER DEFAULT NULL REFERENCES \"seller\" (\"id\"),\"payment_type_id\" INTEGER DEFAULT NULL REFERENCES \"payment_type\" (\"id\"),\"payment_info_location\" TEXT DEFAULT NULL,\"created_at\" INTEGER NOT NULL  DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"message\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"from_user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"to_user_id\" INTEGER DEFAULT NULL REFERENCES \"user\" (\"id\"),\"subject\" TEXT DEFAULT NULL,\"html\" TEXT DEFAULT NULL,\"message_status_id\" INTEGER DEFAULT NULL REFERENCES \"message_status\" (\"id\"),\"created_at\" INTEGER DEFAULT CURRENT_TIMESTAMP);\nCREATE TABLE \"message_status\" (\"id\" INTEGER DEFAULT NULL PRIMARY KEY AUTOINCREMENT,\"title\" INTEGER DEFAULT NULL,\"created_at\" INTEGER DEFAULT CURRENT_TIMESTAMP);\nDELETE FROM sqlite_sequence;\nINSERT INTO \"sqlite_sequence\" VALUES(\"category\",25);\nINSERT INTO \"sqlite_sequence\" VALUES(\"time_type\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"time_span\",8);\nINSERT INTO \"sqlite_sequence\" VALUES(\"currency\",22);\nINSERT INTO \"sqlite_sequence\" VALUES(\"country\",25);\nINSERT INTO \"sqlite_sequence\" VALUES(\"user\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"seller\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"login\",12);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product\",5);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_price\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"auction\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"wishlist_item\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"cart_item\",3);\n'\ncurl localhost:4001/raft?pretty\ncurl localhost:4002/raft?pretty\ncurl -L -XPOST localhost:4001/db?pretty -d 'INSERT INTO \"sqlite_sequence\" VALUES(\"payment\",4);\nINSERT INTO \"sqlite_sequence\" VALUES(\"address\",2);\nINSERT INTO \"sqlite_sequence\" VALUES(\"shipment\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"feedback\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_bullet\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_picture\",3);\nINSERT INTO \"sqlite_sequence\" VALUES(\"product_page\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"review\",1);\nINSERT INTO \"sqlite_sequence\" VALUES(\"review_vote\",1);\nCREATE VIEW time_span_view AS SELECT time_span.id, min || \"-\" || max || \" \" || name as time_span_string FROM time_span left join time_type on time_span.time_type_id = time_type.id;\nCREATE VIEW product_view AS SELECT product.id,seller_id,shop_name,category_id,buy,auction,quantity,title,processing_time_span_id,time_span_string,price,native_currency_id,currency.iso as price_iso,variable_price,price_select,price_1,price_2,price_3,price_4,price_5,expire_time,start_amount,reserve_amount,physical,currency_id as auction_currency_id,auction_currency.iso as auction_currency_iso,shipping.id as shipping_id, from_country_id, from_country.name as from_country, count(review.id) as number_of_reviews, ifnull(avg(review.stars),0) as review_avg, product_html FROM product left join time_span_view on product.processing_time_span_id = time_span_view.id left join product_page on product.id = product_page.product_id left join product_price on product.id = product_price.product_id left join auction on product.id = auction.product_id left join currency on product_price.native_currency_id = currency.id left join currency as auction_currency on auction.currency_id = auction_currency.id left join shipping on product.id = shipping.product_id left join country as from_country on shipping.from_country_id = from_country.id left join review on review.product_id = product.id left join seller on product.seller_id = seller.id  group by product.id;\nCREATE VIEW product_thumbnail_view AS SELECT product.id as product_id,title,seller_id,category_id,shop_name, count(review.id) as number_of_reviews, ifnull(avg(review.stars),0) as review_avg, auction,CASE WHEN auction=\"1\"    THEN (select max(bid.amount) from bid where bid.auction_id = auction.id)    ELSE max(price) END as price, currency.iso as price_iso FROM product inner join currency on product_price.native_currency_id = currency.id left join seller on product.seller_id = seller.id left join auction on product.id = auction.product_id left join review on review.product_id = product.id left join product_price on product_price.product_id = product.id group by product.id;\nCREATE VIEW category_tree_view AS  SELECT t1.name AS name_1, t1.id AS id_1,t2.name AS name_2, t2.id AS id_2,t3.name AS name_3, t3.id AS id_3,t4.name AS name_4, t4.id AS id_4,t5.name AS name_5, t5.id AS id_5,t6.name AS name_6, t6.id AS id_6,t7.name AS name_7, t7.id AS id_7 FROM category AS t1 LEFT JOIN category AS t2 ON t2.parent = t1.id LEFT JOIN category AS t3 ON t3.parent = t2.id LEFT JOIN category AS t4 ON t4.parent = t3.id LEFT JOIN category AS t5 ON t5.parent = t4.id LEFT JOIN category AS t6 ON t6.parent = t5.id LEFT JOIN category AS t7 ON t7.parent = t6.id where t1.parent IS NULL;\nCREATE VIEW browse_view AS select distinct id_1, id_2, name_1, name_2 from category_tree_view;\nCREATE VIEW review_view AS select review.id,product_id,review.user_id,user.name as user_name, stars,headline,text_html, review.created_at, SUM(vote) as votes_sum, count(review_vote.id) as votes_count from review left join review_vote on review.id = review_vote.review_id left join user on review.user_id = user.id group by review.id;\nCREATE VIEW feedback_view AS select feedback.id,cart_item_id,cart_item.product_id,cart_item.user_id,stars,arrived_on_time,correctly_described,prompt_service,comments,feedback.created_at from feedback left join cart_item on feedback.cart_item_id = cart_item.id;\nCREATE VIEW question_view AS select question.id, question.user_id, user.name as user_name, product_id, text, question.created_at, SUM(vote) as votes_sum, count(question_vote.id) as votes_count from question left join question_vote on question.id = question_vote.question_id left join user on question.user_id = user.id group by question.id;\nCREATE VIEW answer_view AS select answer.id, answer.user_id, user.name as user_name,question_id, text, answer.created_at, SUM(case when vote = 1 then 1 when vote = -1 then -1 else 0 end) as votes_sum, count(answer_vote.id) as votes_count from answer left join answer_vote on answer.id = answer_vote.answer_id left join user on answer.user_id = user.id group by answer.id;\nCREATE VIEW shipping_cost_view AS select shipping_cost.id,shipping_id, to_country_id, num_,price, name as to_country,iso as shipping_cost_iso from shipping_cost left join country on shipping_cost.to_country_id = country.id left join currency on shipping_cost.native_currency_id = currency.id;\nCREATE VIEW cart_view AS select cart_item.id,cart_item.user_id,product.seller_id,cart_item.product_id,cart_item.quantity,purchased,cart_item.created_at,title, url,product_price.price,iso ,cart_item.shipment_id,cart_item.payment_id from cart_item left join product_picture on cart_item.product_id = product_picture.product_id and num_ = 1 left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join currency on product_price.native_currency_id = currency.id where purchased = 0;\nCREATE VIEW cart_group AS select cart_item.user_id,seller_id, shop_name, max(time_span_string) as time_span_string, sum(product_price.pricecart_item.quantity) as cost,max(iso) as iso,IFNULL(max(shipping_cost.price),0) as shipping,sum(product_price.pricecart_item.quantity) + IFNULL(max(shipping_cost.price),0) as checkout_total ,shipment_id, address.full_name,address.address_line_1,address.address_line_2,address.city,address.state,address.zip,address.country_id,payment_id,purchased, bitmerchant_address,order_iframe, cart_item.created_at from cart_item left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join shipping on cart_item.product_id = shipping.product_id left join shipping_cost on shipping.id = shipping_cost.shipping_id left join seller on product.seller_id = seller.id left join time_span_view on product.processing_time_span_id = time_span_view.id left join currency on product_price.native_currency_id = currency.id left join shipment on cart_item.shipment_id = shipment.id left join address on shipment.address_id = address.id left join payment on cart_item.payment_id = payment.id where purchased = 0 group by cart_item.user_id, product.seller_id;\nCREATE VIEW order_group AS select cart_item.user_id,seller_id, shop_name, max(time_span_string) as time_span_string, sum(product_price.pricecart_item.quantity) as cost,max(iso) as iso,IFNULL(max(shipping_cost.price),0) as shipping,sum(product_price.pricecart_item.quantity) + IFNULL(max(shipping_cost.price),0) as checkout_total ,shipment_id, shipment.tracking_url, address.full_name,address.address_line_1,address.address_line_2,address.city,address.state,address.zip,address.country_id,payment_id,purchased, completed, order_iframe,payment.created_at from cart_item left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join shipping on cart_item.product_id = shipping.product_id left join shipping_cost on shipping.id = shipping_cost.shipping_id left join seller on product.seller_id = seller.id left join time_span_view on product.processing_time_span_id = time_span_view.id left join currency on product_price.native_currency_id = currency.id left join shipment on cart_item.shipment_id = shipment.id left join address on shipment.address_id = address.id left join payment on cart_item.payment_id = payment.id where purchased = 1 group by cart_item.user_id, payment_id;\nCREATE VIEW order_view AS select cart_item.id,cart_item.user_id,product.seller_id,cart_item.product_id,cart_item.quantity,purchased,cart_item.created_at,title, url,product_price.price,iso ,cart_item.shipment_id,cart_item.payment_id from cart_item left join product_picture on cart_item.product_id = product_picture.product_id and num_ = 1 left join product on product.id = cart_item.product_id left join product_price on cart_item.product_id = product_price.product_id left join currency on product_price.native_currency_id = currency.id where purchased = 1;\nCREATE VIEW address_view AS select address.id,user_id,full_name,address_line_1,address_line_2,city,state,zip,country_id,default_,country.name as country_name,address.created_at from address left join country on address.country_id = country.id;\n'\ncurl localhost:4001/raft?pretty\ncurl localhost:4002/raft?pretty\nkills all the rqlite instances\nps aux | grep -ie rqlite | awk '{print $2}' | xargs kill -9\nrm -rf node_1 node_2\n``\n. I just tested this one out with a 3 node cluster, and I can verify that it is still an issue, in both 2 and 3 node clusters. I still often will get the error,\"error\": \"raft.Server: Not current leader\"`\n. Gotcha, out of our jurisdiction. I'll submit this bug to them.\n. Oh jeez. That stinks.\n. Also, as in the example above, sometimes the connection string for certain connections will be empty and it will mess things up.\nI've noticed the leader will show the correct connection, but the joiner might show it as empty.\n. Hey @otoolep \nSo I've launched my application, here's the admin page. It ran for a day, with 6 peers, and now is stuck in a glitch where all the nodes keep switching back between candidates and followers with no leader. If you refresh the page you'll see it. I'm guessing this has to do with some major errors in goraft.\nhttp://107.170.137.106:4568/network\nSomeone suggested to me that I should be using this here, since goraft is unmaintained.\nhttps://github.com/coreos/etcd/issues/715#issuecomment-94467283\nhttps://github.com/coreos/etcd/tree/master/raft\nThat should replicate all the functions, but its also supported.\nIs there any chance that rqlite could switch to this? I'm having a lot of reliability issues.\nedit: also on the leader instance, writes seem to stall, possibly because a snapshot was taken.\n. @otoolep no problem. These reliability issues are the current bottleneck in my project, enough that I want to start to work some of them out and do some pull requests. \nWhich is the main class I should be looking at that does the leader selection, maybe main.go or server.go?\n. Yep, and the leader election is completely broken. Right now, after running for a day, they're all stalled as candidates/followers with unnamed leaders, permanently.\nCould you point me to which .go file of yours calls goraft, or initiates the leader election?\n. @otoolep No problem, very understandable. \n. Sure, let me test it out\n. So I'm finding rqlite only uses that protobuf dependency indirectly through goraft, which is deprecated/unmaintained. A short term fix then would be to fork goraft, update that dependency, until you eventually move to that new goraft you referenced earlier. I'll start on this now.\n. I just messed with this a bunch, and still can't figure it out. I forked goraft, replaced all references of either goprotobuf or gogoprotobuf to the new github one using the following find and replace command:\nfind . -type f -exec sed -i 's/code.google.com\\/p\\/goprotobuf/github.com\\/golang\\/protobuf/g' {} +\nfind . -type f -exec sed -i 's/code.google.com\\/p\\/gogoprotobuf/github.com\\/golang\\/protobuf/g' {} +\nI don't really know much about building or testing go projects, but running go test, or go install just tell me that it can't find that new package, even after I've set the GOPATH to the goraft directory, and ran go get github.com/golang/protobuf/proto. \nEither this dependency is too complicated for me to fix, or I'm missing something.\n. @otoolep Just to let you know, rqlite is still uninstallable because of this missing dependency, and its holding up my dev work. \n. Wow I didn't realize it was as simple as using that embedded folder, thanks a bunch sir.\n. Ah gotcha, wish I had more expertise with go to save you the work, but thanks again anyway.\n. ",
    "mainframe": "+1 for rpm (centos 7) and deb (ubuntu 16.04) native packages.\n. +1 must have for production setups.\n@otoolep - do I understand correctly that currently new node joining the cluster is not authenticated in any way? Could encryption of inter-node communication solve this problem as well? Like Consul/Serf does for example. Why not use Serf for cluster membership management and raft for data consistency?. +1 this would be extremely useful feature.. +1. +1. +1. It would be still very useful in private clouds (like Openstack) and in public clouds where UDP broadcasts are allowed.. ",
    "StarpTech": "+1 for windows support . @otoolep why you don't provide Windows builds ? If you can't you could setup a routine to upload the asset to the release with https://developer.github.com/v3/repos/releases/#upload-a-release-asset\nScript in golang https://github.com/aktau/github-release. ",
    "thefonzi": "+1 one windows packages. ",
    "mkorszun": "@otoolep yes, definitely. Waiting for your feedback.\n. ",
    "millken": "@zmedico ok, i found it.\nthe problem is ; https://github.com/otoolep/rqlite/blob/master/server/server.go#L503\nsql \nINSERT INTO \"server\" (\"id\", \"servername\", \"setting\")VALUES(2,\"www.test1.com\",'{\"gzip\": 1, \"upstream\": \"server 127.0.0.1:81; server 127.0.0.1:82;\"}');' \nwas split into \nINSERT INTO \"server\" (\"id\", \"servername\", \"setting\")VALUES(2,\"www.test1.com\",'{\"gzip\": 1, \"upstream\": \"server 127.0.0.1:81\n and \nserver 127.0.0.1:82;\"}');\n. ",
    "prateek1306": "Thanks, this works :) \n. ",
    "adamierymenko": ":+1:\nWould make this considerably more transparent.\nAlso wanted to thank you for this! We plan to use this a lot for things like this:\nhttps://github.com/zerotier/ZeroTierOne/tree/master/controller\nUsing this we could cluster our stock network controller implementation (that uses SQLite3) without writing another to use some other kind of database.\nWe're also considering using this for other stuff. Got any place to send donations?\n. ",
    "Sooriya10": "Thanks for checking!\nStill having issue on my system\ngo version xgcc (Ubuntu 4.9.3-0ubuntu4) 4.9.3 linux/amd64\nSooriya@AirP2P:~$ cd rqlite/Sooriya@AirP2P:~/rqlite$ export GOPATH=$PWDSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/...# github.com/mattn/go-sqlite3Go type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/.Sooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/..can't load package: package github.com/otoolep: no buildable Go source files in /home/Sooriya/rqlite/src/github.com/otoolepSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/...# github.com/mattn/go-sqlite3Go type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteSooriya@AirP2P:~/rqlite$ ls -ltotal 12drwxrwxr-x 2 Sooriya Sooriya 4096 Apr 10 03:19 bindrwxrwxr-x 3 Sooriya Sooriya 4096 Apr 10 03:19 pkgdrwxrwxr-x 3 Sooriya Sooriya 4096 Apr 10 03:16 srcSooriya@AirP2P:~/rqlite$ cd binSooriya@AirP2P:~/rqlite/bin$ ls -ltotal 24-rwxrwxr-x 1 Sooriya Sooriya 24000 Apr 10 03:19 rqlite\nThere is no rqlited file?\nDate: Sat, 9 Apr 2016 18:40:20 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\n~ $ mkdir rqlite # Or any directory of your choice.\n~ $ cd rqlite/\n~/rqlite $ export GOPATH=$PWD\n~/rqlite $ go get -t github.com/otoolep/rqlite/...\n~/rqlite $ $GOPATH/bin/rqlited ~/node.1\n[rqlited] 2016/04/09 18:37:48 rqlited starting, version 2.1, commit unknown, branch unknown\n[store] 2016/04/09 18:37:49 SQLite database opened at /home/philip/node.1/db.sqlite\n[store] 2016/04/09 18:37:49 enabling single-node mode\n2016/04/09 18:37:49 [INFO] raft: Node at 127.0.0.1:4002 [Follower] entering Follower state\n2016/04/09 18:37:50 [WARN] raft: Heartbeat timeout reached, starting election\n2016/04/09 18:37:50 [INFO] raft: Node at 127.0.0.1:4002 [Candidate] entering Candidate state\n2016/04/09 18:37:50 [DEBUG] raft: Votes needed: 1\n2016/04/09 18:37:50 [DEBUG] raft: Vote granted from 127.0.0.1:4002. Tally: 1\n2016/04/09 18:37:50 [INFO] raft: Election won. Tally: 1\n2016/04/09 18:37:50 [INFO] raft: Node at 127.0.0.1:4002 [Leader] entering Leader state\n2016/04/09 18:37:50 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n2016/04/09 18:37:50 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n^C[rqlited] 2016/04/09 18:37:51 rqlite server stopped\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Thanks!\nDate: Sat, 9 Apr 2016 20:40:59 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\nSomething is up with your build of go-sqlite3. This is not a rqlite issue, but the error is blocking rqlited from being built. \nI suggest you visit https://github.com/mattn/go-sqlite3 and see if there is any help there. \n\nOn Apr 9, 2016, at 8:29 PM, Sooriya10 notifications@github.com wrote:\nThanks for checking!\nStill having issue on my system\n\ngo version xgcc (Ubuntu 4.9.3-0ubuntu4) 4.9.3 linux/amd64\nSooriya@AirP2P:~$ cd rqlite/Sooriya@AirP2P:~/rqlite$ export GOPATH=$PWDSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/...# github.com/mattn/go-sqlite3Go type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/.Sooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/..can't load package: package github.com/otoolep: no buildable Go source files in /home/Sooriya/rqlite/src/github.com/otoolepSooriya@AirP2P:~/rqlite$ go get -t github.com/otoolep/rqlite/...# github.com/mattn/go-sqlite3Go type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteGo type not supported in export: [0]byteSooriya@AirP2P:~/rqlite$ ls -ltotal 12drwxrwxr-x 2 Sooriya Sooriya 4096 Apr 10 03:19 bindrwxrwxr-x 3 Sooriya Sooriya 4096 Apr 10 03:19 pkgdrwxrwxr-x 3 Sooriya Sooriya 4096 Apr 10 03:16 srcSooriya@AirP2P:~/rqlite$ cd binSooriya@AirP2P:~/rqlite/bin$ ls -ltotal 24-rwxrwxr-x 1 Sooriya Sooriya 24000 Apr 10 03:19 rqlite\nThere is no rqlited file?\nDate: Sat, 9 Apr 2016 18:40:20 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\n~ $ mkdir rqlite # Or any directory of your choice.\n~ $ cd rqlite/\n~/rqlite $ export GOPATH=$PWD\n~/rqlite $ go get -t github.com/otoolep/rqlite/...\n~/rqlite $ $GOPATH/bin/rqlited ~/node.1\n[rqlited] 2016/04/09 18:37:48 rqlited starting, version 2.1, commit unknown, branch unknown\n[store] 2016/04/09 18:37:49 SQLite database opened at /home/philip/node.1/db.sqlite\n[store] 2016/04/09 18:37:49 enabling single-node mode\n2016/04/09 18:37:49 [INFO] raft: Node at 127.0.0.1:4002 [Follower] entering Follower state\n2016/04/09 18:37:50 [WARN] raft: Heartbeat timeout reached, starting election\n2016/04/09 18:37:50 [INFO] raft: Node at 127.0.0.1:4002 [Candidate] entering Candidate state\n2016/04/09 18:37:50 [DEBUG] raft: Votes needed: 1\n2016/04/09 18:37:50 [DEBUG] raft: Vote granted from 127.0.0.1:4002. Tally: 1\n2016/04/09 18:37:50 [INFO] raft: Election won. Tally: 1\n2016/04/09 18:37:50 [INFO] raft: Node at 127.0.0.1:4002 [Leader] entering Leader state\n2016/04/09 18:37:50 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n2016/04/09 18:37:50 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\n^C[rqlited] 2016/04/09 18:37:51 rqlite server stopped\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly or view it on GitHub\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Sooriya@AirP2P:~/rqlite$ gvm list\ngvm gos (installed)   go1.4   go1.5   go1.6\nDate: Sat, 9 Apr 2016 21:56:25 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\n@Sooriya10 -- what version of Go are you using? You must use at least version 1.4.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. Sooriya@AirP2P:/home/work/src/user$ which go/usr/bin/go\nDate: Sat, 9 Apr 2016 23:18:48 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\n~ $ which go\n/home/philip/.gvm/gos/go1.5/bin/go\n~ $ \n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. Thanks for trying! and quick responses.. I'll give another go at before giving it up \nDate: Sat, 9 Apr 2016 23:29:26 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\nOK, I'm stumped. :-( \n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. Thanks for this!\n2016/04/10 06:35:59 [INFO] raft: Node at 127.0.0.1:4002 [Follower] entering Follower state2016/04/10 06:36:00 [WARN] raft: Heartbeat timeout reached, starting election2016/04/10 06:36:00 [INFO] raft: Node at 127.0.0.1:4002 [Candidate] entering Candidate state2016/04/10 06:36:00 [DEBUG] raft: Votes needed: 12016/04/10 06:36:00 [DEBUG] raft: Vote granted from 127.0.0.1:4002. Tally: 12016/04/10 06:36:00 [INFO] raft: Election won. Tally: 12016/04/10 06:36:00 [INFO] raft: Node at 127.0.0.1:4002 [Leader] entering Leader state2016/04/10 06:36:00 [DEBUG] raft: Node 127.0.0.1:4002 updated peer set (2): [127.0.0.1:4002]\nNow I can test it!\nDate: Sat, 9 Apr 2016 23:33:53 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\nPerhaps you can use a pre-built binary, until you sort out the compilation issue. \nhttps://github.com/otoolep/rqlite/releases\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. Thanks, Pre-build work!. Made 5 nodes, Ithink thats what we want for our app\n/execute?pretty&timings' -H \"Content-Type: application/json\" -d \"[>     \\\"INSERT INTO foo(name) VALUES('fiona')\\\",>     \\\"INSERT INTO foo(name) VALUES('sinead')\\\"> ]\"{    \"results\": [        {            \"last_insert_id\": 2,            \"rows_affected\": 1,            \"time\": 0.2434453        },        {            \"last_insert_id\": 3,            \"rows_affected\": 1,            \"time\": 0.46698310000000004        }    ],    \"time\": 0.9060072}Sooriya@AirP2P:~/rqlite/rqlited-v2.1-linux-amd64$ sqlite3 ~/node.5/db.sqliteSQLite version 3.12.0 2016-03-29 10:14:15Enter \".help\" for usage hints.sqlite> select * from foo;1|fiona2|fiona3|sineadsqlite>\nDate: Sat, 9 Apr 2016 23:33:53 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] rqlited: No such file or directory (#78)\nPerhaps you can use a pre-built binary, until you sort out the compilation issue. \nhttps://github.com/otoolep/rqlite/releases\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. I'll test it again and get a report later.\nBTW: Can this \"writing to the SQLite file underneath an rqlite node\" be controlled, because someone might hack/accidentally  do this.\nOtherwise that will be a problem for the application we are rethinking of. It needs replication, but the replicate set should not be able to fiddle with and must be \"READ\" only max.\nDate: Sun, 10 Apr 2016 21:06:49 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] Insert a record to a none master node, it will crash (#81)\nI don't understand this bug. Can you please provide more details? I can't reproduce this issue, since you have not provided enough information.\nJust to be clear, writing to the SQLite file underneath an rqlite node is not supported.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Thanks for asking suggestion. I'm sure your replica set for sqlite3 solution is ideal for many situations/applications.\nFor us, would that be possible to configure the other Nodes that they never will be able Insert/Update or Delete. i.e. those operation only via the master database and only replicate to the other nodes...\n. Yes, I was writing directly a followers node to test it.  Your solution should \"not\" allow  that.  It is useless for us if it allows to do that.\nYour solution is vulnerable for hacking, and accidental writing to the followers.  Hence they not fall in this basic rule \" ensuring that each node in the cluster agrees upon the same series of state transitions\"\nSorry to say this, because allowing this back door entries via the followers, I believe your Rqlite is not a RAFT implementation.\nDate: Mon, 11 Apr 2016 04:39:39 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] Insert a record to a none master node, it will crash (#81)\nFor us, would that be possible to configure the other Nodes that they never will be able Insert/Update or Delete. i.e. those operation only via the master database and only replicate to the other nodes...\nThe answer to your requirement is to only go through the HTTP API on the leader, and don't write to the SQLite file directly. I can't prevent you from doing this, so you shouldn't do it, as rqlite doesn't support this kind of operation.\nI'm closing this bug since it sounds like you're writing to the SQLite file directly and you're not supposed to do that. Let know if this is not what you're doing.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Sorry Peter, Im a DBA with 15+ years of experience. What is the point having a database solution open for hacking, specially on SQLlie3 which are implemented on the client devices (or distributed systems ). So the users hack into it (or anyone have access to the device)\nI think you should check with someone with the RAFT protocol expertise that yours is a RAFT implementation if the followers also allowed the CRUD operation on them..\nPlease warn the users of your solution, The databases may go out of sync..\nBTW: I believe you may be able add further security control to your implementation and make it fully RAFT implementation.  if you would like to discuss a solution let me know.\nDate: Mon, 11 Apr 2016 15:18:02 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] Insert a record to a none master node, it will crash (#81)\nYes, I was writing directly a followers node to test it.  Your solution should \"not\" allow  that.  It is useless for us if it allows to do that.\nYou can't write to anything but the leader. The system explicitly prevents this is use the API. You can't write to a follower -- the request will be rejected. \nAnd If you are writing to the SQLite underneath a node, that is wrong. I've explicitly explained that the system does not support that.\nYour solution is vulnerable for hacking, and accidental writing to the followers.  Hence they not fall in this basic rule \" ensuring that each node in the cluster agrees upon the same series of state transitions\"\nrqlite does not enforce security at the HTTP API level. Use, say, nginx in front of the rqlite API to do this, or roll your own proxy. Or use an API Gateway.\nAnd if you're worried about people writing to the file on disk underneath a node, then don't allow people access to the file system. \nSorry to say this, because allowing this back door entries via the followers, I believe your Rqlite is not a RAFT implementation.\nI don't mean to be rude, but you don't appear to understand what rqlite is about.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Scenario,\nWith your \"current\" solution.\nMaster and 3 followers nodes have the records Id,Name, Account Balance\"1, 'John', $3502, 'Shane',$1003,'Malcolm',$500\nand the follower node 5 suddenly have records being hacked (or accidentally changed) to\nId,Name, Account Balance\"1, 'John', $3502, 'Shane', $1003,'Julia',$500  (record updated to different person)4,''Con',$5000000 (record has been added)\nAnd we have implemented a banking solution and given to the operational team.\nWho is responsible for this?\nDate: Mon, 11 Apr 2016 15:50:21 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] Insert a record to a none master node, it will crash (#81)\nSorry @Sooriya10 -- you simply don't understand what you're talking about. \n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. Thanks for the tip.. hope Rqlite is useful for many other apps..\nThanks for you tolerance and quick responses.\nDate: Mon, 11 Apr 2016 16:04:44 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] Insert a record to a none master node, it will crash (#81)\n@Sooriya10: It sounds like maybe you're looking for something like blockchain, which is much different from RAFT.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. Thanks Zac, If you happened to know any blockchain implementation on SQLite3 or any other database. Please let me know.!\n. I think your solution could have another couple of implementation options. hence 3 flavors!!!\n1) Check out of sync follower databases, re-sync them based on the majority- after all this is a consensus system, so this should work perfectly. Also send alerts if this happen\n2) Implement a file level security. i.e all the followers data base are read only to start with. if the follower become master than also change the file permission. \n. Sorry  I was expecting it was to be like block-chain.\nBTW: But I'm still testing your rqlite as it is and see it is useful for us someway\nDate: Mon, 11 Apr 2016 23:27:13 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] Insert a record to a none master node, it will crash (#81)\nAll that is way beyond the scope of rqlite.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. Thanks for both of you!! clarifying the technology capabilities and the solution..\nDate: Tue, 12 Apr 2016 00:29:37 -0700\nFrom: notifications@github.com\nTo: rqlite@noreply.github.com\nCC: sooriya10@bigpond.com\nSubject: Re: [otoolep/rqlite] Insert a record to a none master node, it will crash (#81)\nThanks Zac, If you happened to know any blockchain implementation on SQLite3 or any other database. Please let me know.!\nI think what you want is rqlite with support for using public-key cryptography to sign all transactions. Each transaction must be signed with a private key that is not divulged to the read-only nodes. The read-only nodes can use the corresponding public key to verify the integrity of transactions, but they won't be able to create new transactions unless they have access to the private key.\nIn order to support something like this, you're probably need it to be built into the RAFT library.\nAll that is way beyond the scope of rqlite.\nIndeed, file level security is way out of scope, since it's a system administration issue. The cryptographic security is out of scope due to it being the domain of the RAFT library.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. ",
    "ejzhang": "There are some redeclared warning when i build it.\n\nc:\\rqlite>go get -t github.com/otoolep/rqlite/...\n # compress/flate\nC:\\Program Files\\Go\\src\\compress\\flate\\inflate.go:30: fixedHuffmanDecoder redeclared in this block\n        previous declaration at C:\\Program Files\\Go\\src\\compress\\flate\\fixedhuff.go:78\n # hash/crc32\nC:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64x.go:14: haveSSE42 redeclared in this block\n        previous declaration at C:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64.go:13\nC:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64x.go:18: castagnoliSSE42 redeclared in this block\n        previous declaration at C:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64.go:19\nC:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64x.go:20: sse42 redeclared in this block\n        previous declaration at C:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64.go:26\nC:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64x.go:22: updateCastagnoli redeclared in this block\n        previous declaration at C:\\Program Files\\Go\\src\\hash\\crc32\\crc32_amd64.go:29\n. But how to build rqlited.exe? There's rqlite.exe only in the bin folder.\n. \n",
    "joonas-fi": "Current best practice is to use Dep [1]. It's really easy to use - I wish I started using it earlier because it was not as scary as I thought it would be. It's basically just $ dep init once to start using it and $ dep ensure at the beginning of your build process.\nWhen Go modules mature (currently in beta), switch to using it.\n[1] https://github.com/golang/go/wiki/vgo#current-state\n\nFor any production workloads, use dep, or migrate to it if you have not done so already.. For high-quality, typesafe and null-safe code I recommend TypeScript, React + JSX together. This way your HTML (\"templates\") will also be typesafe. It can also be compiled into a single .js file. Here's example of typed and null-safe frontend code from my project (note: I don't claim it's absolutely high quality code, just that the code is noticeably better than regular JavaScript): https://github.com/function61/pi-security-module/blob/e6c4f7d2c5248ef6715e2fdab787762e49fb21c1/frontend/pages/HomePage.tsx. Yes, a recent Go version should bring support for H2 out of the box.\n\nI think @carr123 meant that that there's an issue in how rqlite uses TLS. I don't have actual operational experience with H2 but from the high level details I understand that the only way a HTTP client upgrades to H2 if it's advertised in the TLS stack, specifically the ALPN frame: https://en.wikipedia.org/wiki/Application-Layer_Protocol_Negotiation\n\nIt is needed by secure HTTP/2 connections\n\nIf we take a look at rqlite's source code here: https://github.com/rqlite/rqlite/blob/master/http/service.go#L219\nWe notice that tls.Listen() call has no knowledge that what we'll be hosting over the TLS socket is a HTTP application, and therefore the TLS stack wouldn't ever know to advertise for H2 support.\nTherefore, I think what we'd need to do is what @carr123 suggested: use http.ListenAndServeTLS() to tie TLS and HTTP more tightly to enable H2 support.\nI can appreciate the more composable approach that you @otoolep probably strived for in giving either a TCP or TLS listener as an argument to server.Serve(), so the server doesn't have to know about the type of the connection it's hosted on. It sounds cleaner and that's probably what I would have done as well - but unfortunately that loses H2 support.\nI just now learned this as well myself while studying this ticket, thanks @carr123  :). Another alternative could maybe be to manually configure NextProtos member for tls.Config (which is given to Listen()) to include h2. This would probably be a simpler code change for rqlite.. I'm researching for a Raft implementation for my own project, and I'd be curious to hear about the reasons why you'd actively work to change from Hashicorp's Raft to CoreOS' one?\nOne reason I think is coreos/etcd/raft seems simpler, although you have to implement more of the plumbing yourself.\nSecond reason I can think of is that big projects (Kubernetes, Docker Swarm, ..) seem to converge on CoreOS's implementation.\nWhat other reasons do you have? You certainly have more experience than I do of this Raft stuff :). I'm toying around with etcd's Raft, and I found this blog post helpful: http://otm.github.io/2015/05/raft-a-first-implementation/\nIt's easier to digest than https://github.com/etcd-io/etcd/tree/master/contrib/raftexample which was a bit too much of complicated looking code to start with.. Here's another link that I found helpful - a talk about somebody using etcd/raft in their own product: https://www.youtube.com/watch?v=c2RyuTyVHxE&t=798\nI found that link from https://www.reddit.com/r/golang/comments/9emakk/should_i_use_etcd_for_this_project_or_write_my/. Just in case you're new to Prometheus, here's an example code with /metrics HTTP endpoint and use of metrics if it helps: https://github.com/function61/ruuvinator/blob/299f38dc0865afcb74dda4af6c5b00d836944071/cmd/ruuvinator/metricsserver.go\nYou'd probably not use vector metrics though (I needed them because I have N count of sensors so it will generate dynamic amount of metrics), so your use will be a bit simpler.. Sorry if this is the wrong place to ask (I think my question loosely relates to statement-based replication), but do you see any problem in using last_insert_rowid()? The only mention from the whole project I found (by Googling) was in #50\nWhat I think I'm trying to ask if AUTOINCREMENT ids get affected by transaction rollbacks - i.e. if an I/O in only one node (say a three-node cluster) error rollbacks a transaction, will the \"already reserved autoincrement number\" be released for reuse so that when the failed statement will be re-applied from the Raft log the autoincrement algorithm will generate the same ID that the other nodes did, and not for example off-by-one?\nIn case I explained it badly, here's the scenario:\n\ntable foo has autoincrement, next autoincrement number is 3\nClient executes INSERT INTO foo (name) VALUES (\"hello\"); INSERT INTO bar (foo_id) VALUES (last_insert_id())\nrqlite nodes 1, 2 and 3 will try to insert {foo_id: 3} into table bar\nnodes 1 and 2 succeed (therefore reaching Raft quorum), but node 3 had temporary I/O error, resulting in a rollback\nI'm just guessing but I think that Raft semantics mean that the only way for node 3 to recover is to retry the transaction to catch up with official Raft state\nDoes rqlite/sqlite guarantee that the row on node 3 will get {foo_id: 3}? (and not 4 for example)\n\nI'm PoC:ing something \"interesting\" on top of rqlite whose data integrity needs to be 100 % and it needs last_insert_rowid() for foreign keys to be set within the transaction.. Thanks for responding! Oh wow, I didn't even realize that rqlite's SQLite database is in RAM by default (with disk option) :)\nUsing RAM-only SQLite database probably takes care of the I/O error handling issue.\nHowever I'm interested.. if I were to use disk and encounter write I/O error, what would happen? You said \"rqlite would not deal well with this\" - does this mean that the node goes offline (maybe it won't accept new Raft requests or simply panic()), but the other Raft members will keep on partying as long as the quorum exists (2/3 nodes online)?\nThe worst case scenario I was fearing of was that when an I/O error occurrs and the transaction is rolled back, but the AUTOINCREMENT counter is not rolled back (this of course would be SQLite's internal design issue), and if the Raft flow simply retries applying the Raft log entry, this could now succeed and result in the nodes disagreeing on what the id of this new row is, even though at Raft level everything is peachy. This would not be good.\nHowever, SQLite seems to maybe work in an optimal way (w.r.t. use case for rqlite): https://stackoverflow.com/questions/27947712/sqlite-repeats-primary-key-autoincrement-value-after-rollback. Sure, no problem. Link: https://groups.google.com/forum/#!topic/rqlite/ssz5QUuII40. ",
    "progamer71": "@otoolep\nSorry, I did not search before ask.\nAnyway, thanks you.. ",
    "varung": "is it possible to enable the client to listen to the RAFT log as a witness, but not actually participate in the quorum? I know with native RAFT this is possible. Might give you the functionality you want for free.. ",
    "giner": "This change would help to configuration rsqlited dynamically without using a centralized discovery service. Are there plans to implement it?. I do it the following way:\ncurl -XDELETE \"$URI/remove\" -d '{\"addr\": \"$INTERNAL_IP:4002\"}'\nWhere $URI is L7 balancer. If the request goes to a follower I get 500.. ",
    "keisisqrl": "It could help with code complexity by allowing frequently-used queries to have values swapped out on the fly instead of reconstructing the query string. Though prepared queries as seen in #152 may do that even more. \nThe main advantage from my point of view for parameterized queries is that they're the safest way to avoid SQL Injection when dealing with arbitrary user data. \nBased on the db code here and the upstream library I think I can see how to do implement this. I may have a whack at it. \n. go-sqlite3's Exec supports one-shot parameterized queries. rqlite's Execute function currently does not and uses subsequent arguments as additional queries to execute, so this would require modifications to the internal API as well as a new JSON endpoint. The same is true of Query in go-sqlite3 vs rqlite.\n. ",
    "raindog308": "In traditional RDBMS systems, bind values are an important key to performance.  Without them, the engine has to hard parse the query every time (figure out the optimizer plan, etc.), as opposed to just substituting variables against a plan it's already computed.\nI don't know if SQLite caches previous query plans, etc.  If it does, then avoiding hard parses improves performance.  If it doesn't, then every operation is a hard parse.\nAn important additional benefit is it gets the developer out of all the hideous quoting, and it helps avoids the class of problems around misquoting like SQL injection, as keisisqrl mentioned.\nThe real answer here is a proper golang database/sql driver for rqlite.  Is that in the cards?  I'm new :-)\n. I think this would be a radical shift from the stateless model.  You'd have to keep state for each open transaction in the DB, cache, etc.\nI might request results 1-1000, fetch 1-100, and another user deletes 200-250.  Or I request 1-1,000,000, fetch 1000 and then go on vacation.  If sqlite supported this kind of paging it would be one thing but as-is I think this would be very difficult to implement.\nOf course, it'd be awesome if you did.\n. ",
    "zweifisch": "I am using https://github.com/mysqljs/sqlstring for escaping, but mysql is a bit different from sqlite, is there something similar like this package, but for sqlite?. ",
    "joeblew99": "ekanite and rqlite looks really useful.\nI am a golang programmer and use Polymer and gopherjs for front ends, so i could through something together pretty fast. Also once its done, it would be really easy for you to make changes to because its not like Javascript at all using polymer. \nI would need to have an idea of what you want. I have not used rqlite, but i think its a perfect match for the current project i am working on.\nLet me know what you think.\n. https://github.com/jgthms/bulma\nIs a ui framework I used on the last 2 projects.\nIt's lite and easy \nI also like MDL if your into the Google look ;)\nLet me know what your preference is.\nBtw have you looked at sqllite and disk encryption. This is a use case requirement for me at least.\nIt would be good if the golang code supported it in someway.\nIt's 100% same code and API.\n. same for me too. \nIf you can make the actual volume mounted off the host as an option that also is useful.\n. looks like your maybe thinking along the sames lines ? I had to look :)\nhttps://github.com/otoolep/global-rqlite\n. ",
    "snapo": "maybe dns in a records? or a hostlist json file? ... just some ideas :-)\nfor example... rsqlited ./node.mydomain.com ... then it does dns in a lookups to XX.node.mydomain.com, from those 100 it should at least find one host ;=) maybe 10 would be enough. ",
    "lygstate": "Yes, you need mingw for gcc.\n. Please refer to\nhttps://github.com/servo/servo/blob/master/appveyor.yml#L45\n. https://ci.appveyor.com/project/lygstate/rqlite\n. It's passed, please merge, and also enable appveyor for rqlite\n. ",
    "tych0": "No problem, thanks for the quick response!. Hey!\nApologies for the delay, I was traveling. Thanks for the merge though!\nTycho\nOn Sat, Dec 10, 2016 at 7:04 PM, otoolep notifications@github.com wrote:\n\nMerged #237 https://github.com/rqlite/rqlite/pull/237.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/pull/237#event-889364916, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AAv61_BnpyOzTB6qKiApKaPu2j0ZqqHKks5rGum9gaJpZM4LI174\n.\n. Seems I forgot a go fmt. Let me know if you want me to squash these together or leave them separate.. On Thu, Dec 15, 2016 at 04:01:32PM -0800, otoolep wrote:\nYeah, if you squash I will then merge -- thanks!\nhttps://github.com/rqlite/rqlite/blob/master/CONTRIBUTING.md#clean-commit-histories\n\nOk; I've pushed a squashed version. Thanks!\n\n-- \nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/rqlite/rqlite/pull/239#issuecomment-267480784\n. Right; the problem is that the commit above changes the return type of strings from []byte to string, so the code does panic. I'm just wondering if there's a cleaner way. I don't have any bright ideas right now, but I'll think about it :). Yes, the cast will fail if I try to cast a column to a type it's not. It's my job to cast it to the right thing. The problem is when the right thing changes underneath me :). The idea here is to offer introspection of the node's view of the database. This is something we've found useful in the past when debugging issues with LXD's database, and so we want some way to export each node's database.. Assuming you mean func (s *Store) Database(leader bool) ([]byte, error) then yep, sounds good and I just pushed a fix.. Yup, just pushed a fix.\n\nOn Thu, Dec 22, 2016 at 7:03 PM, otoolep notifications@github.com wrote:\n\n@otoolep commented on this pull request.\nIn store/store.go\nhttps://github.com/rqlite/rqlite/pull/242#pullrequestreview-14257387:\n\n@@ -683,13 +683,16 @@ func (s Store) Apply(l raft.Log) interface{} {\n  }\n }\n\n-// Snapshot returns a snapshot of the database. The caller must ensure that\n-// no transaction is taking place during this call. Hashicorp Raft guarantees\n-// that this function will not be called concurrently with Apply.\n+// RawDBSnapshot returns a snapshot of the database. The caller must ensure that\nDocstring isn't quite right. Can you change it to read:\nDatabase() returns a copy of the underlying database. The caller should ensure that no transaction is taking place during this call, or an error may be returned.\nThen I'll merge.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/pull/242#pullrequestreview-14257387,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAv61_6hZl_88tCJwZ0mq24kXoLHDWW7ks5rKyv8gaJpZM4LUNTl\n.\n. No problem, thank you!. Hey, just saw this. I actually don't mind the new way -- as I mentioned in the other issue it makes my code much simpler. My question was just if we can find a way to avoid this breakage entirely, e.g. by doing what the stdlib's sql.Rows.Scan() does, or something similar. i.e. have the user pass in types, and then shoehorn the values in to that type.. Yep, I'm not blocked on it. Also, please feel free to change Query if it makes sense (I think it did in this string case). I can adapt my code easily enough. Mostly I'm just curious if we can make it so that I don't have to at some point in the future :). Actually, after a careful reading of:\n\nhttps://www.sqlite.org/lang_transaction.html\nhttps://www.sqlite.org/lockingv3.html\nI think that this is possible. It would look something like this:\n\nThe leader does a BEGIN and returns a tx id.\nThat transaction accumulates queries (by using golang sql's tx.Execute/tx.Query methods to return results)\nwhen done, the leader acquires a lock, commits the transaction to the sqlite locally, and then also commits the transaction to the raft logs. Once the transaction is committed to the raft logs, the lock is released.\n\nI think this is safe because active transactions will never overlap with each other, so the potential race here is that things are committed in the wrong order. Since we only ever allow the leader to do transactions, and the leader synchronizes transactions in the order they're committed, things should be safe.\nI'll see if I can come with an implementation.. FWIW, there's an implementation of this here: https://github.com/tych0/rqlite/tree/transaction\nThe queries don't quite work, but I think this is likely just some mechanics about converting values from query results to actual usable values. I'll keep fiddling with that, but the transaction approach is there (and it is also quite small, all things considered).. Thanks, I'll check the docs out. I think we should be locking while taking a snapshot anyway, but it seems like there's some time where the snapshot is in the leader, but not all the way through the raft machinery, and we should probably take care to avoid a race there.\n. Actually, I think that locking during Snapshot() should be enough: the race we're concerned about is one where the db has something that the raft log doesn't. Assuming we synchronize on the same lock when committing transactions and taking snapshots, I think this should be okay. (In fact, we have to do this so that we don't corrupt the SQLite databse.)\nOne issue is what to do here: https://github.com/tych0/rqlite/commit/a7c0daab7b5357336f859c004a358baff7d8f2b6#diff-1f8872a5d54402aa220c723deb16293cR176\nThat is a very real error where somehow we fail to commit the logs, but we succeeded to commit the transaction. I suppose we could snapshot before every commit and rollback, but that seems quite expensive. The other option is just to force a rebuild from the raft log somehow.. FWIW, I just posted an implementation in the PR above.. On Mon, Feb 13, 2017 at 09:35:51PM -0800, otoolep wrote:\n\nSince you submitted a second PR, I just want to be sure I understand how you propose this should work.\nIf a client wants to get results of a query in the middle of a transaction (which is the example reason you give and a valid use case), the client must explicitly ask to start a transaction. All good, the node talks to the SQLite database directly without going through the log (which it never does today), and the client gets an ID back.\nNow, while is this transaction is active, the client performs the execs and queries, and these queries are performed against the SQLite database directly -- not through the Raft log. Once the client is happy, it calls commit, the node takes the list of commands that were executed, wraps them up in a single log message, and attempts to send the log message through Raft. If it fails, wipe the database directly and rebuild.\nSome things that occur to me: \n-- for the transaction situation, the rqlite state machine code would need to change such that it just commits those entries to the log, but doesn't apply the log to the database, on the leader (since the leader will have already modified its local SQLite database). But a follower would still need to apply the log messages to its local database since it would not be involved directly with the transaction handling. This makes me nervous -- to have a node handle messages differently depending on whether it is a leader or a follower. And the problem with a node checking if it's a leader is that leadership status can change at anytime. For a node to be absolutely sure it is the leader, it requires a round trip through the Raft consensus mechanism -- this means another message in the log. See strong read consistency to see this in action.\n\nI don't understand what you mean here: why does the follower need to\nbe aware of the transaction at all, until it is committed via raft\nlog?\n\n-- what would happen if the leader handling the transaction was deposed? Due to a network fault? The call to Apply() would fail, which might seem OK. But what would happen if, during the transaction processing, the leader was deposed, was not the leader for a while, and then re-elected so the call to Apply() was successful? But the SQLite database under the leader may no longer be what is was before, since the other node that was leader for a short while may have made changes. Does that make sense?\n\nGreat question, and I hope this is addressed by this code:\nhttps://github.com/rqlite/rqlite/pull/279/commits/31784700a7842886e09ff1fb69045aad5b50fd63#diff-1f8872a5d54402aa220c723deb16293cR155\nBasically, once a transaction has failed a raft Apply, you can't do\nanything but roll it back, exactly because of this problem.\n\nThese are just cases that I think are difficult to address. I think the change you're proposing is ambitious, I think the edge cases are hard to reason and be sure they've been solved.\nLet me know what you think.\n-- \nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/rqlite/rqlite/issues/266#issuecomment-279612950\n. Oh, and I should confirm: your summary is correct, that's how the implementation works right now.. On Tue, Feb 14, 2017 at 07:33:58AM -0800, otoolep wrote:\n\n\nI don't understand what you mean here: why does the follower need to be aware of the transaction at all, until it is committed via raft log?\n\n\nLet me take a step back. Today, when any node has Apply() called on its fsmby the Raft consensus mechanism, the code unpacks the message in the Raft log entry -- one or more SQLite statements -- and applies them to the underlying database. Each node acts exactly the same way. Now, with this new design, it seems to me that the leader will have to act differently than the followers -- it can't apply the SQLite commands to the database contained in the Raft log entry, during the execution of Apply(), because it will have already applied them. Only followers would be safe applying the SQLite commands contained in the log entry.\n\nAh ha, I was missing this point that the leader has its Apply() called\ntoo; makes sense.\n\nAssuming I am correct, this introduces a few issues. Fundamentally for a node to check that it is the leader (so that Apply() executes differently) it must perform a distributed consensus operation -- it much ask each other node if it's the leader in a very specific manner. It's not enough to just check some local state -- not if you want a 100% answer (which we do for any activity that may result in changes to the underlying SQLite database). All this is not trivial. Does this make sense? Or am I missing something?\n\nIt does make sense. Suppose we change the log messages to include a\nuuid for the transaction; then the store can look at its active\ntransaction and not apply it if the uuids match?\n\n\n\nGreat question, and I hope this is addressed by this code:\n\n\nUnfortunately I don't think it does. I might be wrong, but it would need rigorous testing to be sure. The issue is that there is nothing preventing node A being the leader, node B suddenly being elected leader (network fault disconnects A from cluster), node B being deposed (network fault disconnects B, but A is bakc), and node A being elected leader again, any number of times, between these two lines of code:\nerr := t.tx.Commit()\nand\n_, err = t.store.Execute(t.stmts, false, true)\n\nI don't think the leader changing is a problem, but you do raise a\ngood point: if A is the leader and starts a transaction, then B gets\nelected and starts a transaction, then A gets re-elected and commits,\nfollowed by B's re-election and commit, B's commit succeed, but really\nfail silently if they both acquired the same rowid for something and\nused it in a subsequent insert.\nI think the right thing to do here is simply to invalidate any active\ntransactions when a new leader is elected. Does that make sense?\n\nAssuming that the node is leader during both of these lines of code, and that the Raft term has not changed, is an invalid assumption (as far as I know). Assuming I am correct, I have no idea how this change would interact with the system going through an election cycle above.\n-- \nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/rqlite/rqlite/issues/266#issuecomment-279740730\n. On Tue, Feb 14, 2017 at 08:05:03AM -0800, otoolep wrote:\n\n\nthen the store can look at its active transaction and not apply it if the uuids match?\n\n\nIt might, but it's starting to get complicated.\n\nNaturally :)\n\n\n\nI think the right thing to do here is simply to invalidate any active\ntransactions when a new leader is elected. Does that make sense?\n\n\nAssuming you can even hook into when this happens, in a way that guarantees you won't miss the election, and it's not racy.\n\nI think you can:\nhttps://godoc.org/github.com/hashicorp/raft#LeaderObservation\n\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/rqlite/rqlite/issues/266#issuecomment-279750713\n. On Tue, Feb 14, 2017 at 08:03:10AM -0800, otoolep wrote:\n@tych0 -- some of the ideas you raise might work. But I think you can see now that what you are suggesting is not trivial, and has lots of corner cases that need extensive testing. Without this kind of rigorous testing, I would be very hesitant to merge the proposed transaction support into the master. \n\nBelieve me, I could see it before too :). The point of this thread is\nnot to get things merged in to master as is, but to arrive at a\nconsensus (!) that I can implement.\n\nIn its current form rqlite provides very strong correctness guarantees due to the way it uses the Raft consensus module. But a system that attempts to provide transactions in the form you suggest would not do so. What we really need is something more like standard 2-phase commit.\n\nOk. Do you have a suggestion for what that would look like?\n\n-- \nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/rqlite/rqlite/issues/266#issuecomment-279750082\n. On Feb 14, 2017 3:37 PM, \"otoolep\" notifications@github.com wrote:\n\nI think you can: https://godoc.org/github.com/hashicorp/raft#\nLeaderObservation\nSince that's not part of the Raft core, but a convenience feature that\nHashicorp built, I'm not sure what the guarantees are.\nOk. Do you have a suggestion for what that would look like?\nI know, at a high-level, what two-phase commit is -- Raft is sort of a 2PC\nsystem AFAIK, but I have never coded one, so you're running up against the\nlimitation of my knowledge now.\nI have another idea, which I have never had the time to explore. Perhaps it\nwould work? Let me explain, perhaps you can try coding it.\nA distributed transaction is started as follow -- the client requests to\nstart a transaction, and the SQL statement BEGIN is sent through the Raft\nlog in the normal way. Each node will get this statement per the usual\nmethods, and open a transaction on each underlying database. Now each\nSQLite database is in the same state. The client sends further execs and\nqueries as usual, all of which are taking place within the transaction.\nAll these commands go through the log.\nFinally the client decides to commit, or rollback. Again, the system simply\nsends COMMIT or ROLLBACK through the log, and each node processes the\ncommand as usual. Each database ends up in the same state. If COMMIT fails,\nwell, the transaction is aborted on each node as usual. The commands remain\nin the log, but it's not a problem. At the end of the day the database\nunder each node is in the same state. In other words the system operates\nthe same way as ever.\nThe README states that commands such as COMMIT are not supported by rqlite,\nbut this is only because I never tested the above scenario and didn't want\nto make any promises. But perhaps it would all work nicely.\nThere are a few things to consider.\n-- a node crashes while holding a transaction. In this case the transaction\nwill be aborted automatically. However, when the node restarts the database\nis wiped and rebuilt from what's in the logs. It will recover to the state\nit was, and pick up any commands that occurred while it was down.\nWhat will automatically abort the transaction in this case? This seems\nquite hard to detect.\n-- the entire cluster crashes during a transaction. In that case, the\ncluster will come back up in state that finds itself in the middle of a\ntransaction. This could be rather strange, since one would imagine that a\ncluster restart should clear out any transaction. There might be case here\nfor rolling back any transaction that system finds itself in, due to a\nreplay of a log on restart. In other words, after the log is applied after\nstarting up, issue an automatic ROLLBACK by default. If there is no\ntransaction in progress, it's not a big deak.\n-- clients, other than the client that is using the transaction, should be\nallowed to read the database while a transaction is in place. However,\nthose other clients should not be permitted to write to the database while\na transaction is outstanding. So to prevent this, a transaction ID (or\nsomething) should be handed out to the client that starts the transaction,\nand that client should pass back the transaction ID. It might be possible\nto use the transaction ID returned by the command BEGIN.\nDoes this make sense? Do you want to see if sending BEGIN, COMMIT etc\nthrough the Raft system would actually work?\nSounds reasonable. Another problem is parallel transactions, which this\nwon't allow for. But perhaps we can work some magic around that.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/issues/266#issuecomment-279859037, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAv618cO3zxWz1ZZ8pORZHDVX09-tefpks5rciy8gaJpZM4LscOW\n.\n. Euh, looks like github butchered my email reply:\n\n-- a node crashes while holding a transaction. In this case the transaction\nwill be aborted automatically. However, when the node restarts the database\nis wiped and rebuilt from what's in the logs. It will recover to the state\nit was, and pick up any commands that occurred while it was down.\n\nWhat will automatically abort the transaction in this case? This seems\nquite hard to detect.\n\nDoes this make sense? Do you want to see if sending BEGIN, COMMIT etc\nthrough the Raft system would actually work?\n\nSounds reasonable. Another problem is parallel transactions, which this\nwon't allow for. But perhaps we can work some magic around that.\n. Hmm. But sqlite isn't a daemon or anything; if for example golang segfaults, sqlite isn't running any more.. Ok. I don't see how sqlite would know that a transaction was lingering (and then how it would communicate it back to us so that we can ROLLBACK in the raft log), but I'll see what I can dig up.. Sure sqlite may have support for it, but we're not really dealing with sqlite, we're dealing with our own log of things. The problem here is that you can't nest transactions:\n$ sqlite3 :memory:\nSQLite version 3.11.0 2016-02-15 17:29:24\nEnter \".help\" for usage hints.\nsqlite> BEGIN;\nsqlite> BEGIN;\nError: cannot start a transaction within a transaction\nsqlite>\nSo consider:\n\nNode issues a BEGIN\nNode crashes\nNode restarts, and re-builds the sqlite3 database from the raft log.\nNobody can BEGIN, because nothing ROLLBACK'd the previous transaction.\n\nAll the sqlite3 intelligence about crashing doesn't help us here, because our basic primitive is not sqlite3, but statements in the raft log.\nI suppose we could look at the old sqlite DB from the last boot and see if it had a partially written transaction, but there's still no way to detect if that partial transaction was as a result of the crash, or if it crashed during the Apply() of a COMMIT from some raft neighbor.. Right, I guess I think it's possible if just one node crashes, not only the entire cluster. An explicit rollback after a single node failure would be unfortunate.. I suppose we could ROLLBACK after leader election, and only allow the leader to issue BEGIN and COMMIT/ROLLBACK statements.. A third idea I had thought about was to use actual sqlite dumps as raft log entries, instead of the queries themselves. It would be unfortunate to have to transmit the dump every time, though, and when I poked around there's no way to serialize transactions in a binary format that sqlite can apply. But anyway, it's a thought :). Actually, ignore this for now. I think all the stuff with memory needlessly complicates this; let me play around with it some more.. The problem with memory databases is something like the following: when users call sql.Open(), the stdlib creates a sql.DB object wrapping sqlite3, but it doesn't open any connections. If the database URL is just specified as \":memory:\", then each call to database/sql/driver.Conn.Open gives a /unique/ in-memory database. Since the stdlib thinks it can reconnect to the same database and add another connection to its pool by database/sql/driver.Conn.Opening again with the same database URL, things blow up (e.g. the table doesn't exist, because it was created on conn 1, but inserted to on conn 2).\nSee my comment here https://github.com/mattn/go-sqlite3/issues/204#issuecomment-275527228 on the issue linked from the commit message that has a program that demonstrates this behavior. Switch the commented out lines to break/unbreak things.. Right now, the client expects the API to live at /. I'm embedding rqlite (i.e. not using rqlited, but using the go library) into another application at some level that's not the root, e.g. /rqlite. This just allows you to specify something besides /.. Right, the lack of a leader check is intentional. We want the current state of the node's database as-is.. See the comments in the commit message: https://github.com/rqlite/rqlite/pull/279/commits/9c670e6b9e747adf3ff992d86374ff6b6f678db7. The problem is that you don't necessarily know when you want to do that. The stdlib's connection pooling mechanism may open or close connections at will, and you don't want to delete the entire database when one connection in the pool is closed, because the others are still valid.. If the current store is not the leader, you need some way to talk to the leader to actually execute the query; this is the way to provide that. This way, on every node that opens one of these, every query succeeds, instead of sometimes failing with ErrNotLeader and leaving you to handle it.\nI can draft an implementation that's rqlite specific if you like to demo it.. ",
    "gilwo": "thanks for the prompt response, i have some issues to build rqlite.\nI dont really understand how to build rqlite at all let alone that specific branch.\ni am really novice in go and i dont understand whats going on behind the scenes.\ni tried to figure out from the posts around on how to build it but i got confused.\ncan you shed some light on the build process ? i am trying to build it on my linux machine running ubuntu 14.04 LTS.\nthanks\n. thanks for the reference, i tested it and it seems to work nicely for my current use. i just tested it and something is not working very good.\nmy project db structure is quite big and it appear that for large triggers the dump still wont go in  using the db/load api.\nthe different is that now the transaction is failing as it gives a syntax error.\nits quite complex to give an example to this as i cant share the db structure itself.\nis there a way to open logs or run rqlited in debug mode ? \nthanks\n. i double check my structure again and it appear i missed some problem i snugged in with all my tests.\neverything is ok, thanks for the prompt response. ",
    "kikitux": "@otoolep for the message limit. \nwhats the raft function you are using? is this?\nhttps://github.com/rqlite/rqlite/blob/e6586f41f2350a2e3516eccb0f2fdc7db33a495e/store/store.go#L637-L672\nI can ask to the HashiCorp people for the message length limit. ",
    "anddimario": "I've started with go few days ago, and for my early tests i started with rqlite that it seems really interesting. I'm working basically on rest api, and rqlite use http endpoints in some way, so i think that it could be useful extends this functionality with a sort of graphql. A great part of rest endpoint are simply validation+db operations.\nMaybe, it could be interesting the possibility to add this middleware/plugin as extentions in a simple way to maintain the idea of a lightweight core.. For example, for a validation middleware, user can define something like:\nVALIDATION table_name field_name regex,.....;\nFor insert a new record, it could be used a post request with body:\n{ table: table_name, \n     method: 'insert',\n     fields: {\n        field_name: field_value'\n     }\n}\nOn rqlite: post request->http server -> validation middleware -> query (if validation has no errors)\nFor acl, i've read the docs and i saw that users already could have particular permission. Maybe an extension of this method could be the possibility to allow particular permission based on field. For example, user could update only if record has a field called X with his name, a declaration like:\nPERMISSION table_name field_name operation\nPERMISSION posts owner update\nFor hook, maybe after an operation (like insert, or update) could be the possibility to run some code.. ",
    "fpoltronieri": "Do you think that would be a good feature to implement?. ",
    "alanjds": "Disclaimer: I am creating a Django database backend for RQLite, based on SQLite backend code, and disabling code that is not expected to work.. It is just the standard sqlite backend with pyrqlite as the connector and transactions disabled ;)\nWill upload as soon as the existing sqlite tests passes -- minus the transaction ones --\nAnd thanks anyone for the DB-API driver. I would not start the Django backed if there was not the DB-API done.. I see. Yours looks to be working. What version of RQLite are you using? I see a naked \"X-Rqlite-Version: 3\" header on your responses.\nMine shows  \"X-Rqlite-Version: v3.9.1\". Tried with the just-relased 3.9.2: Seems to be unrelated to -nosel. This is the captured network stream with Wireshark:\n```\nPOST /db/execute?transaction HTTP/1.1\nHost: localhost:4001\nAccept-Encoding: identity\nContent-Length: 28\nContent-Type: application/json\n[\"create table test(x foo)\"]\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nX-Rqlite-Version: v3.9.2\nDate: Mon, 16 Jan 2017 15:45:54 GMT\nContent-Length: 52\n{\"results\":[{\"last_insert_id\":1,\"rows_affected\":1}]}\nPOST /db/execute?transaction HTTP/1.1\nHost: localhost:4001\nAccept-Encoding: identity\nContent-Length: 31\nContent-Type: application/json\n[\"insert into test values (1)\"]\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nX-Rqlite-Version: v3.9.2\nDate: Mon, 16 Jan 2017 15:45:54 GMT\nContent-Length: 52\n{\"results\":[{\"last_insert_id\":1,\"rows_affected\":1}]}\nPOST /db/execute?transaction HTTP/1.1\nHost: localhost:4001\nAccept-Encoding: identity\nContent-Length: 67\nContent-Type: application/json\n[\"with bar as (select * from test) select * from test where x = 1\"]\nHTTP/1.1 200 OK\nContent-Type: application/json; charset=utf-8\nX-Rqlite-Version: v3.9.2\nDate: Mon, 16 Jan 2017 15:45:54 GMT\nContent-Length: 52\n{\"results\":[{\"last_insert_id\":1,\"rows_affected\":1}]}\n```\nI am trying to build from the sources right now to see if it changes anything besides the version header.. Hum... So the issue cames from here? https://github.com/rqlite/pyrqlite/blob/master/src/pyrqlite/cursors.py#L98\nAnyway, I would expect that everything that works on /db/query to work on /db/execute too. Thanks for pointing the difference.\nNow I am thinking in how to detect on client side if some query alters data.... Nice. For me the most important is behaviour consistency. Right now I cannot have a way to detect if I should or should not decode the answer based on the type.. You mean... query = \"select 'other' as \\\"\" + \"x [b1b1]\".encode(\"hex\") + '\\\"' should work?. Well, this is a nice hack.\nIt will work until Django's implementation changes. Should not occur a lot, but will need to be tracked.\nI vote for being accepted after polished a bit, but keep pursuing a way to transfer client-side functions code to serverside.. I understand the need to \"bring the code along\" because Golang does not allow dynamic bindings usually, but narrowing to Django needs is wrong.\nThe Right Way is to have a db-side programming language. But how?\nTalking with @sbneto we thought about wire-transfering the code to the servers and compile + link locally, but is hard in Go.\nIf something like a Lua runtime got embedded, at least the ORM could send its functions ahead of compilation time, without needing the whole compilation toolchain on the server.. Another decision: should this PR be accepted as a keg-leg until a db-side language got integrated, just to support at least one ORM? Is this a good compromise?\nI do love to see Django and RQLite working, but I an undecided.. @otoolep: Is a weird word for \"handicapped by too much beer last night\". Sorry for that.\nIn the context, the idea is intended to be of \"so ugly that should be madness to be merged and will be replaced very soon\".\n. I understand, @otoolep. However, please keep in mind that any application needing DB-side custom procedures will not be able to be ported for now.\nI am sure you have not spare hands to do everything. It is just a reminder of the consequences of this decision.. > @tomdesair you should be able to use rqlite with django without this PR too.\nI cannot assure that. Without this PR the ORM of Django does not pass the tests for the SQLite backend. You may be able to do something, but YMMV.. ",
    "glycerine": "r is nil at github.com/rqlite/rqlite/db/db.go:251, even for empty \";\" command. I suspect some wierdness with the go-sqlite3 driver and/or go1.8rc1.. rqlite command: \";\" or any command. rqlited will crash on its own if there is an existing database; no command from rqlite required.\n~~~\n$ rqlite\n127.0.0.1:4001> ;\nERR! Post http://127.0.0.1:4001/db/execute?pretty&timings: EOF\n127.0.0.1:4001> \n~~~. both r and err are nil at db/db.go:251 when the panic happens (obviously due to r being nil).. agreed. there's new code in both go1.8rc1 database package and new code that uses it in the go-sqlite3 driver.. do you have a known-good git hash for github.com/mattn/go-sqlite3?. also happens with go1.7.3 darwin/amd64, so it doesn't appear to be due to go1.8rc1.. The latest release has the panic as well.. ",
    "insionng": "Thanks reply~. ",
    "omerkorenn": "Hi,\nSorry for the late response.\nThe timeout is indeed the problem.\nIt is hard to know how much time is needed to load the data.\nIt really machine/dataset dependent, anyway i aim to use a ~32GB dataset.\nDo you think it is possible to overcome the problem by trying to connect to the raft after loading the data instead of in parallel ?. Yeah sure, it worked with 120s. Thanks i'll try this.\nI saw that the store.open(..)\nhttps://github.com/rqlite/rqlite/blob/master/cmd/rqlited/main.go#L176\nreturns before loading all data to memory, and publishAPIAddr is being called after this\nhttps://github.com/rqlite/rqlite/blob/master/cmd/rqlited/main.go#L216\ncausing the process to fail after certain timeout.\nSo i thought maybe it is possible some how to wait the store to be ready before calling publishAPIAddr.\nBut i'm not sure about it\n. ",
    "kenshaw": "I'm not going to write a full parser. Instead, I'm just going to fake it. As far as I can tell, there's only about 8 or 9 different \"beginning\" words that should be one versus the other. At the end of the day with rqlite, you might want to access the actual underlying sqlite libraries directly. Sqlite has a full blown parser built in, so I would imagine it'd be relatively straightforward to start from there?\nOriginally, when I was planning usql, I was thinking I would bind to the postgres parser. But that's icky.. Yes, I'm deeply embarrassed. I had too many tabs open simultaneously. Apologies!. @otoolep Just want to point out that I wrote some notes on the usql issue. I think for rqlite, you might be able to get away with the same trick I am using in xo to inspect queries:\nsql\nCREATE TEMPORARY VIEW __random_id AS <query>. ",
    "MrHacky": "as i am also in need of this functionality and was reading through this issue and thinking about the problems with it, i would first like to clear up a misunderstanding about sqlite.\nSpecifically, if there is a crash after sqlite BEGIN but before COMMIT, the next time you open the database it will be as if none of the statements after BEGIN ever happened. sqlite has its own log/journal and only a COMMIT will make a sqlite transaction permanent.\nAlso i thought of a possible trick to handle some of the problems mentioned:\n- The leader does a BEGIN and returns a tx id.\n- That transaction accumulates queries (and executes them to return results)\n- when done, execute a ROLLBACK abandoning the sqlite transaction, and use the list of accumulated queries as a normal raft log entry. ",
    "Esowteric": "Thanks, this is a sticking point for me, too. I'm running a node.js app at the moment using a single instance of better-sqlite3, and at some point I'm pretty sure I'll need a distributed setup.\nI was hoping that rqlite might be the way to go, but I need to be able to manually BEGIN a transaction (unless I'm already in a transaction) and call a function (keeping others locked out, waiting) that runs an insert statement and returns an ID. Then I do a bit more processing using that ID, and either COMMIT if everything has gone okay and I'm not already in a transaction, or ROLLBACK if I'm not already in a transaction.\nThis works fine with better-sqlite3 and it might work if rqlite operated statement-by-statement, including BEGIN and COMMIT or ROLLBACK, but not as it stands.  \nTCP support sounds like a good idea, too.\nAnyhow, thanks again: Will keep checking on progress and looking around for alternatives.\n~ Eric T.. Thanks a lot for the reply and the discussion thread, @otoolep.. ",
    "freeekanayaka": "@otoolep @Esowteric you might want to give a look at dqlite. That's all correct. The patch on original SQLite is very light and it really won't compromise the quality of SQLite, although of course it's something that might make people not so happy. I'll be proposing upstream to merge the patch in the coming weeks or months, when I'll also complete some rough edges of dqlite (it currently requires quite a bit of plumbing for consumers, so I'll added some abstractions on top of the low-level Driver to make that easier).. ",
    "JeanGolang": "Hi again, Philip!\nDo you happen to know how to fix this problem? I guess it's a \"bug\" in hashicorp/raft implementation.\nBecause as far as I understood, hashicorp/raft doesn't call Snapshot() and Persist() concurrently, so I don't know of a way to communicate chunks of the database between Snapshot() and Persist() - do you have an idea how to do this?. otoolep, thanks a lot! I've sorted it out with the raft library authors - here\nI guess this could be closed, as if it's more of the raft issue than an issue with your package.. ",
    "gedw99": "would it make sense to use QUIC, which is UDP based and 100% golang based ?\n. What you can't read minds ?\nhttps://en.m.wikipedia.org/wiki/QUIC\nhttps://github.com/lucas-clemente/quic-go\nThis one made my day:)\nhttps://github.com/simia-tech/netx\nRead the slide first\n. I should have said choreography layer, not orchestration layer. Friesian slip I guess :(. ",
    "riaan53": "Discovery can be done nicely with https://github.com/hashicorp/serf :). ",
    "anfho93": "Hi, the process i follow to run the software is just clone the master branch from github, the run get -d ./... , and after that go install ./...,\nAlso i have all the nodes in the same PC, running from the same rqlite binary file, but on different ports\nAnd this is the output from all the running nodes.\nhost in port 4001\nhttps://drive.google.com/open?id=0B9lwPlBmlRuAZm4tbV9GaDdZc3M\nhost in port 4003\nhttps://drive.google.com/open?id=0B9lwPlBmlRuAYnlBOFM2QzkwX0k\nhost in port 4005\nhttps://drive.google.com/open?id=0B9lwPlBmlRuATE5hb2RvM2JQSm8\n. Looks like i have troubles with my environment and building the rqlite from source code. So i went back to the 3.12.0  version and built it  again but same thing happens. \nI tried to download the latest release from https://github.com/rqlite/rqlite/releases and unfortunately the same thing happens.\nI will try to run this on other computer, and i will let you know about it. Thanks for your quick answer.. Ok i tried with a new docker  and this is the full process \nhttps://gist.github.com/anfho93/fa6cbed9f56a61b9201e79c1d3dfec97\n. This is the full process downloading the prebuilt binaries\nhttps://gist.github.com/anfho93/1960026cb8550283b6729c7a98d68fcf\nAnd it works, the funny fact is that a couple of days ago it was working with go1.8. \n. I will try to re build it with go 1.7.1 and i will let you know\n. Thanks a lot. . Works perfectly now, thank  you  so much @otoolep . ",
    "wil222": "Hi,\nI ran into the exact same issue. I build it from the sources using go1.9 on my Raspberry Pi 3 (ARM). I used the source code at commit 2eb02dc14235583f7ed1e7fa9d9f9a8d4e86a426 on branch master (last commit up to now).\nAt the end is the result of curl localhost:4001/status?pretty. Everything seems ok on the other nodes : http.redirect = \"localhost:4001\", and store.raft.state = \"Follower\".\nI will try it with go1.8 and report later. I don't know a single thing about go, but if you have bugs everytime you try to upgrade your version without a single warning... Well I don't want to know more about it.\n{\n    \"build\": {\n        \"branch\": \"\",\n        \"build_time\": \"\",\n        \"commit\": \"\",\n        \"version\": \"\"\n    },\n    \"http\": {\n        \"addr\": \"127.0.0.1:4001\",\n        \"auth\": \"disabled\",\n        \"conn_idle_timeout\": \"1m0s\",\n        \"conn_tx_timeout\": \"10s\",\n        \"redirect\": \"localhost:4001\"\n    },\n    \"node\": {\n        \"start_time\": \"2018-07-11T13:10:47.431260462+02:00\",\n        \"uptime\": \"38m49.599303526s\"\n    },\n    \"runtime\": {\n        \"GOARCH\": \"arm\",\n        \"GOMAXPROCS\": 4,\n        \"GOOS\": \"linux\",\n        \"num_cpu\": 4,\n        \"num_goroutine\": 21,\n        \"version\": \"go1.9\"\n    },\n    \"store\": {\n        \"addr\": \"127.0.0.1:4002\",\n        \"apply_timeout\": \"10s\",\n        \"conn_poll_period\": \"10s\",\n        \"db_conf\": {\n            \"DSN\": \"\",\n            \"Memory\": true\n        },\n        \"dir\": \"/home/pi/node.1\",\n        \"heartbeat_timeout\": \"1s\",\n        \"leader\": {\n            \"addr\": \"127.0.0.1:4002\",\n            \"node_id\": \"localhost:4002\"\n        },\n        \"metadata\": {\n            \"localhost:4002\": {\n                \"api_addr\": \"localhost:4001\"\n            },\n            \"localhost:4004\": {\n                \"api_addr\": \"localhost:4003\"\n            },\n            \"localhost:4006\": {\n                \"api_addr\": \"localhost:4005\"\n            }\n        },\n        \"node_id\": \"localhost:4002\",\n        \"nodes\": [\n            {\n                \"id\": \"localhost:4002\",\n                \"addr\": \"127.0.0.1:4002\"\n            },\n            {\n                \"id\": \"localhost:4004\",\n                \"addr\": \"127.0.0.1:4004\"\n            },\n            {\n                \"id\": \"localhost:4006\",\n                \"addr\": \"127.0.0.1:4006\"\n            }\n        ],\n        \"raft\": {\n            \"applied_index\": \"10\",\n            \"commit_index\": \"10\",\n            \"fsm_pending\": \"0\",\n            \"last_contact\": \"0\",\n            \"last_log_index\": \"10\",\n            \"last_log_term\": \"12\",\n            \"last_snapshot_index\": \"0\",\n            \"last_snapshot_term\": \"0\",\n            \"latest_configuration\": \"[{Suffrage:Voter ID:localhost:4002 Address:127.0.0.1:4002} {Suffrage:Voter ID:localhost:4004 Address:127.0.0.1:4004} {Suffrage:Voter ID:localhost:4006 Address:127.0.0.1:4006}]\",\n            \"latest_configuration_index\": \"6\",\n            \"num_peers\": \"2\",\n            \"protocol_version\": \"3\",\n            \"protocol_version_max\": \"3\",\n            \"protocol_version_min\": \"0\",\n            \"snapshot_version_max\": \"1\",\n            \"snapshot_version_min\": \"0\",\n            \"state\": \"Leader\",\n            \"term\": \"12\"\n        },\n        \"snapshot_threshold\": 8192,\n        \"sqlite3\": {\n            \"dsn\": \"\",\n            \"fk_constraints\": \"disabled\",\n            \"path\": \":memory:\",\n            \"version\": \"3.24.0\"\n        }\n    }\n}\n. Ok, I'm a bit confused here. I tried the following combinations and none worked :\n\ngo1.7 on ARM\ngo1.8 on ARM\ngo1.9 on ARM\ngo1.8 on amd64\ngo1.10 on amd64\n\nWith commit 2eb02dc14235583f7ed1e7fa9d9f9a8d4e86a426 \nAll give the same result :\nThinkPad-E560 ~/rqlite $ ./rqlite\n127.0.0.1:4001> CREATE TABLE foo (id INTEGER NOT NULL PRIMARY KEY, name TEXT)\n0 row affected (0.000000 sec)\n127.0.0.1:4001>  INSERT INTO foo(name) VALUES(\"fiona\")\n1 row affected (0.000000 sec)\n127.0.0.1:4001> select * from foo\n+----+-------+\n| id | name  |\n+----+-------+\n| 1  | fiona |\n+----+-------+\n127.0.0.1:4001> \nEOF (CTRL+D)\nThinkPad-E560 ~/rqlite $ ./rqlite -p 4003\n127.0.0.1:4003> select * from foo\nERR! unexpected end of JSON input\nI am guessing I am not compiling it the way I should, even if I am following the steps of package.sh with very few modifications because the releases indeed work like they should :\n```\nREPO_URL=\"https://github.com/rqlite/rqlite\"\nVERSION=$1\nRELEASE_ID=$2\nAPI_TOKEN=$3\ntmp_build=mktemp -d\ntmp_pkg=mktemp -d\nkernel=uname -s\nmachine=uname -m\nif [ \"$machine\" == \"x86_64\" ]; then\n    machine=\"amd64\"\nfi\nmkdir -p $tmp_build/src/github.com/rqlite\nexport GOPATH=$tmp_build\ncd $tmp_build/src/github.com/rqlite\ngit clone $REPO_URL\ncd rqlite\ngo get -d ./...\nbranch=git rev-parse --abbrev-ref HEAD\ncommit=git rev-parse HEAD\nkernel=uname -s\nbuildtime=date +%Y-%m-%dT%T%z\ngo install -ldflags=\"-X main.version=$VERSION -X main.branch=$branch -X main.commit=$commit -X main.buildtime=$buildtime\" ./...\n```\nI am interested in knowing what I am doing wrong because I would like to compile it on ARM, even though I can't figure out what is wrong even for AMD.\n. Don't mind me. I got it working with v4.3.0 77e345b97c5597c1ef86e75e690539de369b8dd3\nHowever, it means there is a bug since this version.. Hi,\nI'm wondering why you go through all those steps... I just ran into the same issue but I was able to compile rqlite directly on the raspberry just by downloading the sources and by running the relevant part of package.sh\nIt works like a charm while being quicker to compile. ",
    "little-pan": "This issue also occurs in rqlite-v5.0 on windows 8 x86_64. The bugs are at github.com/rqlite/rqlite/cmd/rqlite/query.go makeQueryRequest() and github.com/rqlite/rqlite/http/service.go handleQuery():\n```golang\n// github.com/rqlite/rqlite/cmd/rqlite/query.go makeQueryRequest() \nfunc makeQueryRequest(line string) func(string) (http.Request, error) {\n    requestData := strings.NewReader(makeJSONBody(line))\n    return func(urlStr string) (http.Request, error) {\n        req, err := http.NewRequest(\"POST\", urlStr, requestData)\n        if err != nil {\n            return nil, err\n        }\n        return req, nil\n    }\n}\n// github.com/rqlite/rqlite/http/service.go handleQuery()\n    var resp Response\n    results, err := queryer.Query(&store.QueryRequest{queries, timings, isAtomic, lvl})\n    if err != nil {\n        if err == store.ErrNotLeader {\n            leader := s.leaderAPIAddr()\n            if leader == \"\" {\n                http.Error(w, err.Error(), http.StatusServiceUnavailable)\n                return\n            }\n        // - little-pan Bug-fix: should restore the shifted path.\n        r.URL.Path = \"/db/query\"\n        // - little-pan\n        redirect := s.FormRedirect(r, leader)\n        // - little-pan\n        s.logger.Printf(\"query: redirect to %s\", redirect)\n        http.Redirect(w, r, redirect, http.StatusMovedPermanently)\n        return\n\nThe requestData is a Reader, shouldn't be read many times in the returned func! And only jsonBody string can be reused.A fix method may be:golang\nfunc makeQueryRequest(line string) func(string) (http.Request, error) {\n    //Bug-fix: requestData is a Reader, shouldn't be read many times!\n    //And only jsonBody string can be reused.\n    // @since 2019-01-26 little-pan\n    //requestData := strings.NewReader(makeJSONBody(line))\n    jsonBody := makeJSONBody(line)\n    return func(urlStr string) (http.Request, error) {\n        requestData := strings.NewReader(jsonBody)\n        req, err := http.NewRequest(\"POST\", urlStr, requestData)\n        if err != nil {\n            return nil, err\n        }\n        return req, nil\n    }\n}\n. @otoolep There are many bugs here. The first, **the result func** of makeQueryRequest() is called multiple times when the rqlited follower node returns http 302(eg. this node not the leader). And another bug(such issues also in other http api implementations) exists in following function:golang\n// github.com/rqlite/rqlite/http/service.go handleQuery()\nvar resp Response\nresults, err := queryer.Query(&store.QueryRequest{queries, timings, isAtomic, lvl})\nif err != nil {\n    if err == store.ErrNotLeader {\n        leader := s.leaderAPIAddr()\n        if leader == \"\" {\n            http.Error(w, err.Error(), http.StatusServiceUnavailable)\n            return\n        }\n    // - little-pan Bug-fix: should restore the shifted path here.\n    r.URL.Path = \"/db/query\"\n\n    redirect := s.FormRedirect(r, leader)\n\n    // - little-pan\n    s.logger.Printf(\"query: redirect to %s\", redirect)\n\n    http.Redirect(w, r, redirect, http.StatusMovedPermanently)\n    return\n\n// ...\nWhen s.FormRedirect(r, leader) called in the handleQuery() func, the r.URL.Path(has been shifted in the front handler steps) doesn't be restored to original request URL path, then set as Location header of http redirection. This way can lead to \"ERR! unexpected end of JSON input\"(status code http 400 actually), because of the Location header of http redirection has been truncated and incorrect.\n. And no such issues are in rqlite v4.4.0(http api implementation relatively simple and stable), but the redirection is a bit slow in windows 8 x86_64(the performation issue not in centos 7 x86_64).. Making snapshot in current rqlite hraftd spends too long time(eg. 30 to 60 seconds for millions of rows data).. @otoolep This means that the SQLite database can't be too big(such as more than 1GB) in rqlite. Is it true? For supporting more data, can we solve it by using circular raft log(deleting commited raft log and the snapshot only includes uncommited raft log) that likes MySQL tx log.. Version info: rqlite -v4.4.0, centos 7 x86_64.. # .status\n192.168.145.101:4001> .status\nbuild:\n  branch: 4.3.0-patch\n  build_time: 2019-01-03T19:35:08-0500\n  commit: 2e91858e1ee0feee19f4c20c6f56a21261bcd44a\n  version: v4.4.0\nhttp:\n  redirect: 192.168.145.101:4005\n  addr: 192.168.145.101:4001\n  auth: disabled\nmux:\n  addr: 127.0.0.1:4002\n  encrypted: false\n  timeout: 30s\nnode:\n  start_time: 2019-01-12T10:16:52.640983407+08:00\n  uptime: 9m8.9043421s\nruntime:\n  version: go1.10\n  GOARCH: amd64\n  GOMAXPROCS: 2\n  GOOS: linux\n  numCPU: 2\n  numGoroutine: 19\nstore:\n  apply_timeout: 10s\n  db_conf:\n    DSN:\n    Memory: true\n  dir: /root/rqlite/rqlite-v4.4.0-linux-amd64/node.1\n  election_timeout: 1s\n  heartbeat_timeout: 1s\n  snapshot_threshold: 8192\n  addr: 127.0.0.1:4002\n  leader: 127.0.0.1:4006\n  meta:\n    APIPeers:\n      127.0.0.1:4002: 192.168.145.101:4001\n      127.0.0.1:4004: 192.168.145.101:4003\n      127.0.0.1:4006: 192.168.145.101:4005\n  open_timeout: 2m0s\n  peers: [127.0.0.1:4006 127.0.0.1:4002 127.0.0.1:4004]\n  raft:\n    term: 266\n    commit_index: 5860\n    last_log_term: 266\n    last_snapshot_term: 0\n    num_peers: 2\n    last_snapshot_index: 0\n    state: Follower\n    applied_index: 5860\n    fsm_pending: 0\n    last_contact: 13.173116ms\n    last_log_index: 5860\n  sqlite3:\n    dns:\n    fk_constraints: disabled\n    path: :memory:\n    version: 3.26.0\n```\n.expvar\n192.168.145.101:4001> .expvar\nhttp:\n  executions: 3760\n  queries: 3\n  backups: 0\nmemstats:\n  Lookups: 2.0854025e+07\n  HeapObjects: 36756\n  DebugGC: false\n  Frees: 1.0984228e+08\n  StackSys: 720896\n  MSpanSys: 245760\n  LastGC: 1.547259952983262e+18\n  PauseNs: [41660 72498 127441 124731 53140 56255 58968 117683 67057 975766 85266 28535 57720 67512 68181 64748 109965 158391 76713 103247 34824 658934 51572 70319 69533 75766 27437 2.149375e+06 101534 19214 99298 884615 121696 53226 26475 106516 271391 25840 2.911155e+06 415884 718692 801122 108529 817245 247476 32797 1.0112573e+07 112262 2.794807e+06 28147 45343 49760 25555 46681 23907 187808 74608 60314 86489 254015 84423 60146 57272 160444 32886 55269 96942 920074 53187 30556 53397 65297 33940 519662 1.346879e+06 1.192228e+06 228979 67700 74565 43672 391315 74737 22999 54435 1.0545456e+07 78499 63897 272563 99001 141797 24025 101323 63868 44816 47076 63578 643809 117975 19549 980731 110343 64837 357888 50829 62869 289046 50562 47077 59021 59977 117747 4.286283e+06 1.2274899e+07 61281 80124 325651 67409 2.517296e+06 23003 127996 1.01501e+06 23814 138735 1.2321512e+07 53348 72503 26533 1.014638e+06 27105 226362 70532 33600 94451 32168 54630 58726 168355 99538 1.148131e+06 90242 78465 281042 40869 77031 6768\n2 43441 70554 52736 29634 85682 26440 24498 91950 96694 33813 21880 83429 103792 46656 84229 64761 781576 97251 1.205807e+06 26541 44734 135346 61741 98213 1.944609e+06 1.195871e+06 28842 69687 78291 608856 644267 1.033164e+06 100146 57450 1.039334e+06 955447 18722 34045 34543 20135 36569 26065 65193 31679 128061 23262 794986 6.781652e+06 5.333895e+06 20440 31955 31304 40259 80457 73001 90350 163808 71801 2.749198e+06 52871 21562 1.5255561e+07 24409 36375 98898 33438 56952 37992 22269 714130 72235 75304 59973 53723 47006 47309 444090 23747 25835 27056 36670 563392 39134 392152 52074 105846 25235 38007 23197 175736 85724 28547 25461 27147 1.382337e+06 29500 84083 26788 93910 42367 83201 483642 68562 22714 89155 24350 75137 557448 132815 48940 65384]\n  TotalAlloc: 9.894772872e+09\n  StackInuse: 720896\n  BuckHashSys: 1.501302e+06\n  NumForcedGC: 0\n  GCCPUFraction: 0.006131288665470086\n  Mallocs: 1.09879036e+08\n  HeapAlloc: 2.10064e+06\n  HeapSys: 3.3882112e+07\n  MSpanInuse: 46056\n  NextGC: 4.194304e+06\n  PauseTotalNs: 2.569822775e+09\n  HeapIdle: 3.080192e+07\n  HeapInuse: 3.080192e+06\n  MCacheSys: 16384\n  MCacheInuse: 3472\n  PauseEnd: [1.5472599450766172e+18 1.5472599451284915e+18 1.547259945181261e+18 1.5472599452359887e+18 1.547259945290525e+18 1.547259945344731e+18 1.547259945395512e+18 1.5472599454503616e+18 1.5472599455023913e+18 1.5472599455780116e+18 1.5472599456307994e+18 1.547259945680291e+18 1.547259945729967e+18 1.5472599457812672e+18 1.5472599458297405e+18 1.5472599458796406e+18 1.5472599459311962e+18 1.547259945982559e+18 1.5472599460262034e+18 1.5472599460792763e+18 1.5472599461558264e+18 1.5472599461898634e+18 1.5472599462435845e+18 1.5472599463210665e+18 1.5472599463580127e+18 1.5472599464192358e+18 1.5472599464811686e+18 1.547259946553707e+18 1.5472599465927962e+18 1.547259946672981e+18 1.547259946744105e+18 1.5472599467878618e+18 1.547259946843475e+18 1.547259946906386e+18 1.5472599469584801e+18 1.5472599470106232e+18 1.5472599470582157e+18 1.5472599471088128e+18 1.5472599471723008e+18 1.547259947232924e+18 1.547259947277852e+18 1.5472599473206113e+18 1.5472599473862697e+18 1.5472599474321597e+18 1.54725994753\n14621e+18 1.5472599482363978e+18 1.547259948315888e+18 1.547259948377911e+18 1.5472599484322455e+18 1.5472599484878758e+18 1.5472599485555978e+18 1.5472599490484726e+18 1.5472599491158423e+18 1.5472599491791882e+18 1.5472599492384463e+18 1.547259949312428e+18 1.547259949382846e+18 1.5472599494350674e+18 1.5472599494938028e+18 1.5472599495476662e+18 1.5472599496080786e+18 1.5472599496553748e+18 1.5472599497161167e+18 1.547259949757506e+18 1.5472599498082143e+18 1.547259949854563e+18 1.5472599499135252e+18 1.547259949964365e+18 1.5472599500294838e+18 1.5472599500740093e+18 1.5472599501251607e+18 1.5472599501689897e+18 1.5472599502262536e+18 1.5472599502717028e+18 1.5472599503293942e+18 1.5472599503777743e+18 1.547259950424378e+18 1.547259950476152e+18 1.5472599505538284e+18 1.5472599506103928e+18 1.5472599506747587e+18 1.5472599507187556e+18 1.5472599507943357e+18 1.5472599508610365e+18 1.5472599509258857e+18 1.5472599509693932e+18 1.5472599510219717e+18 1.547259951756686e+18 1.547259952983262e+18 1.54725993324\n55483e+18 1.547259933300555e+18 1.5472599333632835e+18 1.5472599334274732e+18 1.5472599334682936e+18 1.5472599335475328e+18 1.5472599335976812e+18 1.5472599336520425e+18 1.547259933703185e+18 1.5472599337608817e+18 1.5472599338174065e+18 1.5472599338988017e+18 1.5472599339590482e+18 1.5472599340487462e+18 1.5472599341181978e+18 1.5472599342157601e+18 1.5472599342795062e+18 1.547259934331929e+18 1.5472599344171034e+18 1.547259934442517e+18 1.5472599344910205e+18 1.5472599345512023e+18 1.5472599346049057e+18 1.5472599347130762e+18 1.5472599347365128e+18 1.5472599347862543e+18 1.5472599348380833e+18 1.5472599348928018e+18 1.5472599349648435e+18 1.5472599349995768e+18 1.5472599350667515e+18 1.54725993513394e+18 1.5472599351968627e+18 1.5472599352472297e+18 1.5472599353144238e+18 1.5472599353820718e+18 1.5472599354509827e+18 1.547259935505876e+18 1.5472599355505792e+18 1.5472599356083364e+18 1.5472599356612024e+18 1.5472599357292823e+18 1.5472599357728543e+18 1.5472599358284956e+18 1.5472599358807557e+18 1.5472599\n359433444e+18 1.5472599359930301e+18 1.5472599360426284e+18 1.5472599360920916e+18 1.547259936141537e+18 1.547259936190924e+18 1.547259936785687e+18 1.5472599370696783e+18 1.5472599371487813e+18 1.5472599372317059e+18 1.5472599373209324e+18 1.547259937378882e+18 1.5472599374599862e+18 1.5472599375224264e+18 1.5472599375686354e+18 1.5472599376283249e+18 1.5472599376734558e+18 1.5472599377310305e+18 1.5472599377775409e+18 1.5472599378331244e+18 1.5472599378773235e+18 1.5472599379318262e+18 1.5472599379844032e+18 1.5472599380419226e+18 1.547259938099778e+18 1.5472599381571656e+18 1.5472599382110515e+18 1.5472599382668014e+18 1.5472599383204626e+18 1.5472599383810737e+18 1.5472599384322307e+18 1.5472599384938376e+18 1.547259938543273e+18 1.5472599386030387e+18 1.5472599386503299e+18 1.5472599387149837e+18 1.547259938788597e+18 1.5472599388215508e+18 1.547259938876727e+18 1.5472599389326157e+18 1.5472599389748628e+18 1.5472599390279898e+18 1.5472599390752202e+18 1.5472599391293555e+18 1.5472599392068628e+18 1.5472\n599392590723e+18 1.5472599393039887e+18 1.5472599394129275e+18 1.5472599401665418e+18 1.5472599402146808e+18 1.5472599402852495e+18 1.5472599403337306e+18 1.5472599404104412e+18 1.5472599404736102e+18 1.547259940545975e+18 1.5472599406048015e+18 1.5472599407139837e+18 1.5472599408073436e+18 1.5472599408639662e+18 1.54725994090844e+18 1.5472599409531448e+18 1.5472599410037276e+18 1.5472599410806116e+18 1.5472599411495383e+18 1.5472599412112558e+18 1.54725994126711e+18 1.5472599413270449e+18 1.5472599413898831e+18 1.5472599414643812e+18 1.5472599415051177e+18 1.5472599415782295e+18 1.5472599416413304e+18 1.5472599416814856e+18 1.5472599417224637e+18 1.5472599417639222e+18 1.547259941845322e+18 1.547259942503401e+18 1.547259942584249e+18 1.5472599426630807e+18 1.5472599427239818e+18 1.5472599427988664e+18 1.547259942843077e+18 1.5472599429006994e+18 1.5472599429497132e+18 1.5472599430121848e+18 1.547259943060392e+18 1.5472599431178793e+18 1.5472599431701373e+18 1.5472599432244751e+18 1.5472599432815012e+18 1.547\n259943333452e+18 1.5472599433838625e+18 1.5472599434389857e+18 1.5472599434853542e+18 1.5472599435450929e+18 1.54725994359656e+18 1.5472599436507302e+18 1.5472599436979395e+18 1.5472599437504394e+18 1.5472599438105009e+18 1.547259943867929e+18 1.5472599439222615e+18 1.5472599439771423e+18 1.547259944019378e+18 1.547259944073834e+18 1.5472599441189786e+18 1.547259944168485e+18 1.5472599442110351e+18 1.5472599442689787e+18 1.5472599443285376e+18 1.5472599443873185e+18 1.5472599444496294e+18 1.5472599445061197e+18 1.547259944551932e+18 1.5472599446098752e+18 1.5472599446540877e+18 1.5472599447143137e+18 1.547259944773091e+18 1.5472599448394499e+18 1.5472599448991572e+18 1.5472599449598712e+18 1.5472599450282383e+18]\n  EnableGC: true\n  Sys: 3.8471928e+07\n  HeapReleased: 2.6427392e+07\n  GCSys: 1.57696e+06\n  BySize: [map[Size:0 Mallocs:0 Frees:0] map[Size:8 Mallocs:2.0181187e+07 Frees:2.0176961e+07] map[Frees:4.0570499e+07 Size:16 Mallocs:4.0584872e+07] map[Frees:386416 Size:32 Mallocs:393674] map[Size:48 Mallocs:2.8278615e+07 Frees:2.8272353e+07] map[Size:64 Mallocs:212345 Frees:211485] map[Size:80 Mallocs:9.50179e+06 Frees:9.500052e+06] map[Size:96 Mallocs:59257 Frees:57674] map[Size:112 Mallocs:45503 Frees:45474] map[Size:128 Mallocs:24563 Frees:24533] map[Size:144 Mallocs:20909 Frees:20893] map[Size:160 Mallocs:46 Frees:14] map[Size:176 Mallocs:20 Frees:12] map[Size:192 Mallocs:5543 Frees:5540] map[Size:208 Mallocs:13433 Frees:13397] map[Size:224 Mallocs:13410 Frees:13404] map[Mallocs:5 Frees:2 Size:240] map[Size:256 Mallocs:32902 Frees:32868] map[Size:288 Mallocs:19276 Frees:19252] map[Mallocs:9583 Frees:9579 Size:320] map[Size:352 Mallocs:15081 Frees:15069] map[Size:384 Mallocs:1952 Frees:1882] map[Size:416 Mallocs:16 Frees:11] map[Frees:9576 Size:448 Mallocs:9578] map[Size:480 Mallocs:9 Frees:7] map[Size\n:512 Mallocs:15231 Frees:15225] map[Size:576 Mallocs:22 Frees:12] map[Size:640 Mallocs:7 Frees:3] map[Size:704 Mallocs:9590 Frees:9586] map[Size:768 Mallocs:3872 Frees:3870] map[Size:896 Mallocs:348 Frees:344] map[Size:1024 Mallocs:23256 Frees:23240] map[Size:1152 Mallocs:345 Frees:341] map[Size:1280 Mallocs:339 Frees:338] map[Size:1408 Mallocs:375 Frees:373] map[Size:1536 Mallocs:13805 Frees:13803] map[Size:1792 Mallocs:1111 Frees:1104] map[Size:2048 Mallocs:10565 Frees:10547] map[Frees:10435 Size:2304 Mallocs:10441] map[Size:2688 Mallocs:732 Frees:730] map[Size:3072 Mallocs:753 Frees:753] map[Size:3200 Mallocs:181 Frees:181] map[Mallocs:9851 Frees:9850 Size:3456] map[Size:4096 Mallocs:27354 Frees:27330] map[Frees:2 Size:4864 Mallocs:2] map[Frees:9575 Size:5376 Mallocs:9578] map[Size:6144 Mallocs:490 Frees:486] map[Frees:264 Size:6528 Mallocs:264] map[Size:6784 Mallocs:178 Frees:178] map[Frees:88 Size:6912 Mallocs:88] map[Size:8192 Mallocs:20072 Frees:20069] map[Size:9472 Mallocs:913 Frees:910] map[Frees:176\n Size:9728 Mallocs:176] map[Mallocs:4594 Frees:4593 Size:10240] map[Size:10880 Mallocs:396 Frees:396] map[Size:12288 Mallocs:9819 Frees:9817] map[Size:13568 Mallocs:4462 Frees:4461] map[Size:14336 Mallocs:136 Frees:136] map[Mallocs:4130 Frees:4128 Size:16384] map[Size:18432 Mallocs:14184 Frees:14182] map[Size:19072 Mallocs:110 Frees:110]]\n  Alloc: 2.10064e+06\n  OtherSys: 528514\n  NumGC: 3673\ncmdline: [./rqlited -http-addr 192.168.145.101:4001 -raft-addr localhost:4002 ./node.1]\ndb:\n  execution_errors: 10\n  executions: 1.0058018e+07\n  queries: 5\n  query_transactions: 0\n  execute_transactions: 5816. ## The status after http 503\n```\n22:16:42.021 i = 5400000\n22:16:53.759 i = 5500000\n22:17:03.197 i = 5600000\n22:17:12.927 i = 5700000\n22:17:22.160 i = 5800000\n22:17:35.829 i = 5900000\n22:17:47.958 i = 6000000\n22:17:58.163 i = 6100000\n22:18:11.105 i = 6200000\n22:18:21.274 i = 6300000\n22:18:33.801 i = 6400000\n22:18:45.995 i = 6500000\n22:18:57.076 i = 6600000\n22:19:07.908 i = 6700000\n22:19:20.716 i = 6800000\ncom.google.api.client.http.HttpResponseException: 503 Service Unavailable\nnot leader\n    at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1137)\n    at com.rqlite.impl.ExecuteRequest.execute(ExecuteRequest.java:19)\n    at com.rqlite.impl.RqliteImpl.Execute(RqliteImpl.java:63)\n    at BatchInsert.main(BatchInsert.java:51)\n\nstatus:\n{\n    \"build\": {\n        \"branch\": \"4.3.0-patch\",\n        \"build_time\": \"2019-01-03T19:35:08-0500\",\n        \"commit\": \"2e91858e1ee0feee19f4c20c6f56a21261bcd44a\",\n        \"version\": \"v4.4.0\"\n    },\n    \"http\": {\n        \"addr\": \"[::]:4001\",\n        \"auth\": \"disabled\",\n        \"redirect\": \"\"\n    },\n    \"mux\": {\n        \"addr\": \"127.0.0.1:4002\",\n        \"encrypted\": \"false\",\n        \"timeout\": \"30s\"\n    },\n    \"node\": {\n        \"start_time\": \"2019-01-20T21:28:29.150448519+08:00\",\n        \"uptime\": \"51m4.183397177s\"\n    },\n    \"runtime\": {\n        \"GOARCH\": \"amd64\",\n        \"GOMAXPROCS\": 2,\n        \"GOOS\": \"linux\",\n        \"numCPU\": 2,\n        \"numGoroutine\": 19,\n        \"version\": \"go1.10\"\n    },\n    \"store\": {\n        \"addr\": \"127.0.0.1:4002\",\n        \"apply_timeout\": \"10s\",\n        \"db_conf\": {\n            \"DSN\": \"\",\n            \"Memory\": true\n        },\n        \"dir\": \"/root/rqlite/rqlite-v4.4.0-linux-amd64/node.1\",\n        \"election_timeout\": \"1s\",\n        \"heartbeat_timeout\": \"1s\",\n        \"leader\": \"\",\n        \"meta\": {\n            \"APIPeers\": {\n                \"127.0.0.1:4002\": \":4001\",\n                \"127.0.0.1:4004\": \":4003\",\n                \"127.0.0.1:4006\": \":4005\"\n            }\n        },\n        \"open_timeout\": \"2m0s\",\n        \"peers\": [\"127.0.0.1:4002\", \"127.0.0.1:4006\", \"127.0.0.1:4004\"],\n        \"raft\": {\n            \"applied_index\": \"8426\",\n            \"commit_index\": \"8426\",\n            \"fsm_pending\": \"0\",\n            \"last_contact\": \"4.12068812s\",\n            \"last_log_index\": \"8426\",\n            \"last_log_term\": \"7\",\n            \"last_snapshot_index\": \"0\",\n            \"last_snapshot_term\": \"0\",\n            \"num_peers\": \"2\",\n            \"state\": \"Candidate\",\n            \"term\": \"10\"\n        },\n        \"snapshot_threshold\": 8192,\n        \"sqlite3\": {\n            \"dns\": \"\",\n            \"fk_constraints\": \"disabled\",\n            \"path\": \":memory:\",\n            \"version\": \"3.26.0\"\n        }\n    }\n}\n```\n@otoolep . I probably know the cause of this issue: the snapshot too big, it takes too long time. When this problem occurs, the snapshot is taking, taking.... keep it simple! grpc maybe complicated. And I found many bugs in rqlite v5 http api implementation.. @otoolep Those problems happend when you connect to any rqlited follower node by using rqlite command then execute any SQL statement.. ",
    "hmxxyy": "thanks @otoolep for the prompt reply. It works with that step added.. ",
    "WesleyRen": "Great!\nThanks for the quick response and the example code.. ",
    "Majonsi": "@otoolep \nThanks for your response. It's now working! But is that normal that I have to type in the command the Ip adress of the machine instead of localhost? So my command become:\n$GOPATH/bin/rqlited -http IPOFTHEHOST:4001 -raft IPOFTHEHOST:4002 -join http://IPOFTHEANOTHERCOMPUTER:4001 ~/node2\nThis mean that I can't connect a computer to a node which have been launched with the command : $GOPATH/bin/rqlited ~/node1 ?. ",
    "lsm": "I see.  Thanks!. ",
    "rymoore": "Sorry, I guess I'm asking \"can the 2nd node become master when the 1st node goes down\" - so it's a failover. is it possible to do a manual election / failover?\n. Thanks!. ",
    "SadE54": "In fact I'm starting to research a solution to replace a centralized torrent tracker using a decentralized solution -  currently as a proof of concept . IPFS seems a good solution to distribute the static part of the tracker web pages. Now I'm looking at the database part. In fact I'm not sure rqlite is the solution . The idea here is that each client has locally a 'real time' updated version of the tracker database. I guess the latency could be the big deal here, and i thought about utp that is used in bitorrent clients to optimize latency. . ",
    "chenziliang": "Thanks @otoolep . BTW, may i ask what is the performance degradation comparing to single instance sqlite3 ? . ",
    "raarts": "Alright, well, happy that you already are familiar. What I'd like to accomplish is getting changes to sqlite databases into kafka in a similar way as Bottled Water does.\nAccording to what I read on the SQLite mailing list, it's quite hard get the changes that were done in a transaction from the disk blocks, but an alternative was suggested, saving all queries to a special table, and work from there. \nI got on your site from a link in that same thread, and thought you would have needed access to all queries as well, for syncing. Seemed to point in the same direction.\nAnd if you think it's impossible (or at least impractical), that's an answer too.. ",
    "lkxjtu": "There is no problem of showing \"sql\" only,because I have not create any table. My problem is, every time I enter a button, the CLI will output a \"127.0.0.1:4001>\" to me. For example,I just input \".schema\",but CLI show \"127.0.0.1:4001> 127.0.0.1:4001> . 127.0.0.1:4001> .s 127.0.0.1:4001> .sc 127.0.0.1:4001> .sch 127.0.0.1:4001> .sche 127.0.0.1:4001> .schem 127.0.0.1:4001> .schema\" to me.\nMy OS version\uff1a\nroot@op-1:~/rqlited-v4.0.0-linux-amd64# cat /proc/version\nLinux version 4.4.0-31-generic (buildd@lgw01-43) (gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) ) #50~14.04.1-Ubuntu SMP Wed Jul 13 01:07:32 UTC 2016\nThank you.. This is because of there is no glibc in alpine,after add alpine-pkg-glibc, it works fine.This problem is nothing to do with rqlite.\n. Sorry I can't submit google account, so only in this question. If you think it is not right here, you can turn this topic off,thanks!. No, there is only one rqlited node.The rqlited start cmd is\nrqlited -http-addr 0.0.0.0:4001 -raft-addr 0.0.0.0:4002 /root/data/rqlite\nI found the disk performance of this device is relatively low. I have done comparison, the normal device to do a sync action flushing data to disk, need 1ms, this device needs 10ms. Is rqlited doing a lot of disk operation on start?. ",
    "jack-y": "@otoolep you're right. As you suggest, now I'm handling the redirect response in my app. Thanks!. ",
    "justinmorant": "@otoolep for rqlite-js I am blocked on writing the backup and restore endpoints until we can fix this issue. I would have to hack around the client so it does not attempt to parse the body into Javascript objects when 'Content-Type: application/json' is present.  Let me know if this will take a while to fix since I can make the client work, just want to avoid the change.. @otoolep thanks that is fine with me, as long as it does not have a reference to JSON in the header most libraries won't try and parse as such. The application/octet-stream content type is pretty abstract with regards to implementation so we should not run into any issues.\n. ",
    "julisch94": "I had done what's here under \"Linux\" and got the error above. By now, I have realized that I can't just use the supplied binaries, but instead I need to build from source to make rqlite work on Raspberry PI.\nSo I've done what's here and found out that\ncd $GOPATH/bin/rqlited\ngo build\n./rqlited ~/node.1\n\nwon't work, because $GOPATH/bin/rqlited is not a directory but a file instead.\nUsually you build source files from $GOPATH/src/ but unfortunately I don't know how to build $GOPATH/src/github.com/rqlite/rqlite as it contains the following directories and files:\nCHANGELOG.md     appveyor.yml     cmd              gofmt.sh         tcp\nCONTRIBUTING.md  auth             db               http             testdata\nLICENSE          aws              disco            package.sh       vagrant_setup.sh\nREADME.md        circle.yml       doc              store\nVagrantfile      cluster          doc.go           system_test\n\nI want to build these source files with GOOS=linux GOARCH=arm to make it work on Raspberry PI, but I can't build the given folder $GOPATH/src/github.com/rqlite/rqlite. When trying to build that folder nothing happens and no binary file appears.\nWhich folder do I have to build to get the binaries for rqlite and rqlited? Since this is not a specific Raspberry PI problem but refers to building from source in general, I'd like to stay on this discussion if possible.. I am currently running > GOOS=linux GOARCH=arm go build -v . on both folders:\n\n$GOPATH/src/github.com/rqlite/rqlite/cmd/rqlite\n$GOPATH/src/github.com/rqlite/rqlite/cmd/rqlited\n\nActually, this seems to me to be the most reasonable option.\nWhat it does:\nThe first one, rqlite, seems to work. I can run the generated binary file on Raspberry PI. That looks fine.\nWhereas rqlited does not work. Running the command stated above doesn't generate any file. During the verbose build of rqlited, I can see some lines indicating an error regarding mattn/go-sqlite3:\n(...)\ntext/template/parse\ntext/template\ngithub.com/mattn/go-sqlite3\n# github.com/mattn/go-sqlite3\n../../../../mattn/go-sqlite3/sqlite3_go18.go:18: undefined: SQLiteConn\n../../../../mattn/go-sqlite3/sqlite3_go18.go:26: undefined: SQLiteConn\n../../../../mattn/go-sqlite3/sqlite3_go18.go:27: undefined: namedValue\n../../../../mattn/go-sqlite3/sqlite3_go18.go:29: undefined: namedValue\n../../../../mattn/go-sqlite3/sqlite3_go18.go:35: undefined: SQLiteConn\n../../../../mattn/go-sqlite3/sqlite3_go18.go:36: undefined: namedValue\n../../../../mattn/go-sqlite3/sqlite3_go18.go:44: undefined: SQLiteConn\n../../../../mattn/go-sqlite3/sqlite3_go18.go:49: undefined: SQLiteConn\n../../../../mattn/go-sqlite3/sqlite3_go18.go:54: undefined: SQLiteStmt\n../../../../mattn/go-sqlite3/sqlite3_go18.go:63: undefined: SQLiteStmt\n../../../../mattn/go-sqlite3/sqlite3_go18.go:36: too many errors\ngithub.com/boltdb/bolt\nregexp\ncrypto/x509\n(...)\n\nAny ideas if those errors affect the build process to exit unsuccessfully? I wonder why go build doesn't give any kind of error message. It keeps on running the build process as everything's good.. I finally figured out, how to do this and decided to let anyone facing the same issue benefit from my effort. This solution uses a Debian system running in a Docker container. Cross-compiling C programs (sqlite3) to ARM seems to work on Linux.\nHint: You'll need to have docker installed and running on your Mac.\nPreparations on Host\n1. create directory and download golang\nmkdir ~/vol\ncd ~/vol\ncurl -O https://storage.googleapis.com/golang/go1.8.3.linux-amd64.tar.gz\n\nfor more info see https://golang.org/doc/install for installation guide and https://golang.org/dl/ for appropriate packages or versions\n2. pull debian jessie image and start with mounted directory\ndocker pull debian:jessie\ndocker run -it -v ~/vol:/volume debian:jessie\n\n(docker container starts)\nPreparations in Docker Container\n1. Setup golang:\ncd /volume\ntar -C /usr/local -xzf go1.8.3.linux-amd64.tar.gz\nexport PATH=$PATH:/usr/local/go/bin\ncd\nmkdir go\ncd go\nmkdir bin\nmkdir pkg\nmkdir src\nexport GOPATH=$PWD\n\n2. install curl and git:\napt-get update\napt-get install curl -y\napt-get install git-core -y\n\n3. install cross compiler:\necho \"deb http://emdebian.org/tools/debian/ jessie main\" > /etc/apt/sources.list.d/crosstools.list\ncurl http://emdebian.org/tools/debian/emdebian-toolchain-archive.key | apt-key add -\ndpkg --add-architecture armhf\napt-get update\napt-get install crossbuild-essential-armhf -y\n\nWill take a while.\nfor more info see https://wiki.debian.org/CrossToolchains#Installation\n4. get rqlite\ngo get -u -t github.com/rqlite/rqlite/...\n\n5a. build rqlite binary for arm\ncd $GOPATH/src/github.com/rqlite/rqlite/cmd/rqlite\nCC=arm-linux-gnueabihf-gcc GOOS=linux CGO_ENABLED=1 GOARCH=arm GOARM=7 go build -v .\ncp rqlite /volume\n\n5b. build rqlited binary for arm\ncd $GOPATH/src/github.com/rqlite/rqlite/cmd/rqlited\nCC=arm-linux-gnueabihf-gcc GOOS=linux CGO_ENABLED=1 GOARCH=arm GOARM=7 go build -v .\ncp rqlited /volume\n\n6. finally\nYou'll find both binaries in ~/vol on your host machine (Mac).\n~/vol> ls\ngo1.8.3.linux-amd64.tar.gz     rqlited      rqlite\n\n7. further do\n\nTransfer both files via scp to your Raspberry PI\nSSH connect to your Raspberry PI\nRun the files. It works fine!\n. \n",
    "wangke1970": "Thank you. I didn't read the document carefully. ",
    "turbo": "What's the status on this?. It should of course be https://ci.appveyor.com/api/projects/otoolep/rqlite/artifacts/rqlite-latest-win64.zip?branch=master\nSorry, confused your org and user name.. Zeroconf is widely adopted. Apple software uses it (Bonjour, and Bonjour Wide). Mist linux distros ship with a browser by default (avahi).\nhttps://en.wikipedia.org/wiki/Zero-configuration_networking\nhttps://en.wikipedia.org/wiki/Bonjour_(software). Zeroconf is definitely only for local network deployments and should be opt-in. I see two ways this could be implemented in the front end:\nDedicated Option\nE.g. -z. So basically just execute an identical command on all nodes (rqlite --secret 1234 --zeroconf [options]) and the cluster auto builds. This would probably prevent any scripts from breaking.\nModularize Discovery Service\nUse a --discovery switch or similar to switch between zeroconf, your service or manual (default).. As a microservice in a bigger project, on-premise data lake exploration. I can't really say much more than that. I'm battle-testing it right now. My priorities are:\n\nLowering latency (hence my question on the RPC issue)\nEnterprise firewall and IPS/DPI friendly protocol (currently testing this in depth)\n\nSo far, all looks good. I care about Windows environments most of all, but I love that I could get it to run in no time on a number of different platforms. In my specific use case, I can use rqlite to scale for performance, too.. I currently use the HTTP API from various languages (each service might be another language). Mainly we're looking at dotnet core, PHP, Node.js and Go. Different services request different levels of read consistency. As far as I can tell, all these languages support gRPC clients.. Yes, I am. I will try to benchmark this in my own environment, too.. ",
    "meox": "this should be very usefull feature!!!. I discover rqlite few days ago because I'm looking for a distributed sql db to lookup milion of values in real time.\nThe HTTP interface is fine for the most of common scenario but when you have ~150k events/s HTTP is not suitable.\nSo if we can reduce the latency of single lookup this is perfect!. Ok I'll do some benchmark.\nDid you try ZMQ (http://zeromq.org/) as transport?. ok thanks\nOn 31 October 2017 at 19:29, otoolep notifications@github.com wrote:\n\nLinked is a profiling graph, as a result of 20,000 INSERTs into a single\nnode, over HTTP. Unzip and load it into Chrome, or some other SVG viewer.\npprof002.svg.gz\nhttps://github.com/rqlite/rqlite/files/1431857/pprof002.svg.gz\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/issues/350#issuecomment-340858967, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AA0CRJaYiTkK8JTxr_YJ_Ay6g_60OnRcks5sx2cggaJpZM4PQaP1\n.\n\n\n-- \nGL\nhttp://www.meocci.it\n. ",
    "varunudacity": "Thanks. A related question: if I reconfigure the raft cluster, via the\nclient, will that automatically update the discovery service?\nMaybe returning status code 307 would work?\nhttps://softwareengineering.stackexchange.com/questions/99894/why-doesnt-http-have-post-redirect\nOn Fri, Sep 8, 2017 at 5:30 PM otoolep notifications@github.com wrote:\n\nThanks for the report @varunudacity https://github.com/varunudacity --\nyou are right, this is not working. Even passing -L to the command won't\nfix this, since the node to delete is listed in the body of the command,\nand the body is not included when curl redirects the request. Without a\nproper body, the Discovery service responds with 400.\nI need to think about this. In the meantime, if you need to delete a node\nyou can go straight to the AWS Lambda gateway as follows:\ncurl -XDELETE -v 'https://k05nh959gb.execute-api.us-west-2.amazonaws.com \\\n/prod/rqliteDiscoHandler/' -H \"Content-Type: application/json\" \\\n-d '{\"addr\": \"localhost:4001\"}\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/issues/351#issuecomment-328242195, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AY47C4ebFBe88jlE3zisUWHLZO1wgXJsks5sgdwYgaJpZM4PRy3f\n.\n. Perhaps rqlite doesn't support this yet, but raft has additional commands\nfor adding and removing peers from the cluster. These membership changes\nare done in a particular way to ensure that two nodes do not become leaders\nat the same time.\n\nConcrete use case:\nI have three nano servers on ec2. My rqlite memory usage is going up and I\nwant to upgrade. I would like to add 3 bigger instances (e.g m4.medium) and\nremove the original servers entirely. What should happen with raft is that\nthe new servers will be brought up to date and then one of them will become\na leader.\nOn Fri, Sep 8, 2017 at 7:34 PM otoolep notifications@github.com wrote:\n\nif I reconfigure the raft cluster, via the client, will that automatically\nupdate the discovery service?\nI don't really follow what you have in mind. Can you provide me with a\nconcrete example?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/issues/351#issuecomment-328249024, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AY47C68i7ncI1iZGQ3BOBt4HN2JxfouIks5sgfk-gaJpZM4PRy3f\n.\n. Even easier perhaps:\n\nhttps://curl.haxx.se/docs/manpage.html#--post301\nThe --post301 should send the original post data to the redirected URL.\nThat said, returning 307 instead of 301 would probably work automatically\non more clients.\nOn Fri, Sep 8, 2017 at 7:06 PM Varun Ganapathi varun@udacity.com wrote:\n\nThanks. A related question: if I reconfigure the raft cluster, via the\nclient, will that automatically update the discovery service?\nMaybe returning status code 307 would work?\nhttps://softwareengineering.stackexchange.com/questions/99894/why-doesnt-http-have-post-redirect\nOn Fri, Sep 8, 2017 at 5:30 PM otoolep notifications@github.com wrote:\n\nThanks for the report @varunudacity https://github.com/varunudacity --\nyou are right, this is not working. Even passing -L to the command won't\nfix this, since the node to delete is listed in the body of the command,\nand the body is not included when curl redirects the request. Without a\nproper body, the Discovery service responds with 400.\nI need to think about this. In the meantime, if you need to delete a node\nyou can go straight to the AWS Lambda gateway as follows:\ncurl -XDELETE -v 'https://k05nh959gb.execute-api.us-west-2.amazonaws.com \\\n/prod/rqliteDiscoHandler/' -H \"Content-Type: application/json\" \\\n-d '{\"addr\": \"localhost:4001\"}\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/issues/351#issuecomment-328242195, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AY47C4ebFBe88jlE3zisUWHLZO1wgXJsks5sgdwYgaJpZM4PRy3f\n.\n\n\n. \n",
    "dbskccc": "have post on google group, sorry for the noise!. ",
    "bruth": "Is this still planned?. Understood thanks. That said I would argue the generated clients is still a nice benefit in lieu of performance gains.. ",
    "wuxiaoxiaoshen": "How are you getting along with the work? . ",
    "rapoth": "@otoolep: Thank you for your prompt response! I will update this post with numbers from a cluster. In the meantime, some more details regarding my environment (along with a benchmark for in-memory sqlite):\n\n48 cores, 128 GB RAM\nSSD 850 that can support upto 6 Gbps\n\nI re-ran the benchmarks for sqlite in-memory mode (by restarting rqlite without any -on-disk parameter) and here's what I see:\nPS E:\\tmp\\rqlite> .\\rqbench.exe -x  -b 1 -m 10 \"INSERT INTO test1(URI) VALUES('hello');\"\n10 requests completed in 310.5362ms\n...\n90 requests completed in 311.5332ms\nTotal duration: 31.1241688s\nRequests/sec: 3.21\nStatements/sec: 3.21\nCPU (1 statement/request)\n\nSSD IO (1 statement/request)\n\nPS E:\\tmp\\rqlite> .\\rqbench.exe -x -b 50000 -m 10 \"INSERT INTO test1(URI) VALUES('hello');\"\n10 requests completed in 625.9143ms\n...\n90 requests completed in 663.6563ms\nTotal duration: 1m2.5478693s\nRequests/sec: 1.60\nStatements/sec: 79938.77\nCPU (50k statements/request)\n\nSSD IO (50k statements/request)\n\nIn both cases, I am observing that drive IO is fairly low. The overall CPU did not go beyond 10%. \nI am currently setting up a cluster experiment and will follow-up. In the mean time, if you do need any other information, please let me know. I'm super interested in this project and am curious to see how we can obtain a higher throughput for 1 statement requests. Thank you for your time!. Thank you for the pointer. I am not familiar with Go at all but I will look at the blog and run the profiler. I will update this thread soon.. I ran the profiler and collected the following. I am currently looking through them in more detail but I figured I'll attach them here in case you have any other ideas.\nnode.1\nProfile Graph for node.1\nProfile Graph (Malloc GC) for node.1\n```\nPS E:\\tmp\\rqlite> go tool pprof rqlited.exe .\\cpu.prof.1\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n1560ms of 1920ms total (81.25%)\nShowing top 10 nodes out of 218 (cum >= 30ms)\n      flat  flat%   sum%        cum   cum%\n     770ms 40.10% 40.10%      770ms 40.10%  runtime.stdcall1\n     520ms 27.08% 67.19%      520ms 27.08%  runtime.cgocall\n      40ms  2.08% 69.27%       40ms  2.08%  runtime.lock\n      40ms  2.08% 71.35%       40ms  2.08%  runtime.siftdownTimer\n      40ms  2.08% 73.44%      260ms 13.54%  runtime.timerproc\n      30ms  1.56% 75.00%       30ms  1.56%  runtime.acquirep\n      30ms  1.56% 76.56%       40ms  2.08%  runtime.exitsyscall\n      30ms  1.56% 78.12%       30ms  1.56%  runtime.runqgrab\n      30ms  1.56% 79.69%      230ms 11.98%  runtime.startm\n      30ms  1.56% 81.25%       30ms  1.56%  runtime.unlock\nPS E:\\tmp\\rqlite>  go tool pprof rqlited.exe .\\mem.prof.1\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n215.08kB of 269.41kB total (79.84%)\nDropped 210 nodes (cum <= 1.35kB)\nShowing top 10 nodes out of 90 (cum >= 6.33kB)\n      flat  flat%   sum%        cum   cum%\n   67.04kB 24.89% 24.89%    67.04kB 24.89%  runtime.malg\n   54.66kB 20.29% 45.17%    67.28kB 24.97%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).getConn\n   16.14kB  5.99% 51.17%    88.53kB 32.86%  runtime.systemstack\n   14.12kB  5.24% 56.41%    14.12kB  5.24%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.newNetPipeline\n   12.86kB  4.77% 61.18%    12.86kB  4.77%  net.socket\n   12.65kB  4.70% 65.88%    12.65kB  4.70%  github.com/boltdb/bolt.Open.func1\n   12.14kB  4.51% 70.39%    12.14kB  4.51%  net.(netFD).connect.func2\n   11.41kB  4.23% 74.62%    11.41kB  4.23%  net/http.newBufioWriterSize\n    7.72kB  2.87% 77.49%     7.72kB  2.87%  sync.(Pool).pinSlow\n    6.33kB  2.35% 79.84%     6.33kB  2.35%  github.com/boltdb/bolt.(node).put\nPS E:\\tmp\\rqlite>  go tool pprof --inuse_objects rqlited.exe .\\mem.prof.1\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n1373 of 1440 total (95.35%)\nDropped 229 nodes (cum <= 7)\nShowing top 10 nodes out of 71 (cum >= 43)\n      flat  flat%   sum%        cum   cum%\n       256 17.78% 17.78%        256 17.78%  github.com/hashicorp/go-msgpack/codec.(ioDecReader).readn\n       256 17.78% 35.56%        256 17.78%  runtime.gcBgMarkWorker\n       236 16.39% 51.94%        410 28.47%  runtime.systemstack\n       178 12.36% 64.31%        178 12.36%  runtime.malg\n       129  8.96% 73.26%        129  8.96%  net.(netFD).connect.func2\n       128  8.89% 82.15%        128  8.89%  github.com/boltdb/bolt.(Cursor).search\n        61  4.24% 86.39%        118  8.19%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).getConn\n        43  2.99% 89.38%         43  2.99%  github.com/hashicorp/go-msgpack/codec.NewDecoder\n        43  2.99% 92.36%         43  2.99%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(*netPipeline).decodeResponses\n        43  2.99% 95.35%         43  2.99%  time.NewTimer\n```\nnode.2\nProfile Graph for node.2\n```\nPS E:\\tmp\\rqlite>  go tool pprof rqlited.exe .\\cpu.prof.2\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n630ms of 630ms total (  100%)\nShowing top 10 nodes out of 98 (cum >= 10ms)\n      flat  flat%   sum%        cum   cum%\n     510ms 80.95% 80.95%      510ms 80.95%  runtime.cgocall\n      60ms  9.52% 90.48%       60ms  9.52%  runtime.stdcall1\n      10ms  1.59% 92.06%       10ms  1.59%  runtime.acquirep1\n      10ms  1.59% 93.65%       10ms  1.59%  runtime.deferreturn\n      10ms  1.59% 95.24%       10ms  1.59%  runtime.findrunnable\n      10ms  1.59% 96.83%       70ms 11.11%  runtime.semawakeup\n      10ms  1.59% 98.41%       80ms 12.70%  runtime.systemstack\n      10ms  1.59%   100%       10ms  1.59%  runtime.timerproc\n         0     0%   100%       10ms  1.59%  bufio.(Reader).ReadByte\n         0     0%   100%       10ms  1.59%  bufio.(Reader).fill\nPS E:\\tmp\\rqlite>  go tool pprof rqlited.exe .\\mem.prof.2\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n1237.49kB of 1816.92kB total (68.11%)\nDropped 119 nodes (cum <= 9.08kB)\nShowing top 10 nodes out of 90 (cum >= 62.86kB)\n      flat  flat%   sum%        cum   cum%\n  379.67kB 20.90% 20.90%   379.67kB 20.90%  github.com/boltdb/bolt.(Tx).writeMeta\n  237.47kB 13.07% 33.97%   237.47kB 13.07%  github.com/boltdb/bolt.(node).put\n  107.22kB  5.90% 39.87%   107.22kB  5.90%  github.com/boltdb/bolt.(node).read\n      96kB  5.28% 45.15%       96kB  5.28%  html.init\n   84.82kB  4.67% 49.82%   326.04kB 17.94%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).handleCommand\n   72.75kB  4.00% 53.82%   101.15kB  5.57%  github.com/hashicorp/go-msgpack/codec.(encFnInfo).kStruct\n   68.20kB  3.75% 57.58%   132.36kB  7.28%  github.com/hashicorp/go-msgpack/codec.(msgpackDecDriver).decodeString\n   64.34kB  3.54% 61.12%  1154.64kB 63.55%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(Raft).appendEntries\n   64.16kB  3.53% 64.65%    64.16kB  3.53%  github.com/hashicorp/go-msgpack/codec.(ioDecReader).readn\n   62.86kB  3.46% 68.11%    62.86kB  3.46%  runtime.malg\nPS E:\\tmp\\rqlite>  go tool pprof --inuse_objects rqlited.exe .\\mem.prof.2\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n14572 of 21035 total (69.28%)\nDropped 127 nodes (cum <= 105)\nShowing top 10 nodes out of 82 (cum >= 620)\n      flat  flat%   sum%        cum   cum%\n      3462 16.46% 16.46%       3462 16.46%  github.com/hashicorp/go-msgpack/codec.(ioDecReader).readn\n      3336 15.86% 32.32%       6798 32.32%  github.com/hashicorp/go-msgpack/codec.(msgpackDecDriver).decodeString\n      1586  7.54% 39.86%       8367 39.78%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(Raft).appendEntries\n      1289  6.13% 45.99%      10380 49.35%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).handleCommand\n      1024  4.87% 50.85%       1024  4.87%  github.com/boltdb/bolt.(node).split\n       903  4.29% 55.15%       1306  6.21%  github.com/hashicorp/go-msgpack/codec.(encFnInfo).kStruct\n       815  3.87% 59.02%       8511 40.46%  github.com/hashicorp/go-msgpack/codec.(Decoder).decodeValue\n       769  3.66% 62.68%        769  3.66%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).DecodePeer\n       768  3.65% 66.33%        768  3.65%  github.com/mattn/go-sqlite3.(SQLiteConn).prepare.func2\n       620  2.95% 69.28%        620  2.95%  github.com/boltdb/bolt.(Bucket).openBucket\n```\nnode.3\nProfile Graph for node.3\n```\nPS E:\\tmp\\rqlite>  go tool pprof rqlited.exe .\\cpu.prof.3\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n630ms of 630ms total (  100%)\nShowing top 10 nodes out of 57 (cum >= 270ms)\n      flat  flat%   sum%        cum   cum%\n     460ms 73.02% 73.02%      460ms 73.02%  runtime.cgocall\n     110ms 17.46% 90.48%      110ms 17.46%  runtime.stdcall1\n      20ms  3.17% 93.65%       20ms  3.17%  runtime.unlock\n      10ms  1.59% 95.24%      460ms 73.02%  internal/poll.(FD).Fsync\n      10ms  1.59% 96.83%       10ms  1.59%  math/rand.(lockedSource).Int63\n      10ms  1.59% 98.41%       10ms  1.59%  runtime.mcall\n      10ms  1.59%   100%       10ms  1.59%  runtime.selectgo\n         0     0%   100%      470ms 74.60%  github.com/boltdb/bolt.(Tx).Commit\n         0     0%   100%      200ms 31.75%  github.com/boltdb/bolt.(Tx).write\n         0     0%   100%      270ms 42.86%  github.com/boltdb/bolt.(*Tx).writeMeta\nPS E:\\tmp\\rqlite>  go tool pprof rqlited.exe .\\mem.prof.3\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n749.97kB of 1016.30kB total (73.79%)\nDropped 89 nodes (cum <= 5.08kB)\nShowing top 10 nodes out of 73 (cum >= 24.10kB)\n      flat  flat%   sum%        cum   cum%\n  240.46kB 23.66% 23.66%   244.47kB 24.05%  github.com/boltdb/bolt.(Tx).writeMeta\n  139.94kB 13.77% 37.43%   139.94kB 13.77%  github.com/boltdb/bolt.(node).put\n   84.81kB  8.35% 45.78%   217.62kB 21.41%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).handleCommand\n   63.49kB  6.25% 52.02%    63.49kB  6.25%  github.com/boltdb/bolt.(node).read\n   50.62kB  4.98% 57.00%    50.62kB  4.98%  github.com/boltdb/bolt.Open.func1\n   44.45kB  4.37% 61.38%    48.47kB  4.77%  github.com/hashicorp/go-msgpack/codec.(encFnInfo).kStruct\n   40.24kB  3.96% 65.34%   712.24kB 70.08%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(Raft).appendEntries\n   36.54kB  3.60% 68.93%   100.03kB  9.84%  github.com/boltdb/bolt.(Bucket).node\n   25.31kB  2.49% 71.42%   250.65kB 24.66%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).handleConn\n   24.10kB  2.37% 73.79%    24.10kB  2.37%  github.com/boltdb/bolt.(*Tx).write\nPS E:\\tmp\\rqlite>  go tool pprof --inuse_objects rqlited.exe .\\mem.prof.3\nEntering interactive mode (type \"help\" for commands)\n(pprof) top10\n6966 of 11118 total (62.66%)\nDropped 89 nodes (cum <= 55)\nShowing top 10 nodes out of 73 (cum >= 342)\n      flat  flat%   sum%        cum   cum%\n      1298 11.67% 11.67%       5115 46.01%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).handleCommand\n       898  8.08% 19.75%        898  8.08%  github.com/hashicorp/go-msgpack/codec.(ioDecReader).readn\n       898  8.08% 27.83%       1796 16.15%  github.com/hashicorp/go-msgpack/codec.(msgpackDecDriver).decodeString\n       877  7.89% 35.72%       5056 45.48%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(Raft).appendEntries\n       727  6.54% 42.26%        727  6.54%  github.com/boltdb/bolt.(Tx).write\n       559  5.03% 47.28%        687  6.18%  github.com/hashicorp/go-msgpack/codec.(encFnInfo).kStruct\n       512  4.61% 51.89%        555  4.99%  github.com/mattn/go-sqlite3.(SQLiteConn).begin\n       512  4.61% 56.49%        512  4.61%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(NetworkTransport).DecodePeer\n       343  3.09% 59.58%       1070  9.62%  github.com/rqlite/rqlite/vendor/github.com/hashicorp/raft.(Raft).processHeartbeat\n       342  3.08% 62.66%        342  3.08%  github.com/mattn/go-sqlite3.(SQLiteStmt).exec\n```. ",
    "arstercz": "restore with sqlite3 command on centos 6.5 is ok:\n```\nsqlite3 ttt <./restore.dump\nsqlite3 ttt 'select * from foo limit 2'\n1|fiona\n2|fiona2222\n. hi @otoolep , it's ok to restore the table when I shutdown the cluster and delete the data directory each node uses.\nand I found an interesting phenomenon, we can reproduce the error when we use the following steps:\n1. just delete the table rows in the cluster:\nlocalhost:4001> delete from foo;\n4 rows affected (0.000000 sec)\n2. `table foo already exists`` error occurs when to restore:\ncurl -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @restore.dump\n{\"results\":[{\"error\":\"table foo already exists\"}]}\n3. then I drop the `foo` table in the cluster:\nlocalhost:4001> drop table foo;\n4 rows affected (0.000000 sec)\n4. the error occurs when to restore:\ncurl -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @restore.dump\n{\"results\":[{\"error\":\"cannot start a transaction within a transaction\"}]}\n```\nI think the error cannot start a transaction within a transaction  is because the step 2 start a transaction, and does not commit or rollback when the table foo already exists occured. so I execute commit in the cluster:\nlocalhost:4001> commit;\n0 row affected (0.000000 sec)\nand the restore is ok:\n```\ncurl -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @restore.dump\n{\"results\":[{\"last_insert_id\":5,\"rows_affected\":1}]}\n```. thanks @otoolep ,  it's best to remove all data before restore, and it would be better if the system more robust. ",
    "icewukong": "Hi, @otoolep \nHere's a library that supports spatialite, can U support it?\nhttps://github.com/shaxbee/go-spatialite. ",
    "tekbird": "C:\\Users\\xxxx\\Desktop\\rqlite>rqlite -H localhost -p 4101\nlocalhost:4101> .status\nbuild:\n  branch: unknown\n  build_time: unknown\n  commit: unknown\n  version: 4\nhttp:\n  addr: 127.0.0.1:4101\n  auth: disabled\n  redirect: localhost:4103\nmux:\n  addr: 127.0.0.1:4102\n  encrypted: false\n  timeout: 30s\nnode:\n  start_time: 2018-01-09T10:52:22.5499039+05:30\n  uptime: 33.0664655s\nruntime:\n  GOARCH: amd64\n  GOMAXPROCS: 8\n  GOOS: windows\n  numCPU: 8\n  numGoroutine: 14\n  version: go1.9.2\nstore:\n  addr: 127.0.0.1:4102\n  apply_timeout: 10s\n  db_conf:\n    DSN:\n    Memory: true\n  heartbeat_timeout: 1s\n  leader: 127.0.0.1:4104\n  open_timeout: 2m0s\n  snapshot_threshold: 8192\n  sqlite3:\n    fk_constraints: disabled\n    path: :memory:\n    version: 3.21.0\n    dns:\n  dir: C:\\Users\\xxxx\\Desktop\\rqlite\\d\n  meta:\n    APIPeers:\n      127.0.0.1:4102: localhost:4101\n      127.0.0.1:4104: localhost:4103\n      127.0.0.1:4106: localhost:4105\n  peers: [127.0.0.1:4104 127.0.0.1:4106 127.0.0.1:4102]\n  raft:\n    last_snapshot_index: 0\n    num_peers: 2\n    term: 6\n    applied_index: 13\n    commit_index: 13\n    last_log_index: 13\n    last_log_term: 6\n    fsm_pending: 0\n    last_contact: 32.3658ms\n    last_snapshot_term: 0\n    state: Follower\nlocalhost:4101>\n. I am running this on windows, by downloading the windows build.. When I send a post request for a write to a follower, it fails with 405 Method Not Allowed, but works only with the Leader. I was expecting a 302 Permanently Moved response with Location header. No?. Okay. I start three nodes in the same machine with different ports:\n\nrqlited -http-addr localhost:4101 -raft-addr localhost:4102 d\nrqlited -http-addr localhost:4103 -raft-addr localhost:4104 -join http://localhost:4101 e\nrqlited -http-addr localhost:4105 -raft-addr localhost:4106 -join http://localhost:4101 f\n\nwhere d, e, and f are the data directories.\nAfter that I issue HTTP POST from a REST tool (POSTMAN) with the following data:\nURL: localhost:4103/db/execute?pretty&timings\nContent-Type: application/json\nBody: [\n    \"CREATE TABLE foo (id integer not null primary key, name text)\"\n]\nwhich returns the following headers with status 405:\ncontent-length \u21920\ncontent-type \u2192application/json; charset=utf-8\ndate \u2192Mon, 08 Jan 2018 10:45:31 GMT\nx-rqlite-version \u21924\nThis happens when instance with port 4103 is not a leader. In this case leader is the one with port 4101.. Tried with the latest build from AppVeyor, still facing the same issue. Is there anything else I can try?. I checked with curl and it works. But I have a C# application from which I get the same 405 status code.\n       WebRequest request = WebRequest.Create(\"http://localhost:4105/db/execute?pretty&timings\");\n        request.Method = \"POST\";\n        byte[] byteArray = Encoding.UTF8.GetBytes(@\"[\"\"CREATE TABLE foo2 (id integer not null primary key, name text)\"\"]\");\n        request.ContentType = \"application/json\";\n        ((HttpWebRequest)request).Accept = \"*/*\";\n        request.ContentLength = byteArray.Length;\n        Stream dataStream = request.GetRequestStream();\n        dataStream.Write(byteArray, 0, byteArray.Length);\n        dataStream.Close();\n        WebResponse response = request.GetResponse();\n        Console.WriteLine(((HttpWebResponse)response).StatusDescription);. I see it as a default redirection handling issue..\n",
    "Chyroc": "i see this: https://github.com/rqlite/rqlite/pull/354 and https://github.com/rqlite/rqlite/issues/87\nFor some historical reason, the code that led to github.com/hashicorp/raft was submitted to github, and I think it's time to put all the dependencies under the package management tool! The official tool dep by go\nOr, upload all the dependencies to github. ",
    "sum12": "I had this https://github.com/rqlite/rqlite/compare/master...sum12:hashedpass working but turns out base64 of bcrypted password generates value that is not accepted in the headers.\nThat points to having alternate means of authetication apart from basic auth\nNot sure how to go proceed, or if this is even feasible.. I hope this helps clear my comment above.\nUsing this go sample, Password: 111 \n```go\npackage main\nimport (\n    \"fmt\"\n    \"golang.org/x/crypto/bcrypt\"\n)\nfunc main() {\n    password := []byte(\"111\")\n    hashedPassword, err := bcrypt.GenerateFromPassword(password, bcrypt.DefaultCost)\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(string(hashedPassword))\n}\n```\ngenerates a hash \nusing the hash \npython\n'Basic ' +  codecs.encode('{}:{}'.format(user, password).encode('utf-8'),'base64').decode('utf-8').rstrip('\\n')\nGenerating a header \n'Basic MTExOiQyYSQxMCRxVHBOcHl5TlJQOXF6RThWU1FaZ011MHhVUVZZSUNoUWNxa1RiUnVrWDJRNktv\\nd0F5TGJrMg=='\nThe pyrqlite client throws error\nTraceback (most recent call last):\n  File \"test.py\", line 19, in <module>\n    cursor.execute('CREATE TABLE foo (id integer not null primary key, name text)')\n  File \"build/bdist.linux-x86_64/egg/pyrqlite/cursors.py\", line 123, in execute\n  File \"build/bdist.linux-x86_64/egg/pyrqlite/cursors.py\", line 72, in _request\n  File \"build/bdist.linux-x86_64/egg/pyrqlite/connections.py\", line 90, in _fetch_response\n  File \"build/bdist.linux-x86_64/egg/pyrqlite/connections.py\", line 78, in _retry_request\n  File \"/usr/lib64/python2.7/httplib.py\", line 1057, in request\n    self._send_request(method, url, body, headers)\n  File \"/usr/lib64/python2.7/httplib.py\", line 1096, in _send_request\n    self.putheader(hdr, value)\n  File \"/usr/lib64/python2.7/httplib.py\", line 1035, in putheader\n    raise ValueError('Invalid header value %r' % (one_value,))\nValueError: Invalid header value 'Basic MTExOiQyYSQxMCRxVHBOcHl5TlJQOXF6RThWU1FaZ011MHhVUVZZSUNoUWNxa1RiUnVrWDJRNktv\\nd0F5TGJrMg=='. oops my bad.\nPlease ignore the previous comments\nturns out I misunderstood my own implementation :smile: \n. @otoolep thanks for the input.\nI have update the PR to the second option. Let me know what you think.. Argh... Please let me know if such a change is acceptable, then I will proceed to resolve the conflict . @otoolep,  It should be fine now.. Actually I see this as I very interesting idea. If we could some how support mobile. \nrqlite could become something like  ContenProvider (on android) and thus allows other apps to have their sqlite dataase automatically \"backed-up\" or \"cloned\" to the remote server.\nLast time I looked into it. There were issues as the ContentProvider api for android was not possible in go-mobile.. Let me give you more context on why a PR to rqlite.\nsqlite3 has a mechanism to define custom functions and use them while running queries. \nexample: django_extract_year\nselect * from expenses where django_extract_year(spent_on)=2017\nSo now I have the list of all the expenses from 2017.\nboth sqlite3 module from python and gp-sqlite3 have api to register these custom functions.\ngo-sqlite3 expects param Connection_hook which is a  function. The functions receive a  param *sqlite.SQLiteCon. This params has a method create_function which can be used register custom functions.\nHere is an example of how it is done https://github.com/mattn/go-sqlite3/blob/master/_example/custom_func/main.go.\nBecause sqlite3 has this ability to have custom functions. There would be other ORMs who would have such custom functions.  And to use these ORMs with rqlite one will need those functions.\nI agree that rqlite is not necessarily the place to hold these extra functions.  But since rqlite uses go-sqlite3, rqlite should have mechanism to either register these functions \"Dynamically\" (I dont know if that is even possible in golang) and/or have them in contrib(folder?/repo?) and register when asked.\nDoes that help in understanding or is further confusing ? :-) . That sounds exciting. Thanks for planning it.\nMeanwhile can you share your view on how rqlite should handle these cases\nof registering extensions and/or functions .\nSince sqlite3 provides that mechanism i feel rqlite should not shadow that\nfeature simply because it does not have an API.\nIf I may get into details all rqlite has todo is take in a list of\nextensions which it has to register while creating sqlite connection. And\nthese extensions could reside in a contrib folder.\nThink of these contrib extensions as low priority util functions which do\nnot affect the functionality of rqlite however they increase/facilitate the\nenvironments in which rqlite can be used.\nOn Wed, Jul 25, 2018, 05:55 otoolep notifications@github.com wrote:\n\nOK, thanks @alanjds https://github.com/alanjds\nI am planning more major work on rqlite for 5.0 in a couple of weeks or so\n(busy with other stuff right now). So I am reluctant to merge anything that\nmay not make sense (and this code change isn't ready yet). The changes\ncould be significant, including a brand new consensus module.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/pull/523#issuecomment-407593724, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ADIhE5pDH6Jo_1Q0Eu-0wtD4HVteLv8-ks5uJ7rzgaJpZM4VOxoY\n.\n. Its awesome that you don't oppose the idea.\n\nThen how about for now we only get the contrib part in the repo for later\nas you put in the HTTP API.\nIf this sounds like a good plan to you. I can modify the PR.\nOn Wed, Jul 25, 2018, 18:48 otoolep notifications@github.com wrote:\n\nI would be open to a contrib directory as you suggest. However any code in\nthere would still need to be high-quality, and I would need an HTTP API\nexposed that would allow people explicitly hook the stuff in.\nThe connection model is changing is significantly in 5.0, and since this\nfunctionality is based on that, anything you do right now is liable to need\nserious rework. But the general idea you have should work.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/rqlite/rqlite/pull/523#issuecomment-407751001, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ADIhE1zz7PJ9f7YSOne-DF5MC_4_oVfvks5uKHASgaJpZM4VOxoY\n.\n. @otoolep I have updated the PR.\nDo you have any new reviews for me ?. @tomdesair you should be able to use rqlite with django without this PR too. \n\nThis PR just add the functionality to call custom time.Time based functions. So rqlite should work just fine if you are not using these special functions in your project. ",
    "dbabits": "Right, that's my ldd output too, and my glibc is  libc-2.12.so\nYou saying \"Go does not, by default, statically link libc when cgo is used.\" - is it possible to override the default ?\nGoogle search suggests:\n\nCGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -a -tags netgo -ldflags '-w -extldflags \"-static\"' -o mybin *.go. sure, I will try some time later.\nThanks.. \n",
    "joaodrp": "@otoolep done!. Hi @otoolep, would like your feedback about this change.. Here is a sample session: \n$ rqlite\n127.0.0.1:4001> .help\n.help                           Show this message\n.indexes                        Show names of all indexes\n.schema                         Show CREATE statements for all tables\n.status                         Show status and diagnostic information for connected node\n.expvar                         Show expvar (Go runtime) information for connected node\n.tables                         List names of tables\n.timer on|off                   Turn SQL timer on or off\n127.0.0.1:4001> SELECT * FROM foo\n+----+-------+\n| id | name  |\n+----+-------+\n| 1  | fiona |\n+----+-------+\n127.0.0.1:4001> .timer on\n127.0.0.1:4001> SELECT * FROM foo\n+----+-------+\n| id | name  |\n+----+-------+\n| 1  | fiona |\n+----+-------+\nRun Time: 0.00006418\n127.0.0.1:4001> .timer off\n127.0.0.1:4001> SELECT * FROM foo\n+----+-------+\n| id | name  |\n+----+-------+\n| 1  | fiona |\n+----+-------+\n127.0.0.1:4001>. I've change the error message. Is it ok now?. Indeed, I missed that one. Thanks.. No need for this. From the tests I made, spaces have already been trimmed at this stage.. Because nothing useful would come from that error. Since I'm using the SplitHostPort, if the user would do -u bob (no password) this would raise the following message: missing port in address.. Ok, that's fine. However, @otoolep, do you want to mandate a non-empty username and password? Because RFC 2617 doesn't. I'll make the change later today. Thanks.. go vet is ok with that \ud83d\udc4d . I thought the same, but if I add any more tabs it won't be properly aligned. If you try to edit the file here it's aligned. Also, if you take a look at the sample session below, you'll see that all lines are aligned when using the CLI.. Ok, I should have mentioned that I copied the sqlite3 CLI error message:\n$ sqlite3\nSQLite version 3.23.1 2018-04-10 17:39:29\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nsqlite> .timer onn\nERROR: Not a boolean value: \"onn\". Assuming \"no\".\nI can change it though.. ",
    "eariassoto": "I can work on this. Sure:\nbash\n$ ./rqlite \n127.0.0.1:4001> .help\n.help               Show this message\n.indexes            Show names of all indexes\n.schema             Show CREATE statements for all tables\n.status             Show status and diagnostic information for connected node\n.expvar             Show expvar (Go runtime) information for connected node\n.tables             List names of tables\n.timer on|off           Turn SQL timer on or off\n.backup <file>          Create a backup file for the database\n127.0.0.1:4001> .backup bak.sqlite\nbackup file written successfully\n127.0.0.1:4001>. This is another one I can take \ud83d\ude03 I will start the implementation without the FK checks while I investigate on that. Thanks, will take a look on that. Do you think it would be useful to show the last inserted id and rows affected in case of a successful restore? Something like:\nbash\n$ rqlite\n127.0.0.1:4001> .restore <file>\nlast inserted Id: 1\nrows affected: 1\ndatabase restored successfully.. @otoolep Another issue. The sqlite .dump command wraps the SQL queries in a transaction. And that throws an \"cannot start a transaction within a transaction\" error. How should we approach to these cases? \nFor instance, this is what I got from the example given in the doc:\nsql\nPRAGMA foreign_keys=OFF;\nBEGIN TRANSACTION;\nCREATE TABLE foo (id integer not null primary key, name text);\nINSERT INTO \"foo\" VALUES(1,'fiona');\nCOMMIT;. @otoolep PR is up #446. If the dump file does not have the BEGIN TRANSACTION; and COMMIT; commands the restore command succeeds. I suppose that the /db/load service is trying to execute the queries in a single transaction. . @otoolep \nOk so I managed to reproduce the issue consistently:\nI ran a clean rqlited instance:\nbash\n$ rm -r ~/node.1\n$ rqlited ~/node.1\nRun the /db/load once, it works as expected:\n```\n$ curl -v -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @r.dumpNote: Unnecessary use of -X or --request, POST is already inferred.\n   Trying 127.0.0.1...\n Connected to localhost (127.0.0.1) port 4001 (#0)\n\nPOST /db/load HTTP/1.1\nHost: localhost:4001\nUser-Agent: curl/7.47.0\nAccept: /\nContent-type: text/plain\nContent-Length: 152\n\nupload completely sent off: 152 out of 152 bytes\n< HTTP/1.1 200 OK\n< X-Rqlite-Version: 5\n< Date: Wed, 25 Apr 2018 01:17:13 GMT\n< Content-Length: 52\n< Content-Type: text/plain; charset=utf-8\n<\nConnection #0 to host localhost left intact\n{\"results\":[{\"last_insert_id\":1,\"rows_affected\":1}]}\nRun the same curl again, the load fails because the table already exists:\n$ curl -v -XPOST localhost:4001/db/load -H \"Content-type: text/plai\nn\" --data-binary @r.dump\nNote: Unnecessary use of -X or --request, POST is already inferred.\nTrying 127.0.0.1...\n\nConnected to localhost (127.0.0.1) port 4001 (#0)\nPOST /db/load HTTP/1.1\nHost: localhost:4001\nUser-Agent: curl/7.47.0\nAccept: /\nContent-type: text/plain\nContent-Length: 152\n\n\nupload completely sent off: 152 out of 152 bytes\n< HTTP/1.1 200 OK\n< X-Rqlite-Version: 5\n< Date: Wed, 25 Apr 2018 01:18:20 GMT\n< Content-Length: 50\n< Content-Type: text/plain; charset=utf-8\n<\n\nConnection #0 to host localhost left intact\n{\"results\":[{\"error\":\"table foo already exists\"}]}\nRun it a third time and now it fails because a Tx is open:\ncurl -v -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @r.dump\nNote: Unnecessary use of -X or --request, POST is already inferred.\nTrying 127.0.0.1...\n\nConnected to localhost (127.0.0.1) port 4001 (#0)\nPOST /db/load HTTP/1.1\nHost: localhost:4001\nUser-Agent: curl/7.47.0\nAccept: /\nContent-type: text/plain\nContent-Length: 152\n\n\nupload completely sent off: 152 out of 152 bytes\n< HTTP/1.1 200 OK\n< X-Rqlite-Version: 5\n< Date: Wed, 25 Apr 2018 01:18:43 GMT\n< Content-Length: 73\n< Content-Type: text/plain; charset=utf-8\n<\n\nConnection #0 to host localhost left intact\n{\"results\":[{\"error\":\"cannot start a transaction within a transaction\"}]}\n```\n\n\nSo I think the first begin transaction; is not getting comitted. To verify my suspects, open rqlite and enter commit;\n$ ./rqlite\n127.0.0.1:4001> commit;\n1 row affected (0.000000 sec)\n127.0.0.1:4001>\nRun curl again:\n```\ncurl -v -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @r.dump\nNote: Unnecessary use of -X or --request, POST is already inferred.\n   Trying 127.0.0.1...\n Connected to localhost (127.0.0.1) port 4001 (#0)\n\nPOST /db/load HTTP/1.1\nHost: localhost:4001\nUser-Agent: curl/7.47.0\nAccept: /\nContent-type: text/plain\nContent-Length: 152\n\nupload completely sent off: 152 out of 152 bytes\n< HTTP/1.1 200 OK\n< X-Rqlite-Version: 5\n< Date: Wed, 25 Apr 2018 01:19:53 GMT\n< Content-Length: 50\n< Content-Type: text/plain; charset=utf-8\n<\nConnection #0 to host localhost left intact\n{\"results\":[{\"error\":\"table foo already exists\"}]}\nRun curl again, same Tx open error:\n$ curl -v -XPOST localhost:4001/db/load -H \"Content-type: text/plain\" --data-binary @r.dump\nNote: Unnecessary use of -X or --request, POST is already inferred.\nTrying 127.0.0.1...\n\nConnected to localhost (127.0.0.1) port 4001 (#0)\nPOST /db/load HTTP/1.1\nHost: localhost:4001\nUser-Agent: curl/7.47.0\nAccept: /\nContent-type: text/plain\nContent-Length: 152\n\n\nupload completely sent off: 152 out of 152 bytes\n< HTTP/1.1 200 OK\n< X-Rqlite-Version: 5\n< Date: Wed, 25 Apr 2018 01:20:03 GMT\n< Content-Length: 73\n< Content-Type: text/plain; charset=utf-8\n<\n\nConnection #0 to host localhost left intact\n{\"results\":[{\"error\":\"cannot start a transaction within a transaction\"}]}\n```\n\n\nPlease check the code, looks like when an Execute gets an error, it is not closing the Tx it opened before the error.. @otoolep Command works as expected now:\n$ go build && ./rqlite\n127.0.0.1:4001> .restore r\nlast inserted Id: 1\nrows affected: 1\ndatabase restored successfully\n127.0.0.1:4001>\n127.0.0.1:4001> .restore r\nError: table foo already exists\n127.0.0.1:4001> .restore r\nError: table foo already exists\n127.0.0.1:4001>. @otoolep Yes, I'm not used to push to a fork, I guess it is better that I make a new PR. Command example:\n$ ./rqlite\n127.0.0.1:4001> .restore restore.dump\nlast inserted ID: 1\nrows affected: 1\ndatabase restored successfully. Yes, I did not understand why gofmt did not break that line. I would rather have two ctxString calls.. Will do that change.. ",
    "ppsanyal1": "Yeah I actually mean rqlite itself. I saw your Java client and I am not talking about that. My concern is if I decide to use rqlite, I don't want to download it from your github, compile it and upgrade my production environment with the latest. I would rather prefer a centralized repository where you publish the latest release, and our build tool (maven in this case) should be able to automatically download it. \nIf that doesn't work, at least having a centralized repository for downloading the compiled executables/components should be of great help.. thanks. ",
    "damonYuan": "I think sometimes the mobile applications only want some local storage solution especially when offline. For example, restaurant menu application. There might be tens of ipads running the application inside a restaurant, but when a order is placed in one of them, you want all the ipads' data is synchronized. Especially under the fact that the sqlite is mostly used by mobile applications in production environment.. ",
    "rbastic": "(Should mention, I could just change it to TEXT, but I would like to use JSON_OBJECT(), etc. If a custom build of rqlite would fix this, please let me know.). Awesome, thanks! Something broke with gorqlite :) Onto trying to figure that out now.. ",
    "anhldbk": "@otoolep @joonas-fi forgive about my naive question: \nrqlitenodes use raft for reaching consensus. So all rqlite nodes will contain the same data and no data sharding, right? . ",
    "donpdonp": "startup log: https://gist.github.com/donpdonp/49bffc365e2443eeafaac05a63c65b27\nim monitoring raft with curl --silent http://localhost:4001/status|jq '.store.raft | {state, applied_index, commit_index}\nwhich starts out with \n{\n  \"state\": \"Leader\",\n  \"applied_index\": \"12269\",\n  \"commit_index\": \"12269\"\n}\nI have a node script that does select count(*) from Location and it reads Location 41737 rows. Then I run the 10,000 insert script. It finishes in about 10 seconds.\nAt this point the raft index has not moved from 12269. So that seems like a problem?\nOnce the insert script exits, I re run the node count script and get Location 51855 rows so its happy and it seems like the inserts worked.\nAfter a restart of rqlited the logs are https://gist.github.com/donpdonp/b19258f1d89c24618dfffa08a5d63891\nraft: Restored from snapshot 1-12240-1530814483047 is the same snapshot as before. applied index is up to 12271, and the select count(*) is back to Location 41737 rows.\nso im perplexd as to whats going on.. a little more info from debug/vars shows \n```\n{\n  \"execute_transactions\": 0,\n  \"execution_errors\": 5,\n  \"executions\": 5,\n  \"queries\": 10136,\n  \"query_transactions\": 0\n}\n```\n10000 queries but 5 'executions'? perhaps that indicates what you're saying about not waiting for the insert to finish? though if that were the case I would expect count(*) to remain the same.. fantastic. things are working as expected now. thx. makes sense that read-queries are not written to the log.. ",
    "tomdesair": "I also want to use rqlite in a new Django project. Therefor I wanted to check if this PR is still waiting on the 5.0 release or if it could already be merged in a new 4.x release?\nThank you all for all the effort you've put in rqlite and best regards,\nTom\n. ",
    "lalyos": "Automated builds are described here, but basically its connecting a git repository (with the Dockerfile in it), with dockerhub. Than every commit triggers dockerhub to check if it has any image to build (based on tag/branch patterns).\nThis Dockerfile is building the binary in a container, and not downloading it form github release page. Therefore the only needed 2 additional files are:\n-  Dockefile\n- entrypoint.sh\nThis way you dont, have to maintain a new directory for each version, just keep them in the same repo as the source.\nOf course there are valid reasons for having a separate docker-myproject repo, but in this case its only 2 files, so it seems easier to include with the source.\n. I can see, there are alpine versions of the docker image: https://github.com/rqlite/rqlite-docker/tree/master/4.2.2-alpine but they are not pushed to dockerhub. \nSo maybe you can just keep both repos (rqlite/rqlite-docker) but restructure rqlite-docker, to have the versions in branches, insted of directories.\nAutomated builds can be set-up also to build different image tags, from directories, but in that case, every commit will trigger all your images. For example see the oracle/openjdk image. All versions (6/7/8) are rebuilt 3 days ago.\nI think a docker image shouldn't be rebuilt with the same tag. If you want a new version, use a different tag.. I know that a lot of docker images using the per-directory pattern (line nginx or alpine) for maintaining versions. But mostly they are the official/library images. They are using some different images build process, and therefor, those images are not \"automated\" images. Which probably can be trusted in the case of official images, but automated build is the recommended way.. yes that would be the base of your image. Its an automated build you can see the dockerfile here: https://hub.docker.com/r/frolvlad/alpine-glibc/~/dockerfile/\nThe reason behind this base image is, that I wasn't able to get a fully statically compiled binary version of rqlite. What I tried was the usual CGO_ENABLED=0 but than I got some other error messages. I guess some of your dependencies does need cgo...\nAn alternative is that you start from an official alpine, and add the glibc binary packages (they are not officially released) so its 4 lines:\napk --no-cache add ca-certificates wget\nwget -q -O /etc/apk/keys/sgerrand.rsa.pub https://raw.githubusercontent.com/sgerrand/alpine-pkg-glibc/master/sgerrand.rsa.pub\nwget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.27-r0/glibc-2.27-r0.apk\napk add glibc-2.27-r0.apk\nfull explanation here. ",
    "RameshRM": "@otoolep thx, seem like you are pretty active . Sure, \n\n\nStarted Leader node on standalone mode\nrqlited -http-addr 0.0.0.0:4001 -raft-addr x.x.x.x:4002 -http-adv-addr x.x.x.x /etc/opt/db_folder\n\nrqlite started and http interface is up and running @ port 4001\n\n\n\nStarted follower with join address\nrqlited -http-addr 0.0.0.0:4001 -raft-addr x1.x1.x1.x1:4002 -http-adv-addr x1.x1.x1.x2 -join http://x.x.x.x:4001 /etc/opt/db_folder\n\n\n\nLogs : \n\n[rqlited] 2018/08/18 23:00:35 rqlited starting, version v4.3.0, commit 2883094c2b32cee035f44c1dce55326aaf36af9f, branch master\n[rqlited] 2018/08/18 23:00:35 go1.9.1, target architecture is amd64, operating system target is linux\n[store] 2018/08/18 23:00:35 ensuring /etc/opt/db_folder exists\n[store] 2018/08/18 23:00:35 SQLite in-memory database opened\n[mux] 2018/08/18 23:00:35 mux serving on `x1.x1.x1.x1:4002`, `x1.x1.x1.x1:4002`\n[store] 2018/08/18 23:00:35 waiting for up to 2m0s for application of initial logs\n2018/08/18 23:00:35 [INFO] raft: Node at `x.x.x.x:4002` [Follower] entering Follower state (Leader: \"\")\n2018/08/18 23:00:36 [WARN] raft: EnableSingleNode disabled, and no known peers. Aborting election.\n[rqlited] 2018/08/18 23:02:35 failed to open store: timeout waiting for initial logs application\nAt this time rqlite dont start, because leader is not reachable and timesout\n2.1 Now starting the follower in standalone mode: \nrqlited -http-addr 0.0.0.0:4001 -raft-addr x1.x1.x1.x1:4002 -http-adv-addr x1.x1.x1.x1 /etc/opt/db_folder\n\nAt this time sometimes even standalone dont start\n. \n",
    "rhnvrm": "Thanks for pointing that out, I had discounted it as I thought it was something specific to my terminal. Although, the underlying library does not expose the internal terminal which handles setting the mode and it is not possible to call close on it directly. One solution would be to modify the library with a PR. \nI have committed another solution, which is just a simple hack which just saves the history before calling close on the external terminal struct.\nA whole new approach could be to do away with this library and use https://github.com/c-bata/go-prompt or something similar instead.\nWhat's your opinion on this?. @otoolep - I have sent two PRs to prompt to solve this. One is merged, waiting for the other, you can test it using my fork, https://github.com/rhnvrm/prompt. @otoolep - both PRs have merged.. @otoolep - A very nice suggestion, even I think blank lines should not be added to the history. Have sent a fix to Bowery/prompt. . Thanks @otoolep for reviewing \ud83d\ude07\nThis will be a great addition for users of the rqlite client.. For me the history is being saved, but I have to press the up arrow twice and so on. I think the term library logic is saving histIdx which cannot be updated or preserved as it is private. I could send a PR to their library to add getters and setters for that field.. ",
    "runsisi": "yeah, it occurred while restoring from a very big postgresql data set.. @otoolep you are welcome :). ",
    "AshwinJay": "Thanks. Closing this as a Duplicate of #257.. ",
    "titogeorge": "Closing this, SQLite is still going to read-only mode. But looks like that's not an issue. I was thinking going to read-only mode causing the server to fail, but it was because of WaitForApplied timeout being less. Its often going beyond default 2m. Setting to a larger value helped. Will investigate why WaitForApplied is taking 3 to 4 mins in some cases. \nBig Thank you for your efforts! . ",
    "didip": "I see that it uses sqlite \":memory:\" option. I don't think sqlite has an option to limit maximum ram used. I believe it also does not do periodical persistence to disk.. The SECURITY.md docs is also great!\nFollow up question if you don't mind.\nHave you done benchmark on the in-memory backend? I'd love to see a ball park number if you happen to have it.. ",
    "tapir": "Just noticed there is a mail group. I'm closing this one as it's not an issue but just a question.. ",
    "heckdevice": "Thats a valid point. OK\n. Mistake. Will revert.\n. I just checked the code in readhandler that also logs at Tracef not error. This is more or less a copy of the same. Do you want the readHandler to be changed as well?\n. Ok. my first go exp so... :)\nAgain, checked the readHandler and this bit is ctrl+c & v from that only.\n. ",
    "adelowo": "strings.TrimSpace ?. Why is the error being discarded and not returned to the user.. should be fmt.Errorf(\"inv..... %v\", err). Oh, great then. Then why not use errors.New since this would produce an error if ran through go vet. or so I think. \ud83d\udc4d . "
}