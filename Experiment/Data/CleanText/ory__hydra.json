{
    "aeneasr": "Fixed here\n. superceded by #12 \n. done\n. Thanks for your input. I think I'll keep it pluggable / optional like you suggested. It's just a few chars and with HTTP/2 I don't think it will be much trouble sending a few more chars.\n. Thank's for your feedback. I agree with the points you made. Token revokation is actually built into Hydra which is why I also deem JWT not to be as useful as they might be. On the other hand, client services / apps can easily decode and validate JWTs with Hydra's public key and read important information like subject or issuer. On the other hand, Hydra stores everything in Postgres and does itself not really need JWT to work. I will have to think about this a little bit more.\n. One more point, HTTP/2 multiplexing could render the bloated header argument invalid. This is at least what my gutt is telling me.\n. Thanks @tbroyer , after reading your feedback and sleeping over it, I have to agree that implementing JWT was not the best choice. I will make JWT optional for access tokens or maybe even remove JWT signed access / refresh tokens completely.\n. Thanks all, this is now tracked in #32 .\n. Feel free to post your feedback on https://github.com/ory-am/hydra/issues/32#issuecomment-167149893\n. Thanks!\n. Hey thanks for your feedback, I think integrations like LDAP, OpenID and SAML/JWT Assertions are important for the project's success. I have not a clear roadmap yet when to get there but I'm happy for any input, ideas or contributions regarding that matter.\n. You could easily implement LDAP for user storage by introducing a new connector (they are called providers right now see #38). The interface can be found here with an example implementation here. Please be aware that the Provider interface is not final and is subject to change to make things more compatible with non-OAuth2 providers. Additionally, Providers will be renamed to Connectors which is tracked in #38 \n. :+1: :)\n. with #62 hydra has a new identity workflow. you can now implement LDAP easily\n. SAML support would be great. There's already a TODO item for this in the oauth2 handler: https://github.com/ory-am/hydra/blob/master/oauth/handler/handler.go#L263-L268\n. Thanks, great idea! :)\n. This is now possible by implementing a consent endpoint that understands SAML :)\n. Thank you, these things get messed up when you refactor stuff... :)\nDo you want to create a PR for this?\n. I think the smartest thing would be to set the generator strategy through an environment variable: OAUTH2_TOKEN_STRATEGY=<strategy> This way, new / custom strategies could be declared and used. For now, two strategies will exist:\n- RandomToken: A random 64 char string without self-containing information\n- JWT: Use JWT as access tokens\n. Yes you're absolutely right. So you're basically storing the token signature in the database and check if the signatures match? I think that's a smart approach but it still bloats requests, doesn't it? We could basically do this with JWT/JWS out of the box.\nRegarding securely stored client secrets: I don't think that many companies are doing that right now because passwords are auto-generated and available in cleartext for lifetime. I don't want to imply that I don't see the necessity (securing tokens but not secrets is worthless), just pointing out what I have seen so far.\nI saw that client secret encryption was added to osin a few days ago. Osin has terrible error handling which makes it almost impossible to find errors in your request (e.g. forgot to add some parameter or misspelling). Are there any alternatives to Osin out there? I would prefer using a solid framework instead of writing a new one. On the other hand, a solid golang OAuth2 library would be worth the work. Or we could fork / refactor Osin, because it's actually really close (if not completely) to spec with some weaknesses.\nOne more thing to note is that compromising the machine where hydra-host is running would compromise the whole system as well. You would have access to the encryption keys (or at least know their locations) plus database URL and administrative options like hydra-host client create. But in most cases databases are the leaking pipes and hosts are hard to capture if only one service is open to the net. I've actually thought of enabling client / user create only once and requiring a log in afterwards. But this workflow feels very clumsy.\nSorry if everything is a little random, I'm trying to catch as many ideas as possible :)\n. Any ideas how we could make that secure? Thanks by the way for your thoughts, I enjoy these conversations :)\n. Thanks for the feedback. Access tokens should not contain (privacy and abuse concerns) personal information except the subject which should be a unique & opaque id, changing user data should therefore not render the tokens invalid. Right now, Hydra uses a simple { \"jid\": \"\" } claim as refresh tokens and { \"sub\": \"\", \"exp\": \"...\" ... } as acces tokens. What I have seen now is that many Identity Providers support OpenID Connect. I have to be honest that I have never made use this standard before nor have I, until now, used or seen any library implementing OpenID Connect client features.\nI have not yet decided if Hydra's purpose is to offer ID management plus user profile management (/userinfo endpoint) or if it is just a AuthN/AuthZ mechanism. What's cool however is that the Hydra's third party (e.g. connect with dropbox) feature implements capabilities for redirecting to a dedicated login endpoint specified by SIGNUP_URL. This is basically already what Open ID Connect specifies for their login routine and could easily be extended to support the return a identity token. This token could then be used to access a user specified /userinfo endpoint. I will check out Open ID Connect over the next few days and decide if and how this is going to implemented in Hydra.\nWhat's your stand on Open ID Connect?\n. Thanks for the continued feedback. I took a closer look at OIDC and it should definitely be something to be considered in the connectors (which are currently called providers, see #38 ). Unfortunately, dropbox do not support OIDC so we have to keep OAuth2 -> check user endpoint for at least some of them.\nI am in doubt if Hydra should act as a OIDC provider right now. Hydra does offer user accounts and account management and I'm seriously considering to remove this right now or at least put this feature on hold and add a warning to the docs. I will come back with a decision in the next few days.\n. OpenID Connect will be implemented in Hydra by switching from Osin to Fosite (see #46 ). Timeline is not 100% clear yet but I will start implementing once my exams are over which is in ~2 weeks.\n. Additionally, one should be able specify the required scopes for these providers.\n. Thanks!\n. Thank you for the PR. In fact, I wanted to add vendoring with 0.1 release and had added it before. Unfortunately I heard of many problems with vendor locking at other go projects and wanted to check all options first. But since there are already incompabilities with libraries it is a good idea to do this now. Unfortunately tests on your PR fail and due to it's size I can not review it. Please divide your commit in two:\n- vendor: godep save: Make sure to only include changes made by godep save\n- module: changes you made, for example all: added Makefile or oauth: resolved osin bc breaks\nTo do so, simply checkout a new branch on your local machine based on the master and force push your changes to this feature-vendor branch with: git push -f your-remote <localbranch>:feature-vendor\nThank you for contributing to Hydra!\n. One more thing, is the new go vendoring going to stay experimental or is it going to be included in Go 1.6?\n. Feel free to reopen this issue any time.\n. As far as I can tell there are none. However, providers will be renamed to connectors, as this seems to be the wording people have agreed upon.\n. Superseded by #38\n. Yes, all store implementations are abstracted and it should be possible to implement other store backends. I would however do not recommend to use a No-SQL / Non-Acid solution for your auth* services.\nRethinkDB, like probably all No-SQL databases, is not ACID compliant. Let's say you revoke a token. Without ACID compliance, the token will be revoked some time in the future. An attacker owning the revoked would therefore still have access although access has been revoked until RethinkDB has propagated the changes across the cluster.\n. If you want to use RethinkDB anyways (e.g. no need for uber-security) there are different stores that need to be implemented for this. For example:\n- https://github.com/ory-am/hydra/blob/master/account/storage.go\n- https://github.com/ory-am/hydra/blob/master/oauth/provider/storage/storage.go\nI think most of them are pretty straight forward, you can always take a look at the postgres implementations if you want to.\nIf you need any help implementing or if you want to try things out feel free to ask me here or on our gitter channel: https://gitter.im/ory-am/hydra?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\nYou can also play around with dockertest for rethinkDB integration tests :)\n. Hey yep you're absolutely right. I was a little in a hurry and did not read up on everything, sorry for that :)\nAtomicity is already one step in the right direction. If you don't manage an uber RethinkDB cluster, it should be a viable storage solution for Hydra. Osin (the OAuth2 library behind Hydra) actually already supports a RethinkDB: https://github.com/ahmet/osin-rethinkdb\nYou could play around with osin and osin-rethinkdb to get things started. Once that works it shouldn't be hard to get RethinkDB working for Hydra.\n. You rock!\n. good stuff! :)\n. A note on section 5.4\nCertificate based HTTP authentication as proposed by section 5.4.2 is out of most resource provider's scope. RESTful APIs are meant to work well with public clients and user agents. Certificate based authentication is thus unfortunately not realistic.\n. A note on section 5.3\nSection 5.3 deals with client app security and is therefore out of hydra's scope. For transparency reasons and good practices, it has been added to the readme.\n. :) I'm very busy at this and next week due to exams and some other work related things but I will start working on improving Hydra a lot beginning mid/end of feb :)\n. client\ntime=\"2016-01-06T14:41:07Z\" level=warning msg=\"Authentication invalid.\" authentication=invalid error=\"Got errors: [Post http://localhost:9000/oauth2/introspect: dial tcp: lookup localhost: too many open files]\" valid=false\nMost probably caused by client middleware...\n. host\n2016/01/04 14:07:04 http: Accept error: accept tcp [::]:9000: accept4: too many open files; retrying in 5ms\n2016/01/04 14:07:04 http: Accept error: accept tcp [::]:9000: accept4: too many open files; retrying in 10ms\n2016/01/04 14:07:04 http: Accept error: accept tcp [::]:9000: accept4: too many open files; retrying in 20ms\n2016/01/04 14:07:04 http: Accept error: accept tcp [::]:9000: accept4: too many open files; retrying in 40ms\n2016/01/04 14:07:04 http: Accept error: accept tcp [::]:9000: accept4: too many open files; retrying in 80ms\n. confirmation that this is introcued by client middleware. Killed client process and socken immediately free'ed up. Most probably first http request.\n. resolved by https://github.com/ory-am/hydra/commit/6e9b681b73c3978b4dce28cc7be23a1422c90e26\n. Yes, I think that is a good summary!\nWhops, clicked close and comment\n. Cool! Thank's for looking over it :) Did you check out how policies work?\n. Yeah still some cleaning up to do and test cases to write. Docs will follow alongside :)\n. Hey thanks! I will take a closer look at this tomorrow\n. Thanks!\n. Perfect, thanks\n. Wow cool stuff, looks like a lot of work! I'll go over everything in detail.\n. Man I hope I won't break too much of this once we go fosite...\n. Ha! Yeah absolutely :)\n. Okay so priorities for me right now are:\n1. Add rethink db to dockertest\n2. Review and merge ladon PR\n3. Review and merge this PR\n. Ah I see :) I still prefer dockertest because I don't have to set up rethink db on my local environment to get tests passing :)\n. I'll try to get that done tonight. Workload is kinda insane right now but these two PRs are high priority for me :)\n. https://github.com/ory-am/dockertest/pull/23\n. dockertest is merged\n. Hey, thanks for cleaning up! I will need a little time to go through all the changes. Are you planing on using Hydra in a production environment? If so, it would be very good if we two could get together for example on the gitter channel and discuss next steps, caveats and architecture.\nThere are still some areas and concepts in Hydra which I've grown to dislike and if you want to use Hydra in production we need a clear path so you won't get hit by unexpected changes or issues.\nWe will use Hydra at ORY in closed beta \"production\" starting first of march (1.3.2016) and hopefully get some insights into stability, scalability, security and so on.\n. One major issue for me is upgrading / migrating the database - automating this is something where I have very little experience in. But I don't want to break your production system because I decided to rename some struct or add some functionality..\n. Okay very cool, glad we're on the same page then :) I will try to answer you in detail tomorrow\n. Found a couple of free minutes... :)\n\nI do for a living so I'm well aware of that things WILL break in hydra.\n\nPerfect. :) We will have to find a good way to migrate databases but we could for example use a version table and have an array of incremental upgrade commands (ALTER TABLE, ..).\n\n\nDb migrations (only useful for sql)\n\n\nSee above. We need to find a good way to do this for both rethinkdb and sql\n\n\nCluster functionality/scalability (ability to connect multiple hydra instances together and issue commands between them)\n\n\nNot needed! Hydra is written 12-factor so it's completely stateless. Hydra relies on a highly available database cluster (rethink or postgres) - so if you have a good database cluster hydra will be a good cluster as well.\nWhat I want to do is a CLI that uses the hydra RESTful api for managing clients, policies and accounts.\n\n\nImproved documentation ;) Right now I really don't know how to pass\n   arbitrary data in the jwt so other services using the jwt can use that data\n   in a scaleable way.\n\n\nAbsolutely, I won't be able to go into details now but this is definitely something. If the CLI was available, I however think that reading the code would already help a lot.\nRegarding JWT - I will probably remove JWTs as access tokens and introduce OpenID Connect ID tokens instead. This is truly an area which must be covered.\n\nOne thing I've wanted to write for a while is a intra-communication system\nthat is plug and play for more or less all go services. And to this\nintra-communication system write a dashboard where the status of the\nservice is shown, with ability to send commands to each instance (or group\nof instances). I think a system like that in hydra would make hydra more\nenterprise.\n\nSound like a cool idea, really glad you consider hydra :)\nThe following is a list to keep my train of thought. I will explain the things in there another time :)\nI think these are the things that need to be done / talked about are:\n- implement fosite\n- implement OpenID Connect (where should the data come from? what claims/scopes to support?)\n- refactor login and consent logic. maybe login/consent page should be responsible for getting user data\n- consider to what extend account / profile management should be implemented\n- clean up messy tests (replace database integration tests in handlers with mocks)\n- implement better granted endpoint\n. I forgot to add something.\n\n\nCluster functionality/scalability (ability to connect multiple hydra instances together and issue commands between them)\n\nNot needed! Hydra is written 12-factor so it's completely stateless. Hydra relies on a highly available database cluster (rethink or postgres) - so if you have a good database cluster hydra will be a good cluster as well.\n\nRight now it is not anticipated that hydra will consist of multiple executables. I want Hydra to never get on a level of complexity, where it isn't considered \"micro service\" any more. This why I don't want Hydra to have any sort of HTML output nor a complex user management and it should not become a service for connecting legacy enterprise standards / software. I think there are better solutions already available for that! Instead, hydra should be a fast, easy, powerful and yet very secure service one can use for a new (web) app or micro service environment which will provide a secure experience to millions of users. This is my vision for hydra! :)\n. I've took a closer look at about 50% and everything looks really well. Give me a little bit more time to review everything in detail so I don't miss anything :)\n. Done! :) Everything else LGTM\n. Thanks (y)\n. Nice thanks! :) SOO cool that rethinkdb is now implemented. I hope you're getting somewhere with hydra :) \nI will deploy Hydra in it's current form into production very soon (probably tomorrow) and see how it works when facing the public net!\n. Very cool! I will look over it in detail during the day (MEZ)\nGesendet mit meinem HTC\n----- Reply message -----\nVon: \"Michael Golfi\" notifications@github.com\nAn: \"ory-am/hydra\" hydra@noreply.github.com\nCc: \"Aeneas\" aeneas.rekkas@serlo.org\nBetreff: [hydra] Adding basic LDAP package (#57)\nDatum: Mi., M\u00e4r. 9, 2016 06:47\nHi @arekkas,\nI would like to use this project, I need LDAP integration though. So I've taken a shot at writing it myself using the suggestions from #28.\nI am however, not completely familiar with your codebase and I am unsure what you are expecting through the interface for a non-OAuth provider.\nPlease let me know,\nMichael\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/ory-am/hydra/pull/57#issuecomment-194124435\n. Sounds good :) As far as things are looking right now, this should work fine. So you found the right place for everythin! :)\nOnly thing I'm seeing is that\nfunc (l *ldapconf) GetAuthenticationURL(state string) string {\n    return \"\"\n }\nisn't currently used but is a hard-coded workflow in hydra. So I might have to fix a few things there. GetAuthenticationURL is currently used to redirect a user to the sepcified IdP (identity provider, for example google login). Not sure how that works with LDAP (never used LDAP before).\n. Did you take a look at this: https://auth0.com/docs/connections/enterprise/active-directory ? Would this be required for Hydra as well?\n. One more thing, could you maybe elaborate your use case so I get a better feeling of what you're trying to achieve? :)\n. > To authenticate a user with LDAP, you use a system account to login in, you query the user subject who you would like to authenticate, you find his full path (eg: \"cn=riemann,dc=example,dc=com\"). Once that's done, you try to login using that user path and the submitted password. If it doesn't error out then the login is successful.\nOk so what we could do would be:\n- hydra.yourorg.com: A running hydra instance\n- sso.yourorg.com: The bridge between hydra and LDAP. So basically \"you use a system account to login in, you query the user subject who you would like to authenticate, you find his full path (eg: \"cn=riemann,dc=example,dc=com\")\" plus a user interface\n- ldap.yourorg.com: The LDAP / AD server\nThen we could add provider which redirects to sso.yourorg.com, then the authentication against LDAP happens (using custom queries or what-not) by providing a user interface where Peter (for example) enters his credentials and after successful authentication redirects Peter back to Hydra. Hydra then extracts the user info from a SAML Assertion or a signed JWT and issues access tokens accordingly.\nDoes this make sense? If yes, I have some ideas how we could make that work with Hydra and fix the currently broken login / consent workflow. So this is on my to do list anyhow :)\n. Oh and feel free to ask if I am unclear or context is missing or the message doesn't get through. Happy to answer any questions and also happy to see people that want to use Hydra!\n. > I think your proposal makes sense but wouldn't starting a new sso server defeat the purpose of integrating LDAP?\nMaybe SSO was the wrong wording. What I mean is a ldap frontend which offers an user interface (enter your username and password) and verifies the user input by querying the LDAP server. So it is not an SSO service per se, it just feels like one to the user who logs in and never notices that LDAP is being used.\n\nWould it make sense to launch some sort of authentication endpoint on Hydra?\n\nI want to avoid a real authentication endpoint on Hydra because it would require some sort of user interface - and I want to keep that away from Hydra as it is always hard to customize those and adds a lot of complexity. Right now, you can however use the Resource Owner Password Credentials grant which is specified in OAuth2 and allows OAuth2 clients to log users in using their username and password credentials. But that's a little bit off topic, so don't worry about this part too much ;)\n. Yes that's it exactly. I was planning on implementing that flow anyways, because there is no UI in hydra and we need a login interface :)\n. The above works by the way already for signing up users :)\n. Cool I will check that out tomorrow!\nAnother option could be to implement an LDAP Adapter of the account storage. You still need an user interface though :)\n. If you implement the store you still need an UI. Also hydra currently uses BCrypt for password hashing (mandatory) so there might be some trouble there as well. I think that a third party service is the faster and smarter way to go (and more flexible).\n. I had a little time to think about this, and I think we should take the road of letting users connect to multiple user databases. One could be Postgres, another LDAP, another MySQL (and so on). This is going to be some work because we would need to be able to\n- add & remove user databases with a command like hydra connect ldap://...\n- specifying hash options (bcrypt, sha, ...)\n- maybe do other custom stuff\nor more abstract: the connectors should be able to handle common configuration set ups.\nWhat do you think @michael-golfi \nping @leetal \n. Ok so the idea would be:\n- idp.yourdomain.org: implements a HTTP interface that allows for user management (create, login, ...). It is not important if the service uses LDAP or Postgres or what not.\n- login.yourdomain.org: a front for logging people in (user interface) and getting their consent (if oauth2 token is requested). Can use idp.yourdomain.org for user data lookup\n- hydra.yourdomain.org: uses idp.yourdomain.org to request user data for processing\n. Hydra would include packages (hydra-host, hydra-idp) and I would probably bootstrap an exemplary hydra-login front end using e.g. react.\n. > I think using LDAP as a database is a good idea. IMO bigger companies will want to reuse their infrastructure and not recreate anything if possible. LDAP and Active Directory is also used as a primary data source for the most up to date user information. I cannot speak on behalf of having multiple data sources for user information since I have never personally seen this, except in the case when departments would want to enhance user data with custom permissions. They would have a local (eg: Postgres) and remote (eg: LDAP) in this scenario.\nAgreed! Just need to find a good way to tackle the different configuration scenarios. I've never used LDAP but from what I know the queries can look quite different depending on the use case (e.g. query against department, company, ...).\n\nI've started building the LDAP connector. I was following the interface you have for storage as a 'contract' between the services, is that alright? For the frontend in this case I'm going to most likely use a cut-down bootstrap with minimal dependencies (this is already done).\n\nSounds good. I still have the concerns that I raised in the lines above. For implementation help you can also take a look at CoreOS/Dex LDAP connector.\n\nHave you considered using a config manager such as viper to set up deployments with presets?\n\nNot yet, but it looks like a really useful addition. I would really like to have an CLI which let's me do:\nhydra account connection add ldap://...\nFor this, we would need to write a small configuration persistence utility and could use e.g. viper unmarshalling to retrieve it. Also the CLI needs refactoring.\n\nI want to go a little bit more into detail with the IDP idea:\nLet's say I want to connect to my enterprise LDAP and use Hydra for OAuth2 token issuance. I would add my LDAP connector endpoint to hydra:\nhydra account connection add https://ldap-connector.yourdomain.org\nThe endpoint https://ldap-connector.yourdomain.org would implement an HTTP interface, for example:\nGET /accounts - get all accounts\nGET /accounts/<id> - get an account by id\nGET /accounts?username=<..> - get an account by the username (username could be email as well)\n...\nHydra could offer different exemplary (or default) implementations for this http interface, including hydra-connector-ldap, hydra-connector-postgres, and so on. This would be similar to the naming currently existing in the cli directory.\nThat way, we would separate concerns and let people easily extend or modify an existing connector without having to clone all of hydra. Connectors are also likely to receive less and smaller updates so keeping those maintained would be much easier.\nWhat do you think of this approach? It would take time to refactor that stuff, also I'm working on implementing fosite in hydra as well.\n. > I agree this would be a really nice way to separate concerns, and add their own connectors.\nGlad you like the approach :) It will take a little bit of time for me to prepare / implement those things however.\n. The approach we discussed will be tackled with #62\n. No worries, it will take me some time to get the architecture where I want it to be.\n. Superseded by #62\n. @iamthemuffinman hydra itself does not know connectors. Your login endpoint needs to be able to handle LDAP. Hydra authenticates users using JWT. Here's an example how this works in real-life.\nThere is currently no official LDAP login endpoint - so yes, a hydra compatible LDAP endpoints needs to be written :)\n. Thanks, we're experiencing troubles with our hosting provider, who is already notified.\n. Looks good! As of right now, we have multiple executables (see cli). I was thinking of splitting those up in separate repositories as the current pattern tricky do deal with in buildpacks. Could multiple executables work with Docker or is it there an issue as well?\n. Ok, of course we could simply build multiple executables in the Dockerfile and expose them on different ports. So it shouldn't be a huge deal\n. Ok, I don't think that would work with docker autobuild. Looks like we have to create multiple repositories.\n. @leetal keep an eye out for this one :)\n. Repositories relevant for the refactor:\n- https://github.com/ory-am/hydra-signup-react (exemplary sign up app in react)\n- https://github.com/ory-am/hydra-singin-react (exemplary sign in & consent app in react)\n. The following chart is a very basic architecture overview.\n\nCLI\nThe CLI hydra will replace the functionality that currently resides in hydra-host and talk through HTTP REST with hydra-host. The admin needs to log in using app credentials. If no app is registered in Hydra, a OTP (one time password) will be printed to stdout by hydra-host. The admin needs to use that OTP in order to create the first administrative client.\nidp.hydra.abc.com\nI decided to move the identity provider part away from Hydra's core. Instead, it will reside in a microservice. Anyone who wishes to use LDAP or an existing user database as an identity source can do that by implementing the required HTTP REST interfaces (not defined yet).\nIdentity provider(s) will be added using the CLI: hydra idp add http://...\nconnector.hydra.abc.com\nThe connector is responsible for delegating a user to Google, Microsoft and other third party authentication services and returning \"user info\" to hydra. Hydra will then use that user info to find a match at the identity provider and confirm that the user exists. The matching will be done internally in hydra (currently known as \"oauth2 connection\")\nConnectors will be added using the CLI: hydra connector add http://....\nResource Provider Endpoint\nThe middleware and client library will be rewritten and offer two interface:\n1. Check if a token is valid (checks token expiry, token revokation, scope)\n2. Do what 1 does plus access control through policies\n. The reworkings of connectors and identity providers let us additionally paralelize lookups with high efficiency. Cash. :)\n. Separating idp.hyra.abc.com, singin.hydra.abc.com and connector.hydra.abc.com is maybe not a good idea. The question is, if idp.hydra.abc.com is even required and if singin and connector should be one. It might be good if hydra took over a lot of the complexity and on the same time, it complicates service flows.\n. Complicated: The login endpoint could redirect back to hydra which would redirect that request to Google, MS, and so on. The callback would be a hydra endpoint which would validate the authentication request through a \"connection\" database lookup and a quick check in at the idp and redirect to the consent endpoint which would issue the consent token.\n. Alternative: The login endpoint handles all the third party authentication on its own and is simply responsible for returning a consent token. This would require much more sophisticated login / consent endpoints\n. One question that has me spinning in circles is how to handle social / remote logins. There are two possibilities I see right now.\nTerminology:\n- IdP(s): Identity Provider(s)\n- Remote / Social IdP: This could be Google, Microsoft, ...\n- Local IdP: In monolithic applications, there is always a \"user database\" where the username, email and password are stored and retrieved. A local IdP is a such a user database which is usually under full control of the hydra administrator and is run in the same network or domain.\nThe remote party is seen as a standalone IdP\nThe remote idps (e.g. google) are considered a local idp: When the users signs in using a social login, no lookup is made if that user exists at the local idp. This basically means that we can skip the sign up process.\nWorkflow (simplified)\n1. User chooses to use google for authentication\n2. User is redirected to https://hydra.com/oauth2/auth?idp=google&client_id=...\n3. User is redirected to https://google.com/sign-in\n4. After successful authorization at google, the user is redirected to e.g. https://hydra.com/idp/google/callback\n5. Hydra authenticates the user / validates the request by e.g. decoding the id token or making some sort of request to google\n6. Hydra asks for the users consent\n7. Hydra issues an authorization code / access token\nPro:\n- Reduced complexity: No roundtrip or registration at the \"local\" identity provider required when using social logins\n- No need to introduce a functionality like \"social connectors\" because we can use social idps in the same fashion we use local idps.\nCons:\n- Not sure how this scenario would work out if local and social IdPs are used. Because local IdP would create a user account but social IdP would not.\n- Not sure how to fetch user data in an orderly fashion from social IdPs. We would need some sort of adapter, but user profile requirements vary a lot across projects.\n- Any user can simply \"sign up/in\" using a social IdP (if activated). There is no \"control\" possible. Not sure how banning accounts, invitation only sign up and similar things would work.\n- If the remote party discontinues services or bans the user account, the local user account will be lost as well.\nThe remote party acts as an intermediate connector\nIn contrary to above, the remote party is an identity provider as well, but hydra acts as a bridge between it and the local idp. Every user requires thus an account at the local idp and the remote idp in order to sign in.\nWorkflow (simplified)\n1. User chooses to use google for authentication\n2. User is redirected to https://hydra.com/oauth2/auth?connector=google&client_id=...\n3. User is redirected to https://google.com/sign-in\n4. After successful authorization at google, the user is redirected to e.g. https://hydra.com/connectors/google/callback\n5. Hydra authenticates the user / validates the request by e.g. decoding the id token or making some sort of request to google\n6. Hydra checks the connection database. It contains fields remote_id, local_id and connector. If the user id returned by the connector exists, hydra uses the local id for further lookup.\n7. Hydra checks the local IdP(s) for the found local user id and may ask if that user can be authenticated (this could also be done through policies)\n8. If all of the above was successful, hydra will ask for the user's consent\n9. Hydra issues an authorization code / access token\nPro / Con: TBD\n. Connection needs an endpoint which returns \n{\n   Authorization: 'bearer .....',\n}\nor some other value for non-OAuth2 requests. This allows for sign up trickery\n. > Alternative: The login endpoint handles all the third party authentication on its own and is simply responsible for returning a consent token. This would require much more sophisticated login / consent endpoints\nis actually the smarter choice, if the endpoint is returning a \"connection token\" including the remote_id\n. The consent token should be able to carry a remote subject and id\n. 2FA\nhttps://github.com/google/google-authenticator/wiki/Key-Uri-Format\nhttps://tools.ietf.org/html/rfc6238\n. https://github.com/pquerna/otp\n. I have decided to switch from postgres to RethinkDB and use the changes() feature to minimize db queries and significantly increase performance. \n. http://openid.net/specs/openid-connect-core-1_0.html#ServerMTI\n. https://community.pingidentity.com/servlet/fileField?retURL=%2Fapex%2FPingIdentityArticle%3Fid%3DkA340000000Gs7WCAS&entityId=ka340000000GvdRAAS&field=Associated_File__Body__s\n. http://docs.hdyra.apiary.io/#\n. Already on it :)\n. Getting there...\n. This just happened:\ngo\nhydra host &\ngo\nhydra clients create\nClient ID: aaa74b51-e743-4d4c-b69f-ab389bfae503\nClient Secret: 2%fz.c!j.rkKM9aw?.(K(1Qrwr\n. go run main.go keys create foobar -a HS256 --skip-ca-check\nWarning: Skipping TLS Certificate Verification.\n{\n        \"keys\": [\n                {\n                        \"kty\": \"oct\",\n                        \"k\": \"Ql1LdW0vcHlGOUhQJVpnNiNXN2JrPXNCeVMzZGg8KWs\"\n                }\n        ]\n}\ngo run main.go keys get foobar --skip-ca-check\nWarning: Skipping TLS Certificate Verification.\n{\n        \"keys\": [\n                {\n                        \"kty\": \"oct\",\n                        \"k\": \"djY6OyZKbcKnJE12MH0zPlByOSg7WFc5MX0sQj5xMSNo\"\n                }\n        ]\n}\ngo run main.go keys delete foobar --skip-ca-check\nWarning: Skipping TLS Certificate Verification.\nKey set deleted.\ngo run main.go keys get foobar --skip-ca-check\nWarning: Skipping TLS Certificate Verification.\nCould not generate keys: Expected status code 200, got 500.\n{\"request\":\"1aa4c57b-0deb-4c4f-8b0a-ca559a5f2dae\",\"error\":\"Not found\",\"code\":500}\n:raised_hands: \n. The docker image is already available. So feel free to check out the quickstart guide at https://github.com/ory-am/hydra/tree/refactor#quickstart\nInstalling the client cli will not work yet, but you can simply ssh into the docker container.\n. The REST API is now documented at http://docs.hdyra.apiary.io/#\n. > @arekkas the doc says \"Hydra implements all grant and response types, except the resource owner password credentials grant.\" is there any reason for this ? or is it just not implemented yet \nYes. For one, this grant type is discouraged in the official spec:\n\nThe resource owner password credentials grant type is often used for\n   legacy or migration reasons.  It reduces the overall risk of storing\n   usernames and passwords by the client but does not eliminate the need\n   to expose highly privileged credentials to the client.\n[...]\n   The authorization server and client SHOULD minimize use of this grant\n   type and utilize other grant types whenever possible.\n\nAnother reason for not including this grant is that Hydra is not an identity provider any more. Making that grant work with Hydra would require a Hydra-specific endpoint at the identity provider. This reduces interoperability a lot which is the reason for excluding it.\n. Why aren't you using the client credentials grant instead? The resource owner password credentials grant is for resource owners (users) only anyways\n. consent flow in action\n\n. Ok, you can now run hydra wkith an exemplary consent endpoint using docker compose: https://github.com/ory-am/hydra/tree/refactor#run-minimal-installation\n\n. This is extremly hacky: https://github.com/ory-am/hydra/pull/62/commits/9507df3c5b8fcae8de24e4650a6469d61106df10#diff-ff7686b39bf90dc2520886fb874371a4R84\nwaiting for upstream https://github.com/spf13/viper/issues/188\n. A little bit of profiling.\n\n. You can now run the example. Just make sure to check out the right branch:\n$ go get github.com/ory-am/hydra\n$ cd $GOPATH/src/github.com/ory-am/hydra\n$ git fetch origin\n$ git branch -b refactor origin/refactor\n$ DOCKER_IP=$(docker-machine ip default) docker-compose up\nThere's a \"screencast\" gif included in case you don't know what to do.\n. So..I started writing the guide: https://ory-am.gitbooks.io/hydra/content/\nTopics OAuth2 and Access Control are still work in progress.\n. 0.1-beta is ready. Please try things, and break them. :D\n. superseded by #62\n. Hey sorry for the inconvenience, the docs are unfortunately out of date. I'm working on a major refactor right now, so things will change again very soon.\nI suggest to wait for #62 to be merged.\nUpdated docs will follow soon after.\n----- Reply message -----\nVon: \"Diep Pham\" notifications@github.com\nAn: \"ory-am/hydra\" hydra@noreply.github.com\nBetreff: [ory-am/hydra] Fail to execute \"create a new client\" in apiary docs (#64)\nDatum: Di., Apr. 26, 2016 18:04\nI'm learning how to use hydra and trying the example to create a new client, click send request to prod server, but it responses with 404 error code. \nSo:\n- is the documents out of date?\n- is the production server out of date?\nOr I somehow I was doing something wrong?\n\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/ory-am/hydra/issues/64\n. I would give it a month, at maximum 2 months. It really depends on the workload from other projects we are currently involved in. \nHowever, I am confident that the wait will be worthwile. There are a some security issues addressed (kicking out osin and replacing it with fosite), a lot will be done performance wise (switching from polling to in memory & pub/sub with rethinkdb) and it will be much easier to integrate with existing identity providers like LDAP, custom codebases and social login like facebook and the sorts. Additionally, I have defined a very clean workflow for login and consent which will be implemented as well.\nThe code will be much more lightweight and I am looking to partner up with a broadcast driven micro service paas, who might use hydra for authentication. So there will be a lot of real world application and performance inspection.\nAll these changes above required me to do a full rewrite rather than a refactor, which is why I would not build my project on hydra at this point in time.\n. I will additionally add two factor authentication, other means of one time passwords, more security measures and so on ;)\n. it's merged\n. superseded by https://github.com/ory-am/hydra/pull/62/commits/9507df3c5b8fcae8de24e4650a6469d61106df10#diff-4e5e90c6228fd48698d074241c2ba760R1\nHowever, I'm keeping this PR around in case of database env magic stuff.\n. this is now merged in master :)\n. Yes, it's definitely the challenge app's responsibility. But I think that Hydra can take a supportive role in that regard and offer simple APIs to solve these sort of issues.\n\nAm 12.09.2016 um 07:37 schrieb Wayne Robinson notifications@github.com:\nFor time-based OTP, isn't this really a responsibility of the challenge app?\nOr are you planning on storing a number of per-subject keys/secrets in the DB these can be generated against because you want to be the source-of-truth for all things secure (apart from the subject's password)?\n\u2014\nYou are receiving this because you were assigned.\nReply to this email directly, view it on GitHub https://github.com/ory-am/hydra/issues/69#issuecomment-246254009, or mute the thread https://github.com/notifications/unsubscribe-auth/ADN1ellmtVu4oCCxhyyIKNT1ZhQ7utUiks5qpOUAgaJpZM4IWUYM.\n. Moved to unplanned because not a priority and questionable benefit.\n. I don't think this makes a lot of sense. 2FA is usually well supported in all major languages and it's much easier to use language-level api than network level-api.\n. https://github.com/Masterminds/glide/pull/384\n. resolved\n. Let me know if you have any ideas how to improve this. Best practices, specs and ideas alike :)\n. Instead of a flag, JWKs should have an exp claim.\n. JWK Rotation is now implemented by adding another key (pair) to the existing set.. this will become irrelevant once #73 is implemented.\n. This is resolved now. That's weird, did you run glide install first?\n. Looks like this wasn't documented. I fixed that. Check out https://github.com/ory-am/hydra/blob/master/README.md#develop :)\n\nLet me know if that works\n. glad to help\n. done :+1: \n. Hey thanks for the catch. That's my IDE being annoying. I will fix it asap :)\n. To be morged as https://github.com/ory-am/ladon/pull/22 and https://github.com/ory-am/hydra/pull/81\n. Thanks, that happens a lot when it's late and you're german.. :D\n. Thanks, to be merged as https://github.com/ory-am/hydra/pull/81/commits/ed4af602061214ff42a1f6c5a6c1eb9cff1acb57.\n. a high level overview is now merged as #87\n. See https://github.com/ory/examples/issues/4. It doesn't look like this issue get's a lot of attention. It would probably be better to put it in the README.md\n. How disclosure of bugs/security vulnerabilities should be done has been added to the github templates.. thanks, fixed :)\n. fixed that one, too. thanks :)\n. additionally, keys should be passed through env vars\nTLS_KEY_PATH\nTLS_CERT_PATH\n. the keys will be imported to the JWK store. we need to figure out if the key from JWK store overrides the key from disk when changed or the other way around\n. it's probably smarter to call the option import-tls-key instead.\n. upstream #92\n. I think it would be good to wait for https://github.com/square/go-jose/issues/95 to be implemented before this gets merged. The current workaround feels hacky\n. https://github.com/ory-am/fosite/pull/48\n. :open_hands: https://github.com/square/go-jose/issues/95 is now merged. let's roll\n. ```\ngo run main.go keys create foo123 --dry --skip-tls-verify\nWarning: Skipping TLS Certificate Verification.\nCould not generate keys: Because you are using the dry option, the request will not be executed. You can execute this command using:\ncurl -X POST -d \"{\\\"alg\\\":\\\"\\\",\\\"keys\\\":null}\" -H \"Content-Type: application/json\" 'https://localhost:4444/keys/foo123\n```\n. Some values are already possible to pass:\n```\nhydra help clients create\nThis command creates a basic OAuth2 client. Always specify at least one redirect url.\nExample:\n  hydra clients create -n \"my app\" -c=[http://localhost/cb] -g [authorization_code] -r [code] -a [core,foobar]\nUsage:\n  hydra clients create [flags]\nFlags:\n  -a, --allowed-scopes value   A list of allowed scopes (default [core])\n  -c, --callbacks value        REQUIRED list of allowed callback URLs (default [])\n  -g, --grant-types value      A list of allowed grant types (default [authorization_code])\n      --id string              Give the client this id\n  -n, --name string            The client's name\n  -r, --response-types value   A list of allowed response types (default [code])\nGlobal Flags:\n      --config string     config file (default is $HOME/.hydra.yaml)\n      --skip-tls-verify   foolishly accept TLS certificates signed by unkown certificate authorities\n```\nit makes sense to pass the password as well. The password should however not be set using --secret=secret but rather by bool flag --secret that prompts for a password\n. Do you need this feature for hydra clients create or for hydra host (the initial admin client credentials)?\n. if it's not interactive, the secret will be stored in bash history, /proc, ..., no?\n. Hm. I took a little time to research and stumbled upon SSH that does not allow to pipe passwords. As already mentioned, passing passwords to the CLI is a security risk. Read more on this:\n- http://stackoverflow.com/questions/6607675/shell-script-password-security-of-command-line-parameters\n- http://stackoverflow.com/questions/24454037/pass-a-password-to-ssh-in-pure-bash\n- http://serverfault.com/questions/592744/how-to-hide-a-password-passed-as-command-line-argument\n- http://unix.stackexchange.com/questions/78734/why-shouldnt-someone-use-passwords-in-the-command-line\n\nReally, this should be fixed in the application itself. And such applications should be open source, so that fixing the issue in the app itself should be an option. A security related application which makes this kind of mistake might make other mistakes as well, so I wouldn't trust it.\n\nMy best guess right now is setting this through env vars:\nUSE_SECRET=123456 hydra clients create ...\nWhat do you think @janekolszak ?\n. Check out https://github.com/ory-am/hydra/commit/9e4e6273e6e18ca0533ea8e89c7228a4894a6380 - it would work like this:\nFORCE_CLIENT_SECRET=somesupersecretPassword hydra create -n \"my app\" -c=[http://localhost/cb]\n. > Environment variable will be visible in .bash_history, also out.\n\nThe only option I see is to pass a configuration file with a list of clients to create.\n\nIsn't this the same? The file can also be read. .bash_history is at least always chmod 700 or owner-/group-read only\n. In container environments secrets are usually set using environment variables. I believe that all PaaS (heroku, cloudfoundry, kubernetes...) don't log environment variables. Unless you think otherwise, I believe this is the right choice.\n. You're right, it's more obvious if it's a file then a side effect (storing it to .bash_history). Thanks for your thoughts :)\n. @janekolszak I have added this in https://github.com/ory-am/hydra/pull/90/commits/69a54e187d7a7b74aa4681bb0af32d7a1b9a3fb5:\n```\ngo run main.go clients import\nUsage:\n  hydra clients import  [...] [flags]\nFlags:\n  -h, --help   help for import\nGlobal Flags:\n      --config string     config file (default is $HOME/.hydra.yaml)\n      --skip-tls-verify   foolishly accept TLS certificates signed by unkown certificate authorities\n```\nplease let me know if that's what you wanted\n. The format is the one you send to the HTTP API as documented here\n. \n:). upstream https://github.com/square/go-jose/issues/95\n. Without support from go-jose, the library needs to be forked and the functionality added. the specification for x509 certificates is available at https://tools.ietf.org/html/rfc7517\nUntil that is implemented, the HTTPS TLS certificate is gob encoded and stored as a PSK in the JWK store. It should be documented that the JWK store does not support the x509 claims as of now.\nThis approach is okay because:\n- There is no security impact. PSKs are encrypted using AES-GCM as well\n- It is not trivial to add a new TLS certificate using the HTTP REST API. this could be documented somewhere. importing TLS certificates still works!\n- Precomputed values are removed to reduce likelyhood of possible attack vector\n- One draw back is that clients need to be able to decode gob streams. As the certificate will be used only internally in hydra, this is not an issue.\n. > There's not field for it in the struct right now, but it should be fairly simple to add. I can take a look at adding this next week maybe. Or if you want to take a shot at it, pull requests are welcome! \nhttps://github.com/square/go-jose/issues/95#issuecomment-223764077\n. upstream https://github.com/square/go-jose/issues/95\n. upstream #92 \n. resolved in https://github.com/ory-am/hydra/pull/90/commits/e18b44f3b5197cde58a2a729166395a25dc45a18 read https://github.com/ory-am/hydra/issues/92#issuecomment-223746347\n. Hi @faxal ! The example from gopheracademy is out of date. As part of the rewrite we decided to remove the proprietairy IDP (identity provider) from hydra and let people build their own. If you are interested in writing a generic hydra-friendly IDP let me know. There's a lot of example code out there that would help you :)\nHere's the current IDP example: https://github.com/ory-am/hydra-idp-react/\n. Feel free to reopen if you have further questions or   :)\n. Nice! Let me know if you want me to take a look at it. I have time tomorrow and during the week\n. Looks good! You probably already know, but you should add the \nauthentication (check session cookie or prompt for user credentials) here:\n- https://github.com/janekolszak/hydra-idp-go/blob/master/idp/main.go#L194\nOne more note - as I've seen that you load the hydra.yml file from \nvolume on start up. The hydra.yml file might not be available when hydra \nand hydra-idp-go docker containers are started simoultaneously. Hydra \nneeds a little time to generate the keys, connect to db and so on - you \nwill either need to watch the hydra.yml file for changes or delay the \nread-in.\nAh, nevermind, just saw that you already do that: \nhttps://github.com/janekolszak/hydra-idp-go/blob/master/idp/Dockerfile#L10\nWe need to think of a better way to solve this, e.g. by writing a shell \nscript that waits for the hydra port to open and can be added to Dockerfile\nEverything else looks good!\nAm 04.06.2016 um 20:26 schrieb Jan Olszak:\n\nSure, take a look. I'll implement some production code using this \nexample so all comments are welcomed.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub \nhttps://github.com/ory-am/hydra/issues/94#issuecomment-223770576, or \nmute the thread \nhttps://github.com/notifications/unsubscribe/ADN1esqyBMF9clAOLHS7znGp6-YX8x4Rks5qIcNJgaJpZM4IuD_o.\n. resolved by faf9583fedf2063bdb0aafe37de6c05469be051c\n. if an error occurs, the idp url should contain a uri query param called error (https://login.myapp.com/login?error=.... the error should be taken by the idp and displayed :)\n\nthis happens when, according to spec, hydra is not allowed to redirect back to the client callback when an error occurs.\nlet me know if the error param is not available and reopen this issue.\n. However, this should be documented\n. Right now RT are issued always. This is a security weakness. In the future the RT should only be issued when the scope 'offline' is set. This is how most OAuth2 providers do it, like Google and MS \nGesendet mit meinem HTC\n----- Reply message -----\nVon: \"Jan Olszak\" notifications@github.com\nAn: \"ory-am/hydra\" hydra@noreply.github.com\nCc: \"Aeneas\" aeneas@serlo.org, \"Author\" author@noreply.github.com\nBetreff: [ory-am/hydra] Add offline scope for refresh tokens (#97)\nDatum: Mi., Juni 8, 2016 01:07\nWhat's a refresh token with an offline scope?\n\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/ory-am/hydra/issues/97#issuecomment-224441218\n. I am not confident with PEM encoding and in particular the differences between PKCS#1 and PKCS#8 and how to detect which format we are dealing with. Additionally, support for encrypted PEM files should be added as well. Here's my current work in progress take at this:\n``` go\nfunc (h JWKHandler) ImportPEMKey(cmd cobra.Command, args []string) {\n    if len(args) != 3 {\n        fmt.Println(cmd.UsageString())\n        return\n    }\nvar key interface{}\nblock, _ := pem.Decode()\nswitch block.Type {\ncase \"EC PRIVATE KEY\":\n    key = x509.ParseECPrivateKey()\n    break;\ncase \"RSA PRIVATE KEY\":\n    key = x509.ParsePKCS1PrivateKey()\n    break;\ndefault:\n    x509.ParsePKCS8PrivateKey()\n    fmt.Printf(\"Unknown PEM block type: %s\", block.Type)\n    os.Exit(1)\n}\n\n\nerr := h.M.AddKey(args[0], &jose.JsonWebKey{\n    Key: key,\n    KeyID: args[1],\n})\npkg.Must(err, \"Could not store keys: %s\", err)\n\nfmt.Println(\"Key import succeeded.\")\n\n}\n``\n. No one has ever complained about this, I think it's ok to not implement it.. Actually: https://github.com/ory/hydra/issues/175#issuecomment-246252942. @janekolszak when does that happen? I know there's a bug where this happens when you run the tests but usually the CLI doesn't open the browser window, excepthydra token user?\n.curlisn't installed on Windows. The curl command will be printed when using-dry` :)\nThe idea of hydra token user is to initiate an exemplary OAuth2 request - I think opening the browser for that is ok, no? I can't really imagine where this command would be useful except for showing an exemplary flow.\n. ```\ngo run main.go keys create foo123 --dry --skip-tls-verify\nWarning: Skipping TLS Certificate Verification.\nCould not generate keys: Because you are using the dry option, the request will not be executed. You can execute this command using:\ncurl -X POST -d \"{\\\"alg\\\":\\\"\\\",\\\"keys\\\":null}\" -H \"Content-Type: application/json\" 'https://localhost:4444/keys/foo123\n``\n. thanks!\n. this was resolved as part of #130\n. Hey thanks for the report. I believe that this is caused by not enough wait time. I will investigate and let you know once I found the issue.\n. try replacing https://github.com/ory-am/hydra/blob/master/Dockerfile-dangerous#L10 withENTRYPOINT sleep 10; /go/bin/hydra host --dangerous-auto-logonand rerundocker-compose buildanddocker-compose up`\nwhich system are you on? windows? linux? mac?\n. i cannot reproduce the issue on my environment\n. Ok the problem is that you are not using the right dockerfile. Dockerfile does not have any delays, which is why docker-compose.yml uses Dockerfile-dangerous instead:\nhydra:\n    build:\n      context: .\n      dockerfile: Dockerfile-dangerous\nThis causes hydra to try and connect immediately to rethinkdb but rethinkdb hasn't started up yet properly (but is listening on the port). This causes the shard failure\n. On second thought, this should be handled better by hydra. Instead of dying there should be retry attempts.\n. Ok I just removed the wait time from Dockerfile-dangerous and introduced restart: unless-stopped in the hydra section of docker-compose.yml. Everything worked fine then.\nThe cipher: message authentication failed might have to do something with a missing or wrong system secret. Have you set the system secret using SYSTEM_SECRET=<some-supersecret-password>? For example:\nSYSTEM_SECRET=passwordtutorial DOCKER_IP=$(docker-machine ip default) docker-compose up\nIf you have troubles try running docker-compose rm -f and docker-compose up. Don't forget to set the environment variables as mentioned above\n. the message auth failed error is now tracked as #104\n. Perfect, glad I could help! The system secret is not stored by hydra, it is up to the environment to provide it :) this reduces risks on database breaches and similar issues.\n. your suggestion with restart until-stopped is now a PR #105\n. Did you user rethinkdb? Sounds like no database was used\n. Could you list the commands you entered 1-by-1 plus the logs? I cannot reproduce this.\n. Here's what I did:\n```\ntty1$> cd $GOPATH/src/github.com/ory-am/hydra\ntty1$> DOCKER_IP=$(docker-machine ip default) docker-compose build\ntty1$> SYSTEM_SECRET=passwordtutorial DOCKER_IP=$(docker-machine ip default) docker-compose up\ntty2$> hydra token client --skip-tls-verify\ntty1$>ctrl+c\ntty1$> SYSTEM_SECRET=passwordtutorial DOCKER_IP=$(docker-machine ip default) docker-compose up\ntty2$> hydra token client --skip-tls-verify\n```\n. You are using two different SYSTEM_SECRETS:\n$ SYSTEM_SECRET=passwordtutorial DOCKER_IP=localhost docker-compose up --build\n$ SYSTEM_SECRET=\")s0ZeNIoAzgPG_gdTHlLivRo4skO&fW.\" DOCKER_IP=localhost docker-compose up\n. Can you try running:\ndocker-compose rm -f\nSYSTEM_SECRET=passwordtutorial DOCKER_IP=localhost docker-compose up -d --build\nhydra connect (you will need `docker logs` to get the temporary client credentials)\nhydra token client --skip-tls-verify\ndocker-compose kill\nSYSTEM_SECRET=passwordtutorial DOCKER_IP=localhost docker-compose up -d\nhydra token client --skip-tls-verify\n. Hm, is there maybe a docker cleanup job on reboot? Can you connect to the rethinkdb instance and check if the data is still there once you rebooted?\n. What does cat ~/.hydra.yml say?\n. what happens if you do\n``\ndocker-compose rm -f\nSYSTEM_SECRET=passwordtutorial DOCKER_IP=localhost docker-compose up -d --build\nhydra connect (you will needdocker logs` to get the temporary client credentials)\nhydra token client --skip-tls-verify\nREBOOT\nSYSTEM_SECRET=passwordtutorial DOCKER_IP=localhost docker-compose up -d\nhydra connect (the credentials from before)\nhydra token client --skip-tls-verify\n```\n. Could it be possible that another instance of hydra is running on that port when booting? This is so akward, no idea why it happens.\n. Quite possible. Glad it worked out :)\n. Yes, that is called the \"implicit flow\": https://www.digitalocean.com/community/tutorials/an-introduction-to-oauth-2 (ctrl+f -> \"Grant Type: Implicit\")\n. Welcome\n. Today a change in go-jwt was merged. Unfortunately it looks like glide does not work recursively on dependencies. Fosite has a glide.lock file but it doesn't look like running glide install in hydra is doing anything. The issue is tracked in https://github.com/ory-am/fosite/issues/51\n. hm that's weird, the glide.lock file has the right jwt-go commit hash linked: https://github.com/ory-am/hydra/blob/master/glide.lock#L15\n. I just ran\ngo get  github.com/ory-am/hydra\ncd $GOPATH/github.com/ory-am/hydra\nglide install\ngo run main.go\nand did not encounter any issues. Are you sure there isn't anything missing or something else going wrong?\n. Oh I see so the issue is that go get also builds the binary. Can you try go get -d github.com/ory-am/hydra instead?\n. closed by #110\n. Whoops, thanks! I will run some tests (because travis doesn't??) and merge when everything works :)\n. Yes, please use the JWK Store for storing the RootCA. Setting custom RootCAs is also quite dangerous and we should anticipate problems there. Using the JWK Store only trusted clients could update those CAs, so that's a first good step.\n. And I want to keep the number of configuration and env options low :)\n. If you need help with the JWK store let me know\n. Haha wow, I didn't think that one through. Spot on.\n. Ok let's make it work then like the HTTP TLS certificates (CLI option and env var)\n. that's actually better because compromise of a priviledged client would not allow for the rootca to be changed or read\n. Cool, let me know when you made it and I'll add you to the list :)\n. It doesn't really look like this issue get's a lot of attention. I am therefore closing it.\n. Hey this looks already pretty good :) Please remember to sign your commit - read how\n. perfect, thank you!\n. One issue is that ExpiresAt: oauthRequest.GetRequestedAt(), is missing\n. closed by https://github.com/ory-am/hydra/commit/24d34b312ee95f82def54d9f6a48e1cf3f5e3902\n. How about moving the package to ory-am/hydra/sdk? \n. Could you please add unit tests and sign the DCO using git commit -s\n. Oh and a note in the docs would be great! Maybe in the FAQ section? :)\n. make sure to update your local dependencies or use glide, fosite got updated last night\n. You don't need to test the embedded structs (e.g. ClientManager), those are already well tested. It is enough to test new methods such as FromYAML(), ClientID(), ... \n. no that's fine, you don't need to sign every commit. I will squash them anyways :) thanks for your hard work!\n. thanks!\n. No, thank you for your contribution :+1:  :)\n. thanks! please sign the DOC. You can do so with git commit --amend -s\n. thanks!\n. Hydra currently doesn't support 2FA but if it where it would work in a distributed environment, as long as they are backed by the same rethinkdb instance. If you have the ability to check an HTTP api for the 2fa steps, this should work.\n. No, hydra does not provide Identity Provider capabilities. The real time monitoring is the rethinkdb admin ui, which supports real time monitoring. I suggest to read the guide and http api documentation.\n. 2FA support is tracked as #69\n. Hey yes, that should be clarified in the docs. The empty path always defaults to /.\n. this is now documented in the faq section in the readme.\n. resolved by #152\n. Good point, that really depends on the environment. In a docker environment, there should be close to zero collisions, because you set env vars per container. Some of the env vars like PORT and HOST are actually best practice because they make hydra run on heroku/cloud foundry/flynn/dokku/... out of the box.\nHowever, stuff like tls paths could be scoped - did name collision happen in your environment?\n. You can also set env vars with ENV=foo hydra - so i think we should be good :)\n. Yeah that actually doesn't make sense - I overlooked that in review. I think you can remove all paths in the SDK and just do\ngo\n        Endpoint: c.clusterURL,\n. could you just replace all Endpoint: pkg... with Endpoint: c.clusterURL,, test if everything works ok and push this PR? I would merge it then :)\n. Ah yes you're right! Thanks for chipping in!\n. right, we need to add a simple policy check as well!\n. This issue is now superseded by #162\n. what rights should the imported clients have?\n. by default, clients aren't allowed to read/write json web keys, create new clients, ...\n. we should figure out some better semantics - --idp doesn't really imply that it's an administrative account. i also don't really like the idea of the file being looked up on every host boot. wouldn't it be enough to specify the id and secret on first boot?\n. something like:\nFORCE_CLIENT_CREDENTIALS=base64(foo:bar) hydra host\n. Ok just to check - so this would be fine for you?\nFORCE_CLIENT_CREDENTIALS=base64(foo:bar) hydra host\n. > What's the base64 function? You mean base64 of id:secret? \nYes, base64 of id:secret. Thought it might help with binary passwords.\n\nhydra host are the scopes?\n\nNo, that's the hydra host command! In Unix you can set environment variables per process with KEY=VALUE <command>\n. > I don't think accepting binary passwords is worth the extra function invocation.\n\nPeople will get confused (yet another step, just to pass the temporary, most probably developer credentials)\n\nYou're right - let's keep it simple :)\n. whoops, that's a typo here: https://github.com/ory-am/hydra/blob/master/cmd/server/handler_connection_factory.go#L26\n. no, just me not paying attention :D\n. I have not looked through the specification yet, but it might well be possible that openid session management is targeted at RP and IDP instead of the AP. I will have to dig through the documentation.\nIf you find good material on this topic, please let me know.\n. This specification is using iframes and stuff, I'm not confident that it's a good way forward. What do you think @janekolszak ?\n. closing due to missing response and questionable draft\n. Thanks!\n. thanks :)\n. This is now an upstream issue: https://github.com/dancannon/gorethink/issues/344\n. Thanks!\n. Nice catch, this could also be an issue in all implementations of the following interfaces:\n- https://github.com/ory-am/hydra/blob/9b516002d04c3fd84ec9fac214f937f891d53829/client/manager.go#L20\n- https://github.com/ory-am/hydra/blob/9b516002d04c3fd84ec9fac214f937f891d53829/connection/manager.go#L14\n- https://github.com/ory-am/ladon/blob/master/manager.go#L16 (because Policies is a slice of Policy which is in turn an interface)\n. I think ladon is safe from this issue (both memory manager and rethinkdb manager) as they aren't taking an address of a variable in a loop. Would still be good to check that with tests though. I'll look into it.\n. Switching to (clients map[string]Client, err error) is a good idea IMHO. I will do the same in the connection managers\n. solved by #151\n. Could you please add a test case as discussed on gitter? It would be awesome to automate the check :)\n. nvm, I'll create one myself. Thanks for this!\n. already on it\n. see #152\n. What's the benefit of having a method for this? GetHashedSecret, GetGrantedScopes, ... are being used to satisfy fosite.Client\n. Ah wow, I overread the \"Would like to add this to fosite in a sec too.\" part - haha :D\n. Still, there's no reason to bloat the fosite.Client interface - it should only have methods that are useful to the fosite library.\n. Why not simply do m.GetClient('123').(*client.Client) - then you have access to all member vars?\n. No, because GetClient(id string) (*Client, error) does not implement fosite.Storage :)\n. However, I see how this is an issue for the HTTPManager\n. resolved by faf9583fedf2063bdb0aafe37de6c05469be051c\n. Strict mode basically does the same thing. Unless this is being requested by someone, it's not a must.\n. superseded by #162\n. supserseded by #162\n. Actually no, the spec is pretty clear on this:\n\n4.1.3.  Access Token Request\n   The client makes a request to the token endpoint by sending the\n   following parameters using the \"application/x-www-form-urlencoded\"\n   format per Appendix B with a character encoding of UTF-8 in the HTTP\n   request entity-body:\n. upstream fosite\n. Reopening to do some proper stress testing on GCE. I did another benchmark with hydra deployed on GCE. Note that all requests used http, not https. The deployment was a single VM configured as followed (:= 80$/month):\n\n\nPlease note that I did not add any additional policies to the store. Also, there is an effort in ladon to greatly improve the regexp-caused CPU complexity. It is possible that future implementation will perform a lot better on warden endpoints.\nIn-memory\nThe in-memory implementation was tested.\nIntrospection: 500 concurrent connections\n```\n\ngobench -u \"http://xxx/oauth2/introspect\" -c 500 -t 100 -auth \"bearer y58ML1Ef0v5kT_ceVTVcaFRBeogiNzGU93tnvExqMCY.6aAJOtsH381Q6qdVoIEqy7voQvhDQ9476MMThhYpvnU\" -d \"D:\\introspect.txt\"\n\nDispatching 500 clients\nWaiting for results...\nRequests:                           837084 hits\nSuccessful requests:                837029 hits\nNetwork failed:                         55 hits\nBad requests failed (!2xx):              0 hits\nSuccessful requests rate:             2847 hits/sec\nRead throughput:                    683301 bytes/sec\nWrite throughput:                  1073268 bytes/sec\nTest time:                             294 sec\n```\nAnd CPU maxing at about 20%\n\nClient Credentials: 100 concurrent connections\nGetting client credentials is a very CPU expensive task, as we need to use bcrypt in order to receive tokens.\n```\n\ngobench -u \"http://xxx/oauth2/token?scope=hydra&grant_type=client_credentials\" -c 100 -t 100 -auth \"Basic b2NwYWRtOlFNeF9WVlF5TElRQ2E5X2t5VzRJbWExc3Aza0s5N2M4\" -d \"D:\\clientcredentials.txt\n\nDispatching 100 clients\nWaiting for results...\nRequests:                            15282 hits\nSuccessful requests:                 15282 hits\nNetwork failed:                          0 hits\nBad requests failed (!2xx):              0 hits\nSuccessful requests rate:               63 hits/sec\nRead throughput:                     20972 bytes/sec\nWrite throughput:                    20916 bytes/sec\nTest time:                             239 sec\n```\nCPU is drained 100%:\n\n\nWarden (with token): 500 concurrent connections\n```\ngobench -u \"http://xxx/warden/allowed\" -c 500 -t 100 -auth \"bearer y58ML1Ef0v5kT_ceVTVcaFRBeogiNzGU93tnvExqMCY.6aAJOtsH381Q6qdVoIEqy7voQvhDQ9476MMThhYpvnU\" -d \"d:\\warden-allowed.txt\"\nDispatching 500 clients\nWaiting for results...\nRequests:                           493216 hits\nSuccessful requests:                493177 hits\nNetwork failed:                         39 hits\nBad requests failed (!2xx):              0 hits\nSuccessful requests rate:             2394 hits/sec\nRead throughput:                    299264 bytes/sec\nWrite throughput:                  1109623 bytes/sec\nTest time:                             206 sec\n```\nCPU drain is similar to introspection (about 20%)\n\nMemory snapshots\nMemory usage was sampled a couple of times, nothing exceeded:\nMemTotal:        9231748 kB\nMemFree:         6543296 kB\nMemAvailable:    8719684 kB\nPostgreSQL\nPlease note that the PostgreSQL database was running on the same VM as hydra. PostgreSQL configuration was not modified in any way.\n500 concurrent connections returned error messages, probably because postgres was used with a limit. This is why we used 100 connections instead.\nThe CPU drain increased due to postgres:\n\nIntrospection: 100 concurrent connections\n```\n\ngobench -u \"http://xxx/oauth2/introspect\" -c 100 -t 10 -auth \"bearer YzVVG0H3dDLnWHIxJTElUJLKneWhMhipCQE9wtgo0Co.1QBl4SokzHuUcEbfH0dJpsGY1Np45YsbrrWHVYUIE40\" -d \"D:\\introspect.txt\"\n\nDispatching 100 clients\nWaiting for results...\nRequests:                            59237 hits\nSuccessful requests:                 59237 hits\nNetwork failed:                          0 hits\nBad requests failed (!2xx):              0 hits\nSuccessful requests rate:              688 hits/sec\nRead throughput:                    165312 bytes/sec\nWrite throughput:                   259426 bytes/sec\nTest time:                              86 sec\n```\nClient Credentials: 100 concurrent connections\n```\n\ngobench -u \"http://xxxx/oauth2/token?scope=hydra&grant_type=client_credentials\" -c 100 -t 100 -auth \"Basic b2NwYWRtOlFNeF9WVlF5TElRQ2E5X2t5VzRJbWExc3Aza0s5N2M4\" -d \"D:\\clientcredentials.txt\nDispatching 100 clients\nWaiting for results...\n\nRequests:                             1466 hits\nSuccessful requests:                  1466 hits\nNetwork failed:                          0 hits\nBad requests failed (!2xx):              0 hits\nSuccessful requests rate:               61 hits/sec\nRead throughput:                     20035 bytes/sec\nWrite throughput:                    21206 bytes/sec\nTest time:                              24 sec\n```\nWarden (with token): 100 concurrent connections\n```\n\ngobench -u \"http://xxx/warden/allowed\" -c 100 -t 100 -auth \"bearer YzVVG0H3dDLnWHIxJTElUJLKneWhMhipCQE9wtgo0Co.1QBl4SokzHuUcEbfH0dJpsGY1Np45YsbrrWHVYUIE40\" -d \"d:\\warden-allowed.txt\"\n\nDispatching 100 clients\nWaiting for results...\nRequests:                            71513 hits\nSuccessful requests:                 71513 hits\nNetwork failed:                          0 hits\nBad requests failed (!2xx):              0 hits\nSuccessful requests rate:              461 hits/sec\nRead throughput:                     57674 bytes/sec\nWrite throughput:                   213467 bytes/sec\nTest time:                             155 sec\n```\nMemory snapshots\nMemory usage was sampled a couple of times:\n```\nMemTotal:        9231748 kB\nMemFree:         7158072 kB\nMemAvailable:    8716964 kB\nMemTotal:        9231748 kB\nMemFree:         7244592 kB\nMemAvailable:    8729828 kB\n```. For local testing:\n```\nhey -c 500 -n 50000 -m POST -H 'authorization: Basic YWRtaW46ZGVtby1wYXNzd29yZA=='   -H 'cache-control: no-cach\ne'   -H 'content-type: application/x-www-form-urlencoded' -d grant_type=client_credentials http://localhost:4444/oauth2\n/token?grant_type=client_credentials\nexport T1=$(hydra token client)\nexport T2=$(hydra token client)\nhey -c 500 -n 50000 -m POST -H \"Authorization: Bearer $T1\"   -H 'cache-control: no-cach\ne'   -H 'content-type: application/x-www-form-urlencoded' -d token=$T2 http://localhost:4444/oauth2/introspect\n``. This is resolved. @matteosuppo @boyvinall @ericdouglas @janekolszak do you think the endpoints/warden/authorizedand/warden/allowedare semantically easy to understand?\n-/warden/authorized: Check if a token + scope is ok\n-/warden/allowed`: Check if token + scope + action + resource is ok\nAdditionally those two functionalities should be added:\n- strict mode: Only return a 200 result if audience of introspection token and audience of requester token match\n- anonymous mode: Expose an endpoint which does not require an introspection token, but a subject.\nDo you think those should be merged to one endpoint? Or do you have naming ideas?\n. Additionally, I want to implement a strict mode which will only return the data if the introspection token audience (from post body) and the authorization token (from header) match to prevent token substitution attacks.\n. On top of that one API should be able to check for anonymous users on the warden endpoint. This would also need either a dedicated endpoint or maybe some query parameter?\n. Here's my proposal. In total we have these capabilities:\nWarden: Endpoints for resource providers (usually private)\n1. /warden/token/valid: Check if a token + scope is valid, returns context data (subject, scopes, ...) if valid\n2. /warden/token/allowed: Check if a token + scope is valid and the token's subject is allowed to do something, returns context data (subject, scopes, ...) if valid\n3. /warden/allowed Check if a subject (e.g. anonymous user, service) is allowed to do something\nOAuth2 endpoints (usually public)\n4. oauth2/introspect Check if a token + scope is valid, using strict mode (implementation of rfc7662)\nWhat do you think?\n. Great! Let me know on Gitter when you have time. :)\n. I think the naming makes sense and I'll implement it in the next days\n. I think this makes much more sense: \n``` go\ntype Firewall interface {\n    // InspectToken checks if the given token is valid and if the requested scopes are satisfied. Returns\n    // a context if the token is valid and an error if not.\n    InspectToken(ctx context.Context, token string, scopes ...string) (*Context, error)\n// InspectTokenFromHTTP uses the HTTP request to decide weather a token is valid or not. If not, an error\n// is returned.\nInspectTokenFromHTTP(ctx context.Context, r *http.Request, scopes ...string) (*Context, error)\n\n// IsAllowed uses policies to return nil if the access request can be fulfilled or an error if not.\nIsAllowed(ctx context.Context, accessRequest *ladon.Request) error\n\n}\n```\n. No, it's just the client SDK\n. I should have said \"instead of the current client sdk\" -sorry for that :)\n. there will be some more changes. it would be awesome if you could review this\n. Right, thanks!\n. superseded by #192 \n. 0.2.0 will be delayed because there are things to be solved in fosite first\n. resolved by https://github.com/ory-am/hydra/pull/165/commits/a62a2f3599c58b11dd36ff8589a48955736271d8\n. proxying works fine\n. I believe that HMAC-SHA256 (used in fosite) is, although slower, favorable to HMAC-SHA1\n. It's actually the blowfish hashing algorithm that is being used to validate the client credentials:\nDropped 39 nodes (cum <= 1.02s)\nShowing top 10 nodes out of 34 (cum >= 2.94s)\n      flat  flat%   sum%        cum   cum%\n   191.12s 93.34% 93.34%    191.12s 93.34%  github.com/ory-am/hydra/vendor/golang.org/x/crypto/blowfish.encryptBlock\n    10.30s  5.03% 98.37%    201.39s 98.36%  github.com/ory-am/hydra/vendor/golang.org/x/crypto/blowfish.ExpandKey\n     2.12s  1.04% 99.41%      2.12s  1.04%  math/big.addMulVVW\n     0.48s  0.23% 99.64%      2.93s  1.43%  math/big.nat.montgomery\n     0.11s 0.054% 99.70%    201.53s 98.43%  github.com/ory-am/hydra/vendor/golang.org/x/crypto/bcrypt.expensiveBlowfishSetup\n         0     0% 99.70%      2.93s  1.43%  crypto/rand.Prime\n         0     0% 99.70%      2.93s  1.43%  crypto/rsa.GenerateKey\n         0     0% 99.70%      2.93s  1.43%  crypto/rsa.GenerateMultiPrimeKey\n         0     0% 99.70%      2.94s  1.44%  github.com/ory-am/hydra/cmd.Execute\n         0     0% 99.70%      2.94s  1.44%  github.com/ory-am/hydra/cmd.runHostCmd\n. Workfactor of 10 get's us to ~100 hits / s - maybe make this configurable?\n. workfactor is now refactored so that (theoratically) configuring it is possible. However, this is sort of an upstream issue of viper #212\n. > workfactor is now refactored so that (theoratically) configuring it is possible. However, this is sort of an upstream issue of viper #212\nthis is now resolved\n. dupe of #83\n. Another way could be to add something like GetRawClient (better naming wanted) to the HTTPManager.\n. @boyvinall @skymeyer please check if this works for you and let me know if you have suggestions for improvement: https://github.com/ory-am/hydra/pull/165/commits/01e6ae2dd346e5032f38a79e0e009de4c4007fc5\n. perfect\n. The request needs to be of content type application/x-www-form-urlencoded. Should be something like curl --header \"Content-Type: application/x-www-form-urlencoded\"\n. A right sorry, I missed that you are setting client id and client secret as post parameters. This is not supported, please use basic authorization Authorization: Basic base64(id:secret) instead\n. This is per spec. The rationale is usually that authorization headers are truncated from logs, while post bodies might not.\n. Yup that's part of why I wrote hydra. A lot of people are not following the spec 100%, which in turn needs hacks like https://github.com/golang/oauth2/blob/master/internal/token.go#L92-L147 in oauth2 libraries!\n. Thanks for the insight, weird that there is no jwk in the ruby world.\nGesendet mit meinem HTC\n----- Reply message -----\nVon: \"Wayne Robinson\" notifications@github.com\nAn: \"ory-am/hydra\" hydra@noreply.github.com\nCc: \"Aeneas\" aeneas@serlo.org, \"Assign\" assign@noreply.github.com\nBetreff: [ory-am/hydra] The JWK api should be able to export .pem (#175)\nDatum: Mo., Sep. 12, 2016 08:27\nYeah, the Ruby world lacks tools to work with JWK. I had never even heard of the format until Hydra.\nLiterally the only library we were able to find is https://github.com/potatosalad/ruby-jose and it lacks users (it's only been downloaded about 5,200 times\u2026 nothing given how often gems end up being downloaded in the lifecycle of even a single product).\nThis has been fine for our purposes, which are basically to convert the JWKs into PEMs for use in OpenSSL and other libraries. It would be good if we could just get an efficient (hopefully cached) version of the PEM from Hydra itself as required. Especially if we assume we should always get the keys from Hydra for a future where key rotating or revocation may happen. \n\nYou are receiving this because you were assigned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/ory-am/hydra/issues/175#issuecomment-246252942\n. There hasn't been any other request for this since Sep 2016. Also we're now able to import pem formatted keys. For validation of access tokens, all OpenID certified libraries support the ./well-known/jwks.json pattern (part of the certification requirement). Closing.. right now you can force hydra to disable https using --force-dangerous-http\n. HTTP headers shouldn't really be trusted unless those security sensitive parameters can't be spoofed. we could add something like trust-http-headers or edge-tls-termination but\n- you can already disable https with --force-dangerous-http\n- X-Forwarded-Protocol is not a standard header and might vary from proxy to proxy. AWS for example uses X-Forwarded-Proto\n. > an edge-tls-termination flag is different from force-dangerous-http, because hydra would still generate only https-links.\nThis is a very good point and I classified it as a bug.\n\n(BTW: Of course, all X- headers are non-standard. Unfortunately the standard PROXY header support is not widespread yet).\n\nHow could we solve this issue then? My best bet right now is a flag like --enable-edge-tls-termination that disables TLS but returns https links. What would you suggest?\n. I believe that right now the only piece of code that would be affected by this issue is the consent challenge\n. Logging HTTP requests is usually the task of the proxy/gateway/loadbalancer. However, it should be fairly easy to add a middleware (e.g. negroni) for it. If you think this is a neccessity, please open another issue for it.\nI think it's smart to let hydra detect if the original request was HTTPS or not. I checked out RFC7239 and some resources online, it looks like X-Forwarded-Proto is a de-facto standard. So why not use it!\nAdditionally, I like the idea to whitelist tls termination origins: --edge-tls-termination-from=[127.0.0.0/16, ...]\n. @ibotty what do you think of the following:\ngo\nhostCmd.Flags().StringSlice(\"allow-tls-termination-from\", []string{}, \"Whitelist one or multiple CIDR address ranges and allow them to terminate TLS connections. Be aware that the `X-Forwarded-Proto` header must be set and must never be modifiable by anyone but your proxy / gateway / load balancer.\")\ndo you have an idea how to describe this better in fewer words?\n. Instead, this is an env var! Makes more sense for production environments IMHO\n. - HTTPS_ALLOW_TERMINATION_FROM: Whitelist one or multiple CIDR address ranges and allow them to terminate TLS connections.\n    Be aware that the X-Forwarded-Proto header must be set and must never be modifiable by anyone but\n    your proxy / gateway / load balancer.\n    Example: HTTPS_ALLOW_TERMINATION_FROM=[\"127.0.0.1/16\",\"192.168.178.0/16\"]\n. https://github.com/ory-am/hydra/pull/165/commits/53b2f830436f8c1b2fcd43e1dec4abdc8de17b36\n. > hope it is parsed as a comma-separated list, without the brackets. If so, the example should read\ndone\n\nbtw: what about ipv6?\n\nwill be included. do you know if there's something i need to take care of when using ipv6 & go?\n. No, the implicit flow is the only one where you can use custom uri schemes. Using this with the authorization code will leak the token to anyone who is listening. Seriously anyone, including me. ;)\n. upstream https://github.com/ory-am/fosite/issues/60\n. this is justified by https://tools.ietf.org/html/rfc6819#section-4.4.2\n. Most of the command handlers are already being tested, this is now fixed in the code coverage report as well. Closing.. additionally, all consent response claims should be stored in the access token\n. This will probably require modification of the oauth2 session object\ngo\n    return &Session{\n        Subject: subject,\n        DefaultSession: &strategy.DefaultSession{\n            Claims: &ejwt.IDTokenClaims{\n                Audience:  a.GetClient().GetID(),\n                Subject:   subject,\n                Issuer:    s.Issuer,\n                IssuedAt:  time.Now(),\n                ExpiresAt: time.Now().Add(s.DefaultIDTokenLifespan),\n                Extra:     t.Claims, // here probably t.Claims[\"id_token\"]\n            },\n            Headers: &ejwt.Headers{},\n            // here something like Extra: t.Claims[\"extra\"]\n        },\n    }, err\n. I could not reproduce this issue, it was probably one of those IntelliJ cmd.exe didn't flush errors. Here is what's happening if rethinkdb is not available:\n?[0m?[31mhydra_1      |?[0m time=\"2016-09-22T21:20:34Z\" level=info msg=\"DATABASE_URL set, connecting to RethinkDB.\"\n?[31mhydra_1      |?[0m time=\"2016-09-22T21:20:34Z\" level=info msg=\"Connecting with RethinkDB: @database:28015/hydra\"\n?[31mhydra_1      |?[0m time=\"2016-09-22T21:20:34Z\" level=info msg=\"Connected to RethinkDB!\"\n?[31mhydra_1      |?[0m time=\"2016-09-22T21:20:34Z\" level=fatal msg=\"Could not fetch initial state: gorethink: Cannot perform read: primary replica for shard [\\\"\\\", +inf) not available in: \\nr.Table(\\\"hydra_policies\\\")\"\n. This is solved on master. One way would be to:\n1. pull the latest image from dokerhub\n2. run it and connect it to rethinkdb\n3. run a few commands (every api at least once)\n4. kill the hydra image\n5. compile image from source\n6. run it against same rethinkdb\n7. run commands and see if they fail\n. I tested https://github.com/ory-am/hydra/issues/193#issuecomment-241699960 on the 0.5.0 release and it worked quite well.\n. I don't think this is relevant any more as we have the migrate command.. a list of sql migration tools:\n- https://github.com/DavidHuie/gomigrate\n- https://github.com/rubenv/sql-migrate\n- https://github.com/mattes/migrate\n. awesome, thanks!. see https://github.com/ory-am/hydra/pull/329/commits/070520d3d862e39ce1a199be7f50f95380ad7e1e. this is now resolved\n. nice! I'm trying to figure out how to do docs with hydra. I think gitbook was the wrong decision to go with because you, for example, can't create a PR there. maybe create a doc directory? What do you think?\n. hey @boyvinall the docs are now merged directly into github. if you want, you can add an FAQ entry for this.\n. This looks like a bug, not sure why tests aren't catching that. I'll dig into it.\n. still not sure why tests didn't catch it but it should work now\n. ah, the code was actually written in a way that it didn't throw an error...copy and paste errors, as usual\n. Could it be linked to a broken system clock?\n\ns.AccessTokenExpiry ====>  0001-01-01 00:00:00 +0000 UTC\n\nThis is ok because hydra is always using the default value so this is supposed to be \"nil\".\nWhats the iat value?\n. > for log.Println(r.GetRequestedAt(), h.AccessTokenLifespan)\n\nHow can I inspect the iat value?\n\nThat's the iat (issued at) value :)\nIs this maybe a token that got refreshed or is it a fresh one?\nAlso, what does running date in the shell of the server where hydra is running give you?\n. Ok, does the behaviour occur only with implicit tokens?\n. when you receive the implicit access token in the callback, what is the value of expires_in?\n. yes, that's a possibility! i will check that asap\n. hm the nonce is only for the openid connect session, it shouldn't have an impact on the access token. does it work when you use another nonce?\n. @matteosuppo can we take this to the gitter chat channel?\n. @matteosuppo any chance you found the root cause of this issue? the problem is that it's almost impossible to write tests for the implicit flow using golang, as hashbangs are not sent to the server. to get tests working, there would need to be some sort of javascript that posts a form or similar jazz...\n. supserseded by #207\n. this is no longer true\n. damn, this issue again (sometimes go can be a ***). thanks for digging, I'll fix it asap.\n. Yes, very nice, it seems to be working with Conditional Releases.\n. this tutorial?\n. i can reproduce this, thanks for reporting\n. https://github.com/ory-am/hydra-idp-react/commit/b290b1415538e64be999756cb4f8745c3bd220b7 should fix this, might take a minute or two until docker images are published etc etc.\n. https://hub.docker.com/r/oryam/hydra-idp-react/builds/bxo7r3as6hys6np4k3rvbuf/\n. it should work now, please do this:\n```\nkill compose process if still running\n$ docker pull oryam/hydra-idp-react # make sure the image actually updates, it should read something like \"Status: Downloaded newer image for oryam/hydra-idp-react:latest\"\n$ docker-compose up\n... re-run the tutorial\n```\n. when running the CLI from within the docker image, it looks like the callback isn't functioning because docker isn't exposing the 4445 port. if it doesn't work that way, you should try running the cli outside of docker. if you can't compile go on your system, let me know and I'll publish the binary packages\n. however, after success you should see something like this in your browser bar:\nhttp://localhost:4445/callback?code=HjLPph77FuC9If0iFwpsRjoYJdWSEcMG2K8YL-AaMD4.QrScM1twQP_MJj3FrNacsq8AzacQGPe5Ty3yHWspXsA&scope=hydra+offline+openid&state=cwjuzlwgufsweegpfquvvrbu\n. ok, feel free to reopen if issues persist\n. no need to purge, this is enough: https://github.com/ory-am/hydra/issues/211#issuecomment-240687074\n. @silverjam did you manage to get it working? if not, join the gitter channel and i'll try to help you the best i can.\n. @silverjam i pushed a change that will expose the 4445 port in the docker image and let you do the flow with hydra running inside of docker as you wanted it to. It will be released as 0.4.1\n212\n. oh wow, that has never happend to me. the image should be fine, you can verify it with:\n```\n$ docker images oryam/hydra-idp-react\nREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\noryam/hydra-idp-react   latest              10a2253a9c57        7 hours ago         817.7 MB\noryam/hydra-idp-react                 c02f16b85e55        11 weeks ago        825 MB\n``\n. thank you\n. Here is an exemplary request flow for this grant type:\n- OAuth2 client requests/oauth2/token?grant_type=resource_owner_password_credentials(ropc)\n- Hydra redirects client tohttp://consent.app/consent?challenge=....containing a key indicating that this is a a ropc grant and username/password\n- Consent app validates username/password and generates consent response, redirect back to/oauth2/token?grant_type=resource_owner_password_credentials&consent=...`\n- Hydra creates access token / refresh token\n. I'm mostly struggling with a decision on the way this flow works as it will probably be how it's going to look like in the final release. This is simply not straight forward (from a security perspective too) so it needs some very good thinking and reasoning. This is why this issue is not resolved yet.. The reasoning behind it was that usually any http client also supports following redirects. The trade off is if we either want people to implement another (REST) API for authentication, or if we want them to adapt their consent flows, or if we actually don't want this flow at all as it's intended for legacy code bases only anyways.. Closing, see https://github.com/ory/hydra/pull/297#issuecomment-294282671. no longer on the roadmap. Yup, it would be great if there where some libraries for that. I have to check if anything exists in the go ecosystem that solves this easily.\n\nAm 12.09.2016 um 07:23 schrieb Wayne Robinson notifications@github.com:\nWould be especially useful to control delivery by load-balancers like https://aws.amazon.com/elasticloadbalancing/applicationloadbalancer/ https://aws.amazon.com/elasticloadbalancing/applicationloadbalancer/ as well as providing some extra levers for doing things like clearing caches, etc.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/ory-am/hydra/issues/216#issuecomment-246252582, or mute the thread https://github.com/notifications/unsubscribe-auth/ADN1elmHqJpaQlFX4rscrRL-fxTzJydeks5qpOHMgaJpZM4JobTZ.\n. a very simple check (returns 204 on success) will be available at http://hydra/health with #293\n. this has been resolved\n. This is a good point. The issue I have right now is that we don't have an installer and we can only version the binary, not the code (without hassle). Do you have any recommendations for distributing or even automating the build process / installer?\n. This issue is related to #210\n. thank you, this is now updated\n. @amerdidit I can't reproduce that. It's not private here. Probably because you went to hydra.apiary.io isntead of docs.hdyra.apiary.io\n. @janekolszak did you provide a secret for the clients in the JSON file?\n. It will set a client secret of your choosing but won't display generated ones.\n. Resolving this issue is adding the client secret to be printed here: https://github.com/ory-am/hydra/blob/master/cmd/cli/handler_client.go#L49\n. Thank you for pointing me at the apiary docs. The client secret should now be documented properly :)\n. What you're showing in https://github.com/ory-am/hydra/issues/222#issuecomment-241192838 is not the id token, it's the consent token issued by your idp. I'm a bit confused :|\n\nThis is what an ID token looks like, if I request it using the demo:\n{\n  \"alg\": \"RS256\",\n  \"typ\": \"JWT\"\n}\n{\n  \"aud\": \"d7f2ee09-8d28-4be2-bb89-ce3a5e7c3217\",\n  \"auth_time\": 1471691398,\n  \"exp\": 1471694997,\n  \"iat\": 1471691398,\n  \"iss\": \"hydra.localhost\",\n  \"nonce\": \"wqwdpdahrbeotxwzqaldhyow\",\n  \"sub\": \"john.doe@me.com\"\n}\nAccording to spec, the kid claim is not mandatory in the id token so it can't be missing, please check: http://openid.net/specs/openid-connect-core-1_0.html#IDToken\n. You should be able to request an ID token with an request like this:\nhttps://localhost:4444/oauth2/auth\n?client_id=d7f2ee09-8d28-4be2-bb89-ce3a5e7c3217\n&redirect_uri=http%3A%2F%2Flocalhost%3A4445%2Fcallback\n&response_type=code <- alternatively, `token+id_token`\n&scope=hydra+offline+openid <- openid is required, make sure it is included in your consent token\n&state=uksnidtqqzrrvfgqaqciaxac\n&nonce=rzowrioghmymcrhfapakgfaa\nWhen using hydra token user, the id token will be shown in the console only, not the browser.\n. The ID Token issued by the OpenID Connect Playground doesn't include a kid either.\n. According to http://openid.net/specs/openid-connect-core-1_0.html#Signing a kid may be included if multiple JSON Web Keys are in the JWK Set which was used to sign the key. This is usually required when key rotation is used to identify which key was responsible for signing and reduce computational overhead.\nFrom my point of view, it would be ok to include the kid hint in the header field, even if it's not mandatory. What do you think?\n. One issue I have with this, is that it's not possible to identify the JSON Web Key Set, as it doesn't have an ID in the spec. In Hydra however, it is much more important what the set id is than what the key id is, as the API is called with, e.g. https://hydra/jwks/hydra.openid.connect. The set only contains kid public and private.\nThis in turn would mean, that the kid value in the id token header would always simply be private. Including the complete path (hydra.openid.connect/private) however would break the original spec and make this probably incompatible with existing libraries.\nThis is probably best explained in an example from the real code:\ngo\n// OpenIDConnectKeyName = \"hydra.openid.connect\"\nkeys, err := km.GetKey(oauth2.OpenIDConnectKeyName, \"private\")\nThis is a tricky one, maybe I have to overthink JWK kid naming and, for example, prefix the JSON Web Key Set ID: \"kid\": \"hydra.openid.connect/private\"\n. #73\n. I'm closing this because I feel confident that it's not Hydra's fault :)\n. id token variation comes from different iat values\n. Requesting token id_token works fine. It's likely that the implicit flow is executed as well as the hybrid flow, duplicating the keys.\n```\naccess_token=jVXhCjomYFNdz8D067Kzrf0i3V6B3arLAha3PBySuck.Kzg6pg5mZk9bgtnd29uv1BtM-7RMwvphGjhUOe-QQNU\n&expires_in=3600\n&id_token=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdF9oYXNoIjoiRnJBS04ra0g4MXo2b1VDbDJuUzVRUT09IiwiYXVkIjoiZDdmMmVlMDktOGQyOC00YmUyLWJiODktY2UzYTVlN2MzMjE3IiwiYXV0aF90aW1lIjoxNDcxNjkyMDE1LCJleHAiOjE0NzE2OTU2MTUsImlhdCI6MTQ3MTY5MjAxNSwiaXNzIjoiaHlkcmEubG9jYWxob3N0Iiwibm9uY2UiOiJtY3hzbG5hcmRpYnFqYmFoaWRpZXd3bXEiLCJzdWIiOiJqb2huLmRvZUBtZS5jb20ifQ.uP_Fq7pCyyHh3_eXZW07w49qYCZlJcXrda4zDNP4TLS3b-Sjcit2sC_mznmv-Mv2-l8YFcyBW4VgxxRVWtyaweUDfn3aqW82NXiNRHwLyDi5CJDjzitaeyGRIUgQr8Kp2arXUl9gUNdfZiv5GKGNTA3hXynvwD-Gq9_5FCeXTeBT3VWaumH3v0kNc5bIWgU0cfM2a7leBQmbfpdJR8_atP5Rr0ox0CMFgr1AOn3tcS356bvSGeEHhT9DWxdXW9cJ37nIkinbkhx6Tb9k_EjV3XdwdzdeVg4kieBQWJBReRGiRtGXzyXrbfUOM2mv9yz8-p_QJ5v9gRQ-hV0oe3tgSsF1sG5LSAIZwMCwyn07Xc3wT8py6AwVExuLHztETsVJZYsr_LzbGC-2BAsaA8HQJwbETY_KWC_PqsfSwX1kRrKX9bSgPa9HXl4rEVZNfO9ce89XGg9aBygy_hvd5Y0rVsdb1u7XpL3o59hgKjd05AMQb1zOs62P37siO1TtoXCvgjokhVZwQqHAsuUdxbt9B4BgIk36R94dLGK_gRDkBa_k0uGy5xWeTHfJHDEkZOsdYZAGFozwPQn8RMEvjU3d4LHOnGPaPrY56AazXnxtJsESHqtQWo-H2wp-lZF3UgOJD6ISKP3-3S_e-oNDGIOPsYyUA0OpiRtbhJhIxxvUn6k\n&scope=hydra%252Boffline%252Bopenid\n&state=pmatbmvqdabnypfgehfuiuew\n&token_type=bearer\n```\n. resolved by https://github.com/ory-am/fosite/commit/d681fc8aa57b8166b311b57bd50b19a1570f474e\n. resolved by https://github.com/ory-am/hydra/commit/8eea29f01a39944a7ceccbf5fa23311891a6ef87\nsorry, again for this @janekolszak \n. This is now:\n```\n    // Clients offers OAuth2 Client management capabilities.\n    Clients           *client.HTTPManager\n// SocialConnections offers Social Login management capabilities.\nSocialConnections *connection.HTTPManager\n\n// JSONWebKeys offers JSON Web Key management capabilities.\nJSONWebKeys       *jwk.HTTPManager\n\n// Policies offers Access Policy management capabilities.\nPolicies          *policy.HTTPManager\n\n// Warden offers Access Token and Access Request validation strategies (for first-party resource servers).\nWarden            *warden.HTTPWarden\n\n// Introspection offers Access Token and Access Request introspection strategies (according to RFC 7662).\nIntrospection     *hoauth2.HTTPIntrospector\n\n```\n. Thank you for your thoughts and links! I am very confident that Hydra will stay with the Apache 2.0 license. :)\n\nAm 12.09.2016 um 07:21 schrieb Wayne Robinson notifications@github.com:\nBasing licensing on system resources is fine a for something like a DB because usage of it is basically defined by resource use. But for an authentication engine, that doesn't really sound like it fits.\nWe really like the idea of this being open source and, as mentioned privately, would be happy to pay for support of this as well as ad-hoc consulting work to improve the system itself.\nOther open source products (https://github.com/mperham/sidekiq https://github.com/mperham/sidekiq for example) will have a freemium-like model based on features. Mike has Pro and Enterprise levels for his product, but keeps everything else open source. He also provides absolutely no support for the open-source version and that model works for him.\nIf you wanted to go Freemium, something like the Warden policy-based features could be an interesting upsell as they're mostly separate from the core authentication layer.\nIf you wanted to use a resource-based model, may I suggest something like active user count (e.g. https://auth0.com/pricing https://auth0.com/pricing). This seems to fit better with the core product.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/ory-am/hydra/issues/227#issuecomment-246252394, or mute the thread https://github.com/notifications/unsubscribe-auth/ADN1ehkYwp9sTgEn1tFiFMDsl2w6jVD_ks5qpOFegaJpZM4Jp1xK.\n. Closed for now\n. RethinkDB will no longer be actively maintained without customer requests and is superseded by #292\n. ok, will do, thanks for the effort so far\n. no i think it works fine, the test cases seem ok:\n\ngo\n    scopes = []string{\"hydra\", \"openid\", \"offline\"}\n    assert.False(t, strategy(scopes, \"foo.bar\"))\n    assert.False(t, strategy(scopes, \"foo\"))\n    assert.True(t, strategy(scopes, \"hydra\"))\n    assert.True(t, strategy(scopes, \"hydra.bar\"))\n    assert.True(t, strategy(scopes, \"openid\"))\n    assert.True(t, strategy(scopes, \"openid.baz.bar\"))\n    assert.True(t, strategy(scopes, \"offline\"))\n    assert.True(t, strategy(scopes, \"offline.baz.bar.baz\"))\n. could you open a PR with your changes so i know which branch to look at?\n. that's ok\n. resolved\n. Ah yes, if you want, create a PR\n. This is resolved already. ah right, the error is because the client does not have the privilege to access the warden api which was previously possible due to my mistake which @faxal solved here: https://github.com/ory-am/fosite/commit/7faee6bbd53ee762ddfe194fb2ea5e7d0205e46d\nthis is now #232\n. This PR should not break the database. Although the Signature of JWT Containers changed, they are not being saved to the database in Hydra. Plus, the float64 change won't matter to json anyways.\nThat's why this is tagged as 0.4.2\n@leetal let me know if you disagree\n. I released fosite as 0.3.0 because it's still a possible bc break. :)\n. Yes, exactly, this endpoint is for revoking valid tokens. There is currently no possibility to revoke tokens.\n\nAm 12.09.2016 um 07:14 schrieb Wayne Robinson notifications@github.com:\nIs this to explicitly revoke tokens (e.g. by logging out)? Is there currently a revocation list for access tokens in Hydra somewhere that works with the Warden and OAuth Identity endpoints?\n\u2014\nYou are receiving this because you were assigned.\nReply to this email directly, view it on GitHub https://github.com/ory-am/hydra/issues/233#issuecomment-246251686, or mute the thread https://github.com/notifications/unsubscribe-auth/ADN1evv99rqT3Z2Vh-q7VwR4mLpo67sEks5qpN-ggaJpZM4Jr5Ik.\n. done!\n. Per spec: the refresh token revokes all future refresh tokens and all access tokens issued by the refresh token. The revokation of an access token revokes all refresh tokens, given any.\n. I don't think that extending OAuth2 is smart. OAuth2 is for authorizing third party apps, web/mobile api keys are for authentication of public clients and quota checking and similar.\n\nI think it should be possible to validate these tokens using the token valid warden endpoint. Tokens can be issued by any subject that is allowed to do so by policies. The endpoint would reside in:\nPOST /api-keys/web/\nPOST /api-keys/ios/\nPOST /api-keys/android/\nThe key will be matched against an url (web) or namespace (ios, android).\nI am in the process of figuring out how to validate those tokens:\n1. warden: using existing infrastructure is good, but api keys are something very different from access tokens. api keys are used for quota checking (for example) whilst access tokens are used for higher priviledged functions. It would be intransparent for developers when an API key was used and when a access token was used. This could lead to serious vulnerabilities caused by tiny mistakes. probably the core reason why extending oauth2 doesn't make sense.\n2. new endpoint: adding another validation method sucks but it would be clear to the developer what's going on. it would require a lot of boilerplate too\n. Regarding https://github.com/ory-am/hydra/issues/234#issuecomment-243002331 I am not 100% sure. One thing that comes with API tokens is that users are usually allowed to update allowed hosts and ios/andorid namespaces without having to change the API token everywhere.\nIn extension to above, API tokens are delegated authorization rights as well. They could, based on policies, allow user agents to do write requests as well (think anonymous comments). Using the existing OAuth2 infrastructure would additionally allow to leverage OAuth2 Access Token Validation as well as existing Access Token Issuance. By setting the TTL high (e.g. 50 years), they would basically never run out of validity and they could be revoked once #223 lands.\nAPI Tokens could be, for example, exchanged by ID Tokens\n```\nPOST /oauth2/token\nAuthorization: basic\ngrant_type=api_key\nplatform=web\nnamespaces=[\"foo\", \"bar\"]\nid_token=\n```\nand modified through a new endpoint\n```\nPOST /oauth2/api-keys/\nplatform=ios\nnamespaces=[\"foo\", \"bar\"]\n```\nOne question to answer is if api keys can be issued with an id_token only, or if clients can issue those as well. I can currently not see any problems with allowing both, although restricting on id_token and opening up later would be the safer route.\nAnother thing that I have not solved yet is, the token's subject. There are two things to consider:\n- We need to be able to distinguish API Keys from regular Access Tokens. Otherwise, API Keys would receive the same rights that their owners have.\n- Additionally to checking if the API Key as such is allowed to perform an action, we also need to check if their owner is allowed to perform that action.\nValidating the keys could be achieved using the LocalWarden:\n\nThe resulting access token could have a fixed subject (rn:hydra:oauth2:api-token) and carry the ID Token claims as part of it's own extra claims. This would allow for simple to set up policy checks and to identify the original user. The TokenAllowed method would then first check if the api token is allowed to do the stuff and then if the subject is too.\n\nAlternatively, it could be achieved through policy conditions:\n\nDoing both at the same time (checking what public API keys are allowed to do and checking what the user is allowed to do) could be done through policy conditions. This would however require the TokenAllowed method to append to the context if it encounters an API key. This does not feel very transparent.\n. I do not think that the following statement holds:\nAnother thing that I have not solved yet is, the token's subject. There are two things to consider:\n- We need to be able to distinguish API Keys from regular Access Tokens. Otherwise, API Keys would receive the same rights that their owners have.\n- Additionally to checking if the API Key as such is allowed to perform an action, we also need to check if their owner is allowed to perform that action.\n\nThe reason being that we want to limit the scope of an API Key, not distinguish in the resource server what to do if we encounter such a token. So instead of the things written above, API Keys should be issued to a limited set of scopes, which are always validated when looking up the token. For example:\nWe want users to be able to issue api keys in order to\n1. download images\n2. fetch some other data\nBoth of these endpoints have a certain scope:\n1. images.download\n2. data.read\nOther endpoints, like uploading images would have different scopes like images.upload.\nI think that the distinction here is: Policy lookups are used to check if a subject is allowed to do something. An API Key is issued on behalf of a subject, it is not a subject itself. Instead, the API Key carries a subset of to the subject's capabilities.\nIf this logic holds, it would make sense to have API Keys as an extension to OAuth2.\n. This is now being formalised as https://github.com/ory-am/fosite/wiki/OAuth2-API-Key-Grant-Type-Draft\n. Some initial spec:\n```\npackage oauth2\nimport (\n    \"net/http\"\n\"fmt\"\n\n\"github.com/ory-am/fosite\"\n\"github.com/pkg/errors\"\n\"golang.org/x/net/context\"\n\"time\"\n\"github.com/ory-am/fosite/compose\"\n\"github.com/ory-am/fosite/handler/oauth2\"\n\n)\n// this feature is experimental, do not use it.\nfunc OAuth2APIKeyGrantFactory(config *compose.Config, storage interface{}, strategy interface{}) interface{} {\n    return &APIKeyGrantHandler{\n        HandleHelper: &oauth2.HandleHelper{\n            AccessTokenStrategy: strategy.(oauth2.AccessTokenStrategy),\n            AccessTokenStorage:  storage.(oauth2.AccessTokenStorage),\n            AccessTokenLifespan: time.Hour * 24 * 31 * 12 * 100,\n        },\n        ScopeStrategy: fosite.HierarchicScopeStrategy,\n    }\n}\ntype APIKeyGrantHandler struct {\n    *oauth2.HandleHelper\n    ScopeStrategy fosite.ScopeStrategy\n}\nfunc (c APIKeyGrantHandler) HandleTokenEndpointRequest(_ context.Context, r http.Request, request fosite.AccessRequester) error {\n    if !request.GetGrantTypes().Exact(\"api_key\") {\n        return errors.Wrap(fosite.ErrUnknownRequest, \"\")\n    }\nclient := request.GetClient()\nfor _, scope := range request.GetRequestedScopes() {\n    if !c.ScopeStrategy(client.GetScopes(), scope) {\n        return errors.Wrap(fosite.ErrInvalidScope, fmt.Sprintf(\"The client is not allowed to request scope %s\", scope))\n    }\n}\n\n// The client MUST authenticate with the authorization server as described in Section 3.2.1.\n// This requirement is already fulfilled because fosite requries all token requests to be authenticated as described\n// in https://tools.ietf.org/html/rfc6749#section-3.2.1\nif client.IsPublic() {\n    return errors.Wrap(fosite.ErrInvalidGrant, \"The client is public and thus not allowed to use grant type api_key\")\n}\n// if the client is not public, he has already been authenticated by the access request handler.\n\nrequest.GetSession().SetExpiresAt(fosite.AccessToken, time.Now().Add(c.AccessTokenLifespan))\nreturn nil\n\n}\nfunc (c APIKeyGrantHandler) PopulateTokenEndpointResponse(ctx context.Context, r http.Request, request fosite.AccessRequester, response fosite.AccessResponder) error {\n    if !request.GetGrantTypes().Exact(\"api_key\") {\n        return errors.Wrap(fosite.ErrUnknownRequest, \"\")\n    }\nif !request.GetClient().GetGrantTypes().Has(\"api_key\") {\n    return errors.Wrap(fosite.ErrInvalidGrant, \"The client is not allowed to use grant type api_key\")\n}\n\nreturn c.IssueAccessToken(ctx, r, request, response)\n\n}\n```\n...still have to figure out how to check domains\n. @waynerobinson summed this up perfectly:\n\nYou just need a privileged client that can forge long-lived access tokens for specific scopes.\n. This can be solved much better with a proxy scenario. The proxy requests an oauth2 access and refresh token using authorize code and issues a handle, which is the API key. Then, when an API key is set in a request, it is replaced with the access token.. Not really, API keys are actually for identification, not authorization so it's not really in the scope of hydra. I don't think that hydra is going to support identity management any time soon. Maybe a different product but there are no plans yet.\n\nGesendet mit meinem HTC\n----- Reply message -----\nVon: \"Drasko DRASKOVIC\" notifications@github.com\nAn: \"ory-am/hydra\" hydra@noreply.github.com\nCc: \"Aeneas\" aeneas@serlo.org, \"Mention\" mention@noreply.github.com\nBetreff: [ory-am/hydra] SCIM 2.0 (#235)\nDatum: Fr., Aug. 26, 2016 14:45\n@arekkas I was wondering if you looked into this: http://www.simplecloud.info/, and what is your opinion on supporting SCIM 2.0 standard in Hydra?\n\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub:\nhttps://github.com/ory-am/hydra/issues/235\n. Thank you for the PR but I remember now what this was for. I will include your fix in another fix. :)\n. ah no nvm :) thanks!\n. This is no longer possible as the warden has been removed from this project. Please use hydra connect to enter the client credentials and avoid editing hydra.yml manually.\n\n1, \".hydra.yml\" contains the correct 'cluster_url', the client_id and client_secret come from rethinkdb table 'hydra_clients';\n\nThe secret is hashed in the rethinkdb table, that's why your access is denied. You must extract the client id and secret from the hydra logs as described here.\n. > Thanks. I know the logs contain client id and secret when running with docker, but I used binary hydra which only print the following message:\nIt should not matter if you use hydra from source or binary. The client credentials will always be printed. It looks to me as if you are connecting to existing hydra tables in rethink db. On existing hydra installations (hydra checks if it already connected to your database in the past) the client is not regenerated and thus not printed to logs.\n\nThe client id is correct, the secret is hashed or crypted, cannot pass the check in access_request_handler.go:\n\nYes, the secret is being hashed which is why you can't look it up in rethink.\n. Glad to hear that!\n. I will resume work on this release beginning September 19th\n. resolved by various fosite improvements\n. @ericalandouglas as you correctly suggested, this is a great place for OIDC, as you are only interested in meta-data. I don't know why I didn't think of this before. I will still keep this issue open, just in case.\n. Actually, there is no standard way to validate access tokens with public clients, without being at risk of token scanning. Therefore, I'll close this issue until someone comes along with a good use case and ideas how to mitigate that risk.\n. awesome, thanks for the suggestion. hydra is basically doing almost everything already: https://bestpractices.coreinfrastructure.org/projects/364\n. nice! I will!\n. currently blocking:\n- https://github.com/HewlettPackard/gas/issues/51\n- https://github.com/HewlettPackard/gas/issues/50\n. done!\n. > How do we manually add keys for challenges, etc so they don't change constantly on restart\nKeys only change on new installs / if there is no way to persist them. This usually happens when you use hydra without a database. Once you've setup rethinkdb with hydra, hydra will generate them only once.\n\nThat challenge keys for the consent server, etc need to be requested from Hydra every single time they're used?\n\nIn the future, there will be key rotation but you shouldn't be required to lookup the keys always. It is enough to look them up if validation fails.\n\nI see key endpoints, but nowhere to see what keys we're meant to setup and exactly what each is used for.\n\nGood point, this isn't documented at the moment. Here is a list of keys: #239\nUsually, you should not need to modify them, except for the HTTPS TLS key, which can also be set using environment variables or a command line flag.\n. Yes, this already happened on the 0.5.0 PR\n\nAm 12.09.2016 um 07:10 schrieb Wayne Robinson notifications@github.com:\nJust to confirm, the intention is to change the keys to all the hydra.* prefixed forms?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub https://github.com/ory-am/hydra/issues/247#issuecomment-246251034, or mute the thread https://github.com/notifications/unsubscribe-auth/ADN1eiRSIcu5Cz9ng4BZMPgULxCNhXAzks5qpN6rgaJpZM4J3qu-.\n. This will no longer be pursued, instead, we will introduce Oathkeeper which is capable of translating opaque access tokens to JWT tokens.. > because last time I checked - it did.\n\nWhen was that? Back in 2015?\n\nIs it possible to we add support for JWT still?\n\nNot in Hydra because of multiple issues (I'll write a blog post on it soon). But you can use https://github.com/ory/oathkeeper for that. It converts access tokens to JWTs and can also validate the request based on scopes and access control policies. Just be aware that we're currently refactoring it.. 1. Don't use the implicit flow\n2. Do you need an ID Token or an Access Token?\n3. Why does the API only accept RS256 JWT despite various drawbacks?\n4. Oathkeeper is not a replacement, the docs will definitely help you understand what it does and why.. > What drawbacks are you referring to? The main point of accepting JWT there is to be able to verify the token without the access to auth server, or knowing which one (of many) auth servers issued the token.\nNot sure if RS256 has any drawbacks.\nYou can't revoke tokens and the payload is transparent.\n\nSeems like it has to sit in front of the API. It's not obvious if it would work if we have not just Hydra, but also other issuers that provide JWTs. It doesn't seem like it.\n\nWith the refactor, it could! It would even streamline the payloads. > We can blacklist tokens, I think it's as good as revoking. Transparent payload is not really a problem too.\nBlacklisting requires a network roundtrip which in turn negates the request-less validation.\n\nIt'd be cool to have something like that, however it looks like it wont work now. I really missed that lack of JWT support, and I basically already spent all the time I could on integrating with Hydra.\n\nSorry, JWTs won't be added to the project in the foreseeable future.. Yeah, we should probably have a \"limitations\" section in the documentation, I guess that would be really useful. Tracked as #839. Unless you store the black list in memory, you will always have a roundtrip. Be it to the filesystem, or to the database. Sure, some dbs will perform better/faster for this specific task than a HTTP rountrip, but it adds the same possibility of failure.\nI understand that you have multiple issuers which you want to trust where resource-provider-side validation makes more sense than requesting info from every issuer. It is however not according to the revokation spec, which specifically states that the token must be invalidated at the authorization server, not the resource provider. The problem is that the token will be marked as active at the authorization server, despite it not being active at the resource provider. Also keep in mind that revoking tokens is not just invalidating one token, but also \"reovke tokens for all applications\" or \"revoke tokens for application x\"\nIndeed, it's quite the intriguing use case. Usually, apps accept tokens from one or two issuers, not many - so this is actually the first use case I've encountered where JWTs truly make sense. I still think it could be solved via oathkeeper, but I also understand the increase in complexity. You could obviously write something like oathkeeper yourself which is able to resolve tokens that aren't JWTs - you'd have all the benefits of revoking tokens.\nRevoking tokens is a really important security mechanism that can prevent major threats if applied correctly. Not having that work properly may cause significant issues down the road.. > Relying on the ability to revoke a token is not always good. In some cases it's just not correct. It's not a silver bullet, and there are many ways to cover attack vectors that are typically covered by token revocation.\nOf course it's not a silver bullet, but it's a critical tool in your toolbox.. > Correct. And that trade-off is why most access tokens are short-lived (ie 1 hour or less). I think an informed implementor can make this trade-off, which is a short period of irrevocability vs the benefits of statically verifiable tokens (which is good from both a latency and resiliency view).\nActually, I agree. I think we could let developers make the trade off between timeliness of access revokation and avoiding network roundtrips.\n\nFor many resources server that is totally OK. The payload is essentially:\n\nIf you know what you're doing, then yes. However, developers are incredibly lazy (like mathematicians) and what happens often is that over time additional data is added to the token because \"it's already there and I guess the data isn't really private\", but it actually is. I'm not saying that this is the norm, just that this happens and is observable in the wild.\nThe question is if this project should protect you from doing this by enforcing an (opinionated) way of issuing access tokens or not. So far, my belief was that yes - we should enforce secure behavior even if it breaks the 1% use cases. I am, however, today more convinced that certain practices could be allowed if the devs know what they are doing. Having the default of issuing opaque tokens while also having a DO_YOU_KNOW_WTF_YOUR_DOING_OK_USE_JWT (jk) strategy might be an option. It still goes against my beliefs of best practices in API access control which is to stay completely opaque (pass-by-value) to the outside world but transparent (pass-by-reference) on the inside (hence the Oathkeeper project). I do get the point which is integration with third party services though, and it is a valid point where the just mentioned structure does not help.\n\nBtw, I think, if we really need revocation of JWT token, nothing stops us from supporting that. If we place an opaque string inside of a JWT, in a custom key, it can be effectively used to verify the session.\nFor my case it doesn't make sense though, because session is not controlled by issuers (by design).\n\nThat's negating the benefits of validating the tokens without an additional network roundtrip :). To keep this discussion alive, I'm reopening the issue.. Is there a particular reason for using a somewhat more exotic signing algorithm (like PS384) instead of standardised RS256? Keep in mind that most off-the-shelf libraries don't actually support those.. By the way, tampering with dynamically accepting token signing types can be a serious security vulnerability. The typical attack path is to change the alg part in the header (the easiest is setting it to none) and re-generate the signature. I remember reading that there was an attack for changing asymmetric to symmetric (e.g. HS256 -> RS256), but I'd have to find it again. Token signing and verification algorithms should be fixed (configuring this through an env var is an option) and everyone accepting those tokens should agree upon the algorithm to prevent malicious use.. Does the Google KMS sign JWTs or just provide the keys via an API? I generally like the idea of integrating with KMS but would like to see a generic solution that spans GCP, AWS, Azure, (DigitalOcean?) as opposed to having a sizeable code base and maintenance overhead just to integrate with each proprietary system (and its breaking changes wrt to authorization and API usage, which has bitten me often - specifically the auth* part).. ps: key rotation is now a first-class citizen in hydra as that was a requirement for getting the OpenID Dynamic profile certified - just tell hydra to generate a new key hydra keys create hydra.openid.id-token -a RS256 -u sig (to be documented). That's a good idea - it's already possible to do that with plugins, so no need to compile it your on your own (at least not hydra). But it doesn't allow you to replace just one store, you have to write implementations for all of them (but you can obviously import e.g. client.SQLManager).\nI'm not sure how many people compile hydra on their own and if adding this feature would benefit the 95% use cases. I do agree with you on separation of concerns and generally like the idea of integrating with cloud provider's KMS systems. The default store (SQL/Memory) will definitely not be removed as hydra should work standalone, but I don't think you're suggesting that anyways.\nMaybe it would be enough to just provide jwk.manager_google_kms and jwk.manager_amazon_kms natively and make this somehow configurable?. > The current plugin system for database backends isn't generic enough, it expects a *sqlx.DB implementation which doesn't make sense for all databases (e.g. any NoSQL database). \nI don't think it does. There is a sqlx.DB reference but that is for re-using the already existing database connectivity if you want to. I admit that the code is a bit weird there but it's definitely possible to ignore sqlx.DB and use your own connectivity.\n\nEither way, I'm really glad to hear that we can possibly support a pluggable system for signing here - I'd be happy to discuss this more design-wise and help with implementation if you'd like!\n\nIt's not a super-high priority for us right now (first things first like getting out of beta for all services, enhancing the console, working on hive) but it's definitely something worth exploring once there's a bit of downtime.. > The *sqlx.DB reference for plugins is required as when its loaded an immediate call to db.Ping() is made. I can open a separate issue to drop the reference altogether as the plugin should be able to manage the connection on its own and doesn't need the reference it returns to be passed into its own exposed functions as a parameter.\nYeah you're right, feel free to track this whole discussion as a new issue as this one will probably be closed once JWT lands.. #947. That would be awesome, let me know if I can help! :)\n\nAm 12.09.2016 um 07:12 schrieb Wayne Robinson notifications@github.com:\nAuto-generated libraries is probably a good starting point when there is nothing else. But they usually don't follow the form you'd expect from the language you're using them within.\nI don't want to make any promises for myself and @andrewmcnamara https://github.com/andrewmcnamara but we might be able to release what we're creating for Ruby as open-source. Although not for our first implementation which is a combination of both it being more tightly wound in our existing application and us still getting our heads around the exact implementation details here.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/ory-am/hydra/issues/249#issuecomment-246251554, or mute the thread https://github.com/notifications/unsubscribe-auth/ADN1eieXBYxtXm2nn-BswzZVG3Mr6fC9ks5qpN9OgaJpZM4J5ptZ.\n. @amerdidit the api docs are available on apiary, which supports export to swager iirc.. Hey @nikolay-turpitko thank you so much for the sump up and the hard work. The system behind apiary is open source, it's called api blueprint. There are some converters for it that work with command line:\n\n\nhttps://github.com/kminami/apib2swagger\nhttps://github.com/lucybot/api-spec-converter\n\nAlso it looks like apiary will move to OpenAPI spec anyways: https://blog.apiary.io/2016/01/18/We-ve-got-Swagger\nBy the way, I think we should define the APIs in OpenAPI spec as well (which is swagger iirc). The api blueprint is: https://gist.github.com/arekkas/e5cd5a455d68ba4e5bc0457144125a68. Damn this sucks. Maybe there is no way around this and I just need to convert this manually. Could also be an idea to improve the API docs.. Hey @nikolay-turpitko thanks for everything. I have some things to do, but I'll check over it soon!. We now have swagger-based docs!. This is now possible using swagger-codegen. You can customize the verbosity of logs with LOG_LEVEL=<level>, see https://github.com/ory-am/hydra/blob/master/main.go#L18\nWhat sort of health check do you need? Just a simple ping/pong?\nOtherwise, health monitoring is tracked in #216\n. ping @abdollar \n. Ok, then I'm going to close this as a dupe of #216 - thanks for the response :)\n. Which version are you running? How did you get the token - did you use hydra token client or some other way?\n. @faxal thanks for investigating :)\n@janekolszak are you by any chance using a token that was issued on behalf of a user instead of on behalf of the client?\nI tried reproducing your issue with the client_credentials grant but was not able to:\n``` bash\ncreate policy\n$ hydra policies create -f docs/access-control/policies/everyone-can-read-public-keys.json\ncreate client\n$ hydra clients create -c=[http://localhost/cb] -g [client_credentials] -a [hydra] -r [code,token]\nget access token\n$ curl -X POST -H \"Authorization: Basic ZTllYWMzNjAtYjA5Zi00NmY4LWIwNDktODlkMjZhZWNkYWFmOlNqbj1DMXktc19RVEcscHoxPlctckM5ZElv\" -H \"Cache-Control: no-cache\" -H \"Postman-Token: d472a862-943c-3596-fc13-f71ee34d37f1\" -H \"Content-Type: application/x-www-form-urlencoded\" -d 'grant_type=client_credentials&scope=hydra.keys' \"http://localhost:4444/oauth2/token\"\n{\n  \"access_token\": \"9wHkwSg_jThB1sPnt8tX-9tukrXwJymTU9UZCUThB5M.DMVw60sQ8gbh6x29079_fO987_ktHqQT8R4uSD_CGng\",\n  \"expires_in\": \"3600\",\n  \"scope\": \"hydra.keys\",\n  \"token_type\": \"bearer\"\n}\nrequest key\n$ curl -X GET -H \"Authorization: bearer 9wHkwSg_jThB1sPnt8tX-9tukrXwJymTU9UZCUThB5M.DMVw60sQ8gbh6x29079_fO987_ktHqQT8R4uSD_CGng\" -H \"Cache-Control: no-cache\" -H \"Postman-Token: e2851819-8240-6ce3-5017-6fc573fc1943\" \"http://localhost:4444/keys/hydra.openid.connect/public\"\n{\"keys\":[{\"kty\":\"RSA\",\"kid\":\"public\",\"n\":\"7wV6myGPv4XL3v7X3FVwWzQvjnFMOh7t0_Ua-d6AtOA6NcY1b2OnYqpDiYUCp5I3vtq5G9YZPLK7XcuNLTtO2TCf_ycmu0AIX3NMkKSIUpmR5tJEGdRPzG6umMZ5DWNBeERsHGJzNCJyzAyStQ_kI-DfCZEn3iHuL9jsZCb5pYptqESpkvpqzLFfa3R5EXdGrzxrKrALIHCSyTocGoFWQ7ogjcOjdlq0f69cvTrIH5Dia7aRmfmYGXZ6BzXehKPCjGYuexKTUQAmvJov9UWb8jWS8rLf1by-aibwCxsx6aZwYz7_dI7XQSkQ6fzOrqB-9ktcISztc9Act7AUwovg2zZaMJlTojcz1IIBxhSCQ4ZY6quY7skgwTfGpYivhWWnwb0mTjxbph0Ck_za-R6H53U7AGj60H1AgpZRG6bQu06oGY7cTfjKxTGd8_beaFCAVuQaf09_808mkvfSsnPU5EcfNrBjTukiQUxgdyyRljPvSRgJ8JJfZ0_D712JJ-9aXKAVwyLxqhnOWE008tTSNOiyIblgjrSp0Wcjh90eGO2EKpzvJfF7te6FvoBK1cEtl7SiF6oeh9KQvmFJVug4KDRYeGjWFN-iHJHCPgYue3LE1S72q6-zZ4kATSZZceC-SXocpORVgyT1hljEEvc0YoQc4lsjjwSLDeyIQZPj2VU\",\"e\":\"AQAB\"}]}\n```\nwhere policy.json is:\njson\n{\n  \"description\": \"Allow everyone including anonymous users to read JSON Web Keys having Key ID *public*.\",\n  \"subjects\": [\n    \"<.*>\"\n  ],\n  \"effect\": \"allow\",\n  \"resources\": [\n    \"rn:hydra:keys:<[^:]+>:public\"\n  ],\n  \"actions\": [\n    \"get\"\n  ]\n}\n. I believe that the issue is that the idp library is accessing the endpoint without passing along an access token, which is iirc the way the JWKS URI is working in OpenID Connect. So the issue here is that, even though you allowed all subjects to access the endpoint, it still requires a valid access token. As that token isn't passed, the keys endpoint rejects the request.\nTo resolve this, we need to add a way to let anonymous requests pass through, when all subjects are allowed.\n. I will address this in #243\n. You can now allow keys to be publicy available with this policy:\njson\n{\n  \"description\": \"Allow everyone including anonymous users to read JSON Web Keys having Key ID *public*.\",\n  \"subjects\": [\n    \"<^$>\"\n  ],\n  \"effect\": \"allow\",\n  \"resources\": [\n    \"rn:hydra:keys:<[^:]+>:public\"\n  ],\n  \"actions\": [\n    \"get\"\n  ]\n}\nalternatively, you can also achieve this by setting \"subjects\": [\"<.*>\"] or \"subjects\": [\"\"]\n. upstream https://github.com/ory-am/fosite/issues/96\n. resolved by https://github.com/ory-am/fosite/commit/4db14222a006bfdc1e7f2b2769e53f2dbd69f128\n. upstream https://github.com/ory-am/fosite/issues/97\n. resolved by https://github.com/ory-am/fosite/commit/0dc5af31145811987bd24d8a53d62107fc08bfa9\n. Actually, the original request is simply the redir value.\n. One example could be:\n\nhttp://foo/bar includes http://foo/bar?baz but http://foo/bar?baz=bar does not include http://foo/bar?baz=baz\n. @matteosuppo I don't think this would comply with:\nIf requiring the\nregistration of the complete redirection URI is not possible, the\nauthorization server SHOULD require the registration of the URI\nscheme, authority, and path (allowing the client to dynamically vary\nonly the query component of the redirection URI when requesting\nauthorization).\n. What needs to be done for this is parsing urls and removing query components here.\n\n@zepatrik this is a good issue for you, ping me when you have time to address it.. Interestingly enough, the spec also says:\n\n3.1.2.3.  Dynamic Configuration\nIf multiple redirection URIs have been registered, if only part of\n   the redirection URI has been registered, or if no redirection URI has\n   been registered, the client MUST include a redirection URI with the\n   authorization request using the \"redirect_uri\" request parameter.\nWhen a redirection URI is included in an authorization request, the\n   authorization server MUST compare and match the value received\n   against at least one of the registered redirection URIs (or URI\n   components) as defined in [RFC3986] Section 6, if any redirection\n   URIs were registered.  If the client registration included the full\n   redirection URI, the authorization server MUST compare the two URIs\n   using simple string comparison as defined in [RFC3986] Section 6.2.1.\n\nSo, which one is it now \ud83e\udd37\u200d\u2642\ufe0f . Right, so the complete section says:\n\nThe authorization server SHOULD require the client to provide the\n   complete redirection URI (the client MAY use the \"state\" request\n   parameter to achieve per-request customization).  If requiring the\n   registration of the complete redirection URI is not possible, the\n   authorization server SHOULD require the registration of the URI\n   scheme, authority, and path (allowing the client to dynamically vary\n   only the query component of the redirection URI when requesting\n   authorization).\n\nSo if it's not possible to register the full URI, then we should fall back to the partial URI. Since we are capable of registering the full URI, this should not be the case for us.\nClosing.. > Protocol/host/path match can be useful for nested redirects:\nThat would not be compliant with the OpenID Dynamic Discovery so it's out of question unfortunately.\n\ndoes that mean we can use the state param to store it there ? I thought the state param was for security and should be random\n\nNo, it means that the state parameter will be appended to the redirect URL despite it not being whitelisted.. Yes, you can also store it on the server-side. You have to store the state anyways in a cookie, so why not the redirect value? It will also make it harder to spoof this.\nWe inherit from Go. Usually also depends on your API gateway etc.. resolved by https://github.com/ory-am/hydra/commit/3c3b93e6886a473c9472fdb61c584acda3d758aa\n. Thanks for reporting\n. upstream https://github.com/ory-am/fosite/issues/95\n. resolved in https://github.com/ory-am/fosite/commit/ddd8d035eb081200eff2ae9c4235c7228ec0b0b6\n. RethinkDB will no longer be actively maintained without customer requests and is superseded by #292\n. to be resolved in https://github.com/ory-am/fosite/pull/98\n. Good idea regarding policies, but do you really need to check for multiple tokens per request?\n. ok, what would the default behaviour be, allow access if one of the resources is allowed? what if one policy explicitly is set to deny?\n. That makes sense!\n. @waynerobinson is this something you want for the stable release, or is it more like a \"nice to have\"?. Thanks for the quick response. I'm sorting out priorities for the stable release of Hydra and wanted to check with you if it's something you want included there. From what you said I take it as a low prio :). This is now an upstream at https://github.com/ory/keto/issues/15. Thanks for the feedback, unfortunately this is currently not an option as the SDK will always depend on the basic hydra code. This is owed to the fact that hydra comes with HTTP clients for all endpoints which are well integrated in the testing suite. Redoing this in a different code base is prone to errors caused by api changes as well as more work to maintain.\nI think that glide is exactly the right tool for this sort of issue, as you do not need to commit the vendor directory any more to get reproducible builds. Additionally, glide install times are, even for larger projects, quite speedy.\nOnce #249 lands, you might be able to fallback to autogenerated code, but before that I don't see this being done by our organization.\n. Sorry for that, this is a classic typo :) The resource is rn:hydra:warden:token:allowed which causes rn:hydra:warden:token:allowed:<[^:]+> to mismatch as it expects something like rn:hydra:warden:token:allowed:a.\nI will update the API blueprint later, thanks for the hint!\n. @nikolay-turpitko so everything good with the recent docker image? There was once a bug with scopes, but it should be resolved on the 0.5.X version\n. Glad to hear that scopes work. All cases are also automatically tested, so I don't think that there will be any more issues.\n@nikolay-turpitko it would be great if you could create issues for the parts of the documentation that where not up-to-date or that where hard to understand or incomplete. Documentation is only as good as the people who report issues in it :D\n. Thanks, I will improve this!\n. The docs are now updated. The explanation on the warden will be done in the gitbook documentation.\n. good question, i was thinking about missing data, not outdated data. maybe I need to check how to set up rethinkdb + rabbitmq to do the job reliably.\n. however, I don't really get how rabbitmq is going to solve missing updates, it's still an app that listens to the changefeed... https://www.rethinkdb.com/docs/rabbitmq/javascript/\n. in general I don't think it's a good idea to add another external and hard to maintain dependency like rabbitmq on top of rethink. especially if https://github.com/rethinkdb/rethinkdb/issues/6128 holds.\nright now, I see several paths forward that would help those who want to use hydra in production:\n1. the obvious one: hope for the rethink community to help us on getting reliable changefeeds\n2. the \"eventually consistent\" one: refresh the in memory tables every X minutes (configurable). this would also resolve #228 . this would be an interim solution if (1) is likely to happen in the future\n3. the last resort one: switch to a different storage for the stable release (rethinkdb will still be avilable but might not be supported officially). I have no clear idea what and how though, maybe ampq, maybe something else.\nin general, this problem will come up in a production environment, but it will be much less frequent compared to home pc <-> hosted rethinkdb, especially if both are hosted in the same region / datacenter. so maybe a combination of (2) and the original idea (fetching non existing stuff from db) can be a good middle-ground.\nwhat do you think?\n. I just found this section in the rethinkdb docs, which gives me hope that changefeeds will be improved:\n\nWarning! If the RethinkDB river plugin loses connection with the RethinkDB server it\u2019s pulling data from, there\u2019s no way to guarantee no documents will be lost. This should change in the future with improvements to changefeeds, but currently the only way to be sure is to backfill every time, which will still miss deleted documents.\n. This thread shows how to simulate network loss of rethinkdb nodes using iptables, might be useful for generic rdb error tracing: https://groups.google.com/forum/#!searchin/rethinkdb/changefeed|sort:relevance/rethinkdb/7n_lBN6CKoM/iCy-LYpNIAAJ\n. The good news is, there are plans to support reliable changefeeds:\nThere are basically two planned degrees of reliable changefeeds:\n- Surviving short disconnects, as long as the client and servers remain up. This is the part for which we have settled an API so far. In this mode, either no change will get lost and the changefeed can just be resumed, or all changes will get lost and the changefeed will need to be restarted.\n- Surviving restarts and disconnects of both the client or server. Even permanent server failures can be sustained, as long as enough replicas are left. Picking up at a given point will be based on some sort of b-tree timestamp token that the client needs to persist (if client restarts should be survived without starting over from scratch). With this approach, a changefeed can always be resumed. However it will have \"squash\"-like semantics, i.e. it will omit intermediate values of any documents. It will also require an additional \"delete range\" notification and will sometimes emit changes for documents that weren't actually changed. There will be further restrictions, e.g. on the types of queries on which such a changefeed can be used. The goal of this mode is to keep a copy of the data synced with the current table state. A primary use case is for replicating RethinkDB data into a different secondary data store, such as ElasticSearch. For this mode, the API and exact behavior are not settled yet.\n\nSee: https://github.com/rethinkdb/rethinkdb/issues/3471#issuecomment-217587275\nThis makes option (2) a viable one.\n. from a community member on slack:\n\nRestartable change feeds might be at 2.6. I think for 2.5 they aim to get changes() on joins. This is not official or set in stone but rough estimate\nThe idea I think is to know what the last received change was and replay from that onwards. So rethink will buffer these changes in the background. Tho if this is the case its still not reliable when rethink is the one going down. For that we would need persistance of some kind\n[10:31]  there's not definite timeframe, but I think 2.6 is due 1-2 quarter of 2017\n[10:32]  2.4 should be coming out in a month or so\n[10:32]  3ish months for 2.5 and another for 2.6 I think is as accurate as anyone can predict\ndon't take what I said as something that holds too much value. It's just \"a feeling\". They never promised any of that, it's just how things were a month ago when I had a convo about this with a dev\n. There are some better options available until this is being fixed upstream, in particular:\n- includeInitial\n- includeStates\n- includeTypes\n\nSee also: https://www.rethinkdb.com/api/javascript/changes/\n. RethinkDB will no longer be actively maintained without customer requests and is superseded by #292\n. Yup, stray log, thanks for reporting!\n. note to self: make inner logs logrus.DEBUG\n. awesome! could you please sign off your commit using git commit --amend -s? :)\n. @otremblay there's nothing better than getting warmed up :D thanks for the contribution!\n. awesome, thanks!\n. I am collecting some publicly available information on this topic. Feel free to extend this list:\n- http://code.jjb.cc/benchmarking-postgres-vs-redis\n- https://gist.github.com/NateBarnes/3001890 (faulty results because bug in code, but might be used for reproduction)\n- http://redis.io/topics/benchmarks\n- ... more soon\n. @janekolszak ODBC is SQL only, right? So it would not allow users to use e.g. redis/memcached/mongo? However, I like the idea of this. On the con side we would need to rely on basic SQL queries, so no postgres magic.\n. I really like the idea going down the ODBC route, it would allow to run hydra on Google Cloud SQL, Amazon SQL, ...\n. @waynerobinson I think what @janekolszak meant is https://github.com/golang/go/wiki/SQLDrivers\n. Here is a critical view of having redis as a primary datastore and what to consider when rolling with this option anyways: https://muut.com/blog/technology/redis-as-primary-datastore-wtf.html\n. Another point to consider is that we need some sort of regexp matching in our datastore in order to fetch the right policies (by subject). This was actually one of the considerations in going in-memory for policies.\n. We're not only talking about tokens though, it's also about OAuth2 Clients, JWKs, policies and maybe more stuff in the future!\nps: I updated the first post\n. I would like to keep policies in the database and follow 12factor. And I don't like configuration files :) It makes Docker much harder\n. We should consider what people see, when they see hydra. I think the choice of rethinkdb was reasonable, despite the possible issues which would have been resolved, including missing tokens due to pub/sub latency, lost insert, update and delete notifications.\nWith redis my fear is that most people see it as a cache layer (yes, it's a datastore too), so what will they think when they read \"backed by redis\"? It (apparently) includes operational complexity which you don't have with a managed Google Cloud SQL / AWS / Azure one-click deploy. On the other hand, speed is a factor.\n\nOne other thing to note. RethinkDB as a database is going away. But Rethink itself is open source. We don't know what type of community support will spring from the death of the company yet, but it doesn't mean you have to abandon support altogether.\n\nDefinitely and I think that this process of reflection is important as we get closer to the stable 1.0 release of hydra! I will put rethinkdb on the list in the first post\n. I would like to introduce API Keys in the 0.6.0 release, which would be used in cases like: \"I want Google Maps on my app so I need an API Key that I put in my code\". Again, if one API Key is gone - so what? But that's not for Hydra to decide IMHO. Hydra should put in the best efforts to be a solution such as: \"Wow, this is so easy to use, resiliant, available, reliable and fast\". I think that redis satisfies that only partially. The current approach does not solve this perfectly either, but I think it was closer to it. The question I have is: why not talk a little bit about other possible solutions, such as SQL?\n. awesome, thanks for the sum up @Zev23 \n. I think going down the https://github.com/golang/go/wiki/SQLDrivers route is the smartest thing to do right now. It allows to use any SQL RDBMS or ODBC-ish variant, so it will work with managed solutions like Google Cloud SQL or Amazon RDS.\nI am not opposed to have non-traditional databases supported such as Redis, etcd or similar and I think that @waynerobinson has raised some good points on why Redis could rock with Hydra. For the time being, most of the environments that are using Hydra will not require that amount of throughput and low-latency which is why I think that going the SQL \"runs everywhere because you have SQL somewhere anyways and if not it's 2 minutes to set up in any cloud environment\"-route first is smart. I think it would rock to implement one store and have this statement up:\n\nHydra runs with all well-known SQL-compatible databases, including Couchbase (there is a couchbase driver for go SQL), MS SQL, MySQL, ODBC, Oracle, QL, Postgres, HANA, SQLite, Sybase, ...\n. Thanks for all the input, this issue is now #292\n. also, it's not clear that token introspection requires an access token, not basic authorization\n. done (y)\n. I think there's still an issue with the travis file:\n\n/home/travis/build.sh: eval: line 46: syntax error: unexpected end of file\nhttps://travis-ci.org/ory-am/hydra/jobs/165746289#L882\n. It looks like travis executes this as a one-liner which probably causes the issues.\n. Looks like the issue persists: https://travis-ci.org/ory-am/hydra/jobs/165755242#L883\nAre you sure that you can use raw bash in the travis config? Maybe you need to create a little bash script and call it from travis.yml instead.\n. Cool, it doesn't throw any errors any more. Not sure if it really works though, yet :D Thanks for the hard work so far. I'll merge it and see what happens!\n. awesome, thanks so much :)\n. > Also don't seem to be able to use basic digest authentication of a client's key/secret during these requests, only a valid client token.\nRFC6749 is not normative on which method is supported, it just states that some sort of authentication must be done:\n\nTo prevent token scanning attacks, the endpoint MUST also require\n   some form of authorization to access this endpoint, such as client\n   authentication as described in OAuth 2.0 [RFC6749] or a separate\n   OAuth 2.0 access token such as the bearer token described in OAuth\n   2.0 Bearer Token Usage [RFC6750].  The methods of managing and\n   validating these authentication credentials are out of scope of this\n   specification.\n\nWe decided to use access token only to reduce the probability of significant CPU drain when validating tokens. I am open to support both though. Nevertheless, this should be documented - ping #287 \n\nThere seems to be a check in the endpoint that the client's sub must equal the access token's aud.\n\nThis is interesting, I remember that this check was required to prevent token substitution attacks, but it does not seem to be in the current RFC any more, so it will be removed with an upcoming patch.\n. It appears that the token substitution part has been replaced in favor of:\n\nIf the introspection call is properly authorized but the token is not\n   active, does not exist on this server, or the protected resource is\n   not allowed to introspect this particular token, then the\n   authorization server MUST return an introspection response with the\n   \"active\" field set to \"false\".\n. In fact, we could actually remove the /warden/valid endpoint and use the warden for policy-based checks only. This would further strengthen the separation of concerns and help people better understand what the warden is doing. What do you think?\n. > So has this been changed to allow the token to be able to used to authenticate itself (and return at_ext values)?\n\nThe subject == token.Audience check was removed, apart from that nothing changed, as at_ext was already returned by introspection and RFC7662 requires a separate token:\n\nTo prevent token scanning attacks, the endpoint MUST also require\n   some form of authorization to access this endpoint, such as client\n   authentication as described in OAuth 2.0 [RFC6749] or a separate\n   OAuth 2.0 access token such as the bearer token described in OAuth\n   2.0 Bearer Token Usage [RFC6750].  The methods of managing and\n   validating these authentication credentials are out of scope of this\n   specification.\n\n\n\nThis is quite a common operation for us so we'd like it to be as fast as possible. \n\nThis will depend on the latency introduced by the store, the operations in hydra take only a few nanoseconds.\n. yes :)\n. The reasoning behind this is that the id token is self-contained but the access token is not. If you are allowed to receive an id token, you can extract the information from it. The access token has a different scope which is delegation of authorization. As that token is not self-contained, the information is provided at the endpoints.\nThe id token is, in general, just a flow to let third parties use OAuth2 for delegation of authentication, without being vulnerable to token substitution attacks. I don't think that the id token should be used to transport information not relevant to this task.\n. Usually, everything that is included in the id_ext claim should have the consent of the user. In case of roles this could be a scope like user.roles.read. ID Tokens usually have information like email, profile picture, name which are can be used to set up a new account in the third party app, if the subject of the id token is unknown.\nThink of it as something that you would do if you use log in with google. It will give you some basic information that you can use in your log in or sign up endpoint.\n. The abstract of the specification is:\n\nOpenID Connect 1.0 is a simple identity layer on top of the OAuth 2.0 protocol. It enables Clients to verify the identity of the End-User based on the authentication performed by an Authorization Server, as well as to obtain basic profile information about the End-User in an interoperable and REST-like manner. \n. > I understand. But then how do I access things like email, profile pics, etc from the internal apps that just have the access token and not the open ID one without having to manually find that info itself. I'm not saying we couldn't, but we have to verify the token anyway and always, may as well include the data again in that.\n\nThis really depends, keep in mind that email etc should only be included if the right scopes where set during the initial oauth2 request. So that data might not be available at all. It really depends on your use case and if it makes more sense to include this in the access token validation response or in a separate request. I don't think that I can give a one-fits all recommendation here, sorry :/\n\nI now understand the design decision and will take that into account when we submit some documentation PRs. ;-)\n\nThis would be so awesome.\nClosing, because I don't think I can help any further with this issue.\n. Awesome, thanks! Will merge once tests are done\n. @andrewmcnamara this branch is wip :)\n. @janekolszak check out https://github.com/ory-am/hydra/pull/293/commits/1d20c6e8f6b98d608292d45790fef10a8a6bb285\n. @andrewmcnamara apparently most of the environment variables do not work any more\n. looks like this was introduced by a recent viper commit:\n- name: github.com/spf13/viper\n-  version: 654fc7bb54d0c138ef80405ff577391f79c0c32d\n+  version: 50515b700e02658272117a72bd641b6b7f1222e5\n. yup, confirmed regression issue in viper: https://github.com/spf13/viper/pull/195#issuecomment-255517435\n. investigate:\nCould not retrieve validation key: {\"request\":\"2b5eee08-393b-4af4-8f5d-7a0f284d6539\",\"message\":\": : : json: cannot unmarshal array into Go value of type map[string]ladon.jsonCondition\",\"code\":500,\"description\":\"Could not unwrap error of type *json.UnmarshalTypeError\",\"name\":\"internal-error\"}\n```\n?[33mhydra_1     |?[0m time=\"2016-10-22T11:02:22Z\" level=error msg=\"An error occurred\" error=\": : : json: cannot unmarshal array into Go value of type map[string]ladon.jsonCondition\" request_id=2b5eee08-393b-4af4-8f5d-7a0f284d6539 status=500\n?[33mhydra_1     |?[0m time=\"2016-10-22T11:02:22Z\" level=info msg=\"completed handling request\" measure#web.latency=2427500 method=GET remote=\"172.18.0.4:56818\" request=\"/keys/hydra.consent.challenge/public\" status=500 text_status=\"Internal Server Error\" took=2.\n4275ms\n?[32mconsent_1   |?[0m { error: 'Could not retrieve validation key: {\"request\":\"2b5eee08-393b-4af4-8f5d-7a0f284d6539\",\"message\":\": : : json: cannot unmarshal array into Go value of type map[string]ladon.jsonCondition\",\"code\":500,\"description\":\"Could not unwrap\nerror of type *json.UnmarshalTypeError\",\"name\":\"internal-error\"}' }\n```\n. > Additionally is there documentation for how to specify the database connection to postgres or mysql ?\nNot yet, I will add that. Thanks for reminding me :) You can check the docker-compose.yml file though!\n\nThe flag \"--dangerous-auto-logon\" does not add the \"client_id:\" to ~/.hydra.yml.\nWhen I checked the hydra_client table there was no 'id' or 'client_name' set.\n\nThat's weird, it worked on my system. What was the command you ran? Did you set any environment variables? If so, which ones?\n. But this comment is the MySQL store, no? \n. Thanks, is the log file showing the client id?\n. Thanks, I made a patch :)\n. I only tested mysql store with a fixed client id / secret and apparently this bit is not covered by unit tests, whichi s why I missed it.\n. @andrewmcnamara per spec, client_id is the right value. we could add the aud claim too though. What's your use case?\n. https://tools.ietf.org/html/rfc7662#section-2.2\n\nclient_id\n      OPTIONAL.  Client identifier for the OAuth 2.0 client that\n      requested this token.\naud\n      OPTIONAL.  Service-specific string identifier or list of string\n      identifiers representing the intended audience for this token, as\n      defined in JWT [RFC7519].\n\nWe could include both, though. Btw BC breaks are part of the minor versioning and the reason why Hydra is not marked as stable (major version 1) yet. :)\n. > And you really need some way of marking an access token as a client credentials (subject-free) version.\nI don't think that the subject of a client credentials token should be empty. It should be the client id. In which case it's pretty easy to figure out by checking if client_id == subject.\n\nBut you use the Client ID as the AUD in the OpenID token now right?\n\nYes, this is why I offered two times to include the aud claim as well!\n. resolved #293\n. This can probably easily be solved by replacing go install github.com/ory-am/hydra with go install .\n. Ah yes, I forgot about that part. I'm not sure if this is what you suggested, but maybe there is a way to tell travis to put the source code in src/github.com/ory-am/hydra instead?\n. Looks like it's working almost! The culprit is now coveralls, which is trying to push the changes to coveralls.io but since the fork isn't registered there, this fails: https://travis-ci.org/emilva/hydra/jobs/166904073#L631\nOne idea might be to move this to after_success:\nBy the way, the way cfssl is doing it (https://github.com/cloudflare/cfssl/blob/master/.travis.yml#L20-L27) looks really cool, because it's just 2 lines of code without rsync dependency :)\n. Yes, Hydra builds only on Go 1.7 from now on\n. at least in the 0.6.0 branch\n. \ud83d\udc4d \n. What are you using the ROCP grant for? Mobile apps?. I don't fully understand your flow. Could you elaborate? In general, you can always avoid the ROCP grant. The IETF included it only for migration.. > Are we missing something or doing something wrong?\nA little bit, because you're mixing an authentication process with OAuth2, which is a protocol for delegating authorization. It leaves you vulnerable to attacks in certain scenarios / set ups.\nTo work with Hydra, you will need to set up a proper consent app. It does not sound like you have done so. But the consent app is the backbone of how Hydra works and delegates the authentication part.\nYou will be able to get the same user experience you have right now if you add a consent app. And then you can avoid the risky, outdated, and booed ROCP grant.\nWe help various businesses (especially in finance) with setting up a proper security architecture and finding the right fit for Hydra in it. We are also auditing existing security architectures and will hint to potential issues. If this is interesting to you, drop us a line at hi@ory.am. I took a long time for this issue, primarily because I felt very uncomfortable implementing it. The ROCP grant is something from the \"dark ages\" of OAuth2 and there are suitable replacements for mobile clients, such as public oauth2 clients, which are supported by Hydra: https://tools.ietf.org/html/draft-ietf-oauth-native-apps-09\nThe OAuth2 Threat Model explicitly states that the ROPC grant is commonly used in legacy/migration scenarios, and\n\nThis grant type has higher\n   risk because it maintains the UID/password anti-pattern.\n   Additionally, because the user does not have control over the\n   authorization process, clients using this grant type are not limited   by scope but instead have potentially the same capabilities as the\n   user themselves.  As there is no authorization step, the ability to\n   offer token revocation is bypassed.\nBecause passwords are often used for more than 1 service, this\n   anti-pattern may also put at risk whatever else is accessible with\n   the supplied credential.  Additionally, any easily derived equivalent\n   (e.g., joe@example.com and joe@example.net) might easily allow\n   someone to guess that the same password can be used elsewhere.\nImpact: The resource server can only differentiate scope based on the\n   access token being associated with a particular client.  The client\n   could also acquire long-lived tokens and pass them up to an\n   attacker's web service for further abuse.  The client, eavesdroppers,\n   or endpoints could eavesdrop the user id and password.\no  Except for migration reasons, minimize use of this grant type.\n\n\nsource\n\nThus, I decided to not implement the ROPC grant in Hydra. Over time, I will add documentation how to deal with mobile scenarios and similar.. ROPC is discouraged officially by IETF and must not be used for new applications. Since you implement and control the consent app, you can easily skip authentication for logged in users, or skip the consent step for internal clients:\n\nhttps://ory.gitbooks.io/hydra/content/faq/ropc.html\nhttps://ory.gitbooks.io/hydra/content/faq/mobile.html. Auth0 deprecated the terrible mess they made before they became an OpenID Connect certified provider. It's actually in the two links you posted.\n\n\n\nThey deprecated them because they are bad design and encourage insecure behaviour. I hope this answers your question.. Thanks! Could you please sign your commit with git commit -s --amend? :)\n. Thanks!\n. Thanks for reporting, I will investigate.\n. found the culprit, it's ladon. patch due soon\n. Yes, no more JSON fields\n. Thanks for noticing! What do you think a good substitute would be? \"Written in Go (Golang)\"?\n. I removed it from the repository description. Did you find that phrase anywhere else?\n. resolved :)\n. I think the easiest way is to run it on top of a PaaS, such as kubernetes or docker swarm. You get logging, health checking and restarting the service for free. Is that an option?\n. Thanks! Could you add a test case for it too? I think it should be enough to add the additional fields here and here.\n. Thanks!\n. if you have any proposals or ideas how to achieve that feel free to share them here!\n. I'm still not sure how to resolve this properly. Maybe only for priviledged clients?\n. Hm a message queue would add another depedency (what if you don't want to use rabbitmq). The most obvious way is to write a small SQL script that scans the subject and audience from the table and deletes the rows.\nI think there is no way around a dedicated endpoint that is protected, similar like the JWK endpoint.. Yes, this should in fact be a REST API in Hydra which is protected by ACL!. Absolutely!. I think the best way to support log out capabilities is by implementing OpenID Connect's Session Management Specs, specifically section 5. What do you think about this?. What OpenID Session Management Spec doesn't cover is the typical use case of revoking access of an application. I think that is also a valid aspect for this project, and I think it must also include revoking all granted access tokens per user.\nBanning users however should be done by creating a global ban policy such as\njson\n{\n  \"resources\": [\"<.*>\"],\n  \"actions\": [\"<.*>\"],\n  \"subjects\": [\"users\", \"to\", \"ban\"],\n  \"effect\": \"deny\"\n}\nassuming that you use access control policies for AC in your system.. Absolutely, as stated here, in the forums, and the chat, this will make it into the 1.0 release (blocking, so it won't be pushed further back). Just need a bit of free time to work this out.. Yes, basically you'll have to query the consent tables (one for authN, one for consent) and delete the responsible rows. That's how the REST API will handle this as well.. Since you're bringing this up, feel free to participate in #904 :). By the way, I don't think you can easily backport this, we had to resolve a bug in fosite which was merged in 1.0.0 (but not 0.11). The bug caused us to lose the chain of tokens (from consent to first issuance, to refresh, to refresh, ...). Also, the internal consent management is vastly different in 1.0 when compared to 0.11.\nMy personal recommendation is to participate in #904 and raise your use case. We'll try to find a good trade-off between complexity and security. Once merged, you should definitely move to 1.0 as 0.11 will no longer be maintained without a paid support SLA.. Fixed by #856 . Yes, server side does not support updating of policies right now. Currently it's solved by removing the policy in question and adding it with the new values.. Awesome, feel free to create a PR any time! There hasn't been any activity on https://github.com/ory-am/ladon/issues/38 so you would probably have to implement a store for that too\n. No, unfortunately it's not at the moment. But you can easily work around this by replacing localhost:4445 with the right host and port\n. Yes, it's primarily for demo purposes. Yes, for a new redirect url you would have to write an OAuth2 app and create an OAuth2 client in Hydra that allows that redirect url\n. hydra help clients create. hydra help token user. No it's not hardcoded, the URL in your browser shows 172.18.0.1, your callback URL here shows 127.0.0.1. That's two completely different domains, which might cause the error.. No, with redirect_uri=http%3A%2F%2F127.0.0.1%3A9010%2Fcallback (decoded redirect_uri=http://127.0.0.1:9010/callback) the redirect uri looks ok. Pretty sure it's something else, what's the output of:\nclients get --skip-tls-verify --id facebook-photo-backup. I like this idea, because currently this is only possible if you real-time watch the logs, and then, only if you don't have a lot of requests. Unfortunately, the RFC 7662 Sepcification says the following on this topic:\n\nNote that to avoid disclosing too\n   much of the authorization server's state to a third party, the\n   authorization server SHOULD NOT include any additional information\n   about an inactive token, including why the token is inactive.\n\nI'm not sure how to deal with this right now.\n. Sorry, I closed this accidentally.\n. Thank's, I'll clean that up!\n. Awesome analysis, thank you @cainjonm. #312. Awesome! @waynerobinson would you mind taking a look, too?. One more thing, could you add redis to the docker-compose.yml, so it's easy to spin up that environment and test it?. Ok, you still need to link to redis here and use redis instead of localhost here. thank you so much for your hard work, @115100 !. thank you for contributing!\n. I think both are valid (array and string) although array certainly leaves more options. Do you have a specific use case why this should work with Hydra? Because I don't think there is a way to have multiple audiences in hydra at the moment (it's always the client_id). ah I see, that makes sense!. Currently on the run, but I don't think the oidc thumbprint is currently \nimplemented. I'm open though to have that feature in Hydra, especially \nbecause it's a standard. I'll check the spec when I'm home.\nWhat would be even more awesome is a PR. You can ping me in gitter if \nyou want to tackle it!\nAm 01.12.2016 um 17:22 schrieb SonOfBytes:\n\nI'm looking to do a spike in using hydra as an ECS service that \nprovides AWS Console/API federated services using Open Connect ID.\nhttp://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc.html\nThe first hurdle I hit was that it appears the when setting up an \nidentity provider in AWS for Open Connect ID that it is hitting \n|/.well-known/openid-configuration|\nThis seems to be requesting a Thumbprint for the OIDC IDP\nhttp://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_providers_create_oidc_verify-thumbprint.html\nWhat is the best suggested way of delivering the requested thumbprint \nusing hydra?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub \nhttps://github.com/ory-am/hydra/issues/315, or mute the thread \nhttps://github.com/notifications/unsubscribe-auth/ADN1epj4gX9lr-dzk-uJ_U17CP8rbn5aks5rDvRMgaJpZM4LBl1F.\n\n\n. Jup that looks about right, still going to need the jwks discovery, which should also sort of look like this document (but point to the jwk sets instead). this is now implemented. Thanks! Please sign your commit with git commit --amend -s :). thanks!. thanks!. No SCIM is not supported. What is dex?. @jainh I'm so sorry, but I don't understand what you are saying. I see, Hydra itself is currently not working with SCIM. I am unfortunately very unfamiliar with SCIM itself and would have to study it first before I can give an answer if it is realistic that Hydra will support SCIM and if so, how that support would look like. The OpenID Connect Profile for SCIM Services draft is very young and quite sparse in description. For example, it's not clear to me where the metadata will be served.\nI fear that I can not help you right now, and SCIM is currently not a priority.. Sure, always open to pull requests!. As I said I don't know how SCIM works so I can't point you to the right parts. Unfortunately, you have to figure it out yourself. Feel free to come back if you have more specific questions.. Closing because we currently don't have capacities to implement SCIM compliance. Please ask on gitter if you have further questions.. Please, read the manual. It is explained how the docker-compose tutorial works.\nhttps://ory-am.gitbooks.io/hydra/content/tutorial.html. Unofrtunately, I can't reproduce this issue with the same chrome version. We are only using standard markdown in the readme (try opening it on it's own here). What usually helps is setting up a new chrome profile or cleaning cookies/cache. If nothing helps, please contact GitHub support. thanks!. Please read the docs and get familiar with Hydra. Hydra does not solve authentication, thus LDAP is not supported in Hydra. However, you can easily integrate LDAP in your authentication app.\n\nToken validation as a service ?\n\nI'm not sure what you're asking here.\nAlso, please chose appropriate issue titles.. closing as the question has been answered and response is pending. @johnwu96822 is this a critical issue for you?. see https://github.com/ory-am/hydra/pull/329/commits/070520d3d862e39ce1a199be7f50f95380ad7e1e. resolved by #329. Without knowing what the keys look like I can't help you.. No worries, we all make mistakes :). If you have open questions regarding this release, feel free to post them here.. Currently, the group check ignores ladon.DenyAccess if one of the other groups has ladon.AllowAccess. Same goes for subjects. But the order should be deny > allow > none. @kop absolutely, I wanted to do that for a long time but didn't manage yet. The idea would be:\n\nBoot database + hydra with docker\nConnect to it\nCreate a oauth2 client for the consent flow\nSet up the right policies\nCreate another oauth2 client for token validation\nGuard an API with it\nCreate another oauth2 client to perform the auth code flow\n\nWhat do you think?. We could probably start outlining it here, and it would be great to get some help with it :). https://github.com/ory/hydra/issues/385#issuecomment-284698726. this doesn't make a lot of sense, the warden should be separate from oauth2 scopes. Does this work on windows / linux / osx alike?. Because windows has \\r\\n right?. Cool, thanks for investigating!. https://github.com/ory-am/fosite/pull/131. This is resolved already. Currently not, it's tracked as #305 . I'll probably get to it in the next few days.. Closing as dupe :). Could you please include the original OAuth2 request? Hydra does support query param responses, but maybe you're using an implicit or hybrid flow?. You included &response_type=code%20id_token which implies an hybrid flow which is per spec implicit, meaning that you assume an app running on the client side only which requires a hashbang instead of a query parameter. In order to perform the request you want, you need to remove the id_token from the response_type. The openid scope is enough to return an ID token :). welcome!. Thanks for reporting, I think I know what the issue is. Go is encoding []byte values as base64 when using json.Encode() which leads to encoding the c_hash value twice here and isn't catched by the unit tests, as Go also base64 decodes the values when it finds a []byte slice in the struct. Obviously, other languages don't know about this and thus the values are invalid. Yes, I think the bug applies to all hashes!. I hope the commit above resolves this issue. Would you mind trying it out? The PR is #329. No unfortunately not, I'll just release it and fix it in the next minor release if there's still something wrong. I'll reopen if the issues persist. Ah, apparently the problem now is the padding, Go adds two equals E0GjRojb2VZyS0GbugtR3Q== but oidc-token-hash (used by open-id-client) requires no padding E0GjRojb2VZyS0GbugtR3Q. The problem itself is within the oidc-token-hash library, which uses predefined lengths to validate the input, but does not strip away padding:\n```\nconst LENGTHS = { 22: 'sha256', 32: 'sha384', 43: 'sha512' };\nconst ALGS = ['sha256', 'sha384', 'sha512'];\nfunction validate(actual, token) {\n  if (!actual) return false;\n  const alg = LENGTHS[actual.length];\n  if (!alg) return false;\n  return generate(token, alg) === actual;\n}\n```\nSince libraries should be able to deal with base64url encoding and padding (which is not omitted by default), I will create a patch for the dependency. I was not able to find information on padding in the oidc spec.\nThe patch is quite trivial:\njs\nfunction validate(actual, token) {\n  if (!actual) return false;\n  actual = actual.replace(/=+$/, '')\n  const alg = LENGTHS[actual.length];\n  if (!alg) return false;\n  return generate(token, alg) === actual;\n}. The PR is now here: https://github.com/panva/oidc-token-hash/pull/1\nPlease notify the maintainers of the change, maybe they need to upgrade their package.json. No, I'm not certain that the padding should be left in, but let's see what the maintainer says! The library (oidc-token-hash) does not seem to be certified and also not widely used (this was the first PR). Unfortunately, I could not find a oidc connect reference implementation for Go.. Yes, that one is certified, I'm just not sure if that includes the oidc-token-hash dependency :). Even the reference table on wikipedia is confusing :D\nhttps://en.wikipedia.org/wiki/Base64#Implementations_and_history. Let's wait and see what the maintainer says. I'm open to remove the padding, just want to make sure it's not a special case :). Ok, I think I'll just omit it then! Feel free to accept/close the PR :). Resolved with https://github.com/ory-am/fosite/releases/tag/v0.6.11. Ok, thanks for the quick response times!. @panva sorry if I ask so directly, but how did you get the library certified and did it cost money? I intend to get some certifications for this repo as well!. Awesome, thank you so much!. As stated in the docs, Hydra does not solve authentication itself and uses something called the consent flow to validate a user's identity. If you need LDAP, you need to implement an endpoint that is capable of performing the consent flow and that uses LDAP for authentication. You can read up on the consent flow in the docs. One image is missing in the docs (it's already fixed in a PR which isn't merged yet). It's this one. Might help to clarify some things.. Closing, feel free to ask on our gitter chat channel if you need help. Yes, swagger is OpenAPI spec so this is why it was chosen.. OpenAPI spec === swagger 2.0 spec. Superseded by #445. No, Neo4j will not be supported officially. You can always try to implement your own adapters, but they have to be maintained by you.. Which version of Hydra are you running? Do you think this is a regression issue of 0.7?. Also @janekolszak could you include the server side logs from hydra leading up to the error? They usually give better hints at what's happening, especially with LOG_LEVEL=debug. Through env vars:\nexport LOG_LEVEL=debug\nhydra host .... Did this error occur in the 0.6 release?. No, I'll try to reproduce it and let you know if I can't. @janekolszak could you please post the output of:\ncurl --header \"Authorization: bearer $(hydra token client)\" http://localhost:4444/clients/wta-d\n(I assume you're properly connected to the cluster with hydra connect). Found the issue. Fosite is checking wether the redirect URL is secure or not and returns false if not. In this case, since it's a custom protocol, it's saying: nope, that isn't secure.\nSee: https://github.com/ory-am/fosite/blob/master/handler/oauth2/flow_authorize_code_auth.go#L44-L46\nGoing to fix this with hydra 0.7.2, sorry for the inconvenience. yup. Superseded by 0.8.0 release. Wrong password?\nJan 02 21:55:18 p1 hydra[13275]: time=\"2017-01-02T21:55:18+02:00\" level=error msg=\"An error occurred\" error=\"crypto/bcrypt: hashedPassword is not the hash of the given password: Client authentication failed (e.g., unknown client, no client authentication included, or unsupported authentication method)\ncrypto/bcrypt: hashedPassword is not the hash of the given password: Client authentication failed (e.g., unknown client, no client authentication included, or unsupported authentication method)\". Not the user's password, but the password of your oauth2 client. The auth_code requires a client secret when exchanging the auth code for a token. You can however set the public flag to true in your client, then the client won't need a secret for that flow!. I believe the public flag is simply appending \"public\": true to the JSON body when you're creating the client at POST http://hydra/clients or by doing hydra clients create /* ... */ --is-public. Check the docs, section advanced iirc. Also, questions in chat or forum only please.\n\nOn 6. Sep 2018, at 05:50, OvermindDL1 notifications@github.com wrote:\nAny idea on how to add a \"public\":true to the client definition when the client is part of a remote website that is trying to auth to a local hydra server (do not that it works on other openid connect servers), or some override in hydra to imply \"public\":true?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. It\u2019s literally the first subsection in advanced: https://www.ory.sh/docs/guides/master/hydra/6-how-to/3-advanced#creating-a-public-oauth-20-client\n\nLinks to relevant forums and chatrooms as well as rules for opening issues are written in the issue template, the one you deleted when you opened this issue.\n\nOn 6. Sep 2018, at 17:53, OvermindDL1 notifications@github.com wrote:\nCheck the docs, section advanced iirc.\nI've been over those but I didn't find I way, I ended up mutating it on the nginx front-loader to get working.\nAlso, questions in chat or forum only please.\nAh very nice, where would those be located, what is the IRC room and on which IRC server? (I'm in console terminal 95% of my day so anything that works on the commandline is fine, I'm even using github right here and now from the commandline. :- ) )\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Ohhh I see, totally my bad then. I\u2019m also not using GH (only mail) at the moment and didn\u2019t see that it was an existing issue. Glad you got it resolved!\nOn 6. Sep 2018, at 18:39, OvermindDL1 notifications@github.com wrote:\nIt\u2019s literally the first subsection in advanced:\nHmm, I didn't make the connection, I don't know OAuth2 well, I'm setting this up for someone else to allow their other services to access their Discourse forum as the login source so I'm learning on the way. I do apologize for the noise!\nLinks to relevant forums and chatrooms as well as rules for opening issues are written in the issue template, the one you deleted when you opened this issue.\nAh, I didn't open the issue so I never saw it, issue templates don't appear in the comment on an issue. :-)\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. This is too auth0 specific. Thanks for the detailed report, it is very well possible that there's a bug somewhere. I'll try to reproduce it tonight, latest by tomorrow!. Ok I think I found the issue. The problem appears to be that you whitelisted 10.0.19.0/24 but are requesting from localhost. Because localhost is not whitelisted, it actually rejects all requests that do not come from 10.0.19.0/24. Thus you get a Can not serve request over insecure http as localhost is not whitelisted.\n\nI think there are two possibilities here:\n\nOpen two ports, one for http and one for https\nAllow to whitelist more than one range 10.0.19.0/24,127.0.0.0/24\n\nBoth options are viable. What do you think?. Ahh, yes, that makes sense! There is currently no way to fake that, you could however use the REST API with Postman for now - which of course isn't ideal - until I come up with a solution.. Almost all CLI commands have a --dry option which prints the corresponding curl command. That way you could also make the requests using curl. Sounds like a good workaround!. https://github.com/ory/hydra/commit/79580e1ea9f28ed0298436dc7f8f0e611e8f5f34. upstream: https://github.com/ory-am/ladon/issues/45. closing due to #378. Most API gateways can solve this, in the example of kong, preserve_host and strip_tag are the settings to look for.\nClosing as this has been open for a while and you guys have fixed this.. Yeah that makes sense, I would also add a check whether or not the endpoint is https or not (disallow https). Would you mind doing a PR?. Sorry, I meant disallow http for everything except localhost. This is no longer the case. Thanks for the work! The ultimate goal is to have a section in the docs on running hydra in production - so we could probably add it there (or in the FAQ). We now have a section on the deployment environment and some examples - but it still is up to each environment how the deployment actually works. Thus, I'm closing this issue. We did that and also hint that oauth2 knowledge is actually required for this project (why else would you want to become an oauth2 provider). See #707. Thanks!. Could you please sign your commit? git commit --amend -s. Thanks!\n. Unfortunately, this is currently not implemented and there is currently no plan to do so, but I welcome PRs and will put it on the backlog. Removed from the backlog as this is now an issue in Keto. Feel free to reopen there and discuss possible PRs.. Yup:\nmysql> SHOW PROCESSLIST;\n+----+------+------------------+-------+---------+------+----------+------------------+\n| Id | User | Host             | db    | Command | Time | State    | Info             |\n+----+------+------------------+-------+---------+------+----------+------------------+\n|  3 | root | 172.18.0.4:38756 | mysql | Sleep   |   21 |          | NULL             |\n|  4 | root | localhost        | NULL  | Query   |    0 | starting | SHOW PROCESSLIST |\n|  5 | root | 172.18.0.4:38782 | mysql | Sleep   |   21 |          | NULL             |\n|  6 | root | 172.18.0.4:38786 | mysql | Sleep   |   20 |          | NULL             |\n|  7 | root | 172.18.0.4:38790 | mysql | Sleep   |   20 |          | NULL             |\n|  8 | root | 172.18.0.4:38794 | mysql | Sleep   |   20 |          | NULL             |\n|  9 | root | 172.18.0.4:38798 | mysql | Sleep   |   19 |          | NULL             |\n| 10 | root | 172.18.0.4:38802 | mysql | Sleep   |   19 |          | NULL             |\n| 11 | root | 172.18.0.4:38806 | mysql | Sleep   |   19 |          | NULL             |\n| 12 | root | 172.18.0.4:38810 | mysql | Sleep   |   19 |          | NULL             |\n| 13 | root | 172.18.0.4:38814 | mysql | Sleep   |   18 |          | NULL             |\n| 14 | root | 172.18.0.4:38818 | mysql | Sleep   |   18 |          | NULL             |\n| 15 | root | 172.18.0.4:38822 | mysql | Sleep   |   18 |          | NULL             |\n| 16 | root | 172.18.0.4:38826 | mysql | Sleep   |   17 |          | NULL             |\n| 17 | root | 172.18.0.4:38830 | mysql | Sleep   |   17 |          | NULL             |\n| 18 | root | 172.18.0.4:38834 | mysql | Sleep   |   17 |          | NULL             |\n| 19 | root | 172.18.0.4:38838 | mysql | Sleep   |   17 |          | NULL             |\n| 20 | root | 172.18.0.4:38842 | mysql | Sleep   |   16 |          | NULL             |\n| 21 | root | 172.18.0.4:38846 | mysql | Sleep   |   16 |          | NULL             |\n| 22 | root | 172.18.0.4:38850 | mysql | Sleep   |   16 |          | NULL             |\n| 23 | root | 172.18.0.4:38854 | mysql | Sleep   |   15 |          | NULL             |\n| 24 | root | 172.18.0.4:38858 | mysql | Sleep   |   15 |          | NULL             |\n| 25 | root | 172.18.0.4:38862 | mysql | Sleep   |   15 |          | NULL             |\n| 26 | root | 172.18.0.4:38866 | mysql | Sleep   |   14 |          | NULL             |\n| 27 | root | 172.18.0.4:38870 | mysql | Sleep   |   14 |          | NULL             |\n| 28 | root | 172.18.0.4:38874 | mysql | Sleep   |   14 |          | NULL             |\n| 29 | root | 172.18.0.4:38878 | mysql | Sleep   |   13 |          | NULL             |\n| 30 | root | 172.18.0.4:38882 | mysql | Sleep   |   13 |          | NULL             |\n| 31 | root | 172.18.0.4:38886 | mysql | Sleep   |   13 |          | NULL             |\n| 32 | root | 172.18.0.4:38890 | mysql | Sleep   |   12 |          | NULL             |\n| 33 | root | 172.18.0.4:38894 | mysql | Sleep   |   12 |          | NULL             |\n| 34 | root | 172.18.0.4:38898 | mysql | Sleep   |   12 |          | NULL             |\n| 35 | root | 172.18.0.4:38902 | mysql | Sleep   |   11 |          | NULL             |\n| 36 | root | 172.18.0.4:38906 | mysql | Sleep   |   11 |          | NULL             |\n| 37 | root | 172.18.0.4:38910 | mysql | Sleep   |   11 |          | NULL             |\n| 38 | root | 172.18.0.4:38914 | mysql | Sleep   |   11 |          | NULL             |\n| 39 | root | 172.18.0.4:38918 | mysql | Sleep   |   10 |          | NULL             |\n| 40 | root | 172.18.0.4:38922 | mysql | Sleep   |   10 |          | NULL             |\n| 41 | root | 172.18.0.4:38926 | mysql | Sleep   |   10 |          | NULL             |\n| 42 | root | 172.18.0.4:38930 | mysql | Sleep   |    9 |          | NULL             |\n| 43 | root | 172.18.0.4:38934 | mysql | Sleep   |    9 |          | NULL             |\n| 44 | root | 172.18.0.4:38938 | mysql | Sleep   |    9 |          | NULL             |\n| 45 | root | 172.18.0.4:38942 | mysql | Sleep   |    9 |          | NULL             |\n| 46 | root | 172.18.0.4:38946 | mysql | Sleep   |    8 |          | NULL             |\n| 47 | root | 172.18.0.4:38950 | mysql | Sleep   |    8 |          | NULL             |\n| 48 | root | 172.18.0.4:38954 | mysql | Sleep   |    8 |          | NULL             |\n| 49 | root | 172.18.0.4:38958 | mysql | Sleep   |    7 |          | NULL             |\n| 50 | root | 172.18.0.4:38962 | mysql | Sleep   |    7 |          | NULL             |\n| 51 | root | 172.18.0.4:38966 | mysql | Sleep   |    7 |          | NULL             |\n| 52 | root | 172.18.0.4:38970 | mysql | Sleep   |    6 |          | NULL             |\n| 53 | root | 172.18.0.4:38974 | mysql | Sleep   |    6 |          | NULL             |\n| 54 | root | 172.18.0.4:38978 | mysql | Sleep   |    5 |          | NULL             |\n| 55 | root | 172.18.0.4:38982 | mysql | Sleep   |    5 |          | NULL             |\n| 56 | root | 172.18.0.4:38986 | mysql | Sleep   |    5 |          | NULL             |\n| 57 | root | 172.18.0.4:38990 | mysql | Sleep   |    4 |          | NULL             |\n| 58 | root | 172.18.0.4:38994 | mysql | Sleep   |    4 |          | NULL             |\n| 59 | root | 172.18.0.4:38998 | mysql | Sleep   |    4 |          | NULL             |\n| 60 | root | 172.18.0.4:39002 | mysql | Sleep   |    4 |          | NULL             |\n| 61 | root | 172.18.0.4:39006 | mysql | Sleep   |    3 |          | NULL             |\n| 62 | root | 172.18.0.4:39010 | mysql | Sleep   |    3 |          | NULL             |\n| 63 | root | 172.18.0.4:39014 | mysql | Sleep   |    3 |          | NULL             |\n| 64 | root | 172.18.0.4:39018 | mysql | Sleep   |    2 |          | NULL             |\n| 65 | root | 172.18.0.4:39022 | mysql | Sleep   |    2 |          | NULL             |\n| 66 | root | 172.18.0.4:39026 | mysql | Sleep   |    2 |          | NULL             |\n| 67 | root | 172.18.0.4:39030 | mysql | Sleep   |    2 |          | NULL             |\n| 68 | root | 172.18.0.4:39034 | mysql | Sleep   |    1 |          | NULL             |\n+----+------+------------------+-------+---------+------+----------+------------------+. https://github.com/ory-am/ladon/commit/511d561a9a22e6f1c9eda4859673721c56375a23. > But there is no linking of usernames to tokens in Hydra so when introspection is done with Hydra, there is no concept of which user the token was requested for. \nThis isn't true. The subject (user, app, server) that authorized the token is displayed by the sub value when you perform the token introspection. If this doesn't answer your question I'll read through the rest of the issue.. The aud value is the subject the token is intended for. Example:\nClient cool-app asks user peter for his consent on issuing an access token. peter allows it. Therefore, on token introspection, you'll get:\naud: cool-app\nsubject: peter\nexp: ...\niat: ...\n.... Oh, I misunderstood you then. I think you're confused about the OAuth2 flows, I highly recommend reading: https://www.digitalocean.com/community/tutorials/an-introduction-to-oauth-2\nTL;DR the client_credential flow does not involve a user. The flow is intended for programmatic APIs that require an access token. If you're looking for getting a token on behalf of a user, use the implicit or authorize_code flows. You're welcome. Always happy to be of help :). Hydra is setting a cookie for validating an anti-replay token. Are you using Hydra behind a proxy/firewall?. Then it seems to be an issue with the cookie that is being set in incognito mode. Did you switch tabs in between or something?. I can't reproduce this, neither in firefox nor in chrome incognito/private mode. Maybe you have some strange plugin or setting in your browser that is causing this.. Closing due to inactivity. > cookie consent_session is the problem.... This should be resolved already.. Could you share the log entry?. Also, do you have, by any chance, set LOG_LEVEL=debug? It would include the stack trace in that case which would be really helpful. Please upgrade to Hydra 0.7.x it should resolve some issues :). Closing because this didn't come up again. This is happening because you append consent=false where false is not a valid token. Of course, Hydra should throw an error instead of panic. Thanks!. Ah I understand your thinking. The idea was that the consent app would simply show an error, but of course it makes sense to be redirected to the original app. I've tracked this as: #371. This will be handled in the future in some way, in the meanwhile you can implement your own error handling if you want to. No it's not, but fosite is :). This means that no policy was found for the request you made. This could either be because no policy exists for creating clients, or because the client id you are using to make this request is not included by the policy in question.\nIt's possible that this doesn't work because the values in your ~/.hydra.yml file changed.. Closing due to inactivity. Sounds good! We could probably provide an additional docker image flavor that uses this feature!. According to this article golang should do that automatically?. Ah, it seems to have changed with Go 1.5. Do you know how this needs to be done with Go 1.7 / 1.8 @dereulenspiegel ?. That is very likely caused by the base go image. Unfortunately, the \nalpine version doesn't work out of the box because we need git and \nmercurial for go get. The first step would to get hydra working on \nalpine. The hydra binary is (even with debugging symbols) only a few megs.\nAm 13.02.2017 um 15:31 schrieb Till Klocke:\n\nThe command I posted in the initial ticket is a variant of the command \nhow I currently build most of my service under Go 1.7. It creates \nstatically linked binaries (as long as CGo isn't used) without \nproblems and also strips debugging symbols (saving around 30% of the \nbinary size).\nI finally tried your official docker container and was a bit shocked \nthat clocks in at several hundert MB. I think reducing image size is \nvery welcome for many users.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub \nhttps://github.com/ory/hydra/issues/374#issuecomment-279407752, or \nmute the thread \nhttps://github.com/notifications/unsubscribe-auth/ADN1evlkkKwuus7sD86VdLXCiGN7b2KPks5rcGk-gaJpZM4L09cE.\n\n\n. Building it outside of docker is an option, however it would be kinda tricky with the CI toolchain right now because that works like this:\n\ngit tag (via github releases)\ntravis runs tests and builds binaries for github releases\non success, docker hub pulls code\ndocker hub builds image\ndone\n\nIf we build it outside, it would need to be like this:\n\ngit tag (via github releases)\ntravis runs tests and builds binaries for github releases\non success, travis builds docker image with the right binary\non success, travis pushes images to docker repo (can't be the same like right now because docker hub repository settings are extremely limited)\ndone\n\nThis however could be a bit error prone when a part of the CI toolchain fails and there's no easy way to restart only one piece of the chain.\nMaybe preparing an alpine image that supports Go is one way to go, so basically install git, mercurial and go and be done with it. It would probably reduce the size significantly anyways. Squeezing out the last megs would then be a task for the future.\nWDYT?. Awesome, thank you for sharing this!. I didn't know the image is actually 1.2GB large (that's a lot, wow). \noryd/hydra                       latest              c59ae127571e        About an hour ago   1.12 GB\nI was able to get alpine working, bringing it down to:\n<none>                           <none>              55ce844f29d7        About a minute ago   727 MB\n... still a lot but hey, 35% less is a start!. It seems that most of the size comes from the image itself:\ngolang                           1.8-alpine          bcb935bbf1da        3 days ago           257 MB\nas well as ~80mb worth of git and also the vendor directory. Next I'll remove the src after build in the docker image. Let's see where that gets us. I brought it down to 700megs for now. The largest layer is probably the git package. Tackled in https://github.com/ory/hydra/pull/396. @michael-golfi thanks for this, yes scratch makes a lot of sense when building statically. I need to refactor the build pipeline for this however and move the docker push command to travis.. This took longer than it should have, but they say: better late than never!\nhttps://github.com/ory/hydra/pull/645. What do you understand as \"native login\"?. I think this would be possible with the password client credentials flow which I haven't implemented yet: #297. Sorry, I'm not sure what you're asking, but yet the #297 proposal is for the Password Grant. closing due to inactivity. Is there an alternative to \"latin1\"? I'd like to keep utf8 because we store json data which is (usually) utf8 encoded. Is reducing the key size a possibility? uuid use 32 only anyways so if we quadrupel that (128) we're still ready for some long af keys. Another issue is that we need to alter the table's charset which may cause cruel conversion errors (at least that was the case a few years ago) which are really hard to recover from (LAMP nightmares). So I'd like to find a solution that is less prone to error.. The issue is that the default id generation is uuid but it can be overriden by the user in some cases (e.g. clients), so we can't force uuid here, unfortunately.. But would reducing the key size resolve the issue described?. One difficulty is that we don't know the primary key constraint's name, as it was not forced during table construction:\nCREATE TABLE IF NOT EXISTS hydra_warden_group (\n    id          varchar(255) NOT NULL PRIMARY KEY\n)\nI'm not sure if the index name is the same on mysql/mariadb/postgres across versions. So I actually don't know how to write a ALTER  TABLE statement for this that works everywhere. Any ideas?. Yeah that makes sense. I don't think it would be wise to have different versions around. It might make sense to fix that for the 1.0.0 release and let people know who used prior versions that they need to upgrade the key length themselves.. Creating and updating database schemas is now a separate command (hydra migrate dsn://tosql), does this help here?. Yeah this should definitely be addressed in the 0.10.0 branch. I think VARCHAR(128) should already be more than enough. The best thing would be to write a migration set for using that varchar length and I gladly accept a PR for that. Keep in mind that it might become a bit tricky when it comes to updating the keys as well.. An alternative would be to move the current primary key to a surrogate key with a unique index and use a (maybe unqueriable) auto-increment INT primary key. That way we could even allow larger keys than 255 for the surrogate key whilst being nice to ops and generally more interoperable. What do you think?. I want to quickly re-iterate my reasoning here:\n\nBy using a SERIAL (or auto_increment) we'll be using INTs for the primary key which will in turn gain some significant performance improvements over large JOINs (the case for policies)\nBy using the surrogate ID for querying through the public API it's still possible to allow large ID names, fast lookup and unguessability (in case of using hashes for IDs)\n. Here's a quick PR I drafted out for showing you what I mean by that exactly: https://github.com/ory/hydra/pull/642\n\nPlease note that this is only PostgreSQL so far but it should be equally easy for mysql.. I agree that this should be addressed, I'm currently preoccupied with some other things but I definitely want this to land in 0.10.0. Oh snap, that is truly unfortunate. We certainly shouldn't remove indices from the surrogate_id since that will be queried often. Are there any other options?. I think we could live with going for 191 length surrogate_id (I became quite fond of the idea of using a surrogate id!) here.. I would love that! Before you start, how would you migrate FOREIGN KEY relations? We have two modules using those:\n\nwarden/group: https://github.com/ory/hydra/blob/master/warden/group/manager_sql.go#L36\npolicies: https://github.com/ory/ladon/blob/master/manager/sql/manager_sql.go#L83-L102\n\nI think that, if you solve the migration for the first module, the second module will work the same way. My idea so far was to (table A being the table, that table B has a foreign relation to):\n\nDrop the foreign key from B\nMove id to surrogate_id in A\nAlter surrogate_id to VARCHAR(191) in A\nCreate a new primary key id SERIAL (postgres) and id INT AUTO_INCREMENT in A\nMove the foreign key column in B to <fk_column>_surrogate_id and change to VARCHAR(191)\nCreate a new column <fk_column>_id with INT\nCreate a more complex query that does roughly:\nSELECT A.id FROM A WHERE A.surrogate_id = <the surrogate value from column B> \nUPDATE B SET (id= <select value from above>\nRe-add the foreign keys\nChange the VARCHAR lengths to 191 in previous migrations as they will only affect new systems\nWrite a big fucking warning in HISTORY.md :D. Thank you for the thorough investigation! Reducing some of those keys that drastically is indeed a bit tricky, especially with the compiled fields in ladon_action/ladon_resource etc. Regarding some of the others:\n\n\nhydra_jwk table: sid 255 -> 95, kid 255 -> 95\n\nWe could split those into two columns, right?\n\nhydra_warden_group_member table: member 255 -> 95, group_id 255 -> 95\n\nIs this due to the composed primary key?\n\nOne question I have though is, we're using MySQL 5.7 from library/docker for integration tests - why aren't those catching these issues?. > Is it possible to construct different create table statements for MySQL vs Postgres? If so, then appending \"row_format=dynamic\" to MySQL create-table statements is an easy way to enable large-key support in MySQL 5.5 and 5.6 (along with setting the other three values). This would avoid having to reduce the keys sizes.\nYes that is possible, it would also probably be the cleanest solution for now.. Yes that looks good. In ladon, we already separate between postgres and mysql so you would simply append the row_format there. For the other cases where the same schema is used it would be ok to have a helper function such as enhanceSqlSchema(schema string, driverName string) which would wrap the first up statement.. Awesome!. I'm closing this because it was added to the limitations section of the docs. It's unlikely that we'll change this. We don't have extensive foreign key relations which means that shortening private keys doesn't make a lot of sense (apart from this issue), as we always query the long ID. I think all cloud providers are on 5.7+ anyways today and there is a workaround for older installations which is documented in this issue.. There are no changes require in fosite. Instead, we need a consent url here and use that value (if it exists) here. This issue is no longer valid. The risky part of this is that third party clients could register malicious consent apps for phishing user passwords. Adding ACL to this piece complicates the hydra set up more and adds a potential security hole. Thus, this will not be supported in Hydra.. What do you think about implementing a minimalistic discovery file containing all the required fields but none of the optional?. I think you misunderstood. What I was suggesting is implementing this endpoint in hydra, but in a minimalistic version because Hydra does not support all of the things there.. How would this be handled in case of the path? Because http://foo/authorizeSomething is not the same resource as http://foo/authorizesomething.. Makes sense!. The fix is here. Unfortunately due to the moving of orgs the build isn't working currently. Might take a bit of time to fix this, sorry.. Hm, are you sure that you're running version 0.7.7? I checked the code and it looks like this issue 4f931cd6097d9fb7c45f4569f624fb42a5e76f19 which that was resolved in > 0.7.2. Hm, I can't reproduce this, at least on windows:\nC:\\Users\\foobar\\Downloads>hydra-windows-amd64.exe version\nVersion:    v0.7.7\nGit Hash:   868a02b376ad699be9512b20d6fd40f515f0a00f\nBuild Time: 2017-02-21 21:30:32.4132341 +0100 CET\nAre you sure the binary you're running is actually the one you downloaded?. on linux neither:\n$ wget https://github.com/ory/hydra/releases/download/v0.7.7/hydra-linux-amd64\n$ ./hydra-linux-amd64 version\nVersion:    v0.7.7\nGit Hash:   868a02b376ad699be9512b20d6fd40f515f0a00f\nBuild Time: 2017-02-21 21:31:50.9682054 +0100 STD. It depends on the error. If the error is an explicit deny, then propagation is stopped. If the error is \"meh I don't know what to do with this\", then other policies are consulted.. More explicitly:\n```\n    // let's consider all policies the user might belong to\n    for k, g := range groups {\n        errs[k+1] = w.Warden.IsAllowed(&ladon.Request{\n            Resource: a.Resource,\n            Action:   a.Action,\n            Subject:  g,\n            Context:  a.Context,\n        })\n    }\n    // range all errors, if one of them forcefully denies the request, quit\nfor _, err := range errs {\n    if errors.Cause(err) == ladon.ErrRequestForcefullyDenied {\n        return errors.Wrap(fosite.ErrRequestForbidden, err.Error())\n    }\n}\n\n    // check if one rule returned \"ok\"\nfor _, err := range errs {\n    if err == nil {\n        return nil\n    }\n}\n\n    // no rule returned \"ok\", defaulting to deny\n    return errors.Wrap(fosite.ErrRequestForbidden, ladon.ErrRequestDenied.Error())\n\n```. No, it's a bug. Thanks!. > Even though RethinkDB which hydra uses by default I did see that few functionalities wont works in RethinkDB and Redis.\nRethinkDB is not the default storage, MySQL and Postgres are the only officialy supported and maintained adapters.\n\nAny performance benchmark against using different supported storage\n\nGood idea!. Outline for blog post on deploying hydra on google container engine with google cloud sql, follow up to \nhttps://github.com/ory/hydra/issues/330#issuecomment-284354389\nTHIS IS WORK IN PROGRESS! The idea is to have a guide that is specifically targeted at kubernetes, but also includes some general advice on getting hydra up and running.\nNotes\n\nDon't use : in client ids as it will trip basic auth (see so)\n\nSetting up GCE and GCSQL\nPretty straight forward, maybe include screens.\n\nAllow GCE to access SQL: https://cloud.google.com/sql/docs/mysql/connect-container-engine\nMake sure the database exists\n\nSetting up pods\nHydra\nhydra.deploy.yaml\nSetting log level to debug helps finding bugs. We use http because of tls edge termination (could be more sophisticated). Also note that replicas could be anything.\nyaml\napiVersion: v1\nkind: Deployment\nmetadata:\n  name: hydra\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        service: hydra\n    spec:\n      containers:\n      - env:\n        - name: LOG_LEVEL\n          value: debug\n        - name: CONSENT_URL\n          value: !!!!!!!!!!!!!!!!!! TO BE DONE !!!!!!!!!!!!!!!!!!!!!!\n        image: oryd/hydra:v0.7.7-http\n        name: hydra\n        resources: {}\n      restartPolicy: Always\nstatus: {}\nhydra.secret.yaml\nyaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hydra\ntype: Opaque\ndata:\n  SYSTEM_SECRET: somesecret\n  DATABASE_URL: !!!!!!!!!!!!!!!!!! TO BE DONE !!!!!!!!!!!!!!!!!!!!!!\n  FORCE_ROOT_CLIENT_CREDENTIALS: !!!!!!!!!!!!!!!!!! TO BE DONE !!!!!!!!!!!!!!!!!!!!!!\nConsent app\nconsent.deploy.yaml\nyaml\nTO BE DONE\nDeploy secrets & pods\nkubectl apply -f hydra.deploy.yaml\nConfigure hydra\nConsent app client\nCreate\nPolicies\nResource provider client\nCreate\nPolicies\nThird-party OAuth2 client\nCreate\nPolicies\nProtect resource provider\nPerform auth code flow. Thanks for the feedback, I'll try to incorporate the feedback as best as possible. The freezing pages are unfortunately out of my control :/\nBy the way, you can always create a PR for the docs, they're located here: https://github.com/ory/hydra/tree/master/docs. Done. > I'm not a novice programmer and am finding it exceedingly difficult to get this set up and running. Maybe because I don't have familiarity with Docker and the instructions in https://ory.gitbooks.io/hydra/content/install.html do not seem to work (at least not on the AWS EC2 Windows or Linux instances I tried) (it breaks at \"docker exec -i -t hydra_hydra_1 /bin/sh\").\nYou must be reading an old guide. Please make sure to hit F5. If you need a shell in the docker container you can use tags appended with -alpine.\nAnother possibility is that you are mixing up the lengthy installation guide with the 5 minute tutorial which indeed is broken. Tracked #717\n\nI personally think that the using Docker in the installation+config guide is just horrible, for so many reasons-- not the least of which is that when you are done following the installation steps, you are left with something you can't use for production-- but, for what it's worth, and without trying to debate the worthlessness of using Docker, what I would really, really like to see to get started is a very simple set of commands and then examples:\n1. Installation via source or binaries\n\nAgain, not sure what guide you are reading, but this is covered here: https://ory.gitbooks.io/hydra/content/install.html#install-ory-hydra-without-docker\n\n\nList of external components necessary for a production deployment e.g. postgres. No need for installation instructions assuming the external component is well documented (which postgres is)\n\n\nGood point, tracked here: #716\n\n\nOS-independent configuration scripts, such as a SQL file that will set up the requisite postgres environment (create database, create table, etc-- this is also helpful because in itself this script helps to document the database structure that hydra uses), and/or sample hydra config files.\n\n\nThis is probably because you haven't gotten so far yet, but hydra migrate takes care of database migrations, which is pretty standard in software projects today.\n\n\nThis should take care of any \"seeding\" of the database needed to set up e.g. root admin, keys, etc\n\n\nHydra creates a root client and required cryptographic keys, which is documented, on first initialization.\n\n\ncurl commands for each of the critical operations that hydra provides via the REST api (create users, create policies, assign users, query actions, yada yada)\n\n\nNot only does Hydra make this easy using a CLI (hydra help), the whole API is documented using swagger. Link is in the Readme (it's http://docs.hydra13.apiary.io/# )\nDoes this help? If so, why didn't you find these links? Can this be improved somehow? Was the primary reason that the first tutorial is broken which caused frustration and cross-reading? Asking for a friend...so he can improve the docs ;)\n. Actually, mixing up the 5 minute tutorial and the lengthy one has happened twice so far, thus tracked as #718. Thank you for your input, duly noted. The 5 minute tutorial will be fixed, it's actually just replacing the Dockerfile in the docker-compose config. I'm currently working on something bigger which has my focus but since it's tracked I'll get to it afterwards.\nThe ory.am guide is actually the same as the one from GitBook but for an older version branch (0.9.x). I am a bit confused by:\n\n(though I haven't tried them so I can't comment on how well the commands work). Only problem is that the setup commands failed for me.\n\nI'm not sure if the commands worked or not. They should work though.\nRegarding Docker - it's very standard today and we recommend running the software in Docker. Hydra is based on 12 factor principles and thus \"cloud-native\" - which basically means that the ephermal file system of Docker doesn't mess with Hydra, and that it supports autoscaling. Having Docker installed is very common today and it's actually easier to do than downloading and configuring a bunch of environment dependencies such as PostgreSQL, NodeJS, Golang. If you haven't gotten around to it yet, I highly recommend giving Docker a second try. Not sure where your bad experiences come from, but if used correctly, it's an awesome piece of technology that makes application packaging so much easier.\nThe Apiary docs support CURL examples, although those might not work completely. Getting swagger to work properly with Apiary is such a headache, writing down those commands manually is insanity. I'm still looking for a better option.\n\nThe idea of the 5 minute tutorial with docker-compose is in fact exactly the simple install+base config. You're just out of luck that you where the one to catch the error.\nHaving said all that your feedback is highly welcomed. If things are hard to understand it is almost never the person reading it, but the person writing it. As part of our efforts to provide a richer suite of API security tools ( https://www.ory.am/products/api-security ) we are also refactoring the docs and putting everything in one place - API docs, guides, examples (which are definitely missing currently). Once our offering is done, it will be even easier (sign up and spin up a test instance) to see this thing in action.\nIn any case, I hope this experience isn't too frustrating, and you are able to get it working very soon.. Forgot two things:\n\nThe feedback regarding the endpoints is very important. I'm not sure how in-depth we'll go with OAuth2 endpoints, as a basic understanding is required for using Hydra, otherwise it's likely the wrong technology. Everything else has to be documented better, preferably in the guide.\nMigrations are currently stored in code. This won't change because otherwise we can't ship one binary, but have to ship the SQL files together with the binary, which sucks (bigtime).. The tutorial is fixed once #721 is merged and v0.10.10 is tagged. Enjoy!. Ah, it's actually https://gitter.im/ory-am/hydra. I don't like enforcing metadata, but what we could do is have an embedded JSON struct that is arbitrary. This has moved to keto, feel free to create an issue or a PR that solves this there.. This is already possible with the import command which allows to define more than one file.. nvm. Thanks!. Please sign your commit with git commit -s --amend :). Thanks!. Thanks, looks pretty solid. I'll take a closer look next week!. Thank you for your contribution!. Hi, indeed I already have that in place. I'll submit a PR next week. See https://github.com/ory/hydra/issues/374#issuecomment-284713870. No problem :)\n\nVon meinem iPhone gesendet\n\nAm 10.03.2017 um 13:22 schrieb Nicholas Young notifications@github.com:\nClosed #393.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I explicitly warn you to not use access tokens as proof of identity. Do not create user accounts based on access tokens. Use either id tokens or an access code provided by facebook.\n\nHaving said that, yes this is possible because hydra does not manage user accounts. Simply implement this founctionality in your app and you're good to go.\n\nAm 15.03.2017 um 01:31 schrieb mattwoolnough notifications@github.com:\nI have a requirement where a user connects to my API and presents a Facebook access token retrieved using the Facebook iOS SDK Login .\nIs this possible to configure this type of approach using Hydra? I can't see a way to create a user without them entering detail into the Consent App, which in this scenario is not required as it occurs in the SDK.\nIs this possible to do in Hydra?\nmW\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Using the access code is ok :) Using an access token would not be ok. I'm closing this because the problem is not part of hydra, feel free to ask questions on gitter though :). I can reproduce this. Sorry, no, I actually can't. I accidentally used the wrong access token. Attached are screens proof that this should work:\n\nWith basic auth:\n\nWith bearer auth:\n\nProof that allow termination is set:\n\n. @dereulenspiegel can I close this?. Has your client been issued a username / secret with special characters? There is a bug that breaks compatibility with some libraries, as fosite doesn't www-url-decode the client id / secret from the auth header. This is tracked as https://github.com/ory/fosite/issues/150. Thank you for reporting this. https://github.com/ory/hydra/commit/48c229b62af56ab16f26e827b221b9e04bb0c077. This will not be done as part of our official community work and will only be accepted as a PR by a maintainer who commits to maintaining the mongodb adapter over the next 2 years.. I honestly appreciate your input, but unfortunately it will not happen :(\n\nAm 20.07.2017 um 21:39 schrieb Alexander Trauzzi notifications@github.com:\nJust jumping in to say it would be nice to see an officially supported mongodb driver made available.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Now more than ever it is clear that MongoDB and NoSQL is absolutely not the right database engine for this project. Without strong consistency, atomicity, transactions, and ON DELETE CASCADE or similar we'll leave several gates open. Projects like CockroachDB (to be supported in the future) allow to run SQL across AZs in a HA way. We won't support MongoDB but you can always fork the project and write a MongoDB adapter yourself.\n\nFor us, the core maintainers, it is clear that this is not going to happen for the core, because it doesn't make sense to use a hammer for a screw.. Hey @matteosuppo , glad you're still around :)\nThe reasoning behind using \"2017-03-27T13:21:49.188993Z\" is that this is actually the standard json time format while the integers are actually 64bit floats (because javascript) that represent unix timestamps. Unfortunately, the unix timestamp format is what the introspection spec says. You're right that this represents an inconsistency but I think that the warden endpoint should serve the \"best\" & interoperable data possible, which is why this format was chosen.\nI'm open to changing this, although I need to be convinced first :). Awesome, thats cool news! I would be interested in your deployment and how hydra performs, could we maybe jump on a quick discussion on gitter for this? :) It would help me weight future features and issues!. Thanks, could you please sign your commit with git commit -s --amend? . Thanks!. Thanks, that works for now :). Awesome! :). Superseeded by #427 . Thank you!. What link was broken? Could you supply a PR for the broken link? I might have missed some docs.. Ah I see :) The file for that is here. Ah, actually, the link there is correct. Apparently there's an issue with the gitbook sync - reopening for tracking this. Resolved. Thank you! Could you supply a PR? The file is here :). Thanks!. It will not be part of our community efforts. If you want to tackle it yourself, you will need to implement the various managers, for example this one. If you want us to implement it, drop us a line at hi@ory.am. I'm closing this because it won't be part of our open source work and I think the question has ben answered. If it supports the golang pg driver, then you should be able to connect to it with postgres://mycockroachdb:123/database, but please be aware that we can't support that as part of our community effort.. The golang codebases will not be moved, to keep BC. Only new repos will use ory. So keep using ory-am where it says so in the readme :). no, there's a redirect: https://github.com/ory-am/hydra. Thank you! this has been bugging a lot of people :). Oh, could you please sign the DOC with git commit --amend -s. Thank you!. Is this a draft? It does not look like the consent URL is used anywhere.\nI feel very uncomfortable with this feature though. Of the top of my head, here's an attack scenario:\n\nMalicious user (Mali) sets up a client in bob's developer portal. He sets the consent url to http://malicious.com/login\nMali duplicates the log in screen from bob's website http://bobwebsite.com/login\nMali tells alice to use his app. Alice performs the oauth2 flow and lands at http://malicious.com/login. She thinks however that she is at http://bobwebsite.com/login because the sites look the same.\nAlice enters her username and password.\nMali has now alice's username and password.\n. > This scenario is a valid problem, but it's Bob's role not to let Mali register a malicious client.\nThere's a difference between trusted clients (Bob's desktop app, Bob's mobile app etc.) and third party clients.\n\nThis is the problem exactly, because now we assume that Bob has implicit (because he read the documentation or is otherwise aware of the issue) knowledge of this issue. The same thing is achievable with getting the aud claim from the consent challenge and looking it up in a \"routing\" table, e.g.\nswitch aud:\n  case \"my-app\":\n    redirect \"http://my-app/login\"\n  default:\n    redurect \"http://my-other-app/login\"\nHere, Bob has explicit control and knowledge of the routing logic.. That is true, however the benefits outweigh the downsides IMO. However, I'll sleep over it and try to think of a way that we could add this without risking the attack scenario above to system administrators who are not very cautious :). I thought about it and I feel even more uncomfortable with this change. The downside of having another redirect is minimal (averaging on 80ms?) while the downside of risking attacks such as the one mentioned above is maximal.\nI would like to thank you for your initiative on this, but I believe that it's not the right path forward for Hydra. If you feel strongly about this, feel free to chat with me on gitter or in this issue.. > Fixing this in IdP mixes the roles.\nIn my opinion, identity brokerage (which this is effectively) is subject to the consent app, as the consent app would also broker identities to Google/GitHub/Facebook auth :). * https://github.com/ory/hydra/pull/297\n* https://github.com/ory/hydra/issues/214\nIt is currently not supported because hydra does not act as an IDP. Additionally, the ROPC grant is only for legacy scenarios, and we actually support the recommendations for mobile oauth2 from ietf: https://tools.ietf.org/html/draft-ietf-oauth-native-apps-09. Not right now, but it would be great if you could contribute to the docs regarding this topic!. Awesome!. Yeah actualy it's not supported in the code. This might be an old reference. Is it enough for you to set at_ext/id_ext instead?. Yes exactly, and yes, please do! :). Which docker version are you using?. No, it's something with dockertest or the common library. I'll look into it tomorrow. Yup, it's the common library, fixed there: https://github.com/ory/common/releases/tag/v0.4.0\nStill need to update hydra and ladon deps. Thanks, that should be ory-am in there :). Thank you!. Why exactly? ^0.6.9 matches 0.6.18 (latest fosite release) according to semver. There is no fosite 0.7.10: https://github.com/ory/fosite/releases. Closing due to inacitivity, feel free to come back on this.. I consider SQL being stable :). Resolved in #445. Any idea why travis is failing?. Thanks! That's perfect. However, I have to be the mean maintainer here and insist on a test case for this :( It helps keep the code quality high and also test for potential errors not visible to code review.\nTesting this should be easy. For the oauth2 package, set up a handler_test.go, bootstrap the handler itself (should be easy, just set the issuer - there is no other logic required) and do a http request against it, and test the output against what you expect.\nOnce that is done, I'll help you setting up the test for the JWK.. It's weird that the tests are failing, I don't think it's your code's fault, I tracked it as #443. Thank you @Grillz for staying on this issue for so long, I really appreciate it!. @Grillz to get this working I think you need to run glide update. Yeah I'm actually converting that manually via here (just paste the json and it will ask you if it's ok to convert to yaml). I'll take another \ud83d\udc40 tomorrow, 11.55pm over here :). Awesome! Thanks!. > Likewise, a client itself should be able to belong to warden groups in some way for machine to machine authentication.\nThat is possible\n\nIt would be handy if token TTLs could be configured by client, my company is experiencing some use cases where this makes the most sense. Let me know your thoughts, thanks\n\nI will think about it!. Why do you actually need longer TTLs for specific clients? Can't you use refresh tokens?. Keep in mind that access tokens are not session identifiers and must be short living. Additionally, oauth2 libraries exist for every major programming language and hydra implements best practices for mobile apps, including public clients for authorize code flow with refresh tokens.\nI'm not sure if I would accept a PR messing with this, especially because we would probably have to change something substantially in fosite.\nIf it's possible, try to get as far with refresh tokens as possible.. I'm not confident that one hydra instance is enough to manage a multi-tenant oauth2 set up. In my thinking, you would deploy one instance per tenant and keep them as separate as possible.. I feel like the client must be able to deal with this. Access tokens don't make sense if you don't have internet connectivity, thus, they are able to refresh. What use case do you want to cover with this exactly?. You are making a good point there. Hydra is not designed for multi-tenancy, but if you can make it work then that's perfect :). Sure, happy to take a look and if it makes sense have that as an official recommendation!. Closing this issue, as client TTLs will not be added in the near future and should usually be resolved using the refresh flow. In multi-tenant scenarios, you probably need more than one hydra instance in order to get tenant-specific settings. Separating auth* in multi-tenant scenarios is a good idea anyways.. You will need to make HTTP calls to hydra's warden or the introspection endpoint. Hydra has a Go SDK available in the sdk directory. The http calls are documented on apiary (check readme).\nUsually you don't do this in your code but instead have an api gateway (such as kong from mashape) doing this for you. > I don't want to depend on third party gateways etc.. therefore the first step is to integrate with my own code/infra.\nYou most definitely should. You don't want to expose your services to public traffic!. Nice :). > Any ideas?\nThe system secret is wrong, probably because it's not set or something. So it can't decode the store:\ntime=\"2017-04-19T21:29:58Z\" level=warning msg=\"Expected system secret to be at least 32 characters long, got 8 characters.\" \ntime=\"2017-04-19T21:29:58Z\" level=info msg=\"Generating a random system secret...\" \ntime=\"2017-04-19T21:29:58Z\" level=info msg=\"Generated system secret: F&SFjKEDGRO-sgy(K>ns,U8x9aB(6T2%\". Awesome! Thank you for your work on this :). Again, thank you so much for your work on this. I've added it to the readme and thus closing this issue.. https://github.com/ory/hydra/issues/430#issuecomment-295044119\nKeep in mind, this is 1 1/2 years old.. https://ory.gitbooks.io/hydra/content/oauth2.html#consent-app-flow\nThere are fields at_ext and id_ext for this. Sorry for my inresponsiveness, it was a really stressful week. Ah I see, I misunderstood. Simply add the things you want in the IDP to the oauth2 url hydra/oauth2/auth?extra_info=123 and extract it from the redir parameter in the consent challenge.\nHope that helps.. > I'm sorry your week has been tough. :( Here's to better days \ud83e\udd42\nThat cheered me up! :) Glad to be of help!. Yeah, this has actually come up in another question in the forum. I think we can add the original URL as part of the request payload, otherwise you'll have to first accept the login in order to get the URL. Please create a new issue to track this and feel free to create a PR!. How are you trying to build the docker image?. Do this instead:\ndocker build -t hydra .. > I got my owners query working, but it's not code good enough to offer a PR yet and it's not safe sql. I have a conference demo thing coming up in 2 weeks, but after that I'll be able to clean up my code & make tests and offer an official PR. I would love to be a hydra contributor\nGreat! Thank you for your hard work on this and please excuse my late reply. Welcome to the Hydra family :). closing due to inactivity, feel free to reopen. Go ahead :). Thanks, those libraries are really annoying because they introduce breaking changes every few months. This will be resolved with #425 which I hope to get done this week, latest next.. Resolved in #445. There are two issues at hand:\n\nFrozen dependencies (e.g. no prefix, or patch match) force you to use the exact same versions in your code in order to work\nThe hydra sdk should actually not pull the whole hydra stack. why not lock hydra version to 0.7.9 for now?. This is resolved now. You either forgot to set SYSTEM_SECRET or used a wrong SYSTEM_SECRET. This is the error you get when that's wrong. Could use a better one of course.... I will add a note to the error message to make this more obvious :)\n\n\nAm 29.04.2017 um 04:14 schrieb Eric Staples notifications@github.com:\nAh, great. That was it! I had thought that leaving SYSTEM_SECRET empty and allowing the system to generate a system secret was good enough, but yeah of course it's going to try to generate a new system secret on pod recreation. So, yeah, totally my fault; setting SYSTEM_SECRET fixed this.\nThanks for the quick response.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. did you forget to run hydra migrate before?\nAm 25.05.2017 um 02:09 schrieb Dave Kushner notifications@github.com:\nI am experiencing this same issue when attempting to start up hydra in a local docker-compose cluster running against a stock postgres image in the same cluster. This behaviour should be impossible in that case since the postgres container does not save state between runs, yeah? How might this be happening?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. See #816\n\nPlease avoid dupes in the future, thank you.\n\nAm 19.03.2018 um 05:40 schrieb nicerobot notifications@github.com:\nI'm having the same problem. I shut down the container and trying to rerun fails. The problem does indeed appear to be the SYSTEM_SECRET but it's because it's not being respected from the command-line.\n$ echo $SYSTEM_SECRET \n27277\n$ docker run -d \\\n  --name ory-hydra-example--hydra \\\n  --network hydraguide \\\n  -p 9000:4444 \\\n  -e SYSTEM_SECRET=${SYSTEM_SECRET} \\\n  -e DATABASE_URL=${DATABASE_URL} \\\n  -e ISSUER=https://localhost:9000/ \\\n  -e CONSENT_URL=http://localhost:9020/consent \\\n  -e FORCE_ROOT_CLIENT_CREDENTIALS=admin:demo-password \\\n  oryd/hydra:v0.11.6\nNotice that the logs show \"Generating a random system secret...\" and this happened during the first run so it's actually impossible to restart the server.\n$ docker logs ory-hydra-example--hydra\ntime=\"2018-03-19T04:25:55Z\" level=info msg=\"Connecting with postgres://:@localhost:5432/hydra?sslmode=disable\"\ntime=\"2018-03-19T04:25:55Z\" level=info msg=\"Connected to SQL!\"\ntime=\"2018-03-19T04:25:55Z\" level=warning msg=\"Expected system secret to be at least 32 characters long, got 4 characters.\"\ntime=\"2018-03-19T04:25:55Z\" level=info msg=\"Generating a random system secret...\"\ntime=\"2018-03-19T04:25:55Z\" level=info msg=\"Generated system secret: 5CedSNF4Rdh9pUs6ZeI1kzJAZcug-mYj\"\ntime=\"2018-03-19T04:25:55Z\" level=warning msg=\"WARNING: DO NOT generate system secrets in production. The secret will be leaked to the logs.\"\nCould not fetch signing key for OpenID Connect - did you forget to run \"hydra migrate sql\" or forget to set the SYSTEM_SECRET? Got error: unexpected end of JSON input\nIf i delete the tables and run migrate again, it works again though the secret is still randomly generated.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Don't worry, just want to avoid people searching for similar issues that are unanswered because of duplication.. Superseded by 0.8.0 release. https://github.com/ory/hydra/releases/tag/v0.7.12 - should be on dockerhub in ~20 minutes. At your service @matteosuppo \ud83d\udd96 . Resolved in #445. Resolved in #445. > I think that by passing a database URL to Hydra, you are implicitly authorizing Hydra to do with it what it sees fit. \n\nThat doesn't include accidental loss of data because a database migration didn't do what it should do. Also:\nDockerfile\n```\nFROM oryd/hydra\nENTRYPOINT /go/bin/hydra migrate sql $DATABASE_URL; /go/bin/hydra host\nEXPOSE 4444\n```\nHydra is not responsible for your infrastructure set up, all of the infrastructure tools allow automation of this kind.. > Well, to make Hydra production ready it should have integration tests, which would fail fast if data is accidentally lost.\nAbsolutely, this being done in parts already. The migrations are executed linearly already, and up- as well as down- commands are implemented. It is noteworthy that downwards migrations might cause loss of data as they might (not the case at the moment) remove columns or even tables.\nIn general, perfect migrations for all environments and databases in the wild are very hard. Sometimes, operators make small fixes to the schema in order to get better performance from the database. Until now, they had no possibility to run migrations manually. This is now the case.\nIn general, it is the responsibility of operations to properly execute software upgrades (e.g. with release canaries), and separating migration from the actual server is only benefitial here. In fact, I was approached by operations and they asked me specifically to disable auto-migrations and provide a separate command for it, with good reasons for it.\nIn any case, you are not loosing the ability to execute migrations and run the server in one thing, as I pointed out with the docker example above. You need to be aware of the implications though, which is also why those two commands are now separate.. By the way, the ladon migration (the only real thing that changed large portions of the schema) is fully tested - it still needs to be run manually in order to make 100% sure that you don't loose any data due to some weird quirk, as timeouts for example.. Ok, tests are now passing locally and all changes I wanted to address are now in. I'll give myself one or two days away from this issue and then review it and look for things that don't seem right.. https://github.com/ory/hydra/releases/tag/v0.7.13. Thanks, not sure what's up with glide here. I'll probably rebase this on top of the 0.8.0 release #445 . @hlian thank you for this, I'm closing it because I pushed this change in #445 :). Thanks!. I can reproduce this and it's most likely a regression issue as images prior to 0.7.8 are working fine. A potential candidate for causing this is this commit in fosite, however fosite is working fine with scopes, so the issue must lay somewhere else.. Awesome thanks!. I think I accidentally force pushed and re-wrote the commit history which is why your contribution disappeared from the 0.8.0 PR. However, I re-added it https://github.com/ory/hydra/pull/445/commits/fd34c813e58eb3c36cd944982863afff300de46f - sorry for this :). Shouldn't the remote address for the TLS Termination be the last IP in the chain? Or let me repharse: Why is this an issue?. Ha, thanks! My german roots are haunting me :D. Nice, looks much better now :). Definitely more info needed. What docker image are you running, what environment variables are set (don't include secrets)?. Which docker image are you using exactly? There are multiple flavors!. Oh I misread, seems like you're building it yourself. Which docker image are you using?. Ok, that one has https disabled, use the normal one for https - does that answer your question?. Have you seen the TLS termination option? If not, check out hydra help host and look under the \"HTTPS CONTROLS\" section. That should be what you're looking for. otherwise you could probably also issue a certificate from the platform you're using for hydra, use that in hydra and serve regular https. that usually works too for e.g. AWS ELB - should also work on GCP. also head over to our community channel on gitter (link in readme), the community is really helpful and has dealt with this as well :)\nclosing this issue, if you feel there's a bug or something please reopen or create a new issue. Please install go 1.8 as noted in history.md :). Thank you for reporting this, I'm quite busy this week, so if you want to take a look yourself please do so!. https://github.com/ory/fosite/pull/176. Thanks!. You probably forgot to set the subject claim sub in the consent challenge. Read more on this here: https://ory.gitbooks.io/hydra/content/oauth2.html#consent-app-flow or consider using the js or go sdk.. sub needs to be a string, not a number :)\n\nAm 12.05.2017 um 14:56 schrieb Mateo Murphy notifications@github.com:\nAh, I dug through the fosite source and figured out that sub needs to be a string, otherwise it's silently discarded. I also just figured out that a nonce is required, otherwise you get a \"The request used a security parameter (e.g., anti-replay, anti-csrf) with insufficient entropy (minimum of 8 characters)\". Perhaps the error message and/or the documentation could be improved?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. yes definitely needs improvement! :)\nAm 12.05.2017 um 14:56 schrieb Mateo Murphy notifications@github.com:\nAh, I dug through the fosite source and figured out that sub needs to be a string, otherwise it's silently discarded. I also just figured out that a nonce is required, otherwise you get a \"The request used a security parameter (e.g., anti-replay, anti-csrf) with insufficient entropy (minimum of 8 characters)\". Perhaps the error message and/or the documentation could be improved?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Is this the same issue you reported previously? I thought it had to do with a bug in the REST writer which caused an infinite loop if certain error conditions came true. However, that would not explain database spikes and also this error has been resolved in 0.8.x\n\nOne likely cause for database spikes is leaking connections when an error occurs. This might happen in a transaction that has multiple statements that don't close the database connectivity if an error occurs during one of the transactions. However, that would result in a steady increase of connections over time, not an abrupt spike.\nTo identify the issue we need to know which API is causing it. By excluding APIs we will narrow down the search, so are there API endpoints you can exclude? Also it could be important to know which flows you've enabled.\nI think the most likely source is either the warden, then token introspection, then token issuance. Simply because the warden is the most complex and probably has a lot of API calls.\nThe first thing to look for in the logs is the 5xx messages and finding out request that happened before that. Also important is the amount of time it took to leak the database connections. Another part could be how you tweaked your database connection (e.g. max conns).. If the error happens both in 0.7.x and 0.8.x ladon is actually not as likely to be the source of this as I thought. The reason for that is that the ladon sql manager was reworked completely. So it's less likely to be the source for this.\nHow often does this happen by the way? Is there a fixed pattern (ever 5 hours for example)?. Actually, @matteosuppo could you share the CPU, Memory and SQL Connection graphs here, including timestamps?. So I started to run some tests on endpoints, I'll summarize what I did here so we get a good idea of what's happening. I checked the number of connections using\ndocker exec -t -i 991 /bin/bash\npsql --user postgres\nSELECT * FROM pg_stat_activity;\nps: everything ran locally here, so zero chance of network errors, which could be the underlying issue here.\nTesting oauth2 token flow\nwhile true; do hydra token client; done\nHere, I was not able to find connection leaks. They were properly re-used, closed and lower than the amount of concurrent clients, which is a good sign. The connections maxed out with about 5 postgres connections at 15 concurrent clients and returned to 2 idle connections once load was taken away.\nToken validation\nI ran the same test with token validation:\nwhile true; do hydra token validate $(hydra token client); done\nSame observations as above.\nClient creation\nwhile true; do hydra clients create; done\nSame observations as above.\nGroup\nCreate\nwhile true; do hydra groups create $(date +%s%N); done\nFind\nwhile true; do hydra groups find foo; done\nSame observations as above.\nJWK creation\nwhile true; do hydra keys create -a HS256 $(date +%s%N); done\nSame observations as above.\nPolicy\nCreate\nwhile true; do hydra policies create -a foo --allow -r foo -s foo --id $(date +%s%N); done\nGet\nhydra policies create -a foo --allow -r foo -s foo --id 1495199487515477900\nwhile true; do hydra policies get 1495199487515477900; done\nwhile true; do hydra policies get i-do-not-exist; done\nSame observations as above.\n\nI haven't checked the warden yet but since policy, token validation and group finding have been tested already, it's unlikely that the warden has a leak.\nIn general I'm now more confused as to what's causing this. There isn't an obvious sql connection leak, I also checked all the sql implementations for missing rows.Close() but was unable to find any. Maybe it's caused by some infinite loop that hit's off when some error occurs. But we really need to nail down the API that's causing this in order to find it.. @matteosuppo could you share the database DSN without confidential things, so for example: postgres://*:*@*:*/hydra?foo=bar. Oh and by the way, do both instances stop serving traffic or only one?. What I'm interested in is the settings max_conns, max_idle_conns, and max_conn_lifetime - or if you haven't set them at all. If you haven't set them, could you try setting max_conn_lifetime to, for example 1 minute?\npostgres://*:*@*:*/hydra?max_conn_lifetime=1m\nMy guess is that either some connections have issues and then clog up the database, or that connections are capped at a low value (e.g. 4 - which happens on 2 logical cpus) which simply isn't enough. So you could also try:\npostgres://*:*@*:*/hydra?max_conn_lifetime=1m&max_conns=20&max_idle_conns=4\nwhich greatly increases the maximum amount of allowed connections.\nOf course, upgrading to a larger db might also help. Since the symptoms you describe don't fit in a sql connection leak, and only in either a database load issue or an infinite loop issue, upgrading could resolve those issues with at least 50% chance.. Thank you, this helps a lot!. Hm, I was not able to reproduce the memory leak with hey. Are you sure that what you observed wasn't caused by Go ramping up memory to be able to deal with 500 concurrent connections? You can test this assumption by waiting ~5 minutes after the test - if the memory usage drops back to a few megabytes it's not a memory leak. Oh, did you run this against the in memory database or a SQL backend? I think I'm seeing the same results as you with postgres backend enabled. So I ran about 10 million requests against hydra set up in a docker container and postgres connectivity and while at some point the memory kept growing slowly, it was freed up immediately after the load stopped (checked with docker stats). I was unable to reproduce the growing disk size (docker ps -s).\nI checked one of my production deployments on kubernetes (significantly less load though) which is running hydra 0.7.7-http and it looks like this:\n\nwhere the green line is hydra and the disk spikes are caused by the hydra logs (the drops are probably caused by kubernetes cleaning up log files). I'm not sure if that's the same thing you're experiencing but it shows some increase in memory consumption over time. @matteosuppo could you join me on gitter?. https://github.com/ory/hydra/pull/494/commits/9b48b75f7e03867ba4ecc456c6e466f07a374c2a. Hm yeah, actually I think that the PUT command should have the full payload and not mergo at all. What do you think?. I think that's ok, we'll add it to the release notes. @faxal would you mind creating a PR for that? Should be straight forward :). Oh ok so the issue is that we need to remove those parameters from the database DSN as apparently there is some validation going on in postgres!. I'm already working on it :). No, my bad, I updated the log but not the actual URL that get's connected. I also wrote test cases but unfortunately the postgres instance I use does not seem to care.. @matteosuppo what postgres version are you running by the way?. done. thank you for the report. This is weird, why is this a PR with my commit that I already merged into master? https://github.com/ory/hydra/pull/470. Check the logs of the docker container, you probably didn't set DATABASE_URL. It is, just check the logs, it will show you why it didn't start. The container is working fine in prod here ;). If you point me to the section that showed this command, I'll update it accordingly so the container is able to boot properly. 99% missing database url. You need to set -e, see: https://docs.docker.com/engine/reference/commandline/run/. you can't pass flags after arguments in almost all CLIs, the right order is: docker run -d --name my-hydra -p 4444:4444 -e \"DATABASE_URL=memory\" oryd/hydra. glad you got it working! would you mind updating the section where you found the broken docker command? :) all the docs reside in https://github.com/ory/hydra/tree/master/docs. Oh yeah that needs to be /bin/sh. Yes, you can't SSH in any more, but you can do docker exec -i -t 5b49f071819b help or any other hydra command.. Thank you!. Ok, apparently this is simply a huge mess, the naming has been lower-cased, then renamed and is back to lower case again, basically breaking any dependency. The only way to circumvent this for now is to download hydra in the right directory (e.g. via git clone) and then run glide install.\nUnfortunately, there is no way to fix this unless dependencies hydra relies on are fixed.. I checked if this actually prevents downloading hydra - it doesn't. So it's just a warning that you can ignore.. I've added a note on this to the readme.. This is resolved now. Thank you!. Oh, could you please sign your commit using git commit --amend -s?. don't worry, thank you!. This breaks the build, I can't merge it but will investigate. I agree with @20zinnm . should be resolved. thanks!. I am confident that r.Header.Get() follows RFC 7230, otherwise most Go applications would not properly work with http. What issue are you observing exactly?. I can't reproduce this:\n\n\n. The problem with updating the policy is that we need to make a diff and, for example, find out which subjects were added, or which ones need to be removed. The solution to this is probably, to remove and add the policy in one transaction.. https://github.com/ory/ladon/pull/75. Unfortunately no, this is currently not supported but I'm glad to have it on the list. If you want to give it a shot, let me know!. Open for over a year, no one else has complained about this so far - closing due to lack of public interest.. In general I recommend running Hydra behind an API Gateway such as Kong - while Hydra is capable of dealing with public internet traffic, it's always better to have a battle tested entry point to your infrastructure.\nHaving said that, it is quite common to have a CORS plugin in your API Gateway and configure CORS for your whole domain rather than per service.\nConfiguring CORS is a bit painful, because there are various configuration options (methods, hosts, ...) and limitations (e.g. only one host or wildcard) that make this even harder.\nTherefore, if having a reverse proxy, or an API Gateway that is capable of dealing with CORS is the best route to resolve here IMO. Let me know if that works for you.. Unfortunately CORS will not be added to hydra, there are much more elegant ways to solve that with a decent API Gateway, varnish, ngnix, or any other type of reverse proxy. You could even write one yourself within an hour in Go. It is extremely common to have this in place in a distributed or cloud environment.\nI also want to direct you to running hydra in production where it is specifically recommended to not let hydra face public internet traffic.. Not sure why I reopened this - closing as this is usually covered by the reverse proxy. I changed my mind, CORS support will make it into the 0.10.x release as there is the possibility to configure rs/cors in a sane way through env vars. Everything that isn't HTTP GET (/oauth2 endpoint excluded) requires write access. However, I'm not sure if you're not optimizing this prematurely. What issues do you have with warden latency?. @joshuarubin do you have any further questions regarding warden performance? if not, I'll close this issue. By the way, we're working internally on a beefed version of Hydra which will include a caching layer for performance critical endpoints such as the warden. If this is interesting for you ping me on gitter. You got me, requests to /warden (excluding /warden/groups) are all read-only, even when POST :). Hey thank you for your contribution! Could we maybe add a fallback in case the Issuer is not set?. If you just want to play with it and run it locally, or as part of the tests, such a fallback makes sense. It should be easy to get started with Hydra (it's hard enough already ;) ) so let us make this as easy as possible!. HOST is unfortunately often not the real hostname, but rather the interface that hydra is listening on, this is why I used r.RequestURI in the first place here :). Host defaults to empty catching all interfaces which is why hydra works per default in a docker container. Thank you!. > However, hydra token user --id my-id generates a link with redirect_uri = http://localhost:4445/callback, making hydra complain\nThe CLI help command is really helpful:\n```\n$ hydra help token user\nGenerate an OAuth2 token using the code flow\nUsage:\n  hydra token user [flags]\nFlags:\n      --cluster string       Force a cluster url, defaults to value from config file\n      --id string            Force a client id, defaults to value from config file\n      --no-open              Do not open the browser window automatically\n      --redirect string      Force a redirect url (default \"http://localhost:4445/callback\")\n      --scopes stringSlice   Force scopes (default [hydra,offline,openid])\n      --secret string        Force a client secret, defaults to value from config file\n```\nSo this is now:\nhydra token user --id my-id --redirect https://mydomain/callback\n\nBut then looking at logs it seems the consent fails and Hydra presents a login page.\n\nWell, in order to complete the authorize code grant, you need to complete authentication and consent. In normal scenarios you implement the consent app yourself, so you have control whether or not the user needs to consent or authenticate. So I'm not sure what the issue is here, other than maybe getting a bit more into oauth2, the consent app, and the authorization step ;)\n\nhttps://www.digitalocean.com/community/tutorials/an-introduction-to-oauth-2\nhttps://ory.gitbooks.io/hydra/content/oauth2.html#consent-app-flow. @valichek the error message is equal, OAuth2 spec says that only little information should be shown to the end consumer so it's not possible to reverse engineer unauthorized requests. However, this has been a pain point for users for some time now and I'm reconsidering giving more explicit warnings\n\nRegarding your question, the --is-public flag disables the possibility to use a secret and thus disallows the client_credentials grant. Use this flag if you have a client that runs on a user's device (e.g. SPA, mobile app).. Looks like the session isn't properly instantiated, I'll write a failing test case first. @kimooz are you using the SQL backend?. Ok because I just tried to write a failing test case for this using the memory manager and it didn't result in an error.. What hydra version are you on? How are you starting the image? Is this a fork? Are you by any chance working together with @wyattanderson ?\nI can't reproduce this issue with the demo set up, refreshing a refresh token works totally fine here.\nTo resolve this, I need to know what you're doing. Please give as much detail as possible.. Proof that this works (latest master): \n\n. @kimooz can you please include at least 10 lines of the log before the panic?. @kimooz do you have a custom consent endpoint? Is this endpoint setting, for example, id token or access token data?. @wyattanderson are you setting id_ext or at_ext?. @kimooz is id_ext always set? e.g. are all requests openid connect?. Ok so it's improbable that this is the root cause of the issue, because if it was, the error would happen more frequently, right?. Are you by any chance flushing expired access tokens from the database?. It doesn't, just trying to narrow the scope ;). kimooz @wyattanderson if this happens again, could you please share the log + ~50 previous lines, plus (if possible) the payload of the consent response? This is now blocking for the 1.0.0 release because panics are not nice.. Thank you! Could you share the consent payload as well?. user.as_json is just some json object right?. I can not reproduce this. Please check that you have the most recent tag installed.. Since you're apparently on the latest version, please create a reproducible step-by-step guide that includes your whole environment (including consent app), otherwise it's just random guessing by me. check if port 4444 blocked somehow. #514 will show a more verbose error message which will hopefully help resolve this.. #514 is now merged and released under latest master and 0.9.2 - make soure you're actually pulling the latest version in docker with oryd/hydra:0.9.2. Building the docker image usually takes ~20 minutes.. You can try to kill off all containers with docker kill $(docker ps -q) and then re-run this container, but since this isn't a hydra issue I'm closing this. You can also ask on our Gitter chat channel for help!. Sort of upstream, because I want to wait for MySQL 5.7 to become more standard (a lot of people on 5.5 and 5.6) so we can upgrade postgres and mysql to jsonb.. This has been open for over a year but no one else has complained, so it does not seem to be a big issue for anyone else. Closing.. I can't review your python script, also dumping the whole thing here isn't really helpful. All changes are kept track of here. Please check that and see if you took all steps to properly migrate your installation.. docker run -e \"DATABASE_URL=memory\" -e \"ISSUER=https://localhost:4444/\" -d --name my-hydra -p 4444:4444 oryd/hydra. depends on what you're doing or expecting, if you are just calling the root url then yes. I recommend highly that you read the docs. Its all explained there, and has a tutorial\n\nAm 16.06.2017 um 23:26 schrieb Andriy Drozdyuk notifications@github.com:\nOk, seems to not work and not crash.\nGetting \"404 page not found\". Is this expected behavior?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Ok, then I'm not sure what you're expecting at the root as the APIs are all documented (root is not one of them) and there is no UI in Hydra.\n\nIf you haven't, check out the 5 minute tutorial which might give you an idea of what Hydra actually does.. > Also, I actually followed one of the installation instructions here, where it says:\nPerfect, thank you, I set this to /health now which gives some info on the running instance :)\n\nSorry, I may have overreacted.\n\nDon't worry, all good!\n\nI suggest an index page with \"You're up and running - go here to read the API docs and here for tutorial.\"\n\nI wanted to do this for some time but the problem is that most companies using Hydra don't want people to know they are using it - due to security reasons. Unless that's configurable it's going to not go well with some people, probably :|. Thank you!. you need to add the new dependency using glide update. If you ever come back to this issue feel free to comment & reopen. It's been addressed in PR #537 but as you might notice the CI fails sometimes due to https://github.com/golang/oauth2/issues/237. This is now resolved, please be aware that golang.org/x/oauth2 does not send client id and secret using urlencoding, my patch for this is here: https://go-review.googlesource.com/c/46473/. Could you give the output of hydra token validate <token> please?. Closing due to inactivity. Actually, you can use /oauth2/introspect. Token audience and request subject must not match.. Or let me ask differently, what's the issue with /oauth2/introspect?. I don't quite remember what the issue was here, can we re-iterate? The issue with a public token introspection endpoint is that we're now open to token scanning attacks and need other means of preventing those, increasing complexity.\nI know that token introspection is not possible for public clients, the only workaround being to use OpenID Connect ID Tokens (if you're looking for identity information) or alternatively have a server side script that acts as a validation proxy.. Closing due to inactivity. Looks like a docker compose issue, either retry, reinstall docker, or ask in docker github :). Please install Go 1.8+ on your system!. ping @wyattanderson . Thanks!. The issue is that the warden uses the introspection functionality from fosite, which in turn doesn't really care if it's a refresh or an access token. Actually, the introspection endpoint isn't caring about scopes either, which is a bit weird because fosite does, but only for access tokens, not refresh.\nTo resolve, I think the following must be done:\n\nCheck scopes of refresh tokens in fosite\nReturn token type in introspect response (fosite)\nOnly pass warden if token type is access token, not refresh token\n. With the new patch you are no longer able to use refresh tokens in the warden endpoint, and the introspect endpoint properly checks refresh tokens for scopes as well. Thanks for the report!. https://github.com/gobwas/glob. Meh, it's ok to have it. dupe #550. Thank you, I took a quick look at networks when writing the guide but it looked like more work to set that up (create network, create container, link container to network, ...). Do you know how to do this? And if yes, would you mind creating a PR?. Same ID token as per spec. This will be difficult to implement, because once the consent flow is done it is not possible to update access token data or id token data, as the requests to /oauth2/token usually don't happen from the user's browser.\n\nID Tokens can be refreshed indefinitely, unless an access or refresh token are revoked that belong to the same consent request id. ID Tokens have an expiry time (which is why you need to refresh them obviously).\nOn a side note, as a user I would not want to wait an hour until my LDAP memberships are updated. I think you'll have a better system with a dynamic endpoint.. @I'm trying to avoid a REST api dependency from hydra to the consent app as it significantly increases the integration complexity. Since the userinfo endpoint is standardized and it sounds like you need one, my next step would be to explore that route. Maybe at some point there will be support for userinfo within Hydra and then you'll be able to simply switch your API to hydra.. Yes, the case is definitely valid. I will take a look once the workload here is a bit less, in about 3 weeks.\n\nAm 10.07.2017 um 17:20 schrieb Wyatt Anderson notifications@github.com:\nUnderstandable. Thanks!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. So, coming back to this issue. The first concern you raise (revoking refresh tokens without user presence) is very valid and will be addressed as part of #304 which has now been bumped to 1.0 milestone.\n\nWhat I don't fully understand is the integration point. So here, Hydra would query the consent app for claims to be put in the ID Token? What kind of data are we looking at here? Is there a spec that talks about updated claims? Access tokens for example don't receive new claims as per spec, apart from expiration date.\nedit:// I just saw that in an earlier comment I directed to the specs which say explicitly what core claims may be updated and which ones may not: http://openid.net/specs/openid-connect-core-1_0.html#RefreshTokens. Thank you for the suggestion! There is one already! :) I should probably place it more visibly :)\nhttps://www.patreon.com/_ory\n\nAm 15.07.2017 um 07:34 schrieb Andriy Drozdyuk notifications@github.com:\nI think you should open a patreon account, so that some of us can support your work.\nJust an idea. Feel free to close.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. this has been done, thank you for your input!. You could try to remove your go workspace, unfortunately it doesn't look like an error specific to hydra, but some problem with your gopath. Maybe ask on stackoverflow, because I don't really know what the issue is and it doesn't seem to be linked to hydra directly.. The config file is only for the client cli, not the host process\nAm 20.07.2017 um 14:41 schrieb R\u00e9my HUBSCHER notifications@github.com:\nWhen looking at hydra host --help it says that a config file can be specified using --config\nHowever I couldn't find any documentation or example file about it.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. This has security and deployment implications and violates 12 factor principles, it's thus disabled by design and highly unlikely to be implemented.\nAm 20.07.2017 um 15:16 schrieb R\u00e9my HUBSCHER notifications@github.com:\nIt would be nice to be able to set all the system_secret, database_url in a file rather than in env variable especially for production deployments.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. 12 factor principles are design guidelines for cloud native services that run on docker or via buildpacks. Those rarely support file configs, especially because some configs require dynamic settings (eg ip ranges) which are hard to automate via files in prepackaged docker images. Also, leaving highly classified info (system secret) unencrypted on the filesystem is really bad practice that requires either additional business logic (eg file owner check) or trusting sysadmins to properly set up the systems, which is also called \"insecure by default\".\nAm 20.07.2017 um 17:29 schrieb R\u00e9my HUBSCHER notifications@github.com:\nYou will need to elaborate a little bit on this because most service I know are configurable by files.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Preferably\nAm 20.07.2017 um 17:37 schrieb R\u00e9my HUBSCHER notifications@github.com:\nOk so one should use Dockerflow to deploy hydra?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Closing because this will not be changed. The issue with config files here is that we have two sensitive secrets (SYSTEM_SECRET and COOKIE_SECRET). Since we'll store them in plaintext this can get a bit tricky to secure. While there certainly are ways to get the env vars of a process, they typically require root privileges like cat /proc/<pid>/environ (afaik). Your particular set up does not seem to have an issue with that as it's all mounted volumes within kubernetes. But I'm not only thinking about your use case, but also about people that might do this on a baremetal server.\n\nOn a side note, I do see that you save a bit of space in your definition from\nhydra.yml: |\n     port: 4444\n     public-url: \"https://\"\n     admin-url: \"https://....\"\nto\nenv:\n    - name: PORT\n      value: \"4444\"\nbut I'm not yet convinced that it's worth it.. Perfect!\n\nOn 5. Sep 2018, at 14:58, Gorka Lerchundi Osa notifications@github.com wrote:\n@aeneasr TLTR, it works and I don't need a config file.\nWe're going to deploy Hydra, a front/reverse proxy and our conset application all in the same Kubernetes Deployment. This means:\nEnvoy: Which reverse proxies /login and /consent to our own consent application and everything else to the public Hydra port so that we don't need to explicitly define which paths is Hydra publishing (/.well-known/..., /oauth2, ...)\nHydra: A concrete version of hydra, for now v1.0.0-beta.9.\nConsent App: A concrete version of consent application written in Go with a concrete vendored version of Hydra SDK in order to deploy everything at the same time and try to avoid any future incompatiblities (I know that you're probable aware of this but we feel more comfortable doing it in this way).\nThe most important bits for this deployment are the statically defined Envoy configuration for the front/reverse proxy, which is this one:\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: envoy\ndata:\n  envoy.yaml: |\n    static_resources:\n      listeners:\n      - address:\n          socket_address:\n            address: 0.0.0.0\n            port_value: 8080\n        filter_chains:\n        - filters:\n          - name: envoy.http_connection_manager\n            config:\n              codec_type: auto\n              stat_prefix: ingress_http\n              route_config:\n                name: local_route\n                virtual_hosts:\n                - name: backend\n                  domains:\n                  - \"*\"\n                  routes:\n                  - match:\n                      prefix: \"/login\"\n                    route:\n                      cluster: authn\n                  - match:\n                      prefix: \"/consent\"\n                    route:\n                      cluster: authn\n                  - match:\n                      prefix: \"/\"\n                    route:\n                      cluster: hydra\n              http_filters:\n              - name: envoy.router\n                config: {}\n      clusters:\n      - name: hydra\n        connect_timeout: 0.25s\n        type: strict_dns\n        lb_policy: round_robin\n        hosts:\n        - socket_address:\n            address: 127.0.0.1\n            port_value: 8080\n      - name: authn\n        connect_timeout: 0.25s\n        type: strict_dns\n        lb_policy: round_robin\n        hosts:\n        - socket_address:\n            address: 127.0.0.1\n            port_value: 8081\n    admin:\n      access_log_path: \"/dev/null\"\n      address:\n        socket_address:\n          address: 0.0.0.0\n          port_value: 9000\nAnd how to provide the required configuration to Hydra where parts of them are secrets and the others are not.\nconfigmaps/hydra.yaml:\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: hydra\ndata:\n  LOG_LEVEL: debug\n  PUBLIC_PORT: \"8080\"\n  ADMIN_PORT: \"9000\"\n  OAUTH2_ISSUER_URL: http://192.168.99.100.nip.io\n  OAUTH2_LOGIN_URL: http://192.168.99.100.nip.io/login\n  OAUTH2_CONSENT_URL: http://192.168.99.100.nip.io/consent\n  OAUTH2_ERROR_URL: http://192.168.99.100.nip.io/error\n  OIDC_SUBJECT_TYPES_SUPPORTED: public,pairwise\nsecrets/hydra.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hydra\ntype: Opaque\ndata:\n  # postgres://postgres:mysecretpassword@postgres.default.svc.cluster.local:5432/hydra?sslmode=disable\n  DATABASE_URL: cG9zdGdyZXM6Ly9wb3N0Z3JlczpteXNlY3JldHBhc3N3b3JkQHBvc3RncmVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWw6NTQzMi9oeWRyYT9zc2xtb2RlPWRpc2FibGU=\n  # youReallyNeedToChangeThis\n  OIDC_SUBJECT_TYPE_PAIRWISE_SALT: eW91UmVhbGx5TmVlZFRvQ2hhbmdlVGhpcw==\n  # youReallyNeedToChangeThis\n  SYSTEM_SECRET: eW91UmVhbGx5TmVlZFRvQ2hhbmdlVGhpcw==\nSo that everything can get merged in the deployment by leveraging this to Kubernetes using the envFrom:\n[...]\n      containers:\n      - image: docker.io/oryd/hydra:v1.0.0-beta.9-alpine\n        name: hydra\n        args: [\"serve\", \"all\", \"--dangerous-force-http\"]\n        envFrom:\n        - configMapRef:\n            name: hydra\n        - secretRef:\n            name: hydra\n        ports:\n        - containerPort: 8080\n          name: public\n[...]\nThat's all.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thank you for the report!\nAm 24.07.2017 um 01:27 schrieb Alexander Trauzzi notifications@github.com:\nSeems like the documentation isn't showing up quite right:\nFurther, it might be nice to document all the ports, filesystem points and environment variables of the application in these docs. Whether that's done as part of the readme.md in the repository or a specialized set of instructions for the docker hub registry... Probably up to you :)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. This is resolved now. Set the database url in your shell, then:\n\ndocker-compose run --rm --entrypoint \"hydra migrate sql $DATABASE_URL --skip-tls-verify\" hydra\n\nAm 24.07.2017 um 02:43 schrieb Alexander Trauzzi notifications@github.com:\ndocker-compose run --rm --entrypoint \"hydra migrate sql postgres://local:local@postgres:5432/hydra?sslmode=disable --skip-tls-verify\" hydra\n. That is exactly the point, you dont want to run migrations against eg a prod database because it defaults to some value you set two months ago. Typing an url is really not that big of a deal, and it might save you some headaches down the road.\nAm 24.07.2017 um 14:21 schrieb Alexander Trauzzi notifications@github.com:\nThat's not really solving the problem I, that just moves the headache up a level.\nWhy wouldn't you just look at the current env for configuration for the CLI? The application server already does it and you're telling me to put config in my native host env.\nThis is about automatically reading those values rather than asking for it to be passed in. By doing this, you simplify the command line experience and benefit from docker conventions.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. > In this case, \"really not that big of a deal\" has been invoked, which has caused me to lose interest in this project.\n\nYeah, that was badly worded. Sorry for that.\n\nI sincerely hope in the future they can become more familiar with docker conventions and improve the flexibility of hydra and how well it plays with other ecosystems.\n\nSince when is passing arguments to commands not a docker convention? You can literally run docker run oryd/hydra:vX.Y.Z migrate sql database-url, like you do with, for example, kong (docker run kong migrations up [-c /path/to/kong.conf]) or other services.\n\nThere was another story around this I think, asking for a flag we could set to use the environment variable.\n\nYup, we'll add a flag to allow this! Wasn't tracked before, it's now: #896. Oh, I didn't know that! When running in Docker Swarm / Compose, Kubernetes, or just bare Docker this isn't an issue. Can't say how many times I heard about these little things that frustrate the hell out of you from developers that work with AWS ECS.\nIf you want, feel free to supply a patch, it should be just ~5 LoCs to get it working.. #898. Dupe of #565. Unfortunately, this is due to bad design choices by apiary, oauth2 is properly referenced as you can see in the screenshot:\n\n\nI will try to follow up with apiary on this, which might take some time.\nAlso, for some reason, it says implicit OAuth2 which isn't correct.. That's what I meant that it's a bug in Apiary (the api docs provider) :)\n\nAm 31.07.2017 um 15:00 schrieb Ben Hearsum notifications@github.com:\nHm, I'm not sure I understand what you mean. Even if I click \"oauth2\" I don't see any thing about subject, action, etc. It's also not in the Body section of the console, eg: https://screenshots.firefox.com/mAe0p0DKGJeqzZcA/docs.hydra13.apiary.io.\n\u2014\nYou are receiving this because you were assigned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. this has now moved and is no longer an issue. Thabk you!. Sorry that you had this experience, I have no idea who you are. This is definitely not a money set up. If you ask for personal support via email, I don't have unlimited time for free personal support. If you don't like he docs, help improve them. Telemetry is well documented and optional. Google Groups has been inactive for months.\n\nAlso, please adhere to our contribution guidelines (https://github.com/ory/hydra/blob/master/CONTRIBUTING.md#conduct) or face the consequences mentioned there.. Did you run hydra migrate sql <database-url>?. Migrations are no longer done automatically, this includes installs on a new database, in case you want to use (for example) a custom schema :). Maybe you're using the wrong client id? One time you have local-consumer but in the request I see ?client_id=local-app. Closing due to inactivity. Please install Go 1.8 or Go 1.9. Ok, maybe try running glide install or optionally glide update before running go run main.go. Closing due to inactivity. Indeed, I can reproduce this now. I would prefer ory-hydra as a name. However, I have little experience with homebrew. If you want and know how to write homebrew recipes I'd love to see that! If so, ping me on Gitter :). While this would be nice to have, we do not have the resources to support this. Maybe later we will be able to provide different installation options using homebrew, aptitude, chocolate, .... The docs have been updated to use a password generated from /udev/random. Thank you, please sign the DOC using git commit --amend -s!. Closing because it's not a substantial change and author has abandoned the PR. Feel free to comment and I'll reopen.. Hm, that is quite unlikely because we're not using anything custom-made, only regular Go-libraries which are RFC conform. Could you show a reproducible test case?. It's a narrow use case but feel free to contribute this to fosite, the OAuth2 library behind hydra. Closing here because it's the wrong repo :). I would be open to a PR if a decent library for COSE exists in Golang. Closing due to inactivity. Please comment on this issue and let me know what you think of the proposed ideas. I would also like to hear how the current consent flow has impacted your development (e.g. no problem - or - a lot of work). Yes that is true, but also only if the JWK is fetched only once and then cached for re-use. In a naive implementation, the consent app might call the JWK endpoint every time it requires the key. However, I added it to the list above because it's a good point you're making!. @waynerobinson the direction it's currently headed (API) is more suitable to your use case than manually parsing the consent token. The API response will include important information which had to be kept out of the JWT to save space!. Thank you for the sum up! A couple of notes from my side:\n\nMore data to send via HTTP and it won't be packed in a JWT\n\nJWT requires more bytes than regular REST traffic because we have signatures. This is the reason why the JWT claims are all short aud, id_ext, ... as we hit the URL length limit at some point.\n\nWe already have libraries for handling the JWT JWK magic. Rewriting is harder than leaving it be :)\n\nWithout JWT/JWK I think it would be possible to auto.generate client libraries for all languages! Getting JWK to work is always a lot of work because usually JWT libraries use PEM encoded files.\n\nNevertheless I guess it'll slow request handling down.\n\nMaybe a bit, but not significantly.\n\nOption 3: Use the database\nFast but doesn't feel right\n\nDefinitely.\n\nOption 4: Leave it be\nI'm all for this option since I can't rewrite my IdP \n\nWhy not? Not a lot will change and I will supply an SDK for it :). @janekolszak the SDK will cover everything - it's based on swagger and works with swagger-codegen (the generated Go SDK is used in Hydra itself for the CLI and unit tested).\n@ckong1991 that is really valuable feedback! What is great about option one (REST) is that we can autogenerate SDKs so you don't have to figure out anything at all, you're just calling the Hydra SDK. With autogeneration I mean using swagger-codegen to generate SDKs for any language. That way, all you have to do is:\n```\nhydra = NewHydraSDK(\"client-id\", \"client-secret\", \"http://endpoint/)\nconsentRequest, err := hydra.GetOAuth2ConsentRequest(r.URL.Query().Get(\"consent\"))\n// log user in and optionally check scopes\nerr = hydra.AcceptOAuth2ConsentRequest(r.URL.Query().Get(\"consent\"), hydra.AcceptConsentRequestPayload{\n    Subject:     \"some-user-id\",\n    GrantScopes: []string{\"some-scopes\"},\n})\nhttp.Redirect(w, r, cr.RedirectUrl, http.StatusFound)\n```\nand that's it! This doesn't only work for Go but also for NodeJS, Java, Python, Ruby, ...\nIn case of JWK we would have to put a lot more effort in it, because we can't autogenerate the SDK.\nRegarding request roundtrips - it doesn't matter. The reason is that the login process is slower anyways with OAuth2 since we have the redirect dance anyways (initiate oauth2 request, get forwarded to login, type user/password, get redirected back to oauth2 provider, get reditrected to app, exchange code for token(s)). 20-30ms latency more will not worsen the user experience in any meaningful way.. Yes! It will be published as 0.10.0 which is a preview to 1.0.0. I still need to get some feedback on the new flows and SDKs and improved docs which is why I don't want to publish this as a 1.0.0-prerelease because there might be some breaking changes as we progress.\nI know that keeping BC is very important for developers, but it's equally important to improve developer experience. I hope you all understand this step :) I had some very good discussions with people outside of the GitHub community and a lot of people are telling me that it is more important to have good SDKs (which will now be possible) and make things as consumable as possible, even if it means that we'll break old things. However, I'll still keep updating 0.9.x with security patches if any arise!. This is now up to keto/ladon, see https://github.com/ory/keto/issues/11. This is resolved with 0.10.x. This is resolved. This has been added to the FAQ. nevermind - this already exists. Thank you!. Yeah that makes totally sense!. If you want, you can take a shot at it yourself.\nThe handler is here. You could probably build a check after here to see if members == \"\". If so, you could run a manager function that implements ListGroups(limit, offset). Then you would have to implement that function in the managers:\n\nsql\nmemory\nhttp\n\nAnd of course add some test somewhere around here where you check if the groups in the manager match the expected amount of groups.\nIf you don't feel confident with Go you could either ask on Gitter or let me know and I'll try to address it soon (no time guarantees though, sorry).. This does not apply to OpenID Connect ID Tokens:\n\naud\n    REQUIRED. Audience(s) that this ID Token is intended for. It MUST contain the OAuth 2.0 client_id of the Relying Party as an audience value. It MAY also contain identifiers for other audiences. In the general case, the aud value is an array of case sensitive strings. In the common special case when there is one audience, the aud value MAY be a single case sensitive string. . I created a new branch for 0.9.x: https://github.com/ory/hydra/tree/v0.9.x - can you rebase against that?\n\nAlso note that this might be an issue with fosite as well, go-jose is used there as well (version 1.0) so resolving this only here won't solve it properly (I think). This can be closed right?. I made this change to master as well (and switched to dep) which will be released with #630. I see, use of dep makes sense, the idea is to transition at some point anyhow. However, I had some issues with dep on windows which is why it's not included yet. I'm however open to accepting this change.\nOne thing though, could you add dep tests to travis.yml (similar to glide tests)?\nAlso, here's a 0.9.x branch: https://github.com/ory/hydra/tree/v0.9.x. Thank you!. I was unable to reproduce this.. Hey @joshuarubin the way you solved it is perfect. It is common to have a resource endpoints /resources which lists everything, and then query options like /resources?owner=1234 to request a subset (similar to limit & offset).\nThe only thing I would like to change is to remove rn:hydra:warden:groups:<member> and only do rn:hydra:warden:groups AC.\nI will now review your code changes and leave comments where they fit.. Damn, halfway through the review I noticed that you made this against the 0.9.x branch. I would much rather see it done against the 0.10.0 one, is that an issue for you?. > We would like to be able to get this functionality ASAP which would be less risky if we can stay on 0.9.x. However, I don't think it would be too hard to cherry pick the commits and get it working on master. If we can merge this into 0.9.x, I'll set up another PR to get it into master.\nI would love to see that. If you find the time, I'd also love to see that for #605 :). Nice! I'll go over the changes one more time. Regarding swagger, check out this script from the 0.10.x branch. Please make sure to use the latest stable version of go-swagger.. Thank you!. https://github.com/ory/hydra/releases/tag/v0.9.16. Whoops, what a blunder! Would you mind creating a PR? :). I fired up a quick pr myself: #618. Yep, totally forgot about that one.. https://github.com/ory/hydra/releases/tag/v0.10.0-alpha.8\nbuildchain will take a while (~30min) as always. this is solved via the new examples project. This has already been resolved, sorry :(. Nice! If you need help feel free to ask!. Nice! Yes, that should definitely be updated there!. Thank you, this should be fixed with 0.10.x however, are you on 0.9.x?. The docs always match latest master, so it's version 0.10.x. What I meant is that you are probably running a hydra version below 0.10.x which is why you see the issue you describe. This is the patch that fixed this:\nhttps://github.com/ory/hydra/commit/96df49822b1dbce648f324ee699f2ec93bbaea46. Thank you! Can you create a PR for it? The files are in ./docs. Thank you!. Hey, I found the error, it's a typo here:\n$ hydra clients create --skip-tls-verify \\\n  --id consent-app \\\n  --secret consent-secret \\\n  --name \"Consent App Client\" \\\n  --grant-types client_credentials \\\n  --response-types token \\\n  --allowed-scopes hydra.consent*\nspecifically\n--allowed-scopes hydra.consent*\nthat line should read\n--allowed-scopes hydra.consent. Oh yes absolutely! Would you mind updating that in the consent app as well? Thank you so much for this, you are helping a lot of people!. The scopes are stored in this SQL column - and I always welcome docs! :). They are defined in the http handlers, for example here or here.. I hope all your questions are answered and thus closing this issue. If questions remain feel free to come back here.. Thank you!. THank you!. Thank you once again!. I think we should disable the P521 generator for now, as it's not safe to use them for repeated use in private keys.. Ok, let's keep them then. As long as JWK/JWT spec talk of ES521 I think we should keep it that way. Definitely doesn't help though that there are naming inconsistencies now.. My bad, looks like I got mixed up, it's definitely ES512. I closed this because ES512 is now tracked in #651. Ok awesome, that works for me - I'll make a code review and merge if everything checks out!. Ah yes, this should have been fixed with https://github.com/golang/oauth2/commit/13449ad91cb26cb47661c1b080790392170385fd and is probably not included here because the lock file is outdates. I'm currently working on a PR that will also replace glide with dep and I'll make sure to include this change as well.\nThank you for the report!. Hm, not sure, the client secret is being unescaped here.\nIf your secret contains % (e.g. foo%bar) you should encode it so it becomes %25 (e.g. foo%25bar). @ruhavingfun22 did you manage to get it done? IMHO it should simply work with e.g. https://meyerweb.com/eric/tools/dencoder/. That sounds really frustrating, I'll take another look at this -> reopening. hydra connect has been deprecated on master. If the issue persists with flag --client-id or env var OAUTH2_CLIENT_ID let me know. base64decode(\"cGVyY2VudC1zaWduLWNsaWVudDpmb28lUWJhcg==\") is percent-sign-client:foo%Qbar but should be urlencode(\"percent-sign-client:foo%Qbar\") which is percent-sign-client%3Afoo%25Qbar and would be base64encoded cGVyY2VudC1zaWduLWNsaWVudCUzQWZvbyUyNVFiYXI=. See here for spec.. Yes! I've worked on PRs for JS and Go OAuth2 libraries that got that wrong. Using special chars like % is uncommon for OAuth2 so most have not encountered this before. My recommendation is to skip these special chars and only have url-safe chars. This will avoid issues with other libraries that get this wrong.. Not sure what's going on at @wojciechce but here:\ndocker exec -it hydra_hydra_1 \\\n    hydra clients create \\\n    --endpoint http://localhost:4445 \\\n    --id my-client1 \\\n    --secret 'sec%25ret' \\\n    -g client_credentials\ndocker exec -it hydra_hydra_1 \\ \n    hydra token client \\\n    --endpoint http://localhost:4444 \\\n    --client-id my-client1 \\\n    --client-secret 'sec%ret'\nkP8IPu3us--Hkp4hMpXc42CxMI-i8uLaKSPV3MYPmnU.udw5KphRBxYIJU9wx92VD4ZIcI1XrTP5ySyGehievUE\n```\n$ curl -X POST \\\n\nhttp://localhost:4444/oauth2/token \\\n  -H 'authorization: Basic bXktY2xpZW50MTpzZWMlMjVyZXQ=' \\\n  -H 'cache-control: no-cache' \\\n  -H 'content-type: application/x-www-form-urlencoded' \\\n  -H 'postman-token: 992fd5fe-c31d-504f-b7ec-928429b7ad55' \\\n  -d grant_type=client_credentials\n{\"access_token\":\"C3I_XRIK9nR4PtV_PFnGyy9WtZlI6JUv70BjCIDCtnw.vPlsAFM11pYh1XsL58Q7kql9WMTmIWnJ_iUB50nTT3M\",\"expires_in\":3599,\"scope\":\"\",\"token_type\":\"bearer\"}\n```\n\nSo everything is working as expected on our end.. I made a mistake earlier, we actually do not encode the whole username:password but instead base64(urlencode(username):urlencode(password)). Hope that settles this issue at last.. No problem :). Thank you for raising this issue. It is most certainly not a defect, but rather a feature request to the existing project.\nIt should be possible to spin up a python SDK using swagger-codegen as is done for node and go here. However, there will be some additions neccessary, such as requesting an access token using an established library (a quick google search revealed https://github.com/joestump/python-oauth2).\nWould you be willing to work on this? I have little python/flask/django experience.. >  I'm currently looking for an oauth2/OIDC solution that fits our needs that we can leverage and is not powered by anything that requires Auth0 in any way (As Auth0 is far too expensive with our number of users);\nYou are aware that hydra does not solve IDP (login, logout, pw reset, user registration), right?\n\nI have been told by our CTO that this includes upstream patches etc; I just have not found such a solution yet and this lack of python support is one of the things that make this project not a fit for us. \n\nAll endpoints of Hydra are REST so python support is definitely there if you know how to make REST calls. Using swagger-codegen is, by the way, probably a task of a couple of minutes (it autogenerates a REST client). You have to figure out how to use an oauth2 client anyways if you want to use oauth2 with python, so it's actually no additional work.\n\nI'm not able to commit myself or the team to any work for a project that doesn't already fit our needs in a basic way.\n\nI know the space very well, there are no OS projects that have full IDP, OAuth2, and OIDC capabilities and are scalable/cloud native (that I know of). Hydra is the only OAuth2/OIDC provider capable of plugging in to any IDP that doesn't have scaling issues and that works in container environments, but it also doesn't solve IDP itself. (if you do happen to know one, please share them here!). Absolutely no problem. The open source space of identity management is very difficult, primarily because identity management itself is simply not easy. For Hydra, I suggest looking at AWS Cognito for IDP and Hydra for OAuth2/OIDC. AWS Cognito is less expensive than Auth0, but does get expensive when lots of users are in play.. > Fully understand, and if my wording seemed odd my apologies but I'm working with expectations from others that seem.. unrealistic.. to me at this point.\nDon't worry, we've all been there.\n\nWe have enough users that paying per month for them is out of the question, so sadly Cognito isn't a possibility. \n\nThat's what I thought, typically that's the case when Auth0 isn't an option as well.\n\nWe can - and I suspect, will - have our own registration and management system to deal with IDP\n\nThis is something I can endorse. While IDPs typically have some common things (like storing a username and a password), they are also quite different as in what kind of profile data you store, how you want 2FA to work, if you want to support passwordless auth, and so on.\n\nthat external services can actually use our OAuth2/identty server\n\nThat is the definition of OAuth2 - libraries for any language exist (and Hydra is fully OIDC/OAuth2 compliant) so anyone is able to consume your OAuth2 APIs.\n\nJWT that doesn't have to make a call back to a central single point of failure to validate the token, and can do so using Python, Golang, etc and not Java/PHP or their ilk.\n\nJWTs are bad practice, because they are not opaque to the client and because JWTs have been subject to multiple vulnerabilities in the past. This is why Hydra does not issue JWT access/refresh tokens and why you almost never see JWT access/refresh tokens in the wild. We are however booting up a commercial product called ORY Gatekeeper ( https://www.ory.am/products/api-security ). Gatekeeper is basically an OAuth2 provider (ORY Hydra w/ GroupCache support), API firewall (ORY Oathkeeper - later to be released as core OSS), and a management UI (ORY Security Console) for both. Oathkeeper transforms opaque access tokens to JWTs for internal service consumption. If you want to get around developing that stuff for yourself it might be an option.. > Everybody seems to want to sell an auth solution, yet people who want one don't want to buy it.\nSomebody's gotta get paid to build that \"free\" stuff.\n\nDo you have anything I can toss up the ladder on the JWT stuff being an antipattern? I appreciate that we are off topic at this point but I'm interested in understanding why JWT's are an issue when tokens themselves expire and should not have data in them that should be considered \"insecure\" to lose anyway.\n\nThe spec itself: https://tools.ietf.org/html/rfc6749#section-1.4 and https://tools.ietf.org/html/rfc6749#section-1.5\nJWT (those aren't endorsements, just top 5 google search results):\n https://connect2id.com/products/nimbus-jose-jwt/vulnerabilities\n https://paragonie.com/blog/2017/03/jwt-json-web-tokens-is-bad-standard-that-everyone-should-avoid\n* http://blogs.adobe.com/security/2017/03/critical-vulnerability-uncovered-in-json-encryption.html\nAlso, obviously, you can't revoke JWT access tokens and have to wait up to 60 minutes (or however long your expiration is) in worst case scenario.. Cool, feel free to create a PR. Closing this, doesn't mean I'm against a python SDK - just want to clean out some issues. Would happily accept a PR. If you need further info or help feel free to open a new issue or comment here. Closed by #672. This has been improved as we're now explicitly telling people to clean up the environment. > Also, if revoke doesn't have a similar scope or policy restriction, any token could be used to revoke any other token. (I have not tested this scenario yet)\nRFC states:\n\nThe authorization server first validates the client credentials (in\n   case of a confidential client) and then verifies whether the token\n   was issued to the client making the revocation request.  If this\n   validation fails, the request is refused and the client is informed\n   of the error by the authorization server as described below.\n\nWhich is currently not the case (nice catch):\nhttps://github.com/ory/fosite/blob/master/handler/oauth2/revocation.go. Revokation is now tracked as #676. Both are resolved. This is very much intentional, not only does it reduce the docker image's size, it's also unnecessary, even risky, to run production systems with shell. You can do everything you did before (which is executing hydra commands) by overriding the command:\n$ docker run oryd/hydra help\n$ docker run oryd/hydra clients create\n$ docker run oryd/hydra ...\nIf you need shell access to the container you will need to use your own Dockerfile definition for now.. Yes, the tutorial hasn't been updated to the latest docker images, which is also why the .13 tag is used! :). Looks like that library is specifically using Google's OAuth2 flow which uses client id and secret in the post body instead of in the header which is, according to spec, not the best approach:\nhttps://tools.ietf.org/html/rfc6749#section-2.3.1\n\nIncluding the client credentials in the request-body using the two\n   parameters is NOT RECOMMENDED and SHOULD be limited to clients unable\n   to directly utilize the HTTP Basic authentication scheme (or other\n   password-based HTTP authentication schemes).  The parameters can only\n   be transmitted in the request-body and MUST NOT be included in the\n   request URI.\n\nYou would have to make changes to the library and include the client id and secret in the authorization header using basic authorization.. It's actually funny that google does that, Golang has actually an extra variable for that: https://github.com/golang/oauth2/blob/f95fa95eaa936d9d87489b15d1d18b97c1ba9c28/internal/token.go#L92. See https://en.wikipedia.org/wiki/Basic_access_authentication - the client id is the username and the client secret is the password. > Is there a setting in Hydra that would enable reading the code from the post body (since it's discouraged in the spec, but not forbidden)?\nNo, unfortunately not. yes, only the client id and secret are incorrect, everything else stays the same. Try setting LOG_LEVEL=debug, it will give more information on what happened. Also, the header looks extremely malformed, there shouldn't be any quotes:\n\n. Nice, congratulations! :). Ah yes, because if only one scope is allowed, that won't match. Feel free to create a PR!. This is resolved now. Indeed, nice catch! If you have the time, I would welcome a PR!. Merged. Perfect, thank you!. This actually mirrors the behaviour of AWS IAM policies. Since it's a huge breaking change and would require a lot of manual work I think it's safe to keep this as is for now. Let me know if anyone disagrees.. Thank you!. How stable is the Prometheus protocol/payload you would like to include?. Is it possible to pipe stdout/stderr to prometheus instead?. If anyone wants to tackle this, I'm open to discuss it and review PRs :). Solved on master, see #827. hydra help host | grep log\n- LOG_LEVEL: Set the log level, supports \"panic\", \"fatal\", \"error\", \"warn\", \"info\" and \"debug\". Defaults to \"info\".\n- LOG_FORMAT: Leave empty for text based log format, or set to \"json\" for JSON formatting.. Does the JSON DateTime format not include time zones? I'd have to check what the convention is there, but if it's UTC then nice find! :). Hm, the timezone should be appended, see: https://en.wikipedia.org/wiki/ISO_8601#Time_offsets_from_UTC\nAny idea why that isn't happening?. So I checked this myself and it seems like UTC() should not be necessary:\n```go\npackage main\nimport (\n    \"encoding/json\"\n    \"fmt\"\n    \"time\"\n)\ntype TT struct {\n    T time.Time\n}\nfunc main() {\n    t, _ := time.Now().Zone()\n    fmt.Printf(\"%s\\n\", t)\nout, _ := json.Marshal(&TT{T: time.Now()})\nfmt.Printf(\"%s\\n\", out)\n\nvar tt TT\n_ = json.Unmarshal(out, &tt)\nfmt.Printf(\"%s\", tt.T.Format(time.RFC3339))\n\nout, _ = json.Marshal(&TT{T: time.Now().UTC()})\nfmt.Printf(\"%s\\n\", out)\n\n_ = json.Unmarshal(out, &tt)\nfmt.Printf(\"%s\", tt.T.Format(time.RFC3339))\n\nout, _ = json.Marshal(&TT{T: time.Now().Add(time.Hour)})\nfmt.Printf(\"%s\\n\", out)\n\n_ = json.Unmarshal(out, &tt)\nfmt.Printf(\"%s\", tt.T.Format(time.RFC3339))\n\n}\n```\nOutput:\n```\nCET\n{\"T\":\"2017-12-07T22:30:59.6512843+01:00\"}\n2017-12-07T22:30:59+01:00\n{\"T\":\"2017-12-07T21:30:59.6517876Z\"}\n2017-12-07T21:30:59Z\n{\"T\":\"2017-12-07T23:30:59.652284+01:00\"}\n2017-12-07T23:30:59+01:00\n```\nAs you can see, there does not seem to be any data loss when marshalling/unmarshalling.\nWhich database are you using? Maybe there's something funny going on there.. Looks like that one slipped through. Would you mind creating a PR?. > The session seems to persist the request.Form so maybe this can already be done with slight modification of the challenge session persistence?\nYes, that's the case indeed\n\nIf a request comes to the /oauth2/auth handler with an audience URL parameter (in addition to the client_id, state, redirect_uri, etc. like Auth0 does), then this can be persisted in the ConsentRequest and returned as part of the Session.\n\nI'm not quite sure at the moment - is this specified in some spec somewhere? Auth0 is known to bake in some weird custom stuff in their system which is also why they had to basically deprecate all the old APIs.\n\nSide note, it looks like hydra is treating every auth request as an OpenID Connect request? Unless scope=openid is specified, you do not need to force the aud=client_id behavior. All Sessions seem to be represented internally as fosite openid.DefaultSessions. I don't think this impacts anything but was confusing to me as I was trying to use hydra's handlers and wanted to use JWT tokens but got an OpenID token instead.\n\nKinda, we have handlers which \"hook\" in functionality based on request parameters. If openid is specified as a scope, an OpenID Connect handler will try to process the request.\n\nDepending on how issue #772 is implemented, this might be rolled up into those changes?\n\nAbsolutely. This is no longer required because hydra does this automatically. * [x] Certification requires access to the userinfo endpoint which is tracked as #652\n [x] Certification requires allowing sending client secrets via POST -> fosite\n [ ] Support acr value: No acr value present in the ID Token [The acr value in the ID Token]\n [ ] Check how we can support prompt\n [ ] Check how we can support max-age\n* [ ] Error codes need to be adopted to OpenID Connect conformity for reusing authorize codes. \n. All required self-service tests pass now.. Resolved by https://github.com/ory/hydra/pull/694/commits/e12d1ae5d2fcfb6aded0f316443fb777e7f9922a. This is resolved on master. Upstream https://github.com/ory/fosite/issues/230. ### OIDC compliant:\n\ngraph TD\nH{Hydra} -->|Redirects to consent app with consent request ID| C{Consent App}\nC -->CRP(Check if consent url query `?consent=$consent-id` is set)\nCRP-->|no|Err(Notify user with error message)\nCRP-->|yes|CG(Fetch consent request payload from `GET /oauth2/consent/request/$consent-id`)\nCG-->CGL(Check `mustAuthenticateUser`)\nCGL-->|true| FORCELOGIN(Force login, show login ui,  acr)\nCGL-->|false| LOGINCHECK(Is the user signed in?)\nLOGINCHECK-->|true| CONSENTCHECK(Check `mustConsent`)\nLOGINCHECK-->|false| LOGIN(Show login ui)\nLOGIN-->|successful| CONSENTCHECK\nLOGIN-->|unsuccessful| LOGIN\nFORCELOGIN-->|successful| CONSENTCHECK\nFORCELOGIN-->|unsuccessful| FORCELOGIN\nCONSENTCHECK-->|true| CONSENT(Ask user to authorize application and scopes)\nCONSENTCHECK-->|false| ACCEPT\nCONSENT-->|User authorized application| ACCEPT(`PUT /oauth2/consent/request/$consent-id/accept`)\nCONSENT-->|User aborted authorization| REJECT(`PUT /oauth2/consent/request/$consent-id/reject`)\nACCEPT-->END(Redirect user to redirectUrl from consent request payload)\nREJECT-->END\nSimple (not OIDC compliant):\n\ngraph TD\nH{Hydra} -->|Redirects to consent app with consent request ID| C{Consent App}\nC -->CRP(Check if consent url query `?consent=$consent-id` is set)\nCRP-->|no|Err(Notify user with error message)\nCRP-->LOGIN(Force user login in, show login ui)\nLOGIN-->|successful| FETCH(Fetch consent request payload from `GET /oauth2/consent/request/$consent-id`)\nLOGIN-->|unsuccessful| LOGIN\nFETCH-->CONSENT(Ask user to authorize application and scopes)\nCONSENT-->|User authorized application| ACCEPT(`PUT /oauth2/consent/request/$consent-id/accept`)\nCONSENT-->|User aborted authorization| REJECT(`PUT /oauth2/consent/request/$consent-id/reject`)\nACCEPT-->END(Redirect user to redirectUrl from consent request payload)\nREJECT-->END. ### Consent flow in hydra\n\n```\ngraph TD\nUA{User Agent}-->|Initiates OpenID Connect Flow| H{Hydra}\nH --> SESSC(Check if cookie session exists)\nSESSC-->|yes| REQC(Check request for prompt/maxAge)\nSESSC-->|no| CONSENTF\nREQC -->|promp and maxage not set| CLIENTC1(Check if client was previously authorized using specified scopes)\nREQC -->|prompt=login| CONSENTF(Redirect to consent app with mustAuthenticate=true and mustConsent=true)\nREQC -->|prompt=consent| CONSENTCF(Redirect to consent app with mustConsent=true)\nREQC -->|prompt=none| CLIENTC2(Check if client was previously authorized using specified scopes)\nREQC -->|maxAge reached| CONSENTF(Redirect to consent app with mustAuthenticate=true and mustConsent=true)\nREQC -->|maxAge not reached| CLIENTC1\nCONSENTF --> CONSENTCB(Check if consent was accepted)\nCONSENTCF --> CONSENTCB\nCLIENTC1 --> |yes| GRANT\nCLIENTC1 --> |no| CONSENTCF\nCONSENTCB --> |accepted| GRANT\nCONSENTCB --> |denied| DENY(Deny request)\nCLIENTC2 --> |yes| GRANT(Grant request)\nCLIENTC2 --> |no| ERROR(Show error)\n``\n. This is resolved on master. Resolved by https://github.com/ory/hydra/commit/072e54b6f2afbcbd9b1eafedb22b2fc50d2d87f7. It's not very unlikely that the root client will not be able to make any grants except theclient_credentials` grant with 1.0.0. Since it's such a highly priviledged client it shouldn't be used for anything except setting up your environment.\nCreating a new client on the other hand is as easy as\nhydra clients create -a scope1,scope2 -c http://my-callback\nSo I don't really see the need for making the root client even more configurable.. Ok, that sounds really frustrating so let's try to solve this in a way that falls in line with the possiblities at hand. First of all, what you are doing can also be solved like this:\ndocker run --rm -it \\\n  -e CLUSTER_URL=https://ory-hydra-example--hydra:4444 \\\n  -e CLIENT_ID=admin \\\n  -e CLIENT_SECRET=demo-password \\\n  --network hydraguide \\\n  oryd/hydra:v0.10.7 \\\n  <command>\nwhere (obviously) the network should be the network you bring up in docker compose. By the way, you can set the docker compose name prefix with -n or something (I'd have to look it up).\nAnother possibility would be to have a init.d directory similar to what PostgreSQL/MySQL is doing where config files are loaded from on first boot. I would need some time to think this approach over though.\nIn our system, we are running some bash scripts that run hydra import on all files of a directory. They have exponential back off so it will work even if Hydra takes 5 seconds to start on initial install.\nBy the way, we are also working on a few helpers that are even pluggable to GitHub's API for deploying clients, policies etc in Hydra, but that's still work in progress and will not be a completely open source product.\nIs there anything where you say that makes sense?.  > The docker example you give is how we're doing it right now. But because of the way docker-compose works and the lack of a scripting lang inside of the hydra container I need to spin up a separate docker-compose service for each hydra command I want to run.\nI'm not sure I'm getting this. You can attach a docker run command do a network created by docker compose, as seen here:\ndocker network ls\nNETWORK ID          NAME                                    DRIVER              SCOPE\nad2a7d116d21        bridge                                  bridge              local\na8b5ee5b9e29        compose_ory-am-example-project-subnet   bridge              local\nba4a8561b699        compose_platform-subnet                 bridge              local\n911567b847f7        host                                    host                local\n4938a70da3a1        hydraconsentappauth0_subnet             bridge              local\naa763277996f        none                                    null                local\nTypically docker-compose uses the canonicalized (no spaces iirc) directory name as prefix. You can override this with docker-compose -p someprefix <command>. Then you can easily run a docker run command that connects to the network, identified by <prefix>_<network-name>.\n\nSadly this doesn't exist for policies so that will still need to be a separate command.\n\nI can proudly say that it does. Unfortunately, it's not consistent with clients import (had this in the back of my head for a while, good that we're seeing this in the wild now -> #701 ). It's hydra policies import -f a.json,b.json\nHope this helps.. While it's not the most beautiful, you can chain commands in the image like this:\n$ docker -rm -it /.../ \\\n     clients create /.../ \\\n       && hydra foo bar \\\n       && hydra bar bar\nThe other alternative would be to have a global import (maybe init?) command hydra import / hydra init which creates the database schemas and imports a JSON file containing clients / keys / policies / groups:\n{\n  clients: [],\n  keys: [],\n  policies: [],\n  groups: []\n}\nThis would also allow us to do something like hydra export although it won't be possible to export existing tokens/consent flows/client secrets.. This could actually be a good idea. We could provide example configs here that set up e.g. a development environment, or something more advanced. I kind of like this idea!. I see your pain :D How do you feel about: https://github.com/ory/hydra/issues/699#issuecomment-351013866. > oh and mind you, this is just setting up hydra and traefik. We've also got minio, cockroach, mysql, mailhog, jaeger just to name a few supporting services. Not even mentioning our own 20+ services...\nMicro service automation is very hard.\n\nAlso adding a simple /bin/sh implementation in the container would help in the short term as well because we could string all those commands in a single docker run statement like you suggested also in that comment but currently doesn't work.\n\nWe could add an -alpine image to the docker build chain.. > That would be a solution that wouldn't need any actual code changes. And people could opt in to it.\nOk let's go for this now and introduce some elaborate way to deal with this at a later stage.\nTracked as #703. You could have solved this with the stratch image:\nhydra:\n    image: $HYDRA_IMAGE_SCRATCH\n    command: |\n      'migrate sql $$DATABASE_URL &&\n       hydra host --dangerous-force-http'\n    depends_on:\n      - postgres\n    environment:\n      SYSTEM_SECRET: $SYSTEM_SECRET\n      DATABASE_URL: postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@postgres:5432/$POSTGRES_DB?sslmode=disable\n      ISSUER: http://projectx.localhost/api/auth\n      CONSENT_URL: http://projectx.localhost/api/rest/v1alpha1/auth/consent\n      FORCE_ROOT_CLIENT_CREDENTIALS: $HYDRA_ROOT_CLIENT_ID:$HYDRA_ROOT_CLIENT_SECRET\n      DISABLE_TELEMETRY: \"1\". $ docker run --rm -it oryd/hydra:v0.10.8 version && hydra version\nVersion:    v0.10.8\nGit Hash:   0d47938fe3524060a164f795bd20b8ffa95cf577\nBuild Time: 2017-12-12 12:50:37.518901 +0000 UTC m=+0.002692301\nVersion:    dev-master\nGit Hash:   undefined\nBuild Time: 2017-12-12 12:50:38.7407802 +0000 UTC. Oh sorry, nevermind, the second runs in my local environment \ud83e\udd26\u200d\u2642\ufe0f . I'm not sure how much sense this makes for clients. The API currently doesn't allow importing of hashed secrets (and also shouldn't) so we can't really ex- & import clients. I think the DB has been quite stable with migrations so I don't really see a point in having this export function. Also closing due to lack of public interest.. Thank you for your contribution. As explained in https://github.com/ory/hydra/issues/699#issuecomment-350829516 I don't feel this is a smart move. It puts too much emphasis in a client that should only be used for management.\nClosing, but feel free to persuade me :). Ha nice, feel free to update this after merge :). This is solved already. This can not be solved before Go 1.10 is out.. This is resolved on master. done. Solved on master (ory/docs). There are multiple things which need to be addressed:\n\n[ ] Being able to revoke a subjects's (user + oauth2 client) all access + refresh tokens\n[ ] Being able to revoke access of a specific application (oa2 client) for a user \n[ ] Being able to destroy a user's session with regards to the consent flow\n\nLet's take a closer look at the options.\nDestroying previous consent session\nI think this one's pretty easy. We could add something like DELETE /consent/requests?subject=<subject>[&client=<client>] which would delete all previous consent sessions, thus requiring the user to re-authenticate.\nThis could probably also revoke the access & refresh tokens that were issued with that request.\nUser logout\nThis would only destroy the user cookie but not revoke any tokens. Maybe along the lines of /oauth2/destroy-session?. This has been solved by another PR. Thank you for your report.\nThis is caused by httprouter which automatically redirects thinks like domain.com//foo to domain.com/foo and domain.com/foo/ to domain.com/foo. As it does so based on the route name, not the issuer url, there is no clear way to resolve this issue in that specific case.\nAs all endpoints are properly advertised in the discovery endpoints, this will be a nofix, unless serious concerns arise, or practical ideas on how to resolve it.. This has been resolved with #732. I'm not sure I understand the question. Users are automatically resolved to their respective groups (if they are assigned to one) and the policies attached to those groups are also checked. Is that what you're looking for?. https://ory.gitbooks.io/hydra/content/access-control.html#subject-condition. \n. Ah I see, that is currently not possible natively. It might be solvable using conditions though.\nAdding that functionality to the the way policies are used wouldn't make a lot of sense as it's a very specific use case and it would further complicate the template language.. > Is it correct that all \"conditions\" are based upon a context?\nYes\n\nYou can't write conditions based on subject->resource only.\n\nYou can't, but you can use some of the resource information in the context. If there are open questions left feel free to comment / reopen :). #729. Hey yes, there is definitely an issue with UTC time codes, previously reported at #679 - the issues is also already being addressed in #720 but that PR hasn't landed yet. I'm closing this as it's a dupe :). That look pretty solid already, thank you!\nCould you add a quick guide on how to instantiate this to docs/sdk/php.md?. ping @pnicolcev-tulipretail :). Thank you!. This PR was made against master which is currently scheduled for the first alpha of 1.0.0, but that will take a some time before being published.\nCould you re-open this PR against the 0.11 branch? Then I can create a release for that version which includes the PHP SDK.. Damn, I see that the branch was deleted... Maybe you have a backup locally?. I'm not sure if this makes sense. Typically, there should not be too many keys in a JWK set (maybe 2 to 8 after key rotation), and we would want to have all keys available to properly perform key rotation. Seems like a non-issue to me.. This is resolved already. This is resolved. Fixed on master. This is now tracked as https://github.com/ory/keto/issues/10. This has been resolved previously. resolved. Unfortunately very complex, lambdas are quite different to the way stdlib net/http works :(. I think it could be possible, on the same time it's locking this project into AWS, and the feature would not benefit other platforms. I'm unfortunately not too thrilled for this (sorry), but would be open to review some third-party project taking a look at this.. I'm closing this issue because we will, most likely, not offer an official adapter for AWS Lambdas for now. This doesn't mean that it's discouraged to give it a try for yourself (and potentially accepting it in a PR), but primarily at cleaning up stale issues.. That looks pretty reasonable from a code-perspective. Is it maybe possible to implement this gateway on a network level? For example it accepting requests from AWS Lambda and forwarding it to Hydra like a reverse proxy? It would IMO make more sense here, because we don't have an explicit dependency on a vendor's closed source platform. I have literally never worked with AWS Lambda, so excuse my ignorance here ;). Thank you for bringing this to my attention. I retracted the content until a fix is available.. Resolved with 0.11.1. Yes:\n\nStoring the configuration is, for example, done here: https://github.com/ory/hydra/blob/master/cmd/connect.go#L57\nRetrieving the configuration is automatic and accessible through, for example c.ClientID. To add a field to this configuration, you must add a field here\n\nI'd say that the host process should always show that info, and connect only if it has not been entered yet.. I agree, it has less attack surface for leaking email addresses. Resolved. See #759. The error says that something is already allocated at that port (4445), you either have something running on that port locally, or hydra is already running in your docker environment.. Actually, it would be much better to have a docker image which is capable of doing that using the hydra CLI!. Examples how to do that are now at https://github.com/ory/examples. Thank you!. > shouldn't this function (and the next one) be non capital because it is not checking the request at all, it is just a helper right?\nI'm not sure right now, I think they need to be upper case for swagger docs to work. I'd have to check, otherwise all of the handlers can be lower case.. This is now tracked as https://github.com/ory/keto/issues/10. Thank you for your feedback, it is much appreciated! I am not sure if this got through, so I quickly want to reiterate on something:\nThe login / authentication piece (which is part of the consent flow) would not be replaced. Only the consent screen where the resource owner grants scopes would be moved out of the consent app. It should be possible to make this template customizable, with the usual downsides (not your favorite template language, no css/js toolchains, simple markup). It would still be possible to skip consent with a special scope (e.g. force-consent) issued to first-party clients.\n\nFrom our perspective we'd like to retain the UI-less option and have the flow diagram in the issue replicated in the hydra docs as a example of how to interpret the mustAuthenticateUser, etc options hydra would provide.\n\nIt doesn't really end there, unfortunately. There are many different use cases and some of them are not implementable using the current consent flow. These use cases have various primitives, namely:\n\nUser is not authenticated at Hydra\nUser is not authenticated at Consent App\nUser is authenticated at Hydra\nUser is authenticated at Consent App\nUser has not authorized app before\nUser has authorized app with specified scopes (or subset of those) before\nUser has authorized app, but app needs more scopes now\n\nAdditionally, we have OIDC prompts:\n\nprompt=none fails if user does not have a session at Hydra.\nprompt=consent must show consent screen, does not require authentication.\nprompt=login must (re-)authenticate user, consent screen is optional (and based on previous consent).\n\nFor the consent app it is currently impossible to check if a user has previously granted access to an application or not. This implies that with any (re-)authentication, the user must also re-authorize the app. While this doesn't really bother OIDC compliance, it does bother user experience. While it would be possible to fix that using another API call, it adds another layer of complexity.\nThe consent app is also not capable of just handling consent without prior authentication if the user is authenticated in Hydra but the client app is lacking authorization.\nIn any case, the question I have for you is the following:\nDo you want to implement the consent screen, where you select the scopes, yourself - or is it ok if Hydra handles that. Again, the log in screen will not be touched.. Oh and a last one, we definitely want to have a reference implementation for the consent app. The unfortunate issue is though, that we won't support login there, so there's still stuff that developers need to adapt / change, and the more complex this flow gets, the less secure it becomes.. > Some scope grants may be implied or mandated by a subject's role within the organisation, for example, which is probably not capturable in a template based workflow.\nIf you were to do this, it would be a security issue - and our OAuth 2 authorization framework is designed in a way that this isn't possible either! Scopes are not what a user can do in a system, scopes are what you allow a certain application to do on a user's behalf. It doesn't say what the actual user is allowed to do or not. We might add the possibility to auto-grant certain scopes (e.g. offline) but it's not clear yet.\n\nSo, if I understand correctly and this change were to become something like splitting what is now called a \"consent app\" into a \"show and select scopes\" app and a, possibly, separate \"login provider app\", I think that could work for us.\n\nYes\n\nPresumably hydra would take care of tracking whether the token subject logged in before and what scopes have and have not been previously granted for the client?\n\nThat's basically the idea behind this issue. #720 already takes care of some pieces here but while developing it I noticed that there are certain inconsistencies which are not resolvable with the current flow.\n\nWhile we're at it, I suppose there could also be a dedicated error reporting endpoint. So the hydra configuration now contains URLs pointing to a \"select and show scopes\" endpoint, a \"perform user login\" endpoint and a \"display error\" endpoint. The select and show scopes and error endpoints could default to UI apps provided by hydra.\n\nThat was one of the ideas how to modify those pages. It would probably not make it in to 1.0.0 because it would require significant work in order to make this bombshell secure. For the error endpoint, it would be easier because it's not that of a security issue.\n\nBut advanced users can provide their own endpoints for all three. (Sorry, on mobile and hit \"submit\" a bit early.)\n\nWe definitely want to have an option to extend the UI. Either directly via Hydra (which is as you pointed out not perfect) or through some other means.\nIn conclusion: Now that you have a better understanding, what's your take at this? I really see that the no-ui approach is something that propelled Hydra to what it is today and also to what it sets apart from the competition. I am actually sort of drifting in direction of having separate login, consent, and error endpoints (with default state of the art apps), but the flow has to be air tight.\nI might draft something today or in the coming weeks, and would really appreciate \ud83d\udc40 to make sure it's headed in the right direction.. Ok, so let's define this a bit.\nTerminology\n\nAuthorization Server (AS): That's Hydra\nUser Authentication (UA): The process where the end user inputs username and password (or other types of credentials like biometric data) into a UI.\nApp Authorization (AA): The process where the end user explicitly allows an OAuth2 client to perform certain actions on his/her behalf. Typically a UI where the user ticks some boxes (\"Allow access to my profile data\").\nError Handling (EH): When clients make invalid requests that must not be handled by the client itself - for example when the redirect URL is invalid - must be shown to the end user.\n\nMotivation\nThe current consent flow inhibits Hydra's ability to properly handle previous user authentication and app authorization. This does not certainly contradict OIDC certification, but it reduces user experience. Our motivation is to find a highly customizable and secure flow for resolving this issue, with keeping implementation as easy as possible.\nHow it works today\nThe current consent flow consists of two pieces:\n\nUser Authentication\nApp Authorization\n\nThese two are combined into one flow - namely the consent flow. Due to this it is not possible to separate User Authentication from App Authorization which causes the issues described in motivation.\nHow it should work in the future\nWe will explore different ideas in the following sections.\nThree endpoints for User Authentication, App Authorization, and Error Handling\nOne idea is to have four separate endpoints for AS, UA, AA, EH:\n\nAS: https://hydra.mydomain.com/\nUA: https://auth.mydomain.com/login\nAA: https://auth.mydomain.com/consent\nEH: https://auth.mydomain.com/error\n\nThere are four possible environments in which an authorization request exists:\n\nThe end user is not authenticated and has never authorized the application with the requested set of scopes.\nThe end user is not authenticated and has authorized the application previously with the requested set of scopes.\nThe end user is authenticated but has never authorized the application with the requested set of scopes.\nThe end user is authenticated and has authorized the application previously with the requested set of scopes.\n\nUse cases\nUse case 1\n\nUser Authentication\nApp initiates OAuth2 Authorize Code / Implicit flow.\nHydra requires authentication, redirects to UA.\nUA authenticates end user with some credentials. UA MUST ALWAYS authenticate the user - disable session management!\nUA notifies Hydra of user authentication and transmits user data (Hydra will filter out data based on OIDC defined scopes)\nUA redirects user to Hydra\n\n\nApplication Authorization\nApp has never been authorized by the user with the requested set of scopes.\nHydra redirects to AA\nAA fetches information about this authorization request (like requested scopes) and asks for authorization\nAA pushes authorization details (accepted / rejected + granted scopes) to hydra\nAA redirects to hydra\n\n\nHydra continues with OAuth2 flow\n\nUse case 2\n\nSame as use case 2.1\nApplication Authorization\nBecause application has been authorized previously with the requested scopes, the requested scopes are auto granted and no user interaction is required.\n\n\nHydra continues with OAuth2 flow\n\nUse case 3\n\nUser Authenticatoin\nBecause user is authenticated already, Hydra goes straight to handling application authorization. Note that user data (eg email claim in ID token) can not be updated in this case.\n\n\nSame as use case 1.2\nHydra continues with OAuth2 flow\n\nUse case 4\n\nSame as use case 3.1\nSame as use case 2.2\nHydra continues with OAuth2 flow\n\nDiscussion\nLet's take a look at advantages / disadvantages:\n\nAdvantages:\nIt is possible to properly hand previous AA and UA in Hydra, greatling reducing adoption complexity.\nWe would probably ship a default application for handling AA so all devs need to do really is implement UA.\nDisadvantages:\nIt is not possible to update user data when authentication is \"cached\" in Hydra. This includes any data in access and id tokens, as well as Hydra's built-in /userinfo endpoint.\nFrom our perspective, the flow is quite complicated with many moving parts. We have to be especially careful when designing it and it would take an extended period of time before this can be declared stable.\n\nHydra handles app authorization\nIn this case, Hydra would handle AA with a built-in UI, while delegating UA to the customizable login endpoint.\n\nAdvantages:\nDevs don't need to think about AA\nThe flow is easier to implement (on our side) and has less surface for vulnerabilities\nWe can standardise the AA and it will be really easy to integrate, because all a dev needs to do is implement UA\nDisadvantages:\nUI customization can only go so far - CSS and JS options are limited and Go's HTML template language is terrible IMO\nNo business logic customization. While it would probably cover 80% of use cases, it wouldn't cover the 20%. From what we've heard, full customization of the ui flow is why this project stands out.\ni18n is not pretty with Go's current ecosystem - no good solution exists and no stdlib either\n\nFinal Note\nPlease let me know which direction you think is the right one. I will draft up some charts for the solution which gets people more excited.\n. Here are some high level squence diagrams for the aforementioned issues.\nThree endpoints for User Authentication, App Authorization, and Error Handling\nThe error endpoint is not really included here because it's an edge case with almost no implication to security\n\nHydra handles app authorization\n\n. > The two endpoint case (AS, AE) is also workable but is likely to open some flood gates w.r.t. feature requests for improvements to templating/customisation/etc which might dilute hydra's \"small, simple, easy to grok\" nature.\nI agree. You convinced me (95%), thank you very much for your valuable input! I would really appreciate your take on the redirect flows and stuff like that which I will post in this issue soon.. Ok, so there are multiple moving parts where we need to be sure that no attacker is able to swoop in. We would rely on the same measures like OAuth2 for protecting the total flow which is TLS must be enforced everywhere.\nAttack Scenarios\nTricking Bob to authenticate\nScenario:\n\nMalice initiates an OAuth2 flow by clicking \"Authorize\". Malice is redirected to the authentication endpoint login.com/login?login_challenge=1234\nMalice convinces Bob to open login.com/login?login_challenge=1234 and authenticate\nNow that login_challenge=1234 is associated with Bob, Malice could trick the Authorization Server to issue tokens on Bob's behalf.\n\nMitigation:\n\nThe Authorization Server issues a login verifier which is only visible to the person that performed the login. In this case, Malice would not know what the verifier is because only Bob sees it, and because it is protected via TLS.\nThe Authorization Server issues a CSRF session to the person initially requesting the OAuth2 flow. In that case it would be Malice. If a verifier is received that does not match the CSRF session, the request is blocked and the challenge/verifier banned.\nIf a verifier is used twice, all access and refresh tokens associated with it are revoked and the challenge/verifier is banned\n\nTricking Bob to consent\nScenario:\nAssuming that Bob authenticated and is now asked to grant permission using a consent_challenge, and that Malice is able of reading consent_challenge, Malice would be able to grant permission for the app on Bob's behalf and optionally receive the authorize code.\nMitigation:\nIssuing the consent_challenge requires prior authentication, either through a session cookie or through performing the authentication flow. Thus, Malice could only have access to a consent_challenge for his own authenticated session, unless he is able to MITM the consent_challenge somewhere, or Bob's session cookie.\nTricking Bob to disclose sensitive information\nScenario:\nMalice authenticates with his account and authorizes the requested scopes. He is now in possession of the consent_verifier and tricks Bob into using that verifier at Hydra. Now, Bob is authorized as Malice and Malice could trick Bob into submitting confidential data to Malice's accounts (e.g. passwords, credit cards, ...).\nMitigation:\nBecause Bob does not have a valid CSRF session (Malice initiated the flow and only Malice has the CSRF cookie in the user agent9, the consent_verifier request will fail. It's thus not possible to trick Bob.\nFlow overview\nWith the above scenarios and mitigations, I established a flow that would look like the following graph. A flow diagram will follow as well to properly document decisions with regards to these scenarios.\n\n. Thank you for your feedback @pnicolcev-tulipretail - your points are very sensible and you draw some good conclusions which push me further in the direction of the 2-legged auth/consent flow.\n\nThe only potential concern I can think of is that you state: \"UA authenticates end user with some credentials. UA MUST ALWAYS authenticate the user - disable session management!\"\nWe actually have incorporated a SAML authentication endpoint for a 3rd party (a-la Dex) and they're in charge of sessions, as opposed to our consent app. I believe we can force a login with them with our authN assertion, so hopefully this is something we can work around.\n\nThis is a must for OIDC compliance!\n\nI've not properly had a change to think about the flow from a security perspective but from a functionality perspective this looks to be the right shape of things for us.\n\n@rjw57 I'm looking forward to your feedback wrt this.. > * A way to present back to a user what applications they have previously consented to, and to revoke consent on a per application basis\n\n\nA way to revoke all application consents at once (for example if we believe a user account has been compromised)\nFinally - for developers new to the Hydra project a 'blessed' implementation (similar to the existing express and go consent example apps) for all endpoints would allow people to get up and running with Hydra with minimal effort. We would be happy to contribute.\n\n\nAll three are very sensible feature request!\n\nSo I've had time to have a look at the flow proposed above. It seems sensible but, of course, the proof is in the implementation. I see that lessons from issues discovered in the current consent flow have been folded in which is good.\n\nThank you! If it's ok, I'll request your review when the PR is up. Obviously, it will be a larger one because there are a couple of things that will change.\n\nIt looks like the consensus is falling on the three-endpoint solution and I'm going to echo @pnicolcev-tulipretail and @dtt101's enthusiasm for it from a UI-less perspective. (And, @dtt101, waves at Pi towers.)\n\nI embrace the consensus, I think it's a good middle-ground for what we need to achieve!. > Did you consider a use case, that giving consent to certain scopes or even everytime getting another token might require a second factor of a user or even a fresh login in this concept?\n\n2FA on certain scopes: That's still possible. We can include the scope information in the authentication request so it should not be a big deal.\n2FA on token re-issuance: Not sure what you mean here? Are you talking about refresh tokens or performing the authorize code flow a second time?\n\nIn general, 2FA should be requested by the client app using things such as acr. We could add an option to the API to mark the session unsticky, implying that no session cookie will be stored and that the consent can not be reused, and must instead be regained.\nIt would generally be possible to do both - having auth and consent endpoint and also allow consent apps to do everything. But we're adding a ton of complexity and difficulty for implementation here, which leads to potentially insecure behavior and overall bad design. I'd like to keep it as simple as possible (having two endpoints is already complex enough) and don't think all flows will be supported. But we can definitely try to find a solution for edge cases, as long as the complexity is justifiable.. > One thing I'll add to the discussion that having good documentation & samples would be a must, regardless of the approach taken. Am currently finding it quite hard to figure out exactly how to get Hydra and the consent flow going: documentation seems a bit scattered and out of date or requires you to anylise the NodeJS/Go code\nAbsolutely, it would be also great if you (the readers) could help improve the documentation, or at least identify the issues and create issues in the repo with questions / ideas / improvements. It would help tremendously, because I know the technology and software so I can't say what's explained well and what isn't. Also, not an english native speaker :(\n\n@arekkas any approximate timeline for having the stuff discussed in this issue available in the product? As I mentioned we're evaluating whether Hydra fits our needs (seems so). If the whole consent flow will be replaced with the approach outlined in this case, depending on the timeline, it might be better for us to hold off on implementing Hydra with the current consent flow and wait for the new approach to be available\n\nThere's currently a sprint planned in late April which will tacle this. I'll be working on docs before that, basically streamlining everything etc.. No, it's still in development. Yes, that's the branch!. You can stay at the 0.11 branch until you're ready to move on. The new changes are important to get OpenID Connect Certification which is an important goal for 1.0.0. It's unfortunately not (easily) possible to keep both BC and achieve OIDC Certification. We were not aware of the wide scope the OIDC Certification process has, which is why we had to break the promise made in 0.10.0. But it's better to have secure, reliable software, than to keep BC at all cost.\nWe do not support outdated version as part of our open source work (we are very limited in resources), but we do have paid support plans if you wish to have an older version supported by the core maintainers.\nIf you do have an idea on how to improve the new flow and make it backwards compatible, it would be immensely helpful.. Oh and we can, of course, help you adapt to the new changes if you need dedicated help from core devs/maintainers! Just write an email to hi@ory.am or ping me in the chat.. > 2 pieces that are still missing for me is user registration and logout.\n\nI guess registration is no different than login from Hydra's point of view ? UA tells Hydra there's a new user and sends the details just like it would have on login.\n\nRegistration does indeed not concern this at all. The only process we're interested in is authentication. Whether or not you want to have a registration process prior to that is up to you.\n\nBut still, a session might need to be saved on the UA when the user navigates from login page to sign up page ?\n\nDo you mean in the case where the user does not have a valid user account and must register one first? In this case, you'd want to redirect the user back to either the original request URL (/oauth2/auth) or to the login url with the login_challenge (/login?login_challenge=...). You may skip this for first-parties (skip as in always grant the requested scopes) but you shouldn't do so for 3rd party apps (apps written by developers other than you / your company). Since you implement the app, it's up to you and your business logic. Not sure what you want to hear here ;)\nPlease refrain from asking further questions in this issue as it's closed, not on topic, and doesn't meet the issue guidelines and unnecessarily spams the inboxes of everyone that has participated in helping hammer out the design of the new consent flow.\nYou can always ask questions on implementation details in our chat or the forums.\nThank you for understanding.. This is still an issue in the 1.0.0 branch. Done!. We will add this feature (client secret rotation / secret expiration) later, so for now just show a 0!. I understand that this is a bit weird, but let me explain:\n\nWe have a vague idea of what versions people use, and the prevalent ones are outdated ones. Typically, devs integrate Hydra once and never upgrade - either because they don't have time or because they don't know.\nWe don't have a way of contacting operators of deployments because we have no idea who is using the software or not.\nThis technology is at the forefront of your security infrastructure. You really should be aware of any security patches and also release announcements.\nTypically, operators use environment variables (as opposed to hydra connect) to configure the environment because of the nature of how hydra connect works (it persists credentials to a file, this is typically not very secure).\n\nBecause, for some reason, people don't subscribe to the release announcements although we hint at them on the website and in the README, we decided to make it really obvious that this is important, hence adding it to hydra connect which is typically executed on clients (e.g. operators).\nMaking this flag work the opposite way would be in stark contrast what we want to achieve with raising awareness for the release announcements.\nI'm open to better ideas here, but for the time being, I think it will stay as it is.. Cool, so I think that - apparently - we can do a better job at explaining why this is important. What would have helped for you to understand that when seeing it in the CLI? Adding some explanation?. That makes sense, what do you think about:\n\nYou are using the CLI for the first time. It is really important to keep your installation up to date. Because this technology is open source, we have no way of knowing who you are and how to contact you. Subscribe to our release and security announcements, and never miss important patches again:\n\n. Cool, I'll add that to the CLI in the next release - thank you for your feedback!. Nice, thank you!. Whoops, I totally forgot about this issue - thanks for reminding me in the survey :). Closing this because it's resolved (afaik). So the issue is that forked repos also try to push to coveralls, which fails, as the forked repo is not registered at coveralls. There are two ways to fix this:\n\nSee if we can add a check based on Circle CI's environment variables that prevents coveralls push when we're building a fork. (preferred option)\nDon't fail the tests when coveralls push fails. This should be the fallback option that we use if 1 fails.. It doesn't run the test suite in our case - so something like that should work. But I still want code coverage for PRs, just not for the ones from forked repos :). Ah nice! I missed that :). Actually, maybe removing the repotoken is already enough!\n\n\nFor a public github repository, it is not necessary to define your repository key (COVERALLS_TOKEN).\n\nCan you try that (without [ -z \"$CIRCLE_PR_NUMBER\" ] &&)?. Failing test is not your fault, re-running. @zepatrik ok seems like this still fails...but now due to coveralls :). Thank you for your suggestions. We want to keep Hydra as close to the spec as possible and not introduce any custom features for those specs. Customers should not be using their own code anyways and use well-tested open source libraries for interacting with oauth2. In conclusion, this request will not make it into hydra, sorry!. > For us here its not possible to change from json easily as changing anything the customers are currently doing is a big issue and they do json right now.\nI am sorry to hear that, your customers however should rely on open source libraries to implement oauth2 flows. If that is, for some reason, not the case then - unfortunately - hydra can not natively handle those payloads or help with migration.\n\nOne battle at a time. Furthermore its not that uncommon to use json for doing exactly that, see https://auth0.com/docs/api-auth/tutorials/client-credentials\n\nThat's exactly the problem, because people allow this behaviour, other libraries have to implement that as well, although it's not how things should work.\n\nWhile I understand, that its possibly not favorite, for us using hydra means just adding a service in front to translate from json to forms\n\nThis is actually quite common when introducing breaking changes in APIs, check out this blog article on api versioning, which explains that they use modifiers for older clients which transform things so breaking changes are \"hidden\". ps: If you find a IETF/OpenID spec which either allows extension of body payloads for those endpoints, or specifically mentions json I'd be open to add it.. You're welcome, and good luck with fighting the battles ;)\nYou probably don't need to implement that on your own, I think API Gateways such as Kong support request transforms out of the box - maybe there's some json to form plugin available already. It is encouraged to run hydra behind an api gateway anyways, at least something capable of handling TLS termination. It doesn't belong there though, the spec clearly puts it in the JWT claims.. It wasn't a bug in hydra but the mentioned library instead.. The wording is indeed a bit confusing. Hydra does not manage identities (user login, logout, password reset), but with OpenID Connect you can become an identity provider for third parties (think Google SSO) - you still need your own identity management though.. You can skip the consent screen for first party clients.. Tracked as https://github.com/ory/hydra/issues/789. Sorry for my silence on this, but we tracked this issue internally and will address it with the 1.0.0 release!. This is an upstream issue in fosite (patch pending). When upgrading, we'll also have to change how IDTokenClaims is initialized in oauth2/handler.go.\n. This is tracked as #883. Regarding string/array - array MUST be supported according to spec. String MAY be supported, see JWT spec:\n\nIn the general case, the \"aud\" value is an array of case-\n   sensitive strings, each containing a StringOrURI value.  In the\n   special case when the JWT has one audience, the \"aud\" value MAY be a\n   single case-sensitive string containing a StringOrURI value.  The\n   interpretation of audience values is generally application specific.\n   Use of this claim is OPTIONAL.. The issue is that the jwt-go library doesn\u2019t support that very well at the moment. I\u2019ll check into that again to confirm.\nOn 6. Sep 2018, at 17:51, OvermindDL1 notifications@github.com wrote:\nRegarding string/array - array MUST be supported according to spec. String MAY be supported, see JWT spec:\nYep, I've already submitted a PR to them. Just curious if there is a way to just send a single string regardless when there is only a single string in the array, at the very least it lowers processing and network time every so tiny slightly. :-)\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. That is correct @pnicolcev-tulipretail :). I suppose this is docker, right?. Confirmed. 0.11.7 resolved this. > I'd like this feature to be a kind of extension, that one would be able to replace with his custom implementation if needed. I mean, if one already have a far superior threat detection/analysis system (i.e. integrated with network perimeter/firewalls, in-house IDSes and stuff like that), implementing a custom solution would be the only option (based on the existing investments in the infrastructure).\n\nMaybe, not sure - I think one could solve it quite easily with a reverse proxy. Usually these systems should have something like that in place already! But it's definitely optional!\n\nNow when I think about it - it sounds like a niche product. People that don't care about the data leaks won't care about it (and some will even explicitly disable the feature), those who care might invest heavily in security and already have something more generic deployed (or have it in plans). That leaves us with people who care but don't have existing solution (and they also have to use hydra). A market research is needed to tell for sure, but I don't think there'd a lot of those people.\n\nYeah, that's definitely something worth thinking of. We have not a good idea how large the user base would be, and have only few data points that aren't really meaningful imo.\n\nI'd recommend looking at providing enterprise support and hosted solution for hydra (basically like Auth0, but with core product being open source). Lately Gitlab had huge success with model like this. I'm not an very familiar with all this though.\n\nTwo pieces:\n\nSupport: Doesn't really scale because as you grow your margins shrink (as more management is required), unless you increase the price. Sure, there are companies like RedHat and so on, but they are really the exception.\nHosting: Only start ups want this hosted, almost no enterprise wants to give control over their access management away.\n\n\nTo summarize, I like the idea, and the fact that it will allow to monetize hydra and to help you keep up the good work, but also I'm kind of afraid that those additions, if executed in forced and hard-to-cut-out way, might make hydra less appealing to use for me. I have use cases where I'd use the hosted AI threat detection feature, but I also have some where I'd need to cut it out. I also have cases where I don't care about the security at all. \ud83d\ude44\n\nI agree, and the points you raise all make sense. The biggest hurdle to implementing this right now for us is to:\n\nUnderstand demand and pricing\nGet Hydra 1.0.x out\n\nThank you for your input! It's really appreciated!. I there, thank you for making the upgrades! We're not yet ready to fully migrate to open collective, but will do so soon! Once migration is done I'll merge this as well :). That's absolutely sensible. There should definitely be a standard way of solving it without digging through a ton of documentation. Maybe like a standard docker image with default policies and protection.\nI'll have to think a bit more about deployment complexity and so on.. Ok, so I thought about this a bit more.\nFirst I think it makes good sense to move this functionality into a separate service and remove the warden calls internally completely. The reason being that not everyone wants to rely on Hydra's access control. Sometimes it's enough to use a gateway in front and require e.g. an API key for management or whatever. New adopters are always baffled by complexity involved with policies and scopes. Removing that from the core could really help. The user survey has also shown that this stuff is quite complex to grasp.\nThe idea is to have a separate service which is basically ladon as a HTTP API. I think it makes sense to add some functionality to resolve access tokens so it would basically be very similar to the current warden API - probably even equal. There would definitely be some backup mode where hydra's database tables and migrations are used as to make migration as easy as possible.\nThen, we would ship docker images and example set ups where different configurations are shown. One of the configurations would be the current one, so basically what we have now in hydra but with the three services combined in one image.. done!. What you're looking for is the redirect URL - just remove the consent query parameter :). The consent id is used at the consent endpoint. The SDK docs are terrible :( The consent request response contains the redirect url which you can use!\n\nAm 16.03.2018 um 18:15 schrieb Philip Nicolcev notifications@github.com:\nI don't follow. All I have at the consent stage is the consent_id. Introspecting that will give me these details (the golang sdk docs have a broken link to this struct so I'll post the php one)\nhttps://github.com/ory/hydra/blob/master/sdk/php/swagger/docs/Model/OAuth2TokenIntrospection.md\nBut I can't rebuild the original request from that. If I query about redirect_uris belonging to the client I could have several.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Apparently there were issues with the API docs - first the link was broken and second some of the swager models did not show up. I fixed that now, so the response docs look like that now:\n\n\nThere you see the redirectUrl - it's the parameter you're looking for. Just make sure to remove the consent parameters.. It's included!. Yeah it should be a 400 response, it will be included in the next release with the refactored consent flow. The new consent flow is capable of doing that, but it hasn't been properly implemented yet - still tracking.. This is resolved on master. https://github.com/ory/examples. The source resides here: https://github.com/ory/docs/tree/master/guides/1-hydra/7-sdk :). Yes, this should be fine. Thank you!. Appreciated. The system secret must be 32 chars long, it says that in the logs too:\nlevel=warning msg=\"Expected system secret to be at least 32 characters long, got 4 characters.\". Hashing a password does not make it secure. Why should we encourage behaviour that compromises security?. Please read https://en.wikipedia.org/wiki/Password_strength#Guidelines_for_strong_passwords\n\nSomeone attempting to crack the hashed 32-character password won't know to try hashes of shorter passwords.\n\nOf course, the technology is open source.. In any case, I think your question has been answered. To avoid the error, please use a password of 32 characters.\nWe will not change the way passwords are used in hydra because besides painful breaking changes we're applying best practice cryptography and there is little reason to allow shorter passwords.. In that context, it makes way more sense! We could probably die if the secret is to short. This should avoid confusion when starting with the software and is now tracked as #817. Thank you for your suggestion!. Yeah, that's an awesome suggestion @nicerobot ! Got some unix swag! You don't know - by any chance - the equivalent for windows?. Tracked as https://github.com/ory/docs/issues/27. That\u2019s not a big deal. Most issues are regarding tests or undocumented exports. The latter doesn\u2019t really matter because this isn\u2019t a library. Why do you see this as an issue and why is it important to you?\n\nAm 26.03.2018 um 03:19 schrieb Ricardo Aravena notifications@github.com:\ngolint is at 41% . See this for details:\nhttps://goreportcard.com/report/github.com/ory/hydra\navelino/awesome-go#1860\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Hashbangs/Hashtags are special in OAuth2 as they may only be used with the implicit grant so this works as intended. Note that the implicit grant is discouraged.. The reason for this is primarily security concerns. Since all modern browsers allow access to the url bar, hash/hashbang urls are a thing of the past.. I think it's with a capital A as in introspectOAuth2Token. Hi, this has been an issue elsewhere too, the groups: prefix is not fixed! You have to literally name your group groups:my-group. If the ID of your group is my-group, than it is not prefixed with groups:.. Reopening, because you're the third or fourth person having that misconception. Should be fixed in the docs.. Ok, so this has changed significantly over the past few weeks as access control is now optional and configured via oathkeeper and keto. I'll update the docs before the release.. Solved on master. No, all good, I'm just extremely busy with #836 right now, I'll merge it soon. Thank you for your contribution!. @dolbik would you mind sharing how you set up prometheus with hydra? What would be excellent, if you could create an docker example here and create a PR for it :). Thank you for reporting the issue, it should definitely be a 400 Bad Request response.\n\nWhich version are you on?. This is resolved on master. How long is your subject id?. Well, that's too long unfortunately, max is 255 characters. Keep in mind that this column will be indexed in the future, so\n\nlonger keys are not possible\nthe longer the key the lower the index performance and the larger the index. Yeah, that will be fixed with 1.0.0 as we need that field indexed in order to remove all access tokens of a user, for example.. Don't store a JWT as the subject field. The subject field should be a user id in clear text (or hashed to anonymize). If you need extra data use the extra fields in the consent request.\n\nClosing because question answered.. This is resolved. Good point, this sort of confirms my negative bias towards the spec. We'll definitely figure something out. I have no iOS experience however.\nJust to confirm, what you're saying is that a REST call with the token which revokes the session completely is the way to go here?. We have now all the endpoints to deal with basic logout flows. I still think this spec is outdated and very complicated. The OIDC foundation doesn't certify this spec either. Closing.. I'm reopening this because the SSO requirements come up over and over again, and hydra lacks a peer reviewed flow for this. It makes sense to implement at least some of these flows.. Yeah it definitely should return 409. The problem right now is that each database driver has different error codes and also error types for a primary or unique key constraint violation. Matching that is simply not done at the moment but by solving that, we would essentially solve this issue as well. If you want, feel free to give it a shot.\nCheck, for example, the PG error type as well as the specific error code which I think would be thrown when this happens. I guess MySQL will work similarly.. This should be resolved on master. This has been merged directly into 1.0.x branch. Just check for the client id in your consent app and act accordingly ;)\n\nOn 2. May 2018, at 04:10, MOZGIII notifications@github.com wrote:\nWe need to have very different consent flows based on what client initiated the authentication. It is not possible to configure it currently, so we have to run multiple hydra servers.\nCan we add the ability to customize consent URL at client level?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Whoops, missed in my emails that you already found a solution and also closed it!. Which version are you on?. Ok, it's definitely an older version - oryd/hydra:latest doesn't exist an dif the build doesn't show the right version it's definitely outdated. Use v0.11.12. Yeah, my bad, it has actually landed in master (which is not the 0.11 release branch but prepares the 1.0.0 release). There it will work (and has tests too).. Resolved on master. Solved on master. Please resolve the conflict and add a test :). This is solved in 1.0.0 (and also here). If you want to address this in < 1.0.0 please let me know and I'll reopen. Since it's code generated we could provide some type definitions, but they will probably be out of date a lot. Feel free to contribute type definitions though!. Closing because this won't be addressed by us. But feel free to provide TS definitions!. Thank you for the update! We're going through a weird phase in the docs because there is some major refactor going on. The correct tutorial for the last stable version is indeed this one: https://www.ory.sh/docs/guides/v0.11.12/hydra/0-tutorial/0-readme\n\nI'll keep this PR open until 1.0 lands so we can point to the most recent docs properly!. I think this is fixed now and the redirections work as they should, so I'm closing this. In any case, thank you for raising this PR!. Solved on master. Solved on master. The logic should be updated as follows:\n\n[ ] A timeout for the login provider to complete the flow (e.g. 15 minutes after issuing the challenge)\n[ ] A timeout for the login provider to complete the flow (e.g. 1 minute after issuing the verifier)\n[ ] A timeout for the consent provider to complete the flow (e.g. 15 minutes after issuing the challenge)\n\n[ ] A timeout for the consent provider to complete the flow (e.g. 1 minute after issuing the verifier). The question is if this even makes sense. A global timeout for the complete flow is enough given that the time window is reasonably short (15 minutes). Adding additional timeouts will not significantly increase security (imo) whilst increasing complexity. Therefore closing.. This is particularly interesting when it comes to handling an id_token_hint where prompt != none (so we show the login screen) and the login app is actually authenticating another user. So for example:\n\n\nAuthN cookie has user sess-user authenticated\n\nid_token_hint is set to user idt-user\nRequest is forwarded to login endpoint\nLogin endpoint accepts login with user not-idt-user\n\nHere, the request validation will properly throw an error (\"If the End-User identified by the ID Token is logged in or is logged in by the request, then the Authorization Server returns a positive response; otherwise, it SHOULD return an error, such as login_required.\") because idt-user does not match not-idt-user.\nNow the question is what should happen to the AuthN cookie. There are three possibilities:\n\nThe cookie stays and sess-user is logged in (current behaviour)\nThe cookie is updated to not-idt-user as - after all - authentication was successful\n\nThe cookie is purged and neither sess-user nor not-idt-user has persiting authentication at hydra. This is an upstream fosite issue. See https://github.com/openid-certification/oidctest/issues/97. Solved on master. Tests fail. Solved on master. Not sure what this was referring to, tried different configs and was unable to reproduce this. Was issued in the chat so might be some misconfig on their side.. Actually, the audience should probably be defined by the client making the request, not the consent endpoint.. Not sure yet, needs investigation . So the proper course of action, to the best of my knowledge, is as follows:\n\n\nWe're enabling clients to define audiences which they are allowed to request.\n\nWe're defining one or more audience matching strategies (e.g. exact, wildcard, ...)\nWe're checking every implicit, code, hybrid, cc flow for a request parameter called audience\nIf audience is set (either in query or body), we will split that parameter using - well this one is tricky - some character. This could be whitespace or something else. The problem is we're dealing with URLs so all allowed characters could be the URL and it's not really easy to just pick one delimiter. I think to keep with previous practices of scope delimiters, we should go with whitespaces (or url encoded +)\nWe check if each of the audiences is also an intended/allowed audience of the client using the matching strategy.\nWe expose GetRequestedAudience() []string and GrantAudience(audience string) in the requester interface so that the consent endpoint can set/override this value.. Here's what I intend to add to the docs regarding this:\n\nAudience\nThere are two types of audience concept in the context of OAuth 2.0 and OpenID Connect:\n\nOAuth 2.0: Access and Refresh Tokens are \"internal-facing\". The aud claim of an OAuth 2.0 Access and Refresh token\ndefines at which endpoints the token can be used.\nOpenID Connect: The ID Token is \"external-facing\". The aud claim of an OpenID Connect ID Token defines which\nclients should accept it.\n\nWhile modifying the audience of an ID Token is not desirable, specifying the audience of an OAuth 2.0 Access Token is.\nORY Hydra implements this feature, which is not defined as an IETF Standard but is\nconsidered good practice in certain environments.\nTo use the audience feature, you must specify the intended audiences in the OAuth 2.0 Client's metadata on a per-client basis:\n{\n    \"client_id\": \"...\",\n    \"audience\": [\"https://api.my-cloud.com/user\", \"https://some-tenant.my-cloud.com/\"]\n}\nThe audience is a list of case-sensitive URLs. URLs must not contain whitespaces.\nOAuth 2.0 Authorization Code, Implicit, Hybrid Flows\nWhen performing an OAuth 2.0 authorize code, implicit, or hybrid flow, you can request audiences at the /oauth2/auth\nendpoint https://my-hydra.com/oauth2/auth?client_id=...&scope=...&audience=https%3A%2F%2Fapi.my-cloud.com%2Fuser+https%3A%2F%2Fsome-tenant.my-cloud.com%2F\nwhich requests audiences https://api.my-cloud.com/user and https://some-tenant.my-cloud.com/.\nThe audience query parameter may contain multiple strings separated by a url-encoded space (+ or %20). The\naudience values themselves must also be url encoded. The values will be validated against the whitelisted\naudiences defined in the OAuth 2.0 Client:\n\nAn OAuth 2.0 Client with the allowed audience https://api.my-cloud/user is allowed to request audience values https://api.my-cloud/user\nhttps://api.my-cloud/user/1234 but not https://api.my-cloud/not-user nor https://something-else/.\n\nThe requested audience from the query parameter is then part of the login and consent request payload as field requested_access_token_audience.\nYou can then alter the audience using grant_audience.access_token when accepting the consent request:\n```\nhydra.acceptConsentRequest(challenge, {\n  // ORY Hydra checks if requested audiences are allowed by the client, so we can simply echo this.\n  grant_audience: {\n    access_token: response.requested_access_token_audience,\n    // or, for example:\n    // access_token: [\"https://api.my-cloud/not-user\"]\n  },\n// ... remember: false\n  // ...\n})\n```\nWhen introspecting the OAuth 2.0 Access Token, the response payload will include the audience:\n{\n  \"active\": true,\n  // ...\n  \"audience\": [\"https://api.my-cloud/user\", \"https://api.my-cloud/user/1234\"]\n}\nOAuth 2.0 Client Credentials Grant\nWhen performing the client credentials grant, the audience parameter from the POST body of the /oauth2/token is\ndecoded and validated according to the same rules of the previous section, except for the login and consent part which\ndoes not exist for this flow.\n. > How do you plan to alter pairwise subject functionality to cooperate with that?\nNot related IMHO\n\nDo you mind interchangeability of id_token between clients?\n\nNot sure what you mean by that?\n\nHow about client deciding about which of his auds should be visible to other? I think aud content should be decided per client by user on consent page.\n\nDepends on your understanding of audience. It can be user granted or defined per client. The audience is not officially specified nor is how you authorize audience.. > Do you think that id token could be shared between clients from aud list? Otherwise bother putting list of aud into token, ok client can check if that is intended for him, but why put there other aud values? I could imagine situation where third parties share id token, that is signed and can be verified, and pass information about user among themselves that way.\nPersonally, I think it could be shared. However, this will not be addressed as part of this PR. The access token audience is the real deal, requests/use cases for oidc audience have not come up yet.. Thank you @Aggouri for the correction, updated in the docs!. Thank you for reporting this, it's a bug indeed (caused by strings.split always returning at least one element, an empty string). Absolutely valid request, PRs are welcome! Before supplying a PR, please lay out a plan (e.g. pseudocode, short list) how you'd like to achieve that. Doesn't have to be thorough, just a rough idea how it would work. As storage is a DBAL (which could be SQL or in-memory) there is an abstraction layer that has to be resolved properly here.. Yeah, that looks pretty solid so far. However, the pkg/fosite_storer.go interface should be left completely untouched, similar to the fosite store implementation.\nInstead, you should define an healthy interface in the health package and implement it's method signature in files like this (that should return true always) as well as the plugin backend (this one should explicitly define a function that is being loaded from the plugin for health checking).\nFor SQL Connections, you could probably write a wrapper for sqlcon.SQLConnection that implements the health check.. This makes tons of sense! How about:\n\n/health/alive\n/health/ready. @husio sorry if you already put work into this, I'll adapt your changes and quickly supply a PR as I want this to be released in the preview of 1.0 (which will be released today or latest tomorrow). Thank you for raising the issue and your ideas on how to solve this!. Ok, so some commits were missing here. This should now be resolved on this branch: https://github.com/ory/hydra/tree/v0.11.x\n\nCan you please double-check to make sure this is the case? If so, I'll release a 0.11.13 version.. @joshlreese sorry for pinging, but could you check if the branch is ok?. I pushed a new release based on that branch, let me know if something doesn't look right.. Are you using the in-memory store or the SQL one?. Ah yeah, it appears that this info is missing from the consent endpoint but available in the login endpoint due to a missing copy. Thank you for identifying and raising the issue!. Resolved with  #901 . Congrats on raising the 900th issue :D. Due to the current implementation of the consent strategy this is actually not that easy to add. The complexity involved is that this can only work in certain circumstances where prompt=consent and where a previous consent exists that has been remembered and which has not expired yet. The reason for the latter is that we're actually not returning uninteresting (expired/not remembered) consent requests from the store.\nChanging this would require some overhaul of the affected codebase and more or less a redesign of the strategy and storage implementation.\nAs the complexity for this change is rather high but the gain is rather low (as it would only work under certain circumstances), and because one could argue that prompt=consent should leave the user with the conscious decision to re-grant the requested permissions, this feature request will not be implemented for now. It might be revisited at a later point, but I'll close this issue in the meanwhile.\nThank you for your contribution!. > but it might even have legal issues. With the new GDPR, a user should have the right to know what permissions he gave to a certain app.\nEach user authorization (and thus access/refresh pair) may have different permissions. One flow might only need scope email, another might need email and photos, the next might only need address - and so on. It's not straight forward to tell (on the authorization server side) which scopes have been granted apart maybe from trying to go through the whole history and accumulating that data.\nI think the legal argument under GDPR might hold, but this wouldn't be during the consent flow for me. Instead, this could be an endpoint where you can query for that data with the intent of making a detailed report which scopes have been granted before and which have not.\n\nAlso, have in mind that the certain circumstances you mention usually are the most probable situation, api permissions in most cases are very long lived and consent is given on first use of the app. So after the very first visit to the app the certain circumstances almost always are given.\n\nThat's true.\nI'll reopen this so it won't get lost.. > Something like this will also be necessary if I want to display a list of all apps that the user gave permissions to, in this case as a UI the API service offers to the user.\nI agree!. > Does what I'm saying make sense?\nIt does and it's actually a bit difficult to tell given that both apps (mobile and desktop) use the same OAuth 2.0 Client ID. Maybe we could simply return all the accepted consent requests in the API and you decide what to do with it?. > As @clausdenk suggested, remote ip, user agent, etc. would be enough in order to trace the users and their requests.\nAs the user is accessing the consent and login endpoint using his/her browser, this information should be available to you without hydra relaying it, right?. I see. Isn't that already possible by using the challenge? It's unique for each request and you can associate it in the consent app with the data you need. Or am I missing something?. I see, so something like login_metadata or consent_metadata right?. The OP issue was resolved by #953\nIf you're still up for login_metadata etc feel free to open a new issue so we can track it separately!. There was a discussion in the chat, summary is:\n\nIt's probably a good idea to separate those endpoints\nThere could be a distinction between \"user-facing\" and \"admin-facing\"\n\"user-facing\": Endpoints that perform the oauth2 flow, such as /oauth2/auth, /oauth2/token, /oauth2/revoke, /userinfo and the ./well-known ones.\n\nThe /oauth2/introspection endpoint is defined for internal use (resource server) and requires authorization. How that authorization looks like is out of scope:\n\nTo prevent token scanning attacks, the endpoint MUST also require\n   some form of authorization to access this endpoint, such as client\n   authentication as described in OAuth 2.0 [RFC6749] or a separate\n   OAuth 2.0 access token such as the bearer token described in OAuth\n   2.0 Bearer Token Usage [RFC6750].  The methods of managing and\n   validating these authentication credentials are out of scope of this\n   specification.\n\nSo one point raised is that exposing this endpoint at a clearly defined \"admin\" port would already imply some type of authorization (\"priviledged port\").\nIn general, the proposed change was viewed positively.. @clausdenk yes that would be the current approach. We haven't added an ngnix example just yet but planned to do so. Depending on the consensus in this issue we'll move ahead (or not) with this.\n@MOZGIII thank you for your feedback. I think the OAuth 2.0 Token Introspection endpoint is actually the only controversial one. All other endpoints (/oauth2/flush, consent, client, jwk) are no-brainers when it comes to separating between consumer/user-facing (\"unpriviledged\") and internal-facing (\"priviledged\"). Currently, that endpoint is protected by requiring an OAuth 2.0 Client (id+password) or a valid access token. Obviously, that's not very secure because I, as a user, can issue myself an access token and query that endpoint.\nI also agree with the differentiation between internal session state and public session state. Currently, the introspection endpoint is seen as an elevated endpoint that exposes (potentially) internal session state. It's really up to the developer what data get's stored there - but the possibility of accidentally exposing internal session state is there. The downside of adding another endpoint is one of complexity. I think we should reduce complexity (in terms of learning curve) as much as possible to make adoption as easy (and hopefully secure) as possible. By - for example - exposing the introspection endpoint on the secondary (admin) port, you - the developer - would have to make the concious choice of exposing that particular port+path to the public net (and hopefully not store sensitive data there).\nI think re-adding authorization is counterproductive. We got rid of it to reduce complexity when developing and authorization can easily be added with ORY Oathkeeper (as shown in ory/examples). Having said that, I have not yet looked at the kubernetes docs but will definitely do that in the coming days!\nSo far, thank you both for participating and your input. It is very valuable. I hope we can find the best path forward!. It depends, the wording is intentionally vague - authorization can be obtained via different measures - be it access to the internal network, being deployed behind a reverse proxy, requiring valid access credentials. We're currently implementing the examples raised in the spec (securing the endpoint via access token/client credentials) but this doesn't - imo - provide any typo of security other than you - the attacker - requiring an access token to perform token scanning attacks.\nThat being said, the use case of To prevent token scanning attacks is a very narrow one. IMO it's impossible to guess, in the lifetime of planet earth, an access token issued by ORY Hydra. So there is really no need to defend against scanning attacks. Another (imo) inconsistency is that you can perform token scanning attacks by just making requests to your API with random access tokens. Like - what's the difference?\nFurther down in the spec, there's a bit more context on this:\n\nIf left unprotected and un-throttled, the introspection endpoint\n   could present a means for an attacker to poll a series of possible\n   token values, fishing for a valid token.  To prevent this, the\n   authorization server MUST require authentication of protected\n   resources that need to access the introspection endpoint and SHOULD\n   require protected resources to be specifically authorized to call the\n   introspection endpoint.  The specifics of such authentication\n   credentials are out of scope of this specification, but commonly\n   these credentials could take the form of any valid client\n   authentication mechanism used with the token endpoint, an OAuth 2.0\n   access token, or other HTTP authorization or authentication\n   mechanism.  A single piece of software acting as both a client and a\nprotected resource MAY reuse the same credentials between the token\n   endpoint and the introspection endpoint, though doing so potentially\n   conflates the activities of the client and protected resource\n   portions of the software and the authorization server MAY require\n   separate credentials for each mode.\n\n. So according to that, the client making the request should be authorized to do so - this was previously handled with our access control policies. In turn, this implies that the current measures deployed (active token) are insufficient.\nOn possibility to solve this easily would be to require a specific scope (such as introspection) to be granted when making the request..but man..this will be hard to teach people.. > @arekkas good point about the spec scanning attacks, I don't think we understand the attack vector here. We should ask the guys who wrote the spec for advice, can you contact them?\nI think it's clear. They require authorization in order to prevent token scanning. I think the example of using access tokens is sorry trash, because - well - you have to have a valid access token to perform the request. And that way you can actually scan for tokens. So really no idea what type of safeguard this is.\nThe error message is 401 or 403 if the token from the authorization header is invalid and 200 if it's valid. The response payload allowed: ... depends on the token from the body.\nMaybe avoiding this BS and going with a more sane approach (such as declaring this an administrative API) will save us from going insane here :D. By the way, I couldn't find contact information on the authors, but I'll try to talk to them. Usually they hide this info so they don't get constantly spammed by consultants and head hunters, so it might be difficult to come around.. Ok, I still think this is a good idea. The design would look as follows:\n\nhydra serve admin: Exposes all administrative endpoints. This includes:\nAll /clients endpoints. I am aware that /clients implements OpenID Connect Dynamic Client Regsitry which (sort-of) allows public access but since we do not implement any type of access control, anyone could modify existing clients which is why this should not be a public endpoint.\nAll /jwks endpoints\nAll /health, /metrics, /version endpoints\nAll /oauth2/auth/requests endpoints\n/oauth2/introspect as OAuth 2.0 Token Introspection is reserved for resource servers - exposing this endpoint might compromise internal session state which is why we play it safe and have it at the admin port.\n/oauth2/flush\nhydra serve public exposes:\n/oauth2/fallbacks/consent\n/oauth2/fallbacks/error\n/oauth2/auth\n/oauth2/token\nAll ./well-known endpoints\n/userinfo\n/oauth2/revoke\n\nAll environment variables are shared across the two commands (serve admin/serve proxy) and you can choose the port with PORT. This will obviously also change how we use --endpoint-url and HYDRA_URL in the CLI, most likely by keeping these flags and, where neccessary, replace them with --admin-url and --public-url (although I don't think that that's actually neccessary).. Note to self: Need to make sure that there are no race conditions when starting a new hydra installation on an empty database regarding JWK creation. It's a lot of work, can't say honestly.. An OAuth2 scope is not a protective mechanism. OAuth2 Clients can (if OpenID Connect Dynamic Client Registration is open) define their own scopes.\nThe main reason for putting OAuth2 Introspection at another endpoint is:\n\nThis specification defines a method for a protected resource to query\n   an OAuth 2.0 authorization server to determine the active state of an\n   OAuth 2.0 token and to determine meta-information about this token.\n   OAuth 2.0 deployments can use this method to convey information about\n   the authorization context of the token from the authorization server\n   to the protected resource.\n   - Source\n\nWhen we are talking about protected resources, it usually implies \"resource servers\" which are first-party systems running within the infrastructure in which the Authorization Server is available as well.\nWhile it could be possible to expose this functionality to other parties over the open internet, it's not the primary use case, which is why - imo - this makes sense to keep at the \"internal\" or \"admin\" service.\nWhat is your use case for exposing this functionality?. Here's also some more information on that and I would also like to note that - to my knowledge - no popular API system that uses OAuth2 (Facebook, Google, Dropbox, GitHub) exposes the OAuth2 Introspection endpoint.. Also keep in mind that exposing this functionality on the \"internal\" port will not prevent you from actually exposing this endpoint to the public internet. You, as the operator, however have to make the conscious decision to do so, which I think is the right way to approach it!. That's a good question which I have thought about for a while. I believe we would keep the current authorization system in place as it's (sort of) what the spec suggests (note - doesn't require that) and it would make exposing that endpoint easier.. See my previous comment:\n\nAn OAuth2 scope is not a protective mechanism. OAuth2 Clients can (if OpenID Connect Dynamic Client Registration is open) define their own scopes.\n\nThe OAuth 2.0 Scope only \"scopes\" what a someone allowed a token to do, not what a client is allowed to do. That's a huge difference. If you use basic authorization at that endpoint, there is no OAuth2 scope. OAuth2 Scope is not an access control mechanism like RBAC, ACL, and so on.. That's a fresh idea! I still have some reservations:\nBy exposing introspection on the admin port, you, the developer/operator makes the conscious decision to expose that endpoint to the public internet by setting up some routing. I think this is important because token introspection exposes the internal state/data of an access token. Assuming you, the developer, chooses to include personal or sensitive data personal or business in the access token (email, profile picture url, system privileges, ...), the payload would be accessible to the public internet by simply having an OAuth2 Client (which is registered at e.g. my-company.com/developers) capable of introspecting the token. While this might be obvious to some, it might also be an \"oh shit\" moment for others.\nWhile I really like the thinking here, I believe that we should limit introspection to the admin/privileged port and remove the HTTP Authorization requirement. Exposing that functionality is then a decision with trade-offs (no sensitive session data) that must be made. This also allows you to set up access control the way you like it (e.g. access tokens with Oathkeeper or whatever).\nWhat do you think?. > I think intuitively it makes sense to only expose introspection endpoint in the admin port. However, OIDC certification requires this endpoint, and it requires it to be protected.\nThat is not true, OpenID Connect spec does not care at all about this endpoint nor is it required for certification. The endpoint isn't even a valid option in OpenID Discovery. Please clarify your source.. > @arekkas I'm not sure about that, this is my understanding from the discussion here. I'll try to look it up.\nIf there is no source, then this is false. I was personally involved in the certification process, signed the documents, reviewed the test samples, and even wrote most of the stuff required for it. I can tell you with 100% confidence that introspection is in no way affiliated with the certification process. This should already be clear as introspection is an IETF specification and not one from the OpenID Foundation. They lack the authority to certify that.. tl;dr OAuth2 Introspection will be stripped of access control and moved to privileged port. It might be (re-)added to the public port with access control at a later stage.\nLong version:\nWe talked this through internally and came to the conclusion that the endpoint will be exposed at the privileged port without access control for beta.8 and probably also rc.1. There is still the possibility to add this endpoint with access control to the public port, but we need more time to make a good decision (and design) here and we also want to see if it is actually necessary for us to do so (maybe developers don't expose the endpoint to the public at all and the feature would be unused).\nHere's the current draft for the changelog:\n```\nSplit of Public and Private Ports\nPreviously, all endpoints were exposed at one port. Since access control was removed with version 1.0.0, privileged\nendpoints (JWKs management, OAuth 2.0 Client Management, Login & Consent Management) were exposed and had to be secured\nwith sophisticated set ups using, for example, an API gateway to control which endpoints can be accessed by whom.\nThis version introduces a new port (default :5555, configurable using environment variables PRIVILEGED_PORT and\nPRIVILEGED_HOST) which is serves all privileged APIs:\n\nAll /clients endpoints.\nAll /jwks endpoints.\nAll /health, /metrics, /version endpoints.\nAll /oauth2/auth/requests endpoints.\nEndpoint /oauth2/introspect.\nEndpoint /oauth2/flush.\n\nThe second port exposes API endpoints generally available to the public (default :4444, configurable using environment\nvariables PUBLIC_PORT and PUBLIC_HOST):\n\n./well-known/jwks.json\n./well-known/openid-configuration\n/oauth2/auth\n/oauth2/token\n/oauth2/revoke\n/oauth2/fallbacks/consent\n/oauth2/fallbacks/error\n/userinfo\n\nThe simplest way to starting both ports is to run hydra serve. This will start a process which listens on both ports\nand exposes their respective features. All settings (cors, database, tls, ...) will be shared by both listeners.\nTo configure each listener differently - for example setting CORS for public but not privileged APIs - you can run\nhydra serve public and hydra serve privileged with different settings. Be aware that this will not work with DATABASE=memory\nand that both services must use the same secrets.\nOAuth 2.0 Token Introspection\nPreviously, OAuth 2.0 Token Introspection was protected with HTTP Basic Authorization (a valid OAuth 2.0 Client with\nClient ID and Client Secret was needed) or HTTP Bearer Authorization (a valid OAuth 2.0 Access Token was needed).\nAs OAuth 2.0 Token Introspection is generally an internal-facing endpoint used by resource servers to validate\nOAuth 2.0 Access Tokens, this endpoint has moved to the privileged port. The specification does not implore which\nauthorization scheme must be used - it only shows that HTTP Basic/Bearer Authorization may be used. By exposing this\nendpoint to the privileged port a strong authorization scheme is implemented and no further authorization is needed.\nThus, access control was stripped from this endpoint, making integration with other API gateways easier.\nYou may still choose to export this endpoint to the public internet and implement any access control mechanism you find\nappropriate.\n```\nIf there are any doubts or concerns left, please raise them now!. Oh, and please let me know if you think that it should be called \"privileged port\", \"internal port\", \"admin port\", or any other name suggestions. . I really like control, and yes definitely server - I was referring to the environment variable PUBLIC_PORT but that was obviously out of context :D\nSo we would have environment variables PUBLIC_PORT, PUBLIC_HOST, CONTROL_HOST, CONTROL_PORT and commands hydra serve (runs both servers), hydra serve public (runs only public server), hydra serve control (runs only control server).\nOpinions?. Yeah I think it makes sense to expose /health/* (but not /version, /metrics/*) at the public endpoint too. Load Balancers will probably want to check the health of each service individually.. Hm, what is the difference between hydra serve public and hydra serve --only-public? Aren't both conceptually the same (you reduce the scope of the command) - whilst one is using a flag and the other a subcommand?. Ah, that makes total sense, good point. Maybe hydra serve public control isn't such a bad idea? :D. > @arekkas But in this case older Dockerfiles (that use hydra serve) will stop to work.\nThat's fine for two reasons:\n\nOur old Dockerfiles available on Docker Hub will still work as the software did not change, and the new Docker Images will work as well as we'll update the default entrypoint.\nWe're still in beta which has been communicated as \"good enough to work with and potentially expose to the public\" but also with the clear warning of \"we might break bc from version to version until we're stable\".\n\nA breaking change from versions <= 1.0.0 happened anyways as the server command was hydra host back then.\nIn general I'd like to make this clean and understandable with the stable release than keep BC between betas :) I hope you agree!  . Yes, one binary. The all option is what we have in place for oathkeeper at the moment (oathkeeper serve proxy, oathkeeper serve api, oathkeeper serve all) so it wouldn't be a completely new concept to the ecosystem. I agree that chaining the serve processes is a bit lengthy. My personal opinion is towards serve all|public|control where serve all could be an alias for serve public control.. Arguments are easier to handle when it comes to help messages - hydra help serve public can (can, not must) have a different message than hydra help serve control while hydra serve --all -h will have the same message as hydra serve --control -h. I think that allows for a bit more flexibility here :). Oh, and it's easier to spot in the overview, see hydra help clients for example:\n```\nhydra help clients\nUse this command to create, modify or delete OAuth2 clients.\nUsage:\n  hydra clients [command]\nAvailable Commands:\n  create      Create a new OAuth2 client\n  delete      Delete an OAuth2 client\n  get         Get a client by id\n  import      Import clients from JSON files\n```\n. @boydgreenfield thank you for the detailed feedback. Protecting the control/privileged/admin service is definitely something that should be easy to set up. Heroku is a bit of an outlier as they do not expose any functionality of the load balancer whatsoever. Other platforms (GCP, AWS) support - for example - TLS Client Certificates in their LBs or API Gateways. Nevertheless, this should be more easy to set up. Maybe we could provide a docker image that runs Oathkeeper alongside Hydra privileged and that requires - per default - some type of basic authorization. This is what we're trying to get working with the examples repository, but we're not there yet.\nI think adding it to the core would decrease flexibility and also raise questions of permission systems (RBAC, ACL) which we want to avoid.\nRegarding -dangerous-force-http, the best was to approach it is to remove the flag and set environment variable HTTPS_ALLOW_TERMINATION_FROM. This allows you to set an IP range (CIDR notation) which allows requests coming from that range to be HTTP instead of HTTPS. Please note that hydra expects HTTP Header X-Forwarded-Proto to be set to https for all incoming requestst. Most routers/gateways support that, some don't. The header transports (similar to X-Forwarded-For) the original scheme that was used when calling the gateway/edge.. Yes, it's even auto-build and available in the release tab for windows.. You are missing the --endpoint flag:\n```\nhydra help clients create\n[...]\n    --endpoint string        Set the URL where ORY Hydra is hosted, defaults to environment variable HYDRA_URL\n[...]\n```\nShould probably throw an error though if it's not defined.. Thanks, I'll look into it. Fixed by https://github.com/ory/hydra/commit/95c96a035bd64e682d9b770058b093f02b19b8d6. Please read https://github.com/ory/hydra#building-from-source. Documented, thanks!. Can you please show the bash history. Oh boy, I hope the commit history didn't get messed up \ud83d\ude28 I'll check it out, connect should definitely be included.. Seems like 0.11.13 was accidentally branched off master instead of v0.11.x. I just scheduled a 0.11.14 release off the right branch, should work once published.. \ud83d\udc4d . Hey, thanks for the report :) A fix will be available soon (already working on one) and it will also add a test suite which will run the migrations and add data after each migration step, so this doesn't happen any more (hopefully)!. This is how we roll! :D --> #919. Thanks!. I think the issue is that the new generator expects the keys from the JSON Web Key storage to have matching public/private kids. This wasn't the case before and the strategy had a bug which caused the keys to mismatch. Can you sign into the db and run:\nDELETE FROM hydra_jwk WHERE sid='hydra.https-tls' OR sid='hydra.openid.id-token'\n. See: https://github.com/ory/hydra/blob/master/UPGRADE.md#oauth-20-clients-must-specify-correct-token_endpoint_auth_method\nIf you're sending the client credentials in the POST body, this mus be set to client_secret_post. This is part of the OpenID Connect Dynamic Client Registration spec which was implemented with beta.5. The original issue will be fixed by hydra re-generating the keys if the format is broken. There are various aspects to calling something \"ready for production\". We have extensive qa/test suites that make sure that each release is safe to run in the wild. Any release, be it beta or rc is ok to run facing the public net. The beta flag refers to the software not having (a) the full feature set yet and (b) warning you that upgrading from each beta version to the next might introduce minor or major breaking changes.\nWe generally recommend going with 1.0.0 release as you will need to do a lot of work to get from 0.11 to 1.0. And there, always go with the latest release. The mismatch of versions on the branches might be caused by some CI pipeline failing.. Closing, because I believe the question is answered. If the CSRF value doesn't match, you might have started the oauth2 flow in two browsers or tabs, or something is wrong with the cookies.\nIf you're behind an API gateway or router, make sure the cookies make it through. Try to restart the flow and see if it works.. Is hydra running behind a proxy (e.g. ngnix, kong, load balancer, ...)?. Ok, that's weird, glad it works now.. > I have started the oauth2 flow in two tabs simultaneously\nHydra doesn't support two simoultaneous oauth2 auth code flows from the same browser.. Are you calling the SQLManager directly? The HTTP handler (aka REST API) calls a validator which in turn hydrates the client id based on both id and client_id.\nIf you're calling the SQLManager directly please be aware that those are internals and they are not intended to be exposed/consumed by outside code. The respective storage structs are \"dumb\" - ie don't care about validation as the only source of data should be the REST handler.\nIf this is in fact about the REST API then I'll investigate, otherwise this will be closed as wontfix.. Hm, first of all I really like the Coalesce solution and will replace this with the current way this is being solved. What's weird though is that I wrote a test case to test your code and was unable to get it to failing. The test case is:\n```\n    for k, tc := range []struct {\n        client   hydra.OAuth2Client\n        expectID string\n    }{\n        {\n            client: hydra.OAuth2Client{},\n        },\n        {\n            client:   hydra.OAuth2Client{Id: \"set-properly-1\"},\n            expectID: \"set-properly-1\",\n        },\n        {\n            client:   hydra.OAuth2Client{ClientId: \"set-properly-2\"},\n            expectID: \"set-properly-2\",\n        },\n    } {\n        t.Run(fmt.Sprintf(\"case=%d\", k), func(t *testing.T) {\n            result, response, err := c.CreateOAuth2Client(tc.client)\n            require.NoError(t, err)\n            require.EqualValues(t, http.StatusCreated, response.StatusCode, \"%s\", response.Payload)\n\n            assert.NotEmpty(t, result.Id)\n            assert.NotEmpty(t, result.ClientId)\n            assert.EqualValues(t, result.Id, result.ClientId)\n\n            id := result.Id\n            if tc.expectID != \"\" {\n                assert.EqualValues(t, tc.expectID, result.Id)\n                assert.EqualValues(t, tc.expectID, result.ClientId)\n                id = tc.expectID\n            }\n\n            result, response, err = c.GetOAuth2Client(id)\n            require.NoError(t, err)\n            require.EqualValues(t, http.StatusOK, response.StatusCode, \"%s\", response.Payload)\n\n            assert.EqualValues(t, id, result.Id)\n            assert.EqualValues(t, id, result.ClientId)\n        })\n    }\n\n```\nDid I miss something here? I'll update the code nonetheless because I really like the Coalesce solution.. See #927. To which version of 1.0 are you upgrading? Did you set the SYSTEM_SECRET?. Could you try upgrading to beta.4 and see if that works?. So the thing is, \"unexpected end of JSON input\" points to a malformed JSON string in the table. I'm not sure how that can happen here. The store works as follows:\n\nMarshall the key as JSON string\nEncrypt the resulting string with SYSTEM_SECRET and AES-GCM\nStore the resulting byte array in the database\n\nTo retrieve it, it works as follows:\n\nRetrieve the encrypted byte array from the database\nDecrypt the byte array using SYSTEM_SECRET and AES-GCM (aka with integrity check)\nIf integrity check passes decode/unmarshall the byte array with json.Unmarshal\nReturn the resulting object\n\nSince you're seeing unexpected end of json input, something weird is going on. First, the AES-GCM check passes. This means, that the encrypted string has been properly decrypted, otherwise the integrity check would fail. This also means that the decrypted string is somewhat JSON parsable as we're seeing an error that points to the end of the string, not the beginning - implying that the string starts, at least, with something like {.\nNot sure what's going on here. One way to solve this without negative side effects is to remove the key from the database manually:\nDELETE FROM hydra_jwk WHERE sid='hydra.openid.id-token'. No effect whatsoever, unless you hardcoded that JSON Web Key somewhere (which you shouldn't and probably didn't). All the command does is to remove the old key. When restarting hydra, the key will be automatically re-generated. There's also a bug in #921 which causes the beta.6 upgrade to fail if a pre-existing key is stored in the database but that is - as far as I can tell - unrelated to what you're experiencing.. Thanks!. I think we could add the http middleware, would that be enough?. Yup, PR welcome, most likely to be added somewhere around here: https://github.com/ory/hydra/blob/master/cmd/server/handler.go#L83. Wouldn't it be better to adopt opentracing instead of zipkin? Namely go-opentracing? It also seems like opentracing is part of the CNCF as opposed to zipkin. I\u2019m open to different integrations. I think one of the dangers (for us) of adding a ton of adapters is that they must be maintained over a long period of time. That\u2019s why there\u2019s currently a focus towards CNCF products. I\u2019m not entirely sure how to handle the magnitude of cloud products for tracing, performance, metrics sensibly.Any ideas?\n\nOn 5. Sep 2018, at 16:36, Prateek Malhotra notifications@github.com wrote:\nAnybody have a look at https://opencensus.io/? I personally bootstrap Hydra on my own and overlay StackDriver for tracing - I only bring this up as the PR's current implementation seems specific to a single tracing service (jaeger).\nIs the idea to only support CNCF projects within Hydra?\nEither way, I'd really love to see tracing beyond just HTTP requests - luckily for me since I also use my own database plugin I get tracing for both HTTP requests and database queries but only where the requests' context.Context is passed down. Maybe some restructuring can be done to pass the context down throughout the entire application on a per-request basis, and wire up more traces throughout (especially for database interactions)?\nWould also like to see StackDriver support though doesn't look like there's opentracing.io support for it, however opencensus.io does seem to support most of the same backends as opentracing.io + StackDriver!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Interesting. I have no answer at the moment for this. Maybe there is a way to abstract this away and offer different strategies for tracing, but the API contract will always be somewhat close to the features being offered. For now, OT has been merged but I'm open to give OC a go as well. IMO all of this should be in the runtime and not hardwired in the code, but we're not there yet unfortunately.. However, I think we can close this since open tracing is now supported via jaeger!. Please describe how you run hydra, if you compiled it yourself, and so on. The image from docker hub works fine:\n\n$ docker run -d -p 4444:4444 -e DATABASE_URL=memory oryd/hydra:v1.0.0-beta.6 serve --dangerous-force-http\n$ curl http://localhost:4444/version\n{\"version\":\"v1.0.0-beta.6\"}. That is really just for demonstration purposes, usually you would download the binary from github releases or fetch the image from docker hub. The docker-compose example builds the source code in-place which causes the version to be undefined. Resolved by #939. Resolved by 6885a3fc94be9cab17e7588ebc0710da840144bf. This needs to be handled in the CLI as well. dupe #935. The flags are properly enabled. Seems like the original cause was that the user accepted the consent challenge before the login challenge, which does not work.. #962. I think all of them are very sensible requests. Happy to talk proposals and PRs (please discuss first)!. This looks pretty solid. The dependency checks have been removed (they check if the dependency has been initialized and if not fatalf) which should definitely be re-added. I can't promise right now that this will stay 100% as is in the future as there might still be issues which we'll yet have to surface but from a high level perspective this looks good. Feel free to PR.. One thing to note is that I'm currently working on #904 which will refactor the way we initialize the router. I'm not sure if I should wait for your PR (which cleans up some stuff, I really like it) or ask you to rebase your changes once mine is done. Might come down to who is faster :D. Ok sounds good, I'll keep refactoring #904 because my train is also delayed 2 hours so I have more than enough time to work on this ;) Then you can rebase your changes on top of that without touch handler.go. I'll incorporate some of your ideas around NewHandler into my PR.. That's a sensible request. I think there are two ways to support this (we can combine both):\n\nWe use sector_identifier_uri (for clients with sector IDs) and redirect_uri (clients without sector IDs) as well as the subject value and compute an SHA-256 hash to be used as subject using the system secret as salt. This would be something encouraged and defined in the specification.\nWe provide a way to specify another parameter during consent acceptance called subject_pairwise which allows the consent endpoint to specify the subject pairwise ID.\n\nAs we're implementing the OIDC Dynamic Client Registration, clients need to specify subject_type=pairwise during registration in order to use this feature. I am currently unsure if the subject_pairwise key should be disabled/ignored for clients that have subject_type=public or if setting subject_pairwise forces the pairwise subject type, regardless of the client's subject_type.\nThis might actually be something we'd like to configure using an environment variable, which could be something along the lines of OIDC_SUPPORTED_SUBJECT_TYPES=pairwise, OIDC_SUPPORTED_SUBJECT_TYPES=pairwise,public,  OIDC_SUPPORTED_SUBJECT_TYPES=public. That way we can enforce clients to use only the pairwise algorithm which increases data privacy, while still being able to support both public,pairwise as well as only public.\nWhat do you think?. Note to self: This should work with id_token_hint as well - where id_token_hint will have a different subject than stored in the cookie, for example. This would imply that the subject_pairwise value must be set during authentication in order to properly hydrate the auth session. This would also imply that if subject_pairwise is set, authentication with id_token_hint will break if a different client initiates the authorize code flow. It will break because the algorithm computing the subject value is opaque to hydra. In turn, this would work where hydra generates the pairwise subject identifier.. > I would be great to have option to get \"external subject\" from hydra in that case.\nThat's a good point, we'll add this to the things to think about when implementing this.\n\nWhen it comes to the topic of supporting both types (public, pairwise) at the same time, I can't find a valid use case for now, perhaps it may come handy in the future? If you decide to support both types at the same time per client, we would need a flag to determine which subject_type is used during the authentication phase.\n\nIf both types are supported by the server, then the proper algorithm is chosen by checking the subject_type set by the OAuth2 Client during registration.. The idea is to have both. One of the ideas is to have a resolver that associates the pairwise ID with the \"real ID\". It's a bit complicated though as many use cases (e.g. id_token_hint) need to be supported.. This is kinda tricky to implement. The idea would be the following:\n\nSubject IDs in the session cookie, the consent and login payloads are always the \"raw\" subject ID.\nSubject IDs in the ID Token, Access and Refresh Token are the pairwise subject ID.\n\nThis means that on consecutive login flows you will always receive the \"raw\"/\"true\" subject ID. So the \"internal\" view will be untouched while the \"external\" / public view would be different depending on the subject algorithm.\n@michalwojciechowski another idea is to add an endpoint like GET /oauth2/consent/pairwise/<pairwise-id> (naming tbd) which is capable of resolving the pairwise ID to the true subject ID.\nAnother idea is to return the true subject ID on token introspection.\nDo you really need to be able to have full control over setting the subject ID? As far as I understood the thinking behind it was to be able to resolve the subject ID. This could be achieved with the ideas mentioned above.. The sub field is only impacted by this algorithm when the ID Token or the /userinfo endpoint are used. They do not impact OAuth 2.0 Token Introspection as that spec is separate from OIDC Core 1.0.\nThis in turn implies that only the ID Token and the userinfo payloads have to adhere to the pairwise algorithm. This in turn makes the process for the access/refresh tokens completely uninteresting.\nI am assuming that you need to be able to resolve the sub field in the following scenario:\n\n3rd party developer requests ID Token via OAuth2/OIDC\n3rd party developer gets ID Token with pairwise sub\n3rd party developer gets sub value through /userinfo or by parsing the ID Token\n3rd party developer uses something like curl -x GET -h \"Authorization: <access-token> /some-api/<value-from-sub-field>\nYou as the provider need to map that pairwise subject ID to the real subject ID\n\nAm I assuming this correctly?. One issue persists though. Assuming we are issuing a JSON Web Token as access token - the sub field will be visible to the client. In this case, the sub field of the access/refresh token has to be altered as well.. I checked how other libraries solve this. node-oidc-provider has a different subject ID in the introspection response too. I think they are wrong though, the introspection is really to fetch metadata about a subject from the PROVIDER side, not the consumer (client). Thus it doesn't make sense to have the pairwise subject in the introspection response. This gets muddier with JWTs where the sub is actually transparent to the clients (that's why I don't like JWT for access tokens...) but I think it's legitimate to (at least for now) disable JWTs with pairwise config. It's a bit dirty but then again JWTs as access tokens are dirty and it removes development overhead which makes hitting the deadline more realistic.. @michalwojciechowski @damian0o could you please comment on https://github.com/ory/hydra/issues/950#issuecomment-410738973 ? Otherwise I'll move on with the implementation laid out in https://github.com/ory/hydra/issues/950#issuecomment-410739772 https://github.com/ory/hydra/issues/950#issuecomment-410837656. I disagree. OAuth 2.0 Token Introspection has a clear definition of who's calling:\n\nThis specification defines a method for a protected resource * to query\n   an OAuth 2.0 authorization server to determine the active state of an\n   OAuth 2.0 token and to determine meta-information about this token.\n   OAuth 2.0 deployments can use this method to convey information about\n   the authorization context of the token from the authorization server\n   to the protected resource.\n\n* protected resource = resource on the resource provider (your first-party API)\n\nIn OAuth 2.0 [RFC6749], the contents of tokens are opaque to clients.\n   This means that the client does not need to know anything about the\n   content or structure of the token itself, if there is any.  However,\n   there is still a large amount of metadata that may be attached to a\n   token, such as its current validity, approved scopes, and information\n   about the context in which the token was issued.  These pieces of\n   information are often vital to protected resources making\n   authorization decisions based on the tokens being presented.  Since\n   OAuth 2.0 does not define a protocol for the resource server to learn\n   meta-information about a token that it has received from an\n   authorization server, several different approaches have been\n   developed to bridge this gap.  These include using structured token\n   formats such as JWT [RFC7519] or proprietary inter-service\n   communication mechanisms (such as shared databases and protected\n   enterprise service buses) that convey token information.\nThis specification defines a protocol that allows authorized\n   protected resources to query the authorization server to determine\n   the set of metadata for a given token that was presented to them by\n   an OAuth 2.0 client.\nAdditionally, a protected\n   resource can use the mechanism described in this specification to\n   introspect the token in a particular authorization decision context\n   and ascertain the relevant metadata about the token to make this\n   authorization decision appropriately.\n\nTo me, it is very clear what the intention of OAuth 2.0 Token Introspection is. It is for your first-party resource provider (basically your API or API Gateway) to check if the access token is valid and if so, what metadata is associated with it.\nFor the resource server it makes no sense to have an obfuscated user id (sub). The obfuscated user id is only relevant for the outside view (namely 3rd party clients using your OIDC server to authenticate users).. By the way, this is also the reason why there is no public OAuth 2.0 Token Introspection endpoint Google, Microsoft, Amazon, Dropbox, Facebook, ... (you name it).. If a 3rd party wants to expose their APIs to other 3rd parties (or 4th parties? \ud83d\ude03) they should have their own authorization infrastructure in place:\n\nA user clicks on \"sign in with verimi\" in application \"mybank\"\nUser authenticates at the idp\nApplication \"mybank\" gets an access, refresh, and ID token\n\"mybank\" validates ID token and verifies the claims. Here is the obfuscated user id. \"mybank\" now sets up internal metadata in a session cookie or whatever. The user is authenticated.\n\"mybank\" uses the access token at verimi to perform e.g. updates to the user profile or whatever\n\nSo in the case that \"mybank\" now exposes resource providers (let's just call that \"mybank API\" for now):\n\nA user clicks on \"sign in with mybank\" in application \"3rd-party-app-mybank\"\nUser is redirected to mybank\nUser authenticates via \"sign in with verimi\" (this is step 1 from above)\nUser performs the flow etc until step 5 from above\nUser is now authenticated at mybank\n\"mybank\" sends \"3rd-party-app-mybank\" access, refresh, id tokens\n\"3rd-party-app-mybank\" uses access token to do whatever on \"mybank API\" - for example see the last 10 transactions\n\nFrom my understanding, there is no need for introspection here anywhere. Authentication is done via OIDC. Authorization is done (at the first party) via introspection. Authorization for the third party / relying party / client is done in the client and completely independent and isolated from your authorization infrastructure.. As discussed on the phone we'll add an additional field to the OAuth 2.0 Token Introspection obfuscated_sub (open for name suggestions) which contains the obfuscated user id. This way, your first-party server can obtain both cleartext and obfuscated IDs!. The JWT strategy does not support the pairwise algorithm at the moment. It's one of the problems which I have been advocating for a while (transparent access token metadata) with regards to JSON Web Tokens as access tokens, but now it's a real effect. There is currently no way of making this work with the JWT strategy because the access token state is regarded as internal. Internal resources however must be able to resolve the user ID from the access token which is not possible with a one-way hashing algorithm like the one we're using (SHA-256). So there is no way really to make this work.\ntl;dr there is currently no way to make this work with JWTs natively in ORY Hydra. If you try to use both (JWT + Pairwise) then OAuth2 flows will fail.. Thank you for raising this issue. This is actually according to the recommendations made in the OpenID Connect Core 1.0 specification:\n\nOPTIONAL. ID Token previously issued by the Authorization Server being passed as a hint about the End-User's current or past authenticated session with the Client. If the End-User identified by the ID Token is logged in or is logged in by the request, then the Authorization Server returns a positive response; otherwise, it SHOULD return an error, such as login_required. When possible, an id_token_hint SHOULD be present when prompt=none is used and an invalid_request error MAY be returned if it is not; however, the server SHOULD respond successfully when possible, even if it is not present. The Authorization Server need not be listed as an audience of the ID Token when it is used as an id_token_hint value.\n\nThe important part is here:\n\nIf the End-User identified by the ID Token is logged in or is logged in by the request, then the Authorization Server returns a positive response; otherwise, it SHOULD return an error, such as login_required.\n\nwhile SHOULD is not imperative, the language is clear (see RFC2119):\n\n\nSHOULD   This word, or the adjective \"RECOMMENDED\", mean that there\n   may exist valid reasons in particular circumstances to ignore a\n   particular item, but the full implications must be understood and\n   carefully weighed before choosing a different course.\n\n\nThe OpenID certification self-service has a test for this. It requires a fresh browser, logs the user in, requests an ID token, and then redoes the flow with setting the id_token as id_token_hint.\nPlease let me know if you see this differently or can cite sources that contradict my statement.. To clarify a bit more:\n\n\"If the End-User identified by the ID Token is logged in\": You provide an id_token_hint with subject=foouser. The device (browser) accessing the /oauth2/auth endpoint has a session for foouser -> valid request.\n\"If the End-User identified by the ID Token [...] or is logged in by the request\": You provide an id_token_hint with subject=foouser. The device (browser) accessing the /oauth2/auth endpoint has no session. The user requires re-authentication. If the authenticated user is foouser -> valid request\n\"otherwise, it SHOULD return an error, such as login_required.\": Any other case where either the session or the re-authenticated user does not match the sub value from the ID token.. Right, the important piece is Close the browser which removes the session cookies (so cookies that have no Max-Age set). It's possible that the cookie that was set has no Max-Age set (e.g. because remember_for or remember were not set). There was also a PR ( #930 ) about this recently which has been merged on master but not yet released. Could you check if the cookie is set properly during the first authentication process?. > Ok, so without \"Remember me\" checkbox enabled on login page, cookie has Max-Age set to 3600. With \"Remember me\" enabled, Max-Age value is 2592000. But we have tested that in incognito mode in the browser and close the browser after the first flow has ended.\n\nWhen you close an incognito browser window, all cookies will be removed regardless of Max-Age. So it is to be expected that the user has to re-authenticate.\n\nHow do you understand by \"logged in by the request\"?\nIn our case, authenticated user is foouser.\n\nIn the scenario you described (closing an incognito browser window), the user is no longer authenticated.. > If I understand the specification correctly, the valid and not expired IdToken send as id_token_hint in authorization request is responsible to tell Authorization Server that Resource Owner of this IdToken is already authenticated. So if the valid and not expired IdToken has been sent by RO then RO should be authenticated and Hydra should skip the login page no matter what the cookies values are.\nIn the OpenId specification, there is no correlation between IdToken and cookies.\nI explained this in comments \nhttps://github.com/ory/hydra/issues/951#issuecomment-407754418 and https://github.com/ory/hydra/issues/951#issuecomment-407755268\nThe id_token_hint is a hint, so something that hints towards the identity of the user. It is not a supplement for authentication.\n\nI have also tried to send id_token_hint with prompt=none and got this error\n\nSee point 3 in comment https://github.com/ory/hydra/issues/951#issuecomment-407755268\nJust imagine what kind of hacks I could do if I could authenticate you with an ID token. Just assume I have a malicious app that you use that request ID Tokens. I own your ID token now and authenticate with a new set of scopes at the OAuth2 server - suddenly I have control over your bank transactions although you never consented to that.. Thank you!. This also touches #902 - PRs appreciated!. I'm pinging you @kingjan1999 so this doesn't get lost in your notifications. This looks already very solid, just a few things which I mentioned during review :). The only thing left is the naming of the one struct and then this is good to get merged from my side! Thank you so much for your contribution :). Perfect!. Thank you for the updates! The newly generated SDK breaks tests because the methods have been renamed:\nconsent/sdk_test.go:121:24: sdk.ListUserClientConsentSessions undefined (type *hydra.CodeGenSDK has no field or method ListUserClientConsentSessions)\nconsent/sdk_test.go:128:23: sdk.ListUserClientConsentSessions undefined (type *hydra.CodeGenSDK has no field or method ListUserClientConsentSessions). Thank you so much for your hard work!. Please share your configuration (all env vars, truncate sensitive ones) too.. I can not reproduce this. Refresh tokens do not have an expiry time by the way.. > Updated though one thing to note is dependency checks are still used in cmd/server unrelated to injecting so I basically just copied this out to config and left it there.\nThat makes total sense and is much cleaner. Thank you for your work on this, I truly think this is a step forward to re-usability and customization of Hydra and I really like the design you chose. Thank you for this contribution!. Please provide more context:\n\nWhich endpoints should be affected?\nWhat's the use case?\nDoes this exist in the wild, and if so, where?\n\nThank you!. Right, but in this case this would be only the /oauth2/token and /oauth2/revoke endpoints, as all other endpoints do not have a concept of request ownership. Does that cover your use case?. That endpoint is only accessed by the user through the browser directly, no CORS needed here.. Closed by https://github.com/ory/hydra/pull/1009. You can generate your own, see examples here: https://github.com/ory/hydra/blob/master/scripts/run-gensdk.sh#L15\n. Sounds good! I think Generate(claims jwt2.Claims, header jwt.Mapper) (string, string, error) is only used in fosite, if I am not mistaken.. Ah right, userinfo uses it. Makes sense regarding extending the fosite interface!\n\nOn 3. Aug 2018, at 16:31, Prateek Malhotra notifications@github.com wrote:\nDoes it make more sense to just add GetPublicKeyID() (string, error) to the JWTStrategy interface in fosite and just use that here? Looks like the implementation in hydra just layers ontop of fosite to refresh the keys.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Yes, I think this should be introduced in Hydra as the GetPublicKeyID() (which basically allows refreshing the public/private keys) is currently a Hydra-only feature.. The changes look solid!. Thank you!. This is actually caused by the SDK which sets \n\n``\nActive booljson:\"active,omitempty\"````. Yes, feel free to PR. If you do, please add docs to github.com/ory/docs that explain the new mysql mode.. https://github.com/ory/sqlcon/releases/tag/v0.0.4. yes. I think there should be an environment variableLOGOUT_REDIRECT_URL` to which the browser is redirected upon successful logout. There should not be an option to set the redirect URL from the browser. If wee need it, we can add that later.\nThe method for logging out is already implemented. All we need to do is expose this method via a URL. The HTTP handler should probably be in this file.\nI think the URL should be something like /oauth2/auth/logout. Be aware that the router being used there is the one for port 4445. You will have to get the second router (frontend router on port 4444) for this to work.. One more thing, please document LOGOUT_REDIRECT_URL somewhere around here. > One more thing - What should be the behaviour if the user does not set LOGOUT_REDIRECT_URL ?\nTwo options\nSee this comment: https://github.com/ory/hydra/pull/971#discussion_r208136347\n\nAdditionally, we should set up a default handler for the log out screen, similar to this one and add it to the frontend router here. The layout of the page doesn't matter. It should read something \"You have been logged out successfully. ... Admin forgot to set up the redirect URL after logout ... to fix that set environment variable LogoutRedirectURL, e.g. export LogoutRedirectURL=http://... or on windows set LogoutRedirectURL=http://... ...\". I know now why this (reformat) in the SDK happens. Apparently, gofmt tries to format the .php and .js files which causes this error (uppercasing). Not sure why it does that but that's the error. Happened to me as well. VScode executes gofmt automatically on all files. It was really weird, I commited all the changes to a new branch, then switched back. Only then did they disappear. I honestly have no idea what's going on here.... Did you manage to get it fixed? Maybe it was a broken git index? I had the issue several times too. I finally fixed it though, I think it had something to do with lower/uppercase of the filename. If this blocks you from working on the PR let me know.. Just letting you know that I'll take your changes and integrate my feedback so this can be released with beta.8 today. Thank you for your hard work - new PR is #984. No problem!. LGTM. Exporting them sounds OK to me!. Oh and could you, once those are all done, add an example to the advanced section in the docs?. Yeah, basic example would be perfect!. Thanks!. That looks like a bug, I'll try to confirm once I'm back in office by end of this week.. > oryd/hydra:unstable (v1.0.0-beta.8). As a sidenote, it would be nice if hydra could print the version number to the logs on startup.\n\nTracked #987 \n. Confirmed bug. Thanks!. Huh, that's interesting, it seems like the nil pointer is coming from the session object. I'll investigate.. Would it be possible for you to provide your login+consent app as a fully functioning app? I'd like to use it to reproduce the issue.. Oh I think I know what the issue is. Because you omitted session (which is fine!) its value is nil but we're accessing a member of said value with session.Session.IDToken which then causes the panic. This is a bug in Hydra and will be fixed. Thank you for reporting!. I really want to avoid having another migration table like here. I also suspect that the two issues you mentioned wont be the only ones. I'm not sure how well CockroachDB works with SQL and specifically more complex join and lock statements. As most cloud providers support manages postgres and mysql at very low cost (but not cockroach), adding cockroach is not a priority for this project.. > Can you point me to concrete SQL sentences, the more complex one you can think of?\nOf course, this is a particularly nasty one.\n\nCockroachDB is working hard making everything pg-compat so if something doesn't work it should be fixed in the upstream and not here.\n\nWith pg-flavoured SQL-compatibility it should be no work to get it working with this project. How far away are they from achieving that?\n\nWould you be open to do some reviews of further PRs at least?\n\nReview yes but no guarantee of merging. This is not about \"oh I don't like nothing that isn't MySQL or PostgreSQL\" or \"I dismiss the upsides of the project\". Instead the issue is that including this in master implies that we:\n\nWrite and test proper migrations for feature versions for another database\nAre able to support people who use CDB and have issues with our database layer due to whatever (e.g. unsupported syntax)\nActually know how to maintain and use CDB because we officially support it\nWork around issues in CDB which clutter the proper/easier to read SQL but might stay there because we are not following the project and don't know when specific issues will be addressed.\n\nNone of these four things are something we can currently afford wrt to resources. Depending on the PR it may be possible that we have an \"implicit\" compatibility with CDB, but if CDB specific issues are addressed in a new migration \"table\"/instruction or existing migrations change (would bring serious trouble) this can't be merged.\nI am however happy to review a PR regarding this, maybe it's much less stuff that changes than I think it is.. > IMHO merging doesn't mean official support, as you said what about just implicit compatibility and test it out explicitly adding a note saying that \"[...] although it seems CockroachDB to be working properly no official support is given\"?\nThat's not how this project works :) If we're including stuff in the codebase, it's supported. With implicit support I mean that there will be no extra migrations, integration, nor e2e tests that check if this actually works! This means that future upgrades might not work with CDB or break the database (very unlikely but possible). If we're making substantial code changes it means that it needs to be tested, and with tests we must maintain it. I hope you understand this reasoning here.\nBut again, if it's possible to do this without any funkiness, let's try it!. That really depends, there are production instances with millions of tokens - depending on which table this touches that could cause some serious db downtime. Which one is it?. Which column is causing the trouble?\nThe latest patch introduces real primary keys (uint, serial) to all tables iirc.. Ah ok, I see. I am more inclined now than I was back in August to have CockroachDB officially supported. The new migration layout would potentially allow to run different migrations for each database, so theoretically, we could add just one new migration file for cockroach db.. The /oauth2/auth and /oauth2/token endpoints should not be included. They have difficult parameters to handle which should be implemented via a proper library. The others could/should be added (except RevokeUserLoginCookie).. Thanks, this is definitely a typo but does not cause any issues because that strategy is actually not used :) Cleaning this up anyways.. Please provide more context, where is 400 thrown, what's the precondition, and so on.. You're talking about log in, but this shows the consent API. Which is it?. If you remember the consent, you should not to show the consent screen again for the same client_id + user + scopes. The remember flag sets that. So yes, expected!. Thanks!. Thanks!. So the issue is that the access token session data is (usually) coupled to the consent state, not to authentication. Personally, I see access token data as internal session data that should not be available to the outside world. The issue is that many people see this differently and want JWT with transparent session data. As we added JWT due to popular demand, the session data is no longer internal and should thus rely on the scopes that have been granted. Therefore, it makes most sense to set the session data during the consent acceptance.\nWe had an issue where we discussed that it would be great to set additional data (\"metadata\") during consent and login. This would allow the consent app to delegate state management to hydra instead of implementing a DB connectivity for this. Would this improve your situation?. > If you mean that instead of setting the accessToken I\u2019ll be able to set and then read some other metadata field that would be not be shown anywhere in the JWT or token introspection - or even be available solely in the current authentication flow (and consequent \u201cskipped\u201d ones) - that would also solve the issue, as I could read that metatada at the consent callback and properly reference the the correct the user object.\nThe data would be available when\n\nthe same user is found during login dance (requires login.remember: true)\nthe same user is found during consent dance (does not require login.remember: true)\n\nYou're right however that writing to this store unhinged is prone to conflict. It's probably not such a great idea after all.\nAnother possibility would be to include the login challenge in the consent request payload. That way you could set up a store where you temporarily keep the data you need during login (the key would be the login challenge) and retrieve (and optionally delete) that data during consent by looking up the login challenge.\nWith that, you can implement what you're asking and we're not adding stuff to the hydra functionality that might work for some cases but not all.. I don't think it's that easy generalizable. Just off the top of my hat, I already see two distinctions:\n\nYou set data during login and it is available for the related consent request. If the user performs another OAuth 2.0 flow the data will not be available, unless you explicitly set it there as well.\nYou set data during login which is available for the remainder of the login session validity (if remember is true that's e.g. 30 days) to both login and consent. Assuming the user performs another OAuth 2.0 flow, the data will be available for both login and consent.. > (2) is not needed in my opinion.\n\nWell...it's not needed for your use case, which is why I said that it's not that easily generalizable.\nNevertheless, I think including the login challenge during consent is a good start. We might even include the login session ID if it exists, that way you can persist data across multiple login requests. Storing the data for you isn't something I'd put on the priority list. First it's not something required for getting to 1.0.0 stable and second is that ORY Hydra isn't a datastore. I mean sure, we can have store a JSON object for you, but you can't query it. You can't update the schema. You can't migrate. You can't test it. I'm doubting if that would be a good idea. Your consent/login app is connected to a store anyways (where would you get your user data from otherwise?) so the added complexity of storing something along a key in a format that you see fit isn't something that is difficult to achieve.. > I didn't mean to say I know what's needed and what's not, sorry if I miscommunicated that.\nNo need to apologize. I may sound harsh sometimes, but that's just my German nature ;)\nOk, I think the first actionable item will be to add the login challenge to the consent payload so we can track this across requests. Regarding storage of metadata, I really have to think about this. As I said in the previous comment, I see a lot of downsides to this. But maybe I can come up with something that eases those concerns! Please note though that this isn't high priority as there's a ton of stuff currently on my / our plates. If you need this rather soon, either work out a proposal for a PR or drop a line to hi@ory.sh to figure something out. Cheers!. We added login.session_id and consent.login_session_id as well as consent.login_challenge which allow you to link the request to one another. The store you requested will not make it in the product because of the issues I mentioned.. Ok, let's reopen this - feel free to PR (please discuss the changes first in this issue).. Why don't we add another field to the /login/:challenge/accept endpoint with metadata json.RawMessage which is then returned at /consent/:challenge as login_metadata? I don't think this should persist though but be individual metadata for every login&consent flow. The login endpoint would have to resend the data. Keep in mind that every login request is being forwarded to the login endpoint, regardless of remember state.. Tracked as enhancement but currently not on our priority list for 1.0.0 stable.. Looks like a bug, although = isn't url safe it probably shouldn't be double encoded. It's also allowed per spec in the state iirc.. Actually, I can not reproduce this. I tried it with &state=rflvvkpeldfzfdzyoocqihxh%3D%3D and  &state=rflvvkpeldfzfdzyoocqihxh== in the browser url. The first time the state comes back with &state=rflvvkpeldfzfdzyoocqihxh%3D%3D and also the second time &state=rflvvkpeldfzfdzyoocqihxh%3D%3D. I also checked the code and there is no double encoding. Are you sure this isn't on your side (client code)?. Closing, feel free to comment/reopen you found the issue. > From developer point of view second request from user is something that may happen and developer should be able to handle that correctly (ignore?) in consent provider application.\nYup, the error should be ignored or shown to the user.. Is this MySQL?. Ah, yeah, dupe key detection is broken there, fixing.... You can not authenticate users using an ID Token, it is only a hint to the user's identity. That being said, expired tokens should still be accepted as token hints.. thanks!. Thanks, PRs welcome!. Thank you for your hard work!. Flags like --allow-insecure-behaviour are a two-sided sword. On the one side, set ups like yours are much easier to test. On the other, what's used in development often makes it to production. People forget flags like these in Dockerfiles, kubernetes configs, you name it. I was thinking about whitelisting certain domains with a flag but I think it's also a bad idea, because you're apparently mirroring the public TLD but without SSL, so it's incredibly easy to forget that you need to remove this flag later on, and the error won't be caught because it's the same domain.\nIs there no other way to work around this for you?. > If that's your stance, I totally understand it and will not argue this further.\nYes, the \"mantra\" of this ecosystem is to make bad things hard. Another option is of course to add an SSL termination proxy in front of your API gateway or whatever you use, with a certificate that is either issued by an internal-trusted CA or self-issued (and trusted obviously). It makes sense to fix that and lower developer frustration. It makes sense to have --dangerous-force-http to enable http redirect urls as well.. We will probably not address this as part of rc.1 but it's on the roadmap for 1.0 stable!. Thank you for the detailed explanation. This is indeed not supported at the moment but should be possible to be added without adding complexity in the consent flow.. Looks good, thanks!. Thanks!. Thanks! I\u2019ll investigate this over the weekend!. Ok so this is actually a mixture of bad CLI error messages and mistaken assumptions:\n\nAll used secrets are 32 alphanumerics.\n\nNo they're not, SYSTEM_SECRET=system_secret_2 and SYSTEM_SECRET=system_secret_1 are each only 16 characters long.\nI'll fix the broken error messages but the root cause of this issue is misconfiguration. Thank you for reporting!. Reopening for investigation following discussion on discord. > CORS_ENABLED enables CORS on both the backend handler as well as the Client ID OAuth2 endpoints - should these be tied together? In other words, if I want CORS to work for my Clients but don't need it for the backend, why am I tied to both from a single setting?\nYeah you're right, this is kind of akward. The idea is that hydra serve all is like a catch-call serve process wrt config. If you need more granular control you can use hydra serve admin and hydra serve public where you can set up the configs individually. But you're generally right that admin and public ports usually have different CORS settings. I'm not sure if splitting env vars is worth it though, as you can set up the processes individually.\n\nNo way to set CORS settings for the /.well-known/ paths currently - what if my SPA needs to read this before trying to initiate a PKCE Auth Code flow as is the case with the AppAuth-JS library?\n\nOh really? That's definitively a bug!\n\nAnother potential bug here, even with CORS enabled, am I able to exchange an authorization_code for a token? If I whitelisted URI's on my client for CORS, the way the CORS middleware is currently written, unless I use Basic AUTH on my request, it will expect an Access Token on the request which is what I'm trying to get with the request.\n\nIndeed, there a two ways the token endpoint can be used (or rather three ways the token endpoint allows authorization):\n\nUsing HTTP Basic Authorization.\nTransmitting client_id in POST body (when using public clients). This will not work at the moment!\n\nBearer tokens can be used when revoking access tokens, which is why this is enabled here.. Yes, this can be closed now!. Interesting, that could indeed be an easy win. It would be great to initialize this with some \"works out-of-the-box\" configuration, like setting allowed domains to IssuerURL.. That's the trade off for these headers. Browsers are typically fine with implementing them correctly, but other software - such as LBs, client libs, sdks, sometimes even proxies - do not always adhere to those as most HTTP servers are very forgiving wrt to headers.\nI am thus also a bit hesitant on my decision. On the one hand, we do have TLS and CORS support in the server, but is it really supposed to be there? Shouldn't that be something a global proxy handles for all of the application? Then again, some custom logic is required, for example for client-specific cors handling.\nIf we add every feature above (and make it configurable) to the stack, we will end up with a ton of options for configuration. I always knew that this would happen in the end but I really want to avoid configuration nightmares that are e.g. apache configs.\nAny ideas?. Ok, that makes sense to me. Would you be open to tackle this?. > Introduce github.com/unrolled/secure middleware - statically set BrowserXssFilter & ContentTypeNosniff options to true\nSounds good.\n\nIntroduce HSTS options to hydra to enable the feature in the new middleware\n\nHere is where I'm a bit confused. HSTS is a useful technology, but I don't see the use for it in Hydra. Hydra runs only in two modes - HTTPS or HTTP. If HTTPS is enabled, no HTTP can be exposed. As such, it's not possible to \"accidentally\" connect to HTTP instead of HTTPS in Hydra. If we do have some proxy magic (with potential TLS term / http & https) going on, wouldn't that imply that we want to solve HSTS for the whole domain in the proxy?\n\nAs for CSP - I think this should be set statically here, but only have we introduce dynamic CSP options on a per-client basis. This can be done by auto-whitelisting redirect URIs like some providers do or introduce a CSP Referrer option to clients like there are for CORS. I can open a new issue to track this.\n\nPer-client CORS is already enabled, it's the origin attribute.. > Not all Load Balancers support adding headers on responses (e.g. Google's cloud load balancer) so adding the option in hydra would make sense. It's up to the user to understand the ramifications of enabling this feature if the domain is shared with other services - I personally deploy hydra in a dedicated host with a dedicated subdomain.\nOk, let's add it then. However, will this be disabled in https / ALLOW_TLS_TERMINATION_FROM mode? Or should we deploy this independently from that? In either case, I think configuring this with env vars is an option.\n\nRe CORS vs CSP: I understand Per-client CORS is already enabled, I was asking if we should do the same for CSP headers. My idea is to explicitly disallow everything via CSP by default and only enable domains on a per-client basis as we do CORS.\n\nWhat attack surface does hydra offer for CSP-relevant issues? The only endpoint that could potentially be vulnerable is the /oauth2/auth endpoint which is accessed through the browser. Assuming there would be a bug where you could set /oauth2/auth?foo=<script>alert('xss')</script> CSP could be a valuable mitigation. For all other endpoints I see little use as they return JSON only and are (usually) not accessed directly by a browser.\nTherefore, because we do not actually serve any HTML, CSP could be simply default-src 'none' (if that works), indicating that no resources at all may be loaded. It seems that some new tags have been added as well, like frame-ancestors, maybe they make sense too but I haven't looked them up yet.. > if the user enables the option(s) then it should be used. It's only possibly incorrect to enable the feature if running in HTTP-only mode so we could add a check in for that to warn the user.\nAnd disable/warn if we're running on localhost? I think sensible defaults are good for now. If people complain we can update it. I'd set a long max-age and would not include subdomains as it doesn't make sense for hydra to control this.\n\nMost providers automatically whitelist redirect URLs for both CSP/CORS but I see that in hydra this is broken out separately. Should CSP Frame Ancestors be a new client option?\n\nHm I don't think it adds any value to let clients configure Frame Ancestors. If I can do bad stuff with an iframe I can bypass your CSP policy by registering a client and whitelisting the frame, right?. On second thought, I don't think restricting the frames makes a lot of sense. It's actually by design allowed. This is definitely different for the login and consent page which should set those headers as you want to disallow messing with that.. Yeah, I think we should go with default-src 'none' for now. I am intrigued by disabling iframe all-together (due to the things from the spec and because there are always ways to break out of iframes). As I said before, I don't think it makes sense to whitelist iframes based on client redirect urls. It's not a security measure, just making it a bit harder to penetrate if client registration isn't open (which doesn't make a ton of sense for oauth2 servers). The iframe CSP could make sense for other endpoints as it would disallow inclusion of the payloads in the iframe. I'm not sure if it's a big issue but if it doesn't break anything, why not?. Regarding disabling iframe alltogether..well..openid connect is \"special\" here, they rely on iframes for things like silent refresh. I think FitBit is doing the right thing by disabling this. IMO silent refresh is obselete anyways because we have PKCE flows which give you refresh tokens.. > Regarding PKCE + Silent Refresh - there is no way to secure data in the browser, and since PKCE was written with \"apps\" in mind - not necessarily all public clients such as a web browser, I don't think there is a good way to use refresh tokens with PKCE in the browser. That said, refresh tokens should be avoided in the browser and mechanisms such as silent refresh should instead be used IMHO.\nPoint made, point taken. The question for me is if it's less secure to keep secrets in the browser (like refresh tokens) or to enable iframes (and clickjacking) in ORY Hydra. I'm not sure which one's which, but attacking one specific app that keeps the secret in the browser (using XSS to extract the refresh token) has less impact then clickjacking with an iframe which is for the whole domain. I'm really not sure what's best here.\n\nI think it's a defense-in-depth mechanism to only allow the auth handler in an iframe from a whitelist - let the developer decide if it's ok to embed the authorization handler as an iframe, and only on trusted domains.\n\nI think frame-ancestors gives you a false sense of security. We can enable it for all endpoints other than /oauth2/auth but it's only a cosmetic fix. For the auth endpoint it just doesn't make sense to me. Here's why:\n\nWe use http-only and secure cookies for csrf and auth cookies. Even if there was some way of performing XSS on the iframe (due to a browser bug and misconfigured CSP) there is nothing to be stolen. Maybe we could modify the redirect to a forged login page? Not sure if that's possible.\nLet's say frame-ancestors blocks everything. Since we need silent refresh, OAuth2 clients would need some way of saying which iframe is ok (e.g. myapp.com). But now we're enabling issue 1 from happening. Why? Well, I'm a hacker. I want to exploit an iframe bug. I create an OAuth2 app and set the allowed url to my malicious domain. Voila, frame-ancestors is useless.\n\nAs the authorization server owner, allowing iframes globally is as secure as allowing iframes per client. I hope it's possible to follow me here.. Awesome! Yeah let's disable HSTS preloading for now.. Would it make sense to propagate context down to other stores too?. It's definitely a bit larger, but that's fine as there's no functional change so it's very easy to review. So far this looks good to me!. Do you want to address the rest of the managers in this PR as well? You can also create another one - it doesn't really matter to me :) Maybe it's best to have the context in one commit (the one I'll squash when merging this). Ah yeah, that makes sense regarding JWT Strategy. It will also improve the API contract in fosite, which is using context almost everywhere anyways (well, except there and in bcrypt).. Wow this is massive! But looks good to me so far!. Thank you for your contribution!. Ah, interesting, I think this is indeed a wrong handling of sql.ErrNoRows which returns 404 but in this case should just return an empty list!. Sorry, I misread your trace and it makes total sense when you look at the stack trace. This is really about consistency between the different modules. I'm closing this as it is tracked by #1131. Thank you, I'll investigate this.. I'm not sure if you can set acr_value if acr_values isn't set in the request.. Busy schedule, will try to get it done next week.. But feel free to investigate yourself & supply a PR :). I can confirm that this is not properly propagated!. Since we don't implement UIs in ORY Hydra (and won't change that) this has to be solved another way. Maybe use a redirect URL which shows the authZ code used for pasting?. urn:ietf:wg:oauth:2.0:oob does not seem to be an official namespace, it's at least not possible for me to find the specification for it anywhere. In fact, it seems to be a google-specific value and IETF folks really don't like it:\n\nurn:ietf:wg:oauth:2.0:oob is a google thing that is not part of the OAuth 2 specification.I think it was mostly a windows thing.It is not a real redirect URI it is used as a flag to the authorization server to have the result returned \u201cOut Of Band\u201d and the user cut and paste the token.On windows applications could snoop the title bars of other apps so programatically retrieve the token value from the title bar.I don\u2019t really want to put effort into expanding all the reasons this is not secure.I don\u2019t honestly know what would happen if you sent that redirect URI to a non Google AS probably nothing good. \u00a0\u00a0It is not part of the OAuth specification and not something people should use without having a good reason and understanding the security implications.William and I documented several ways to impliment native applications on OSX and Windows in RFC8252.\n\nAs such, this will not be added to ORY Hydra but I'm sure you can work around this by implementing an app with a dedicated redirect url http://my-out-of-band/app/which/is/not/that/secure that handles this.. Closing due to reasons given above, feel free to elaborate if you think this is a bad decision or if you have questions on how to implement this yourself!. Please use the provided issue template to describe your problem.. Please update to the latest version (beta.9) and see if the problem persists. If it does, provide meaningful ways for reproducing the problem. For example:\n$ DATABASE_URL=memory hydra serve all --dangerous-force-http\n$ hydra token user ...\n$ curl -X DELETE ....\nAnd give some details about the error you're experiencing (client callback page fails is nothing I can work with). Thank you!. Not sure what's going on there but the URL you posted returns a 404 (https://test-oauth.****.org/clients) so it's either misconfigured or whatever, but it's definitely not a bug with hydra. Maybe someone in the chat can help you, but I'm going to closing this because it has to do with your deployment / setup and not the project itself.. Please read the upgrade guide (UPGRADE.md in root directory). Hydra has now two ports, you\u2019re probably accessing the public one.\n\nOn 15. Sep 2018, at 20:37, \u674e\u56fd\u5b9d notifications@github.com wrote:\nDo you want to request a feature or report a bug?\nbug\nWhat is the current behavior?\nGET https://localhost:9000/clients return 404 not found\nClick here to show Hydra Traceback\nIf the current behavior is a bug, please provide the steps to reproduce and if possible a minimal demo of the problem.\nrun docker image : v1.0.0-beta.9\ndocker run -d \n--name ory-hydra-example--hydra \n--network hydraguide \n-p 9000:4444 \n-e SYSTEM_SECRET=$SYSTEM_SECRET \n-e DATABASE_URL=$DATABASE_URL \n-e OAUTH2_ISSUER_URL=https://localhost:9000/ \n-e OAUTH2_CONSENT_URL=http://localhost:5000/Account/Consent \n-e OAUTH2_LOGIN_URL=http://localhost:5000/Account \noryd/hydra:v1.0.0-beta.9 serve\non beta.7 ,hydra log like that:\ntime=\"2018-09-15T16:36:40Z\" level=info msg=\"started handling request\" method=GET remote=114.91.68.137 request=/clients request_id=90a119bd266a8af73e9b1cc352b0752c\ntime=\"2018-09-15T16:36:40Z\" level=info msg=\"completed handling request\" measure#https://mydomain.com\n latency=2505374 method=GET remote=114.91.68.137 request=/clients request_id=90a119bd266a8af73e9b1cc352b0752c status=200 text_status=OK took=2.505374ms\non beta.9 ,hydra log like that:\ntime=\"2018-09-15T16:33:54Z\" level=info msg=\"started handling request\" method=GET remote=114.91.68.137 request=/clients request_id=953081257a40206153e800d04a53da94\ntime=\"2018-09-15T16:33:54Z\" level=info msg=\"completed handling request\" measure#https://mydomain.com .latency=102896 method=GET remote=114.91.68.137 request=/clients request_id=953081257a40206153e800d04a53da94 status=404 text_status=\"Not Found\" took=\"102.896\u00b5s\"\nWhich version of the software is affected?\n1.0 beta 9\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I see, that's weird. I can't tell right now what's causing this, any ideas?. Ah I see, thank you for the traceback! Do you think you could supply a fix for it?. Another possibility is to introduce swaggerOAuth2Client which is basically 1:1 the existing client definition but with the jwk structs. This would remove the need for the JSON dance and yield the same result\nOn 20. Sep 2018, at 03:22, Pierre-David B\u00e9langer notifications@github.com wrote:\n@pierredavidbelanger commented on this pull request.\nIn client/client.go:\n\n@@ -204,7 +206,19 @@ func (c *Client) GetJSONWebKeysURI() string {\n }\n\nfunc (c Client) GetJSONWebKeys() jose.JSONWebKeySet {\n- return c.JSONWebKeys\nYeah, this function is weird and not trivial now, but I used the fact that your - now named - jwk.JSONWebKeySet is JSON 100% compatible with jose.JSONWebKeySet.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Ah damn, I didn't think about that. The problem I have with this patch is really the JSON marshalling in the get function. I was thinking if we could construct jose.JSONWebKey without using marshal but I don't really think so. Maybe we could try to modify the method and use a `byte.Buffer? This would make it a bit more readable:\n\ngo\nfunc (c *Client) GetJSONWebKeys() (*jose.JSONWebKeySet) {\n    if c.JSONWebKeys == nil {\n        return nil\n    }\n        b := bytes.NewBuffer()\n        if err := json.NewEncoder(b).Encode(c.JSONWebKeys); err != nil {    \n        return nil\n    }\n    var j jose.JSONWebKeySet\n    if err := json.NewDecoder(b).Decode(&j) err != nil {\n        return nil\n    }\n    return j\n}\nIt's still a long stretch from \"readable\" but at least it's a bit shorter. I would still like to see a better option here though.... Another issue I see though is that the meaning of c.JSONWebKeys changed. I don't think it's being used somewhere else right now but we'll have to make sure to use GetJSONWebKeys at all times when we're expecting the jose version. This is hard.... Closed in favor of #1045. Thanks!. Thanks, would you mind addressing this in a PR?. Ok, so I just checked with the spec and end_session_endpoint is a value from OpenID Connect Session Management 1.0 which is currently a draft and is thus not stable. We discussed implementing this spec a few times here but the general consensus was to wait until it's final, and also big question marks regarding some of the flows which use hidden iframes and other ugliness. As such, this feature will currently not be added as we don't want to implement something from a spec that's actually not supported.\nPlease raise an issue with the lib you're using for making this configurable or working towards a solution which enables you to consume this functionality without relying on the value. Thanks!. This is intended behavior. First of all, there is no difference between http://localhost:4444 and http://localhost:4444/. But there is a difference between http://localhost:4444/foo and http://localhost:4444/foo/. The second is a path, the first is a file. The authorization server is a collection of things (path).\nUnless there is a proper issue with this (which I'm sure there isn't), this will not change.. The examples are just that, examples. But the bigger question is, why do you care and why is this a problem? Is there a client library that expects this to not have a trailing slash?\nStreamlining the little things (like this) is extremely important. Let's assume you run two instances with equal configs but forget to add the / to one of the configs. Now tokens from instance A can not be verified by some clients because they expect a trailing slash.\nRemoving this would not improve the product, it would degrade developer experience (making it easier to make simple mistakes). Unless there's a proper issue here, again, this is expected and will not be changed.. Thank you!. yup, feel free to go ahead. Thanks!. Haha, nice find! This will be a tough decision. After some deliberation, I like this one much more! One thing though, could you document here and here why it is important that these stay uppercase? This helps preventing regression issues in the future!. Thank you!!. This is already the case.. This vulnerability has been fixed by all browsers a long time ago, even in IE 10. It was not possible for Array only (Array.prototype overloading) but objects too (with Object.prototype overloading) so both variants were \u201evulnerable\u201c - well, the browsers were.\n\nOn 24. Sep 2018, at 20:22, retendo notifications@github.com wrote:\nPros for 2:\nThere seems to be a security concern for returning plain arrays in responses:\nhttps://haacked.com/archive/2008/11/20/anatomy-of-a-subtle-json-vulnerability.aspx/\nAlso, the response would be better suited for future extension, for example if you would want to return a totalCount or something like that next to the actual data.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I agree. I think the GitHub link header is a good direction. I will check if it is possible to include additional payloads (like count) without modifying the payload.\nOn 24. Sep 2018, at 23:23, Amir Aslaminejad notifications@github.com wrote:\nI opt for maintaining backwards compatibility in the response payload as some people may already plumbed together some form of administrative UI.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. While the problem is definitively there, having a session-fixed cursor opens a different can of worms, especially because Hydra\u2018s IDs are currently user-defined and not ordered, so something like last_seen won\u2019t work. I\u2019ll take it into consideration but can\u2019t promise it will make it to the final result.\n\nAlso, the impact is minimal. There aren\u2019t a ton of OAuth2 Clients around usually, neither are there a lot of JWKs. This may be an issue with sessions and tokens, but we\u2019re not exposing list capabilities there.\n\nOn 25. Sep 2018, at 13:45, Dmitry notifications@github.com wrote:\nI propose to consider pagination tokens instead of offsets, this way you prevent the case when some data will be added/deleted between requests. The idea is that you specify amount of items you want in request and you receive token back. By using this token you will get next amount of items. Here is more info: https://use-the-index-luke.com/no-offset\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Changing the PKs has been on my mind for a while. I always backed off from it because of the policy module but as that is no longer relevant in Hydra it would be a smart move pre-1.0 stable. We do have auto-increment PKs now which we will use as offset. This works really well with the memory adapter too as we'll just index the slice. I really like the GitHub approach as that will also not cause any BC breaks in the API:\n\nLink: <https://hydra/clients?offset=123131&limit=10>; rel=\"next\",\n  <https://hydra/clients?offset=123121&limit=10>; rel=\"last\". Oh, and anyone interested in contributing?. Sure, we don't really care if a query param is string or int!. I think it would make generally sense to remove the public endpoints, such as userinfo, oauth2/token, oauth2/auth, oauth2/revoke from the SDK and only keep the administrative ones here. Reason being that a lot of people think that those methods actually help you implement oauth2 or oidc specific flows. they do not. userinfo is one such example where it's also difficult to properly set up authorization with access tokens (especially refreshing them).. I revisited this and the problem is that we can't express this with the go type system at the moment. We really want to have a userinfo payload that represents the common values as specified by the openid foundation, which leads to this layout:\n``gotype swaggeruserinfoResponsePayload struct {\n    // Subject - Identifier for the End-User at the IssuerURL.\n    Subject stringjson:\"sub\"`\n// End-User's full name in displayable form including all name parts, possibly including titles and suffixes, ordered according to the End-User's locale and preferences.\nName string `json:\"name,omitempty\"`\n\n// Given name(s) or first name(s) of the End-User. Note that in some cultures, people can have multiple given names; all can be present, with the names being separated by space characters.\nGivenName string `json:\"given_name,omitempty\"`\n\n//...\n}\n```\nBecause of that, we can't add an extra field as the extra field is embedded (using maps in the userinfo handler) directly in there. In go, we can't express that. It's not possible to have a mixed struct with defined fields and \"free-for-all\" fields as structured by maps. The downside of using a map[string]interface{} here to represent additional fields is not worth it IMO as the userinfo endpoint is really easy to consume.\nUnfortunately, this is a nofix for the time being. If you have other ideas feel free to comment/reopen.. Do you know how I can define multiple HTTP Methods in the swagger spec for go-swagger?. Yeah that makes sense!. Yes that's the intention. This is part of the efforts for version 1.0 and has long been anticipated. The issue is of course that we're introducing it without having it tested extensively prior to that. Then again, as long as we adhere to the contract set by ourselves (I heavily tend towards Accept: v1.0.1) the implementation is just a detail. The big decision that has to be made is if we want semantic versioning here too (makes the most sense to me as it would be 1:1 with the software version) or stripe-like date-based versioning. What I don't like is v0, v1 as part of the URL. It makes it really hard to introduce even minor changes without having like v100 at one point. This may lead to pushing back fixes that could land today because of \"oh yeah let's release that all together\".. Moving this to post v1 as this is quite a huge task and there are currently no resources to get it done in time.. I'm confused, you only changed code in consent and did not change any package definitions (except for the new one). What caused the cyclic dependencies? Would it not have been enough to just Upper-case the required methods? Packages like testhelpers are an anti-pattern in go.. Nice, thanks!. Stupid flaky tests. I'll fix this one, really annoying. Was it the pseudo-random one again? Tracked as #1053. Ah yeah, I think another one is that the random port assignment chooses the same port twice which then fails because we're setting up public and admin endpoints at the same port. This looks superb! From a code-prespective I have nothing to say.\nYou originally included an example for setting up the right docker images and everything. Now comes the second part:\n\nDocument how to set up tracing with ORY Hydra as a new chapter Setting up OpenTracing for ORY Hydra\noptional: Add an easy to use docker-compose example somwhere. I'm currently unsure if this should be in this repository (hydra), or in ory/examples. If it is in ory/examples, the question is if it should be a new example or added to an existing one. What do you think?. Yeah that makes total sense. Merging :). this is resolved on master. The CLI uses /oauth2/flush for this.. That's a good idea! However, in ORY Hydra, the client can specify the ID so we can't rely on ksuid and ordered results. For the \"internal\" or \"database-specific\" ID I think it would make more sense to leave it up to the DBAL layer and for SQL I think auto_increment makes most sense. resolved by #1069. > Is this issue really resolved by adding indexes to those columns in the oauth2 tables? Wasn't the issue this was trying to address on the client table and the lack of a stable, sortable ID column?\n\nSorry my bad, I got confused :D. Nice catch, thank you!. @aaslamin currently introduces open tracing, this could probably help. But without any details about which endpoint(s) are affected is hard to give advice. Are you aware of the SQL config options available (max_con etc)?. Regarding the original issue, please make sure to actually kill the command at some point. I think the data is only flushed then. For build commands you can check out the Dockerfile itself or compile the binary yourself to see if it works then.. Hm, interesting, I can't get it working even with regular compilation. Not sure what's going on.... I think the flushing doesn't work properly or maybe there is some racy behavior, it would be helpful if someone could help investigate!. Nice! Would be great if we could track this independently, feel free to create an issue regarding this any time.. Ok so my gut feeling here tells me that maybe the graceful http server handler causes issues with gracefully shutting down profiling. Not sure about this yet though.\n@michalwojciechowski maybe #1069 is something that fixes your issues.. Oh right, then it doesn't hook into the shutdown. Not sure why that's in there though, it has to have a reason?. Oh I see, it might have to do something with .Stop() not actually being called because, well, we're doing a SIGINT with ctrl+c or shutdown. I think this should fix it then.. Thanks!. The file is indeed generated by swagger but we have to revert it because the underlying code template does not support certain features we needed before. Open to change the import path as long as it doesn't break stuff.. We're manually updating it anyways because of a patch I had to add. So it's fine to hotfix this as a new commit. swagger-codegen is kinda f*ed anyways because they introduced a new version 2.4 (we're on 2.2 I think) which has a completely different template which is even worse than the one right now. version 3.0 is in rc I think but there are no templates yet, so even if you make a PR or issue it's unlikely that it will be fixed.. This is resolved. All tests are failing, please format and run dep ensure. > I do not know why I had to manually edit Gopkg.toml, but it should work now.\nThat's fine :). Thank you, this is already tracked as #1056 :) Would you like to work on a PR for that?. Closing as dupe here. Yes, this should be fixed asap. Accepting PRs!. This is most likely a bug in your login & consent logic or your auth flow. Maybe you're requesting other permissions or forgot to properly accept the consent part. Silent refresh is supported and tested and certified by the OpenID Foundation.. Please also add a test. Since you didn't change the schema it's probably enough to re-enter the previous data again but with a new ID.. Nice! I'll review that tomorrow!. Thank you!. Yeah, that's a bug. Feel free to PR!. I think the best way to solve is is what @fredbi set on discord: Introduce \"admin\" and \"public\" tags to the swagger conf and thus separating the implementations.. Perfect!. I think we should probably have this configurable. In cases where OIDC Dynamic Client registry is enabled, this should be available - and it shouldn't be available if it's not allowed to the public.. Yeah, wildcards are currently interpreted as literals, see also: https://www.w3.org/TR/cors/#access-control-allow-origin-response-header\nIt's useful nonetheless, tagging as feature request.. You're right, in fact this is a bug. rs/cors (the library we use for cors) should support this: https://github.com/rs/cors#parameters\nNot sure what's going on.. You could just store the database url in the secret. That's one less secret and env var you have to configure.. Is there no way to substitute the variables in the form of postgres://$DB_USER:$DB_PASSWORD@$DB_HOST:$DB_PORT? I'd really like to have only one way of specifying things.. We could probably have a docker image with a custom entrypoint that does something along the lines of:\n```\n!/bin/bash\nexport DATABASE_URL=postgres://$DB_USER:$DB_PASSWORD@$DB_HOST:$DB_PORT\nhydra $1\n```\nThat way, we don't need to deal with this in hydra and there is no need to think about precedence as well as no need to add more environment variables which make it harder to configure this, but still have something that integrates well with kubernetes.. > I disagree based on looking at the source code. But I'm not the maintainer.\nIt's not about the changes in the code, those are easily done within a few lines. But we already have a bunch of environment variables that configure things, I really want to avoid adding more and more stuff to accommodate every use case. The solution for the task you're facing is either env substitution (see my previous comment) or storing the DATABASE_URL as a whole or using TLS. All of those are viable solutions and I agree that we should have better integration with kubernetes. But we shouldn't add more and more config to the already (kinda) bloated config, instead we should opt to reduce it.. Resolved. TY. https://www.ory.sh/docs/guides/master/telemetry/. We have this which uses RSA private/public keypairs. I don't think x.509 client certificates are something that can be added in reasonable time.. Forgot to add: If you have ideas or plans to implement it a PR would be interesting. Please address what you're planning on doing first though.. As discussed in SF, https://tools.ietf.org/html/draft-ietf-oauth-mtls-11 is a pretty good draft but needs some polishing. While Evan and I work on this, I'll put this on hold.. This is currently on hold due to lack of clarity and lack of resources. But happy to talk options if you have any.. Feel free to create a PR for this in fosite.. We switched to go modules, dep is no longer supported.. This has been removed intentionally as refresh tokens are long living credentials and do not have an expiry time defined. To revoke refresh tokens you can use the /oauth2/revoke endpoint.. I'm not sure, there isn't really a reason for doing that, let me explain:\nYou're probably coming from an angle where limiting credentials' lifetimes is seen as a security feature. I agree. The thing is, there is not much upside to introducing a lifespan to refresh tokens. Here's would we gain if refresh tokens expire after some time:\n\nThe application is unable to refresh the token and requests re-authorization from the user.\nThe user performs the oauth2 dance but because the application is already authorized is not shown the consent screen. Maybe the user has to re-authenticate but that's not something we really care about in wrt to the 3rd party app as an oauth2 provider.\n\nThe re-authorization process (consent) is skipped because the user already granted consent. If the user was to actually click the permissions, that can only be because prompt was set or because we revoked the application's access. In the latter case, all access and refresh tokens are invalidated anyways.\nThere is the case where consent is not remembered. This is the only interaction where I think expiring refresh tokens make sense. You would basically need to re-authorize an app after a certain period, but it's also a bit strange because what's the reference? Just because you didn't use an app for a three days, do you have to reauthorize? Why is this requirement not valid if you use the app every day? What's the difference?\nTo conclude, I understand the desire, but I doubt it's usefulness.\nedit:// And please no +1, we're past that with github issue reactions!. As a consumer of the API you can voluntarily do that with prompt=login. Alternatively, you can use the implicit flow with e.g. hidden iframe refresh to achieve the same. Or you use a small proxy that stores the tokens in a httpOnly + secure cookie, mitigating risk of XSS.. I'm closing this here and am tracking it in fosite: https://github.com/ory/fosite/issues/319. I've added this feature in fosite and will enable it in hydra next: https://github.com/ory/fosite/pull/337. Why would you store secrets in an unencrypted format on disk? Platforms are getting better at hiding env vars marked as secrets from the shell. I don't really see the upside to this.. I'm not sure about this. Every platform supports secret management with environment variables, is there a specific issue you're addressing with this, like - say - secret management doesn't work with env vars on AWS ECS?\nRegarding HTTPS certificates I agree, it is sort of have to allow it for one thing but not for the other. But then again, TLS Certificates are lengthy and a bit tricky to add as env vars (because of newlines) whereas those secrets are just 32 byte strings.. Actually, I stand more firmly by my point. If we were to indeed support config file configuration like you're suggesting it, we must put more effort into it and let everything be configurable using the filesystem. I don't really want to go there at the moment because it opens another bag of questions and problems (like reloading config, config from db). Adding more and more env config does not make this product more usable but harder to set up. We should try to reduce the amount of things you can use and change and update and have one coherent, streamlined approach to configuration. I'm generally open to file configuration because I think it works great with CI, but it needs to be properly planned and all the things we want in the future should be supported.. That's of course another option, writing a bash script/entrypoints that load env vars from files.. Closing in favor of #1108. feel free to PR. That's usually due to some mishap while c&p, could you retry the tutorial again from afresh?. If you're getting unique key violation you're not starting against a fresh installation. Do docker-compose kill and docker-compose rm, then restart the tutorial.. The IP 0.0.0.0 is not a valid one. Where did you get it from? It\u2019s obviously localhost/127.0.0.1\n\nOn 15. Oct 2018, at 05:40, nishaantchauhan notifications@github.com wrote:\ntime=\"2018-10-15T08:57:34Z\" level=info msg=\"Connecting with postgres://:@ory-hydra-example--postgres:5432/hydra?sslmode=disable\"\ntime=\"2018-10-15T08:57:34Z\" level=info msg=\"Connected to SQL!\"\ntime=\"2018-10-15T08:57:34Z\" level=info msg=\"JSON Web Key Set hydra.openid.id-token does not exist yet, generating new key pair...\"\ntime=\"2018-10-15T08:57:35Z\" level=info msg=\"Setting up Prometheus middleware\"\ntime=\"2018-10-15T08:57:35Z\" level=info msg=\"Transmission of telemetry data is enabled, to learn more go to: https://www.ory.sh/docs/guides/latest/telemetry/\"\ntime=\"2018-10-15T08:57:35Z\" level=info msg=\"JSON Web Key Set hydra.https-tls does not exist yet, generating new key pair...\"\ntime=\"2018-10-15T08:57:42Z\" level=info msg=\"Setting up http server on :4445\"\ntime=\"2018-10-15T08:57:42Z\" level=warning msg=\"HTTPS disabled. Never do this in production.\"\ntime=\"2018-10-15T08:57:42Z\" level=info msg=\"Setting up http server on :4444\"\ntime=\"2018-10-15T08:57:42Z\" level=warning msg=\"HTTPS disabled. Never do this in production.\"\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50076\" request=/health/ready\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=910851 method=GET remote=\"172.18.0.1:50076\" request=/health/ready status=200 text_status=OK took=\"910.851\u00b5s\"\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50076\" request=/favicon.ico\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=72942 method=GET remote=\"172.18.0.1:50076\" request=/favicon.ico status=404 text_status=\"Not Found\" took=\"72.942\u00b5s\"\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50076\" request=/favicon.ico\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=84389 method=GET remote=\"172.18.0.1:50076\" request=/favicon.ico status=404 text_status=\"Not Found\" took=\"84.389\u00b5s\"\ntime=\"2018-10-15T08:57:53Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50076\" request=/health/ready\ntime=\"2018-10-15T08:57:53Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=76367 method=GET remote=\"172.18.0.1:50076\" request=/health/ready status=200 text_status=OK took=\"76.367\u00b5s\"\ntime=\"2018-10-15T09:00:40Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50084\" request=/health/ready\ntime=\"2018-10-15T09:00:40Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=159033 method=GET remote=\"172.18.0.1:50084\" request=/health/ready status=200 text_status=OK took=\"159.033\u00b5s\"\ntime=\"2018-10-15T09:01:19Z\" level=info msg=\"started handling request\" method=POST remote=\"172.18.0.4:51434\" request=/clients\ntime=\"2018-10-15T09:01:20Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=157155587 method=POST remote=\"172.18.0.4:51434\" request=/clients status=201 text_status=Created took=157.155587ms\ntime=\"2018-10-15T09:05:01Z\" level=info msg=\"started handling request\" method=POST remote=\"172.18.0.4:52016\" request=/oauth2/token\ntime=\"2018-10-15T09:05:01Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=160591619 method=POST remote=\"172.18.0.4:52016\" request=/oauth2/token status=200 text_status=OK took=160.591619ms\ntime=\"2018-10-15T09:36:03Z\" level=info msg=\"started handling request\" method=POST remote=\"172.18.0.4:51454\" request=/oauth2/introspect\ntime=\"2018-10-15T09:36:04Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=949375859 method=POST remote=\"172.18.0.4:51454\" request=/oauth2/introspect status=200 text_status=OK took=949.375859ms\ntime=\"2018-10-15T09:59:40Z\" level=info msg=\"started handling request\" method=POST remote=\"172.18.0.5:35052\" request=/clients\ntime=\"2018-10-15T09:59:41Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=605183913 method=POST remote=\"172.18.0.5:35052\" request=/clients status=201 text_status=Created took=605.183913ms\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:38848\" request=/\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=15670017 method=GET remote=\"172.18.0.1:38848\" request=/ status=404 text_status=\"Not Found\" took=15.670017ms\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:38848\" request=/favicon.ico\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=92691 method=GET remote=\"172.18.0.1:38848\" request=/favicon.ico status=404 text_status=\"Not Found\" took=\"92.691\u00b5s\"\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:38848\" request=/favicon.ico\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=84591 method=GET remote=\"172.18.0.1:38848\" request=/favicon.ico status=404 text_status=\"Not Found\" took=\"84.591\u00b5s\"\ntime=\"2018-10-15T10:06:35Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:39048\" request=/\ntime=\"2018-10-15T10:06:35Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=82995756 method=GET remote=\"172.18.0.1:39048\" request=/ status=404 text_status=\"Not Found\" took=82.995756ms\ntime=\"2018-10-15T10:11:20Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:39268\" request=/\ntime=\"2018-10-15T10:11:20Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=120031129 method=GET remote=\"172.18.0.1:39268\" request=/ status=404 text_status=\"Not Found\" took=120.031129ms\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. I would like to help but I don\u2019t understand the issue either. Could you show all the commands you\u2019re executing (after docker-compose kill && docker-compose rm) and then point out the one where it\u2019s failing? It\u2019s very difficult to follow and a comprehensive reproduction guide would help. Otherwise I\u2019m unable to help you.\nOn 15. Oct 2018, at 05:52, nishaantchauhan notifications@github.com wrote:\nI don't get it yet what's the issue?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thank you, it would have been even more helpful if you had included the responses of each command, but let's go with what we have :)\n\nSo step 10 & 11 work fine, right? It should look like this:\n```\n$ docker run --rm -it \\\n\n--network hydraguide \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  token client \\\n    --client-id some-consumer \\\n    --client-secret some-secret \\\n    --endpoint http://ory-hydra-example--hydra:4444\n\nQ9j1ONjGPNXT0vcZaGGoAlONkfhQZ5MPXjsMenJfAUs.xL9N9Zol5jZnkqE6jms3O6AggPMv9Uua5hOtNAaw3Qc\nH-O-N-E-Y-P-O-T:hydra aeneas$ docker run --rm -it \\\n\n--network hydraguide \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  token introspect \\\n    --client-id some-consumer \\\n    --client-secret some-secret \\\n    --endpoint http://ory-hydra-example--hydra:4445 \\\nQ9j1ONjGPNXT0vcZaGGoAlONkfhQZ5MPXjsMenJfAUs.xL9N9Zol5jZnkqE6jms3O6AggPMv9Uua5hOtNAaw3Qc\n{\n        \"active\": true,\n        \"client_id\": \"some-consumer\",\n        \"exp\": 1539613570,\n        \"iat\": 1539609970,\n        \"iss\": \"http://127.0.0.1:9000/\",\n        \"sub\": \"some-consumer\",\n        \"token_type\": \"access_token\"\n}\n```\n\nThe token will obviously be different but the output should be similar.\nFor me, all of the above command work just perfectly. After executing the last command I see:\n\nThen I click on http://127.0.0.1:9010 which opens:\n\nAnd after clicking \"Authorize application\" I see:\n\nSo the tutorial works as expected. Is it possible that one of those ports is either blocked by your firewall or another process is running on it? If you run docker ps you should see something like this:\nd2e3ec66e4e8        oryd/hydra-login-consent-node:v1.0.0-beta.8   \"/bin/sh -c 'npm sta\u2026\"   3 minutes ago       Up 3 minutes                    0.0.0.0:9020->3000/tcp                           ory-hydra-example--consent\n2f4feefa976f        oryd/hydra:v1.0.0-beta.8                      \"hydra serve all --d\u2026\"   6 minutes ago       Up 6 minutes                    0.0.0.0:9000->4444/tcp, 0.0.0.0:9001->4445/tcp   ory-hydra-example--hydra\n22e4075da230        postgres:9.6                                  \"docker-entrypoint.s\u2026\"   7 minutes ago       Up 7 minutes                    5432/tcp                                         ory-hydra-example--postgres\nMake sure that all three containers are up and running and don't have errors.. go lint isn't reporting undocumented but exported functions right?. I would feel more comfortable with this if there was a bot ready to use. I think webhooks are being deprecated at GitHub as well (not entirely sure, maybe I misread). added (channel #github on discord). Thank you, see #1057 . Thank you, sir!. This is a tricky one as it relates to issues with the Java SDK, see #1037, #1045. My recommendation is to use just simple the language-native get/post requests to the API as it's pretty straight forward.. I don't think there's a reasonable way (in terms of resources) for us right now to supply SDKs outside of what's generated by swagger right now. Closing as a wontfix.. It would be helpful if you filled out the form, like which version are you running and so on. But in general, docker logs <id> should help or optionally setting OAUTH2_SHARE_ERROR_DEBUG. I'm explicitly asking for the version because we improved error reporting at some point and it seems like you might not be using that version.. Don't, I'm still interested what caused the issue. Reducing dev frustration is something I hold dear, so let's make this better than it is by understanding what went wrong :). I see, that makes sense, thank you for elaborating. I've tracked this as https://github.com/ory/docs/issues/59\n. Thank you!. Please read this: https://www.ory.sh/docs/guides/master/hydra/6-how-to/4-debug\n\nAlso, I don't understand I did the same process in my local system in that it's working but only one time, only one time it will generate the token after that if I try to generate it again then it will give Unable to connect Error why?\n\nBecause the CLI command that initiaties the OAuth2 flow terminates after you ran everything. You have to re-run it.. That CLI command you posted will stop working once you hit the callback URL. You have to re-run it in order to get it working again.\n\nhow can i make our server ip to localhost or this http://myapp.localhost/ type of ip ?\n\nThat works, thing is you didn't use that as the redirect URL but instead redirect_uri=http%3A%2F%2F10.10.0.10%3A9010%2Fcallback which is http://10.10.0.10:9010/callback.\nPlease follow up with people in the chat or forums if you have more questions.. > i am working on server so is there any other option except this http and myapp.localhost.\nNo, it's a security measure.\n\nI am using docker so I don't understand that you have to re run it but i have stopped the container and restart it but also it's not working at all it gives Unable to connect\n\nSeems like you have some trouble with understanding how Docker works here. Ask in the chat for more help on this, I'm sure someone can help.. Yup, that looks definitely like a bug! Can you please add a test for this as well? I think one place to do that is here and another one in this file. Thank you!. Oh sorry, I missed that you added it to the latter file already. Adding it to the first one should assure that the behaviour is correct across all managers.. Because another PR was merged, there's a small conflict now which has to be addressed as well.. Hm, that's interesting, the session ID should always be set. Maybe it hints to another error?. Yeah awesome, good thing the other test was added too :) Thank you!. That's rather unlikely because this whole pipeline is tested to death and has been added since the first 1.0 beta without anyone else noticing the issue you're mentioning. Can you show the commands (e.g. hydra token user, hydra token validate) you're running to reproduce this? I'd also like to know if you're confident that your changes were actually deployed.. I tried to reconstruct this with the context given but as noted before was unable to reproduce this issue. However, you linked a line in the code which sets the session data for already accepted consent requests. If you're starting anew, the proper lines are probably a bit further down.\nI really encourage you to read the documentation, it's there for a reason and all of this stuff is explained there as well. This could have saved both you and me time to figure out what's going on ;)\nIf that's not the cause, most likely sources of something like this happening is:\n\nForgetting to restart the consent/login server after changes made\nMaking changes in consent/login server at the wrong place or misspelling something\nForgetting to rebuild and re-tag the docker image (if running in docker)\nMixing up deployments (e.g. 2 or 3 instances running in docker, different ports, ..\nMixing up the flows (e.g. mistaking authorize code flow with client credentials)\n\nAs the provided context is extremely sparse (no information on how to reliably reproduce what you did) I can not help you any further.. To set additional claims of the access tokens set session.access_token, to set additional claims of the id token (only available if scope openid is granted) set session.id_token. It works, I tested it, it's tested with e2e, unit, integration tests. That's all I can help. If you still have trouble, someone in the chat can help you for sure.. Well, I disagree, it does work as again, I tested it, and there are several unit, e2e, integration tests that also check this behavior. A screencast would indeed be incredibly helpful because with the information given I can not help you any further.. Are you by any chance using JWT for access tokens (export OAUTH2_ACCESS_TOKEN_STRATEGY=jwt)? It appears that the extra claim is not set in the JWT Access Token, only in the introspection response.. Just to be clear, when OAUTH2_ACCESS_TOKEN_STRATEGY=jwt is set, there is a bug. If it is not set, there is no bug. I'm creating a PR to fix the bug where the claim is missing from the JWT Access Token but not the introspection response. . And on another sidenote, using OAUTH2_ACCESS_TOKEN_STRATEGY=jwt is bad and should be avoided, unless you really need it and know what you're doing and why and all the downsides of using it, see also: https://www.ory.sh/docs/guides/master/hydra/6-how-to/3-advanced#json-web-tokens. > the only hurdle i had, the introspect endpoint is on the admin port which i did not map to the public on my reverse proxy...\nThat's a pretty bad practice, the introspect endpoint is not hidden for fun, but because it may expose confidential data to people that are not you or in your company. Do this only if you really know what you're doing.. > but how should a third party app be able to get the subject of that token it requested?\n/userinfo or OpenID Connect. there has been extensive discussion (#904) about this, the short answer is no and for good reason.. Sounds good, I'll probably do that myself because the build pipeline is a bit tricky to test.. Man, I don't know what's up with that. it seems to break randomly but always works locally. In any case, thank you for reporting.. I think I finally figured it out, when hard-reloading the page the text is dark, when browsing there from the \"blog\" section it's not, I'll try to fix it asap. For some reason, netlify chose not to update the CDN any more which caused react to try and render unknown nodes which caused react to not load at all which caused react-highlight not to run which was also caused by react-highlight not functioning with SSR (server-side rendering) which in fact caused the issue, along the not updating part. Anyways, I built a custom build pipeline around circle-ci and created a new netlify site which hopefully fixes all of those issues now. At least the color is back!. We'll be using pure go modules from now on.. Thank you for your hard work!. Perfect, thanks!. I'm sorry, this is not a valid GitHub issue. There is no content body, the question in the title doesn't make sense. If you have a question join the chat: www.ory.sh/chat. Tests are failing because some method signature is broken . That won't help, you need to update the signature of the handler (remove the httprouter.Params I think). Thank you! This failing test is not caused by you :). Interesting, this could be caused by missing indices as well as a missing boundary (LIMIT) when scanning for existing login or consent sessions. There's a PR for setting up open tracing spans that also screen query time which make this much easier to debug (#1105). Do you think it would be possible to run that with jaeger and see what exactly causes the long response time?\nFor a quick remedy, you can try (first back up) and remove all sessions related to that user (USE AT YOUR OWN RISK):\n\nDELETE FROM hydra_oauth2_authentication_request_handled WHERE subject=<the-user-id>\nDELETE FROM hydra_oauth2_authentication_session WHERE subject=<the-user-id>\nDELETE FROM hydra_oauth2_authentication_request WHERE subject=<the-user-id>\n\nThis MAY take some time depending on the size of your DB because subject doesn't have an index.. Yeah, pretty sure this is caused by a missing limit, in particular in this method. The issue here is that we first fetch all the previous consent sessions and then query for each of their IDs. If there are a lot of them, it will query a lot. One remedy would be to sort this by a timestamp and limit it to the last 50 requests or something.. Hm, I'm also a bit confused because the query looks for previous requests where remember=true but skip=false. This should only apply to consent requests where no previous consent was given (e.g. wrong set of permissions/scope) but it seems like that's not the case here. Maybe because the application is using prompt=consent always but remember=true in the consent app?. Typically, in regular scenarios and over the lifetime of a user in a system, this shouldn't be more than a couple of requests (maybe 10, hence no limit). I don't quite remember when I re-authorized a GitHub Application for example. For CI tools like CircleCI that's at most 2 or 3 times over my account lifespan.. In any case, adding a limit here will fix that. If we're looking for the 51st consent request that's not a big issue because the worst that can happen is that the user is shown the authorization screen again. That might be a bit inconvenient but if the issue is as I suggested prompt=consent then the scope will not change, so this will be a very rare/exceptional case and the worst that happens is that the user gives permission again, which is sometimes even considered good security practice.. > I'm not that familiar with the Hydra code and golang itself, but I'm just thinking: FindPreviouslyGrantedConsentRequests is used ultimately for matchScopes. Would it be enough to store the set of ever consented scopes per user rather than the whole history?\nYes, it would however be the equal to setting LIMIT 1 as we would always take the most recent view. IMO that's actually enough.. Well, we do scan for all the consents but IMO it makes more sense (from UX and security) to only take the most recent one, as that is the one the user \"remembers\", right?. https://github.com/ory/hydra/issues/1119#issuecomment-432683668 sums up the reasoning for it, but as I said that's definitely a bug and not what we want here. The other method lists previous consents regardless of the client, so that might be more than 50, depending on how many apps have been granted, which is why a limit here made \"more sense\".. Yup, makes sense. Would probably also make sense to track updates, so created_at, updated_at. LGTM - thanks!. Pushed back as we do have OpenID Connect Discovery which is more or less the same.. This is now partially possible as refresh tokens expire now. It's also important to note that the current flush feature only removes entries from hydra_oauth2_access whereas we also have _code, _refresh, _pkce, _oidc which should also be cleaned up once in a while. I'm moving this to post rc.1 as it will need a bit more tinkering to figure out the right cleanup chain.. Moving this to post-v1 as we need a better understanding of production impacts.. We need to provide a migration that purges old data with broken consistency before applying this. Could be part of the migration, would need a big fat warning before applying it because some clients might lose access.. Right, missed that one too!. > What problem does it solve?\nIf you have a focused authorization server where all clients are created equal (with equal audience, scope) it will be easier to manage it than to e.g. update 100 clients when you're adding a new scope to the mix.\n\nWill there be possibility to enforce wider aud for certain clients?\n\nCan you elaborate?\n\nIn case od scopes you refer to default scopes described in https://tools.ietf.org/html/rfc6749#section-3.3 last paragraph?\n\nYes, the OAuth 2.0 Scope, as it exists today in ORY Hydra. Feel free to PR!. thank you!. You forgot -e in DATABASEURL=\"postgres://hydra:secret@localhost:5432/hydra?sslmode=disable\" $GOPATH/bin/hydra migrate sql, it should be DATABASEURL=\"postgres://hydra:secret@localhost:5432/hydra?sslmode=disable\" $GOPATH/bin/hydra migrate sql -e but obviously not panic.. Not sure what this was about, but all WHERE clauses access columns which are indexed. Closing.. I suppose this happened with beta.9?. hydra version. I see, is that not the latest version?. Ok, that's definitely an older version because that was a bug in the container build system which was fixed at least a couple of months ago. I think docker ps should show you all the running containers and the name+tag (e.g. oryd/hydra:v0.10.0)\nI also think that I can recall an error in that particular place of the server which has been fixed since then. I'm closing this because I'm pretty sure it has been fixed but please keep the details coming!. Nevermind, let's reopen it and find the issue. Any bit of info helps!. Ok, closing this again but feel free to reopen any time you encounter this.. As noted in the issue templates, ask questions like these in the chat or in the forums.. Security model is documented here: https://www.ory.sh/docs/guides/master/hydra/2-environment/1-securing-ory-hydra.html\nThe issue templates and contribution guidelines are there for a reason. Questions belong in the forum or the chat.. Closing in favor of #834 . Could you please add tests for this, otherwise regressions may occur.. ping :). > consent: Properly propagate acr value \n. Same here, this is auto-generated. If something has to be fixed it must be done at the place where the swagger was defined.. Thank you! However, the code is auto-generated so this will not have an effect. Instead, you need to update the struct (in the right source file) that is the source of the swagger definition.. I think the idea here was to educate people about the consent flow and user interaction model, but that doesn't really happen - all it does is make this flow more confusing.. Which database are you using, MySQL or PostgreSQL? It's possible that the row check isn't working properly.. Interesting. Are you sure this happens every time? The code is written in a way that would only throw a 404 if no session exists. It might make sense to always return 200/201 here though.. However, it seems like there is no proper test for this - putting it on the list for investigation.. @someone1 this will impact you. Make sure to remove tokens that belong to clients when deleting clients.. The e2e tests are doing some consistency checks, but very simple ones.. It has tests, but the complexity of setting it up is...not light. That's why it ended up in binary e2e tests because the set up is much faster and easier there.. Sounds good, let's get this landed for rc.1!. Closed by #1182. ty!. Fix: https://github.com/ory/x/pull/17. Make sure the user you\u2019re executing the migration with has permission to create, alter, delete data, tables, indices\n\nOn 22. Nov 2018, at 09:41, David Fern\u00e1ndez Gonz\u00e1lez notifications@github.com wrote:\nRunning rc2 miggrate database we received this:\nApplying jwk SQL migrations...\nApplied 1 jwk SQL migrations.\nApplying client SQL migrations...\nApplied 3 client SQL migrations.\nApplying consent SQL migrations...\nAn error occurred while running the migrations: could not apply consent SQL migrations: Could not migrate sql schema, applied 3 migrations: pq: se ha denegado el permiso para cambiar la opci\u00f3n \u00absession_replication_role\u00bb handling 7\n(Last part translated: permission denied to change option \"session_replication_role\")\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub, or mute the thread.\n. https://github.com/ory/hydra/pull/1226. Nice catch, that should be oldSecret and set to old secret in handler_migrate.go. ty. Thank you! There was another PR solving the same issue which I already merged :) closing. Any particular reason for the argument re-shuffeling?. ty!. ty!. ty!. That is deliberate as goimport and other tools accidentally remove this line otherwise!. Thank you!. Oh yeah, super nice!. Thank you!. Thank you, but that's not the right way to approach #846 . There isn't really a reason why docker itself should wait for hydra to start, the docker command might not even execute the serve command or run on a different port. This has to be done by customizing the RoundTripper of the HTTP Client in the Go code.\n\nThank you for putting effort into this!. https://github.com/ory/hydra/blob/master/composer.json :). Awesome!. Thank you!. That's how we roll here :). Would you mind creating a PR?. Could you include the whole table row? Things like \"remember\" and \"remember_for\" are important here!. Oh and could you please include logs :). Another question @pixelblend , which DB are you using?. Cool, that is really helpful. Could you do me another favor and give the output of:\nSELECT h.*, r.* FROM\n    hydra_oauth2_consent_request_handled as h\nJOIN\n    hydra_oauth2_consent_request as r ON (h.challenge = r.challenge)\nWHERE\nr.subject=\"<YOUR SUBJECT ID GOES HERE>\"\nand print the (redacted) output here?. Ok so remember is set to false here, so the consent request has actually not been remembered. I realize that this is misleading as the app still has access. If it were set to true, you would see the values. I'll get onto that with the next release.. In the meanwhile, set remember to true and you will see the values, which should help you build the UI while the issue is being fixed.. Just me being stupid, sorry - I forgot about you. Feel free to revert and add a note/comment to remind me not to mess it up again :). Sounds good, and sorry again :). Resolved by #1212. Make sure that the collation of your database is utf8: https://dev.mysql.com/doc/refman/8.0/en/charset-database.html. Closing because I think this is resolved. Let me know if you have further questions.. Use a different user for migrations?. That's by the way one of the reasons why migrations are a separate command, so we can modify schemas with different privileges than the normal process needs.. > One-off admin processes should be run in an identical environment as the regular long-running processes of the app. They run against a release, using the same codebase and config.\nRefers to commands such as \"hydra clients create\", migrations are a separate things that need a different set of privileges. Would you mind updating the docs there?. The environment section would be good for that (in hydra). Sorry, I missed part of the post:\n\nI'm not sure exactly why session_replication_role is used, is it just for performance reasons during the migration or is it truly required?\n\nYes, performance reasons.\n\nWhat about using ALTER TABLE ... DISABLE/ENABLE TRIGGER ALL instead?\n\nI fear that modifying migrations retroactively is not possible/a bad idea unless the outcome is 1:1 100% of the time for all versions of the software and database under all circumstances.. > I would tend to think that the performance of verifying the foreign keys doesn't matter too much for a one-time migration. But of course you'll have more information than me about that \ud83d\ude04\nThat would be nice, but unfortunately it can lock your database for several hours depending on the size.. Ok damn, I didn't know that. I'll try to come up with a fix.. Ok, so the reason is really only session_repliaction_role, right? I think it should be possible to disable that retroactively in the SQL migrations. If you confirm that, I'll merge a patch for this today.. And by the way, sorry for the inconvenience and my initial stubbornness on this issue!. https://github.com/ory/hydra/pull/1226. Hey, thank you for the PR. Unfortunately, this part is auto-generated using swagger-codegen, so everytime that runs your changes will be lost. It's not possible to fix that at the moment, unfortunately.. There seem to be several things mixed here:\n\nThe /oauth2/auth endpoint does not have CORS, it's an endpoint viewed by the browser/user-agent and not by a programmatic client (e.g. browser JS)\nThe /oauth2/fallbacks/error endpoints do not serve CORS, they are exemplary/default/fallback endpoints that show certain messages when the developer has not configured them.\nThe client auth-code-client seems to not be properly registered as the error message shows error_hint=The+requested+OAuth+2.0+Client+does+not+exist.. This usually happens when you're running multiple instances of hydra locally (e.g. one in docker, one locally, multiple in docker, ...).\n\nWhile your original post showed that you set allowed_cors_origins, that's not the case in the above reproduction steps.. For clarification, only endpoint /oauth2/token and /oauth2/revoke and wellknown can be consumed as an API, which makes it possible for them to be CORS-able.. I think what you're looking for is OIDC Silent Refresh (or similar) which is typically done using a (hidden) iframe (example). The /oauth2/auth endpoint is not to be touched by non-user clients.. No problem, to the best of my knowledge, it is possible to configure fetch in such a way that ignores CORS errors (it will return a response code of 0). With a combination of redirecting to an endpoint that satisfies your CORS requirements for programmatic clients interacting with the OAuth2 Authorization endpoint you might be able to get something done, no guarantees though.\nThe other, more obvious and easier, solution is to add Nginx with forced CORS for /oauth2/auth in front of Hydra.\n\nAnyway I can certainly accept if you don't want to change the current state. In that case you may want to close this issue as \"wontfix\" or whatever seems appropriate (\"not a bug\", maybe?) and I'll have to think up a workaround for us. Many thanks again for your prompt feedback.\n\nClosing as \"intentional behaviour\". :). By the way, reason for not adding CORS here is because developers have misconceptions about that endpoint every now and then. Your use case is exotic enough to weigh it as \"intentional behaviour\" as opposed to fixing a (small) part of the code base, as it will prevent inexperienced devs from accidentally misusing the endpoint (which happens more regularly)!. Please add comments to the exported functions so we don't go back to making them unexported :). Thank you!. Closed by https://github.com/ory/hydra/pull/1214. While it looks like a reasonable approach, there are so many different grant extensions to the existing OAuth2 protocol in draft (or self-defined by e.g. Google) that we simply lack the resources to implement and maintain them, which is why drafts are generally not being implemented.\nIn my personal view, I'm not a fan of using OAuth2, a framework that was initiated to give 3rd party developers a way to access personal information, for things like workload/service auth. I think systems like SPIFFE take a much more sane approach to this. We are actually working with Scytale, co-founded by Evan Gilman (he wrote the Book Zero Trust Networks), to deliver a way to solve workload auth in the context of OAuth2. But this will (obviously) take a while.\nClosing this, for now, as a wontfix/wontdo. Feel free to keep the conversation going though.. The client credentials grant is fully supported and you can request any scopes you want, as long as they're whitelisted.. The keycloak document shows very clearly that you can not just choose the subject (for good reasons). And it's also not very helpful to just dump a few links in here and say: yo please look at this and implement it. Either you put out a proper feature request (the templates aren't there for fun by the way) or there is no incentive to look at what you're trying to solve and even less so considering to implement it.. I still don't get it, the Keycloak documentation says veryl clearly:\n\nEach OIDC client has a built-in service account which allows it to obtain an access token. This is covered in the OAuth 2.0 specifiation under Client Credentials Grant. To use this feature you must set the Access Type of your client to confidential. When you do this, the Service Accounts Enabled switch will appear. You need to turn on this switch. Also make sure that you have configured your client credentials.\n\n```\n    POST /auth/realms/demo/protocol/openid-connect/token\n    Authorization: Basic cHJvZHVjdC1zYS1jbGllbnQ6cGFzc3dvcmQ=\n    Content-Type: application/x-www-form-urlencoded\ngrant_type=client_credentials\n\n```\nThis is 100% supported in ORY Hydra. Please provide a flow example or the appropriate IETF RFC. We're also generally not implementing non-standardized flows or specifications which are in draft status.. Yeah, as I've said already, this is possible today with ORY Hydra. Just create an OAuth2 Client with a client ID of your choosing (that will be the subject) and allow that OAuth2 Client to request the permissions/OAuth2 Scope you want it to be able to.. What do you mean with claims? Please explain and give an example.. You are mixing concepts that do not match. An OpenID Connect ID Token (what you linked with oidc core) is not an ID Token, and not the flow Keycloak implements. A client credentials flow is never able to request an ID Token. Please read the section you linked in the Keycloak document with attention.\nJWTs are not only a method of transporting information in a stateless manner, it has nothing to do with OAuth2 itself.\nGoogle implements a proprietary (they invented it, and it is not standardised afaik) flow which allows you to work with their platform in their (proprietary) way. This is not something that will be implemented in this project.. I see, that makes it clearer. I don't think that we'll add this feature in the foreseeable future though as the concept of Service Accounts may or may not be part of the overall identity model you have in your business. What hydra does do is implement the RFCs according to specs and none of the specs have the concept of a Service Account.\nHow you retrieve metadata about a certain session is really up to you. Hydra offers a way to specify this metadata for flows that are not client_credentials grants and put that in an access/id token, but it does not have a conceptual model of an OAuth2 Client being a substitute for an identity. You can obviously always use the sub field of the access token to pull additional data for that subject from a custom datastore, but I do not see that as the responsibilty of Hydra.\nID Tokens in general are for real end-users, not for pure programmatic clients. While some platforms might choose to implement this as an enterprisy feature on top of the original spec, that's not something I want to do here. One reason being complexity, and the other being that I think it's an opinionated decision to allow that.\nI'm certainly sure that you can implement this type of behavior with Hydra with some custom code - so it is possible, but I don't think this belongs into the core product.. Dupe: #1221. Sorry, yes!. Dupe #1209. The correct syntax would be in the form of: mysql://root:secret@tcp(mysqld:3306)/mysql?parseTime=true. That's a bash/shell error, you need to escape the string.... Thank you!. That's a nice addition! Please add some docs so people are able to find out about this. Good places for that would be:\n\nhere\nhere (add a new section) or here (also new section). Thank you!. > Sidecar pattern produces requests originating from localhost & its subnet \u2014 would it be safe to assume that localhost <-> localhost communications deep inside the cluster with an optional addition of mutual-TLS between cluster components are as secure as publicly available https?\n\nYes, it's as secure. The question I have if this is an issue with istio or hydra.. The point of being super strict about this is that HTTP is not a secure protocol. The security model OAuth2 is built upon is TLS, it does not have any other type of security mechanism - in contrast to OAuth (1.0) which used e.g. HMAC based message authentication. Giving people slack on this is an explicitly bad concept for this product. I know that TLS is perceived as being hard (it's not that difficult imo), but so is OAuth2, and systems design in general. I'm not sure how a compromise would/should look like here but I'm - as always - open for suggestions.\nRegarding your question, of course is mTLS more secure than public TLS because both parties are authenticated. If mTLS is activated and used for HTTP communication, the proxy should set the right forwarded-proto, as do proxies such as ngnix, kong, aws api gateway, .... Thanks!. Thank you, can you please create a PR?. Without more context and without technical details how to implement this, and given the very real and complex nature of SQL migrations, this is not something that can be considered by this project. Feel free to provide more details and concrete proposals despite closure of this as a nofix.. That's an interesting concept! However, it looks like it would be very challenging to set up a proper test plan and make sure that everything runs smoothly with every release. I fear that we don't have the resources / incentives to support and maintain this. Sorry!. I don\u2019t know what you\u2019re talking about, all recent tags are literally 5MB, please check the docker hub info properly.\nAnd next time follow community rules regarding issue creation. No context, no info, no version, no due dilligence, no proposal how to fox this. That\u2019s not how participating in OSS looks like.. Closed in favor of #1243. Did you upgrade recently? Maybe missed SQL migrations?\n\nOn 16. Dec 2018, at 23:22, es-lab notifications@github.com wrote:\nDescribe the bug\nOAuth flow breaks after a while. Currently unknown how to reproduce. But for some reason it breaks for a user & client specifically.\nWhat happens visually is:\nthe client requests authorization\nhydra redirects on login provider\nlogin provider gets skip true and accepts login request and redirect on redirectTo value received from hydra\non accessing the link to hydra it gets the error *sql: Scan error on column index 13, name \"login_challenge\": unsupported Scan, storing driver.Value type into type string and redirects to client with error The error is unrecognizable\nTo Reproduce\nStill do not know.\nExpected behavior\nTo not break.\nScreenshots\nLogs of hydra of a complete OAuth flow:\ntime=\"2018-12-15T10:14:48Z\" level=info msg=\"started handling request\" method=GET remote=remote_ip_here request=\"/oauth2/auth?client_id=client_id_here&scope=offline&response_type=code&redirect_uri=https://client_host_here/oauth/redirect&state=23b00222-ef52-40df-aa07-4dc19330ebe0&ui_locales=en\"\ntime=\"2018-12-15T10:14:48Z\" level=info msg=\"completed handling request\" measure#https://hydra_host_here/.latency=5613845 method=GET remote=remote_ip_here request=\"/oauth2/auth?client_id=client_id_here&scope=offline&response_type=code&redirect_uri=https://client_host_here/oauth/redirect&state=23b00222-ef52-40df-aa07-4dc19330ebe0&ui_locales=en\" \nstatus=302 text_status=Found took=5.613845ms\ntime=\"2018-12-15T10:14:48Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.13:43830\" request=/oauth2/auth/requests/login/cf015261732444469bc3670643235896\ntime=\"2018-12-15T10:14:48Z\" level=info msg=\"completed handling request\" measure#https://hydra_host_here/.latency=4867655 method=GET remote=\"172.18.0.13:43830\" request=/oauth2/auth/requests/login/cf015261732444469bc3670643235896 status=200 text_status=OK took=4.867655ms\ntime=\"2018-12-15T10:15:03Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.13:43830\" request=/oauth2/auth/requests/login/cf015261732444469bc3670643235896\ntime=\"2018-12-15T10:15:03Z\" level=info msg=\"completed handling request\" measure#https://hydra_host_here/.latency=4808050 method=GET remote=\"172.18.0.13:43830\" request=/oauth2/auth/requests/login/cf015261732444469bc3670643235896 status=200 text_status=OK took=4.80805ms\ntime=\"2018-12-15T10:15:03Z\" level=info msg=\"started handling request\" method=PUT remote=\"172.18.0.13:43830\" request=/oauth2/auth/requests/login/cf015261732444469bc3670643235896/accept\ntime=\"2018-12-15T10:15:03Z\" level=info msg=\"completed handling request\" measure#https://hydra_host_here/.latency=6392958 method=PUT remote=\"172.18.0.13:43830\" request=/oauth2/auth/requests/login/cf015261732444469bc3670643235896/accept status=200 text_status=OK took=6.392958ms\ntime=\"2018-12-15T10:15:03Z\" level=info msg=\"started handling request\" method=GET remote=remote_ip_here request=\"/oauth2/auth?client_id=client_id_here&login_verifier=797c33b6f64b452facead47aca386127&redirect_uri=https%3A%2F%2Fclient_host_here%2Foauth%2Fredirect&response_type=code&scope=offline&state=23b00222-ef52-40df-aa07-4dc19330ebe0&ui_locales=en\"\ntime=\"2018-12-15T10:15:03Z\" level=error msg=\"An error occurred\" error=\"sql: Scan error on column index 13, name \\\"login_challenge\\\": unsupported Scan, storing driver.Value type  into type *string\"\ntime=\"2018-12-15T10:15:03Z\" level=info msg=\"completed handling request\" measure#https://hydra_host_here/.latency=14863933 method=GET remote=remote_ip_here request=\"/oauth2/auth?client_id=client_id_here&login_verifier=797c33b6f64b452facead47aca386127&redirect_uri=https%3A%2F%2Fclient_host_here%2Foauth%2Fredirect&response_type=code&scope=offline&state=23b00222-ef52-40df-aa07-4dc19330ebe0&ui_locales=en\" status=302 text_status=Found took=14.863933ms\nVersion:\nEnvironment: Docker Compose\nVersion oryd/hydra:v1.0.0-rc.5_oryOS.10 (happend on oryd/hydra:v1.0.0-rc.2_oryOS.9 too)\nAccess Token type: jwt\nAdditional context\nThought that the problem might be that I did not handled correctly 409 conflicts of login challenges, but even after proper logging and errors handling I still get the issue.\nTried to delete the data from tables with tokens and all the others excluding clients and migrations tables, everything started working properly, and then again it did break for some user/client. For the same user but other clients it still works.\nTo mention that the clients are first party apps that do not request audiences and scopes (it does request offline scope though), the consent logic authorizes the client with all its pre-defined scopes and audiences. May this be the problem? Do I need to allow to the client just its requested scopes and audiences?\nClient details\n{\n  \"audience\": [\n      \"some_audience_here\"\n  ],\n  \"client_id\": \"client_id_here\",\n  \"grant_types\": [\n      \"authorization_code\",\n      \"refresh_token\"\n  ],\n  \"jwks\": {},\n  \"redirect_uris\": [\n      \"https://client_host_here/oauth/redirect\",\n      \"http://another_client_host_here/oauth/redirect\"\n  ],\n  \"response_types\": [\n      \"code\"\n  ],\n  \"scope\": \"offline oauth_auto_consent\",\n  \"subject_type\": \"public\",\n  \"token_endpoint_auth_method\": \"none\",\n  \"userinfo_signed_response_alg\": \"none\"\n}\noauth_auto_consent is used by the consent provider to check if it should skip consent and allow automatically for some clients. In this case it allows automatically for this clients. But the same happens for other clients and it works perfectly.\nTHIS NEEDS A SOLUTION ASAP\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. What database are you using? Exact version please.\n\nThe JWT strategy is, as noted, in beta and not the primary/recommended way, but it should obviously not break stuff.\nThe error is proper weird because  is actually assignable to string. That\u2019s the whole point of nil \ud83e\udd14\n\nOn 17. Dec 2018, at 07:43, es-lab notifications@github.com wrote:\n@aeneasr The last 3 weeks it was just integration of hydra in an existing system. I started with version oryd/hydra:v1.0.0-rc.2_oryOS.9 initially, sql migration did ran successfully from the first time.\nThen came a lot of clients create/update/delete/recreate because of development/prototyping of different use-cases.\nThere was also a change to the Access Token type from the time I started. Could this change the way migrations run, and that now that it's jwt it expects some different schema/indexes?\nAlso, I still can not reproduce this on my localhost, the current issues happens on a staging (https) environment.\nI did the upgrade to oryd/hydra:v1.0.0-rc.5_oryOS.10 3 days ago, just though it may solve the issue, but it did not. SQL migrations did run successfully though.\nWhat I did not try to do is a clean install of hydra. I will try this one and hope to come back with more useful info.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thank you for reproducing this! I\u2019ll push & publish a fix tomorrow\nOn 17. Dec 2018, at 18:36, es-lab notifications@github.com wrote:\n@aeneasr I think there are some other ways to get to the issue, but I've found these way to get to it consistently, I've also noticed that this does not happen if in the database already exists a consent for the user/client, it somehow does not query the one with the NULL login_challenge and it does not fail.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. This should work now, could you also check to make sure? :). Currently unreleased, on master, if you need help with that LMK. Yes, this will be rc.6, I won't be able to release it today as there are a couple more things that need to be solved, but it should be out by latest end of week.. Admin URL should be 4445\nOn 20. Dec 2018, at 00:33, sumeet jain notifications@github.com wrote:\nDescribe the bug\nWhen running\nhydra clients create\ni get an error\nCommand failed because error occurred: invalid character 'p' after top-level value\nTo Reproduce\nSteps to reproduce the behavior:\nDownload hydra binary for darwin-amd64 and version:1.0.0-rc.5+oryOS.10\nSet environment variable 'HYDRA_ADMIN_URL' to http://localhost:4444/\nRun hydra client create after making the binary executable\nSee error described above\nExpected behavior\nShould receive information about necessary flags required to run the command instead of the error.\nScreenshots\nVersion:\nEnvironment: macOS High Sierra\nVersion: 10.13.6\nAdditional context\nSurprisingly, hydra clients delete and hydra clients get work as expected.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. You linked to the oathkeeper docs and did not provide a way to reproduce the issue. But my guess is that you're still using hydra token user to perform the oauth2 example:\n\n$ docker run --rm -it \\\n  --network hydraguide \\\n  -p 9010:9010 \\\n  oryd/hydra:v1.0.0-rc.4_oryOS.9 \\\n  token user --skip-tls-verify \\\n    --port 9010 \\\n    --auth-url https://localhost:9000/oauth2/auth \\\n    --token-url https://ory-hydra-example--hydra:4444/oauth2/token \\\n    --client-id facebook-photo-backup \\\n    --client-secret some-secret \\\n    --scope openid,offline,photos.read\nIf you'd execute the help command\n$ docker run --rm -it \\\n  --network hydraguide \\\n  -p 9010:9010 \\\n  oryd/hydra:v1.0.0-rc.4_oryOS.9 \\\n  token user --help \\\nYou would see that there is a flag called --redirect which allows you to set the redirect url.. read tcp 10.0.155.158:41540->10.0.155.7:5432: read: connection reset by peer indicates a database connectivity issue, should/is not related to hydra internals.. Have you seen https://www.ory.sh/docs/hydra/dependencies-environment#sql. Yeah sounds like an issue related to that. Try tweaking the parameters, it should eventually work. Other than that I can't be of much more help but feel free to come back to this issue if you can't figure it out - closing. \ud83d\udc4d . thanks!. Could you explain in a few sentences what problem this solves?. That makes sense! It was intentional at first to not allow that but it makes sense. Thank you :). Don't worry about it :). Yup, they are indeed introspectable and you'll get a type back which says if it's a refresh or access token! Feel free to create a PR to fix this :). Thank you!. This will be something else, the endpoint is working fine. Please provide reproducible steps.. Best would be to have fully reproducible steps, the strategy shouldn't really make a difference but it's possible that there is an issue with JWT.. Ok, that's not unusual - OAuth2 has a steep learning curve. So this here can be closed, yes?. Use Docker or rebind the environment variable. Please check the Heroku documentation for more specific help.. Again, just rebind the environment variables. There is plenty of information on how to do that but here's for a starter:\n```\nFROM oryd/hydra:vX.Y.Z\nCMD export PUBLIC_PORT=$PORT; hydra serve public\u00b4\n```\nSomething similar will probably work with buildpack-based builds too.. Thanks! Tracked as enhancement. The error is handled correctly though with a 409. What problem are you facing when the error is returned? Is it that you need to check for the 409 error state explicitly?. Yeah that makes sense, tracking. > This occurs when consent remember is set to true and consent has been granted.\nA second new request will have the consent information with skiptrue.\nI was unable to accept the consent and redirect the user.\nThis is because you've probably forgot to set remember to false when skip is true. This was intended as a safeguard but has lead to issues and will be fixed soon ( #1165 ).. Whoops, thank you!. Thank you!. This is unfortunately nothing that can be merged. The SDK code is auto-generated and will be overwritten by the next run. Also, HTTP codes >= 300 < 400 are not error codes and should not be treated as such.. Thank you!. Sorry for the late reply. Generally that's a possibility - one thing to keep in mind with : is that they are special characters in URLs and have to be encoded properly. Is there a specific reason why you want that delimiter instead of the more common . notation?. You're setting the access token audience but expect the id token audience to be different - here lies the problem. The ID Token audience is usually only the client id. The access token audience might be different because you may want the access token to be applicable only for certain resource servers.. Those are conceptually different:\n\nThe access token audience targets the resource servers (your internal stuff / first party)\nThe id token audience targets the relying party (the third party / client / external developer)\n\nTherefore it doesn't make sense for the two to be equal.. The ID token is used to authenticate at the client side, not the first party resource server (secrets). If you want to access a resource at secrets simply use an access token.. Not a bug, wget 127.0.0.1:4445/clients is missing the X-Forwarded-Proto: https header.. Closing, feel free to reopen/comment if I'm mistaken.. revocation_endpoint is not defined per spec which is why it isn't included. Are you, by any chance, confusing this with this draft for which we have an issue already?. Ok, let's include it. How's up for a PR?. Thank you! That's really unfortunate, 0.0k stars :( :D\nThis can in fact happen when you're loading the site a couple of times or when the connectivity is bad. We're fetching this info directly from GitHub. It might make sense to have a default that isn't 0 there though :)\nTracked this internally - closing :). Merged!. Thank you!. Resolved by #1273 - thank you!. API endpoints are documented here: https://www.ory.sh/docs/hydra/sdk/api. /oauth2/token is not an endpoint where you create clients. If you want to interact with OAuth2 I suggest to use a library like simple-oauth2 (or similar for other languages). You can also find more debug info in the hydra logs. If the error says The POST body can not be empty. you're probably sending some unsupported payload (e.g. xml, json) which indicates that you're not using an appropriate library.. That's unfortunate! I also just noticed that the documentation is only showing the Accept/response header but not the request type. Reopening to track and fix this.\nHowever, a proxy that's doing such a conversion should probably not do that per default. I don't think that any documentation on this can help you debug such a network chain when one thing isn't doing what it's supposed to be doing. That doesn't imply that the docs shouldn't be improved though here!\n. Hm, I just checked, the swagger definition properly defines the consume/produce part:\n```\n// swagger:route POST /oauth2/token public oauthToken\n//\n// The OAuth 2.0 token endpoint\n//\n// This endpoint is not documented here because you should never use your own implementation to perform OAuth2 flows.\n// OAuth2 is a very popular protocol and a library for your programming language will exists.\n//\n// To learn more about this flow please refer to the specification: https://tools.ietf.org/html/rfc6749\n//\n//     Consumes:\n//     - application/x-www-form-urlencoded\n//\n//     Produces:\n//     - application/json\n//\n//     Schemes: http, https\n//\n//     Security:\n//       basic:\n//       oauth2:\n//\n//     Responses:\n//       200: oauthTokenResponse\n//       401: genericError\n//       500: genericError\n```\nWhich is being translated to (swagger json):\n\"/oauth2/token\": {\n      \"post\": {\n        \"security\": [\n          {\n            \"basic\": []\n          },\n          {\n            \"oauth2\": []\n          }\n        ],\n        \"description\": \"This endpoint is not documented here because you should never use your own implementation to perform OAuth2 flows.\\nOAuth2 is a very popular protocol and a library for your programming language will exists.\\n\\nTo learn more about this flow please refer to the specification: https://tools.ietf.org/html/rfc6749\",\n        \"consumes\": [\n          \"application/x-www-form-urlencoded\"\n        ],\n        \"produces\": [\n          \"application/json\"\n        ],\n        \"schemes\": [\n          \"http\",\n          \"https\"\n        ],\n        \"tags\": [\n          \"public\"\n        ],\nSo this might be an issue with the documentation template.. This seems to be an upstream bug: https://github.com/Mermade/widdershins/issues/216. Please read the issue template and ask your question in the forum or the chat. Please note that Hydra won't teach you oauth2 and that it is assumed that you have knowledge about oauth2. You can find resources on oauth2 in the docs or by asking in the chat. Thank you.. It's literally in the first sentence of your issue.... If you look in the clients table, does it have mailservice? Can you also check your database logs for e.g. dropped connections? What does your DB config string look like (filter out credentials).. Strange - do you have features like tracing enabled? Maybe try playing around with different configuration settings (e.g. setting max lifetime): https://www.ory.sh/docs/hydra/dependencies-environment#configuration. If you run SELECT * FROM hydra_clients WHERE client_id=mailservice a bunch of times, does that return empty rows?. Also, is the network dislocated? So e.g. PostgreSQL running on AWS and you're running hydra locally?. Yeah, that might be really useful!. Any update on this @alien0matic ?. No worries!. I'm closing this for the time being as this is not reproducible in other environments and it seems to no longer be relevant. Thank you, Michael!. It should be possible to filter this out in your log system, as you would do with any inspection into a specific trace. The router is emitting to info for all routes and it's actually not easily possible to have different routes with different log levels. It's also not very clear where this would be documented and could be quite frustrating to debug e.g. loadbalancers.. Thank you!. Seems like you're confusing some of the requests and doing AJAX requests where the browser should be used. Feel free to ask in the chat or community forums for more guidance :). You're calling the oauth2 auth URL from ajax (thus cors), that's not how OAuth2 works. Check the docs: https://www.ory.sh/docs/hydra/oauth2#the-flow-from-a-user-s-point-of-view\nPlease note that issues are not intended general advice or support but only on technical issues in the project, not the depending implementation.. It\u2019s not open source but you can buy a license allowing you to run it locally.\n\nOn 10. Feb 2019, at 07:34, Sze Ka Wai Raymond notifications@github.com wrote:\nIs your feature request related to a problem? Please describe.\nCould I deploy the security console myself like running a docker container instance? I didn't find any source on github.\nDescribe the solution you'd like\nDescribe alternatives you've considered\nAdditional context\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Why wouldn't you just set HTTPS_ALLOW_TERMINATION_FROM to the IP of proxy?. X-Forwarded-For is not being used correctly here. This header is reserved for the IP of the actual client (browser, mobile app, ...), not the proxy chain in your network stack.. Sorry, my bad, I overlooked that you're splitting it. In that case, the header is being used correctly and I think this PR makes sense!. Awesome! Thank you :). Thank you! Feel free to PR :). If you have the tokens, you can store them in the session storage. How you implement that is totally up to you. This doesn't have to do anything with hydra itself (it's not a bug, not a feature request) -> closing.. Seems like you're using hydra token user as a substitute for your own application. This command is just an example. As noted in the docs, there are plenty of software libraries around that help you with oauth2: https://oauth.net/code/. Not really, there's a lot of context missing. Make sure that:\n\n\nYour client is allowed to use the redirect url http://localhost:4200\nThe oauth2 authorize url contains the right redirect url.\n\nBut again, this is all standard oauth2 stuff. Use a library for these things and most of your problems will go away.. You need to send a POST request with a body, see the docs: https://www.ory.sh/docs/hydra/sdk/api#flush-expired-oauth2-access-tokens. I tried to delete the :latest tag before but it's just not possible in docker. Might have to re-add :latest to the CI release pipeline to fix this.. Could you rebase on master? Seems like some issue with go modules.. Thank you!. Thank you :). :) This may happen when you hit the GitHub API request limits (i.e. reloading the front page a couple of times). We might have to add some caching in there.... This should be fixed with the next website update!. Ok so the idea would be to add this somewhere around herre. One difficulty is that the mysql driver doesn't handle this automatically so we would have to add a hardcoded check here against mysql to make this work which kinda sucks (the postgresdriver supports setting the CA via a flag). Any ideas how to solve this in a better way?. Ah my description wasn't very clear, that's definitely the idea here, have something like ?tlsCAPath or whatever (we can mimic what postgres is doing).. > The only other idea I have how to make it better without hardcoded check here against mysql is to file another feature request on mysql driver to support it tough DNS the way postgres driver does it.\nI think that would be the most reasonable path as this should really be part of the driver spec IMO and it would benefit the community using the upstream dependency (mysql driver) the most.. Awesome!. Please use the issue form, they are there for a reason. Without info on which version, database and all other relevant pieces this will be closed as invalid.. Also, please include some tracing information. You can usually enable tracing by setting the environment variable LOG_LEVEL=debug. Can you include more log info please?. Keep in mind that the more info you give, the easier it is to solve your issue. Redacting stuff doesn't help and there's also no sensible reason why it should be redacted as sensitive information is kept out of logs.. Please also include your configuration, here you can obviously redact info like system secrets etc.. Thank you for providing more info, that is really helpful. It doesn't seem like you have tracing enabled which might have caused this otherwise. Are you seeing any issues in the PostgreSQL logs?\nAlso could you please provide logs -+10 lines around the error?\nIncluding @aaslamin in the convo: This seems to be related to passing down the context from *http.Request. Any ideas what could cause this?. Ok, it seems like this request is taking a long time to execute - over 4 seconds! That's probably why it's being canceled. This could be an issue with your PostgreSQL database, missing indices or something else. Could you check if there are slow queries? You can also set up tracing in Hydra to debug this: https://www.ory.sh/docs/hydra/debugging#distributed-tracing. BCrypt is supposed to take some time but obviously 3 seconds is too much. Maybe beef up the VM you're running hydra on? But it seems in general that the system is quite laggish - 1.5s for a SQL call is way too much.\nI'm closing this issue because we know now that it is caused by a timeout as opposed to a bug. Feel free to post here though in case you have new findings.. I see! It's probably still a good idea to beef up the system a bit in case you'll end up with multiple calls to that endpoint :). What does git rev-parse HEAD say?. Your master is way behind, please try with a recent version.... Could you provide appropriate CURL commands for easier debugging? Also, does this affect only the response of token introspection?. Yeah that seems to be the cause here! Anyone up for a PR?. I don't get why crypto is failing all the time. You can fix this with go mod tidy though!. Alternatively go get -u  golang.org/x/crypto with go modules enabled.. Perfect, last thing would be to add a test so this doesn't break in a future patch by accident :). Thank you!. Probably a network issue! Nothing we can help with right now. But you can always use the prebuilt images from docker directly.. You could try go mod tidy before running docker-compose up --build -d. Also, you're checking out an old version, maybe try the most recent one: git checkout tags/v1.0.0-rc.6+oryOS.10 :). The failing test can be fixed with go get -u golang.org/x/crypto. Why is golang.org/x/... so f* annoying. Use go mod tidy to update... :). > For this behavioural change we will want tests to avoid future regressions.\n\nSome test scenarios:\n\nIntrospecting a refresh token that have been configured to never expire\nIntrospecting a refresh token that has been configured to expire (use a different expiry than that of the access token)\nIntrospecting an access token\nIntrospecting an authorization code?\nIntrospecting an id_token?\n\n\nOnly access and refresh tokens are relevant :) All the other cases are super valid though!. > > Why is golang.org/x/... so f* annoying. Use go mod tidy to update... :)\n\nBut I did not make any new dependencies, did not change the go.mod and go.sum. Maybe I do not understand something, could you explain to me?\n\nI would love to but I can't. For some reason golang.org/xis special and breaks constantly. If you find out why I'd invite you for a night out or something because it's so f* annoying.. Hi there! Sorry for the silence here - can you rebase on master? The broken test will go away by magic then. :). Nice, thanks! :). Please rebase onto master then the annoying go modules error will go away.. Nice! This LGTM - run make format and the format error will go away too :). That's working fine, there's a merge conflict with go.sum which can be resolved I think easily. The tests fail due to flakiness and also some code errors (see the format task).. Yeah this has only one change now?. @kminehart will you be opening a new PR or trying to fix this one? If you need help with git let me know.. I love you.. This is awesome!! We might even end up forking this here officially :). Thank you!. LGTM - needs a test now :). Nice, good job :). Feel free to PR this!. Awesome, thank you!. Nice catch, would you be up to create a PR and change this to on-failure?. Yeah, open to move to v3! Should we close this then?. ty!. and send over that v3 :). ty. Nice, thank you :). I generally like the idea. One centerpiece will be to figure out how we can store access/refresh tokens in a scalable way - I'm not sure CRDs are the right place for that. Another idea I had was to import specific data on boot from disk. I'm not sure if that's possible, but it would allow to mount CRD/whatever on disk and hydra would load that on boot. This would not work with watching though. The problem with hydra really is that clients are usually created from 3rd parties without access to the k8s cluster. I'm not sure how much optimizing we should do towards k8s in that regard. The same goes for consent/login flows which are always browser-initiated. The only thing that's really super static is usually the JWKs.\nIf we're talking Oathkeeper or Keto, there it really makes sense because rules etc. are rather static and there a watcher for CRDs is really smart imo.. couldn't this be done via:\n- postgres://user:password@host:port/database - postgres\n- rethinkdb://... - rethinkdb\n- mysql://...\n. This is actually for setting up the schemata, not for pinging the database :)\n. seeing this I'm considering wether this should be handled by each database implementation or the calee instead..what do you think?\n. is res.Close() missing here?\n. not sure how rethinkdb handles this stuff, but if err != nil, could result be nil? In this case, result.Close would panic\n. handling errors in go is painful because we're missing important stack information for debugging. Througout hydra I have used go-errors to wrap \"native\" error results. It would be good if you could do so in the rethink implementation as well.\n. there are many LoCs where this is an issue I will not comment on all of them :)\n. Great idea!\n. This shouldn't be hardcoded, so other people can use different LDAP servers.\n. Actually, the whole thing should be configurable. Maybe don't define New at all and simply make ldapconf public and rename it to e.g. LDAPProvider.\n. &tls.Config{InsecureSkipVerify: true} is a security risk and should default to false.\n. I would appreciate it if you would use dockertest to spin up an LDAP server and test against that one. Using a public LDAP is not reliable because the server could shut down or configuration could change.\n. god, this looks so much cleaner already..\n. There will be no more middleware, just one client. This will clean up the code base a lot. This interface should basically be implemented by any client in any language. Maybe we can use something like Thrift to build a client library for various languages\n. https://github.com/spf13/viper/issues/188\n. Could you add a test for this? Also, the name suggests that this is a function for loading any certificate, not just the RETHINK_TLS one. For better testing, you could implement this signature instead:\ntype importRethinkDBRootCA func(opts *gorethink.ConnectOpts)\nAdditionally, if a root ca is loaded, there should be a warning using logrus.Warnf(), similar to https://github.com/ory-am/hydra/blob/master/cmd/host.go#L98 or https://github.com/ory-am/hydra/blob/master/cmd/host.go#L135\n. remove blank line :)\n. this should be a warning because a path was given but an error occurred. if you think Debugf makes more sense here, we should change that in all locations where a debug message is emitted\n. Maybe add examples here? e.g.\n// client, err := ...\noauth2Client, err := client.Client.GetClient(\"1234\")\n. please document exported functions :)\n. Could you rename this to SkipTLSVerify, it's clearer then that the tls verification is disabled, not SSL in total\n. Endpoint: c.clusterURL, :)\n. this looks weird?\n. ah right, that's the problem I have with go vet because gofmt -s actually removes those\n. Could you change this to:\nHOST: The host interface hydra should listen on. Leave empty to listen on all interfaces.\n. It's the default data that makes hydra compliant with https://tools.ietf.org/html/rfc7592 - you can still use your own metadata storage\n. I didn't know that, do you have any resources on that? In general it's nicer to deal with non-nullable strings in Go because Go doesn't know nil strings. tl;dr SQL null fields are a bit tricky to deal with in Go iirc.\n. \ud83d\udc4d \n. It doesn't look like you make any use of the Cipher? The idea is that JWKs are encrypted with the SYSTEM_SECRET and then stored in the datastore, reducing the likelihood of compromise.. This can't work. You're referencing a nil-Pointer. This should be something like this instead:\nvar d Client\nif err := json.Unmarshal(resp, &d); err != nil {\n    return nil, errors.Wrap(err, \"\")\n}\nreturn &d, nil\nI don't know if you've seen it, but I think the Go tour gives good ideas how this works: https://tour.golang.org/moretypes/1\n. note-to-self: needs review. Do you want singular for the table names or plural? Because here it is hydra:clients but in the JWK it's singular hydra:jwk. Since it's singular in sql/rethink I would recommend having it singular here as well. It's a runtime error. If the tests don't check this specifically at runtime you won't see the error.. Thanks!. does redis need something like schema generation?. What is the /0 for?. I think it would be better if the port are actually the defaults of the databases (same goes for mysql/postgres/rethink). I will fix it for those three, but could you replace :123 with the redis default port?. Ok so it works with a fresh redis instance?. Perfect. maybe uncomment this and mysql too, so it doesn't pull unneccessary images. The private key is used for signing the consent response, the public key is looked up by hydra to verify the consent response. The client does not neccessarily need acces to the public consent key. Please check out https://github.com/ory/hydra-js for an easy to use js API on this topic. Maybe due to newline. You don't need to include client id and client secret in the POST body, it is enough when provided via basic auth :). Maybe make it clear that this is a separate thing? Because you can't use the auth code, only a refresh token. Maybe as a new bullet point?. Same as above, client_id/secret are only required in the authorization header :). Instead of returning the consent response token here, we could probably return the URL instead. The former requires us to do something like this:\ngo\nresponse, err := c.GenerateResponse(/* ... */)\nhttp.Redirect(r,w,claims.RedirectURL + \"&consent=\" + response)\nwhile the latter would allow for an easier flow:\ngo\nredirectURL, err := c.GenerateResponse(/* ... */)\nhttp.Redirect(r,w redirectURL)\nTo deny consent, the idea is to have:\ngo\nredirectURL, err := c.DenyConsent(/* ... */)\nhttp.Redirect(r,w redirectURL)\nCurrently this would be possible with:\ngo\nhttp.Redirect(r,w,claims.RedirectURL + \"&consent=deny\"). Yes absolutely, I'll also write tests for it, just wanted a branch to get started. Please remove this. Hm, good question, this was actually a problem previously. The cluster url is usually set on the client side, not the server side. We could either use the issuer url, or make it easier to understand by renaming ISSUER env var to something like PUBLIC_URL. what do you think?\nSorry by the way for taking so long on responding, the last days were really busy.. Why did you remove this?. Don't do this, it will force glide install on every code change. Yes, sounds good!. Besides adding it in the docs, also make the usage clear in hydra help host :). This is no longer needed right?. doesn't matter :). I'm not entirely sure why I did generator.Generate(\"\") here. Can you confirm that the docker-compose example works with your patch?. I don't feel comfortable about this, what if the issuer is formated as http://foo.bar/foo/ and the AuthPath as /foo, then we get http://foo.bar/foo//foo as a result. For resolving this, see this SO question. Oh, I totally missed that! Then this is fine of course :). > So this changes the generic key names to public:id-token-foo, which in turn changes a couple policies as documented here\nYeah that's what I thought which is why I asked the question. I don't know how I feel about that. Does it change the URLs which are used to look up the keys as well?. Ok, I see, I now also understand the change better. I think going with a timestamp, a uuid or some other unique identifier is the way to go here, the doubling of the name feels kinda weird and is also not unique, right?\nHowever, this will impact the way we query for those keys within hydra, and maybe also in the SDK. So I think this is your suggestion for the key type?\nI understand now the need for this, but it also complicates things a bit, so we need to document this, especially if we expose the KeyFromType functionality to the SDK/REST.. Couldn't get key just return the most recent key?. Yeah you're right here. Damn this one is tricky. Couldn't we be doing the following:\nPublic and private are reserved keys. Only one key can have the kid private/public. On, for example, key rotation, the old keys with kid public and private get reassigned something like private:<timestamp/uuid> and the new keys get public/private?. Oh I think you misunderstood, the kid public and private are unique - like a fixed primary key. However, if multiple keys exists, they have a different id, for example 1234 or public-1234. This way we only have one public kid in the set. Does that make sense?. I think I wasn't able to get the point across yet :D \nWhen booting Hydra on a new database, the signing keys for OIDC will be generated with:\n{\nset: \"openid\",\nkeys: [{kid: \"private\"}, {kid: \"public\"}]\n}\nIn this case, the kids private and public are unique because the set does not have any other keys. Let's say the administrator of Hydra now adds a new keys to the set by accident:\n{\nset: \"openid\",\nkeys: [{kid: \"private\"}, {kid: \"public\"}, {kid: \"public:just-any-key-whatever\"}]\n}\nThe private and public keys are still unique in this case - so no problem. Let's say the admin now wants to do some fancy key rotation. First, he renames the keys private and public:\n{\nset: \"openid\",\nkeys: [{kid: \"private:old\"}, {kid: \"public:old\"}]\n}\nnext he adds the new keys:\n{\nset: \"openid\",\nkeys: [\n  {kid: \"private\"}, {kid: \"public\"},\n  {kid: \"private:old\"}, {kid: \"public:old\"}\n]\n}\nNow, we have four keys. The old ones plus the fresh ones from key rotation. In a later stage I want to provide automatic key rotation, so this process would be automated by, for example, calling PUT /keys/rotate/openid with the result being something like this:\n{\nset: \"openid\",\nkeys: [\n  {kid: \"private\"}, {kid: \"public\"},\n  {kid: \"private:some-uuid-or-a-timestamp-or-something-else\"}, {kid: \"public:some-uuid-or-a-timestamp-or-something-else\"}\n]\n}\nDoes this make more sense now?. Oh wow, this took me some time to get it. I didn't get that well-known is aggregating all those keys and putting them in the same set. Now this all makes sense, sorry for being so slow on understanding this :D \nOk, so how about we simply prefix the kid with the set id in the well-known endpoint? Or is that a hack job?. Yeah, only returning the keys for openid connect makes sense IMO :). This is actually required, was it removed by accident?. This is actually required, was it removed by accident?. Without description, this causes a schema error, could you revert this change?. Without description, this causes a schema error, could you revert this change?. This is actually required, was it removed by accident?. This is actually required, was it removed by accident?. This is actually required, was it removed by accident?. This is actually required, was it removed by accident?. This is actually required, was it removed by accident?. This looks like a fluke?. This looks like a fluke?. This looks like a fluke?. This looks like a fluke?. This looks like a fluke?. This looks like a fluke?. I think you imported the wrong assert package somewhere :). Awesome, thank you so much! Could you replace the jwk tag with oauth2 and jwks and openid-connect? :). There it is! Replace this with testify assert :). This can be simplified with:\nrequire.NoError(t, err, \"problem in http request\"). This can be simplified with:\nrequire.NotNil(t, err, \"Could not find key public\"). I'm not super picky on this but since you probably will take another pass at this anyways, could you run goimports on this file? Please on this file only so we get a clean changeset!. Nice! Thanks for adding the model here :) You could copy the descriptions from the JWK RFC here so it's clear what each of those values are.. Could you add the tag openid-connect here? :). Adding the kid here should work. Is the idea here that you don't want to exit on error but rather process everything and then return the first error?. As discussed in my comment, I'd like to revert this and replace this with a policy check against rn:hydra:warden:groups. As discussed in my comment, replace this with one check to rn:hydra:warden:groups. In fact, we're receiving the full group payload (no longer only their IDs). This isn't your fault, but mine since I forgot to update the header title. But since you're already at it, maybe you could change that too ... :). This should actually be renamed to listGroups. List groups. listGroupsResponse. This can be removed as discussed in my comment. Can we wrap this and the parsing in it's own function? It would allow for better readability and a shorter function body, e.g.\nfunc intFromQuery(r *http.Request, key string) (int, error). is this to assert that MemoryManager implements Manager?. This applies to the 0.10.x branch - for the 0.9.x branch this is correct.. For 0.9.x this should be List group IDs. I think it should be fine to set limit to 0 (or 1) if it's below 0. I think it should be fine to set offset to 0 if it's below 0. This is nice, I totally did not know about that flag. That way, postgres and mysql will be run alongside. This should be everywhere. Thank you!\n617. I'm not sure about the order clause here, what it's goal?. Sorting makes sense here because maps don't have an order.. No worries, most of them are encapsulated in their own libraries (e.g. the whole json/statuscode/error stuff) and thus a kind of invisible to the naked eye :). Since it's used somewhere in the code, that should happen anyways, but it probably makes sense when testing only this specific package/file - maybe move this line to the tests?. Oh, I did not know that! Then this is fine!. Makes sense, let's keep it where it is. ping. ping. This line and the following policy can be removed, as discussed in the comments. ping. If you supply a default value, no error checking is requried and you can save the limit == 0 check!. Could you please change this to 0.10.0-alpha.8? Thank you! :). If no results are returned, this will be nil which in turn will return null in the JSON response (see https://play.golang.org/p/7H6y1t2mdd ). To avoid this please initialize the slice (q := []string{}). If no results are returned, this will be nil which in turn will return null in the JSON response (see https://play.golang.org/p/7H6y1t2mdd ). To avoid this please initialize the slice (q := []string{}). In fact, this is no longer correct as Hydra does indeed support OpenID Connect Discovery :) Could you change this to\n\npublic key for verification. Additionally, Hydra supports OpenID Connect Discovery.. Do you think we should remove ES521 completely?. This needs to be re-added. This is weird, why is the description gone?. Hm strange, maybe a version mismatch in go-swagger. The corresponding line is here: https://github.com/ory/hydra/blob/master/client/client.go#L39-L40\n\nI think the issue is , for example: http://mydomain/oauth/callback . which is apparently parsed as an example section. You could try rewriting it to , for example http://mydomain/oauth/callback. Damn, I was just a bit late! :D. I guess this can be updated? I registered packagist here: https://packagist.org/packages/ory/hydra-sdk. Same thing here I guess?. Add case=client is ... here. Add case=public client is ... here. I would probably rename it to \"UpdateGroup\". Yes, maybe I was using g here for some reason which was why it was decoded first, but as it stands now the order can be reversed\u00b4the way you did it.. requests are really transactions, right?. If rollback fails, the error should be returned instead\nif err := tx.Rollback(); err != nil {\n  return err\n}. this can be simplified to return m.ApplyIn.... You have duplicate rollbacks here, let applyInTransaction handle rollbacks instead!. Rollback is already covered by applyInTransaction. Normal errors do not have stack traces in go, to add a stack trace do return errors.WithStack(err). Normal errors do not have stack traces in go, to add a stack trace do return errors.WithStack(err). Normal errors do not have stack traces in go, to add a stack trace do return errors.WithStack(err). Exactly, and it also needs to be called at the location which is the deepest in the stack trace and there only once - otherwise you'll overwrite the stack trace. This is a bit tricky unfortunately. The rule is that we wrap all errors coming from other libraries but don't wrap errors coming from our own. That way we ensure that traces are always as deep as possible in the stack.. How about executors?. PUT requests typically don't return 204 responses but instead 200 + body. 204 is typically used for DELETE responses to aknowledge that the resource is gone. Not sure if this works for nil values? So if error is nil, does this return nil as well or not?. Absolutely, it returns nil in that case: https://github.com/pkg/errors/blob/master/errors.go#L145. It's also in the response, see w.WriteHeader(http.StatusNoContent). This should probably be renamed to prometheus. This is a side effect of NewMetricsHandler which might introduce some issues during testing. Not sure if I like this here.. Not sure if we should disable prometheus if this is true. The idea of this is to allow people to disable sending reports to our servers. Prometheus runs locally and doesn't send anything to us. How do we decide which prometheus statistics to use here? Is sts_response_time_seconds standardized somewhere, or chosen arbitrarily?. Factories should try and avoid side effects such as logging. Not sure we need a defer here? Just put it behind next?. > Name of the counter should be like https://prometheus.io/docs/practices/naming/ and we can change it accoring rules in doc\nDamn, that's what I feared. Naming is subject to the environment you're in, so hardcoding this is not a very good idea. Another issue is what metrics we collect, like do or do we not want to collect CPU metrics? But what about the thousands of other possible metrics?\nI feel like implementing prometheus is like implementing proper analytics/tracking - the data being sent is really dependent on what you want to learn.. Just as an example, you want to name this secure_token_service. I'd disagree and say to use the name of the product. Someone else might want to have here oauth2_server or whatever. It's really hard to define something that is so dependent on the context it's being used in.. But here we have the same issue, right? Who decides:\na. What metrics to include\nb. What the key (\"name\") is for each metric\nIn your specific example, I'd say (just to prove the point) that I'd like to have response_time_ms because if an endpoint requires more than one seconds then something is very wrong. So it's really hard to find\na. The right metrics to export\nb. Name them correctly\nbecause it's so very dependent on the context in which the technology is being used in.\nLet's consider this:\nI have a small site which isn't latency critical. But what interests me really is how often each token is being used. This metric is probably not something we'd include per default in the project.\nI'm 100% sure that someone will come up with such a requirement and demand a change to the code base to add it.\nApart from the original metrics module being really shitty written, similar conceptual issues led to me removing it from the project. I thought prometheus had like some standard middleware which would be accepted as \"best practice\" - or just default metrics which are always collected, and use them to monitor services. But defining everything manually and (in my case) without much experience with prometheus, will lead to lots of breaking changes and constant readjustments.\nIsn't there a better way to achieve this?. Ah I see - maybe a good idea then would be to just send the default metricsf or now?. Yeah, that makes sense!. Yeah I think that makes sense - we could - in the future - also have the ability to load a plugin for handling prometheus middleware, which would make this a nobrainer to use.. ping @dolbik . Oh Yeah! Sorry, didn't see that - perfect :). Fatalf runs os.Exit(1). I really think we need pagination here, because this can be a lot! Examples can be found here, here and here.. You can revert this logic to == and add rs = append(rs, c) in the loop, it is easier to read!. The problem with exposing this is that acceptance of the consent request could overwrite this value and potentially mess stuff up. I haven't checked if that's actually the case but it could be an issue in some regression. I think it would be ok to copy this struct 1:1 and there set the consent_request value. If the order of the fields is the same, you can easily convert the type:\ngo\nvar foo HandledConsentRequest\nvar bar = NewTypeWithJSON(HandledConsentRequest). We don't really need the ctx.Hash/logger dependencies here. This could be the case for plugins for example (they might use a different hasher). I think it would make more sense to put expectDependency in the concrete implementations.. I think this should read: Unknown DSN scheme \"%s\" in DATABASE_URL \"%s\\\", schemes %v supported. I think Connection or Connector would be a better choice here :). The problem is that some services have dependencies to others. In some cases (in the past) these had not been properly instantiated during the set up of a particular service/manager. This caused nil point exceptions (see #928 for example). To solve that I added this little helper that makes sure that no dependency is nil.\nAdding this to the SQL or Memory Managers (where required) prevents that.. Yup, BackendConnector or Connector both work fine. Choose one you like. The plugin should export the same name, so also either BackendConnector or Connector.. How about PreviousConsentSession? :). I see, I don't think this solution will work with SQL as they don't support negative offset (I think).. Oh sorry, I didn't see that you duplicated the other method. Then it will obviously work. I agree that it's not the cleanest solution but it does get the job done for now. So from my side, this is fine.. The error must be handled here!. You can rewrite this to return m.resolveHandledConsentRequests(a). Re-add newline. Remove newline. Re-add newline. Remove newline. Add a newline on top of start, end := ... Re-add this newline. I think the naming should be listUserConsentSessions. With the current naming, I would expect the method to be like listUserClientConsentSessions(user, client string). So one issue with this is that the HTTP handler function will return errNoPreviousConsentFound which is a \"dumb\" error (meaning it will return a 500 status code with no context in the API). On the same hand, this error is required to be returned for the consent_strategy to work. Since you duplicated the methods and this particular method is not used in the consent_strategy, you can remove the err == sql.ErrNoRows check and just return return nil, sqlcon.HandleError(err).\nPlease also add a test for this. It should check that sqlcon.ErrNoRows is returned when we expect that no session exist in the store. This will return a proper 404 error in the API which I think is to be expected here.\nIn the handler, you may want to choose to ignore the error of type sqlcon.ErrNoRows and instead just write an empty array. This will return [] instead of a 404 which might be a better suited response.. Let's rename this to swagger:route GET /oauth2/auth/logout oAuth2 userLogout. Perfect! You can actually write this in one line:\ngo\nif err := revokeAuthenticationSession(w, r); err != nil {. You can remove Consumes because we don't consume anything. It produces JSON in case of an error, no text/html. This solution is ok, but it makes setting defaults and testing the configuration harder. Typically what we do here is:\n\nAdd a config item in config/config.go\nAdd a field (e.g. LogoutRedirectURL) to set this in the handler.go and the respective factors (new...)\nBind and set a default in cmd/root.go like here.\nUse LogoutRedirectURL here instead of os.GetEnv()\n\nAdditionally, we should set up a default handler for the log out screen, similar to this one and add it to the frontend router here. The layout of the page doesn't matter. It should read something \"You have been logged out successfully. ... Admin forgot to set up the redirect URL after logout ... to fix that set environment variable LogoutRedirectURL, e.g. export LogoutRedirectURL=http://... or on windows set LogoutRedirectURL=http://... ...\". Let's rename this to UserLogout (because it's UserConsent :) ). This should be empty, we can't assume that this service is running on that port and doing so could even be a security issue (it's a different service/malware not explicitly configured). Same here, don't assume default hostnames!. This should be ORY Hydra. Are there any stats on reliability and/or network performance, specifically wrt to memory use under high load? If it's minimal we can have this always enabled. If it isn't, it should be either enabled by default (but possible to disable) or disabled by default (maybe the better option).. The problem with :latest tags is that, while they do fetch the latest tag, they don't fetch those the next time you're running :latest. This can lead to problems where machine A uses version 1.0 and machine B uses 2.0 although both have the same tag. This can then lead to a ton of confusion and issues. It's much better (and safer) to explicitly define the version.\nThat being said, I don't think jaeger belongs in this docker-compose file. Instead I'd love to see either a docker command (e.g. docker run --network --rm ..... jeagertracing/all-in-one-latest) that you can just run \"on top\" of this docker-compose set up, or alternatively add this to one of the ory/examples. If it's the latter, please coordinate with me as I'm currently working on that repository and changing some substantial things.. Not sure about this line, are you sure this is negroni? I think it would be better do define your own interface here or use one from the standard library. Oh I see, so omitting TRACING_PROVIDER disables tracing?. Perfect. I think it would be good to lowercase this so JAEGER and jaeger are equivalent. IMO we should have two cases here:\ncase \"\":\n// disabled\ndefault:\n// fatal because unknown tracer\nBy explicitly failing on an unknown tracer, we make debugging much easier.. Ok I see how this works now. This is a negroni middleware so we're getting the correct RW here. I though it worked differently, my bad :). This can be simplified to:\ngo\nif tracer := c.GetTracer(); tracer.IsLoaded() {\n  middlewares = append(middlewares, tracer)\n}. Same here, or depending on what Close() returns (if it returns nothing) maybe:\nif tracer := c.GetTracer(); tracer.Loaded() {\n  srv.RegisterOnShutdown(tracer.Close)\n}. Should this be handled \"silently\", aka no service crash? I'm not sure if it should.. Yes it should, because it's an obvious mistake so hydra should make it explicit that it's misconfigured. Better to have a service not start than to discover that some feature didn't work all along that you now urgently need to debug something.. Is it possible that there is an error here? If yes, tracer MAY be nil which will cause a panic. Agreed!. I think it would make sense to have an unique index. They key should really be unique and it will help with query speed.. These two can be merged, no?. Yeah definitely!. Oh yeah, I see, this is because of the function design. Let's keep it the way you have it. I think it would be better to have a descriptive error here like the one from the manager: fosite.ErrInvalidRequest.WithDebug(\"Authentication verifier has been used already\").. I think it would be better to have a descriptive error here like the one from the manager: fosite.ErrInvalidRequest.WithDebug(\"Consent verifier has been used already\").. Please document this around here: https://github.com/ory/hydra/blob/master/cmd/serve.go#L182\nAnd while you're add it, please document the other tracing env vars there too :). ping @someone1 fyi. would it make sense to reuse those from sqlcon?. That makes sense to me. Yeah, let's just keep it as is. If people complain we can add it or they have to re-build the binary which hopefully makes them incredibly aware of removing that once they're done.. This makes a ton of sense to me, all of these options are only used internally for testing and other stuff. Good job!. Please use keyed fields here. I also noticed that this is kinda duplicated with here. I also noticed that hasher might be null if tracing is disabled. So instead this should use the bcrypt from the config (here). The nil thing is actually default behavior and did not cause any issues. BCryptWorkFactor was also set properly.. I think for clarity it should we should use the hasher from the config here.. Let's call this TRACING_PROVIDER_JAEGER_LOCAL_AGENT_ADDRESS. Ory should be uppercase: ORY. A particular reason for this change?. Ah!. Fixed, thanks!. Line 138 variable ROTATED_SYSTEM_SECRET to the new secret: should also be variable ROTATED_SYSTEM_SECRET to the **OLD** secret:. ping @prateek1192 :). Perfect :D. I was under the impression that go1.11 refers to the latest go 1.11.x tag. Actually I just double checked and that is indeed the case. The question being that, if go1.11 is cached in docker already, it is updated or not. In that case, making the dependency explicit would be an option. Alternatively we could run git pull golang:1.11 (or whatever version) to force an update to the latest tag.. This is fine! However, a more idiomatic would be by using int (optionally with iota)\ntype transactionKey int\nconst txKey transactionKey = iota. remove empty line. dbAccess is both a type and a value here. Maybe just rename this to db := s.db()?. Rename this to sqlxDB which represents the type that sqlx.DB represents?. Would it make sense to test this against all methods?. Add whitespace :). Nice!. This test doesn't actually do anything, it's just the same as the one above (you're checking for the remote address which is 127.0.0.1 and thus satisfied, X-Forwarded-For is not being touched). Please also note that \"X-Forwarded-For\":   []string{\"227.0.0.1\", \"127.0.0.1\", \"227.0.0.2\"}, should (most likely) be \"X-Forwarded-For\":   []string{\"227.0.0.1, 127.0.0.1, 227.0.0.2\"},.. This test could also fail because no remoteaddress is given (thus SplitHostPort returns an error). This has some issues, one of them is that strings.Split always returns at least one element (even if the string is empty) and that we shouldn't expect a whitespace after ,. Let's rewrite this a bit:\n```\nremoteIP, _, err := net.SplitHostPort(r.RemoteAddr)\nif err != nil {\n    return errors.WithStack(err)\n}\ncheck := []string{remoteIP}\nfor _, fwd := stringsx.Split(r.Header.Get(\"X-Forwarded-For\"), \",\") {\n    check = append(check, strings.Trim(fwd))\n}\n``\n. This should probably beneither remote address nor any x-forwarded-for values match CIDR ranges %v: %v, ranges, check). Errors names [should not start with a capital letter](https://github.com/golang/go/wiki/Errors) :). Probably makes sense to remove this too?. I think we can check here forif exp.IsZero()` as well. In that case we can probably simplify the logic too.. The description can be upper case :). Wouldn't it make sense for the name and description to always be set to the default values? Then you can override e.g. just the description or only the name without having to set both?. > Also, it is possible for refresh tokens to not expire if the value of the lifespan has been set to -1. In that case, perhaps it is best to omit the expiry field in the response payload.\nDamn, you know this system better by me. I'm almost \ud83d\udcaf that's true. In that case it should be omitted.\n\nThe introspection point serves access or update tokens. Other tokens are outside the specification.\nhttps://tools.ietf.org/html/rfc7662#section-2.1\n\nProbably just a typo, introspection serves access and refresh tokens. So @aaslamin point is right!. In this case we wouldn't override the existing value. However, I think that's what we should do here as long as was_used is false.. This method can be shortened, d is already defined by it's outer method HandleConsentRequest and processing it another time is thus not necessary. ReplaceUnusedConsentRequest should also not be exported since it's only being used internally.. Query implements a scanner for things like SELECT, not an executor, see query versus exec in godoc. If you update this to NamedExecContext be aware that it won't return sqlcon.ErrNoRows if no rows are affected. Instead, you need to check the first argument, probably something like results.ReowsAffected(). If it's 0, the update failed.. Let's avoid duplication and construct this from sqlParamsConsentRequestHandled instead.. Let's rename this to ListClients :). Response Type should be Response Types. I also think it would be important to add the following fields:\n\nRedirectUris\nGrantTypes\nTokenEndpointAuthMethod. that's probably not intentional?. The test is actually that this fails if the subject is empty, right?. Let's change this to challenge, res, err := apiClient.... ... and add a assert.False(t, challenge.Skip). This will make sure that the test is actually failing because the subject is empty, not because the subjects don't match.. \n",
    "bketelsen": "JWT is pretty standard - my vote is to keep them and make it pluggable at least.\n. ",
    "tbroyer": "Disclaimer: just came in here from your post on Gopher Academy; I built an OAuth 2.0 Provider \u2013OpenID Connect 1.0 actually\u2013 in Java https://github.com/ozwillo/ozwillo-kernel; I'm not a Hydra user.\nJWTs as access tokens have only one advantage: they save storage on your server. When you don't support token revocation, then they also save you a hit to your database from the introspection endpoint \u2013or anywhere you need to introspect the token\u2013 because they're self-contained.\nBut:\n- they trade storage on your server for network bloat and storage on others' machines\n- as soon as you support token revocation (and you claim Hydra does), you'll have to at least make a hit to your DB to check whether the token has been revoked whenever you \"introspect\" it.\n- unless they're encrypted, you're exposing all the \"doors\" the token can open to anyone bearing it, and this includes anyone of those \"doors\" receiving it. If you're generating tokens that can be used at several APIs (those APIs calling your introspection endpoint to validate the token and decide whether they should accept it), each one can now know it can also use it at the other ones (through scopes and/or audiences), and possibly gather (private) information about the user. The introspection endpoint can choose to filter the response depending on the client making the request to mitigate those things, but if all the information is embedded in the token this is not possible.\n. Clients relying on the token format is fragile (what if Hydra changes to something else as proposed here?) and somehow defeats OAuth2 which states a token is opaque. You're free to do it in a \"controlled environment\" of course but it's not worth it IMO. You can also return that info in the token endpoint's response for example (\u00e0 la OpenID Connect's id_token)\nRe. HTTP/2, that only holds over the same TCP connection though. If you work with mobiles or otherwise flacky Wi-Fi, it may very well not be true; but also in many other cases I believe. Depends on use-cases though.\n. Ha, looking at osin-storage implementation it looks like you're paying the size cost at all levels. Had you been using your own implementation you could have stored only the revoked jti (along with the token's expiry date to easily clean up the data store) ;-)\n. Not directly related but I believe you should not store tokens as-is. If the DB data ever leaks, an attacker would have tokens ready to use. FWIW I treat tokens like passwords: a token is in two parts, the first serves as an ID, the second is hashed and only the salt and hash are stored in DB. I have the impression that OSIN would make such storage impractical if not impossible (well, until a few days ago it wouldn't even allow secure storage of client_secrets so definitely OSIN doesn't take security seriously; given how easy OAuth 2 is to get right, I wouldn't bother using a badly-designed framework; YMMV)\n. That's why I didn't talk about compromising the server but only leaking the data (could be a backup, or possibly an eavesdropper on the network)\n. If Hydra's goal is identity management and/or authn (and not just authz) then it SHOULD (MUST?) use OpenID Connect: http://oauth.net/articles/authentication/\n. ",
    "vgrabko": "JWT\n. ",
    "allan-simon": "thanks for the hint, I think I will have time to look on it in 4~5 weeks, I will tell you if I start to write actual code so that tobe sure things integrate nicely :) \n. thanks, after on a side note, just my humble advice, but i always associate my TODO in the code with a ticket in github (by doing TODO: #4 blabla , so that people that come around like me, are more likely to read the issues list rather than the code :) and if somebody is to give you a hand they can directly check the list and grep for the issue number\n. you're welcome, I'm really looking forward to see your project becoming more mature :)\n. great :)\n. @arekkas  the doc says \"Hydra implements all grant and response types, except the resource owner password credentials grant.\"  is there any reason for this ? or is it just not implemented yet \n. ok I see, perfectly make sense,  in my case it's indeed the \"for legacy reasons\" , i.e we have some hardware devices with the password grant hardcoded in it, so something we have to live with until the end of life of the old gen. \n. as said, unfortunately legacy (from before I arrive) :( \n. same for \"warden guide\" link in http://docs.hdyra.apiary.io/#reference/warden  :) \n. ",
    "zsims": "Firstly, awesome project -- thanks for the hard work!\nWe've been using https://github.com/IdentityServer/IdentityServer3 for a while. And I think it has a good model for token formats, per client setting (for access tokens), identity tokens are always JWTs (per the spec). The only catch is supporting refreshing claims in JWTs is a pain for clients, e.g. you change your email -> self contained JWTs are now invalid. For this reason, opaque tokens are a lot easier for clients. Plus there's no need to sign them, or for clients to check signatures per the JWT (complicated) spec\n. ",
    "ibotty": "What's the current plan regarding OpenID Connect? Should AuthN be outsourced to the providers? Is that feasible?\n. I am aware of the security implications of trusting headers: I am not advocating blindly trusting them. In a way, an edge-tls-termination flag is different from force-dangerous-http, because hydra would still generate only https-links. Also logging the right IP (from e.g. X-Forwarded-IP) is only necessary then.\n(BTW: Of course, all X- headers are non-standard. Unfortunately the standard FORWARD header support is not widespread yet).\n. I prefer an option like \"--edge-tls-termination-from\" where you can specify one or more netmasks from which you trust the headers.\nBut I am fine with any way that makes it possible to use it behind a tls terminating router.\nIn a way, I like using RFC 7239, the FORWARDING header (confused above with PROXY), but it's not as straightforward to parse and not very widespread.\nAnd don't you log IP addresses somewhere? That part will most likely benefit by inspecting the headers and logging the client's IP.\n. I like it. I can't think of anything shorter which is as precise.\n. I hope it is parsed as a comma-separated list, without the brackets. If so, the example should read\nExample: HTTPS_ALLOW_TERMINATION_FROM=127.0.0.1/16,192.168.178.0/16\nbtw: what about ipv6?\n. Sorry, I don't know anything about go and IPv6.\n. ",
    "akhedrane": "you're welcome :)\n. ",
    "joeblew99": "Thanks for the feedback from: \nhttps://www.rethinkdb.com/docs/architecture/\n.Write atomicity is supported on a per-document basis \u2013 updates to a single JSON document are guaranteed to be atomic. RethinkDB is different from other NoSQL systems in that atomic document updates aren\u2019t limited to a small subset of possible operations \u2013 any combination of operations that can be performed on a single document is guaranteed to update the document atomically.\nIt maybe that this scope if atomicity is enough, but until idig through the DAL / CRUD in the code I can't say.\nIt all comes down to how relational your design is. If its no too much, its possible to scope everything to a su gle json dic for atomic reason.\n. It's OK.\nNice. Good idea. Will take a crack at it tomorrow.\nBut I need all that hydra has, so will have to bite the bullet.\nCheers\nOn Tue, 29 Dec 2015, 20:30 Aeneas notifications@github.com wrote:\n\nHey yep you're absolutely right. I was a little in a hurry and did not\nread up on everything, sorry for that :)\nAtomicity is already one step in the right direction. If you don't manage\nan uber RethinkDB cluster, it should be a viable solution for Hydra. Osin\n(the OAuth2 library behind Hydra) actually already supports a RethinkDB:\nhttps://github.com/ahmet/osin-rethinkdb\nYou could play around with osin and osin-rethinkdb to get things started.\nOnce that works it shouldn't be hard to get RethinkDB working for Hydra.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/ory-am/hydra/issues/39#issuecomment-167860461.\n. Hey Alexander. I never got time to do this , so thanks for this. I will be\nable to help beta test for sure and contributed back I hope\n\nOn Mon, 8 Feb 2016, 10:16 Aeneas notifications@github.com wrote:\n\nYou rock!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/ory-am/hydra/issues/39#issuecomment-181291278.\n. If you can push and merge I can try it out on Monday\n\nOn Tue, 9 Feb 2016, 23:58 Aeneas notifications@github.com wrote:\n\ngood stuff! :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/ory-am/hydra/issues/39#issuecomment-182123210.\n. This allows a user or system admin to reflect on a users account, and see all the things they are authorised to do ? Like auditing you could say ?\n. Ok nice feature. As a system grows it helps allot\n\nOn Mon, 8 Feb 2016, 13:21 Aeneas notifications@github.com wrote:\n\nReopened #48 https://github.com/ory-am/hydra/issues/48.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/ory-am/hydra/issues/48#event-542903248.\n. wow you have been busy.\n\ni gave it a quick read. yes acls basically suck once the code and api expands.\nhow is the ability to audit coming along as per this main issue.\ni would really like to try this out with some test examples too.\n. ",
    "leetal": "I'm pro for adding RethinkDB. If you haven't already started working on it, I'll take a bite at it tomorrow. We use RethinkDB in our service backend and has so far not had any problems with atomicity, like pushing changes through the clusters immediately.\n. Update on this: 40% percent done last night. Will finish after work tonight.\n. So, i didn't finish this today, but most certainly will tomorrow. I only have one function left in ladon (TestFindPoliciesForSubject) to implement but since that function is quite harsh to overview, i'll finish this tomorrow instead so i can get some sleep tonight ;) \n@arekkas I think it's time to add rethinkdb support to dockertest as well. Right now all tests for rethinkdb are done locally instead of run in a container.\n. Ok, i think i'm done now :) Will need some live testing (how the heck i now do that?) and some smaller polishing bits, but at least hydra starts and sets upp all tables without giving any errors!! YAY!\n. :+1: on this one ;)\n. Awesome Aeneas! :D\n. So, of course Ladon has to be merged for the tests to even run... ;)\n. Yeah. There was quite a few storage interfaces to cover ;)\n. I count on it! But the best part with that is that then both of us knows\njust a little bit more of how the interfaces should work for extensibility\n:)\n. That should do it. BUT, I think that the tests actually will pass anyways\nsince I have added rethinkdb to travis. Ladon just passed and I think that\nthe same will go for hydra as soon as ladon is merged (Ladon\u00b4s tests all\npass now, just coverage that has decreased due to some errors being hard to\nreproduce like connection errors to rethinkdb) :)\n. Then we are two! :D\n. Awesome! I'll fix the tests and update the PR's.\n. As soon as ladon is merged and usable, i'll rebase and squash the changes and rewrite the commits to a better format.\n. We are a few guys doing a project at home right now that's not connected to\nwork. In this project we plan on using hydra (with fosite) and are also\nwell aware of the current status if the project. Personally I like to have\nthings break because that means that you can improve on those areas by\nfinding out that the base implementation was incorrect. Refactoring is what\nI do for a living so I'm well aware of that things WILL break in hydra.\nEspecially when fosite comes into picture. Also, any modifications that is\nmade on the interfaces (for example automatic db migrations) will break the\nbase implementation in a irreversible way, which at least I know is subject\nto change. So please, since the status is very well explained in the\nReadme, do what you have to. You guys own the rights so you also own the\nrights to change what needs to be changed.\nThe status of our personal project is like 40% done. We actually have a\nstandalone oauth2 service that we've written ourselves based on osin. Hydra\nlooked so much more promising so that's why I'm eager to help out with the\nstuff I know I can handle.\nA few things wanted with hydra:\n1. Db migrations (only useful for sql)\n2. Cluster functionality/scalability (ability to connect multiple hydra\ninstances together and issue commands between them)\n3. Improved documentation ;) Right now I really don't know how to pass\narbitrary data in the jwt so other services using the jwt can use that data\nin a scaleable way.\nOne thing I've wanted to write for a while is a intra-communication system\nthat is plug and play for more or less all go services. And to this\nintra-communication system write a dashboard where the status of the\nservice is shown, with ability to send commands to each instance (or group\nof instances). I think a system like that in hydra would make hydra more\nenterprise. Plus, then almost all services would be guarded and controlled\nremotely. :) I'll see what I can come up with in the coming month. We\nreally want such a system in our project so we can see the status of all\nmicro-services and issue commands to them, making them perform things like\nrolling updates and backups and even scaling dynamically.\n. @arekkas i sure will! :)\nDen 22 mars 2016 16:15 skrev \"Aeneas\" notifications@github.com:\n\n@leetal https://github.com/leetal keep an eye out for this one :)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/ory-am/hydra/pull/62#issuecomment-199860567\n. @arekkas I think i have successfully updated jwt-go in hydra now as well to 3.0.0. All tests in the oauth2 package pass. BUT, the following commit 7faee6bb @\u00a0fosite really messes up the tests in hydra/warden. Thus, i cannot verify the changes i've made and i really think you should take a look at what that commit does to hydra.\n. I think it actually accepts more or less all scopes right now...\n. On its way! Keep in mind that tests might/will fail. I cannot guarantee anything ;)\n. Seems good to me! \nWill have to fix a new version of fosite as well. Time for a 0.2.5? :)\n. Ah, okey! :+1:\n. Yes it could, no standard way of doing it was implemented so i just chose the easier way. I can fix this today. I think that prefixing it would me much more neat.\n. Fixing this.\n. No, runWrite runs and closes immediately after the write is run.\n. This should not be a problem, but for reliabilities sake, i'll add error checks before to cover all possible cases.\n. I'll wrap them all up.\n. I think that the use-case for the validate call is to narrow right now which makes me to believe that we can leave it in the storage implementations for now. I can't see any case where the user would want to do anything else than validating the structs (right now at least).\n. yeah, that is due to go vet complaining about \"composite literal uses unkeyed fields\". The only thing that 0 does is silencing that go vet error. Looks really ugly, but does the job.\n. Yeah ;) I think i'll remove the 0's. Will just confuse lesser bewildered gophers.\n. \n",
    "michael-golfi": "Hi @arekkas,\nI would like to use this project, I need LDAP integration though. So I've taken a shot at writing it myself using the suggestions from #28.\nI am however, not completely familiar with your codebase and I am unsure what you are expecting through the interface for a non-OAuth provider.\nPlease let me know,\nMichael\n. This is more a proof of concept since I just want to know will this would work with your current codebase to integrate LDAP?\nI'll tidy it up and submit another pull request with the config and security changes afterwards.\n. Right now from the tests, the LDAP querying works against the public server. However there is no redirect which takes place given this is not an oauth provider. Which is the part I need some clarification for.\nThis does return a 'user info' object though.\n. Where I work we use Active Directory but we talk to it using LDAP. I think it eventually could be necessary to implement support for Active Directory in order to get access to some extra features implemented by Microsoft, but so far we have been fine just using LDAP alone (solely for authentication).\nAt the moment I'm not sure how I would add AD support to this provider. We use LDAP to manage Windows clients with SSO and store organizational data in it, like who reports to who, which groups or departments certain people belong in. So there is already a concept of groups, which could work well with the policies portion of this project. However, I don't think at the moment AD would be really beneficial to authentication alone.\nSample LDAP Workflow\nTo authenticate a user with LDAP, you use a system account to login in, you query the user subject who you would like to authenticate, you find his full path (eg: \"cn=riemann,dc=example,dc=com\"). Once that's done, you try to login using that user path and the submitted password. If it doesn't error out then the login is successful.\nYou could knock out the part of the workflow by setting a base DN as a search base for users and authenticate by having users provide their username and password and attempting the log in portion of the above workflow.\n. I think your proposal makes sense but wouldn't starting a new sso server defeat the purpose of integrating LDAP? Would it make sense to launch some sort of authentication endpoint on Hydra?\n. Alright so in a nutshell:\nThis would require a separate auth server (using LDAP) that exposes an API to authenticate users given a username and password. This server would have a simple frontend that would accept the username and password and post to the backend.\nHydra would redirect users to this frontend, then the frontend would redirect the users back to hydra with some user info and then would take the user info and redirect to the 'final destination app'.\nDo I understand this correctly?\n. I had started to do something similar to this several months ago using the osin oauth library. I had created a login page using the text/template library. It's a bit messy and I was in the process of changing the storage backend to Postgres (from MongoDb), it has a working LDAP signin. I don't think I have a lot of time to support it though between school and work. Feel free to check it out and grab the login interface if you'd like.\nIt's hosted  here.\n. That sounds like a good option too. Making a simple UI for login isn't such a big deal for me, I can add that if you'd like.\n. @arekkas \nRegarding implementing an LDAP adapter for account storage, where should I start? Do you still want to continue this way?\nEDIT: I was taking a look at Postgres Storage. Creating one that uses LDAP backend seems like a really nice way to proceed from a design perspective since this won't require the use of multiple account storage backends.\n. I think using LDAP as a database is a good idea. IMO bigger companies will want to reuse their infrastructure and not recreate anything if possible. LDAP and Active Directory is also used as a primary data source for the most up to date user information. I cannot speak on behalf of having multiple data sources for user information since I have never personally seen this, except in the case when departments would want to enhance user data with custom permissions. They would have a local (eg: Postgres) and remote (eg: LDAP) in this scenario.\nI've started building the LDAP connector. I was following the interface you have for storage as a 'contract' between the services, is that alright? For the frontend in this case I'm going to most likely use a cut-down bootstrap with minimal dependencies (this is already done).\nHave you considered using a config manager such as viper to set up deployments with presets?\n. > Sounds good. I still have the concerns that I raised in the lines above. For implementation help you can also take a look at CoreOS/Dex LDAP connector.\nThanks I wasn't aware of this library I'll definitely take a closer look!\n\nFor this, we would need to write a small configuration persistence utility and could use e.g. viper unmarshalling to retrieve it. Also the CLI needs refactoring.\n\nKubernetes uses cobra (from the viper guys) for CLI, it works pretty well for them. I've never used it but looked really closely at it a while ago.\n\nThat way, we would separate concerns and let people easily extend or modify an existing connector without having to clone all of hydra. Connectors are also likely to receive less and smaller updates so keeping those maintained would be much easier.\n\nI agree this would be a really nice way to separate concerns, and for others (myself included) to add their own connectors.\n(Sorry I accidentally closed, I'm on mobile)\n. I'm going to work on this but I'm going to be a bit stalled by work and school so it might take me a bit. I'll try and contribute some time as I can.\n. I'm hoping this may be helpful for others along with the stuff I posted in #374 . \nI run Hydra and Hydra-idp in Kubernetes. Certain things in the configs are probably a bit sketchy like the dangerous auto logon but it's easier for me to setup if root credentials are printed to log. I could also reset Hydra, configs will be stored in db long term and logs won't carry the root credentials, if necessary. Also only our team has access to the logs (definitely helps).\nOne of the pain points IMO is that it's difficult to automate deployment and I realize that part of this is by design, particularly the client set up. Our other components use ConfigMaps (yaml configs) or env vars in the Pod specs and usually just need to be deployed and work out of the box. So I've tried to replicate most of this in the configs below and try to automate most of the setup.\nThough maybe you know a better way to accomplish this :).\nHere are my configs.\n\nFor Hydra:\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: hydra\n  namespace: user\n  labels:\n    name: hydra\nspec:\n  ports:\ntargetPort: 4444\n  port: 4444\n  selector:\napp: hydra\n\n\n\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: hydra\n  namespace: user\ndata:\n  hydra.url: https://oauth.$cluster_domain\n  consent.url: https://idp.$cluster_domain\n  .hydra.yml: |\n    cluster_url: https://oauth.$cluster_domain\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n   name: hydra\n   namespace: user\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: hydra\n    spec:\n      containers:\n      - name: hydra\n        image: oryam/hydra:latest\n        env:\n        - name: SYSTEM_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: hydra\n              key: system.secret\n        - name: CONSENT_URL\n          valueFrom:\n            configMapKeyRef:\n              name: hydra\n              key: consent.url\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: hydra\n              key: database.url\n        - name: HTTPS_ALLOW_TERMINATION_FROM\n          value: 0.0.0.0/0\n        command:\n        - hydra\n        - host\n        - --dangerous-auto-logon\n        ports:\n        - name: default\n          containerPort: 4444\n        - name: other\n          containerPort: 4445\n        volumeMounts:\n        - name: hydra-volume\n          mountPath: /root\n      volumes:\n      - name: hydra-volume\n        configMap:\n          name: hydra\n      - name: client-data\n        secret:\n          secretName: hydra\n```\n\nFor idp:\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: consent\n  namespace: user\n  labels:\n    name: consent\nspec:\n  ports:\n    - targetPort: 3000\n      port: 3000\n  selector:\n    app: consent\n\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n   name: consent\n   namespace: user\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: consent\n    spec:\n      containers:\n      - name: consent\n        image: $docker_repo/hydra-idp-react:latest\n        env:\n        - name: HYDRA_URL\n          valueFrom:\n            configMapKeyRef:\n              name: hydra\n              key: hydra.url\n        - name: HYDRA_CLIENT_ID\n          valueFrom:\n            secretKeyRef:\n              name: hydra\n              key: client.id\n        - name: HYDRA_CLIENT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: hydra\n              key: client.secret\n        - name: NODE_TLS_REJECT_UNAUTHORIZED\n          value: \"0\"\n        ports:\n        - containerPort: 3000\n  volumes:\n  - name: hydra-volume\n    configMap:\n      name: hydra\n  - name: client-data\n    secret:\n      secretName: hydra\n\n- For Ingress:yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: consent\n  namespace: user\ndata:\n  tls.crt: $tls_crt\n  tls.key: $tls_key\nyaml\napiVersion: v1\ndata:\n  tls.crt: $tls_crt_for_hydra\n  tls.key: $tls_key_for_hydra\nRoot Credentials\nclient_id:\nclient_secret:\nhydra clients create -a [hydra.keys.get,openid,offline,hydra] -c [https://$redirect_url] -g [authorization_code,implicit,refresh_token,client_credentials] -r [code,token] -n $APP_NAME\nResponse\nClient ID:\nClient Secret:\nNavigate to:\nhttps://oauth.$cluster_domain/oauth2/auth?client_id=$response_client_id&redirect_uri=https://$redirect_url&response_type=code&scope=&state=${...}&nonce=${...}\nsystem.secret: $secret\nRoot Credentials base64 encoded\nclient.id: $root_client_id #base64_root_client_id\n  client.secret: $root_client_secret #base64_root_client_secret\n  database.url: $database_host_connection\nkind: Secret\nmetadata:\n  name: hydra\n  namespace: user\ntype: Opaque\n```. So in order to deploy hydra and idp I need to run:\nkubectl create -f hydra.yaml\nkubectl create -f idp.yaml\nkubectl create -f ingress.yaml\nkubectl create -f hydra-secret.yaml # For hydra ingress and client ids/secrets\nkubectl create -f idp-secret.yaml # For idp ingress route\n\nI also realize that in some places I call idp by \"consent\". I call it by that in my configs and don't use \"idp\" much but tried to change it for the purposes of posting... Sorry for the inconsistencies :/.\nOne other issue that I don't think can really be solved is that Hydra and Idp can't be served on the same domain name for Ingress. The Ingress setup either uses path-based routing or domain-based routing.\nIn path-based, Idp won't find it's resources (css, js, ...) since it assumes the base URL is root. So I had no choice but to serve it on its own domain name. \nThe only drawback here is that with that the situation gets a bit more complicated due to requiring more SSL certs for HTTPS. If you're in an environment where certs are not easy to order or wildcard certs aren't possible then this will be a bit more work.\nIngress routes:\n\nFor hydra:\n\nyaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n  name: hydra\n  namespace: user\nspec:\n  tls:\n  - hosts:\n    - oauth.$cluster_domain\n    secretName: hydra\n  rules:\n  - host: oauth.$cluster_domain\n    http:\n      paths:\n      - backend:\n          serviceName: hydra\n          servicePort: 4444\n        path: /oauth2\n  - host: $host\n    http:\n      paths:\n      - backend:\n          serviceName: gatekeeper\n          servicePort: 8080\n        path: /api\n\nFor idp:\n\nyaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n  name: consent\n  namespace: user\nspec:\n  tls:\n  - hosts:\n    - idp.$cluster_domain\n    secretName: consent\n  rules:\n  - host: idp.$cluster_domain\n    http:\n      paths:\n      - backend:\n          serviceName: consent\n          servicePort: 3000\n        path: /\nThen gateway authentication is possible as follows:\n```yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    ingress.kubernetes.io/auth-url: \"https://oauth.$cluster_domain/api/proxy\" # Custom introspect endpoint on Gatekeeper\n    ingress.kubernetes.io/enable-cors: \"true\"\n  name: $ingress_name\n  namespace: default\nspec:\nSSL Settings\ntls:\n- hosts:\n- $host\nsecretName: $some-secret-ssl-cert-for-main-app\nrules:\n  - http:\n      paths:\n      - backend:\n          serviceName: $protected-service\n          servicePort: 80\n        path: /$protected-endpoint\n```. I'll try and write up something a bit more procedural and easier to follow as this is pretty messy. :). Hi @dkushner, I'm really happy I was able to help others! I think an important aspect to the deployment is that Hydra connects to a db (Postgres for us). So whenever we redeployed, most of the credentials were still available as long as the db is preserved.\nI can't remember where exactly I saw this in the docs but I believe that @arekkas recommended deploying twice. Once to get the root credentials and persisting setup in the db and a second time to erase any trace of the root credentials from any log files (such as our Docker logs).\nAs for first time deploys and storing credentials in a running cluster in general, we kept most of our secret info in Kubernetes secrets. They are only base64 encoded so normally this may have been an issue but our environment is only accessible by my team so we didn't consider this to be a huge roadblock. Here is the code used to create tokens (for demonstration purposes and since it seems like other people had asked similar questions):\n```go\npackage client\nimport (\n    \"net/http\"\nldap \"github.com/jtblin/go-ldap-client\"\n\"github.com/michael-golfi/log4go\"\nhydra \"github.com/ory-am/hydra/sdk\"\n\"github.com/spf13/viper\"\n\n\"fmt\"\n\n\"context\"\n\n\"golang.org/x/oauth2\"\n\"golang.org/x/oauth2/clientcredentials\"\n\n)\n// ClientCredentials uses the OAuth configuration to request access tokens from the OAuth Server\n// The server will assume an SSL connection\nfunc ClientCredentials(c clientcredentials.Config, hydraClient hydra.Client) func(rw http.ResponseWriter, r *http.Request) {\n    bindDn := viper.GetString(\"ldap.bind\")\n    bindPassword := viper.GetString(\"ldap.password\")\n    baseDn := viper.GetString(\"ldap.base\")\n    host := viper.GetString(\"ldap.host\")\n    port := viper.GetInt(\"ldap.port\")\nlog4go.Info(\"Connecting to LDAP Server: ldaps://%s:%d\\nWith \\tbind: %s\\n\\tbase: %s\", host, port, bindDn, baseDn)\n\nldapClient := &ldap.LDAPClient{\n    Base:               baseDn,\n    Host:               host,\n    Port:               port,\n    UseSSL:             true,\n    InsecureSkipVerify: true,\n\n    BindDN:       bindDn,\n    BindPassword: bindPassword,\n    UserFilter:   \"(&(cn=%s)(objectClass=User)(!(objectCategory=Computer)))\",\n    GroupFilter:  \"(memberUid=%s)\",\n    Attributes:   []string{},\n}\n\nreturn func(w http.ResponseWriter, r *http.Request) {\n    log4go.Info(\"Authenticate\")\n\n    r.ParseForm()\n    username := r.FormValue(\"username\")\n    password := r.FormValue(\"password\")\n\n    if username == \"\" || password == \"\" {\n        log4go.Error(\"No username or password provided\")\n        w.WriteHeader(401)\n        return\n    }\n\n    ok, _, err := ldapClient.Authenticate(username, password)\n    if err != nil {\n        log4go.Error(\"Error authenticating user %s: %+v\", username, err)\n        w.WriteHeader(500)\n        return\n    }\n    if !ok {\n        log4go.Error(\"Authentication failed for user %s\", username)\n        w.WriteHeader(401)\n        return\n    }\n\n    defer ldapClient.Close()\n\n    accessToken, err := c.Token(context.Background())\n    if err != nil {\n        w.WriteHeader(500)\n        log4go.Error(\"Couldn't get a token: %s\", err.Error())\n        return\n    }\n\n    w.Header().Set(\"Content-Type\", \"application/json\")\n    w.Write([]byte(translateToken(accessToken)))\n}\n\n}\nfunc translateToken(tok *oauth2.Token) string {\n    return fmt.Sprintf({\"token_type\":\"%s\",\"expires_in\":\"%s\",\"access_token\":\"%s\"},\n        tok.TokenType,\n        tok.Expiry,\n        tok.AccessToken)\n}\n```. Sorry I didn't mean to be rude, I'm more confused than anything. I was hoping you might be able to clear up some of that... Been banging my head against the wall for a little while now :/. When performing client credentials the sub is the same as the client id right? \nSo maybe I'm more confused about the flows themselves. If I use authorization code flow then can I get the username as the subject?. Ok thank you so much. I'm going to close for now. I will also provide some code for others if they end up in a similar situation once I'm done this!. I came across #253 earlier but it still seems to fail when I put in a anonymous public key policy.. I had a similar issue in the past with our own pipeline. We run a go server that connects to Hydra and is configured with the client id/secret for introspect.\nI implemented the following pipeline for it (in gitlab):\n1. Builds a static binary and caches it for remaining steps\n2. Unit tests are run on the codebase\n3. API tests are run on this cached binary (using Postman test specs). We build using Docker DinD (Docker inside Docker) then we push to our docker repo. \n4. Deploy to Kubernetes using a Docker-inside-Docker build.\nThe final result comes out to a 6 Mb static binary. The only issue is if you have to contact https urls then you also need to include ca-certificates in the Docker image.\n```yaml\nstages:\n  - build\n  - test\n  - docker_build\n  - deploy\nVerify Build: \n  artifacts: \n    paths: \n      - assets/\n      - vendor/\n      - gatekeeper\n    untracked: true\n  except: \n    - tags\n  image: \"golang:1.7.4\"\n  script:\n    - go get github.com/Masterminds/glide\n    - glide install -v\n    - CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo --ldflags=\"-s\" -o gatekeeper\n  stage: build\n  tags: \n    - golang\nUnit Test:\n  image: \"golang:1.6.0\"\n  script:\n    - go test -race -cover $(go list ./... | grep -v vendor)\n  stage: test\n  tags: \n    - golang\nAPI Test:\n  image: \"uadevnet/docker-newman:latest\"\n  script:\n    - sed -i -e \"s/{{USERNAME}}/$USERNAME/g\" assets/postman/tests.json\n    - sed -i -e \"s/{{PASSWORD}}/$PASSWORD/g\" assets/postman/tests.json\n    - mkdir -p /etc/ssl/certs\n    - cp assets/ca-certificates.crt /etc/ssl/certs/\n    - ./gatekeeper &\n    - SERVER_PID=$!\n    - sleep 10\n    - /usr/bin/newman --collection=\"assets/postman/tests.json\" --environment=\"assets/postman/environment.json\"\n    - kill $SERVER_PID\n  stage: test\n  tags:\n    - golang\nBuild Image:\n  image: \"docker:latest\"\n  script:\n    - docker build -t ${CI_PROJECT_NAME} . 2>&1 | tee build.log\n    - ID=$(tail -1 build.log | awk '{print $3;}')\n    - docker login --username=\"\" --password=\"\" $docker_repo\n    - docker tag $ID \"$docker_repo/${CI_PROJECT_NAME}:latest\"\n    - docker push \"$docker_repo/${CI_PROJECT_NAME}:latest\"\n  services:\n    - \"docker:dind\"\n  only: \n    - master\n  stage: docker_build\nDeploy to SUT:\n  variables:\n    SPREAD_DIR: $CI_PROJECT_DIR/assets/kubernetes\n    KUBECFG_SERVER: \"https://kubernetes_server\"\n    KUBECFG_CERTIFICATE_AUTHORITY: /certs/kubernetes.ca.crt\n    KUBECFG_CLIENT_CERTIFICATE: /certs/kubernetes.kubecfg.crt\n    KUBECFG_CLIENT_KEY: /certs/kubernetes.kubecfg.key\n    KUBECFG_TOKEN: $token\n  stage: deploy\n  image: redspreadapps/gitlabci\n  only:\n    - master\n  script:\n  - null-script\n  tags:\n    - kubedeploy\n```\n```Dockerfile\nFROM scratch\nMAINTAINER Michael Golfi michael.m.golfi@gmail.com\nADD gatekeeper /\ncurl -o ca-certificates.crt https://raw.githubusercontent.com/bagder/ca-bundle/master/ca-bundle.crt\nADD assets/ca-certificates.crt /etc/ssl/certs/\nCMD [ \"/gatekeeper\" ]\nEXPOSE 8080\n```. No problem, glad I could help!. Sorry, meant to respond much sooner.\nI think you could pretty easily switch to a scratch image, is there a reason why you'd prefer alpine over scratch?\nSpeaking of scratch, I created a blank Ubuntu 16.04 VM, installed golang 1.7.4, installed docker and ran the following commands:\n```bash\ngo get github.com/ory/hydra\ngo get github.com/Masterminds/glide\ncd $GOPATH/src/github.com/ory/hydra\nglide install\nCGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo --ldflags=\"-s\" -o hydra\nmkdir ~/build\nmv hydra ~/build\ncd ~/build\nwget https://raw.githubusercontent.com/bagder/ca-bundle/master/ca-bundle.crt\nCreate following Dockerfile\nsudo docker build -t michaelgolfi/hydra .\n```\n```Dockerfile\nFROM scratch\nADD hydra /hydra\nADD ca-bundle.crt /etc/ssl/certs/ca-certificates.crt\nCMD [ \"/hydra\", \"host\" ]\nEXPOSE 4444\nbash\nubuntu@default:~/build$ ls -l\ntotal 11060\n-rw-rw-r-- 1 ubuntu ubuntu   261889 Mar 12 19:00 ca-bundle.crt\n-rw-rw-r-- 1 ubuntu ubuntu      123 Mar 12 19:01 Dockerfile\n-rwxrwxr-x 1 ubuntu ubuntu 11057568 Mar 12 18:57 hydra\nubuntu@default:~/build$ sudo docker images\nREPOSITORY           TAG                 IMAGE ID            CREATED             SIZE\nmichaelgolfi/hydra   latest              f6cd972dc84a        8 minutes ago       11.3 MB\nubuntu@default:~/build$ sudo docker run -it michaelgolfi/hydra\nINFO[0000] DATABASE_URL not set, connecting to ephermal in-memory database.\nWARN[0000] Expected system secret to be at least 32 characters long, got 0 characters.\nINFO[0000] Generating a random system secret...\nINFO[0000] Generated system secret: 2/(-!5t?CExHdPeFGkZfLqfUD_Px).n=\nWARN[0000] WARNING: DO NOT generate system secrets in production. The secret will be leaked to the logs.\nINFO[0000] Key pair for signing hydra.openid.id-token is missing. Creating new one.\nINFO[0003] Key pair for signing hydra.consent.response is missing. Creating new one.\nINFO[0007] Key pair for signing hydra.consent.challenge is missing. Creating new one.\nWARN[0010] No clients were found. Creating a temporary root client...\nINFO[0010] Temporary root client created.\nINFO[0010] client_id: 18779eff-3873-4576-8af8-f6613c8d84be\nINFO[0010] client_secret: r)TIer/zKs._cWPH\nWARN[0010] WARNING: YOU MUST delete this client once in production, as credentials may have been leaked in your logfiles.\nWARN[0010] No TLS Key / Certificate for HTTPS found. Generating self-signed certificate.\nINFO[0010] Setting up http server on :4444\n```\nOff first glance it seems to work correctly as intended... I pushed the image to michaelgolfi/hydra if you want to test it out further.. @arekkas If you run into any trouble let me know. \nI think the steps above from our pipeline should essentially do the trick though I'm not familiar with Travis and that is written for Gitlab.. ",
    "rdeusser": "@arekkas Does an LDAP connector still need to be written?\n. ",
    "sbani": "My suggestions what should be done here:\nAlpine and/or debian\nCreate an image based on alpine golang:1.6-alpine and debian golang:1.6\nInfo from the golang image\n\nThis variant is highly recommended when final image size being as small as possible is desired. The main caveat to note is that it does use musl libc instead of glibc and friends, so certain software might run into issues depending on the depth of their libc requirements.\n\nImage sizes\n$ sudo docker images -a\nREPOSITORY             TAG                 IMAGE ID            CREATED             SIZE\ngolang                 1.6                 2529f72145a7        8 days ago          744 MB\ngolang                 1.6-alpine          c40da134e949        4 weeks ago         238 MB\nAll in one package\nShould we create an \"all in one package\" with postgres? Could be useful for testing purpose like the vagrant machine is.\nBuild and push\nOne task is to build and push the image with the CI server (travis)\nDocker compose\nCreate a compose yaml to run database and hydra with one command. I don't know how to \"hide\" the database passwords - by environments vars?\n. The docker best practice doc says:\n\nIn almost all cases, you should only run a single process in a single container.\n\nThat's why we should create multiple containers for the different executables.\n. I will wait for #67 and rebase here. \n. ",
    "ng-vu": "Could you list all Hydra APIs (implemented or will be implemented when #62 is merged) in Apiary? This would help us decide whether Hydra is fitted to our system. Thank you a lot :)\n. How about your estimation? How long until #62 to be merged?\n. ",
    "waynerobinson": "For time-based OTP, isn't this really a responsibility of the challenge app?\nOr are you planning on storing a number of per-subject keys/secrets in the DB these can be generated against because you want to be the source-of-truth for all things secure (apart from the subject's password)?\n. For standard, regular key rotation that are meant to prevent key abuse, I would recommend a period of time where the old and new keys could be used. Basically the maximum expiry period for anything that would've been encrypted or signed with the old key.\nIf an existing key has been compromised, it should be replaced instantly and anything encrypted with the old key should be considered unsafe anyway and discarded. Locking during the replacement process would be nice, but ultimately there is going to be failing messages at some point if you're not respecting the previous keys anyway.\n. Yeah, the Ruby world lacks tools to work with JWK. I had never even heard of the format until Hydra.\nLiterally the only library we were able to find is https://github.com/potatosalad/ruby-jose and it lacks users (it's only been downloaded about 5,200 times\u2026\u00a0nothing given how often gems end up being downloaded in the lifecycle of even a single product).\nThis has been fine for our purposes, which are basically to convert the JWKs into PEMs for use in OpenSSL and other libraries. It would be good if we could just get an efficient (hopefully cached) version of the PEM from Hydra itself as required. Especially if we assume we should always get the keys from Hydra for a future where key rotating or revocation may happen. \n. Would be especially useful to control delivery by load-balancers like https://aws.amazon.com/elasticloadbalancing/applicationloadbalancer/ as well as providing some extra levers for doing things like clearing caches, etc.\n. Basing licensing on system resources is fine a for something like a DB because usage of it is basically defined by resource use. But for an authentication engine, that doesn't really sound like it fits.\nWe really like the idea of this being open source and, as mentioned privately, would be happy to pay for support of this as well as ad-hoc consulting work to improve the system itself.\nOther open source products (https://github.com/mperham/sidekiq for example) will have a freemium-like model based on features. Mike has Pro and Enterprise levels for his product, but keeps everything else open source. He also provides absolutely no support for the open-source version and that model works for him.\nIf you wanted to go Freemium, something like the Warden policy-based features could be an interesting upsell as they're mostly separate from the core authentication layer.\nIf you wanted to use a resource-based model, may I suggest something like active user count (e.g. https://auth0.com/pricing). This seems to fit better with the core product.\n. Is this to explicitly revoke tokens (e.g. by logging out)? Is there currently a revocation list for access tokens in Hydra somewhere that works with the Warden and OAuth Identity endpoints?\n. Does refreshing a token revoke the previous one? This is how other providers I've used work, but unsure as to whether that's the standard.\n. Just to confirm, the intention is to change the keys to all the hydra.* prefixed forms?\n. Auto-generated libraries is probably a good starting point when there is nothing else. But they usually don't follow the form you'd expect from the language you're using them within.\nI don't want to make any promises for myself and @andrewmcnamara but we might be able to release what we're creating for Ruby as open-source. Although not for our first implementation which is a combination of both it being more tightly wound in our existing application and us still getting our heads around the exact implementation details here.\n. Specifically, allow clients to vary the query parameters of URLs.\n. Nope. One token is fine, as is a simplified response that basically\nincludes an OK/Fail for each check.\nOn Friday, 23 September 2016, Aeneas notifications@github.com wrote:\n\nGood idea regarding policies, but do you really need to checking for\nmultiple tokens per request?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/issues/264#issuecomment-249108865, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAG4pswiVOHGfIu8e7DWRZmpNrtM-vZ0ks5qs2k6gaJpZM4KEg3t\n.\n. One result per resource/action check in an array.\n\nOn Friday, 23 September 2016, Aeneas notifications@github.com wrote:\n\nok, what would the default behaviour be, allow access if one of the\nresources is allowed? what if one policy explicitly is set to deny?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/issues/264#issuecomment-249110367, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAG4pgcUX6GgtD6rJKsVgHvFB1QobmOtks5qs2wwgaJpZM4KEg3t\n.\n. No, this is just a nice to have for now. We can make do without. We're still working through the best way to get Warden to work in our app and we can always build our client interface to be easily upgradable to be able to request multiple policies later.. There are a number of DB backends that could be good to use.\n\nRedis is a big, established, mature key/value store with some very nifty atomic operations around pub/sub, bitmaps, set and list management and is very, very fast (100-700k QPS on commodity hardware). It's not just a caching store. It also has the benefit of being familiar to a large number of developers and devops and may already be part of a systems existing infrastructure.\nPostgres/MySQL are also established players and are very mature and reliable. They are full RDMSes though and may be slower, but again from a developers perspective, they will probably have one of these already in use. The less education you have to do of new developers, the more likely they are to pick up and use your library.\nI personally think the in-memory pub/sub of changes to tokens is wasted effort and will cause issues in production without making a significant difference to overall performance/throughput.\nPub/sub will always end up with a delay between the write and propagation to all the other Hydra instances. If you're running more than one Hydra instance, this propagation delay will cause a non-insignificant amount of token verification errors unless the load balancer maintains state (more wasted memory) or falls back to a DB query on a fail (even more complex caching engine). \nAlso, if you're effectively keeping an in-memory data cache in each Hydra instance, it needs to be running on hardware big enough to hold (at a minimum) all current, unexpired access and refresh tokens. This puts some significant limits on the scalability of Hydra as you basically have to scale each instance to be as big as your DB instance.\nFinally, you need to ask, is Hydra a great authentication engine\u2026\u00a0or is it a caching/DB engine. Redis, Postgres, MySQL, etc are all tools purposely built to handle large quantities of data safely, efficiently and be as performant as possible. Does Hydra really need to replicate something like this to be a great authentication engine?\n. Ick. ODBC is lowest common denominator as database drivers go and using it on anything but Windows can be problematic. \nIf you want to simplify DB access within Go, it surely has one or more libraries that support multiple DB backends. This would be better than ODBC, which is more of a protocol abstraction and tends to have very poor performance. \nAlso, I think RDMS is too heavy for Hydra (although it's a good, simple starting point) and that a key/value store like Redis is all that's necessary anyway. \n. That sounds much better because ODBC itself is\u2026 not good. :-p\nIf you've got any other choice that is. \n. There are a lot of good notes in there on Redis. Using a persistence slave is a little strange but I understand why they did so in their implementation. \nI may have over-played the durability aspect. In our experience we have never once had a Redis process terminate uncleanly or had to deal with hardware failure causing data loss. However, these are obvious possibilities. \nBut you have to consider that you're talking about microseconds between a Redis instance dying or becoming unavailable and it's data not persisting to storage. These are both incredibly rare events and incredibly unlikely to have unpersisted data when they happen. \nYou need to consider your use case too. Even if there is data lost, what is the end-user impact? If a token is lost, the user is treated as unauthorized and must recomplete that process. This might be slightly unexpected, but it's hardly unprecedented or especially jarring to find out you've been logged out. \nI wouldn't want to store my user accounts or three preferences in Redis, and we don't. We don't personally use Redis for our queue backend because we need for durability and guarantees deliverability of our messages because I'm a little insane about it. \nBut access tokens are largely ephemeral anyway. If we lose one, I don't care, we'll just regenerate. And the probability of losing one in a durability event anyway that I care even less. \n. Redis has glob-matching behavior with http://redis.io/commands/scan. It's not regex though. \nPolicies may make some sense to store locally because they're not really data as much as they are configuration (although our use case will end up with dozens of custom policies per user). \n. Some comments about Redis and those other datasets. OAuth2 clients, policies and keys change so rarely that the likelihood of a persistence issue (something that's already very rare) effecting one of these types of writes may as well be considered statistically impossible. \n. One other thing to note. RethinkDB as a database is going away. But Rethink itself is open source. We don't know what type of community support will spring from the death of the company yet, but it doesn't mean you have to abandon support altogether. \n. Maybe it's a bias I have coming from the Ruby world, but it's used all the time here for primary-ish data stores. No one would use it to back a billing system. But high-volume messaging and the like are powered all the time by Redis. And apart from Clients and Policies, the data Hydra is primarily dealing with is largely emphemeral. \n. Also see #289 regarding the actual required authentication mechanism for this endpoint being different from our discussion earlier today.\nAnd #290 regarding id_ext only ever being included in the OpenID token and never when requesting data again from Hydra.\n. So has this been changed to allow the token to be able to used to authenticate itself (and return at_ext values)?\nThis is quite a common operation for us so we'd like it to be as fast as possible. \nCurrently, we have to get a client_credentials token (with any scope, including blank) to be able to be able to validate the access_token.\n. No problem.\nSo any token will be allowed to validate others?\nOn Monday, 10 October 2016, Aeneas notifications@github.com wrote:\n\nSo has this been changed to allow the token to be able to used to\nauthenticate itself (and return at_ext values)?\nThe subject == token.Audience check was removed, apart from that nothing\nchanged, as at_ext was already returned by introspection and RFC7662\nrequires a separate token:\nTo prevent token scanning attacks, the endpoint MUST also require\nsome form of authorization to access this endpoint, such as client\nauthentication as described in OAuth 2.0 [RFC6749] or a\nseparate OAuth 2.0 access token such as the bearer token described in\nOAuth\n2.0 Bearer Token Usage [RFC6750]. The methods of managing and\nvalidating these authentication credentials are out of scope of this\nspecification.\nThis is quite a common operation for us so we'd like it to be as fast as\npossible.\nThis will depend on the latency introduced by the store, the operations in\nhydra take only a few nanoseconds.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/issues/289#issuecomment-252552007, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAG4pm1tRh1TjcaSQj3Uu4cNAlqz51AUks5qyerqgaJpZM4KQrC0\n.\n. It's more the stuff that's in the ID token is also relevant to be used\nelsewhere. For us, it's a role_id which we need in the final token\nexchange, but also when we verify the token afterwards. I don't understand\nwhy it wouldn't be included afterwards.\n\nWhat is your use case for id_ext values that wouldn't be useful to a normal\ntoken introspection?\nOn Friday, 7 October 2016, Aeneas notifications@github.com wrote:\n\nThe reasoning behind this is that the id token is self-contained but the\naccess token is not. If you are allowed to receive an id token, you can\nextract the information from it. The access token has a different scope\nwhich is delegation of authorization. As that token is not self-contained,\nthe information is provided at the endpoints.\nThe id token is, in general, just a flow to let third parties use OAuth2\nfor delegation of authentication, without being vulnerable to token\nsubstitution attacks. I don't think that the id token should be used to\ntransport information not relevant to this task.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/issues/290#issuecomment-252193118, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAG4phQjZjG3fpnWIEXsirbmx2_115sKks5qxg_hgaJpZM4KQrEx\n.\n. I understand. But then how do I access things like email, profile pics, etc\nfrom the internal apps that just have the access token and not the open ID\none without having to manually find that info itself. I'm not saying we\ncouldn't, but we have to verify the token anyway and always, may as well\ninclude the data again in that.\n\nAlthough I can partially understand in that statement I just made why you\nwouldn't want to. Because of size/performance constraints.\nYou can close this issue if you like. I now understand the design decision\nand will take that into account when we submit some documentation PRs. ;-)\nOn Friday, 7 October 2016, Aeneas notifications@github.com wrote:\n\nUsually, everything that is included in the id_ext claim should have the\nconsent of the user. In case of roles this could be a scope like\nuser.roles.read. ID Tokens usually have information like email, profile\npicture, name which are can be used to set up a new account in the third\nparty app, if the subject of the id token is unknown.\nThink of it as something that you would do if you use log in with google.\nIt will give you some basic information that you can use in your log in or\nsign up endpoint.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/issues/290#issuecomment-252210498, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAG4pvbMWV4ws7uIBk7LkcKaCSXqP9Rlks5qxh-KgaJpZM4KQrEx\n.\n. Our use case is preventing issues with backwards compatibility based on what we've implemented. \n\nThe existing version uses aud, not client_id as they are practically the same thing. \nAnd it's the way we identify a client credentials token from a standard auth one, because these fields match.\nAnd what spec?\nIf you're going to use the JWT fields of iat, exp, etc. Mixing in the non-JWT client_id when aud represents the same thing is very strange.\n. But you use the Client ID as the AUD in the OpenID token now right? So the behaviour is inconsistent. And you really need some way of marking an access token as a client credentials (subject-free) version.\n. Adding the aud claim would be great! \nSorry, didn't notice that above.\n. Our use case is preventing issues with backwards compatibility based on\nwhat we've implemented.\nThe existing version uses aud, not client_id as they are practically the\nsame thing.\nAnd it's the way we identify a client credentials token from a standard\nauth one, because these fields match.\nOn Monday, 24 October 2016, Aeneas notifications@github.com wrote:\n\n@andrewmcnamara https://github.com/andrewmcnamara per spec, client_id\nis the right value. we could add the aud claim too though. What's your use\ncase?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/pull/293#issuecomment-255659435, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAG4poWcAlC_GF-gBSu_a6T4-Njawyilks5q3FJsgaJpZM4KSFxV\n.\n. And what spec?\n\nIf you're going to use the JWT fields of iat, exp, etc. Mixing in the\nnon-JWT client_id when aud represents the same thing is very strange.\nOn Monday, 24 October 2016, Wayne Robinson wayne.robinson@gmail.com wrote:\n\nOur use case is preventing issues with backwards compatibility based on\nwhat we've implemented.\nThe existing version uses aud, not client_id as they are practically the\nsame thing.\nAnd it's the way we identify a client credentials token from a standard\nauth one, because these fields match.\nOn Monday, 24 October 2016, Aeneas notifications@github.com\n<javascript:_e(%7B%7D,'cvml','notifications@github.com');> wrote:\n\n@andrewmcnamara https://github.com/andrewmcnamara per spec, client_id\nis the right value. we could add the aud claim too though. What's your use\ncase?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/pull/293#issuecomment-255659435, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAG4poWcAlC_GF-gBSu_a6T4-Njawyilks5q3FJsgaJpZM4KSFxV\n.\n. Is the scope/s key also different?\n\n\nOn Monday, 24 October 2016, Andrew McNamara notifications@github.com\nwrote:\n\n@arekkas https://github.com/arekkas Token introspection no longer\nreturns the \"aud\" field which is part of the JWT spec. Instead it returns a\nclient_id field. Can the introspect response be change to include \"aud\"?\nCurrent Hydra (version 5)\nhydra token validate TBpyZhWoJGB7xvuyPzL2jZPuEazYnmdm7wYfG32k3qc.mr3OtSkj90d_lf584s4dktwlO7BB0oNnkq6FNI072zk\n{\n    \"sub\": \"f13d49c3-b61d-4fbc-b0a7-048a5f138115\",\n    \"scopes\": [\n        \"hydra\"\n    ],\n    \"iss\": \"hydra.localhost\",\n    \"aud\": \"f13d49c3-b61d-4fbc-b0a7-048a5f138115\",\n    \"iat\": \"2016-10-24T14:23:57.897+11:00\",\n    \"exp\": \"2016-10-24T15:23:57.897+11:00\",\n    \"ext\": null\n}\nNew Hydra\nhydra token validate \"qLmMAnvRtXeGs3fvKYqtsv9XqKeTe3ORZ0aDmZ6PKN4.fMIFVa7LpFYXwZ61CI_WsWNEbrLlKBsnOIgBCI6IT5g\"\n{\n    \"active\": true,\n    \"scope\": \"hydra\",\n    \"client_id\": \"828c4958-4359-49d6-83be-02e235841c64\",\n    \"sub\": \"828c4958-4359-49d6-83be-02e235841c64\",\n    \"exp\": 1477280498,\n    \"iat\": 1477276899\n}\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/pull/293#issuecomment-255642021, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAG4psqUOWje53jMYJ7WncyIu0ux-DCRks5q3CmJgaJpZM4KSFxV\n.\n. Discovered this has to do with the JSON column type only being supported in MySQL 5.7. \n\n5.5 & 5.6 are by far the most popular versions of MySQL in production. I thought you were going to steer away from using JSON column-types (at least in MySQL) because of this.\n. Also, the error is a little bit weird as it doesn't seem to raise anything when the CREATE TABLE script runs, only when it tries to insert data into a non-existent table.\n. Had a brief look through your queries too\u2026\u00a0you don't seem to be using anything JSON-specific in your SQL, so a LONGTEXT (or MEDIUM or TEXT) field should be fine for storing this data.\n. Does this change the requirement for JSON columns too that are only supported in MySQL 5.7+?\n. \ud83d\udc4c\n. Doesn't quite work for us at the moment, but we'll make do.\n. That doesn't work in all cases. For example, our app has self-service custom branding. To avoid users ever seeing our internal Hydra domain flash, it and each of our services need to exist on the customer's own (single) domain.. Having a sensible default for MaxIdleConnections is a good idea.\nI don't know what the definition of sensible is though, LOL. 10 idle connections? \nBeing able to override with an environment variable would be even better.\nWhilst you're in there with config, being able to set MaxConnections would be good too. Including maybe a maximum sensible default for this too (based on a reasonable expectation about concurrency \u2026\u00a0like cores * 2 or something).. \ud83d\udc4c. If you want to stay on-spec, hosts aren't case sensitive and paths are. \nAlthough you're only making it case-insensitive for the comparison part. The actual abuse window for a case-sensitive versus insensitive path is so tiny that I wouldn't think it was worth thinking about. And changing it will prevent future questions like these when people (Windows users in particular), fat-finger paths and wonder why there is an error. :-). It's fine for now. We have a hot fix in our own app that should prevent most of these issues at our end. . Sorry it's taken me so long to look at this.\nEven though we have a current working implementation, we occasionally run into some unusual edge-cases related to them.\nHowever, we actually rely on some info in the challenge token for passing information to the consent app from our load-balancer, namely we need to extract the domain from the redir portion to know which partner the authentication is for. \nAs long as there is some way to continue to pass information to consent app (say as part of the REST request to query that info), I'm for the change as it has the potential to simplify some of the hoops we have to jump through (although some of our use-cases are quite unique) to keep the challenge token around.\n. Looks like something that might be solvable by a relatively simple method proxy: http://artem.krylysov.com/blog/2018/01/18/porting-go-web-applications-to-aws-lambda/. ",
    "janekolszak": "yeap, forgot about glide :)\nThanks\n. You could add the info here: https://github.com/ory-am/hydra/blob/master/README.md\n. and saved I guess in case hydra is restarted\n. hydra clients create covers all use cases. I could create the IdP client and possibly some other clients for test purposes (for example the Resource Provider). \nBut hydra host would be nice as well. There would be only one client for IdP.\n. Please don't make it interactive\n. Command line app has to flush stdin before asking for any security related data, so this option is out.\nPassing as an argument will be visible in ps, so it's out.\nEnvironment variable will be visible in .bash_history, also out.\nThe only option I see is to pass a configuration file with a list of clients to create.\n. You can set the right permissions for this file too. You can also remove it after your're done with creating clients. \nWhat if I need to create couple of clients? \nEnv variable would have to be a list.\nThe configuration and env variable will be on your local laptop anyway. So I guess security isn't that important. Also this feature isn't for production, it's only for debugging and examples. I'd even allow passing the password via command line argument. \n. What's the format of   ?\n. Example in Go: https://github.com/janekolszak/hydra-idp-go\n. Sure, take a look. I'll implement some production code using this example so all comments are welcomed.\n. What's a refresh token with an offline scope?\n. I think it's OK if you support only one, the most popular key format. Users can always convert their key with openssl.\n. Also automatically opening the browser is annoying. It should be disabled by default, not the other way around.\n. yes, hydra token user even has an option to switch this off. I think it would be better to print a curl command: curl -Lkv \"address\"\n. I take this dockerfile and build it with --no-cache and get:\n```\ndocker-compose build --no-cache hydra\nBuilding hydra\nStep 1 : FROM golang:1.6\n ---> 78e3813eb6dd\nStep 2 : RUN go get github.com/Masterminds/glide\n ---> Running in ae84e92757b1\n ---> 8a9b54e5ae9b\nRemoving intermediate container ae84e92757b1\nStep 3 : RUN go get github.com/ory-am/hydra\n ---> Running in 43992fde66cb\ngithub.com/ory-am/fosite/token/jwt\nsrc/github.com/ory-am/fosite/token/jwt/jwt.go:29: cannot use claims.ToMap() (type map[string]interface {}) as type jwt.Claims in assignment:\n    map[string]interface {} does not implement jwt.Claims (missing Valid method)\nERROR: Service 'hydra' failed to build: The command '/bin/sh -c go get github.com/ory-am/hydra' returned a non-zero code: 2\n```\nSo it's go get github.com/ory-am/hydra that fails.\n. yeap, now it works. Thank you!\n. Well if your container has only Hydra inside then you're right.\n. You mean scopes? \n. Oh, I thought that's the \"hydra\" scope. Of course I need those rights to be added to the imported clients. Those are the clients for the IDP instances.\nhydra host --idp idp_clients.json\nand idp_clients.json:\n[\n{ client_1},\n{ client_2}\n]\nAlll other clients that don't need admin rights will be created with hydra clients import. \n. If this client is only described by id/secret then a file is pointless and parameters will leak via /proc.\nSo maybe good old env variable checked when client is starting? \n. - What's the base64 function? You mean base64 of id:secret? \n- hydra host are the scopes?\n. Oh yes, sorry. Looked like a peculiar env export :)\nIt's ok. I will define that in docker-compose file.\nI don't think accepting binary passwords is worth the extra function invocation. \nPeople will get confused (yet another step, just to pass the temporary, most probably developer credentials)\n. And with base64() I won't be able to fit this into docker-compose file...\n.  I think all database code should be in a separate folder, in separate sql scripts. All tables in one place.\nFirst script would be 001-create-db.sql. When there's an update we add a script 002-some-update.sql\nIn order to create the database hydra would:\n- create transaction\n- run scripts in order\n- commit\nIn order to update the database schema hydra would:\n- create transaction\n- run scripts from the updated version to the latest\n- commit\nIf hydra does this automatically we get rid of the problematic (for user) schema updates.\n. You could create a separate tag or a branch for releases and maybe use this https://docs.travis-ci.com/user/deployment/releases ?\n. Consul has a go library and many kinds of health checks:\nhttps://www.consul.io/docs/agent/checks.html#TTL\n. yeap, confirmed\n. no, I have not. Setting \"client_secret\" will do the trick?\n. Then documentation needs fixing: http://docs.hdyra.apiary.io/#reference/oauth2/manage-the-oauth2-client-collection/create-a-new-oauth2-client\nAdding the \"client_secret\" field in the example would do the trick. \n. I think this log contains the bad response\ntime=\"2016-08-20T10:40:17Z\" level=info msg=\"completed handling request\" measure#web.latency=186782098 method=GET remote=172.23.0.1 request=\"/oauth2/auth?client_id=wta-site&redirect_uri=https%3A%2F%2Flocalhost%2Ftestoidc%2F&response_type=id_token%20token&scope=openid%20all&state=995787dc2625419387b4ffd90d0bdab7&nonce=a96fca455a4644eaadd2847f7e2d84d6&consent=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJ3dGEtc2l0ZSIsImV4cCI6MTQ3MTY4OTkxNywiaWF0IjoxNDcxNjg5NjE3LCJzY3AiOlsib3BlbmlkIiwiYWxsIl0sInN1YiI6IjY2ZWM5Njc5LWNmZDgtNDI0My05ZmEyLTQ4ZTVjOTI5YzFjMiJ9.QT38PSu0PU5i1qoQtXWAU3Y8-hUMuVF1Uw-I9DCpU88pYD-ndtrIrMm4ksyeecY3JibPHizcBb6QOeFHR3g1AKGiXl76wY6LsQwW7RXxCuNom9WWXOMZD0CpSxR_nlaiqmhnxDlPG4NiyHTr415p325wGZ7S2eUkNtDaXeCDgTijPCe8fz08YliCk6NgMyL0mXHYk3gyjaYybV8ulCPtYKLUz6vsfUWkojbTKVfgJluX1Xz62c8t53_1ckzfw1YPY67wGGr1tlDJTTOucMxb1QqDc-lVR0jfC0rjqLhzQzJOsmwjGcybrHH6-TuEGAr6s_eZj-U0GTQX46eh9QN0rOEMG8Y5YkMoUgQQA8GFaTFB0ICvBCuQgYMJ9Gr8CDvOWI2pQ0jknsZlUjt4Eh6Pb4IqZzpWnNQnyBQ76E_HjIcm9fpo7iyQzslz-80n9vHdhBnunm1xkmHR0lDCfR608J7Ko5tmrhMJwUgC_MHo7PehKEif35XkNYBaRPZVFTb4t5K0UxalMt6S6uTyEsjD7uzQUDSYdnM_Mj4zcT47obCt_VCC0amr1NpY6-yPQQu05aIcnJv62FBCTLzpU85ywZHiWUE7GYNFAKll1b0GJX1pB8HCRrFgQueSlKDmjik31oeM7dvw_fHj6DhArDFUMQgRYSk6tpfGg_DLSTyKQOo\" status=302 text_status=Found took=186.782098ms\n. Decoded with https://jwt.io/\njson\n{\n  \"alg\": \"RS256\",\n  \"typ\": \"JWT\"\n}\n{\n  \"aud\": \"wta-site\",\n  \"exp\": 1471689917,\n  \"iat\": 1471689617,\n  \"scp\": [\n    \"openid\",\n    \"all\"\n  ],\n  \"sub\": \"66ec9679-cfd8-4243-9fa2-48e5c929c1c2\"\n}\nand signature isn't valid\n. Sorry for that. I can't find what's the id_token returned by hydra.\nThe id_token validation fails here:\nhttps://github.com/IdentityModel/oidc-client-js/blob/178d19f279bfeb39915db9fc443623605130da33/src/ResponseValidator.js#L246\n. If other OIDC providers do this it would be nice to have as well. \n. What about key rotation? Hydra manages that any way?\n. https://github.com/IdentityModel/oidc-client-js/issues/96\n. Used the oidc-client-js library (that I used before) https://github.com/IdentityModel/oidc-client-js\n$ hydra token client --skip-tls-verify\nWarning: Skipping TLS Certificate Verification.\nVCudVUydX2SlSPYXzIZGlmSNumTeWvVFBOmbIgMFmys.gbDLk1SF_hz0Iaj3eEmJGnjyswKEnqSyynAmOJpmr_c\n. @faxal No, clients are different. \nGetting keys from hydra has to work with client credentials, the idp library uses it.\n. Confirmed. Temporary solution is to serve the unprotected key from RP, e.g.:\n``` go\n    jwk, err := model.HydraClient.JWK.GetKey(\"hydra.openid.connect\", \"public\")\n    if err != nil {\n        // ...\n    }\nc.JSON(http.StatusOK, jwk)\n\n```\n. Confirmed. \nI can verify when it's solved. \n. This API is a mapping between local userid and remote userid. \nThis mapping would be used in the IdP, keeping this in hydra is just one request more for IdP.\n. Maybe just rely on GO's odbc driver and let users decide what they want?\n. I don't think hydra would benefit from nosql database. Using odbc would make force hydra to use simple queries. This would make writing storages for mongo etc. very easy.\nThere are some comersial odbc for mongo.\n. Verified, works.. This was found when using a custom protocol name, not http/https.. I'm using response_type=code id_token\nFrom Hydra's logs:\nrequest=\"/oauth2/auth?redirect_uri=wta%3A%2F%2Fauth&scope=openid%20all&state=8f6057ae-158e-4755-8a12-20b535bf4202&nonce=b61f68bd-1cb7-448d-ae7b-e0a735574b73&response_type=code%20id_token&client_id=wta-d&consent=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJ3dGEtZCIsImV4cCI6MTQ4Mjk2ODI0NywiaWF0IjoxNDgyOTY4MDA3LCJzY3AiOlsib3BlbmlkIiwiYWxsIl0sInN1YiI6ImIzMjhjNDcyLTRmMTktNDBmNy1hODM5LWRiMGY3ZTkwYmMyMyJ9.NT4hzhQ_kdA-6K_i-bInLiHClXNy7nE6S70Tjo0asx63tfZ610gvAPQId-bxp2bc0pknzzawG_Y99fKGrjDVj99MTlaO_sTRdLrVMbxnD10LDI7Lw13ASr8nb4pVubWVyN0SIfPkvk5gHfS0nuJJWVU2o-jvpgv3T9HrJxVeSwZd3kKAyerGm6pB6i970xVV6lZx4xC73X2YLLdBgMS5j2nz694CxRgczCSW6yLCSCUKRgxQfxYfJ2GCLE_O4A417414j2uQqIxFzDZRdTQvaPU4lAFgYmE0LfsipLFzNKlPA5B4-j05gKwKAA0VW465XjDIltGGfkgY5u1uf4o1Ak-4ovcCvPmDv9r01caMzgpQj9nY-a7e3hjbgDCxPap7Yjo7moot6VlccbYtS1NE1bFQIGHD0BPjjW1RPPmHqrhlRTKrlzOvMh1qjuZcESJ5xlsECS7EOVrL--vLMQ-NXAfCEY-BRkAZkwPIyxtGe0k1ec_qij7DfCYY3ZbBUDZxU32rt98Gjx-UTLlozeWm2Z7OfTffKxx005DXJRWyEH7gL6cIH3XXMjMBkUub0K4Kc-Qr5S9L95gtoroIkfPzB4eCEWBh6ievbDoF38xuzkK4eyt9rIQIGA33pnA4uzslqncoahJtnIUG1Af1YrZNtcMt6qSYlMLfLVMHSSwdgHU\". yeap, thank you.. Maybe at_hash is also broken?. Are the prerelease builds stored anywhere?. Please reopen. The seems to persist for \"code\" response_type:\nwta://auth#code=l7KUM--gWVE2wRoQPj5D61r0byDaXdCsh5ed9SdYih4.q2mJqC4D_q-fOEjclrzOovIk8ESaSbusyFAeRrAroKU&id_token=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdWQiOiJ3dGEtZCIsImF1dGhfdGltZSI6MTQ4MzIwOTY3NCwiY19oYXNoIjoiRTBHalJvamIyVlp5UzBHYnVndFIzUT09IiwiZXhwIjoxLjQ4MzIxMzI3NGUrMDksImlhdCI6MS40ODMyMDk2NzRlKzA5LCJpc3MiOiJodHRwczovL29pZGMud29ya3RpbWVhc3Npc3RhbnQuY29tIiwibm9uY2UiOiIwNGI0OWQwYy01YTczLTQyMmMtYWViNy1jMjdkNzZjMmFjNzIiLCJzdWIiOiJiMzI4YzQ3Mi00ZjE5LTQwZjctYTgzOS1kYjBmN2U5MGJjMjMifQ.tBufjkHkwLliL5G8oMeRXMlcVHCqkTYOC3WCtfHnBW6VlNETfCIYr1IU0ivC7HnxEY8ywMzim7SrKiktO-BDZ2zGZu1ZrCKHeQ_mfPKxY1q9sFX6bLzzBZ8b6klQujXumjhjG5dxy76S-1UzdJBeC8Eum1rtke_q2nXcoTBnt1B6J7S908ihjbryo5GA9wtnDntb-uvKFkyOwx_5fwoJIcTPhi5ZTcxmJufNR7DTJX0YRtiM31eKl8TcD9aJyLFmabYnrEM55Jk1m-6RZ41sOph6YyMN-lLNd1EuDuvEDsZjpTUoB3E9wNPC1BI0muclPo2ijFFABtexyOX1oZ5LGqQDvlGH8Oz70DjfUjC0Z0B_Lu2bjjz6WKb5MKn9BpQcKXRiEpO1sWOrk94ajtozBcZ3GOKCTnQzGQUokuPJ1gKfeW1nYr2B-5BAqxNdjCZjA4_SMyjqSOljy6fN2zM-ePahBU6Qwl1S1nitaC-rko3heBduFzq9lA6BLtUHDYgYyqYilppMiCQ9tPj2B3PN02cnhpY6UtsQSJdfUTjmS8jAra1kLN9YSdW7T0Df9sJcKAgHeXnOiG5Vc6eKurMLO4Y7qMi_a6hhT3iI18WjbwTvxM9k02591ZR9KPhgMN0bjVzsSM0EbG2VobBSJBRie08DpH-ca1r4_YFctT2U6RI&state=a02cc43a-2d57-464e-ad73-a5049587ac9d. Thank you!\nBut are you sure this is the right way? I'm certain the library already works with google OIDC.\nMaybe hydra should strip the padding?. The linki https://www.npmjs.com/package/openid-client says it's certified.. And I can't find any base64url encoded values (in the docs and here:\nhttps://community.pingidentity.com/servlet/fileField?retURL=%2Fapex%2FPingIdentityArticle%3Fid%3DkA340000000Gs7WCAS&entityId=ka340000000GvdRAAS&field=Associated_File__Body__s ) that contain ==\nMaybe it's yet another thing that's undocumented but everyone does it.. This is v0.7.1.\nHow do I set the log level?. I don't know, should I check?. Are you going to prepare a release?. Client authentication failed but I can't see any client authenticating. This isn't the client credentials grant, it's the authorization code.\n( and I'm 100% the user's password is typed ok ). The solution from gitter is to add \"public\":true to the client definition.. +1. I think the easiest is to have a separate subdomain for hydra.. I only have logs from my resource owner and LOG_LEVEL=debug doesn't log anything (about those requests). Login page displayed by a native app, not the IDP web app. . Is this the Password Grant?. I think I need to change something in fosite.\nI can't find a way to get hydra Client, but I see fosite Client is available. \nhttps://github.com/ory/hydra/blob/master/oauth2/handler.go#L192. You can implement it yourself in the idp.. Hydra doesn't implement many endpoints that can be specified in this configuration, but can be implemented by your service, e.g. userinfo endpoint. \nThe simplest way in my opinion is to have one, statically hosted file with this info.. Yeah, it's work in progress. I'll use CI from time to time. Do you get a lot of spam because of that?\nThis scenario is a valid problem, but it's Bob's role not to let Mali register a malicious client. \nThere's a difference between trusted clients (Bob's desktop app, Bob's mobile app etc.) and third party clients. \nThat's why by default if there's no client_uri or it's empty the default client_uri should be used. The old behavior will be preserved, don't worry.\n. You are right, but there's this extra redirect that we could avoid. Redirects take time and Hydra already has couple.\n. There are some other options you can sleep on:\n- Switch this on, during build time\n- Switch this on with CLI parameter\nFixing this in IdP mixes the roles. Hydra should store all OIDC data. It will be much harder to break into Hydra than to break into someones IdP since Hydra get a lot of reviews.\n. OK, let's have it your way, but I still think it's overprotective. . ```\ndocker version\nClient:\n Version:      17.03.0-ce\n API version:  1.26\n Go version:   go1.7.5\n Git commit:   60ccb22\n Built:        Thu Feb 23 11:02:43 2017\n OS/Arch:      linux/amd64\nServer:\n Version:      17.03.0-ce\n API version:  1.26 (minimum version 1.12)\n Go version:   go1.7.5\n Git commit:   60ccb22\n Built:        Thu Feb 23 11:02:43 2017\n OS/Arch:      linux/amd64\n Experimental: false\n```. Maybe it has something to do with hydra's path? I still have it under ory-am. Maybe since I use ~0.7.10 in idp it will use ~0.6.9?. Oh yes. First we get a stable API using SQL, then the community can write whatever they need.\nI think redis may be great in future, but I haven't got into any performance issues with SQL yet.\nI would even propose getting rid of mysql, but someone might already be using that.. Maybe this could be helpfull: https://tip.golang.org/pkg/plugin/ ?\n. wow. 1 is not an issue if 2 is solved.. Yes, it was a bug in glide, solved in more recent versions. It took HEAD from git instead of the right release.. You must be joking... From my experience Hydra's dev is very helpful, Hydra's stable, well documented and as secure as I can review.\nThere's nothing bad in buying commercial support if you need it, but clearly the concept of paying for work must be foreign to you.. No, why should I? It's an empty database.. Confirmed - in order to setup Hydra for the first time, on an empty database one has to do hydra migrate sql .... \n. ## Option 1: Replacing the JWTs with a REST request\nSpeed:\n\nPrivate traffic between server nodes is generally free and fast. \nIt may be even better if Hydra is on the same physical machine. \nWe may use http instead of https. Possibly another RPC some day. Maybe Unix sockets?\nMore data to send via HTTP and it won't be packed in a JWT\nMore data send to the database\nLess time spent in signing / verifying signature\n\nNevertheless I guess it'll slow request handling down.\nComplexity\n\nWe already have libraries for handling the JWT JWK magic. Rewriting is harder than leaving it be :)\n\nSecurity\n\nOpens up new attack pane - session id's introduce state that's kept in Hydra. \n\nThe problem with micro services is that people tend to treat them like daemons in OS, but they're not. The RPC and availability is a nightmare.\nOption 2: Keep JWT dance but replace PKI with shared secret\n\nProbably easier if someone writes a new IdP\n\nOption 3: Use the database\n\nOption 1 but without http.\nYou already control the SDK, no complication for the user\nAccess guarded by privileges on the database\nWorks only if IdP has access to the Hydra's database. \nFast but doesn't feel right\n\nOption 4: Leave it be\n\nI'm all for this option since I can't rewrite my IdP :smile: \n\n. What will be in the SDK?. Now it looks much simpler and better. \nPlain SQL will be a great advantage. It's fast and predictable.\n. I'd divide this table into two - one with OIDC specific data and one with the ClientInfo. \nI'm not sure Hydra should handle ClientInfo part at all. It looks IdP specific and I know I will have to add some fields in my service and not use others. I might as well store my own version of ClientInfo\n. Remember NOT NULL on not indexed fields is expensive (not important here, since there isn't a lot of clients)\nAre all of the fields really required?\n. damn, sorry. NOT NULL is ok. \nIt's UNIQE that I was thinking about :)\n. I think it should be 0.11.5. (at least that's how I do it in my projects). ",
    "dancannon": "Thanks :)\n. ",
    "ashic": "Is there an updated link? The apiary one seems broken. . Yeah... that was my thoughts too. The trouble is that I'm looking to use flask-oidc, which in turn uses google's oauth2client (which by the way, is deprecated!). Is there a setting in Hydra that would enable reading the code from the post body (since it's discouraged in the spec, but not forbidden)? . Christ the google library is confused! The ctor for OAuth2WebServerFlow has the option:\nauthorization_header: string, For use with OAuth 2.0 providers that\n                                  require a client to authenticate using a\n                                  header value instead of passing client_secret\n                                  in the POST body.\nbut factory methods like flow_from_clientsecrets have no such options. . The google library is encoding parameters into the body like so:\npost_data = {\n            'client_id': self.client_id,\n            'code': code,\n            'scope': self.scope,\n        }\n        if self.client_secret is not None:\n            post_data['client_secret'] = self.client_secret\n        if self._pkce:\n            post_data['code_verifier'] = self.code_verifier\n        if device_flow_info is not None:\n            post_data['grant_type'] = 'http://oauth.net/grant_type/device/1.0'\n        else:\n            post_data['grant_type'] = 'authorization_code'\n            post_data['redirect_uri'] = self.redirect_uri\n        body = urllib.parse.urlencode(post_data)\nCould you please advise which of these is expected in the authorisation header? What would the authorisation header string look like? . Thanks... I was asking about what to put in the header as there seems to be support for both basic auth and bearer tokens. With basic, the code would go in the body then? . Right... so I'm monkey patching flask-oidc, and I've got it to include the header:\nif auth_method == 'client_secret_basic':\n        basic_auth_string = '%s:%s' % (self.client_secrets['client_id'], self.client_secrets['client_secret'])\n        print (\"Authorization header: {}\".format(basic_auth_string))\n        basic_auth_bytes = bytearray(basic_auth_string, 'utf-8')\n        flow.authorization_header = 'Basic %s' % b64encode(basic_auth_bytes)\nInspecting in wireshark shows https://imgur.com/a/YfEAk . However, the request still fails, and hydra logs show:\ntime=\"2017-11-23T10:54:38Z\" level=info msg=\"started handling request\" method=POST remote=\"172.30.0.1:48214\" request=/oauth2/token\ntime=\"2017-11-23T10:54:38Z\" level=error msg=\"An error occurred\" error=\"HTTP authorization header missing or invalid: The request is missing a required parameter, includes an invalid parameter value, includes a parameter more than once, or is otherwise malformed\"\ntime=\"2017-11-23T10:54:38Z\" level=info msg=\"completed handling request\" measure#http://localhost:4444.latency=220486 method=POST remote=\"172.30.0.1:48214\" request=/oauth2/token status=400 text_status=\"Bad Request\" took=\"220.486\u00b5s\"\nDo you have any pointers as to what I'm missing? . I'm guessing that's wireshark formatting. I'm trying the log level thing. . Nope... it's not wireshark.... it's in the string... debugging. . Right... the issue was with how python encoding works. I needed to change the code to:\nif auth_method == 'client_secret_basic':\n        basic_auth_string = '%s:%s' % (self.client_secrets['client_id'], self.client_secrets['client_secret'])\n        print (\"Authorization header: {}\".format(basic_auth_string))\n        basic_auth_bytes = bytearray(basic_auth_string, 'utf-8')\n        flow.authorization_header = 'Basic %s' % b64encode(basic_auth_bytes).decode('utf-8')\nand it worked like a charm. Thanks for your continued help on this. I'll submit a PR to flask-oidc. . ",
    "faxal": "It was annoying for me too at first, because chromium is my default browser and it doesn't work with chromium because of the certificate issue. \nHowever it can be disabled in chromium for localhost by putting\n--allow-insecure-localhost in ~/.config/chromium-flags.conf or your $XDG_CONFIG_HOME/chromium-flags.conf.\n. Can't build now, I'm getting this:\npkg/test_helpers.go:65: unknown strategy.HMACSHAStrategy field 'AccessTokenLifespan' in struct literal\npkg/test_helpers.go:66: unknown strategy.HMACSHAStrategy field 'AuthorizeCodeLifespan' in struct literal\n. When you said unit tests, did you mean something similar to tests in HTTP Managers or did you have something else in mind?\n. I forget to sign every other commit and it looks messy. Sorry about that, is that okay?. Shall I create a new PR?\n. Thank you! For being patient with me. :smiley: \n. This is an oversight on my part, I saw what @boyvinall mentioned and didn't bother adding the Endpoint.\nOverlooked this part: \nhttps://github.com/ory-am/hydra/blob/1e48e1819672fada95d8b24251d12cd883ba61fc/warden/warden_http.go#L71 \nAFAIK Everything else requires correct Endpoint be set.\n. Ah, makes sense. Seemed weird to me too, but rationalized that you might be trying to save a bit of memory by reducing number of tables as it has a small overhead. \n. I've had this \"premature expiration\" issue too. I can't reproduce at the moment. I'll report with more info if it happens again.\n. @matteosuppo yes! it's due to coldStart in fosite storage layer, recent tokens get overridden with old ones. See #207 \n. JSON file has scopes. Hydra expects scope\n. @arekkas @leetal I was in a hurry with this commit: https://github.com/ory-am/fosite/commit/7faee6bbd53ee762ddfe194fb2ea5e7d0205e46d\nI realized after I pushed that it can be simplified to this:\nif current != needle {\n    break\n}\n. No problem\nOn Sat, Aug 27, 2016, 19:28 Aeneas notifications@github.com wrote:\n\nThank you for the PR but I remember now what this was for. I will include\nyour fix in another fix. :)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/pull/236#issuecomment-242920179, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABs0pmWzR2K4UPHQzYAwNcJSOk7TUd78ks5qkEl1gaJpZM4Jur7Y\n.\n. Are you using a different client to request for token here (different from the one above)?\n$ hydra token client --skip-tls-verify\n\nBecause the above requires grant_type client_credentials and hydra in scope. no?\nMaybe I'm missing something, I'm trying If I can reproduce.\n. I can't think of a simple way to fix without resorting to *bool. Another way would be to inspect the JSON payload with any json query package and check if value was sent by the user. But then we would need to pass around the fact that Public flag was set or not.. SGTM, that is more inline with the semantics of PUT. One downside would be backwards compatibility, I can't think of anything else.. Done #478. Sorry about that. Done.\n. ",
    "matteosuppo": "If I set it to wait for 10 seconds it avoids the error gorethink: Cannot perform read: primary replica for shard but I still get cipher: message authentication failed\nNow I'll try cleaning everything up\n. Ah now I get it. The first time I set the SYSTEM_SECRET but after that I didn't, so it generated a different secret and it didn't work. Thank you very much.\n. Yes I used rethinkdb, and I can see the data in the database, but the same command that worked before now gives me:\nhydra_1      | time=\"2016-06-17T07:42:33Z\" level=info msg=\"Got error.\" error=\"Client authentication failed (e.g., unknown client, no client authentication included, or unsupported authentication method)\" stack=\"*errors.Error Client authentication failed (e.g., unknown client, no client authentication included, or unsupported authentication method)\\n/go/src/github.com/ory-am/hydra/vendor/github.com/ory-am/fosite/access_request_handler.go:71 (0x75d588)\\n\\t(*Fosite).NewAccessRequest: return accessRequest, errors.New(ErrInvalidClient)\\n/go/src/github.com/ory-am/hydra/oauth2/handler.go:34 (0x7761d4)\\n\\t(*Handler).TokenHandler: accessRequest, err := o.OAuth2.NewAccessRequest(ctx, r, &session)\\n/go/src/github.com/ory-am/hydra/oauth2/handler.go:25 (0x777aac)\\n\\t(*Handler).TokenHandler-fm: r.POST(\\\"/oauth2/token\\\", h.TokenHandler)\\n/go/src/github.com/ory-am/hydra/vendor/github.com/julienschmidt/httprouter/router.go:344 (0x5cf545)\\n\\t(*Router).ServeHTTP: handle(w, req, ps)\\n/usr/local/go/src/net/http/server.go:1910 (0x55b76d)\\n\\t(*ServeMux).ServeHTTP: h.ServeHTTP(w, r)\\n/usr/local/go/src/net/http/server.go:2081 (0x55c1ee)\\n\\tserverHandler.ServeHTTP: handler.ServeHTTP(rw, req)\\n/usr/local/go/src/net/http/server.go:1472 (0x558c5e)\\n\\t(*conn).serve: serverHandler{c.server}.ServeHTTP(w, w.req)\\n/usr/local/go/src/runtime/asm_amd64.s:1998 (0x45f451)\\n\\tgoexit: BYTE\\t$0x90\\t// NOP\\n\"\n. ``` go\n    ctx := context.WithValue(context.Background(), oauth2.HTTPClient, &http.Client{Transport: &http.Transport{\n        TLSClientConfig: &tls.Config{InsecureSkipVerify: true},\n    }})\noauthConfig := clientcredentials.Config{\n    ClientID:     \"a836d46c-9984-46b1-9d3a-5f6909e9c8a2\",\n    ClientSecret: \"hyB-d$XWYs6bk!T9\",\n    TokenURL:     \"https://hydra:4444/oauth2/token\",\n    Scopes: []string{\n        \"core\",\n        \"hydra\",\n    },\n}\n\nt, err := oauthConfig.Token(ctx)\n\n. Now I'll try with the commands\n. bash\n$ SYSTEM_SECRET=passwordtutorial DOCKER_IP=localhost docker-compose up --build\nCreating volume \"hydra_hydravolume\" with local driver\nBuilding hydra\n[...]\nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=warning msg=\"Expected system secret to be at least 32 characters long but only got 16 characters.\" \nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=warning msg=\"Generating a random system secret...\" \nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=warning msg=\"Generated system secret: )s0ZeNIoAzgPG_gdTHlLivRo4skO&fW.\" \nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=warning msg=\"Do not auto-generate system secrets in production.\" \nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=info msg=\"DATABASE_URL set, connecting to RethinkDB.\" \nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=info msg=\"Connecting with RethinkDB: rethinkdb://database:28015/hydra (database:28015) (hydra)\" \nhydra_1      | Pointing cluster at https://localhost:4444\nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=info msg=\"Connected to RethinkDB!\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"Could not find OpenID Connect singing keys. Generating a new keypair...\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"Keypair generated.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"WARNING: Automated key creation causes low entropy. Replace the keys as soon as possible.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"Key pair for signing consent.endpoint is missing. Creating new one.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"Key pair for signing consent.challenge is missing. Creating new one.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"No clients were found. Creating a temporary root client...\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"Temporary root client created.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"client_id: fbd1843c-7e5b-4b6b-8360-a210179e1924\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"client_secret: w2J-ESub2)y,W_-r\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"The root client must be removed in production. The root's credentials could be accidentally logged.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"Do not use flag --dangerous-auto-logon in production.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"Key for TLS not found. Creating new one.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=warning msg=\"Temporary key created.\" \nhydra_1      | time=\"2016-06-17T08:26:19Z\" level=info msg=\"Starting server on :4444\" \n```\nbash\n$ hydra connect\nCluster URL [https://localhost:4444]: \nClient ID: fbd1843c-7e5b-4b6b-8360-a210179e1924\nClient Secret: w2J-ESub2)y,W_-r\nDone.\nbash\n$ hydra clients create --skip-tls-verify\nWarning: Skipping TLS Certificate Verification.\nClient ID: 75972b5b-8c94-4c09-bb96-10ec5178c226\nClient Secret: Cvszrw>IC_FsQorhrEn$p8VYnb\nREBOOT\nbash\n$ SYSTEM_SECRET=\")s0ZeNIoAzgPG_gdTHlLivRo4skO&fW.\" DOCKER_IP=localhost docker-compose up\nhydra_1      | time=\"2016-06-17T08:30:38Z\" level=info msg=\"DATABASE_URL set, connecting to RethinkDB.\" \nhydra_1      | time=\"2016-06-17T08:30:38Z\" level=info msg=\"Connecting with RethinkDB: rethinkdb://database:28015/hydra (database:28015) (hydra)\" \nhydra_1      | time=\"2016-06-17T08:30:38Z\" level=info msg=\"Connected to RethinkDB!\" \nhydra_1      | time=\"2016-06-17T08:30:38Z\" level=warning msg=\"Do not use flag --dangerous-auto-logon in production.\" \nhydra_1      | time=\"2016-06-17T08:30:38Z\" level=info msg=\"Starting server on :4444\"\nbash\n$ hydra connect\nCluster URL [https://localhost:4444]: \nClient ID: fbd1843c-7e5b-4b6b-8360-a210179e1924\nClient Secret: w2J-ESub2)y,W_-r\nDone.\nbash\n$ hydra clients create --skip-tls-verify\nWarning: Skipping TLS Certificate Verification.\nCould not authenticate, because: oauth2: cannot fetch token: 400 Bad Request\nResponse: {\"name\":\"invalid_client\",\"description\":\"Client authentication failed (e.g., unknown client, no client authentication included, or unsupported authentication method)\",\"statusCode\":400}\nDid you forget to log on? Run `hydra connect`.\nDid you run Hydra without a valid TLS certificate? Make sure to use the `--skip-tls-verify` flag.\nDid you know you can skip `hydra connect` when running `hydra host --dangerous-auto-logon`? DO NOT use this flag in production!\nbash\nhydra_1      | time=\"2016-06-17T08:55:00Z\" level=info msg=\"Got error.\" error=\"Client authentication failed (e.g., unknown client, no client authentication included, or unsupported authentication method)\" stack=\"*errors.Error Client authentication failed (e.g., unknown client, no client authentication included, or unsupported authentication method)\\n/go/src/github.com/ory-am/hydra/vendor/github.com/ory-am/fosite/access_request_handler.go:71 (0x74fa18)\\n\\t(*Fosite).NewAccessRequest: return accessRequest, errors.New(ErrInvalidClient)\\n/go/src/github.com/ory-am/hydra/oauth2/handler.go:34 (0x7684f4)\\n\\t(*Handler).TokenHandler: accessRequest, err := o.OAuth2.NewAccessRequest(ctx, r, &session)\\n/go/src/github.com/ory-am/hydra/oauth2/handler.go:25 (0x769dcc)\\n\\t(*Handler).TokenHandler-fm: r.POST(\\\"/oauth2/token\\\", h.TokenHandler)\\n/go/src/github.com/ory-am/hydra/vendor/github.com/julienschmidt/httprouter/router.go:344 (0x591035)\\n\\t(*Router).ServeHTTP: handle(w, req, ps)\\n/usr/local/go/src/net/http/server.go:1910 (0x524e0d)\\n\\t(*ServeMux).ServeHTTP: h.ServeHTTP(w, r)\\n/usr/local/go/src/net/http/server.go:2081 (0x52588e)\\n\\tserverHandler.ServeHTTP: handler.ServeHTTP(rw, req)\\n/usr/local/go/src/net/http/server.go:1472 (0x5222fe)\\n\\t(*conn).serve: serverHandler{c.server}.ServeHTTP(w, w.req)\\n/usr/local/go/src/runtime/asm_amd64.s:1998 (0x45f451)\\n\\tgoexit: BYTE\\t$0x90\\t// NOP\\n\"\n. According to these lines:\nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=warning msg=\"Expected system secret to be at least 32 characters long but only got 16 characters.\" \nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=warning msg=\"Generating a random system secret...\" \nhydra_1      | time=\"2016-06-17T08:25:56Z\" level=warning msg=\"Generated system secret: )s0ZeNIoAzgPG_gdTHlLivRo4skO&fW.\"\nI needed to use that new secret. If I use the previous one I get \nhydra_1      | time=\"2016-06-17T09:24:24Z\" level=warning msg=\"Expected system secret to be at least 32 characters long but only got 16 characters.\" \nhydra_1      | time=\"2016-06-17T09:24:24Z\" level=warning msg=\"Generating a random system secret...\" \nhydra_1      | time=\"2016-06-17T09:24:24Z\" level=warning msg=\"Generated system secret: KUnnXjHr8,JqOt1kInv$m03,4(Dn!(Cr\" \nhydra_1      | time=\"2016-06-17T09:24:24Z\" level=warning msg=\"Do not auto-generate system secrets in production.\" \nhydra_1      | time=\"2016-06-17T09:24:24Z\" level=info msg=\"DATABASE_URL set, connecting to RethinkDB.\" \nhydra_1      | time=\"2016-06-17T09:24:24Z\" level=info msg=\"Connecting with RethinkDB: rethinkdb://database:28015/hydra (database:28015) (hydra)\" \nhydra_1      | time=\"2016-06-17T09:24:24Z\" level=info msg=\"Connected to RethinkDB!\" \nhydra_1      | time=\"2016-06-17T09:24:24Z\" level=fatal msg=\"Could not fetch initial state: cipher: message authentication failed\"\nThe problem by the way exists only if I reboot the computer. Which is strange.\n. The data is still there, and hydra can connect with the proper secret and do not generate other client_id and client_secret.\n. Now it worked. I'm perplexed. This time it was happy with the system secret too. I have the feelings the two things are connected.\n. Oh, perfect, thank you\n. Aren't JWK stored in rethinkdb?\n. I'm working on it\n. https://www.arduino.cc (especially for services such as https://create.arduino.cc)\nWe aren't using it yet, but we're planning to migrate our current authentication system to oauth2 using hydra.\n. I also corrected a couple of typo\n. Yes, that's definitely it. Thank you.\n. Uhm no, it gives me the same issue even if I use https and a 8char nonce\n. Yes, now it's \"redirect_uris\": [\n\"https://172.17.0.2:3000/\", \n]\n. Tomorrow I'll try to run hydra with  a lot of custom log.Print()\n. By debugging I found out that the trailing / in the redirect_uri from database was the culprit.\nI'll never mistrust hydra again, I am ready to comply.\n. /token/valid and /token allowed are much more understandable than /authorized and /allowed.\nI like the 4 endpoints, they sounds very clear. Do you need help implementing them? Next week I should put some efforts in our migration to hydra, so I can help.\n. Do you mean instead of having http endpoints?\n. It seems pretty clear to me. There's only a typo in /warden/allowed. It says \"This endpoint requires a token, a scope, a resource name, an action name and a context.\" While it clearly need a subject, not a token.\n. I don't think it's a system clock issue, because the logs have the correct date:\n2016/08/16 10:48:14 2016-08-12 15:10:52.485 +0000 +00:00 1h0m0s\nfor log.Println(r.GetRequestedAt(), h.AccessTokenLifespan)\nHow can I inspect the iat value?\n. I'm getting it with the implicit flow, so it shouldn't be a refreshed token\n. I'm going to check\n. Yes, sounds like it occur only with implicit tokens\n. 3600\n. Ok, could it be because the nonce in the request was already been used on 2016-08-12 ?\n. I use this to get the token:\n``` javascript\nfunction login() {\n    var redirectUri = encodeURIComponent(\"http://localhost:3000\");\n    location.href = \"http://localhost:4444/oauth2/auth?client_id=test&response_type=token&nonce=9871233&state=statestate&scopes=core&redirect_uri=\"+redirectUri\n}\nfunction GetURLParameter(location, sParam) {\n    var sPageURL = location.hash.substring(1);\n    var sURLVariables = sPageURL.split('&');\n    for (var i = 0; i < sURLVariables.length; i++) {\n        var sParameterName = sURLVariables[i].split('=');\n        if (sParameterName[0] == sParam) {\n            return sParameterName[1];\n        }\n    }\n}\ntoken = GetURLParameter(window.location, \"access_token\");\n```\nBut it can work only on the browser. I can try to spin up some automated tests using https://karma-runner.github.io/1.0/index.html\n. Also this problem happens when I restart the hydra service. My gut tells me it has something to do with the way tokens are loaded at startup.\n. Would it be possible to specify a wildcard path? LIke http://foo/* Are there security shortcomings in doing so?\n. Uhm, it's happening again. Seems like the error returned doesn't implement StatusCodeCarrier so it return 500. Also what are the default scopes, like offline and hydra. (We're finally putting the hydra-powered authorization system in production by the way: https://auth.arduino.cc)\nActually it's not a big deal, I was just wondering if you knew about that inconsistency. Handling it on my side it's a matter of minutes, so I don't think it makes sense to change hydra api. I'm closing it, ok?. Since I need it at introspection I should use at_ext, right?\nMaybe I could make a pull request to fix the documentation?\nIl ven 14 apr 2017, 09:23 Aeneas notifications@github.com ha scritto:\n\nYeah actualy it's not supported in the code. This might be an old\nreference. Is it enough for you to set at_ext/id_ext instead?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory/hydra/issues/418#issuecomment-294106592, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABdjeZKa8HsH3c-Qqxoj4hsY3nDQpY6pks5rvx8IgaJpZM4M88t5\n.\n. Could be, it happened again. I will try as soon as there is a release with this commit.. <3. Looks good. Indeed, we were using the wrong client. Sorry. No problem. You're right. I was confused.. As soon as I get another crash. Both instances. I recreated the database (bigger) on rds and it seems it's\nstabler now. My guess is that the issue was in the database instance, that\nhanged on some queries and caused slowdowns and reconnections. I don't have\nthe URL here since I'm from the phone. It's only accessible from inside the\nVPN though, so I'm not sure what you could do with it :p\n\nIl sab 20 mag 2017, 11:48 Aeneas notifications@github.com ha scritto:\n\nOh and by the way, do both instances stop serving traffic or only one?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory/hydra/issues/461#issuecomment-302863006, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABdjec7Xdmhh7S_x7z7lkpfXrv_W0Y-9ks5r7rbogaJpZM4Nfg0M\n.\n. I didn't set up those values, so it may indeed be that. I'll try that on\nMonday if I'll encounter issues. Thank you very much.\n\nIl sab 20 mag 2017, 11:59 Aeneas notifications@github.com ha scritto:\n\nWhat I'm interested in is the settings max_conns, max_idle_conns, and\nmax_conn_lifetime - or if you haven't set them at all. If you haven't set\nthem, could you try setting max_conn_lifetime to, for example 1 minute?\npostgres://:@:/hydra?max_conn_lifetime=1m\nMy guess is that either some connections have issues and then clog up the\ndatabase, or that connections are capped at a low value (e.g. 4 - which\nhappens on 2 logical cpus) which simply isn't enough. So you could also try:\npostgres://:@:/hydra?max_conn_lifetime=1m&max_conns=20&max_idle_conns=4\nwhich greatly increases the maximum amount of allowed connections.\nOf course, upgrading to a larger db might also help. Since the symptoms\nyou describe don't fit in a sql memory leak, and only in either a database\nload issue or an infinite loop issue, upgrading could resolve those issues.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory/hydra/issues/461#issuecomment-302863505, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABdjeaw2cGxJP50d60GcKCeI2-KYRCRxks5r7rmfgaJpZM4Nfg0M\n.\n. Those flags don't seems to have changed anything.\n\nI managed to capture some stats of the machine before it died:\nhttp://imgur.com/wqDR4tT\nhttp://imgur.com/8nb3qdr\nYou can see that there seem to be some memory leak going on, since the memory allocated keeps growing. It reaches 2.5GBs\nAt that point my theory is that it reaches the maximum memory allocated per process set by docker so it tries to go into swap and everything goes south.\nWe can also see that the disk space used is growing, probably because of the logs. I wonder if those two are connected.\nAnyway I tried monitoring top usage while running a bunch of load in my local machine with\nhey -n 2000 -c 500 -H \"Authorization: bearer z5VepohqLE3hIEfHfCkfpzJCrufJbhXVZcO43SNWG18.FaYVcXhgd5lUSemxQG-Vitg8IxuSSD3JIKrzdJeACXo\" -d '{\"scopes\":[\"profile:core\"],\"token\":\"BKxpqvBicy6YP64JNzRdnu_DAlzq0lQ9q0_KFHNxiu4.ez2I29zoArRYuvHDmlTmCleRkp-xHJ94IfiYuPSRLdI\",\"resource\":\"user:me\",\"action\":\"show\",\"context\":null}' -m POST http://localhost:4444/warden/token/allowed\nAnd I saw the memory usage grow steadily.\nI also tried to make sense of go tool pprof but I'm not very good at it\n. I was running it against a postgresql database. It could indeed be that the memory is growing to accomodate the load, but wouldn't it reach a stable point? Instead it growed hour after hour until it allocated 2.5 GB before the crash.. I can attempt a pull request in the next few days. Uhm, it doesn't seem to have been fixed:\n```\n\u279c  hydra git:(master) \u2717 docker run -e \"DATABASE_URL=$DATABASE_URL\" -e \"SYSTEM_SECRET=$SYSTEM_SECRET\" --rm --name my-hydra -p 4444:4444 oryd/hydra:v0.8.3-http -h\ntime=\"2017-05-24T08:48:42Z\" level=info msg=\"Connecting with postgres://:@*:5432/auth?\" \ntime=\"2017-05-24T08:48:43Z\" level=error msg=\"An error occurred\" error=\"Could not connect to SQL: pq: unrecognized configuration parameter \"max_conn_lifetime\"\" \ntime=\"2017-05-24T08:48:43Z\" level=info msg=\"Retrying in 0.100000 seconds...\" \n```\nAm I doing something wrong?. I had some difficulties implementing the consent flow, and now that it's working I'm not eager on doing it again, but it seems to me that this new consent flow could be easier to implement.\nOne downside is that it requires more network round-trips (and probably more trips to the database)\nOld method:\nget hydra \nget consent\npost consent\nget hydra\nnew method\nget hydra\nget consent\nget session\npost consent\npost session\nget hydra. Wow, that was quick . Return all the errors. The accumulator returns an error containing a list of errors . ",
    "yageek": "Done.\n. ",
    "fnzv": "Okk.. there is a web ui\\dashboard to manage users? in the features i saw this : Real Time monitoring, with this feature is it possible to trace every API request? (Audit logging)\n. ",
    "boyvinall": "Hi @matteosuppo, I think this is probably the same issue that I had a little while back. See https://github.com/ory-am/fosite/blob/dfb047d52b75b5d8a28bcd8d70a3e139da289da1/authorize_helper.go#L96 .. you 'll want to either specify https or somehow use the localhost IP.\n. BTW, I think you might also need to specify an 8-char nonce in your request too.\n. did you update it in your client definition as well as the redirect_uri URL query param? The query param has to be one of the (potentially multiple) registered against the client.\n. FWIW, I've got a lot of mileage from the vscode golang debugger integration. You can connect to a remote host, set breakpoints and single-step code.  See https://github.com/Microsoft/vscode-go#optional-debugging.  I'm running this on a remote host as\ncd $GOPATH/src/github.com/ory-am/hydra ; dlv attach --headless --listen=:2345 --log $(pgrep hydra)\nthen configure a vscode debugger launch.json as:\n{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Remote\",\n            \"type\": \"go\",\n            \"request\": \"launch\",\n            \"mode\": \"remote\",\n            \"remotePath\": \"/remote/path/to/gocode/src/github.com/ory-am/hydra\",\n            \"port\": 2345,\n            \"host\": \"<remote-ip>\",\n            \"program\": \"${workspaceRoot}\",\n            \"env\": {}\n        }\n    ]\n}\nIt doesn't take that long to get setup, and it's saved me a ton of custom log prints :smiley: \n. @matteosuppo Looks like you beat me to this by a few hours :) I did basically exactly the same thing, except I didn't add warden.AllowedHandlerPath.  Looking at https://github.com/ory-am/hydra/blob/1e48e1819672fada95d8b24251d12cd883ba61fc/warden/warden_http.go#L72, it seems the path is basically overridden every time, so I'm not sure what the best practice is here.  In any event though, your fix works for me too :)\n. I've tested this change with my use-case, but not yet added anything to the regressions tests, sorry.\n. sorry, just catching up again, thanks. If I get time then I'll add one in a bit..\n. https://github.com/ory-am/hydra/blob/master/client/manager_http.go#L17 returns a fosite.Client interface, so I can't read the name :)\n. Ah yeah, sorry\n. As per gitter, take a look at https://tools.ietf.org/html/draft-ietf-oauth-native-apps-03\n. BTW - for my purposes, I'm looking at using the implicit flow, but I think this can also affect the authorisation code flow. Perhaps this makes the implementation easier?\n. Yeah, a docs directory can often work well. I'll create something with that.\n. Cool!  On the static analysis thing, you could maybe try https://github.com/HewlettPackard/gas - I've not used it myself on anything yet but heard it mentioned on https://changelog.com/gotime-14/\n. Probably worth also to consider the ease of operation in a fault-tolerant scenario.  RethinkDB was/is nice here because of the clustering, similarly mongo. CockroachDB is an interesting one for this too though .. and it's using postgres wire protocol.  Unfortunately doesn't have the change notifications (yet) ... that's currently scheduled for adding next year.  Older SQL do obviously allow readonly replicas with some yak-shaving for slave promotion, but natively-clustered are easier to work with.\nGot to agree with not throwing out RethinkDB just yet though. It's good to be aware of plans, but you don't need to actively migrate off it just yet.\n. you can probably use bash as long as it's inside the yaml array.  Something like:\nafter_success:\n- [ \"${TRAVIS_TAG}\" != \"\" ] && [ \"${TRAVIS_GO_VERSION}\" == \"1.7\" ] && gox -ldflags \"-X github.com/ory-am/hydra/cmd.Version=`git describe --tags` -X github.com/ory-am/hydra/cmd.BuildTime=`TZ=UTC date -u '+%Y-%m-%dT%H:%M:%SZ'` -X github.com/ory-am/hydra/cmd.GitHash=`git rev-parse HEAD`\" -output \"dist/ {.Dir}}-{{.OS}}-{{.Arch}}\"\nexcept ... you need to ensure the leading [ isn't seen as a yaml token, so maybe some sort of heredoc:\nafter_success:\n- |-\n  [ \"${TRAVIS_TAG}\" != \"\" ] && [ \"${TRAVIS_GO_VERSION}\" == \"1.7\" ] && gox -ldflags \"-X github.com/ory-am/hydra/cmd.Version=`git describe --tags` -X github.com/ory-am/hydra/cmd.BuildTime=`TZ=UTC date -u '+%Y-%m-%dT%H:%M:%SZ'` -X github.com/ory-am/hydra/cmd.GitHash=`git rev-parse HEAD`\" -output \"dist/ {.Dir}}-{{.OS}}-{{.Arch}}\"\n. ",
    "nishaantchauhan": "Hi @matteosuppo @aeneasr @boyvinall \nFacing the same issue by following tutorial when i set all localhost and callback url as a my server's IP\n\n. hi, @wangyun I am facing the same issue as you faced As @aeneasr suggested the set required to host and port I did but the error is still same. \n\nNo, unfortunately, it's not at the moment. But you can easily work around this by replacing localhost:4445 with the right host and port\n\n\nMaybe callbacks URL is still hardcoded!!\n$ docker run --rm -it \\\n  -e HYDRA_ADMIN_URL=https://ory-hydra-example--hydra:4445 \\\n  --network hydraguide \\\n  oryd/hydra:v1.0.0-rc.4_oryOS.9 \\\n  clients create --skip-tls-verify \\\n    --id facebook-photo-backup \\\n    --secret some-secret \\\n    --grant-types authorization_code,refresh_token,client_credentials,implicit \\\n    --response-types token,code,id_token \\\n    --scope openid,offline,photos.read \\\n    --callbacks http://127.0.0.1:9010/callback\n. Thank you for quick response @aeneasr \nI have used our server's callback URL `--callbacks http://172.18.0.1:9010/callback` but the Error is same. i have get the URL link which ishttps://172.18.0.1:9000/oauth2/auth?audience=&client_id=facebook-photo-backup&max_age=0&nonce=zpqrmxissxmwqwajjbxbfvdj&prompt=&redirect_uri=http%3A%2F%2F127.0.0.1%3A9010%2Fcallback&response_type=code&scope=openid+offline+photos.read&state=sivhtaipzyjumqmtfhkeuvkv```\nIf it was not the hardcoded than why the redirect url is 127.0.0.1 instead of 172.18.0.1 ?\n. sorry @aeneasr  but I didn't get it how to fire this \n\nclients get --skip-tls-verify --id facebook-photo-backup\n\nMaybe I thought we can set only http://127.0.0.1:9010/callback callback URL. we don't have any choice except 127.0.0.1 host. if we set any other host than we get this error.\n\n. I did it twice. The first time we get the unique key violation Error so we did it the second time and we get client authentication failed Error.. After that, I retry the tutorial from the fresh here are the ports with their Error\n127.0.0.1:9020\n\n127.0.0.1:9010\n\n127.0.0.1:9000\n\nLogs also clear no Error except 404 for favicon\nAlso, https://localhost:9001/health/status URL gives an ok response\nplease check this log also \ntime=\"2018-10-15T08:57:34Z\" level=info msg=\"Connecting with postgres://:@ory-hydra-example--postgres:5432/hydra?sslmode=disable\"\ntime=\"2018-10-15T08:57:34Z\" level=info msg=\"Connected to SQL!\"\ntime=\"2018-10-15T08:57:34Z\" level=info msg=\"JSON Web Key Set hydra.openid.id-token does not exist yet, generating new key pair...\"\ntime=\"2018-10-15T08:57:35Z\" level=info msg=\"Setting up Prometheus middleware\"\ntime=\"2018-10-15T08:57:35Z\" level=info msg=\"Transmission of telemetry data is enabled, to learn more go to: https://www.ory.sh/docs/guides/latest/telemetry/\"\ntime=\"2018-10-15T08:57:35Z\" level=info msg=\"JSON Web Key Set hydra.https-tls does not exist yet, generating new key pair...\"\ntime=\"2018-10-15T08:57:42Z\" level=info msg=\"Setting up http server on :4445\"\ntime=\"2018-10-15T08:57:42Z\" level=warning msg=\"HTTPS disabled. Never do this in production.\"\ntime=\"2018-10-15T08:57:42Z\" level=info msg=\"Setting up http server on :4444\"\ntime=\"2018-10-15T08:57:42Z\" level=warning msg=\"HTTPS disabled. Never do this in production.\"\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50076\" request=/health/ready\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=910851 method=GET remote=\"172.18.0.1:50076\" request=/health/ready status=200 text_status=OK took=\"910.851\u00b5s\"\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50076\" request=/favicon.ico\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=72942 method=GET remote=\"172.18.0.1:50076\" request=/favicon.ico status=404 text_status=\"Not Found\" took=\"72.942\u00b5s\"\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50076\" request=/favicon.ico\ntime=\"2018-10-15T08:57:47Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=84389 method=GET remote=\"172.18.0.1:50076\" request=/favicon.ico status=404 text_status=\"Not Found\" took=\"84.389\u00b5s\"\ntime=\"2018-10-15T08:57:53Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50076\" request=/health/ready\ntime=\"2018-10-15T08:57:53Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=76367 method=GET remote=\"172.18.0.1:50076\" request=/health/ready status=200 text_status=OK took=\"76.367\u00b5s\"\ntime=\"2018-10-15T09:00:40Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:50084\" request=/health/ready\ntime=\"2018-10-15T09:00:40Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=159033 method=GET remote=\"172.18.0.1:50084\" request=/health/ready status=200 text_status=OK took=\"159.033\u00b5s\"\ntime=\"2018-10-15T09:01:19Z\" level=info msg=\"started handling request\" method=POST remote=\"172.18.0.4:51434\" request=/clients\ntime=\"2018-10-15T09:01:20Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=157155587 method=POST remote=\"172.18.0.4:51434\" request=/clients status=201 text_status=Created took=157.155587ms\ntime=\"2018-10-15T09:05:01Z\" level=info msg=\"started handling request\" method=POST remote=\"172.18.0.4:52016\" request=/oauth2/token\ntime=\"2018-10-15T09:05:01Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=160591619 method=POST remote=\"172.18.0.4:52016\" request=/oauth2/token status=200 text_status=OK took=160.591619ms\ntime=\"2018-10-15T09:36:03Z\" level=info msg=\"started handling request\" method=POST remote=\"172.18.0.4:51454\" request=/oauth2/introspect\ntime=\"2018-10-15T09:36:04Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=949375859 method=POST remote=\"172.18.0.4:51454\" request=/oauth2/introspect status=200 text_status=OK took=949.375859ms\ntime=\"2018-10-15T09:59:40Z\" level=info msg=\"started handling request\" method=POST remote=\"172.18.0.5:35052\" request=/clients\ntime=\"2018-10-15T09:59:41Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=605183913 method=POST remote=\"172.18.0.5:35052\" request=/clients status=201 text_status=Created took=605.183913ms\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:38848\" request=/\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=15670017 method=GET remote=\"172.18.0.1:38848\" request=/ status=404 text_status=\"Not Found\" took=15.670017ms\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:38848\" request=/favicon.ico\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=92691 method=GET remote=\"172.18.0.1:38848\" request=/favicon.ico status=404 text_status=\"Not Found\" took=\"92.691\u00b5s\"\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:38848\" request=/favicon.ico\ntime=\"2018-10-15T10:02:07Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=84591 method=GET remote=\"172.18.0.1:38848\" request=/favicon.ico status=404 text_status=\"Not Found\" took=\"84.591\u00b5s\"\ntime=\"2018-10-15T10:06:35Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:39048\" request=/\ntime=\"2018-10-15T10:06:35Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=82995756 method=GET remote=\"172.18.0.1:39048\" request=/ status=404 text_status=\"Not Found\" took=82.995756ms\ntime=\"2018-10-15T10:11:20Z\" level=info msg=\"started handling request\" method=GET remote=\"172.18.0.1:39268\" request=/\ntime=\"2018-10-15T10:11:20Z\" level=info msg=\"completed handling request\" measure#http://127.0.0.1:9000/.latency=120031129 method=GET remote=\"172.18.0.1:39268\" request=/ status=404 text_status=\"Not Found\" took=120.031129ms\n. I don't get it yet what's the issue?\nI just follow the same instructions which were in the tutorial didn't change a single thing... I started from fresh (didn't use docker-compose kill && docker-compose rm) used followed commands but it's all executed perfectly. when I check through the UI http://127.0.0.1:9020 I get the error from all ports which I saw you on an earlier post.\nStep 1 :\n$ docker network create hydraguide\nStep 2 :\n$ docker run --network hydraguide \\\n  --name ory-hydra-example--postgres \\\n  -e POSTGRES_USER=hydra \\\n  -e POSTGRES_PASSWORD=secret \\\n  -e POSTGRES_DB=hydra \\\n  -d postgres:9.6\nStep 3 :\n$ export SYSTEM_SECRET=y82XL-wAPCCZu+B4\nStep 4 :\n$ export DATABASE_URL=postgres://hydra:secret@ory-hydra-example--postgres:5432/hydra?sslmode=disable\nStep 5 : \n$ docker run -it --rm \\\n  --network hydraguide \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  migrate sql $DATABASE_URL\nStep 6 :\n$ docker run -d \\\n  --name ory-hydra-example--hydra \\\n  --network hydraguide \\\n  -p 9000:4444 \\\n  -p 9001:4445 \\\n  -e SYSTEM_SECRET=$SYSTEM_SECRET \\\n  -e DATABASE_URL=$DATABASE_URL \\\n  -e OAUTH2_ISSUER_URL=http://127.0.0.1:9000/ \\\n  -e OAUTH2_CONSENT_URL=http://127.0.0.1:9020/consent \\\n  -e OAUTH2_LOGIN_URL=http://127.0.0.1:9020/login \\\n  oryd/hydra:v1.0.0-beta.8 serve all --dangerous-force-http\nStep 7 :\nThe check is it alive through http://localhost:9001/health/ready URL get an ok response\nStep 8 :\n$ docker run --rm -it \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  help\nStep 9 :\n$ docker run --rm -it \\\n  --network hydraguide \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  clients create \\\n    --endpoint http://ory-hydra-example--hydra:4445 \\\n    --id some-consumer \\\n    --secret some-secret \\\n    --grant-types client_credentials \\\n    --response-types token,code\nStep10 :\n$ docker run --rm -it \\\n  --network hydraguide \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  token client \\\n    --client-id some-consumer \\\n    --client-secret some-secret \\\n    --endpoint http://ory-hydra-example--hydra:4444\nStep 11 :\n$ docker run --rm -it \\\n  --network hydraguide \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  token introspect \\\n    --client-id some-consumer \\\n    --client-secret some-secret \\\n    --endpoint http://ory-hydra-example--hydra:4445 \\\n    >INSERT-TOKEN-HERE<\nStep 12 :\n$ docker run -d \\\n  --name ory-hydra-example--consent \\\n  -p 9020:3000 \\\n  --network hydraguide \\\n  -e HYDRA_URL=http://ory-hydra-example--hydra:4445 \\\n  -e NODE_TLS_REJECT_UNAUTHORIZED=0 \\\n  oryd/hydra-login-consent-node:v1.0.0-beta.8\nStep 13 :\n$ docker run --rm -it \\\n  --network hydraguide \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  clients create \\\n    --endpoint http://ory-hydra-example--hydra:4445 \\\n    --id another-consumer \\\n    --secret consumer-secret \\\n    -g authorization_code,refresh_token \\\n    -r token,code,id_token \\\n    --scope openid,offline \\\n    --callbacks http://127.0.0.1:9010/callback\nStep 14 :\n$ docker run --rm -it \\\n  --network hydraguide \\\n  -p 9010:9010 \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  token user \\\n    --port 9010 \\\n    --auth-url http://127.0.0.1:9000/oauth2/auth \\\n    --token-url http://ory-hydra-example--hydra:4444/oauth2/token \\\n    --client-id another-consumer \\\n    --client-secret consumer-secret \\\n    --scope openid,offline \\\n    --redirect http://127.0.0.1:9010/callback\n. Thank you for solution unblock the port 9010\nThanks a Lot.. > Please read this: https://www.ory.sh/docs/guides/master/hydra/6-how-to/4-debug\n\nI have checked the log and I get a followed error. \ntime=\"2018-10-22T09:13:17Z\" level=info msg=\"started handling request\" method=GET remote=\"10.10.20.10:59171\" request=\"/oauth2/auth?client_id=another-consumer&consent_verifier=27268dc6c37c43ef9af17b6bb2b6adf3&max_age=0&nonce=oofwtmosnyagklyeroctufro&prompt=&redirect_uri=http%3A%2F%2F10.10.0.10%3A9010%2Fcallback&response_type=code&scope=openid+offline&state=wwujsryireokwjvubyxsdton\"\ntime=\"2018-10-22T09:13:17Z\" level=error msg=\"An error occurred\" description=\"The request is missing a required parameter, includes an invalid parameter value, includes a parameter more than once, or is otherwise malformed\" error=invalid_request hint=\"Redirect URL is using an insecure protocol, http is only allowed for hosts with suffix `localhost`, for example: http://myapp.localhost/.\"\ntime=\"2018-10-22T09:13:17Z\" level=info msg=\"completed handling request\" measure#http://10.10.0.10:9000/.latency=54527165 method=GET remote=\"10.10.20.10:59171\" request=\"/oauth2/auth?client_id=another-consumer&consent_verifier=27268dc6c37c43ef9af17b6bb2b6adf3&max_age=0&nonce=oofwtmosnyagklyeroctufro&prompt=&redirect_uri=http%3A%2F%2F10.10.0.10%3A9010%2Fcallback&response_type=code&scope=openid+offline&state=wwujsryireokwjvubyxsdton\" status=302 text_status=Found took=54.527165ms\nhow can i make our server ip to localhost or this http://myapp.localhost/ type of ip ?\n. > >Also, I don't understand I did the same process in my local system in that it's working but only one time, only one time it will generate the token after that if I try to generate it again then it will give Unable to connect Error why? \n\nBecause the CLI command that initiaties the OAuth2 flow terminates after you ran everything. You have to re-run it.\n\nI have followed this https://www.ory.sh/run-oauth2-server-open-source-api-security/ link for OAuth and after I open the browser as in last steps they said to us \n```docker run --rm -it \\\n  --network hydraguide \\\n  -p 9010:9010 \\\n  oryd/hydra:v1.0.0-beta.8 \\\n  token user \\\n    --port 9010 \\\n    --auth-url http://127.0.0.1:9000/oauth2/auth \\\n    --token-url http://ory-hydra-example--hydra:4444/oauth2/token \\\n    --client-id another-consumer \\\n    --client-secret consumer-secret \\\n    --scope openid,offline \\\n    --redirect http://127.0.0.1:9010/callback\nSetting up home route on http://127.0.0.1:9010/\nSetting up callback listener on http://127.0.0.1:4445/callback\nPress ctrl + c on Linux / Windows or cmd + c on OSX to end the process.\nIf your browser does not open automatically, navigate to:\n    http://127.0.0.1:9010/\n\n```\nso the first time it will work I don't know which CLI command are you talking about?. Hi @aeneasr \n\nThat works, thing is you didn't use that as the redirect URL but instead redirect_uri=http%3A%2F%2F10.10.0.10%3A9010%2Fcallback which is http://10.10.0.10:9010/callback.\n\nthe url is proper it's an ASCII code format so it's correct may b.\nThe error gives also solution which is \nRedirect URL is using an insecure protocol, http is only allowed for hosts with suffix 'localhost', for example: http://myapp.localhost/.\nMy issue is OAuth required secure SSL for redirect url for generating access token which i have used http protocol instead of https also i have found the same issue on github but there is no solution.\n\nThat CLI command you posted will stop working once you hit the callback URL. You have to re-run it in order to get it working again.\n\nI re run the code and it's working but for every request do i need to re run the code for every request, i don't think its a valid approach . >> i am working on server so is there any other option except this http and myapp.localhost.\n\nNo, it's a security measure.\n\nI have checked GitHub for the same issue there are available issues like (Disable IsRedirectURISecure), there is no solution found yet for that issues. How can i enable the https in server ?\n\n\nI am using docker so I don't understand that you have to re-run it but I have stopped the container and restart it but also it's not working at all it gives Unable to connect\n\nSeems like you have some trouble with understanding how Docker works here. Ask in the chat for more help on this, I'm sure someone can help.\n\nI re-run the code and it's working but for every request do I need to re-run the code. currently I am doing changes on server side this is not a valid approach for this.\n. ",
    "skymeyer": "@arekkas wouldn't it be more consistent to return Client instead of fosite.Client to line up with with GetClients ? Just a detail though.\ngo\nfunc (m *HTTPManager) GetClient(id string) (*Client, error) {\n. Looks good to me @arekkas  :+1:\n. ",
    "kke": "Looks like I had some leftovers from before, running docker-compose down and docker-compose rm fixed it.\n. ",
    "nubs": "curl automatically sets that when using -d.  I tried adding it explicitly and I'm still getting the same response.\nWith --trace-ascii, this is the raw request data:\n0000: POST /oauth2/token HTTP/1.1\n001d: Host: localhost:4444\n0033: User-Agent: curl/7.43.0\n004c: Accept: */*\n0059: Content-Type: application/x-www-form-urlencoded\n008a: Content-Length: 104\n009f: \n=> Send data, 104 bytes (0x68)\n0000: grant_type=client_credentials&client_id=886781ac-9095-4aae-887e-\n0040: 373182d468f6&client_secret=XX&scope=core\n. Awesome, thanks @arekkas.  It would seem that a lot of oauth 2 apis out there use form encoding, but I do like the idea of using the authorization header.\nThis ended up working fine:\nbash\ncurl -k -X POST -d grant_type=client_credentials -d scope=core -u '886781ac-9095-4aae-887e-373182d468f6:XXXXX' https://localhost:4444/oauth2/token\nThanks again!\n. ",
    "20zinnm": "I highly recommend migrate--you can see a great usage of it here.. How about having some memory-based messaging channel or whatnot between the auth servers and the resource servers such that, if the auth server revokes access for a user, it sends out a message to resource servers to reject tokens issued for a user from before the message came out? (I.e. some RabbitMQ deal?)\n```\ntype MessagingService interface {\n    RevokeAccess(user string) // Sends a message to everyone saying \"this guy's tokens are invalid\"\n    MinimumIssuedAt(user string) (int64, error) // Returns the earliest time a token for this user should be issued at and be valid, or 0 if there has been no recall.\n}\ntype MemoryMessaging struct {\n    revocations map[string]int64\n}\nfunc (mm MemoryMessaging) RevokeAccess(user string) {\n    mm.revocations[user] = time.Now().UTC()\n}\nfunc (mm MemoryMessaging) MinimumIssuedAt(user string) (int64, error) {\n    a, _ := mm.revocations[user]\n    return a || 0\n}\n// Somewhere else\nvar ms MessagingService\nfunc IsValid(token Token) {\n    mia, err := ms.MinimumIssuedAt(token.Subject)\n    if mia > token.IssuedAt {\n        // Token is pre-revoke-all\n    }\n}\n```\nOtherwise, I'd handle this the OAuth2 way--issue short-lived access tokens and longer refresh tokens.. I would actually ask that migrations happen automatically, because as-is it's exceptionally difficult to include hydra in an automated sequence like docker-compose because it requires this extra step.\nI think that by passing a database URL to Hydra, you are implicitly authorizing Hydra to do with it what it sees fit. That means it's a blank canvas, ready to be shaped by hydra itself to work. That takes out the human error part, and further allows Hydra to keep its database steady--for example, if there is a small change in an index between migrations and a user doesn't migrate manually, that index remains unfixed regardless of Hydra version. However, if Hydra did SQL migrations automatically, that would not be an issue.\nSee https://github.com/drone/drone 's use of https://github.com/rubenv/sql-migrate for what I'm talking about.. Well, to make Hydra production ready it should have integration tests, which would fail fast if data is accidentally lost. The point is basically to couple a Hydra version with a specific migration to allow for a linear progression over time. It makes it more predictable to have Hydra set up the database exactly how it needs.\nJust my two cents, but it wouldn't take much to add it.. Also, this isn't mutually exclusive with a separate migration tool, rather it's complementary. So if you want to upgrade Hydra you could use the manual tool to test it to make sure it didn't somehow get through integration testing with a database bug.. @kminehart I don't see why this couldn't be done with the URL right now. If you set these as secrets, then you can interpolate them into the URL (i.e. DATABASE_URL=postgres://${DB_USER}:${DB_PASS}...). If the secrets are added as environmental variables, they could in turn be used to configure another environmental variable.. @arekkas I would consider this closed.. Hydra fails requests through the load balancer because it's seemingly missing X-Forwarded-Proto. However, the docs say that that header is added.. ",
    "silverjam": "yes\n. Awesome, thanks, I'll give it a try in a few hours.\nOn Thu, Aug 18, 2016, 3:40 AM Aeneas notifications@github.com wrote:\n\nhowever, after success you should see something like this in your browser\nbar:\nhttp://localhost:4445/callback?code=HjLPph77FuC9If0iFwpsRjoYJdWSEcMG2K8YL-AaMD4.QrScM1twQP_MJj3FrNacsq8AzacQGPe5Ty3yHWspXsA&scope=hydra+offline+openid&state=cwjuzlwgufsweegpfquvvrbu\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/issues/211#issuecomment-240687591, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AALMjMorBY4-14Us3l6tG7HJ5hDZ_AAOks5qhDadgaJpZM4JnU4G\n.\n. I purged purged the docker containers (and removed the shared volume) but I'm not able to verify, but also not sure how to check what version of oryam/hydra-idp-react I have either.\n. @arekkas I'll look into verifying that the image I have is updated tonight (I'm at UTC-08:00)-- \"docker for mac\" crashed my machine then refused to start, so I ended up having to rebuild everything, thus... I'm not sure what I have at the moment.\n. Works now, thanks! \ud83d\udc4d \n. \n",
    "jainh": "when this will be added to release ?\nThank you.. @arekkas Typo corrected, is it possible to create proposal and priority for SCIM support through Hydra ?. @arekkas \"dex\" i put was typo corrected it to Hydra but my question is as per draft following is what the specification define:\n\" Discovery metadata indicating the availability of a SCIM protocol base endpoint.\n Dynamic registration metadata that is used to indicate a clients intent to use the SCIM protocol and its associated endpoint.\n An additional ID Token claim which specifies the SCIM resource endpoint and identifier associated with the authenticate subject.\n In addition to the above metadata attributes and claims, the specification will also show how a client MAY access the SCIM endpoint.\"\nSo, is it possible OpenID connect implementation in hydra can support these attributes (scim_id, scim_location, scim_profile, scim_endpoint) ?\n. @arekkas would you ok to accept help, if one needs to add support for SCIM ?. @arekkas can you point the documentation and suggestion where to look in the code, before adding support for the SCIM?. @arekkas no i am  not behind any proxy or firewall. Also, this issue is happening when i tried chrome incognito mode, once i switched to normal mode, hydra was working as expected and redirecting challenge to consent app. However, not when i tried with incognito chrome. I am running all this on local host.. Not switching tabs. I have chrome running in normal mode in separate windows and 3 windows running separately in an incognito mode. I have been trying this incognito mode, with my application, it was giving securecookie issue since beginning , but when i tried through CLI, it did work 1st time but second time same securecookie issue. . ",
    "pasikarkkainen": "Hmm.. I thought the Resource Owner Password Credentials Grant flow can't use redirects, because it's not (necessarily) web-based or interactive client? \nhttps://tools.ietf.org/html/rfc6749#section-4.3\ndid I miss something?\n. Ok, that explains. And it makes sense. I think it's better to support Resource Owner Password Credentials Grant flow with the added requirement of client needing to follow redirects, than not supporting it at all.\nSo +1 from me :)\n. ",
    "amerdidit": "It still says hdyra for me. \nhydra.apiary.io is private and unaccessable to me. \n. @arekkas do you have any other plans to include swagger in hydra? . ",
    "pbarker": "@arekkas I have an ask for this, are you still interested in implementing it?. np, https://github.com/ory/hydra/pull/412. hmm thats a bit odd, how are you syncing them? I made modifications to the oauth2 package and now I need to use those modifications in cmd, I don't see the repo under ory-am anymore, are you just renaming locally?. ok, I can make that work, this is just where Go's absolute imports are no fun, thanks for the help \ud83d\udc4d . Added \ud83d\udc4d . @arekkas this guy is good to go, I'm getting blocked on the coveralls, in order to increase the code coverage we would have to implement HTTP tests, which seems non-trivial. Let me know how you want to proceed here. CI is good now, not sure what that blip was, also removed the unnecessary parameter from the oAuth handler. ok no worries, I'll cook those up \ud83d\udc4d . Ok @arekkas, I've added tests for both routes. Some additional changes were necessary per https://github.com/ory/hydra/issues/433, having key ids as \"public\" or \"private\" is not sufficient when they are returned in the well-known response. The key id must be unique, so I added set to the key generator here https://github.com/ory/hydra/pull/427/files#diff-98aed7eaac1441068d28c70047dd9fdbR21 . Let me know if you think there is a better way of handling that. Thanks!. ok @arekkas I think we are close on this guy \ud83d\ude04, the one piece I couldn't figure out is how you are generating the swagger spec. I see https://github.com/ory/hydra/blob/master/gen-swagger.sh but thats generating a json file, are you just converting that to yaml?\nLet me know if there is anything else you see, and I will squash before we merge.  . No worries @arekkas I'm happy to get it right \ud83d\udc4d , I updated all the changes you listed and ran goimports and gofmt on all the files. Turns out the odd swagger stuff was due to a slightly older version of go-swagger I was running. There were still a couple of pieces that didn't generate right that I manually fixed. \nhttps://github.com/ory/hydra/blob/master/oauth2/handler.go#L207 is producing '302': {} where you said it needed a description to parse right. I manually added that, but we may want to look at having a custom response there. Also the scopes piece of the securityDefinitions I had to manually add to the swagger spec.\nLet me know if you want to find a more automated solution to those in this PR. Thanks!. Likewise, a client itself should be able to belong to warden groups in some way for machine to machine authentication.. So, the use case for the long TTLs is that some applications have a hard time requerying for tokens, I don't think its a priority right now, but I may whip up a PR for adding the warden groups. Thanks!. I agree short lived tokens are necessary, but their duration is somewhat relative. Ultimately, the parameter is configurable. So what about a multi-tenant space? Wouldn't each client want its own limits on the duration of access grants?. > In my thinking, you would deploy one instance per tenant and keep them as separate as possible.\nThe only issue with that is then trying to make them HA, you have a substantial overhead per tenant. Multi-tenancy seems to work fine if you make the Client ID a URN.  I can understand if thats not the aim of this project, but it could definitely be a nice add :). Is fuller multi-tenant support a feature you would consider allowing in the future? Id be happy to at least draw up a manifest to take a look at what it would involve. Thanks. @arekkas I think we are good here now \ud83d\udc4d  Thanks!. This was the one part I was unsure of, where should the BaseURL come from? Issuer might actually make the most sense. I think Issuer is fine actually, thats what its generally called by most implementers. I suppose I should add a section to the docs that emphasizes its use. Would it be ok to remove BaseURL then? . I agree I added a trim suffix to root.go https://github.com/ory/hydra/pull/427/files#diff-ff7686b39bf90dc2520886fb874371a4R125 , do we want to do that for any of the other urls there?. The docker-compose example works, I went through all of the flows in the tutorial. So this changes the generic key names to public:id-token-foo, which in turn changes a couple policies as documented here https://github.com/ory/hydra/pull/427/files#diff-08781ef00709d5059315ac5095fafabbR73 and https://github.com/ory/hydra/pull/427/files#diff-0704e4259cd334d9340c20bd02095628R8 . This has the downside of making the policy a bit more confusing. I suppose there aren't many policies that need to be written for the root keys, but let me know if you see a better way.\nIf we do want to go ahead with that, there are quite a few references to the kid being \"public\" or \"private\", the easiest way to get by that may be to add a getKeyFromType function that could be swapped out fairly easily.. The API contract would remain the same, but there may need to be some changes to /keys/set on the backend. \nGoogle: \nhttps://www.googleapis.com/oauth2/v3/certs \nMS: \nhttps://login.windows.net/common/discovery/keys  \nThey are using just a uuid for the kid, so thats another option. . Ok, I've been thinking on the least breaking change here, and let me run this by you. What if getKey() supported wildcards? Then the identifier could be mykeyset:public:29873489234, to retrieve that key you could run getKey(\"mykeyset\", \"public*\") which would return all public keys in that set. Policy could be written with a mykeyset:public:<[^:]+>. so I forgot wildcards aren't supported in url schemes. Perhaps we could do a getKey(\"mykeyset\", \"public:all\"), or maybe just assume that if only public or private are provided that it will grab all.. I think that would work as long as we are ok with reserved keywords of public and private referring to the most recent key of that type in the set. Policy could still be written as normal, but the actual key-id would be public:12345. Obviously we would need heavy documentation on the matter. The issue with that is when you return all the public keys in the well-known response, they would all have the kid of public, and the breaks a lot of client libraries that are expecting a unique kid there, which is matched to the kid in the jwt header. So the kid needs to be more enriched than just public but perhaps we can still reference it that way with a layer of abstraction. So that could work, but when I add the kid to the JWT header, which would need to happen here https://github.com/ory/hydra/blob/master/oauth2/consent_strategy.go#L102 I would need to know what that ID is. We could have the understanding that the kid in the JWT header is appended with a known value -- say a hash of the set name, and then when we send the keys in the well-known response we append that as well. \nThe downside of this is that if a person looks at the key in well-known and tries to make an API call to hydra modifying it, that kid it wouldn't exist. The same could be said for writing policy.\nA bit of a rock and a hard place \ud83d\ude04 . So the confusion here is stemming from which keys are returned in the well-known response. I am assuming that all of the public keys are returned, hence each set would have a kid of public and then you put all of those public keys in a single set and return them. Leading to 3 keys with the kid of public. \nWhats interesting as I read through the OpenID spec http://openid.net/specs/openid-connect-discovery-1_0.html#ProviderMetadata again, they don't specify which key types should be returned. Looking at Okta http://developer.okta.com/docs/api/resources/oauth2.html#get-authorization-server-keys they are returning just one key type, but with an added status parameter.\nI was seeing 3 keys from google and ms thinking it was consent, challenge, and idtoken, but it may be past, present, future of the same key type.. Yeah so the more I look at this and think about it, I think you may have been right to assume that its just the idtoken key that needs returned. I can't find any reason to have the consent or challenge keys in that set. I'll update to reflect that, sorry about the run around. \nOn the upside we've had a chance to look at key rotation within the sets. I'll leave that for another PR though \ud83d\ude09  . @arekkas I'm not sure what was going on with the swagger changes here, I just ran the gen-swagger.sh and ran it through the conversion. I was hoping you knew lol. @arekkas I know you had mentioned putting this here https://github.com/ory/hydra/blob/master/oauth2/session.go#L21 but fosite appears to not be passing the session headers though entirely. \nEven if the token headers are populated in the session, https://github.com/ory/hydra/blob/master/oauth2/handler.go#L169 appears to strip them. This is the only solution I have found that works, if we want a different solve we will likely need to move into fosite.\n. ",
    "threefoldo": "Thanks. I know the logs contain client id and secret when running with docker, but I used binary hydra which only print the following message:\nINFO[0000] DATABASE_URL set, connecting to RethinkDB.\nINFO[0000] Connecting with RethinkDB: @localhost:28015/hydra\nINFO[0000] Connected to RethinkDB!\nINFO[0000] Setting up http server on :4444\nSo, I have to look up rethinkdb tables for the client id and secret. The client id is correct, the secret is hashed or crypted, cannot pass the check in access_request_handler.go:\n```\n    // Enforce client authentication\n    if err := f.Hasher.Compare(client.GetHashedSecret(), []byte(clientSecret)); err != nil {\n        return accessRequest, errors.Wrap(ErrInvalidClient, err.Error())\n    }\n```\n. Thank you! The problem is solved. I delete the database, then everything works as expected.\n. ",
    "ericalandouglas": "Thanks for making this issue @arekkas. I like Github's way as well for the added security around audience verification but Google/Amazon's way is sufficient. The at_ext claim is the only token claim I currently envision this endpoint returning as I am not doing validation, just data introspection.\n. @arekkas that is correct. OIDC should be sufficient for my use cases, thanks for helping me figure all this out!\n. I have not updated the glide.yaml file present in this project, only the glide.lock file has been modified. If there is a particular version I should use for the new Ladon package and a place where I can derive the right version number I will updated accordingly.. ",
    "MOZGIII": "Wow. There should be a really big red warning: hydra no longer supports JWT as access keys.\nThat's a shame, because last time I checked  - it did.\nToo bad I'm only discovering it now. The solution I'm working on really requires JWT as access tokens.\nIs it possible to we add support for JWT still?. Yes, somewhere around 2015. I didn't use it then, but I stumbled upon and noted it.\nSo, how do I use Oathkeeper? Is it a replacement for Hydra?\nThe constraints I have right now is that I need an implicit grant returning a JWT access token. The client app code only supports standard implicit openid flow, and API only accepts RS256 JWT access tokens and the ability to specify well-known JWKS URL. I'd be so happy if it would just work with Hydra (or at least with Oathkeeper or maybe with Oathkeeper + Hydra somehow).. 1. Don't use the implicit flow\nThanks for the links, that's something that can be addressed later. Though, currently things kind of rely on implementing things within the constraints.\n\nDo you need an ID Token or an Access Token?\n\nI need an access token extended with custom claims.\n\nWhy does the API only accept RS256 JWT despite various drawbacks?\n\nWhat drawbacks are you referring to? The main point of accepting JWT there is to be able to verify the token without the access to auth server, or knowing which one (of many) auth servers issued the token.\nNot sure if RS256 has any drawbacks.\n\nOathkeeper is not a replacement, the docs will definitely help you understand what it does and why.\n\nSeems like it has to sit in front of the API. It's not obvious if it would work if we have not just Hydra, but also other issuers that provide JWTs. It doesn't seem like it.. > You can't revoke tokens and the payload is transparent.\nOh, yeah, but that's no big deal. Benefits are more important.\nWe can blacklist tokens, I think it's as good as revoking. Transparent payload is not really a problem too.\n\nWith the refactor, it could! It would even streamline the payloads\n\nIt'd be cool to have something like that, however it looks like it wont work now. I really missed that lack of JWT support, and I basically already spent all the time I could on integrating with Hydra.. That's ok, though I'd honestly recommend adding a note about the lack of JWT somewhere. It was really unpleasant to find out about it in the issues when the integration is done. That'd be at least some improvement in this area.. > Blacklisting requires a network roundtrip which in turn negates the request-less validation.\nBlacklist only has (and, in our case, can, since there's no single issuer that's responsible for all tokens) to live at the validation side, so no roundtrip is required there.. I need something really simple for the job. I'd use opaque tokens, but need to distinguish between the issuers to avoid verifying with all the issuers. Also typically different issuers will be only available in different environments. This authentication model is fundamentally different than the usual one, it's kind of more decentralized.\nRelying on the ability to revoke a token is not always good. In some cases it's just not correct. It's not a silver bullet, and there are many ways to cover attack vectors that are typically covered by token revocation.\nSeems like OAuth 1/2 had a paradigm shift, early on it was more like a framework that allowed, and, to some degree, encouraged implementing custom enhancements. Now it seems to be more like a set of some strict normatives. I'm counting that (the culture change, I guess) as the reason why support for JWT was eventually dropped.. Btw, I think, if we really need revocation of JWT token, nothing stops us from supporting that. If we place an opaque string inside of a JWT, in a custom key, it can be effectively used to verify the session.\nFor my case it doesn't make sense though, because session is not controlled by issuers (by design).. @arekkas, I\u2019m catching up on this issue, but there\u2019s an inportant point I\u2019d like to state, regarding adding fields to jwt: it\u2019s pointless to try to guard developers from stupidity (in the code level). There\u2019s always a way to do things wrong. That\u2019s why we have seniors, architects and other people that protect the dynamic systems from moving into wrong directions.\nHowever, empowering people with reliable, robust and well-designed tools helps a lot with mitigating the possible stupidity issues. Purposely introducled limitations, that limit the options - like removed jwt access tokens support at hydra - really takes the control out of hands of users of a tool in a way that\u2019s not helpful. Devs are lazy in general, but there are still teams that spend days designing just the interfaces, with people on keeping clean system boundaries :)\nI\u2019m not saying that the decision to remove JWT is wrong here - there is a rationale for it, but it\u2019s limiting for sure.. > > Btw, I think, if we really need revocation of JWT token, nothing stops us from supporting that. If we place an opaque string inside of a JWT, in a custom key, it can be effectively used to verify the session.\nFor my case it doesn't make sense though, because session is not controlled by issuers (by design).\n\nThat's negating the benefits of validating the tokens without an additional network roundtrip :)\n\nYeah, but what if you only need to validate the session in some cases (i.e. half of the endpoints)?. I'd love to see Vault support as well, and/or custom HSMs (for baremetal deployments).. In general, an API to use external signer is better than a bunch of the built-in ones. Take a look at caddy server model of plugins - it's very easy to use and also very flexible. I think implementing a good extensibilitry model brings benefits beyond the scope of just JWT support, and would help project to move in the right direction in the long term.. We stumbled upon the need for this too.\nSince it's not implemented yet, we'll be using a workaround solution: we have an auth gateway that accepts token from multiple sources (JWTs and opaque from hydra, I explained it at #248), and we'll add a blacklist of subs to it. Upon encountering a request from the blocked sub, we'll be denying the access, and also revoking the access token (since we'll have it in the request). So, does it seems reasonable?\nOne downside is we won't be able to anyhow invalidate a refresh token, because our gateway should actually never see it, but that's not a big deal, the access is granted via access tokens.\nThat said, without this feature, using hydra is practically as good as just using JWTs for our use case - at least in terms of session termination.\n@arekkas, hope this feedback is useful, looking forward to discuss our approach if you spot any issues with it.. @arekkas good to hear. Btw, is there any approach we could take to implement this now (without the changes to hydra itself)? For example, we can manually delete records from the database. If we just delete the session record, would hydra pick it up?. Great, thanks. So, it seems like something we could also easily backport to 0.11.12 when it's implemented. I don't think we will be upgrading to 1.0.0 at this point, as it adds complications with securing access to the hydra itself.. Got it, thanks for the info, I'll look into #904.. Sounds cool.\nI'd like this feature to be a kind of extension, that one would be able to replace with his custom implementation if needed. I mean, if one already have a far superior threat detection/analysis system (i.e. integrated with network perimeter/firewalls, in-house IDSes and stuff like that), implementing a custom solution would be the only option (based on the existing investments in the infrastructure).\nNow when I think about it - it sounds like a niche product. People that don't care about the data leaks won't care about it (and some will even explicitly disable the feature), those who care might invest heavily in security and already have something more generic deployed (or have it in plans). That leaves us with people who care but don't have existing solution (and they also have to use hydra). A market research is needed to tell for sure, but I don't think there'd a lot of those people.\nI'd recommend looking at providing enterprise support and hosted solution for hydra (basically like Auth0, but with core product being open source). Lately Gitlab had huge success with model like this. I'm not an very familiar with all this though.\nIn the technical perspective, what I really don't like is the API keys and stuff being baked in (including default keys). That means for some use cases one would have to fork the code and remove the API keys and remote server interaction parts (just like some people can find it necessary to clear out telemetry).\nAlso, note hydra, being sort of a generic OAuth token manager, may be used to not authenticate people, meaning sub not necessarily being related to a person. For example, someone might use it to authenticate a device (i.e. a teapot, or a drone, or a tank).\nTo summarize, I like the idea, and the fact that it will allow to monetize hydra and to help you keep up the good work, but also I'm kind of afraid that those additions, if executed in forced and hard-to-cut-out way, might make hydra less appealing to use for me. I have use cases where I'd use the hosted AI threat detection feature, but I also have some where I'd need to cut it out. I also have cases where I don't care about the security at all. \ud83d\ude44 \nHope my feedback is useful.. Found this: #416\nThat thread has a quite elegant solution: actually implement a single consent app and in it read the consent authorization request, verify it, map the client (we have the clientId at the response from /oauth2/consent/requests/{id}) to the correct consent URL, and redirect the user agent to a client specific consent request page. This is much better than just allowing custom consent URLs from the security standpoint.. I personally like this idea, however I'd propose something a bit different. In my opinion, if it's possible, we should separate OAuth and Hydra-specific API, not the user-facing or admin-facing ones. Rationale is the following: hydra should probably only expose OAuth API to non-admin consumers, and all hydra-related (custom) APIs can just be considered privileged. In our case, that access to hydra-specific endpoints will be organized via backend calls.\nAlso, note that the spec does not explicitly state that introspection is intended for internal use. All it says is there should be some kind of authorization. I would propose implementing two authorization options there (for user to choose): either a secret bearer token, or an plugable authorization for incoming request via webhook sent to something else, containing request details and requiring whether to allow access or to deny it (with some kind of message) in response.\nFor admin-level access, I think there should be a separate endpoint (not even under /oauth resource), that doesn't necessarily follow the OAuth spec, but provides the introspection information in the way it makes the most sense for hydra. What I mean by that is hydra most probably is capable of providing more data on it's internal state to an internal consumer than it would want to provide via public API. Format for that data might be different from what the OAuth spec dictates if makes more sense for hydra to deviate there, simply because this API should be a custom hydra endpoint (since it lives on a \"privileged control listener\").. Btw, take a look at what Kubernetes does to authorize access. It has a lot of nice patterns. Hydra could make use of few simple ones to authorize access to /oauth2/introspection.. As a service, Hydra must provide it's own authorization for that endpoint (endpoint MUST also require some form of authorization to access this endpoint). What that means in the spec is Hydra can't rely on being deployed behind a reverse proxy that would manage the access control.\nIf the authorization via a reverse proxy makes sense, hydra should probably provide the ability to disable the internal authorization.. > I think re-adding authorization is counterproductive. We got rid of it to reduce complexity when developing and authorization can easily be added with ORY Oathkeeper (as shown in ory/examples). Having said that, I have not yet looked at the kubernetes docs but will definitely do that in the coming days!\nTrue, but just partially. In my opinion, what hydra needs is a very simple but pluggable way to authenticate requests, and afaik it's only required for introspection requests. So, definitely re-adding the complexity of built-in client-based authorization doesn't make sense. That effectively means that Hydra, being an OAuth server, also becomes it's own OAuth client, which doesn't look good to have built in - I'd rather implement that as a introspection auth webhook handler.. @arekkas good point about the spec scanning attacks, I don't think we understand the attack vector here. We should ask the guys who wrote the spec for advice, can you contact them?. > On possibility to solve this easily would be to require a specific scope (such as introspection) to be granted when making the request..but man..this will be hard to teach people.\nI don't see any how it's hard to grasp :). For my use case, I'd only use the privileged (admin) variant of the introspection endpoint, so just the ability to disable the publicly accessible OAuth variant of token introspection would be required.\nI don't want to set up a reverse proxy just for that.. @arekkas I can think of ways the security might be compromised in our system through token scanning if some other security layers are breached. Though, not brute-force scanning.. > Maybe avoiding this BS and going with a more sane approach (such as declaring this an administrative API) will save us from going insane here :D\nThis works for my use case, not sure about others. I'd say if it passes the OAuth compliance we're good.. This looks good, when will it be available?. I think, intuitively it makes sense to only expose introspection endpoint on the admin port. However, OIDC certification requires this endpoint, and it requires it to be protected. And not exposing it on the public port may be considered an the \"lack\" of endpoint, despite it being exposed on the admin port (meaning that move is not considered \"protected\").\nSo, now, there should be a certification committee to judge what's the case.\nHowever, if we expose the endpoint on both endpoints - with protected version on one of them - it will completely eliminate the uncertainty there. Due to that, I'd just expose on both.\nBy the way, if we have two endpoints, we can actually mark some scopes to be hidden on the public introspection endpoint - and this may be an additional feature.. @arekkas I'm not sure about that, this is my understanding from the discussion here. I'll try to look it up.. @arekkas sorry for confusion, you can ignore that part of my message :). I'd suggest using server instead of port. In addition to that: public server and control server. What you think?. That's great, flexible enough for me!. Can we also expose /health when using hydra serve public?. I like two separate commands more. Either that, or flags, i.e. with --.... Having subcommands used in that manner is confusing.. @arekkas there still will be just a single binary with everything, right?\nI make use of both bare variant of the docker image and alpine variant btw, kudos for having two images.. @clausdenk hydra server will still work, it will just listen on two ports instead of one. Two new subcommands will allow starting either of the servers separately.. I'd suggest using subcommand flags instead of subcommand arguments, because arguments are usually positional, while flags are not. In practice it only matters a little, and I'm ok with whatever we'll settle on.\nExamples: hydra serve --all, hydra serve --public, hydra serve --control\nMaybe even hydra serve -cp instead of --all.. That's ok, I just don't like public control thing. But whatever, I've seen worse and I'm still alive :). Side note: I'm not sure, but I think dangerous-force-http is not supposed to be used in the scenario when TLS termination is done externally.. I like TLS client cert idea too. However it's unlikely I'll need this feature - when we deploy local PKI it's almost always handled with local loadbalancers. For that case, btw, unix socket support would be useful.. If you mean that instead of setting the accessToken I\u2019ll be able to set and then read some other metadata field that would be not be shown anywhere in the JWT or token introspection - or even be available solely in the current authentication flow (and consequent \u201cskipped\u201d ones) - that would also solve the issue, as I could read that metatada at the consent callback and properly reference the the correct the user object.\nHowever, I\u2019m not sure that adding a generic thing to manage store (i.e. with an unrestricted flow of updates) is a great idea. My guess that having a \u201chidden\u201d piece of data that you can assign only when accepting login request and then read everywhere else where you can read the subject might be a simpler to maintain and less error prone thing.. Data availability you're describing would solve the issue we have.\nI don't like the idea with login challenge being passed because currently the consent/login app is stateless. Hydra already persists the data related to login/consent, so in a general, I'd prefer it to handle the state. For our case it's not better than the workaround I described in the issue - to maintain internal state per subject ID in the consent/login app. I don't like it because it becomes too complicated.\nSince our case can be generalized as referencing sharded data with explicit sharding key (i.e. it's not derived from ID) having the ability to pass some additional state via hydra in there would help a whole class of systems.. For the case of just passing state from login to consent handlers we only need the first (1) option. (2) is something else, as it shares the session data. Might be useful too, but not clear when.\n(1) with the skip mode should also allow access to data, so (2) is not needed in my opinion.. I'm trying to elaborate on the generic case, not just my case.\nAnd I'm not saying that (2) is not needed in general, I mean that it's not need to pass the data from login to consent because it's solved by (1) already, and that (2), being not bound to consent/login session but to just login session, is something else.\nI didn't mean to say I know what's needed and what's not, sorry if I miscommunicated that.\nDefinetly, adding logic challenge is a good idea. :) But for me it doesn't improve the situation.\nOn the other hand, if we had both login challenge and the ability to store metadata in the login request record, I could fetch login request from the consent endpoint and it would solve my issue.. It's also true that we can add a database on our end. I just hope to find a way to keep this part stateless, because we already have a database for hydra, but the datastore for our \"users\" is kind of specific, so it's not a good option for us to extend that. Probably, therefore, our use case it's not that important for hydra - it's very restrictive. Although, I'm sure there are a lot like it in the wild.. Thanks @aeneasr. It's not urgent for us, since we implemented workaround already (we're pretty tight on time with this upgrade, so we're willing to exchange time for tech debt).\nLooking to forward to help with elaborating, hope we'll be able to remove our workaround if favor of a proper way.. Good start, thanks. This will improve the situation.. Still hoping to see a proper solution though.. I'd just want login and consent flow to be stateless. I mean, we don't even have a meaningful consent semantics - but we still need to push the extra fields for the introspection to return for token. Would work best if we just could pass them from the login endpoint.\nHow about supporting two integration flows? This sounds bad, but maybe it's not really that bad.. But then with autologin you won't be able to use that metadata.. Shouldn't a return or panic be here?. ",
    "aeijdenberg": "fyi as a drive-by comment, we were keen to find an OAuth impl to integrate with an existing product (that already has it's own OAuth server) which expects access tokens to be in the JWT format, and not supporting them will rule this out.\n(as a side note, I fully agree that JWT is an inappropriate format for refresh tokens, so please read the below in the context of access tokens only)\nI disagree about the drawbacks listed, and thought it might be productive to list the reasons why, in case it informs future product direction:\n\"You can't revoke tokens\"\nCorrect. And that trade-off is why most access tokens are short-lived (ie 1 hour or less). I think an informed implementor can make this trade-off, which is a short period of irrevocability vs the benefits of statically verifiable tokens (which is good from both a latency and resiliency view).\n\"The payload is transparent\"\nFor many resources server that is totally OK. The payload is essentially:\n\nIdentity of the user who granted the access.\nClient to which it was granted.\nScopes\nExpiration\n\nThese are not secret - and there is a latency and reliability benefit to being able to statically verify these.. ",
    "mderazon": "Using jwts can be useful for service to service communication with password credentials grant.\nLet's assume the common use case I have been seeing where opaque access tokens are terminated in an api gateway and transformed into JWTs internally to be consumed by various services (something like Oathkeeper is capable of)\nUnder this assumption, let's say service A wants to communicate with service B. It goes to Hydra and does the password flow to get an opaque access token. Then it calls service B with that access token.\nService B needs to validate that opaque token but the service already knows how to consume and validate JWTs, not opaque tokens.\nOne option would be to route service A --> B request through a gateway like Oathkeeper so that they will be terminated as well, but that's an overhead for internal service communication.\nAlso, at this point, if all services are sharing a secret, why having the overhead of calling hydra to get access token and then calling hydra again to validate that access token on the other side. They could just use a pre shared jwt as a secret and use that for authentication between them \n(?). > So if it's not possible to register the full URI, then we should fall back to the partial URI.\nIn which cases it's not possible to register the full url from the auth server perspective?\nWe are doing exact matches, right ?\nProtocol/host/path match can be useful for nested redirects:\n\nhttps://foo.com/callback?redirectTo=https%3A%2F%2Fbar.com\n\nAnd as for\n\nthe client MAY use the \"state\" request parameter to achieve per-request customization\n\ndoes that mean we can use the state param to store it there ? I thought the state param was for security and should be random\nThanks \ud83d\udc4d . Yup. Okay, from what I read, it is commonly used to store return urls\nhttps://auth0.com/docs/protocols/oauth2/oauth-state#format-and-limitations\nWe can for example have the state contain\n{\n  \"nonce\": \"_dsd3af_\",\n  \"redirectTo\": \"https://foo.com\"\n}\nBase64 it:\newogICJub25jZSI6ICJfZHNkM2FmXyIsCiAgInJlZGlyZWN0VG8iOiAiaHR0cHM6Ly9mb28uY29tIgp9\nAnd send as a state param\nAlso, according the the doc above:\n\nNote that the allowed length for state is not unlimited. If you get the error 414 Request-URI Too Large try a smaller value.\n\n414 error response defined in a spec here: https://tools.ietf.org/html/rfc7231#section-6.5.12\nI wonder if Hydra checks for a specific length or just inherits from the Go http server config. > Yes, you can also store it on the server-side. You have to store the state anyways in a cookie, so why not the redirect value?\nGood point. Thanks \ud83d\udc4d . What an awesome open discussion. Helped me a lot understanding the changes coming in 1.0.\nThanks for all the participants.\n2 pieces that are still missing for me are user registration and logout.\nI guess registration is no different than login from Hydra's point of view ? UA tells Hydra there's a new user and sends the details just like it would have on login. But still, a session might need to be saved on the UA when  the user navigates from login page to sign up page ?\nAnd regarding logout, would that be done via calling Hydra's /oauth2/revoke endpoint ?. @arekkas Can I use Hydra to authenticate my own app's users via OIDC ? In such case, would I still have to show a consent screen to the user ? Doesn't make much sense if I have a sign up page for my own service and in the sign up / sign in flow I show the users a consent screen. @arekkas the fix is very small, however since it's my first time dealing with Go, I was hitting some issues running tests (missing packages, even after go get) and also a weird behaviour something making changes to files in the project that I didn't ask for.\nI checked and the changes were forced even after I closed VSC, very bizzare. No way to revert them, they just keep popping back.\nAnyway, would probably take me a lot more time to understand the tooling around it than to actually make the changes.\nRegarding the changes themselves:\n1. I am not sure I wrote the actual redirect correctly: https://github.com/ory/hydra/pull/971/commits/171fb6d8d26d98a4a409fff3666b6decae46e51a#diff-ac4ce4ab0ca6c69035745a50d3108c65R603. Also, should it be 302 redirect ?\n2. Please review the swagger decorators for the route. Not sure it's good (see description and return type etc)\n3. Please review the route handler name. Naming is hard...\n4. Couldn't find a place to write test for this route.\nAnyway, hope it's not creating more work than it would for you to write it :-/. Thanks for the valuable feedback.\nOne more thing - What should be the behaviour if the user does not set LOGOUT_REDIRECT_URL ?\nTwo options\n1. Fail at startup (too aggressive probably)\n2. Fail at the endpoint. Were you able to disable it ?\nIt might be something  with the repo, because if I clone the repo on a new location I am getting errors\ngit clone git@github.com:ory/hydra.git\nCloning into 'hydra'...\nremote: Counting objects: 15217, done.\nremote: Compressing objects: 100% (158/158), done.\nremote: Total 15217 (delta 119), reused 128 (delta 80), pack-reused 14973\nReceiving objects: 100% (15217/15217), 33.07 MiB | 952.00 KiB/s, done.\nResolving deltas: 100% (10042/10042), done.\nerror: unable to unlink old 'sdk/js/swagger/docs/JsonWebKey.md': No such file or directory\nerror: unable to unlink old 'sdk/js/swagger/docs/JsonWebKeySet.md': No such file or directory\nerror: unable to unlink old 'sdk/js/swagger/src/model/JsonWebKey.js': No such file or directory\nerror: unable to unlink old 'sdk/js/swagger/src/model/JsonWebKeySet.js': No such file or directory\nerror: unable to unlink old 'sdk/php/swagger/docs/Model/JsonWebKey.md': No such file or directory\nerror: unable to unlink old 'sdk/php/swagger/docs/Model/JsonWebKeySet.md': No such file or directory\nerror: unable to unlink old 'sdk/php/swagger/lib/Model/JsonWebKey.php': No such file or directory\nerror: unable to unlink old 'sdk/php/swagger/lib/Model/JsonWebKeySet.php': No such file or directory\nfatal: unable to checkout working tree\nwarning: Clone succeeded, but checkout failed.\nYou can inspect what was checked out with 'git status'\nand retry the checkout with 'git checkout -f HEAD'. Thanks a lot of this @arekkas .\nSorry I wasn't able to contribute more, was in the midst of incorporating your changes but was hitting the git issues and then had to work on something else.\nIt seems your changes ended up being more substantial and you also added the tests, so I guess it's for the better ;-)\nThanks again for all the hard work for this really great open source jewel. ",
    "someone1": "Just a quick plug here - I'd love for there to be JWT support for access tokens, I'd like it even better if we could plugin custom JWT signing mechanisms.\nI mention this because I've effectively (read: foolishly) hacked the hydra bootstrap process to get my own database and JWT signing mechanism in place. I also had to wrap the oauth2.DefaultJWTStrategy used since it always expects a OpenID Session (See this commit) which you may run into while implementing this feature.\nI know for the database part I could try the plugin route, but this doesn't make sense for my backend. There currently exist nothing for plugging in a custom signing mechanism.\nIf this opens the possibility to selecting a signing mechanism, maybe this can be made to be customizable? I'd suggest to use the model used by the https://github.com/dgrijalva/jwt-go package where you can dynamically register token signing types (which I did for GCP).\nJust food for thought, I'd also like to see that for the database side too and would be happy to suggest a simple modification to the current codebase to enable this or even submit a PR!\nI hope this all made sense, I'd be happy to discuss in chat or elaborate here if anything is unclear.\nEDIT: Also, the use of oathkeeper doesn't make sense for my use case as I already plan on using an API Gateway from my cloud provider (not an equal comparison but still relevant) - I have an existing IDP to layer hydra on top of and can leverage other existing technologies for protecting my oauth2 protected endpoints-  in my case an API.. Well I'd actually utilize RS256 myself, but leave the signing to GCP - they manage secrets and rotate keys so I don't need to worry about it. ~~Its my preference to utilize a proper KMS.~~\n~~Alternatively, maybe I can create a ticket to introduce GCP/AWS key management systems as pluggable backends for the jwk features of hydra?~~ Keeping secrets is hard to get right, and separating keys such that not even hydra knows the private key greatly enhances it's security IMHO (separation of duties, utilizing a battle-tested system, etc.)\nRE accepting token signing types: I'm aware of this and the jwt package does a good job of explaining how to mitigate this. I don't think this is a reason to prevent enabling the usage of such mechanisms - just helps those of us looking to extend the capabilities while adding arguably little-to-no overhead to the core hydra features/goals.\nEDIT: Removed mention of KMS - not relevant for handling signing, only encryption. However, I know GCP offers a signing API with backend key management, not sure about AWS.. I don't think you'd get a generic solution that spans multiple providers. Just like you do with database backends, I'd expect a generic interface each implementation would have to satisfy for the backend wanted. I don't expect this to be a part of hydra, but something that we (as developers) could inject in a custom hydra deployment without having to do all the copy pasta as I did in my repository.\nI was mistaken in thinking GCP/AWS KMS does signatures, it only does encryption/decryption. I do utilize GCP's IAM API to sign blobs and utilize them for JWTs - it uses the RS256 algorithm. I believe Vault by HashiCorp also allows secrets management with signing capabilties.\nThere could be other such systems out there that may be more secure than using what's baked into hydra, or just to enable separation of duties. I don't believe hydra would incur any maintenance overhead in enabling dynamic registration of backends for this, it would just ship with reasonable defaults.\nTo illustrate a bit on how I envision the change to be, I'll take the backend example where you can use a plugin vs SQL: Instead of a switch for the types supported, an interface would be defined for the backend registered that returns the manager type required.\nhandler_oauth2_factory.go becomes:\n```go\n// Showing a simple interface for this specific file, probably would be a more generic interface that had functions which returned the proper backends for each of jwk/oauth2/client/consent/etc.\ntype FositeStoreManager interface {\n     NewFositeStore(clients client.Manager, lifespan time.Duration) pkg.FositeStorer\n}\nvar fositeBackends = make(map[string]FositeStoreManager)\nfunc init() {\n  // Load default supported backends\n fositeBackends[\"memory\"] = oauth2.FositeMemoryStore\n fositeBackends[\"mysql\"] = oauth2.FositeSQLStore\n}\nfunc RegisterFositeBackend(prefix string, backend FositeStoreManager) {\n  fositeBackends[prefix] = backend\n}\nfunc injectFositeStore(c *config.Config, clients client.Manager) {\n    var ctx = c.Context()\n    var store pkg.FositeStorer\n    if backend, ok := fositeBackends[ctx.DatabasePrefix]; ok {\n         store = backend.NewFositeStore(clients, c.GetAccessTokenLifespan())\n} else {\n    panic(\"Unknown connection type.\")\n}\n\nctx.FositeStore = store\n\n}\n```\nThen in a package such as mine I could register such as:\n```go\nimport \"github.com/ory/hydra/cmd/server\"\nfunc init() {\n    server.RegisterBackend(\"datastore\", MyDatastoreImplementation{})\n}\n``. The current plugin system for database backends isn't generic enough, it expects a*sqlx.DB` implementation which doesn't make sense for all databases (e.g. any NoSQL database). Additionally, I want to inject my own middleware handlers for logging/tracing/security and other misc. things specific to my deployment environment. I don't think a plugin system is necessary for all these parts, but just exposing the bootstrap process a bit in the code to allow this would be helpful.\nEither way, I'm really glad to hear that we can possibly support a pluggable system for signing here - I'd be happy to discuss this more design-wise and help with implementation if you'd like!. Sounds good, I'll keep an eye on this issue when development starts.\nThe *sqlx.DB reference for plugins is required as when its loaded an immediate call to db.Ping() is made. I can open a separate issue to drop the reference altogether as the plugin should be able to manage the connection on its own and doesn't need the reference it returns to be passed into its own exposed functions as a parameter.. The session seems to persist the request.Form so maybe this can already be done with slight modification of the challenge session persistence?\nIf a request comes to the /oauth2/auth handler with an audience URL parameter (in addition to the client_id, state, redirect_uri, etc. like Auth0 does), then this can be persisted in the ConsentRequest and returned as part of the Session.\nSide note, it looks like hydra is treating every auth request as an OpenID Connect request? Unless scope=openid is specified, you do not need to force the aud=client_id behavior. All Sessions seem to be represented internally as fosite openid.DefaultSessions. I don't think this impacts anything but was confusing to me as I was trying to use hydra's handlers and wanted to use JWT tokens but got an OpenID token instead.. Depending on how issue #772 is implemented, this might be rolled up into those changes?. Anybody have a look at https://opencensus.io/? I personally bootstrap Hydra on my own and overlay StackDriver for tracing - I only bring this up as the PR's current implementation seems specific to a single tracing service (jaeger).\nIs the idea to only support CNCF projects within Hydra?\nEither way, I'd really love to see tracing beyond just HTTP requests - luckily for me since I also use my own database plugin I get tracing for both HTTP requests and database queries but only where the requests' context.Context is passed down. Maybe some restructuring can be done to pass the context down throughout the entire application on a per-request basis, and wire up more traces throughout (especially for database interactions)?\nWould also like to see StackDriver support though doesn't look like there's opentracing.io support for it, however opencensus.io does seem to support most of the same major backends as opentracing.io as well as StackDriver!\nEDIT:\nTo further my opencensus.io vote:\n- SQL wrapper in Go for adding tracing (looks like a simple addition!)\n- Can replace current prometheus export functionality\n- Already has a idiomatic Go HTTP server wrapper. I think it makes sense to choose a framework and wire up Hydra (and other ORY products) for tracing/metrics with said framework. Then you can probably support 1 or 2 exporters and maybe introduce a plugin system similar to databases for others? OpenCensus also has this repository which aims to let your code be instrumented with OpenCensus but lets the user setup which backend to report the data to - probably worth keeping an eye on as it probably eliminates the need for Hydra to do anything more than support a single exporter which can then be confiured to send metrics/traces to other systems without Hydra having to support them all itself.\nReally it comes down to OpenTracing vs OpenCensus today, with the latter covering stats in addition to tracing. Both provide a vendor-agnostic way to instrument your code for tracing, but they differ in project scope. From what I can tell, outside of stats collection that OpenCensus provides, OpenTracing is more of a spec that vendors are urged to support, OpenCensus will do the data collection for you and officially support backend products to report to.\nThere is much discussion about the two - Google decided to bring OpenCensus out there despite OpenTracing being revealed almost 2 years prior.\n. I actually have a PR for the first part done (database plugin) - I think it simplifies a lot of the database config process around hydra. I'll submit a PR shortly for this and maybe we can discuss the changes I made there (though no hard feelings if you reject it!)\nI'd like to discuss the plugin extension around external JWT signing mechanisms - I think hydra needs to decouple the jwk bits by adding more interfaces like there is around the other parts of the code first.. Actually, just read the contributing document. Here is my work in a single commit.\nThe gist of the changes are:\n- Introduce a backend interface for databases\n- Create both memory and sql implementations of the new interface\n- Update plugin load sequence to leverage new backed interface\n- Update config/context loading for the new interface\n- Update cmd/server bootstrap for the changes to config (greatly simplified)\n- Enhancement to cmd/server: create an exported function that takes in a hydra.Config and spits out a http.Handler\nIt's a relatively small change architecture-wise (IMHO) - and it removes much more code than it adds while increasing flexibility of backends supported.\nLet me know if you're open to a PR for this, I've run tests (with -short) and can follow the remaining steps in the contribution guide. Open to feedback as well!. How about I take that out of my PR and you put something in #904 to the same effect (for both the Admin and Public facing handlers)? It's really an oddball in the PR anyway, the entire handler.go file doesn't need to be touched for the changes to the Plugin system/new database backend interface. \nI really just cut/paste out the handler code to an exported function NewHandler and moved out anything that was still changing the configuration object.\nGlad to hear you like the changes, let me know which way you're leaning!. Added a PR - reintroduced dependency checks as requested and added a test script to compile and load a database backend (just the memory backend using a different name).\nCan wait/rebase if you want to finish your PR first.. Updated though one thing to note is dependency checks are still used in cmd/server unrelated to injecting so I basically just copied this out to config and left it there.. It's actually used once when signing userinfo responses - maybe this was not intended?. Does it make more sense to just add GetPublicKeyID() (string, error) to the JWTStrategy interface in fosite and just use that here? Looks like the implementation in hydra just layers ontop of fosite to refresh the keys.. I opened an issue on fosite but maybe I was mistaken in doing so. Should we introduce a new interface in hydra, extending the fosite interface with the GetPublicKeyID() (string, error) function? Reason being is that this feature is dependent on key management which may be out of scope for the fosite interface? \nThe only way I see this being implemented in fosite is by adding an exported PublicKeyID string property to the existing RS256JWTStrategy implementation so it can be set/updated along with the exported PrivateKey value? \nI think it makes more sense to extend the fosite interface by introducing a new interface in hydra. If this is what you meant then I'll go ahead with a PR and close the issue  I opened in fosite. I'm open to discussing this further.. It was fairly quick to get this one done, you can preview my hydra changes and let me know what you think!. Sure I don't mind adding an example - do you just want a basic example of how to bootstrap hydra outside of hydra?. closed by https://github.com/ory/hydra/pull/1023. Another potential bug here, even with CORS enabled, am I able to exchange an authorization_code for a token? If I whitelisted URI's on my client for CORS, the way the CORS middleware is currently written, unless I use Basic AUTH on my request, it will expect an Access Token on the request which is what I'm trying to get with the request.\nAm I reading this right? The other alternative is to whitelist CORS with the CORS_ALLOWED_ORIGINS option but that is more of a global setting than a per-client setting, the latter being desired.. #1116 and #1118 may have addressed some concerns here - I'll review and close this if necessary.. Word of caution: The AllowedHosts setting killed hours of debugging for me - my health checks weren't passing in a Host header (or rather, a value of '-') which was being rejected.. I think we should put some easy-win security headers in hydra - given that hydra's function is explicit to a certain purpose and is supposed to be hardened, some headers such as the XSS, No Sniff, CSP (dynamic for frame-ancestors?) should be set without question (e.g. not user configurable). I think adding a HSTS option should be quick/useful given there is already so many controls around TLS (I'd suggest to make this automatic as well but it can have lasting effects on a users domain that may be unintended).\nCORS in hydra needs to be revisited in general - we can leave that for the other ticket. \nUsers don't always have control over load balancer's/reverse proxies that sit in front of hydra, or may have to setup one for adding such headers. Overall, I think if hydra is billed as a hardened security appliance it should put some default, hard-coded headers in place as appropriate for its function, leaving the rest to user's where deployment specifics may warrant tweaks (e.g. forwarding TLS requests over HTTP, CORS, HSTS, etc.)\nWith cobra/viper in hydra, config can be as easy as a YAML file - though I know there are a lot of options already. Sensible defaults are already provided and I think it's great hydra gives advanced control over its operation for advanced deployment scenarios.. Yes I can tackle this. Just so we're on the same page, here is what I'd plan to do:\n\nIntroduce github.com/unrolled/secure middleware - statically set BrowserXssFilter & ContentTypeNosniff options to true\nIntroduce HSTS options to hydra to enable the feature in the new middleware - Preload, Subdomains, Seconds - or is 3 options too many? Should I give the option to pass in the header's value or just an on/off which puts the typical subdomain=false, preload=true, seconds=315360000?\n\nAlthough the middleware does overlap in terms of enforcing HTTPS connections, it doesn't have a health check bypass or IP enforcement check like hydra gives options for so I think it's best to leave those as-is. I could complicate the middleware to bypass the secure middleware on health checks and still keep an IP check middleware somewhere after this one - what do you think?\nAs for CSP - I think this should be set statically here, but only have we introduce dynamic CSP options on a per-client basis. This can be done by auto-whitelisting redirect URIs like some providers do or introduce a CSP Referrer option to clients like there are for CORS. I can open a new issue to track this.\n. HSTS will ensure no MITM attacks are possible - e.g. ALWAYS disallow HTTP at the client level, it doesn't matter if hydra is configured to only accept HTTPS, but HSTS explicitly forbids HTTP. This will make it so a  client (e.g. a web browser) won't accidentally connect to a HTTP server if a MITM attack occurs. \nNot all Load Balancers support adding headers on responses (e.g. Google's cloud load balancer) so adding the option in hydra would make sense. It's up to the user to understand the ramifications of enabling this feature if the domain is shared with other services - I personally deploy hydra in a dedicated host with a dedicated subdomain.\nRe CORS vs CSP: I understand Per-client CORS is already enabled, I was asking if we should do the same for CSP headers. My idea is to explicitly disallow everything via CSP by default and only enable domains on a per-client basis as we do CORS.. I think HSTS is independent of the other HTTP settings - regardless of whether or not hydra is running with its own cert, behind a secure proxy, or in HTTP mode; if the user enables the option(s) then it should be used. It's only possibly incorrect to enable the feature if running in HTTP-only mode so we could add a check in for that to warn the user. \nI think we should still discuss the flexibility of the HSTS options though - should it be a single option with sensible defaults, a single option which passes the header through (e.g. the user passes in the header's value as an option), or break each part into separate options for the user to configure and we assemble the header in code (e.g. preload, subdomain, age).\nI think we're on the same page for CSP - nothing in hydra should load anything external so by default the value you gave should be used (default src 'none'). The only exception would be when we want to try a silent refresh from an iframe, in which case we need to whitelist via the frame-ancestors option. Most providers automatically whitelist redirect URLs for both CSP/CORS but I see that in hydra this is broken out separately. Should CSP Frame Ancestors be a new client option?. I think it should only be allowed on whitelisted domains? Here were my thoughts on it:\n\nEvery request, by default, is set with the default-src 'none'; frame-ancestors 'none'; CSP header (frame-ancestors does not fallback to default-src)\nOnly the /oauth2/auth handler should overwrite the header with something like default-src 'none'; when the referrer is a whitelisted URI?\n\nRegarding the login/consent pages within the iframe - yes the developer will need to figure this out on their own. There is a section from the spec that discourages the use of iframes completely. Some providers allow it (e.g. Google) and some don't (Fitbit, Intuit). For silent refresh to work in the background, I think hydra must allow it.\nAdditionally, since frame-ancestors is fairly new (not supported in IE), setting X-Frame-Options may also be valuable alongside the CSP settings.\nI think you have a much better understanding of all this so if you think we should just leave it be in hydra, I'd be happy to oblige - we can at least set the default CSP to default-src 'none' which does not affect frame-ancestors and would prevent any sort of external content loading in web browsers from any of the hydra page handlers.. Regarding PKCE + Silent Refresh - there is no way to secure data in the browser, and since PKCE was written with \"apps\" in mind - not necessarily all public clients such as a web browser, I don't think there is a good way to use refresh tokens with PKCE in the browser. That said, refresh tokens should be avoided in the browser and mechanisms such as silent refresh should instead be used IMHO. \nI think it's a defense-in-depth mechanism to only allow the auth handler in an iframe from a whitelist - let the developer decide if it's ok to embed the authorization handler as an iframe, and only on trusted domains.. I think I follow and I guess most situations are avoidable as long as the login, consent, and actual app correctly have CSP headers in place to prevent framing them. The auth handler will always redirect to one of these, all of them being whitelisted (hopefully HTTPS) destinations. I think the RFC assumes that the authorization server's /oauth2/auth page is the login/consent pages which is where clickjacking would occur, but in hydra this is not the case.\nThe attack also assumes that the owner of the hydra server is allowing public or otherwise non-vetted clients to register, thus allowing a malicious actor access to carry out such an act (this goes to your second point). For users of hydra where clients are more strictly created, allowing per-client CSP options may be valuable but I guess arguably not necessary.\nI'll get a PR together. To re-cap:\n\nIntroduce github.com/unrolled/secure middleware - statically set BrowserXssFilter & ContentTypeNosniff options to true\nIntroduce an option to enable HSTS options to hydra to enable the feature in the new middleware - using a cautious value of subdomain=false, preload=false, seconds=315360000 (do we want to set preload=true here?)\nEvery request, by default, is set with the default-src 'none'; frame-ancestors 'none'; CSP header (frame-ancestors does not fallback to default-src) except for the /oauth2/auth path which will only get the default-src 'none'; header.. When updating my plugin to work with the latest context fixes (thanks @aaslamin !) I was getting panics when running tests as a nil context was being used in parts of the test.. I like the token over offset idea since I use a NoSQL datastore and so offsets are expensive compared to tokens (in my case, cursors). Luckily, even without ordering there's an implicit order in queries to create a token off of - maybe there can be a way to do this with MySQL? Or maybe introduce an auto increment ID column for each table and make that the PK (adding UNIQUE and INDEX where applicable on other columns)?. Asking for clarification - only clients within hydra cannot be ordered and thus need some mechanism put in place if hydra uses token-based pagination, correct? Like a new auto-increment PK? Everything else can be sessioned by the creation/request date? Would it not also make sense to add a creation date to clients from an auditing perspective?\n. Ahhh - would it be possible to leave that as a string type in the code so I can shove my token in there? There's going to be some kind of int64 -> string and vice-versa conversion for it anyway.. I had to create a testhelpers subpackage to avoid cyclic imports (consent tests rely on the oauth2 package and vice-versa). Yes I realize that, but since the tests found in the package use the package name consent_test (black-box testing) I could not break out the tests without introducing cyclic imports unless I placed it in a separate package. I realize I used an anti-pattern here, though I'm not sure of a proper fix which wouldn't introduce code changes all around hydra. I think the only reason you can get away with a different package name for the test files than of the package itself is due to the _test.go file name prefix which the compiler ignores when building the package and running tests.\n\nOther ideas:\n\nBreak out each inner t.Run as a separate helper function, and leave oauth2 dependent tests separate (seems counter to the goal of the PR)\nMove interface definitions for the various managers to a centralized location (config package? ~~also introduce an interface for the FositeStore?~~ I realize hydra/pkg has the interface in question) - this would be a lot of work and touch a lot of places of hydra\n\n. the interface find in the pkg package fixes all this! Sorry for the confusion, I'll update the tests to deal without access to the direct object but only access via the interface.. Another thought: https://github.com/segmentio/ksuid\nI used to use UUIDv4 and switched to this in my application. The benefit is you still get ordered results and a non-integer, random ID, saving you a column of data and an index.\n. Ah - completely forgot the API allows user-created client ids... Though I hope you'll keep ksuids in your toolbox for the future!\nIs this issue really resolved by adding indexes to those columns in the oauth2 tables? Wasn't the issue this was trying to address on the client table and the lack of a stable, sortable column (e.g. auto_increment PK and/or a creation_date field)?. LGTM\nGreat job!. I've done this so many times and yet I didn't realize ...Mondays, amirite? \nAlso should have been DATABASE_URL. @aeneasr Thanks for the heads up - is this in any of the exported tests? If so it shouldn't be a problem!. If this is a security concern then there should be a test for it (IMHO) - don't want to forget about it one day! Adding it to one of the test_helpers.go files would make it reachable for anybody developing plugins.. Not a problem! \nI wonder if there's a way for tests to load the plugin (if present) into the database managers  list when running tests, maybe that way I don't have to worry about tests being exportable and can even gain entry to any tests I've overlooked. I'll be sure to look into as I catch up with hydra over the next couple weeks!. This should be good to merge, let me know if there's any other changes you'd like made!. Hmmm - so move the function and all calls to config and call it as required there, e.g. for the SQL Manager? I'm not entirely sure why these were added so I just copied them back as best I could.. Sure, so BackendConnector then? Any thoughts on what variable we should load from the database plugins? I'm using Manager right now but can update this to Connector to match this name change.. This is the only test that was modified. Since we don't have access to the actual fosite memory manager anymore, we rely on the interface access methods to validate the Access Tokens/Refresh Tokens are present or not. Added when running dep ensure - probably a dependency added from commit 26d1d12c77b69dc155ba8ba89b629c2743023969. As-is, this additional argument is useless in the context of plugins - the underlying options type is inaccessible and should be exported.. It would be clumsy to have to keep the two in sync though they should probably be decoupled. \nSome of these seem developer specific for debugging/testing purposes. Why build them in as general options/hydra config settings when you can just have them hidden in the driver level and enable them as-needed? UseRandomDriverName and AllowRootTracingSpans don't seem to be used at all (not even user-configurable) so why even introduce them as options in hydra? OmitSQLArgsFromTracingSpans should almost always be disabled and I'd guess enabled only for debugging/testing - this can be left out of hydra as a config option IMHO and left as a hidden option enabled in the driver using env vars for those \"in the know\". It's also currently specific to just the SQL driver - in the case of plugins it might not even make sense.\nOptions should probably be exported for plugins to leverage - and should be general in their definitions.. My apologies for not being clear on that - I meant that traces should always omit the data. For general hydra use-cases, I don't think there's a time this is needed outside of debugging/testing.. I had to copy theses out since they're originally found in a _test.go file here: https://github.com/ory/hydra/blob/master/oauth2/handler_test.go#L55. I didn't bother properly naming the exported fields although I could if desired. Moved these to the exported package to make it easier to track changes to tests.. Marked this function as a Helper since its function name would be useless in any stack output when running tests.. ",
    "nikolay-turpitko": "@arekkas as we discussed in the gitter, I've tried to convert API spec from apiary to swagger and generate code from it in my own project (using go-swagger). You may check results here (this is a folder of my project, containing interface to Hydra and unit-test for it). Here is the difference between API invocation without and with swagger-generated code (to highlight \"sdk\" usage).\nupdate-spec is a script I used to fetch API spec from apiary and convert it to swagger 2.0 yaml with online converter API (you need an account to execute it). After conversion, script applies 3 patches to downloaded yaml file. I intentionally separated this patches to clarify required changes. First of them only fixes spec so it won't fail validation (online or with go-swagger). Next patch adds some missing parts to the spec (oauth2/revoke request and JWK type definition). I haven't found all possible issues in the spec, only those, related to the methods I actually use in my project. Finally, last patch removes all staff I don't use, because some lead to error during code generation and I decided to leave it for now.\nActual generation runs during project build with go:generate. I added generated code to gitignore, after build it would appear in the folders 'client' and 'models'.\nBelow is a summary of my findings about Hydra API and generation process:\n\nSome parts of spec, which I don't use in my project, caused errors during model generation. I just removed them from my version of spec, but they stay in the full spec.\nI had to enhance JWK type definition, otherwise generated code failed to unmarshal it.\nI changed some tags and operationId's in my version of spec, otherwise go-swagger generated ugly names for packages, types, fields and methods. But these names may not fit into human-readable documentation well.\nEven with changed names I was not able to fine tune generated names. For example, it changes 'JWK' to '_j_w_k' in package name and 'jwk' to 'Jwk' in property name. Both originate from the same field in yaml.\nModel of the returned errors is, probably, out of sync with actual implementation.\noauth/revoke request was missed in original spec.\ngo-swagger uses pointers more often, then necessary, but it's known issue.\n\nRegarding PR, I just don't know what is worth to pull into Hydra project at the moment. I may give you partially fixed swagger spec (or you may easily create it with my script). But someone should check and fix the rest of the spec.\nRegarding this issue as whole, I think, I'd be pretty happy to have actualized swagger spec in the Hydra project, so that I would fetch it into my own project, remove all unnecessary parts from it and generate my own lean API. It would be even better, if Hydra used API versioning and versions wouldn't change between major releases. This way, I'd be able just generate \"sdk\" for my own use on whatever language I need. I suppose, it can be pretty difficult to test and support all SDKs on all different languages. If you want to do this, it's, probably, worth to move this support into different github projects and leave only spec in the main project.\nIf you are interested in using go-swagger in your project, you have a couple of options:\n\nYou may want to use it only to generate client SDK. In this case you may create spec manually, or generate it from annotations in your code. Annotations you'll create manually as well, so difference only in that annotations are closer to the code, so you'll sooner notice them when you change the code.\nYou may start from spec and generate both client SDK and server-side stubs from spec.\n\nObviously, you'll need to use some other swagger tool to generate SDKs for other languages.\n. @arekkas I've tried to use both apib2swagger and api-spec-converter. Unfortunately, all 3 of them (if count apimatic online converter, which I used before) produce differently incomplete swagger spec.\napimatic created some noise, but extracted more information and produced more reliable references and definitions.\napib2swagger lacked some of references and definitions. For example, it completely omitted definitions for warden endpoint.\napi-spec-converter created output file with all sections in different order. I was not able to work with this output. Probably, it's output is syntactically correct, but I was not sure if the order of sections is stable between invocations, so I was not sure if patch tool would work with it.\n. @arekkas: https://gist.github.com/nikolay-turpitko/472213904f324ef89cb27a9225adb142#file-hydra-yaml\nI've merged output of all 3 tools. Process was mostly manual. File validates with go-swagger and online swagger editor. Both online and go-swagger can serve it with swagger UI, seems OK. Go code for client also can be generated from it. I've tried to convert it back to apib with apimatic, but, of course, result is not quite similar to original file. You should check this file, because something may be missing. For example, basic auth headers are lost for sure. They, probably, should be similar to oauth/revoke, which I added manually. I've not tried to compile generated code yet.\nEdit: changed link, so it point directly to file, because I added also both script and generated apib there and yaml get lost between them. Also, I've tried to compile generated code, but after some \"beautification\" - I've changed human readable names in spec to generate less ugly names in the code (don't know how to do it right, probably it should be done right in the swagger spec). It works.\ngo-swagger uses tags as package names, but swagger UI uses them to display API doc to the user. Also, I changed some type names, generated by converter, probably this part might be done right in spec - someone should review the spec and choose nice names instead of generated. I'll add link to my patch here (just for idea what I'm talking about) when I push it.\nEdit 2: You may also use this link to see spec it UI, just submit it with previous link in the field at the top. And here is the patch which highlights fields of yaml files, used by go-swagger to generate code. It uses tags as package names, so I converted them to lowercase and just one word. It uses operationId as name for the methods and names of definitions goes into generated type names.. Well, OK. #249 is an interesting approach, might be a good alternative.\n. Please, disregard following comment. I've found an issue. It was due of outdated docker image.\nYet another question about this request. When I send request with some scope in it, it responds with another set of scopes and \"allowed\": true. Is it intended behavior? Sample:\n```\nrequest:\n{\"token\":\"xxx\",\"resource\":\"rn:xxx\",\"action\":\"get\",\"scopes\":[\"test.zzz\"]}\nresponse:\n {\"sub\":\"\",\"scopes\":[\"core\",\"hydra.keys.get\"], ...,\"ext\":null,\"allowed\":true}\n```\nHere, test.zzz is arbitrary scope which is not in the set of scopes of the client.\nQuestion is: shouldn't response be status 403 Forbidden? Or should API user compare set of scopes himself?\nI use dockerized version of Hydra.\nClarification: we fixed setup in accordance with your previous answer, now it works in regard to policies, but seemingly ignores scopes.\n. Yes, scopes seems to work as we expect with recent docker image. We have not tested them thoroughly, but, at least, unknown scopes are rejected. Documentation is a bit of an issue though. We had to study sources of hydra, fosite and ladon to understand usage of this API request.\n. Well, regarding this particular request (http://docs.hdyra.apiary.io/#reference/warden:-access-control-for-resource-providers/check-if-an-access-tokens-subject-is-allowed-to-do-something/check-if-an-access-token's-subject-is-allowed-to-do-something), it, probably, helped if description explicitly says what is the meaning of each argument passed to request and what is expected behavior. I mean, it more or less intuitive now, when we know how it works internally, and observe a correct behavior. But we were puzzled, when observed incorrect behavior and were not sure is it incorrect behavior or we misunderstood how it is supposed to work.\n. Well, RFC 7662, say \"SHOULD NOT\" not \"MUST NOT\" at this particular point. And https://tools.ietf.org/html/rfc2119 explains, that \nSHOULD NOT   This phrase, or the phrase \"NOT RECOMMENDED\" mean that\n   there may exist valid reasons in particular circumstances when the\n   particular behavior is acceptable or even useful, but the full\n   implications should be understood and the case carefully weighed\n   before implementing any behavior described with this label.\nBut, seriously, it probably not worth it. Fill free to close this issue.\n. ",
    "abdollar": "@arekkas In terms of the health check. It would be great to use something that is an indicator of the health of the system but its not a high priority at this stage. One thought I had was to create a specific client for the load balancer so it actually generated a token and use the client_id and secret as part of the health check. This could then be tied to an auto scaling infrastructure.\n. ",
    "theflyingcoder": "it looks like we may have a need for this and i'm looking into how best to implement this. let me know if you guys have any concern/suggestions.. At what point is it the most effective to add the fallback queries? In other words, how do we know when the data in memory/cache is not up-to-date?\n. ",
    "joshuarubin": "This would be hugely beneficial for us as well. Right now we have to loop through several possible actions and check with warden for each of them for a single request to our api.. I'm just curious if a solution to this issue is required to do the following:\n\nEnd user is taken through the user auth flow and approves the RequestedScopes for a single \"app\" (ClientID) which include the offline scope. User may never have access to the token or refresh_token.\nUser later would like to revoke their approval for that particular \"app\".\n\nAs I understand it, this would only be possible if the \"app\" provides a mechanism for the user to do this since the app (which has access to the tokens) can revoke the token and refresh_token with the /oauth2/revoke endpoint.\nWe, however, would like to have a single interface for the user to see all the applications they have approved and have an opportunity to revoke access for any particular app.\nWe keep track of the applications (claims.Audience) that the user has approved by hooking into the consent app. So listing the applications for the user is not an issue. We just don't appear to have any way to revoke the refresh_token for that application/user without having it in hand.. We could certainly put a reverse proxy like nginx in front of hydra (or use a full blown API gateway like Kong, as you suggest, or aws api gateway) but that is still a much more complicated setup. We are deliberately running hydra outside of our main (in our case kubernetes) clusters so that such a critical component to each of our clusters (we have many clusters, but share the auth system) isn't dependent on any one of our clusters.\nRight now, we are simply using aws ec2 container service to host hydra. While it is absolutely possible to put something in front of it, it would be a whole lot easier to just reconfigure hydra.\nI definitely understand your perspective though and understand if that's not something you feel belongs in hydra directly.\nThat said, as I've mentioned, here and in #507, we would also love to see more ways that hydra could natively support a decentralized architecture (while understanding that the DB is the biggest factor in this). CORS support would help with that to some degree.. So just to be 100% clear, hydra's /warden/token/allowed does require write access because it is a POST request?. I haven't had an issue with fosite so far, but yes it can't hurt to add a Gopkg.toml there either.\nI've rebased this as asked.. yes, it's included in #606 . OK, based on v0.9.x and all glide and dep tests now pass. We would like to be able to get this functionality ASAP which would be less risky if we can stay on 0.9.x. However, I don't think it would be too hard to cherry pick the commits and get it working on master. If we can merge this into 0.9.x, I'll set up another PR to get it into master.. OK. Updated with changes from review. Still don't know how to generate the api.swagger.yaml so I hope it's correct.. OK. Updated again.. Nice catch. I think everything should be ready now.. closed in favor of #628 . RFC7518 lists ES256 as \"Recommended+\" meaning:\n\nThe use of \"+\" in the Implementation Requirements column indicates\n   that the requirement strength is likely to be increased in a future\n   version of the specification.\n\nI think that the stronger algorithm should continue to be supported.\nAlso, the webcrypto spec has renamed ES521 to ES512: \n\nIf the \"alg\" field is equal to the string \"ES512\":\nLet algNamedCurve be the string \"P-521\".. Can you link to the spec which still references ES521?. I agree with you, that's why I have updated the master branch of our repo to be in sync with your master and all my recent changes. After you approved this, I planned on making that pull request. You can see it here https://github.com/zvelo/hydra. Available and ready to merge in zvelo master. Available and ready to merge in zvelo master. Sure, I didn't see many (any?) separate functions for these things, so I was just trying to maintain the existing style.. Yes. It will throw a compile time error if the interface isn't satisfied.. OK. OK. ORDER BY is required to ensure that the paging is consistent.\nhttps://www.postgresql.org/docs/8.2/static/queries-limit.html. Your call. I like putting it right after type definitions so I can see how it is intended to be used. Also, I think it was manager_http that didn't fail the build at all if it didn't satisfy Manager. However, the tests failed to build. This didn't feel right to me. Whatever you want though.. See my https://github.com/ory/hydra/issues/627#issuecomment-339326814. \n",
    "otremblay": "There ya go :)\n. Lol just realized that I'm ahead of time for hacktoberfest. XD Oh well. Getting warmed up I guess.\n. ",
    "Zev23": "Couchbase\nFirst of all, Couchbase is not CouchDB and I'm just a user. I do not have any performance benchmark so i will mention things it can be applied to Hydra as storage.\n- (+) Both K/V (binary) or Document (JSON) store.\n- (+) Support secondary indexes\n- (+) Have official Go SDK. https://github.com/couchbase/gocb\n- (+) N1QL is A LOT like SQL. Can perform CRUD, JOIN and aggregation.\n  - In RDBMS, FROM sometable clause refers to table in database with fixed schema.\n  - However in Couchbase, FROM bucket is kind of like database in RDBMS. So documents of any type are in the same bucket. \n  - Usually each document will have a property \"type\" to differentiate themselves or prefix type in id \"accesstoken::123456\"\n- (+) N1QL has regex. http://developer.couchbase.com/documentation/server/4.0/n1ql/n1ql-language-reference/patternmatchingfun.html\n- (+) Can leverage Go's database/sql API: https://github.com/couchbase/go_n1ql\n- (+) Easy scale out/clustering. (No need table/key partitioning upfront)\n- (+) Master/Master replication\n- (+) Admin Console is realtime.\n- (-) Community Edition (4.1) atleast 6-months outdated than Enterprise Edition(4.5)\n- (+) TTL supported in Go SDK\n- (-) TTL NOT supported in N1QL\n- (-) TTL NOT supported in Sync Gateway REST API\nIn-Memory PUB/SUB\nIMHO, go ahead and create 2 set of managers. Let the user decide whether to use in-memory or not.\nThere are few ways that you can get change feeds from Couchbase. Each with their own traits and limitations.\n1. Sync Gateway REST API\n\nIf use this method, client must use Sync Gateway REST API for all CRUD because they have extra properties added to the document.\nStill able to use Go SDK or N1QL to query the documents. http://stackoverflow.com/questions/36871589/query-sync-gateway-buckets-using-n1ql \nCannot use K/V. Only document.\nIt provides 2 methods: \nWebhook (Push)\nCalls and send changed document to external service whenever a change occurs.\nIf have n endpoints, need to set n webhooks. Not scalable.\nNo replay on failure\nMore Info: http://developer.couchbase.com/documentation/mobile/current/develop/guides/sync-gateway/server-integration/index.html\n\n\nChanges Feed (Pull)\nMultiple clients can request at the same time. Scalable.\nCan replay or start from a specific sequence per request.\nMore Info: http://developer.couchbase.com/documentation/mobile/1.3/develop/references/sync-gateway/rest-api/index.html#operation---db--_changes-get\nClient have to perform 2 calls for every watch loop:\nCall to _changes to get list changed document ids.\nCall to _bulk_get to get the actual documents.\n\n\n\n2. dcpl: lightweight Database Change Protocol (DCP) proxy\n\nExperimental? Its not release.\nDocument CRUD can use GO SDK or N1QL to perform\nIts like a mini server that serve change feed through websocket or http continuosly\nCannot start from specific sequence\nOnly 3 modes:\n'everything' -- start from the beginning, and listen forever (default)\n'from_now'   -- start from current state, and listen forever\n'till_now'   -- start from the beginning, and listen until current state\nResponse contains actual document so no need extra step to get document.\nhttps://github.com/couchbaselabs/dcpl\n\n3. Go SDK (gocb)\n\nBuild own custom solution since dcpl is build from Go SDK and written in Go.\nUse streamingBucket.\nNo documentation.\n\nEvery replication or sync operation Couchbase use the DCP to do it. Recently they start releasing dcp-client sdk for Java. No news for other lanaguages yet.\n. ",
    "emilva": "Yeah, will look into that\nOn 7 October 2016 at 10:54, Aeneas notifications@github.com wrote:\n\nI think there's still an issue with the travis file:\n/home/travis/build.sh: eval: line 46: syntax error: unexpected end of file\nhttps://travis-ci.org/ory-am/hydra/jobs/165746289#L882\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory-am/hydra/pull/288#issuecomment-252187176, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAZwplOZz1C3OVhatkFdnNPEbIyzmvLfks5qxgi6gaJpZM4KQf99\n.\n\n\nBest regards\nEmil Vaagland\nSoftware Engineer\nSchibsted Products & Technology Oslo http://www.schibsted.com\nMob +4792668890\n. yeah, should be ok now! Tested the bash syntax in another project, and it worked as expected. \n. No, that will not work, as there are other packages inside ory-am/hydra that the install depends on. When doing that we get this warning:\n`[WARN] The name listed in the config file (github.com/ory-am/hydra) does not match the current location (github.com/emilva/hydra)``\nand subsequently a failure:\nmain.go:7:2: cannot find package \"github.com/ory-am/hydra/cmd\" in any of:\n    /home/travis/gopath/src/github.com/emilva/hydra/vendor/github.com/ory-am/hydra/cmd (vendor tree)\n    /home/travis/.gimme/versions/go1.5.linux.amd64/src/github.com/ory-am/hydra/cmd (from $GOROOT)\n    /home/travis/gopath/src/github.com/ory-am/hydra/cmd (from $GOPATH)\nThe command \"go install .\" failed and exited with 1 during .\nhttps://travis-ci.org/emilva/hydra/jobs/166904313#L450\n. Yupp. Tried something like that in \ud83d\udc49 https://github.com/emilva/hydra/commit/26a59b0c9c988d5ee7646ff31f2dbdf2bbd7aa74\nhowever, now it fails further down in some test I think https://travis-ci.org/emilva/hydra/jobs/166904073#L883\n. Found a related fix for it here, but have not yet made it work in this repo.\n. Yupp, I will revisit it and take a look at it later! \n. Moved it and now the build is green! However, I still see this strange error message at the end tho:\nhttps://travis-ci.org/emilva/hydra/jobs/167926554#L884\nis it intended? \n. Still having some issues with just a simple create dir and move commands. \nIt works for go1.7 but not for the two other versions. Any idea why?\nFailed build:\nhttps://travis-ci.org/emilva/hydra/jobs/167935209#L270\nSuccessful:\nhttps://travis-ci.org/emilva/hydra/jobs/167935211\n. ",
    "andrewmcnamara": "The DATABASE_URL environment variable doesn't seem to be picked up anymore when starting under this branch.\n. The flag \"--dangerous-auto-logon\" does not add the \"client_id:\"  to  ~/.hydra.yml.\nWhen I checked the hydra_client table there was no 'id' or 'client_name' set. \nbash\nmysql> select * from  hydra_client \\G\n*************************** 1. row ***************************\n            id:\n   client_name:\n client_secret: $2a$10$FH07lupmVLyXL8npc/8qMOIE58h5TIxE1UQ.XqB14pMfA35JKSpfa\n redirect_uris: http://localhost:4445/callback\n   grant_types: implicit|refresh_token|authorization_code|password|client_credentials\nresponse_types: id_token|code|token\n         scope: hydra openid offline\n         owner:\n    policy_uri:\n       tos_uri:\n    client_uri:\n      logo_uri:\n      contacts:\n        public: 0\n`\n. Additionally is there documentation for how to specify the database connection to postgres or mysql ? \nhydra help host only returns configuration details for RethinkDB\n``` bash\n- DATABASE_URL: A URL to a persistent backend. Hydra supports various backends:\n  - None: If DATABASE_URL is empty, all data will be lost when the command is killed.\n  - RethinkDB: If DATABASE_URL is a DSN starting with rethinkdb://, RethinkDB will be used as storage backend.\n    Example: DATABASE_URL=rethinkdb://user:password@host:123/database\nAdditionally, these controls are available when using RethinkDB:\n- RETHINK_TLS_CERT_PATH: The path to the TLS certificate (pem encoded) used to connect to rethinkdb.\n    Example: RETHINK_TLS_CERT_PATH=~/rethink.pem\n\n- RETHINK_TLS_CERT: A pem encoded TLS certificate passed as string. Can be used instead of RETHINK_TLS_CERT_PATH.\n    Example: RETHINK_TLS_CERT_PATH=\"-----BEGIN CERTIFICATE-----\\nMIIDZTCCAk2gAwIBAgIEV5xOtDANBgkqhkiG9w0BAQ0FADA0MTIwMAYDVQQDDClP...\"\n\n```\n. @arekkas Only the client_id was missing from hydra.yml.\n. @arekkas Yes. Here is the full command I was Hydra running with.\nsh\nPORT=4444 SYSTEM_SECRET=4d371c2d4265feb6ae9f3e76e7eccdab DATABASE_URL=\"mysql://root@tcp(127.0.0.1:3306)/hydra\" CONSENT_URL=http://sample-app.dev/consents/new hydra host --dangerous-auto-logon --dangerous-force-http\n. Logfile for command\nsh\n08:38:16 hydra-mysql.1 | time=\"2016-10-24T08:38:16+11:00\" level=warning msg=\"No clients were found. Creating a temporary root client...\"\n08:38:16 hydra-mysql.1 | time=\"2016-10-24T08:38:16+11:00\" level=info msg=\"Temporary root client created.\"\n08:38:16 hydra-mysql.1 | time=\"2016-10-24T08:38:16+11:00\" level=info msg=\"client_id: \"\n08:38:16 hydra-mysql.1 | time=\"2016-10-24T08:38:16+11:00\" level=info msg=\"client_secret: 8_tpO>F468sLF&v0\"\n08:38:16 hydra-mysql.1 | time=\"2016-10-24T08:38:16+11:00\" level=warning msg=\"WARNING: YOU MUST delete this client once in production, as credentials may have been leaked logfiles.\"\n. @arekkas Thanks. That patch fixed it. I can now see the client_id in hydra.yml.\nsh\n09:26:49 hydra-mysql.1 | time=\"2016-10-24T09:26:49+11:00\" level=warning msg=\"No clients were found. Creating a temporary root client...\"\n09:26:49 hydra-mysql.1 | time=\"2016-10-24T09:26:49+11:00\" level=info msg=\"Temporary root client created.\"\n09:26:49 hydra-mysql.1 | time=\"2016-10-24T09:26:49+11:00\" level=info msg=\"client_id: af1c0242-c11a-49d3-9fe9-45455998b4f9\"\n09:26:49 hydra-mysql.1 | time=\"2016-10-24T09:26:49+11:00\" level=info msg=\"client_secret: zCS>S4iBShqvcIn6\"\n. @arekkas Token introspection no longer returns the \"aud\" field which is part of the JWT spec. Instead it returns a client_id field. Can the introspect response be change to include \"aud\"?\nCurrent Hydra (version 5)\nsh\nhydra token validate TBpyZhWoJGB7xvuyPzL2jZPuEazYnmdm7wYfG32k3qc.mr3OtSkj90d_lf584s4dktwlO7BB0oNnkq6FNI072zk\n{\n    \"sub\": \"f13d49c3-b61d-4fbc-b0a7-048a5f138115\",\n    \"scopes\": [\n        \"hydra\"\n    ],\n    \"iss\": \"hydra.localhost\",\n    \"aud\": \"f13d49c3-b61d-4fbc-b0a7-048a5f138115\",\n    \"iat\": \"2016-10-24T14:23:57.897+11:00\",\n    \"exp\": \"2016-10-24T15:23:57.897+11:00\",\n    \"ext\": null\n}\nNew Hydra\nsh\nhydra token validate \"qLmMAnvRtXeGs3fvKYqtsv9XqKeTe3ORZ0aDmZ6PKN4.fMIFVa7LpFYXwZ61CI_WsWNEbrLlKBsnOIgBCI6IT5g\"\n{\n    \"active\": true,\n    \"scope\": \"hydra\",\n    \"client_id\": \"828c4958-4359-49d6-83be-02e235841c64\",\n    \"sub\": \"828c4958-4359-49d6-83be-02e235841c64\",\n    \"exp\": 1477280498,\n    \"iat\": 1477276899\n}\n. ",
    "coveralls": "\nCoverage increased (+10.9%) to 68.758% when pulling c51397f06fc942d0c2371367923a748f69fbc2f8 on prepare-0.6.0 into f5299a105a2d1ae0ab8e25c69f22afe21fc8a28d on master.\n. \n\nCoverage remained the same at 69.345% when pulling 0ddc8f3cc78ddf1928edb3f7724ada39c73d461e on fix-ci into b08d5213aa089e6199f07544edd41b14955f4c11 on master.\n. \n\nCoverage decreased (-0.005%) to 69.34% when pulling 8598cd3ace888fa41836bc13f19f998d5140d245 on fix-ci into b08d5213aa089e6199f07544edd41b14955f4c11 on master.\n. ",
    "MikeRalphson": "It may be simpler to set the go_import_path explicitly in .travis.yml. See https://docs.travis-ci.com/user/languages/go#Go-Import-Path\n. ",
    "ventayol": "Hi @arekkas,\nwhat's the status about this?\nCurrently to do user login we are creating a client for each user on the system, so we can get a token and a refresh token, it's not the best solution but let us move forward. We really miss a way to do the password grant.. For a website, we are using micro-services architecture, so we have a user service that store users and then we have a frontend that connects to this user service via oauth2.\nFor creating a new user, we use the client credentials, but once the user is created we need to do a \"login\" with that user. We don't want to code any login form for that on the API as it needs to be customized for each frontend that creates users. So we would like to use ROCP for this.\n. Let me explain the case better.\nOur system has:\n- Hydra as oAuth Server\n- A user service that provides an API\n- A website where people can singup and modify his data\nOur workflow will be the following, first let's see how to create a user:\n\nThe website calls hydra to get a client token using client credentials\nThe website shows a form to the user to fill the signup information\nThen it calls the user API with the client token to create the user\nThe user API check the token against Hydra using introspection endpoint\nIf everything is ok, it creates the user and returns OK to the website\n\nNow that we have a user on our system, he wants to login to get his data. The expected workflow will be:\n\nThe website shows a login form to the user (pay attention that it's the website that shows the login form, not the user api)\nOnce the user has put the email / password it should call Hydra with ROPC to get a token for that user\nWith the user token now he can call the user api\nThe user api will use again the intorspection endpoint to check the token against hydra\n\nAre we missing something or doing something wrong?\n. Found it has been changed but not yet update in the docs.\nJust in case someone has the same problem:\nhttp://docs.hydra13.apiary.io/. I've checked the problem and the link in the Readme is right but it's wrong in the Official documentation link.\nI was reading the docs here:\nhttps://ory.gitbooks.io/hydra/content/\nAnd on this page the rest api link is wrong.. ",
    "aalimovs": "@ventayol did you end up carrying on using Hydra for your setup?\n@arekkas I'm looking for a similar setup that @ventayol explained and was looking to use ROPC as well.\nMy understanding about adding the consent app is it will be using the Authorisation Code grant? If so, how would you do a silent authentication in this case for a trusted, first party client?\nThe setup we're both after is using OAuth 2.0 only for internal, trusted clients, that's why I believe there's a use case for ROPC. In this case, there's a trusted front-end (client) with a simple login page for your app that challenges you with a username/password, and on success has a valid access_token for you that you can use down the line for your microservices.\nBeing new to OAuth 2.0, I'm not sure how can you achieve a simple, silent login for your own app without breaking the UX, asking the user about giving consent to the app he's logging in to?\nThanks!. ",
    "gentunian": "Interesting discussion here as I was reading about this project to implement oauth2. \nConfussion gets in the middle after reading this article followed by this one to use the ROPC flow from a site like oauth.com without mention anything about this.\nAnyway, @arekkas links are broken, I will leave here what I suppose they are the new links:\n\nhttps://ory.gitbooks.io/hydra/8-faq/0-README.html#why-is-the-resource-owner-password-credentials-grant-not-supported\nhttps://ory.gitbooks.io/hydra/8-faq/0-README.html#how-to-deal-with-mobile-apps\n\n. ",
    "justinclift": "Done. :wink:\n. ",
    "caseyf": "Could this be added as a REST API that requires rn:hydra:whatever permissions? \nMy use case is the usual: \n users need to be able to revoke permission that they have granted from a web dashboard outside of any client apps\n staff needs to be able to revoke all tokens for a specific client + user combination. In the meantime, can I safely delete records from hydra_oauth2_refresh and hydra_oauth2_access  as a workaround?. ",
    "pnicolcev-tulipretail": "same situation here for implementing a logout endpoint. I believe we'll go with dipping into the table as well for now. . That will do the trick for user logouts but we also have server side events, like disabling of users, that we'd like to trigger revocation by subject. I don't think section 5 would help us out with that. In our case we'd probably only have the subject and client id (maybe not even the client id).\nIf you implement the OpenID spec, would you be bouncing users to the consent app to perform operations on logout? We may want the flexibility to trigger events on logouts. If the consent app gets handed control and an api call to revoke tokens, we can implement our own events system (like I think what @20zinnm was asking for).\n. There was another story around this I think, asking for a flag we could set to use the environment variable.\nCurrently we work around this by running our migrations container inside the alpine image rather than the scratch image. We bury a shell script in there that fires off hydra migrations with the correct environment variables. It would be preferable not to have to use this workaround though. \nedit: I can't find an issue about it but I thought i had created one a while back. I know we talked about it! I really think you should consider it. . The reason you can't run docker run oryd/hydra:vX.Y.Z migrate sql database-url in all cases is because the variable expansion required on database-url doesn't actually happen inside the container so whatever system you use to run the command would need to do it (AWS does not). In docker-compose when you give it a command like migrate sql ${DATABASE_URL} it is docker-compose itself that does that variable substitution on ${DATABASE_URL}. I spent a few hours pulling my hair out until I realized this, but it makes sense considering a scratch image doesn't have bash at all. Kubernetes also hides that it does this replacement for you, but AWS? No such luck. The command must be a fixed literal string.\nAt least, that's my understanding. I can't say I'm a fan of AWS.. Running genswag caught another change in there. Can remove if that's a problem.. Cool! Will switch to this once you merge. . @arekkas I'm here! Added and squashed. You may also want to fork/take ownership of the oauth2 client: https://github.com/tulipretail/oauth2-hydra which is referenced in the php.md.\nAlso please register on packagist.org and submit this sdk once you merge so that composer users have an easier time pulling in your sdk.. Hm, I just restored it. Will try opening one to 0.11. Throwing together a dockerized go app to use the SDK to bootstrap initial clients was really easy, but this would be super convenient. . I'm late to the party. Great discussion, thank you for being so open about your goals and asking for feedback. It's greatly appreciated so we can scope our project accordingly.\nI'm in agreement with rjw57. The consent app flow has been perfect for us because it's so powerful. Leveraging Hydra without a UI has distinct advantages in terms of flexibility. I also understand that  the number of cases that need to be accounted for, especially once you support prompt, can have us shoot ourselves in the foot. This is something we're willing to tackle, but not everyone will get it right.\nI strongly prefer the 3 endpoints solution. It seems like an elegant compromise if it helps you to handle the burden of user state complexity without sacrificing the power we have. If you were to offload display and consent logic to hydra, I'm sure there would be many feature requests to reintroduce things people have done. For instance: we would like to run Hydra in a multi-tenant environment, meaning different styles for each tenant. We'd also like programmatic customization of login (and consent) pages in the long run.\nFurthermore, rjw57 mentioned that consent is implied for certain applications in their system. Ours is the same. For now all our apps are trusted and we skip the consent step, going forward we plan to make this configurable.\nI see the collection of services as an events system. Each endpoint can trigger any business logic needed on our end. On that note, a logout endpoint would also be useful for us, depending on how you go forward supporting logouts.\nThe only potential concern I can think of is that you state: \"UA authenticates end user with some credentials. UA MUST ALWAYS authenticate the user - disable session management!\"\nWe actually have incorporated a SAML authentication endpoint for a 3rd party (a-la Dex) and they're in charge of sessions, as opposed to our consent app. I believe we can force a login with them with our authN assertion, so hopefully this is something we can work around.. I do agree with the comments on the documentation. I think that some parts regarding the relationship between client scopes, user scopes, and policies can get pretty confusing. Part of this is just the nature of OIDC/OAuth2 but I think a breakdown of exactly what components need what perms would make it easier. . Using dev-master will work until the api has a breaking change. Another workaround is to compose in a specific git SHA, like \"ory/hydra\": \"dev-master#4125eabb96cae588eeb8336c21a48b93b6e9a0b3\". This is more of a question than a feature request, I don't think issues is for questions.\nBut currently yes, because you write the consent app yourself you can determine on your own if an app is first-party and doesn't require consent.. This sounds like a great way for you to monetize all the hard work you've been doing on Hydra and it's a feature we will seriously consider.. I don't follow. All I have at the consent stage is the consent id. Introspecting that will give me these details (the golang sdk docs have a broken link to this struct so I'll post the php one)\nhttps://github.com/ory/hydra/blob/master/sdk/php/swagger/docs/Model/OAuth2TokenIntrospection.md\nBut I can't rebuild the original request from that. If I query about redirect_uris belonging to the client I could have several.. Hmm, okay! Thanks. I'll also need state, if that's not included there. Will check on monday.. Updating here for some discussion.\nAs of hydra 0.11.12, Hydra's behaviour is such when a consent expires it does not report an error when the consent app confirms it. We're using a check like in the golang demo app here: https://github.com/ory/hydra-consent-app-go/blob/master/main.go#L135-L141\nHydra returns a 204 though, regardless of whether the consent has expired or not.\nHere's a timeline starting from the 204 response on the consent confirmation\ntime=\"2018-04-13T18:53:42Z\" level=info msg=\"completed handling request\" measure#https://example.com/auth.latency=17446989 method=PATCH remote=... request=/oauth2/consent/requests/85a7b5ff-e0ee-40ed-be0b-fc85b5215aae/accept status=204 text_status=\"No Content\" took=17.446989ms\ntime=\"2018-04-13T18:53:42Z\" level=info msg=\"started handling request\" method=GET remote=\u2026 request=\"/oauth2/auth?scope=openid&state=d15c419f662335bfc70bb0f05d0c8b1a&response_type=code&approval_prompt=auto&redirect_uri=https%3A%2F%2Fexample.com%2Frp%2Fexchange&client_id=rp-id&consent=85a7b5ff-e0ee-40ed-be0b-fc85b5215aae&consent_csrf=1d8bd9c9-8247-4931-ab3e-f862f8b4b9d8\"\ntime=\"2018-04-13T18:53:42Z\" level=error msg=\"An error occurred\" error=\"Consent session expired\"\ntime=\"2018-04-13T18:53:42Z\" level=info msg=\"completed handling request\" measure#https://example.com/auth.latency=12050123 method=GET remote=\u2026 request=\"/oauth2/auth?scope=openid&state=d15c419f662335bfc70bb0f05d0c8b1a&response_type=code&approval_prompt=auto&redirect_uri=https%3A%2F%2Fexample.com%2Frp%2Fexchange&client_id=rp-id&consent=85a7b5ff-e0ee-40ed-be0b-fc85b5215aae&consent_csrf=1d8bd9c9-8247-4931-ab3e-f862f8b4b9d8\" status=302 text_status=Found took=12.050123ms\nI guess that 204 should be a 400-level response. \nSince our consent app maintains sessions, we can work around this problem by asking users to restart the login flow at which point they're remembered by the consent app and don't need to enter credentials, however I understand Hydra's going to be taking over that responsibility in the long run. If you're doing that, perhaps you can remove the need for consent id's to expire? At least not before a user's session cookie does.\nedit: we can also explicitly query the consent id before confirming it which would probably catch it, and then restart the flow without the user noticing\nWhat I didn't expect was that in this case Hydra sends the user back to the redirect_uri, rather than to the consent app, with a query string like  ?error=error&error_description=The+error+is+unrecognizable.. gotcha. Looks like this picked up https://github.com/ory/hydra/pull/814/commits/6bf7e800d45b68af7bfc050c8de97fdf492b116f\nBut it looks harmless assuming you'll merge master up to 11.7 into this branch.. Heyo, I think these two endpoints are different concepts. A health endpoint that responds with a hard-coded \"ok\" is useful in a different way than a full status check is. Some systems separate these two concepts. I guess Kubernetes calls them liveness and readiness. The idea being to distinguish between a need to restart a container (unresponsive, not alive) versus waiting for its deps (not ready) where perhaps you are diverting traffic away from it while it starts up but don't want to restart it.\nPerhaps call one health and the other status?. I don't know, i assumed you'd removed it. Strange that's the only thing that changed. I tried running genswag again, same result. I'll investigate what I did wrong.. Looks like the latest version of go-swagger is interpreting the whole description line as an example because it has 'example:' in it. If I take out the colon (:) it works as you'd expect. Seems like a bug on their part? \nI can manually revert this line in my commit. . @arekkas fixed. Oops, the above was from internal testing. Fixed this reference to your packagist repo.. Different repo. I can change the org to ory but maybe it's better if you take ownership if it's official. You can fork this guy https://github.com/tulipretail/oauth2-hydra, change tulip/oauth2-hydra to ory/oauth2-hydra in composer.json and submit it to packagist.\nYou could also make it official by making a PR to add it to the league's list https://github.com/thephpleague/oauth2-client/blob/master/docs/providers/thirdparty.md. ",
    "raravena80": "@arekkas I have a fix for this for the client, but doesn't seem to work on the server. Do we need to add anything on the server side too ?. ",
    "wangyun": "Yeah, I see, thank you. \nFrom my understanding, the \"hydra token user\" command here is just for tutorial?\nIf for example, I deploy my web app, I need to create a new client in hydra, and at that time, I can set the redirect url to my web app's domain?\nSorry for my poor English.\n. I see, thanks.\n. ",
    "vinodborole": "@arekkas How do I set the redirect url while creating a new client; as far as the hydra CLI is concerned the \"hydra clients create\" automatically generates the client_id and client_secret and does not ask for the redirect URL. The documentation also does not mention anything about setting redirect_url for the new client. Can you please help me here?. @arekkas  thanks for your prompt response i tried that as well;       \n   /go/src/github.com/ory-am/hydra # hydra clients create -c http://11.12.23.33:4\n  445/callback\n  Client ID: 0e3db2e1-82b8-454f-8317-a0c5123f4320\n  Client Secret: %Jl1wccE$.oYpbG(6bKbL7WXFF\n\n  /go/src/github.com/ory-am/hydra # hydra token client\n  kwimUTBP_-KjmPo0oQljqJE1T-\n  fzUyPt2Lr78JVIVlQ.AQgX24co49DnMfcQyEKQijr0jgBn2HxYrNOnfgA69H0\n\nEvent with this the callback listener is set to localhost\n /go/src/github.com/ory-am/hydra # hydra token user\nSetting up callback listener on http://localhost:4445/callback\nPress ctrl + c on Linux / Windows or cmd + c on OSX to end the process.\nIf your browser does not open automatically, navigate to:\n\n. ",
    "rick7712": "I got the same issue here...\nHere is my result of  clients get --skip-tls-verify --id facebook-photo-backup\n$docker run --rm -it   -e HYDRA_ADMIN_URL=https://ory-hydra-example--hydra:4445   --network hydraguide\n oryd/hydra:v1.0.0-rc.6_oryOS.10   clients get --skip-tls-verify facebook-photo-backup\n{\n        \"client_id\": \"facebook-photo-backup\",\n        \"grant_types\": [\n                \"authorization_code\"\n        ],\n        \"jwks\": {},\n        \"redirect_uris\": [\n                \"http://10.17.56.114:9010/callback\"\n        ],\n        \"response_types\": [\n                \"token\",\n                \"code\",\n                \"id_token\"\n        ],\n        \"scope\": \"openid offline photos.read\",\n        \"subject_type\": \"public\",\n        \"token_endpoint_auth_method\": \"client_secret_basic\",\n        \"userinfo_signed_response_alg\": \"none\"\n}\nAnd I run \"toker user\" as the following with forcing redirect_uri to my ip address:\ndocker run --rm -it \\\n  --network hydraguide \\\n  -p 9010:9010 \\\n  oryd/hydra:v1.0.0-rc.6_oryOS.10 \\\n  token user --skip-tls-verify \\\n    --port 9010 \\\n    --auth-url https://10.17.56.114:9000/oauth2/auth \\\n    --token-url https://ory-hydra-example--hydra:4444/oauth2/token \\\n    --client-id facebook-photo-backup \\\n    --client-secret some-secret \\\n    --scope openid,offline,photos.read \\\n    --redirect http://10.17.56.114:9010/callback\nI can see the url link of \"Authorize application\" is:\nhttps://10.17.56.114:9000/oauth2/auth?audience=&client_id=facebook-photo-backup&max_age=0&nonce=tebmghqzzjpdfewhyoqbduvk&prompt=&redirect_uri=http%3A%2F%2F10.17.56.114%3A9010%2Fcallback&response_type=code&scope=openid+offline+photos.read&state=glwqqaumscijmexqowcaoqag, which has a redirect_uri=10.17.56.114:9010/callback, just like the one registered as my client.\nBut after I clicked the link, the output is:\nCannot read property 'match' of undefined\nTypeError: Cannot read property 'match' of undefined\n    at normalize (/usr/src/app/node_modules/url-join/lib/url-join.js:11:21)\n    at /usr/src/app/node_modules/url-join/lib/url-join.js:70:12\n    at get (/usr/src/app/services/hydra.js:15:16)\n    at Object.getLoginRequest (/usr/src/app/services/hydra.js:59:12)\n    at /usr/src/app/routes/login.js:17:9\n    at Layer.handle [as handle_request] (/usr/src/app/node_modules/express/lib/router/layer.js:95:5)\n    at next (/usr/src/app/node_modules/express/lib/router/route.js:131:13)\n    at csrf (/usr/src/app/node_modules/csurf/index.js:117:5)\n    at Layer.handle [as handle_request] (/usr/src/app/node_modules/express/lib/router/layer.js:95:5)\n    at next (/usr/src/app/node_modules/express/lib/router/route.js:131:13)\n. ",
    "115100": "I've found a small bug so I'll fix that too.. I've added a few commits to a WIP branch here: https://github.com/115100/hydra/tree/feature/redis-backend-wip\nI don't have a proper environment set up here so I'll have to test on Monday before adding to the PR.. Thanks for merging!. Looks like it's a fosite thing. I can open a PR and enforce a slice size of 1?. Sorry, I wasn't very clear. I don't expect there to be more than one audience ever.\nfosite/token/jwt's ToString only works with a string parameter.\naud may still be a single element array though, in which case I won't be authorised after a callback from the consent server.. An example fix would be this in ToString:\n+       if sl, ok := i.([]string); ok {\n+               if len(sl) == 1 {\n+                       return sl[0]\n+               }\n+       }\n+. Yes, I forgot about this completely. Fixed.. Yeah, I'll keep it consistent and make this singular.. Strangely enough, it hasn't broken tests locally :/. I'll change it to that because I have no idea why it wouldn't fail.. Hmm. It's panicking for me with the newer commit.. No, I've kept everything quite similar to the memory manager so it's all done in Hydra.. The /0 is the database number to connect to:  https://redis.io/commands/SELECT.\nI'll fix the port number later.. Yeah, I ran my local tests after a FLUSHDB and it started up fine.. ",
    "SonOfBytes": "I'm quite new to iidc and hydra - so I'll probably have the fog of ignorance to work through :P\nLooking at a sample else where this appears to be the broad format\n{\n  \"issuer\": \"https://some-auth-service.com/\",\n  \"authorization_endpoint\": \"https://some-auth-service.com/authorize\",\n  \"token_endpoint\": \"https://some-auth-service.com/oauth/token\",\n  \"userinfo_endpoint\": \"https://some-auth-service.com/userinfo\",\n  \"jwks_uri\": \"https://some-auth-service.com/.well-known/jwks.json\",\n  \"scopes_supported\": [\n    \"cut_for_brevity\"\n  ],\n  \"response_types_supported\": [\n    \"code\",\n    \"token\",\n    \"code token\"\n  ],\n  \"response_modes_supported\": [\n    \"query\",\n    \"fragment\",\n    \"form_post\"\n  ],\n  \"subject_types_supported\": [\n    \"public\"\n  ],\n  \"id_token_signing_alg_values_supported\": [\n    \"HS256\",\n    \"RS256\"\n  ],\n  \"token_endpoint_auth_methods_supported\": [\n    \"client_secret_basic\",\n    \"client_secret_post\"\n  ],\n  \"claims_supported\": [\n    \"cut_for_brevity\"\n  ]\n}\n. Ref: https://openid.net/specs/openid-connect-discovery-1_0.html. ",
    "bbigras": "\nPlease sign your commit with git commit --amend -s\n\nDone.. @arekkas: ping. Go 1.8 is out.. ",
    "chinglinwen": "\n(try opening it on it's own here).\n\nThe provided link is okay, no problem,  I tried open the that homepage in incognito is okay too\nThis time I tried open the hydra github homepage again(to verify again), it is okay, no problem ( even though I don't know why ) ( I'm sure I test it again before I create the issue here )\nSorry if I report the issue at wrong place ) ( by the way, I send the feedbacks to the chrome too, after I created the issue here ) . While I doing check the chrome version, I guess I just got an updated version for the verify above, So the problem may fixed by the new chrome version (Version 55.0.2883.87 m (64-bit)). ",
    "johnwu96822": "This happens on MySQL. @arekkas Yes we have deployed Hydra for testing. If this issue doesn't get fixed and we modify policies (Hydra currently modifies a policy by deleting and recreating it), we'll get a bunch of policy records in those tables and we wouldn't know which record we'd get.. ",
    "NightDevel": "Nevermind, I'm an idiot and didn't read the documentation properly.  Apologies.\n. ",
    "kop": "+1 to this. Personally, I don't really understand how to use scopes together with Ladon/Warden and how they should work together.\n@arekkas, maybe you could write a blog post showing how to build a simple API application using Hydra for both Authentication and Authorization?. @arekkas, sounds great! I would definitely love to see such post.. ",
    "ewilde": "I will test it on windows and get back to you. I've only tried it on mac and linux. Seems to load okay on window\n\nSee 'Loaded certificate from environment variable' at the bottom. ",
    "panva": "= is not url safe, so not part of base64url :) but i'm happy to accept the PR as it does not necessarily break anything per-se. I think stripping the paddings to produce valid hashes is the way to go, nevertheless the PR is merged, version published and @janekolszak just needs to update his locked dependencies.. oidc-token-hash is simply a shared piece of code for node-openid-client and node-oidc-provider to produce and validate these hashes, made no sense to have the same js file in both libraries :). @arekkas the tools and processes are linked at http://openid.net/certification/, they are btw great tools to validate your functionality, for example the padding would have been checked and rejected by the OP testing tool. Hit me up via email if you'd like more details.. ",
    "flotho": "thanks, \nA little hard to understand from now for me but I'll dign into this.\nregards. ",
    "MelleKoning": "Apparrently gitter chat moved to discord https://discord.gg/PAMQWkr. ",
    "stevenroose": "Did you look at RAML while deciding on Swagger?. @arekkas The OpenAPI website confuses me. Is it an initiative to develop a new standard based on Swagger? Or is it just an alliance that pledges to use Swagger for it's APIs?. ",
    "foobargeez": "Thanks for the response!. ",
    "OvermindDL1": "Any idea on how to add a \"public\":true to the client definition when the client is part of a remote website that is trying to auth to a local hydra server (do not that it works on other openid connect servers), or some override in hydra to imply \"public\":true?. > Check the docs, section advanced iirc.\nI've been over those but I didn't find I way, I ended up mutating it on the nginx front-loader to get working.\n\nAlso, questions in chat or forum only please.\n\nAh very nice, where would those be located, what is the IRC room and on which IRC server?  (I'm in console terminal 95% of my day so anything that works on the commandline is fine, I'm even using github right here and now from the commandline. :- )  ). > It\u2019s literally the first subsection in advanced:\nHmm, I didn't make the connection, I don't know OAuth2 well, I'm setting this up for someone else to allow their other services to access their Discourse forum as the login source so I'm learning on the way.  I do apologize for the noise!\n\nLinks to relevant forums and chatrooms as well as rules for opening issues are written in the issue template, the one you deleted when you opened this issue.\n\nAh, I didn't open the issue so I never saw it, issue templates don't appear in the comment on an issue.  :-)\nEDIT:  Checked the issue template, but the chat appears to redirect to a Discord thing, what is the IRC room for a bridge, or is there a commandline client for Discord that I'm unable to find on a cursory Google search?  Brow.sh makes a decent command-line browser for most sites but Discord is a bit too much for it...  >.>. For note, I'm trying to run the master HEAD version of hydra right now and multiple OpenID Connect libraries are reporting something akin to:\noauth2: error validating JWT token: audience in token does not match client key\nSuch as, for an open source example, the one at:  https://github.com/go-gitea/gitea/blob/master/vendor/github.com/markbates/goth/providers/openidConnect/openidConnect.go#L202. And more testing, it looks like hydra is returning \"aud\":[\"my_client_id\"] instead of \"aud\":\"my_client_id\", which is what these libraries expect.  Any chance of hydra putting out a string instead of an array when it is only a single value?. > Regarding string/array - array MUST be supported according to spec. String MAY be supported, see JWT spec:\nYep, I've already submitted a PR to them.  Just curious if there is a way to just send a single string regardless when there is only a single string in the array, at the very least it lowers processing and network time every so tiny slightly.  :-). I think that was a similar issue the library itself had, they ended up writing their own (obviously incomplete) JWT handler, my fix for this issue for them is at:  https://github.com/markbates/goth/pull/240. ",
    "djeeg": "Hey, thanks for the near instant response!\nI dig some tweaking in the last couple of minutes, pretty much as you said, went with something like this:\n\nHTTPS_ALLOW_TERMINATION_FROM=127.0.0.1/32,192.168.178.0/24,10.0.19.0/24,::1/32\n\nUnfortuately I couldnt get the updated IPs to work.\nI will try with your multiport suggestion\n. Ahh I see what might be missing now, is there a way to fake the X-Forwarded-Proto header when calling [hydra clients import]\ntime=\"2017-01-03T17:22:19Z\" level=warning msg=\"Could not serve http connection\" error=\"X-Forwarded-Proto header is missing\"\ntime=\"2017-01-03T17:22:19Z\" level=error msg=\"An error occurred\" error=\"Can not serve request over insecure http\" request_id=62c2a8ed-98c2-4105-b57e-d9570eeb6072 status=502. My current workaround is to just connect and import via the public URL, rather than localhost. As this is only a test environment, not too concerned.. ",
    "wyattanderson": "We're generally able to run Hydra behind a proxy that strips out the prefix, but we're running into the issue mentioned here:\n\nURL rewriting can effect the redir portion of a challenge token being set incorrectly and issues with the session cookie used to prevent replay attacks.\n\nThe openid-configuration response includes the right authorization_endpoint field by concatenating ISSUER (https://foo.bar.com/hydra) with the URL (see the source), but the redirectToConsent function just uses the incoming request, which isn't accurate since we strip /hydra/ from the URL at the load balancer.\nWould it make sense to update redirectToConsent to construct the redirect URL from the configured issuer URL and the AuthPath?\nSomething like this, perhaps.. I'll work on a PR.\n\nI would also add a check whether or not the endpoint is https or not (disallow https)\n\nWhy would we want to disallow HTTPS? Or do you mean we should respect the ForcedHTTP option?. What do you think about performing that check (ISSUER have https scheme, unless host is localhost and dangerous-force-http is set) on startup, say, in cmd/server/handler.go or when the config is parsed in cmd/root.go?. > Could we maybe add a fallback in case the Issuer is not set?\nSure, but what are valid uses of Hydra with an empty issuer (versus, say, the default of hydra.localhost)?. 100% agree; the ISSUER config option has a default value when not set, though, so this still works. I'd suggest (and was considering sending in a separate PR) changing the issuer logic:\nWhen ISSUER is not set, construct an ISSUER URL from HOST (default localhost), PORT (default 4444), and --dangerous-force-http to set the scheme. The current default of hydra.localhost seems out-of-spec, since it doesn't have a scheme:\n\nAn Issuer Identifier is a case sensitive URL using the https scheme that contains scheme, host, and optionally, port number and path components and no query or fragment components.. Right, so, when starting out or testing locally it would work (because HOST defaults to localhost), and in production you'd probably be setting the ISSUER explicitly (ISSUER would not be constructed from HOST/PORT etc. when explicitly set), which I think is worth encouraging. This is roughly how Dex behaves.. \ud83e\udd26\u200d\u2642\ufe0f  sorry; was reading the documentation wrong. I'll add the fallback.. We're not working together, but this is the same stack trace I was seeing. I haven't yet had time to put together a reproducer, but my setup:\n- Using a PostgreSQL DB\n- Using a custom consent endpoint. Is this cooperative with the consent application or does it just reissue the same ID token again and again?. I'm happy to contribute some work to this, but I think it'd be much more useful to be able to update any of the standard claims such as email, name, etc. in addition to any custom-supplied claims that may change over the lifetime of the token (e.g. LDAP group membership, custom permissions, etc.), or even have the option for the consent application to reject issuance of a new ID token at all (is it even possible for the consent app to revoke tokens right now or are they effectively permanent?).\n\nOf course we can work around this with a userinfo endpoint, but if I want to pass around a signed JWT to various services over the lifetime of the request, it would greatly simplify things if we could rely on the ID token alone and the standard refresh flow.. Right, what I'm suggesting is an optional way for Hydra to directly access an API endpoint on the consent application, secured by a signed request with the challenge keys or something, to fetch a new set of claims to add to the refreshed ID token. Hydra/Fosite would still be responsible for validating the refresh/access tokens, ensuring adherence to the spec in terms of not updating the sub, iss, etc.. Understandable. Thanks!. I want to revisit this again and get your thoughts; I think the current behavior is at best not very useful and at worst dangerous because there's no way for anyone but the end-user to revoke tokens if a refresh token has been issued. Since token revocation requires the token itself, it's impossible for the identity provider to tell Hydra to stop issuing new tokens and new identity tokens in this scheme. Aside from the need for updating claims in the ID token, it should be possible for the operators of the identity provider to somehow \"lock out\" a user's account.\nThat's why I think it's worth having an optional integration point between Hydra and the consent application to allow an out-of-band consent refresh to correspond with the issuance of new tokens, and the ability to trigger an invalid_grant error response per spec if the refresh token has been revoked. I don't think this dramatically increases the integration complexity if it's optional.. > specs which say explicitly what core claims may be updated and which ones may not: http://openid.net/specs/openid-connect-core-1_0.html#RefreshTokens\nI don't read this as a whitelisting of which claims may change. I read it as saying \"certain claims must remain stable because changing them doesn't make sense (such as changing the sub, i.e. changing the identity of the logged-in user mid-session) or would present a security risk\". Of course things like iss, sub, aud must not change, but per the spec:\n\notherwise, the same rules apply as apply when issuing an ID Token at the time of the original authentication.\n\nSo, we have standard claims such as email, name, profile, picture, etc. which could change (imagine you change your email address, display name, profile information, etc. and want that change reflected in the refresh token).\nThen, we have additional claims:\n\nother Claims MAY be used in conjunction with the standard Claims. When using such Claims, it is RECOMMENDED that collision-resistant names be used for the Claim Names, as described in the JSON Web Token (JWT) [JWT] specification. Alternatively, Private Claim Names can be safely used when naming conflicts are unlikely to arise, as described in the JWT specification.\n\nThis, of course, is part of the draw of JWTs: the ability to set arbitrary, application- and context-dependent claims in the token to facilitate a microservices architecture. Even without non-standard claims, I think there's an argument to be made for changing standard OIDC claims since they can and will change over the lifetime of a user session.\nBecause Hydra lets the consent app sign arbitrary claims into the ID token with id_ext, I think we must support cooperative updating of those claims somehow. Maybe not on every refresh, but ideally there would be at least some way for the consent app or IdP to say \"invalidate the ID token for this user\" and require a claim refresh (but not necessarily a reauthentication) on next refresh.\n. ",
    "dkushner": "@michael-golfi, hey just wanted to thank you for contributing your Kubernetes use case, it has helped us immensely. I was just curious, what are you doing for client management in production deployments? Are you having to manually set up critical clients each time you deploy?. I am experiencing this same issue when attempting to start up hydra in a local docker-compose cluster running against a stock postgres image in the same cluster. This behaviour should be impossible in that case since the postgres container does not save state between runs, yeah? How might this be happening?. @arekkas, I did not but had a misunderstanding about how docker-compose was handling container state which you actually helped me address in the Gitter. Appreciated! . ",
    "itsjamie": "Done.. ",
    "vorce": "I've seen similar behaviour. Running Hydra (0.5.2) in AWS behind an ELB. No logs in hydra for it.. I just tried the same thing with oryd/hydra:latest with the same result.. ",
    "himanshucricket": "so what should be expected behavior from hydra when user deny consent ? app should append consent=false right ?. @arekkas i thought Hydra might be handling that error redirection when consent is set to false, is it not the case ? then how would consent app should deal with exception and error, to make it production ready ?. ",
    "dereulenspiegel": "The command I posted in the initial ticket is a variant of the command how I currently build most of my service under Go 1.7. It creates statically linked binaries (as long as CGo isn't used) without problems and also strips debugging symbols (saving around 30% of the binary size).\nI finally tried your official docker container and was a bit shocked that clocks in at several hundert MB. I think reducing image size is very welcome for many users.. You could also build the binary outside of docker and then just include it in an image derived from scratch. This way the image only about as big as the hydra binary. At least for many deployments this will be useful.\nBut the static binary should also run without problems on Alpine based images.. Also thanks from me. \nGenerally I would like to add that I like to keep development and build tools out of my production images. It makes them smaller, and reduces the toolset a potential attacker has to do stuff in the container.\nI am really looking forward to a reduced image size for hydra because right it takes longer to deploy hydra than the rest of our platform. Making things faster is always good :). Yeah, for now please close this. We are still having issues, but I want to understand the whole thing better before reopening this. . ",
    "berlincount": "well, the only issue is the primary key .. if that's not a VARCHAR(255) in actuality, it shouldn't be stored as such ...\nif it's actually a UUID it might be worth looking at http://mysqlserverteam.com/storing-uuid-values-in-mysql-tables/ - there are some serious performance improvements possible, but it goes for one hell of a migration (once) .. and the charset could be kept.. It should, if it's reduced below 767 effective bytes, making it VARCHAR(191) .. 191*4 = 764 ... Hmm. Not really. Existing tables should also be fine, so no need to alter them. Don't know whether the DB layer can live with differences there, though ;)\nCREATE for a new table on a system with issues will simply fail.. ",
    "DallanQ": "I just ran into this as well while trying to initialize a new hydra db. In order to enable large key support by default, you need to set:\ninnodb_large_prefix=on\ninnodb_file_format=Barracuda\ninnodb_file_per_table=on\ninnodb_default_row_format=dynamic\nUnfortunately, innodb_default_row_format isn't available as an option until MySQL 5.7, and RDS Aurora (which is what I'm using) only supports MySQL 5.6, so I can't enable large key support by default on RDS Aurora.\nThere are several options:\n1. alter the database to use latin1 as the default character set\n2. reduce the key sizes to 191 characters\n3. modify the SQL create statements to append \"row_format=dynamic\" for MySQL. The dynamic row format is available since 5.5 I think, but it isn't the default\n4. require MySQL 5.7 and tell people to set all four settings above\nTo get started I'm going with option 1, but option 2 would be really nice if the keys don't really need to be over 191 characters.\nI'd be happy to submit a PR to reduce the VARCHAR(255) statements to VARCHAR(191), but I don't know if that would break anything.\n. Ok, I'll put something together next week.. If I'm reading the PR correctly, it looks like this line\n    ADD CONSTRAINT hydra_client_surrogate_id_unique UNIQUE (surrogate_id)\nwould still require that the varchar(255) column to have a unique key. Unfortunately it's not just primary keys that can't be more than 767 bytes, but no key can be more than 767 bytes.\n. If you think we can live with 191 length for surrogate_id, that's a pretty straightforward migration. I can build on your PR and alter the tables to make surrogate_id varchar(191) if you like. What do you think?. I reviewed all of the table keys and constraints that need to be modified:\nKEYS\nhydra_client.id(255)\nhydra_client_migration.id(255)\nhydra_consent_request_migration.id(255)\nhydra_groups_migration.id(255)\nhydra_jwk.sid(255) + kid(255)\nhydra_jwk_migration.id(255)\nhydra_oauth2_access.signature(255)\nhydra_oauth2_code.signature(255)\nhydra_oauth2_migration.id(255)\nhydra_oauth2_oidc.signature(255)\nhydra_oauth2_refresh.signature(255)\nhydra_policy_migration.id(255)\nhydra_warden_group.id(255)\nhydra_warden_group_member.member(255) + group_id(255)\nladon_action.compiled(512)\nladon_action.template(512)\nladon_policy.id(255)\nladon_policy_action_rel.policy(255) + action(64)\nladon_policy_permission.policy(255)\nladon_policy_resource.policy(255)\nladon_policy_resource_rel.policy(255) + resource(64)\nladon_policy_subject.policy(255)\nladon_policy_subject_rel.policy(255) + subject(64)\nladon_resource.compiled(512)\nladon_resource.template(512)\nladon_subject.compiled(512)\nladon_subject.template(512)\nCONSTRAINTS\nhydra_warden_group_member.group_id -> hydra_warden_group.id\nladon_policy_action_rel.policy -> ladon_policy.id\nladon_policy_action_rel.action -> ladon_action.id\nladon_policy_permission.policy -> ladon_policy.id\nladon_policy_resource.policy -> ladon_policy.id\nladon_policy_resource_rel.policy -> ladon_policy.id\nladon_policy_resource_rel.resource -> ladon_resource.id\nladon_policy_subject.policy -> ladon_policy.id\nladon_policy_subject_rel.policy -> ladon_policy.id\nladon_policy_subject_rel.subject -> ladon_subject.id\nI'm starting to have concerns about whether shortening the key lengths will work, because we're not just shortening id to 191. Some keys have to be shortened to 95. I don't know the code well enough to say whether shortening has the possibility of truncating keys. Here what would need to happen:\n\nall id fields: 255 -> 191\nhydra_oauth2_access, hydra_oauth2_code, hydra_oauth2_oidc, hydra_oauth2_refresh tables: signature 255 -> 191\nhydra_jwk table: sid 255 -> 95, kid 255 -> 95\nhydra_warden_group_member table: member 255 -> 95, group_id 255 -> 95\nladon_action, ladon_resource, ladon_subject tables: compiled 512 -> 191, template 512 -> 191\nladon_policy_action_rel table, ladon_policy_permission, ladon_policy_resource, ladon_policy_resource_rel, ladon_subject, ladon_subject_rel tables: policy 255 -> 127\n\nNote that in the hydra_jwk table, the sid and kid fields would have to be reduced to 95 each since the key includes both fields, similarly in the hydra_warden_group_member table, the member and group_id fields would have to be reduced to 95 each. The compiled and template fields in three tables would have to be reduced from 512 characters to 191. And the policy field would have to be reduced to 127 since the keys include policy and another 64-character field.\nIs this reducing the fields too much?  If not, I will write a PR to shorten the keys in this way, along with renaming id to surrogate_id, introducing a new id field, and dropping and re-adding the foreign-key constraints.\nOther possible approaches:\n use latin1 as the default character set for mysql. Do the tables need to store multi-byte unicode characters?\n specify only fields involved in keys be latin1 in mysql, but allow other fields to be utf8mb4.\n* append \"row_format=dynamic\" to the create table statements for mysql, tell people to use mysql version >= 5.5, and to set innodb_large_prefix=on, innodb_file_format=Barracuda, and innodb_file_per_table=on.\nWhich is the best approach?\n. The hydra_jwk table has a combined key: sid + kid. If we split this into two separate (non-unique) keys, then each key could be 191 bytes long. Does the database have to enforce that sid + kid be unique? If not, then creating two separate non-unique keys is the way to go.\nA similar question applies to the hydra_warden_group_member table, which currently has a combined key of member + group_id. If the database doesn't have to enforce that member + group_id be unique, then we could create two separate keys here and allow member and group_id to be 191 bytes long.\nThe reason that Hydra works in MySQL 5.7 is that the four fields that I mentioned all have the required values as their default values in MySQL 5.7. Unfortunately the innodb_default_row_format option wasn't added until MySQL 5.7. Before 5.7, you have to add \"row_format=dynamic\" to the create table statements. \nIs it possible to construct different create table statements for MySQL vs Postgres? If so, then appending \"row_format=dynamic\" to MySQL create-table statements is an easy way to enable large-key support in MySQL 5.5 and 5.6 (along with setting the other three values). This would avoid having to reduce the keys sizes.\n. Ok, what's the best way to do this? I see CreateSchemas functions in client/manager_sql, jwk_manager_sql, oauth2/consent_manager_sql and fosite_store_sql, and warden/group/manager_sql. I could make a function: customize(migrations, s.DB.DriverName()) that would customize the migrations depending upon the driver name, which would append \"row_format=dynamic\" if the driver looked like a mysql driver. What do you think?\nThe same thing would have to be done for the ladon project as well, since it also creates tables.\n. Ok, I'll draft a PR this weekend for your approval.. Not needed. ",
    "ruhavingfun22": "I hit this too over the weekend. Doesn't work on mySQL5.6, but works fine on mySQL5.7 I looked over your change and think that is a neat way to get around the size problem without having to reduce the length of the keys. Would be nice to mention somewhere this limitation until the fix is committed.. Note I have also had problems with '%' and with '$' (on version v0.10.0-alpha.10). This bit me pretty hard, as one of my deployments was using this as the root client credential. I spent a couple hours trying a lot of permutations of escaping my secrets for the root, as well as escaping when trying to call it from the CLI, before I eventually gave up on getting these two characters to work... Would be very interested if someone figured out the right combination of escaping to make this work.. @arekkas I did not. I did try with the correct encodings from the site you mention, but something in the docker string parameterization, http request or how the DB was storing the special character didn't agree. I'm not saying it isn't possible to make it work, but after almost 2 hours of trying, it just wasn't worth the effort to make it work. All of the other special characters work without having to specify any encoding, so it was easier to just use those.. ",
    "waterdudu": "\nHydra is a runnable server implementation of the OAuth 2.0 authorization framework and the OpenID Connect Core 1.0. \n\nAs a server implemetation of oidc, I think hydra should implement the required endpoint in hydra side.\n. I was integrating oidc client with hydra but came across the problem that the well-known endpoint was missing. I thought hydra is a full-implemented oauth2 and oidc server but I know now it's not. As @janekolszak said,  the missing endpoint is to easy to implement.. ",
    "ErnstA": "Hi Aeneas,\nYou are right:\n$ hydra  version\nVersion:    v0.7.1\nGit Hash:   5b425372b0e54a2e9ff00aa555083b8b6034ee6a\nBuild Time: 2017-02-21 21:21:08.677064699 +0100 CET\nI am surprised as I downloaded:\nhttps://github.com/ory/hydra/releases/download/v0.7.7/hydra-linux-amd64\nThanks\nErnst. Somehow I must have mistakenly downloaded the wrong version.\nSo sorry.. ",
    "ysaakpr": "How the warden groups are getting used. I could not find any kind of document related to that. is it related to something the policy subjects .\nFor example : if subject: \"user:1\" is belong to group admin\nand a policy with subject \"group:admin\" will allow warden request if the subject is  \"user:1\"\n. And informations about limitations while using Different Storage implementation. \nWhich DB supports all features ? Even though RethinkDB which hydra uses by default I did see that few functionalities wont works in RethinkDB and Redis. \nAny performance benchmark against using different supported storage (out of this scope, but still will be very helpful for people to decide on what and why to choose hydra with specific storage...again its up to user)\nIt will be very good to suggest whats suggested storage for hydra, and limitations of using other storage.\n. ",
    "therebelrobot": "One thing I found was missing documentation on what type of authorization header was needed when swapping out the authorization code for access or refresh token, I finally landed on a base64'd client_id:client_secret (or maybe it was documented somewhere else?). Also, the format of multiple scopes in the cli, I tried scope1 scope2 scope3, then scope1|scope2|scope3, and finally landed on scope1,scope2,scope3. List and explanation of the available grant types would be extremely helpful, still not sure what every single one does yet.. Also, sometimes when searching in the docs, the page freezes and needs to be killed... kinda weird.. Hey @arekkas! I'll get those changes in today and update this PR once ready.. @arekkas I updated the PR, should be good for another pass.. For context, we're using the warden/token/allowed endpoint to validate external tokens coming into our infrastructure, until #539 is resolved.. not sure why this line is listed as a change... I made this update in the Github UI if that helps at all.. ",
    "Moggers": "I would like some documentation on the different policy resources and their meanings. What clients should and should not be given access to to complete the different auth flows.. What is response public vs response private?. ",
    "drozzy": "\nMaybe a guide \"for dummies\"? For people not familiar with crypto? For example, I read oauth2 spec and understand the flows, but this file just overwhelms me:\nhttps://github.com/ory/hydra-idp-react/blob/master/src/common/service/hydra.js\nIf one is working in a different language to Node.js - they have to re-implement hydra.js themselves. It seems like it is very important thing to understand. The HTTP API reference is not sufficient. I think maybe we need a dedicated section about HTTP API.\nPerhaps a better documentation for the sample app? \nMaybe can we drop in an actual identity provider docker container instead of a fake userService.js?\n. Ok, seems to not work and not crash.\nGetting \"404 page not found\". Is this expected behavior?. Thanks, I read the docs.. Sorry, I may have overreacted. But you have to admit 404 is probably not the most straightforward message to display, especially to check that the system is working.\n\nI suggest an index page with \"You're up and running - go here to read the API docs and here for tutorial.\"\nAlso, I actually followed one of the installation instructions here, where it says:\n\nNow, you should be able to open https://localhost:4444. If asked, accept the self signed certificate in your browser.\n\n. Yes, on the documentation page and the front page.. ",
    "mozbhearsum": "More documentation on working with Warden would be greatly appreciated. I've not been able to figure out what exactly I need to provide it to make its endpoints work. The API docs tell me the parameters it needs, but there also appears to be some sort of authorization that's undocumented (and different than what /oauth2/* needs).. Hm, I'm not sure I understand what you mean. Even if I click \"oauth2\" I don't see any thing about subject, action, etc. It's also not in the Body section of the console, eg: https://screenshots.firefox.com/mAe0p0DKGJeqzZcA/docs.hydra13.apiary.io.. ",
    "mewalig": "I'm not a novice programmer and am finding it exceedingly difficult to get this set up and running. Maybe because I don't have familiarity with Docker and the instructions in https://ory.gitbooks.io/hydra/content/install.html do not seem to work (at least not on the AWS EC2 Windows or Linux instances I tried) (it breaks at \"docker exec -i -t hydra_hydra_1 /bin/sh\"). \nI personally think that the using Docker in the installation+config guide is just horrible, for so many reasons-- not the least of which is that when you are done following the installation steps, you are left with something you can't use for production-- but, for what it's worth, and without trying to debate the worthlessness of using Docker, what I would really, really like to see to get started is a very simple set of commands and then examples:\n\nInstallation via source or binaries\nList of external components necessary for a production deployment e.g. postgres. No need for installation instructions assuming the external component is well documented (which postgres is)\nOS-independent configuration scripts, such as a SQL file that will set up the requisite postgres environment (create database, create table, etc-- this is also helpful because in itself this script helps to document the database structure that hydra uses), and/or sample hydra config files. This should take care of any \"seeding\" of the database needed to set up e.g. root admin, keys, etc\ncommand to start hydra\ncurl commands for each of the critical operations that hydra provides via the REST api (create users, create policies, assign users, query actions, yada yada)\n\nIt seems like #1 and #2 are there, but, maybe I'm blind but I can't seem to find #3, #4 and #5 (other than perhaps some Docker-bastardized versions of #4).\nAnyway, #1-#5 would be the bare bones to start with. The next phase-- a \"nice to have\" in my opinion, but very valuable-- would be a \"let's imagine a common scenario\" and follow with curl examples for each of the steps along that story line.\nAdmittedly I don't know much about hydra so maybe the above is misguided. But from an ignorant person's perspective, this is what I'd like to see, and if it's not possible or desirable to do that, then I'd be interested to better understand why.\nI should add that I really like a lot of the documentation I've seen about how to use hydra-- it's just, I haven't had a chance to actually use any of it because the \"Getting started\" documentation so far has not been good enough for me to actually get started.. Thank you for your comments. Things are indeed clearer in the morning! Yes, I apparently was attempting to use the 5-minute tutorial and the visual look & feel of it is so similar to the tutorial that I was confusing the two. I now have hydra running and in a couple days will return to comment more re #5 (usage examples) later. \nIn the mean time, re #1-4:\nI agree that #1 and #2 are covered. I only included them in comments of what I'd like to see so that the list was comprehensive and all in one place.\nMy comment re Docker was not just for installation, and also applies to the rest of hydraguide which also relies on Docker at least for the examples. It definitely clutters up the commands and I could be wrong about this next speculation but it seems like the Docker-related pieces would have to be stripped out anyway in the reasonably likely case that someone wanted a non-Docker configuration (e.g. native, Kubernetes, AWS Container etc). \nI understand that hydra migrate does the database seeding etc, but would find it more useful to see the actual sql script. I suppose I could just do a database dump to do that so this isn't a big deal.\nI had looked at http://docs.hydra13.apiary.io/ already and I think it is fine as a reference document. However, that is not the same, or nearly as useful as, as a guide. The problem with the existing guides, at least for me, is that they do not explain the endpoints in the context of their usage. The closest they come is to show some NodeJS code, which would be great except that I am not going to be using NodeJS. It would be a lot easier for me to just see the analogous curl commands, and even if I was using NodeJS, I'd probably still rather be able to see what's going on under the hood without having to dissect the module code myself.\nTo summarize the most salient of my thoughts, here are the three resources I used to get set up, along with my preliminary view on how to make the whole experience better, minus any comments re usage examples:\n 5-minute tutorial is broken and should be removed or at least clarified as broken with big bold cap words immediately. I wasted a long time trying to find a fix, chasing tips related to virtualization settings etc. What I thought would save me a few mins ended costing a few hours and I almost gave up on trying this project out at all if it weren't for how much I liked everything else I read about it\n ory.am guide is a GREAT guide in that the visual layout is way better and the examples are much more useful (though I haven't tried them so I can't comment on how well the commands work). Only problem is that the setup commands failed for me.\n* installation + configuration: this was the only guide whose commands worked (for me) so far-- though I have not finished getting through the example section.\nInstead of all of the above, what I would really like to see is:\n simple install+base config in under 3 commands. you know, like the old school\n    ./configure && make install\nConfigure could include options such as what db to install (postgres or none), what db connect to (create new or existing), similar re consent app etc (btw I am not actually suggesting a configure bash script, only using as an analogy to a 1-step os-independent command that supports a range of options).\nAt this point, no explanations of anything it is doing is necessary. It's too early for that\n  A \"Getting Started\" guide that has steps for setting up common use cases. For example, use case A might be, securing web application where users log into a website that serves each user her own private content (like Gmail). Use case A-2 might be an extension of A, where any user can grant any other user and/or user group privileges for content (like Google Docs, where a doc creator grants access to another user to view/edit the doc). Use case B might be for securing a web API such as Zillow, where the end users use API keys for authentication, and use case B-2 might be an extension analogous to the API version of A-2. I'll probably have more specific thoughts on what this could look like after I dive into the examples more.\n. Very much appreciated! Will be back to this in a couple of days and as long as the feedback is deemed helpful I am happy to continue to comment. Will actually start to read that Docker book I bought now.... ",
    "darron": "Should be GPG signed now - let me know if there's anything else you need.. ",
    "secretfader": "@arekkas Ah, I missed that. Sorry for the duplicate.\nThanks for your kind and quick response. Hydra is awesome so far. \ud83d\udc4d . ",
    "mattwoolnough": "I was planning to use something the approach used in passport-facebook-token, where the id is retrieved from FB after using a valid access code. \nI'm open to other alternative approaches if there are risks in this approach.  What are the risks & where can I find info on these alternative approaches? \nthx. mW. ",
    "Cikey": "Just a heads up: The sdk currently uses &consent=denied in line 115:\nreturn fmt.Sprintf(\"%s&consent=denied\", claims.RedirectURL), nil\n\n. ",
    "atrauzzi": "Just jumping in to say it would be nice to see an officially supported mongodb driver made available.. I don't know -- It seems like something you'll eventually have to change your mind on.  Forcing people into making deployment considerations for databases that aren't part of their tech stack eliminates this project from their consideration.\nIf I'm running on an MS tech stack (sometimes, not always thankfully), I don't have postgres and I definitely don't have rethink.  Driver support seems like something you really want to ace.. That's not really solving the problem, it just moves the headache up a level.\nWhy wouldn't you just look at the current env for configuration for the CLI?   The application server already does it.  I already have these values in a compose file as env vars not as env vars in my shell which is cumbersome to manage.\nThis is about automatically reading those values rather than asking for it to be passed in.  By doing this, you simplify the command line experience and benefit from docker conventions.. \"Typing an url is really not that big of a deal\"\nIn this case, \"really not that big of a deal\" has been invoked, which has caused me to lose interest in this project.\nI sincerely hope in the future they can become more familiar with docker conventions and improve the flexibility of hydra and how well it plays with other ecosystems.. ",
    "ravihara": "\nI don't know -- It seems like something you'll eventually have to change your mind on. Forcing people into making deployment considerations for databases that aren't part of their tech stack eliminates this project from their consideration.\nIf I'm running on an MS tech stack (sometimes, not always thankfully), I don't have postgres and I definitely don't have rethink. Driver support seems like something you really want to ace.\n\nTotally agree. We need driver support for NoSQL databases as well. Adoption of Hydra should not be hindered by lack of storage backend support.. ",
    "maximesong": "No problem. Done.. ",
    "cheddarwhizzy": "I figured out my issue. I needed to create the policy with the Client ID in the subjects field. I'm working on a better guide for Hydra so I will contribute as soon as I'm done :). ",
    "drasko": "+1 for CocroachDB. It uses PQ driver, so effort should be minimal: https://www.cockroachlabs.com/docs/build-an-app-with-cockroachdb.html. ",
    "iNDicat0r": "Thank you for the prompt response.\nIs there any link to the documentation with examples to use hydra for mobile apps ?. Also the documentation should be more clear, something which makes it easier for people to implement,. Alright then, i will dedicate some time for a proper implementation and contribute to the docs. . Sorry my bad, for some crazy reason the search box wasnt returning any results. Thanks for the response.\nI don't want to depend on third party gateways etc.. therefore the first step is to integrate with my own code/infra.\nSo the Go SDK basically communicates with hydra using HTTP/REST, which means that hydra is completely decoupled and can be used across many languages and runtimes.. Thanks. ",
    "kminehart": "If you're curious or want to keep up with the development you can see it here\nhttps://github.com/kminehart/charts/tree/master/incubator/hydra\n. That didn't take long!\nHave a look, let me know if there's anything alarming that should be changed.\ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Connecting with postgres://*:*@authorization-postgresql:5432/hydra?sslmode=disable\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Connected to SQL!\" \ntime=\"2017-04-19T20:48:35Z\" level=warning msg=\"Expected system secret to be at least 32 characters long, got 8 characters.\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Generating a random system secret...\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Generated system secret: 3DP5IZWI&Z6PN?4BI<A?b?hPN,8F&Mqq\" \ntime=\"2017-04-19T20:48:35Z\" level=warning msg=\"WARNING: DO NOT generate system secrets in production. The secret will be leaked to the logs.\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Applied 0 migrations postgres!\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Key pair for signing hydra.openid.id-token is missing. Creating new one.\" \ntime=\"2017-04-19T20:48:37Z\" level=info msg=\"Key pair for signing hydra.consent.response is missing. Creating new one.\" \ntime=\"2017-04-19T20:48:46Z\" level=info msg=\"Key pair for signing hydra.consent.challenge is missing. Creating new one.\" \ntime=\"2017-04-19T20:48:52Z\" level=warning msg=\"No clients were found. Creating a temporary root client...\"\nhelm install --dry-run --debug\n```yaml\nNAME:   hardy-clownfish\nREVISION: 1\nRELEASED: Wed Apr 19 15:50:42 2017\nCHART: hydra-0.7.10\nUSER-SUPPLIED VALUES:\n{}\nCOMPUTED VALUES:\nconfig:\n  accessTokenLifespan: 1h\n  authorizeCodeLifespan: 10m\n  consentUrl: https://consent.example.com\n  idTokenLifespan: 1h\n  logLevel: info\n  system:\n    secret: changeme\nimage: oryd/hydra\nimagePullPolicy: Always\nimageTag: v0.7.10\nmountPath: /root\npersistence:\n  accessMode: ReadWriteOnce\n  enabled: true\n  size: 1Gi\npostgresql:\n  cpu: 250m\n  global: {}\n  image: postgres\n  imageTag: \"9.6\"\n  memory: 256Mi\n  metrics:\n    enabled: false\n    image: wrouesnel/postgres_exporter\n    imagePullPolicy: IfNotPresent\n    imageTag: v0.1.1\n    resources:\n      requests:\n        cpu: 100m\n        memory: 256Mi\n  persistence:\n    accessMode: ReadWriteOnce\n    enabled: true\n    size: 10Gi\n    subPath: postgresql-db\n  postgresDatabase: hydra\n  postgresPassword: hydra\n  postgresUser: hydra\n  resources:\n    requests:\n      cpu: 100m\n      memory: 256Mi\nreplicas: 2\nresources:\n  requests:\n    cpu: 100m\n    memory: 128Mi\nHOOKS:\nMANIFEST:\n\nSource: hydra/charts/postgresql/templates/secrets.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hardy-clownfish-postgresql\n  labels:\n    app: hardy-clownfish-postgresql\n    chart: \"postgresql-0.6.0\"\n    release: \"hardy-clownfish\"\n    heritage: \"Tiller\"\ntype: Opaque\ndata:\npostgres-password:  \"aHlkcmE=\"\n\nSource: hydra/templates/hydra_secret.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hardy-clownfish-hydra-secret\n  labels:\n    app: hardy-clownfish-hydra\n    chart: \"hydra-0.7.10\"\n    release: \"hardy-clownfish\"\n    heritage: \"Tiller\"\ntype: Opaque\ndata:\n  system.secret: Y2hhbmdlbWU=\n\nSource: hydra/charts/postgresql/templates/pvc.yaml\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: hardy-clownfish-postgresql\n  labels:\n    app: hardy-clownfish-postgresql\n    chart: \"postgresql-0.6.0\"\n    release: \"hardy-clownfish\"\n    heritage: \"Tiller\"\n  annotations:\n    volume.alpha.kubernetes.io/storage-class: default\nspec:\n  accessModes:\n    - \"ReadWriteOnce\"\n  resources:\n    requests:\n      storage: \"10Gi\"\n\nSource: hydra/templates/hydra_pvc.yaml\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: hardy-clownfish-hydra\n  annotations:\n    volume.alpha.kubernetes.io/storage-class: default\nspec:\n  accessModes:\n    - \"ReadWriteOnce\"\n  resources:\n    requests:\n      storage: \"1Gi\"\n\nSource: hydra/charts/postgresql/templates/svc.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: hardy-clownfish-postgresql\n  labels:\n    app: hardy-clownfish-postgresql\n    chart: \"postgresql-0.6.0\"\n    release: \"hardy-clownfish\"\n    heritage: \"Tiller\"\nspec:\n  ports:\n  - name: postgresql\n    port: 5432\n    targetPort: postgresql\n  selector:\n    app: hardy-clownfish-postgresql\n\nSource: hydra/templates/hydra_service.yaml\nkind: Service\napiVersion: v1\nmetadata:\n  name: hardy-clownfish-hydra-service\n  labels:\n    app: hardy-clownfish-hydra\n    chart: \"hydra-0.7.10\"\n    release: \"hardy-clownfish\"\n    heritage: \"Tiller\"\nspec:\n  type: ClusterIP\n  selector:\n    app: hardy-clownfish-hydra\n  ports:\n    - name: service\n      port: 4444\n      targetPort: 4444\n      protocol: TCP\n\nSource: hydra/charts/postgresql/templates/deployment.yaml\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: hardy-clownfish-postgresql\n  labels:\n    app: hardy-clownfish-postgresql\n    chart: \"postgresql-0.6.0\"\n    release: \"hardy-clownfish\"\n    heritage: \"Tiller\"\nspec:\n  template:\n    metadata:\n      labels:\n        app: hardy-clownfish-postgresql\n    spec:\n      containers:\n      - name: hardy-clownfish-postgresql\n        image: \"postgres:9.6\"\n        imagePullPolicy: \"\"\n        env:\n        - name: POSTGRES_USER\n          value: \"hydra\"\n          # Required for pg_isready in the health probes.\n        - name: PGUSER\n          value: \"hydra\"\n        - name: POSTGRES_DB\n          value: \"hydra\"\n        - name: PGDATA\n          value: /var/lib/postgresql/data/pgdata\n        - name: POSTGRES_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: hardy-clownfish-postgresql\n              key: postgres-password\n        - name: POD_IP\n          valueFrom: { fieldRef: { fieldPath: status.podIP } }\n        ports:\n        - name: postgresql\n          containerPort: 5432\n        livenessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - exec pg_isready --host $POD_IP\n          initialDelaySeconds: 60\n          timeoutSeconds: 5\n          failureThreshold: 6\n        readinessProbe:\n          exec:\n            command:\n            - sh\n            - -c\n            - exec pg_isready --host $POD_IP\n          initialDelaySeconds: 5\n          timeoutSeconds: 3\n          periodSeconds: 5\n        resources:\n          requests:\n            cpu: 100m\n            memory: 256Mi\n    volumeMounts:\n    - name: data\n      mountPath: /var/lib/postgresql/data/pgdata\n      subPath: postgresql-db\n  volumes:\n  - name: data\n    persistentVolumeClaim:\n      claimName: hardy-clownfish-postgresql\n\n\nSource: hydra/templates/hydra_deployment.yaml\napiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: hardy-clownfish-hydra\n  labels:\n    app: hardy-clownfish-hydra\n    chart: \"hydra-0.7.10\"\n    release: \"hardy-clownfish\"\n    heritage: \"Tiller\"\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hardy-clownfish-hydra\n  template:\n    metadata:\n      name: hardy-clownfish-hydra\n      labels:\n        app: hardy-clownfish-hydra\n        chart: \"hydra-0.7.10\"\n        release: \"hardy-clownfish\"\n        heritage: \"Tiller\"\n    spec:\n      volumes:\n        - name: hydra-data\n          persistentVolumeClaim:\n            claimName: hardy-clownfish-hydra\n        - name: hydra-secret\n          secret:\n            secretName: hardy-clownfish-hydra-secret\n      containers:\n        - name: hydra\n          image: oryd/hydra:v0.7.10\n          imagePullPolicy: Always\n          command: [\"hydra\", \"host\", \"--dangerous-auto-logon\"]\n          volumeMounts:\n            - name: hydra-data\n              mountPath: /root\n          ports:\n            - name: service\n              containerPort: 4444\n          env:\n            - name: SYSTEM_SECRET\n              valueFrom:\n                secretKeyRef:\n                  name: hardy-clownfish-hydra-secret\n                  key: system.secret\n            - name: DATABASE_URL\n              value: postgres://hydra:hydra@hardy-clownfish-postgresql:5432/hydra?sslmode=disable\n            - name: HTTPS_ALLOW_TERMINATION_FROM\n              value: 0.0.0.0/0\n            - name: LOG_LEVEL\n              value: info\n            - name: CONSENT_URL\n              value: https://consent.example.com\n            - name: ACCESS_TOKEN_LIFESPAN\n              value: 1h\n            - name: ID_TOKEN_LIFESPAN\n              value: 1h\n            - name: AUTHORIZE_CODE_LIFESPAN\n              value: 10m\n          resources:\n            requests:\n              cpu: 100m\n              memory: 128Mi\n```\nHere are the configuration options I provide to helm users.  Are there any extras I should include for environment variables and whatnot?\n```yaml\nimage: \"oryd/hydra\"\nimageTag: \"v0.7.10\"\nimagePullPolicy: \"Always\"\nreplicas: 2\nmountPath: \"/root\"\nPersistent storage.\npersistence:\n  ## If this is false, then emptyDir: {} will be used.\n  ## Setting this to true is highly recommended for production use.\n  ## If this is false, you will lose your data when your pod is destroyed.\n  enabled: true\n  ## If defined, volume.beta.kubernetes.io/storage-class: \n  ## Default: volume.alpha.kubernetes.io/storage-class: default\n  #\n  # storageClass: \n  accessMode: ReadWriteOnce\n  size: 1Gi\npostgresql:\n  imageTag: \"9.6\"\n  memory: 256Mi\n  cpu: 250m\n  postgresUser: hydra\n  postgresPassword: hydra\n  postgresDatabase: hydra\n  persistence:\n    size: 10Gi\nconfig:\n  system:\n    secret: \"changeme\"\n  consentUrl: \"https://consent.example.com\"\n  logLevel: \"info\"\n  accessTokenLifespan: \"1h\"\n  idTokenLifespan: \"1h\"\n  authorizeCodeLifespan: \"10m\"\nhttp://kubernetes.io/docs/user-guide/compute-resources/\nresources:\n  requests:\n    memory: 128Mi\n    cpu: 100m\n```\n. Actually, I had a problem with one of the pods constantly terminating with an exist status 1.\nLogs:\ntime=\"2017-04-19T21:29:58Z\" level=info msg=\"Connecting with postgres://*:*@authorization-postgresql:5432/hydra?sslmode=disable\" \ntime=\"2017-04-19T21:29:58Z\" level=info msg=\"Connected to SQL!\" \ntime=\"2017-04-19T21:29:58Z\" level=warning msg=\"Expected system secret to be at least 32 characters long, got 8 characters.\" \ntime=\"2017-04-19T21:29:58Z\" level=info msg=\"Generating a random system secret...\" \ntime=\"2017-04-19T21:29:58Z\" level=info msg=\"Generated system secret: F&SFjKEDGRO-sgy(K>ns,U8x9aB(6T2%\" \ntime=\"2017-04-19T21:29:58Z\" level=warning msg=\"WARNING: DO NOT generate system secrets in production. The secret will be leaked to the logs.\" \ntime=\"2017-04-19T21:29:58Z\" level=info msg=\"Applied 0 migrations postgres!\" \nCould not fetch signing key for OpenID Connect\nThese are the logs for a working pod:\ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Connecting with postgres://*:*@authorization-postgresql:5432/hydra?sslmode=disable\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Connected to SQL!\" \ntime=\"2017-04-19T20:48:35Z\" level=warning msg=\"Expected system secret to be at least 32 characters long, got 8 characters.\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Generating a random system secret...\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Generated system secret: 3DP5IZWI&Z6PN?4BI<A?b?hPN,8F&Mqq\" \ntime=\"2017-04-19T20:48:35Z\" level=warning msg=\"WARNING: DO NOT generate system secrets in production. The secret will be leaked to the logs.\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Applied 0 migrations postgres!\" \ntime=\"2017-04-19T20:48:35Z\" level=info msg=\"Key pair for signing hydra.openid.id-token is missing. Creating new one.\" \ntime=\"2017-04-19T20:48:37Z\" level=info msg=\"Key pair for signing hydra.consent.response is missing. Creating new one.\" \ntime=\"2017-04-19T20:48:46Z\" level=info msg=\"Key pair for signing hydra.consent.challenge is missing. Creating new one.\" \ntime=\"2017-04-19T20:48:52Z\" level=warning msg=\"No clients were found. Creating a temporary root client...\" \ntime=\"2017-04-19T20:48:52Z\" level=info msg=\"Temporary root client created.\" \ntime=\"2017-04-19T20:48:52Z\" level=info msg=\"client_id: eb11d028-fc89-459e-9288-4e9caec2ef7f\" \ntime=\"2017-04-19T20:48:52Z\" level=info msg=\"client_secret: 91BhL3ukzaY5EqPn\" \ntime=\"2017-04-19T20:48:52Z\" level=warning msg=\"WARNING: YOU MUST delete this client once in production, as credentials may have been leaked in your logfiles.\" \ntime=\"2017-04-19T20:48:52Z\" level=warning msg=\"Do not use flag --dangerous-auto-logon in production.\" \ntime=\"2017-04-19T20:48:52Z\" level=info msg=\"Persisting config in file /root/.hydra.yml\" \ntime=\"2017-04-19T20:48:52Z\" level=warning msg=\"No TLS Key / Certificate for HTTPS found. Generating self-signed certificate.\" \ntime=\"2017-04-19T20:48:52Z\" level=info msg=\"Setting up http server on :4444\" \ntime=\"2017-04-19T20:48:52Z\" level=info msg=\"TLS termination enabled, disabling https.\"\nAny ideas?. Makes sense. Providing a long enough secret makes it run flawlessly. \nI'll just need to test it a bit more and have the option to provide a tls certificate and it should be finished. . Sorry about the delay!\nI've created a PR to kubernetes/charts.  If someone more familiar with the application wants to take a look at it, the PR is here:\nhttps://github.com/kubernetes/charts/pull/1022\nAnd the chart itself, documentation and everything is here:\nhttps://github.com/kminehart/charts/tree/master/incubator/hydra. That's true, I had not considered that.  Thanks!. > Ok so my gut feeling here tells me that maybe the graceful http server handler causes issues with gracefully shutting down profiling\nI did some playing around with the profiling and that's what I found.\nIn ory/x/profilex/profile.go, changing:\nreturn profile.Start(profile.CPUProfile)\nto\nreturn profile.Start(profile.CPUProfile, profile.NoShutdownHook)\nseemed to do the trick. I'll make a PR as soon as I've verified that the profiling data shows up as expected. While it's not empty anymore, I haven't been able to get any actual data to propagate, which could be related to my environment or just not letting it run for long enough.. I think reading https://www.ory.sh/docs/hydra/oauth2 makes the remember process makes sense.\nWhat alternative would you suggest to imply that a login UI should not be presented?\nMaybe to resolve confusion it would worth renaming \"skip\" to \"remembered\". Just a guess, but most people might expect the data in a response to be descriptive of the data rather than the action the client should take.. My bad, go modules are a new thing for me. I ran go mod tidy and committed the go.mod and go.sum files. That should suffice, right?. Cool. I wasn't sure what the right place was to put the unit tests for this change, or if they were necessary given the nature of the tests in hydra/consent.\nI also am not sure if there needs to be any documentation changes. I couldn't find anything relevant but I could have missed something.. @aeneasr I think this one is ready.\nPretty basic, if Name is not provided, it'll use the default. Description and Hint no longer have defaults.  All of the commits were me just getting used to the way everything is structured. \ud83d\ude05\nLooks like there's go mod conflicts so I'll run a rebase again, I guess.. hmm. I ran make format but that didn't seem to resolve the missing dependencies. I see that it's listed in go.mod; go mod tidy didn't seem to help.\nAny thoughts? \ud83e\udd14 . I completely borked the history on this one. I forgot to sign a commit somewhere and I'm still not sure how to correct that if that happens.\nif needed I can recreate the changes and open a separate PR that doesn't screw around with the history.. Yeah I'll open a new PR for this one.\nI ran the rebase commit that the DCO bot suggested; that on top of the merge I did from upstream/master did some weird shit. \ud83d\ude05  I'll do that now.. > One centerpiece will be to figure out how we can store access/refresh tokens in a scalable way - I'm not sure CRDs are the right place for that\nI agree with that.\nCRDs are particularly good for objects / resources which humans have to modify / create manually.\nThere's a pretty good section here about that: https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#should-i-add-a-custom-resource-to-my-kubernetes-cluster\n\nThis would not work with watching though. The problem with hydra really is that clients are usually created from 3rd parties without access to the k8s cluster\n\nI actually didn't think about that use-case, but it definitely makes sense, and I imagine that would be more common than the one I'm about to discuss.\nIn a previous scenario I've run into, we had a fairly large list of authorized clients that were all internally maintained, but changed infrequently. CRDs would have been ideal for us then.\nIt definitely makes a lot of sense for Oathkeeper and Keto.\nI built something similar for Ladon a while ago which would watch for LadonPolicies and update Redis to reflect the LadonPolicies created in k8s. This was really helpful when we were defining accounts \"default\" users for each service as it was just some extra yaml that went along with the Deployment.. I like capitalization too much.\nFixed.. Yeah I think so.\nShould the default error code stay as fosite.ErrInvalidRequest (400)? . ahhhh!. That makes the logic a lot cleaner, actually. I return m.GetConsentRequest regardless of how many rows were affected. I just needed to make sure that if an error was returned, then take the appropriate action. (I thought 0 rows affected would apply here). Not sure what changed that, or why I git added it. Definitely not intentional.. Yup, you're right!. ",
    "philips": "I can't find the helm chart now, where is it?. @aeneasr right, but the README of this repo links to a PR that was merged. But, the chart no longer seems to exist in the chart repo. \ud83d\ude15 . ",
    "bodewig": "actually the README links to a PR that has been closed as superseeded by a different PR https://github.com/helm/charts/pull/1241 which has then been closed without being merged. Please let me try to explain what I want to do, it is not really an API usage of /oauth2/auth but still requires CORS to be enabled.\nI've got two relying parties using the authorization code grant flow with different OAuth2 clients. The consent endpoint is set up to automatically accept the scopes requested and will not show any page.\nWhen the user visits relying party 1 the generated HTML tries to include a snippet of HTML from relying party 2 (\"transclusion\" implemented in a way similar to https://github.com/gustafnk/h-include). Under the covers this uses the fetch API. \nIf the user is not yet known to relying party 2 the fetch request results in a redirect to Hydra. As relying party 1 is considered an allowed origin by relying party 2 the redirect is followed and now hits Hydra's authorization endpoint.\nIn a normal browser flow (the user clicking on a link to relying party 2 rather than using fetch) Hydra would redirect to the login endpoint (with skip=true as the user is remembered) which redirects back to Hydra then to the consent endpoint then to Hydra then to relying party2's redirect URI and finally the page the user wanted to visit in the first place. A lot of redirects but no interaction with the user.\nWith fetch this stops at the authorization endpoint because the redirect to the login endpoint (which happens) lacks the allowed-origin header. To me this looks like a valid use case for the authorization code grant flow and I want to ask you to reconsider adding CORS support.\nI'm sorry if I messed up my \"how to reproduce\" setup, I've tried to strip it down to the bare minimum needed and overlooked details while doing so. I could fix things - in my real system things work for the \"normal\" flow so the clients are registered properly and I have added allowed_cors_origins=* without any difference - but this is probably moot if having /oauth2/authsupport CORS  is out of question anyway.. Thank you.\nI am aware of the OpenID Connect Session spec but it looked like overkill and I think it wouldn't work with our use case as we need to tell a different RP about the user being logged in We could include an iframe from the second party and have it run its authorization code grant flow there but wanted to avoid that. What I was after is more akin to the prompt=none case (which we'd use inside the iframe as well).\nAfter all it is a user client making the request to the authorization endpoint - it is the same browser window just using fetch rather than following a link.\nAnyway  I can certainly accept if you don't want to change the current state. In that case you may want to close this issue as \"wontfix\" or whatever seems appropriate (\"not a bug\", maybe?) and I'll have to think up a workaround for us. Many thanks again for your prompt feedback.. yep, the reverse proxy approach is what I had in mind as well. Thanks.. Understood. Initially I already suspected this was intentional, that's why I asked in the forum first.\n. ",
    "caryfitzhugh": "Hi @arekkas - thanks.\nPardon me if I am incorrect, but I believe that those are fields (id_ext, and at_ext) are added by the IDP when replying back to Hydra after consent is given by the user.\nI am trying to get data passed through the /oauth2/auth call to the /consent call.\nUser --> hydra/oauth2/auth?extra_info=123\nredirect to IDP/consent?challenge=XXX\nThe second call there is what I would like to receive that extra information.  It may be in the challenge token, or maybe in the /consent query parameters.\n. @arekkas any ideas? \nThanks. I'm sorry your week has been tough. :( Here's to better days \ud83e\udd42 \nYour solution fits things perfectly. Thank you very much!. ",
    "impactmass": "I landed on this issue with the same need as the author, but the solution described here doesn't work as of v1.0.0-beta.9. Is this behavior now deprecated? The extra query fields I added to the auth URL to Hydra do not get passed to the /login IDP login redirect.\nTo achieve the same effect, I had to depend on the URL returned as part of getLoginReq call:  \nhydra.getLoginRequest(challenge)\n  .then(async (getLoginRequestRes) => {\n    console.log(getLoginRequestRes.request_url);\nIs this the new/correct approach? Happy to make a PR to the docs/guide if so.\n. ",
    "parallaxisjones": "as far as how I'm building the docker container, \ngo build && go install &&\ndocker build -t  oryd/hydra .\nthen running the container from a docker-compose file with the rest of my services\nsorry about the test fail, I had some trouble with the PR because I believe my branch was behind and I had to update and re-merge the changes because I guess there were too many differences to make the pull request from the fork that I made.  I clobbered some of my changes, then pushed it up as I was leaving and didn't check well enough. thanks.  That was totally it, I wasn't tagging the image correctly, I was using latest-http in my docker compose file. \nI got my owners query working, but it's not code good enough to offer a PR yet and it's not safe sql. I have a conference demo thing coming up in 2 weeks, but after that I'll be able to clean up my code & make tests and offer an official PR.  I would love to be  a hydra contributor. because I added the following. I was trying to force a re-install to get my code to build.. ",
    "erstaples": "Ah, great. That was it! I had thought that leaving SYSTEM_SECRET empty and allowing the system to generate a system secret was good enough, but yeah of course it's going to try to generate a new system secret on pod recreation. So, yeah, totally my fault; setting SYSTEM_SECRET fixed this. \nThanks for the quick response.. ",
    "grega": "@dkushner could you share your findings re. docker-compose + postgres + Hydra's migrations?. @arekkas We discussed this briefly a while back, glad to see it has made it in! Our particular case was AWS API Gateway requiring the Access-Control-Allow-Origin to be set by the application (since it cannot be configured by the Gateway for proxy set-ups):\n\nWith Lambda, AWS or HTTP integrations, you can leverage API Gateway to set up the required headers using the method response and integration response. For Lambda or HTTP proxy integrations, you can still set up the required OPTIONS response headers in API Gateway. However, you must rely on the back end to return the Access-Control-Allow-Origin headers because the integration response is disabled for the proxy integration.\n\n(http://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-cors.html). ",
    "nicerobot": "I opened #816 since it seems I can't reopen this issue.\nI'm having the same problem. I shut down the container and trying to rerun fails. The problem does indeed appear to be the SYSTEM_SECRET but it's because it's not being respected from the command-line.\n$ echo $SYSTEM_SECRET \n27277\n\n$ docker run -d \\\n  --name ory-hydra-example--hydra \\\n  --network hydraguide \\\n  -p 9000:4444 \\\n  -e SYSTEM_SECRET=${SYSTEM_SECRET} \\\n  -e DATABASE_URL=${DATABASE_URL} \\\n  -e ISSUER=https://localhost:9000/ \\\n  -e CONSENT_URL=http://localhost:9020/consent \\\n  -e FORCE_ROOT_CLIENT_CREDENTIALS=admin:demo-password \\\n  oryd/hydra:v0.11.6\n\nNotice that the logs show \"Generating a random system secret...\" and this happened during the first run so it's actually impossible to restart the server.\n$ docker logs ory-hydra-example--hydra\ntime=\"2018-03-19T04:25:55Z\" level=info msg=\"Connecting with postgres://*:*@localhost:5432/hydra?sslmode=disable\"\ntime=\"2018-03-19T04:25:55Z\" level=info msg=\"Connected to SQL!\"\ntime=\"2018-03-19T04:25:55Z\" level=warning msg=\"Expected system secret to be at least 32 characters long, got 4 characters.\"\ntime=\"2018-03-19T04:25:55Z\" level=info msg=\"Generating a random system secret...\"\ntime=\"2018-03-19T04:25:55Z\" level=info msg=\"Generated system secret: 5CedSNF4Rdh9pUs6ZeI1kzJAZcug-mYj\"\ntime=\"2018-03-19T04:25:55Z\" level=warning msg=\"WARNING: DO NOT generate system secrets in production. The secret will be leaked to the logs.\"\nCould not fetch signing key for OpenID Connect - did you forget to run \"hydra migrate sql\" or forget to set the SYSTEM_SECRET? Got error: unexpected end of JSON input\n\nIf i delete the tables and run migrate again, it works again though the secret is still randomly generated.. @arekkas I opened #816 when I realized posting to this one didn't reopen it and I wasn't confident that anyone would address a closed bug. I decided to keep the comment above and just amend the comment with the newly opened bug to point that out.. How about hashing whatever is provided by the user instead of generating a random one so that at least if the user provides one, it'll always be the same?. How is simply requiring a 32 character string secure? I could just do:\nexport SYSTEM_SECRET=01234567890123456789012345678901\n\nA hashed 32 character password is as good as any 32 character password and far better than a pattern-based 32 character password like i provided above. Someone attempting to crack the hashed 32-character password won't know to try hashes of shorter passwords.\nAlso, FYI, when someone is testing out a tutorial, many times they jump straight to the code and only skim the details. . I'm well aware of security concerns with and comparisons of hashes. My point is that in a tutorial, it's not critical and user experience should matter. . Maybe this is also partly a documentation enhancement:\n$ export SYSTEM_SECRET=this_needs_to_be_the_same_always_and_also_very_$3cuR3-._\n\nis fine to explain the variable but we could also recommend a fast way to obtain a relatively secure secret, e.g.:\n$ export SYSTEM_SECRET=$(export LC_CTYPE=C; cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1)\n\nThe key here being that I was aware that I would need to retain this secret but I didn't catch that the first time I tried, the secret I used was ignored and a random one was generated. So when I tried restarting with the same insecure secret, it caused the failure which was unexpected.. @arekkas I don't but i can look into it.. @arekkas I've had it tested in the Windows 10 Linux Subsystem and that does work. Now, figuring out a solution for Windows classic shell is another story.. ",
    "hlian": "@arekkas . ",
    "ahillman3": "My docker image is built from the most recent code as of yesterday.\nEnvironment variables:\nSYSTEM_SECRET: **\nDATABASE_URL: mysql://:@tcp(xxx.xxx.xxx.xxx:3306)/hydra?parseTime=true\nFORCE_ROOT_CLIENT_CREDENTIALS: :**\nAUTHORIZE_CODE_LIFESPAN: 10m\nAUTH_CODE_LIFESPAN: 10m\nID_TOKEN_LIFESPAN:8760h\nACCESS_TOKEN_LIFESPAN: 8760h\nCHALLENGE_TOKEN_LIFESPAN: 10m\nCONSENT_URL: https://ad6c1aff82f3411e7899506d9bf1932f-844480084.us-west-2.elb.amazonaws.com:8081/consent\nPROFILING: cpu\nThe consent url is not currently working, but I'm not having a problem with that.. Ahh.\nDocker-http. Will that still work if I have it running without https in kubernetes? I like having the certificate outside kubernetes.\n. I'll look. Thanks.. I'll look into that as well.. Thanks.\n. ",
    "mateomurphy": "My consent claim looks like\n{\n  \"jti\": \"64c4f79e-e016-45b8-8c0e-d96c671c1e8a\",\n  \"aud\": \"c3b49cf0-88e4-4faa-9489-28d5b8957858\",\n  \"exp\": 1494558745,\n  \"scp\": [\n    \"openid\"\n  ],\n  \"sub\": 58318,\n  \"iat\": 1494558145\n}\nand everything works fine when I don't use the openid scope.. Ah, I dug through the fosite source and figured out that sub needs to be a string, otherwise it's silently discarded. I also just figured out that a nonce is required, otherwise you get a \"The request used a security parameter (e.g., anti-replay, anti-csrf) with insufficient entropy (minimum of 8 characters)\". Perhaps the error message and/or the documentation could be improved?. ",
    "milenkozahovic": "Looks like the container is not executed in background after it run.\n\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS               NAMES\n7e44b5470586        oryd/hydra          \"/bin/sh -c '/go/b...\"   7 minutes ago       Exited (1) 7 minutes ago                       my-hydra\n. I just setup the DATABASE_URL to memory and run the container, and got error message that indicate DATABASE_URL was not set.\n\ntime=\"2017-05-30T09:09:53Z\" level=fatal msg=\"DATABASE_URL is not set, use \"export DATABASE_URL=memory\" for an in memory storage or the documented database adapters.\"\nweird. I run this command and the container still not running:\ndocker run -d --name my-hydra -p 4444:4444 oryd/hydra -e \"DATABASE_URL=memory\"\nAlso the log message is the same with previous one.. thanks a lot. my bad :) :+1: . yeeeah no problem. thank you again. I think this should be fixed too.. Another problem occurs when i try following command:\ndocker exec -i -t e92543e0a50e /bin/bash\nand got this error:\n\nrpc error: code = 2 desc = oci runtime error: exec failed: container_linux.go:247: starting container process caused \"exec: \\\"/bin/bash\\\": stat /bin/bash: no such file or directory\". ok. it works now, the command should be:\n\ndocker exec -i -t e92543e0a50e /bin/sh\nthank you. ",
    "ballad89": "```bash\nubuntu@ip-172-31-57-106:~$ sudo docker ps\nCONTAINER ID        IMAGE                                          COMMAND                  CREATED             STATUS              PORTS                    NAMES\n5b49f071819b        oryd/hydra:v0.10.0-alpha.18                    \"hydra host\"             About an hour ago   Up About an hour    0.0.0.0:9000->4444/tcp   ory-hydra-example--hydra\ne6697ba0787a        postgres:9.6                                   \"docker-entrypoint...\"   2 hours ago         Up 2 hours          5432/tcp                 ory-hydra-example--postgres\nubuntu@ip-172-31-57-106:~$ sudo docker exec -i -t 5b49f071819b /bin/sh\noci runtime error: exec failed: container_linux.go:265: starting container process caused \"exec: \\\"/bin/sh\\\": stat /bin/sh: no such file or directory\"\n``\nI am getting this error, it seems there is now no shell at all in the image. Thanks, I got it to work withdocker exec -i -t 5b49f071819b hydra help`. ",
    "valichek": "@arekkas Hello, could you explain what is the difference when one creates the client with --is-public flag. Does it change the auth flow somehow? Also the error_description value that is passed to consent app is different from log message. \nConsent redirect:\nhttp://localhost:4444/oauth2/consent?error=invalid_request&error_description=The+request+is+missing+a+required+parameter%2C+includes+an+invalid+parameter+value%2C+includes+a+parameter+more+than+once%2C+or+is+otherwise+malformed\nLog message: time=\"2017-09-12T10:02:04Z\" level=error msg=\"An error occurred\" error=\"redirect_uri parameter does not match with registered client redirect urls: The request is missing a required parameter, includes an invalid parameter value, includes a parameter more than once, or is otherwise malformed: The request is missing a required parameter, includes an invalid parameter value, includes a parameter more than once, or is otherwise malformed\"\nredirect_uri parameter does not match with registered client redirect urls is missing. ",
    "kimooz": "Here is the log I get (maybe could help)\n```\nINFO[0012] started handling request                      method=POST remote=\"[::1]:58879\" request=\"/oauth2/token\"\n2017/06/13 12:55:51 http: panic serving [::1]:58879: runtime error: invalid memory address or nil pointer dereference\ngoroutine 15 [running]:\nnet/http.(conn).serve.func1(0xc4202bcc80)\n    /usr/local/opt/go/libexec/src/net/http/server.go:1721 +0xd0\npanic(0x162f3a0, 0x1a01680)\n    /usr/local/opt/go/libexec/src/runtime/panic.go:489 +0x2cf\ngithub.com/ory/hydra/vendor/github.com/ory/fosite/handler/openid.(DefaultSession).SetExpiresAt(0x0, 0x16deaad, 0xc, 0xed0d1c9c7, 0xc408ea2c87, 0x1a1cb00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/ory/fosite/handler/openid/strategy_jwt.go:55 +0x26\ngithub.com/ory/hydra/vendor/github.com/ory/fosite/handler/oauth2.(RefreshTokenGrantHandler).HandleTokenEndpointRequest(0xc4202ca500, 0x19d8e80, 0xc420014270, 0x19dcaa0, 0xc4200a5760, 0x19d0f00, 0xc4204141e0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/ory/fosite/handler/oauth2/flow_refresh.go:66 +0x68c\ngithub.com/ory/hydra/vendor/github.com/ory/fosite.(Fosite).NewAccessRequest(0xc4202ee090, 0x19d8e80, 0xc420014270, 0xc420410400, 0x19da0a0, 0xc4204030b0, 0xc, 0x22, 0x6, 0x15f7740)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/ory/fosite/access_request_handler.go:78 +0x409\ngithub.com/ory/hydra/oauth2.(Handler).TokenHandler(0xc4202f93b0, 0x300c128, 0xc4203f3440, 0xc420410400, 0x0, 0x0, 0x0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/oauth2/handler.go:261 +0x179\ngithub.com/ory/hydra/oauth2.(Handler).TokenHandler-fm(0x300c128, 0xc4203f3440, 0xc420410400, 0x0, 0x0, 0x0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/oauth2/handler.go:106 +0x66\ngithub.com/ory/hydra/vendor/github.com/julienschmidt/httprouter.(Router).ServeHTTP(0xc420288e10, 0x300c128, 0xc4203f3440, 0xc420410400)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/julienschmidt/httprouter/router.go:299 +0x750\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.Wrap.func1(0x300c128, 0xc4203f3440, 0xc420410400, 0xc420404880)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:41 +0x4d\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.HandlerFunc.ServeHTTP(0xc4202d3580, 0x300c128, 0xc4203f3440, 0xc420410400, 0xc420404880)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:24 +0x4e\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP(0x19d31c0, 0xc4202d3580, 0xc4202d35e0, 0x300c128, 0xc4203f3440, 0xc420410400)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:33 +0xb4\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(middleware).ServeHTTP-fm(0x300c128, 0xc4203f3440, 0xc420410400)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:33 +0x60\nnet/http.HandlerFunc.ServeHTTP(0xc420404860, 0x300c128, 0xc4203f3440, 0xc420410400)\n    /usr/local/opt/go/libexec/src/net/http/server.go:1942 +0x44\ngithub.com/ory/hydra/cmd/server.(Handler).rejectInsecureRequests(0xc42026ecd0, 0x300c128, 0xc4203f3440, 0xc420410400, 0xc420404860)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/cmd/server/handler.go:143 +0x65\ngithub.com/ory/hydra/cmd/server.(*Handler).(github.com/ory/hydra/cmd/server.rejectInsecureRequests)-fm(0x300c128, 0xc4203f3440, 0xc420410400, 0xc420404860)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/cmd/server/handler.go:58 +0x52\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.HandlerFunc.ServeHTTP(0xc4202d18b0, 0x300c128, 0xc4203f3440, 0xc420410400, 0xc420404860)\n```. Yes a Postgres DB. No I am not :) \nI agree that it works because this only happened to me twice in 3 weeks!\nI will attach more info once it happen again \nsorry :s. only id_ext for me. Yes all requests with authorization flow uses openid scope and the consent includes id_ext. The Error happens if the access token is expired and I am using the refresh token endpoint to refresh it. However if the Access Token is still valid I can refresh without any errors!. No I don't, Didn't know that Hydra already provides a tool for that :) . @arekkas  It just happened again!!\nINFO[3922] started handling request                      method=POST remote=\"[::1]:58964\" request=\"/oauth2/introspect\"\nERRO[3922] An error occurred                             error=\"Validator returned error A validator returned an error: Token expired: Token is inactive because it is malformed, expired or otherwise invalid\"\nINFO[3922] completed handling request                    measure#hydra.localhost.latency=4023782 method=POST remote=\"[::1]:58964\" request=\"/oauth2/introspect\" status=200 text_status=OK took=4.023782ms\nINFO[3922] started handling request                      method=POST remote=\"[::1]:58965\" request=\"/oauth2/token\"\n2017/06/14 15:19:16 http: panic serving [::1]:58965: runtime error: invalid memory address or nil pointer dereference\ngoroutine 1032 [running]:\nnet/http.(*conn).serve.func1(0xc4202ba460)\n    /usr/local/opt/go/libexec/src/net/http/server.go:1721 +0xd0\npanic(0x162f3a0, 0x1a01680)\n    /usr/local/opt/go/libexec/src/runtime/panic.go:489 +0x2cf\ngithub.com/ory/hydra/vendor/github.com/ory/fosite/handler/openid.(*DefaultSession).SetExpiresAt(0x0, 0x16deaad, 0xc, 0xed0d33ce4, 0xc41d00f6d3, 0x1a1cb00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/ory/fosite/handler/openid/strategy_jwt.go:55 +0x26\ngithub.com/ory/hydra/vendor/github.com/ory/fosite/handler/oauth2.(*RefreshTokenGrantHandler).HandleTokenEndpointRequest(0xc420249e40, 0x19d8e80, 0xc420014270, 0x19dcaa0, 0xc42048a0b0, 0x19d0f00, 0xc4203d0380)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/ory/fosite/handler/oauth2/flow_refresh.go:66 +0x68c\ngithub.com/ory/hydra/vendor/github.com/ory/fosite.(*Fosite).NewAccessRequest(0xc42008ef30, 0x19d8e80, 0xc420014270, 0xc4204f6c00, 0x19da0a0, 0xc4205021a0, 0xf52, 0x22, 0x6, 0x15f7740)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/ory/fosite/access_request_handler.go:78 +0x409\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler(0xc42024d680, 0x1f84000, 0xc42049e100, 0xc4204f6c00, 0x0, 0x0, 0x0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/oauth2/handler.go:261 +0x179\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler-fm(0x1f84000, 0xc42049e100, 0xc4204f6c00, 0x0, 0x0, 0x0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/oauth2/handler.go:106 +0x66\ngithub.com/ory/hydra/vendor/github.com/julienschmidt/httprouter.(*Router).ServeHTTP(0xc420288e10, 0x1f84000, 0xc42049e100, 0xc4204f6c00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/julienschmidt/httprouter/router.go:299 +0x750\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.Wrap.func1(0x1f84000, 0xc42049e100, 0xc4204f6c00, 0xc4203d00e0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:41 +0x4d\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.HandlerFunc.ServeHTTP(0xc4202c1920, 0x1f84000, 0xc42049e100, 0xc4204f6c00, 0xc4203d00e0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:24 +0x4e\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP(0x19d31c0, 0xc4202c1920, 0xc4202c1980, 0x1f84000, 0xc42049e100, 0xc4204f6c00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:33 +0xb4\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(middleware).ServeHTTP-fm(0x1f84000, 0xc42049e100, 0xc4204f6c00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:33 +0x60\nnet/http.HandlerFunc.ServeHTTP(0xc4203d00c0, 0x1f84000, 0xc42049e100, 0xc4204f6c00)\n    /usr/local/opt/go/libexec/src/net/http/server.go:1942 +0x44\ngithub.com/ory/hydra/cmd/server.(*Handler).rejectInsecureRequests(0xc420270c30, 0x1f84000, 0xc42049e100, 0xc4204f6c00, 0xc4203d00c0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/cmd/server/handler.go:143 +0x65\ngithub.com/ory/hydra/cmd/server.(*Handler).(github.com/ory/hydra/cmd/server.rejectInsecureRequests)-fm(0x1f84000, 0xc42049e100, 0xc4204f6c00, 0xc4203d00c0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/cmd/server/handler.go:58 +0x52\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.HandlerFunc.ServeHTTP(0xc420304460, 0x1f84000, 0xc42049e100, 0xc4204f6c00, 0xc4203d00c0)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:24 +0x4e\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP(0x19d31c0, 0xc420304460, 0xc4202c1960, 0x1f84000, 0xc42049e100, 0xc4204f6c00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:33 +0xb4\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(middleware).ServeHTTP-fm(0x1f84000, 0xc42049e100, 0xc4204f6c00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:33 +0x60\ngithub.com/ory/hydra/vendor/github.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP(0xc4202999e0, 0x1f84000, 0xc42049e100, 0xc4204f6c00, 0xc4203d0040)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/meatballhat/negroni-logrus/middleware.go:135 +0x2a6\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP(0x19d0cc0, 0xc4202999e0, 0xc4202c1940, 0x1f84000, 0xc42049e100, 0xc4204f6c00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:33 +0xb4\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(*Negroni).ServeHTTP(0xc4203023f0, 0x19d8480, 0xc4203da000, 0xc4204f6c00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:73 +0x118\ngithub.com/ory/hydra/vendor/github.com/gorilla/context.ClearHandler.func1(0x19d8480, 0xc4203da000, 0xc4204f6c00)\n    /Users/kareemdiaa/BrickYard/go/src/github.com/ory/hydra/vendor/github.com/gorilla/context/context.go:141 +0x8b\nnet/http.HandlerFunc.ServeHTTP(0xc4202c19c0, 0x19d8480, 0xc4203da000, 0xc4204f6c00)\n    /usr/local/opt/go/libexec/src/net/http/server.go:1942 +0x44\nnet/http.serverHandler.ServeHTTP(0xc4200a73f0, 0x19d8480, 0xc4203da000, 0xc4204f6c00)\n    /usr/local/opt/go/libexec/src/net/http/server.go:2568 +0x92\nnet/http.(*conn).serve(0xc4202ba460, 0x19d8e40, 0xc420284200)\n    /usr/local/opt/go/libexec/src/net/http/server.go:1825 +0x612\ncreated by net/http.(*Server).Serve\n    /usr/local/opt/go/libexec/src/net/http/server.go:2668 +0x2ce\nINFO[3922] started handling request                      method=GET remote=\"[::1]:58966\" request=\"/oauth2/auth?client_id=1505adc3-25b6-44ec-8df3-37eed603e7eb&nonce=5e5d5911c86bcbaa2f7479c20222fadc&redirect_uri=http%3A%2F%2Flocalhost%3A3000%2Foauth%2Fcallback&response_type=code&scope=openid+hydra+offline&state=0e4b84452e905255e8ef7d40d3206432\"\nINFO[3922] completed handling request                    measure#hydra.localhost.latency=63095130 method=GET remote=\"[::1]:58966\" request=\"/oauth2/auth?client_id=1505adc3-25b6-44ec-8df3-37eed603e7eb&nonce=5e5d5911c86bcbaa2f7479c20222fadc&redirect_uri=http%3A%2F%2Flocalhost%3A3000%2Foauth%2Fcallback&response_type=code&scope=openid+hydra+offline&state=0e4b84452e905255e8ef7d40d3206432\" status=302 text_status=Found took=63.09513ms. {\n  jti:   decoded_challenge['jti'],\n  aud: decoded_challenge['aud'],\n  exp: decoded_challenge['exp'],\n  scp: decoded_challenge['scp'],\n  sub: user.uuid,\n  iat: Time.now.to_i,\n  id_ext: user.as_json,\n  at_ext: {}\n}. you are not asking for actual values right? :)\n. yes it is just a normal json object\nnothing special in it . Seems that the issue is caused by the id_ext. if the id_ext in the consent response contains a nested object like organisation in the following example \n{\n    \"id\"=>1,\n    \"first_name\"=>\"Kareem\",\n    \"last_name\"=>\"Diaa\",\n    \"email\"=>\"admin@admin.com\",\n    \"organisation\" => {\"name\" => \"sdfsfsdf\", \"id\" => \"sdasdasd\"}\n}\nThe panic bug occurs and even more the refreshed access token loses the subject!\nI am using Hydra 0.9.6 (complied from source)  with PostgreSQL 9.6. ",
    "nblum": "I tried to start container without port binding (to prevent used ports on the host system) docker run -e \"DATABASE_URL=memory\" -d --name my-hydra oryd/hydra. \nnetstat -tulpn (inside the container) shows:\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \ntcp        0      0 :::4444                 :::*                    LISTEN      7/hydra\nI think this is from the entrypoint which runs the hydra host command initially. perfect, i will try again. ok as you expected the error message is: FATA[0014] Could not gracefully run server               error=\"listen tcp :4444: bind: address already in use\"\nShould it be possible to run hydra host inside the docker container again? . ",
    "torrange": "Jiggly puff\nOn 16 June 2017 at 09:14, Aeneas notifications@github.com wrote:\n\nClosed #525 https://github.com/ory/hydra/issues/525.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory/hydra/issues/525#event-1126418683, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AEflOrfp7D-QsL70QBnzXOaTJxAkHFKEks5sEjlogaJpZM4N753l\n.\n. \n",
    "eliasgs": "I experienced this as well, but I don't see urlencoding the credentials mentioned in rfc2617#section-2 (even the example given is just base64 encoded). The formulation in  rfc6749#section-2.3.1 seems ambiguous on this point, so in my opinion hydra does the right thing following rfc2617.\nOn the other hand it's an annoying detail that might have some pragmatic solution?. ",
    "Natim": "So hydra host --config config.yml is not really a thing?. It would be nice to be able to set all the system_secret, database_url in a file rather than in env variable especially for production deployments.. You will need to elaborate a little bit on this because most service I know are configurable by files.. Ok so one should use Dockerflow to deploy hydra?. ",
    "glerchundi": "I love 12 factor apps guidelines but I'll vote for this feature to be implemented, mainly because one doesn't hurt the other and it adds value as well as ease the deployments in several cases.\nFor example, I want to deploy Envoy + Hydra + Consent App by using a unique Kubernetes deployment + a unique Kubernetes secret/configmap. Each entry in this secret is going to be the configuration file for one of those containers:\napiVersion: v1\nkind: Secret\nmetadata:\n  name: authn\ntype: Opaque\ndata:\n  hydra.yml: |\n     port: 4444\n     public-url: \"https://\"\n     admin-url: \"https://....\"\n  consent-app.yml: |\n    port: 4445\n    hydra-url: \"https:/....\"\n  envoy.yml: |\n    cluster-1: \"/oauth2\"\n      ip: \"127.0.0.1:4444\"\n    cluster-2: \"/\"\n      ip: \"127.0.0.1:4445\"\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: authn\n  labels:\n    app: authn\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: authn\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: hydra\n        image: oryd/hydra:v1.0.0-beta.8-alpine\n        args: [\"--config\", \"/etc/authn/hydra.yml\"]\n        ports:\n        - containerPort: 4444\n        - containerPort: 4445\n        volumeMounts:\n        - name: authn-hydra\n          mountPath: \"/etc/authn\"\n          readOnly: true\n      - name: consent-app\n        image: mycompany/consent-app:v1.0.0\n        args: [\"--config\", \"/etc/authn/consent-app.yml\"]\n        ports:\n        - containerPort: 3000\n        volumeMounts:\n        - name: authn-consent-app\n          mountPath: \"/etc/authn\"\n          readOnly: true\n      - name: envoy\n        image: envoyproxy/envoy:v1.7.0\n        args: [\"--config\", \"/etc/authn/envoy.yml\"]\n        ports:\n        - containerPort: 8080\n        volumeMounts:\n        - name: authn-envoy\n          mountPath: \"/etc/authn\"\n          readOnly: true\n  volumes:\n  - name: authn-hydra\n    secret:\n      secretName: authn\n      items:\n      - key: hydra.yml\n        path: hydra.yml\n  - name: authn-consent-app\n    secret:\n      secretName: authn\n      items:\n      - key: consent-app.yml\n        path: consent-app.yml\n  - name: authn-envoy\n    secret:\n      secretName: authn\n      items:\n      - key: envoy.yml\n        path: envoy.yml\nBtw, It has the benefit of deployment consent and hydra at once thus avoiding API incompatiblities between them.\nWould you even consider this? I don't mind creating a PR.\nAnother references:\n* https://gist.github.com/telent/9742059. Let me do a complete test and will come back here. Kubernetes seems to be implementing an envFrom key in the specs and referencing this one to a complete ConfigMap/Secret by using configMapRef or secretKeyRef. So it seems fairly easy to deploy this configuration parameters in the way i'm thinking.\nWill tell you something once I have a working example.. @aeneasr TLTR, it works and I don't need a config file.\nWe're going to deploy Hydra, a front/reverse proxy and our conset application all in the same Kubernetes Deployment. This means:\n Envoy: Which reverse proxies /login and /consent to our own consent application and everything else to the public Hydra port so that we don't need to explicitly define which paths is Hydra publishing (/.well-known/..., /oauth2, ...)\n Hydra: A concrete version of hydra, for now v1.0.0-beta.9.\n Consent App*: A concrete version of consent application written in Go with a concrete vendored version of Hydra SDK in order to deploy everything at the same time and try to avoid any future incompatiblities (I know that you're probable aware of this but we feel more comfortable doing it in this way).\nThe most important bits for this deployment are the statically defined Envoy configuration for the front/reverse proxy, which is this one:\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: envoy\ndata:\n  envoy.yaml: |\n    static_resources:\n      listeners:\n      - address:\n          socket_address:\n            address: 0.0.0.0\n            port_value: 8080\n        filter_chains:\n        - filters:\n          - name: envoy.http_connection_manager\n            config:\n              codec_type: auto\n              stat_prefix: ingress_http\n              route_config:\n                name: local_route\n                virtual_hosts:\n                - name: backend\n                  domains:\n                  - \"*\"\n                  routes:\n                  - match:\n                      prefix: \"/login\"\n                    route:\n                      cluster: authn\n                  - match:\n                      prefix: \"/consent\"\n                    route:\n                      cluster: authn\n                  - match:\n                      prefix: \"/\"\n                    route:\n                      cluster: hydra\n              http_filters:\n              - name: envoy.router\n                config: {}\n      clusters:\n      - name: hydra\n        connect_timeout: 0.25s\n        type: strict_dns\n        lb_policy: round_robin\n        hosts:\n        - socket_address:\n            address: 127.0.0.1\n            port_value: 8080\n      - name: authn\n        connect_timeout: 0.25s\n        type: strict_dns\n        lb_policy: round_robin\n        hosts:\n        - socket_address:\n            address: 127.0.0.1\n            port_value: 8081\n    admin:\n      access_log_path: \"/dev/null\"\n      address:\n        socket_address:\n          address: 0.0.0.0\n          port_value: 9000\nAnd how to provide the required configuration to Hydra where parts of them are secrets and the others are not.\nconfigmaps/hydra.yaml:\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: hydra\ndata:\n  LOG_LEVEL: debug\n  PUBLIC_PORT: \"8080\"\n  ADMIN_PORT: \"9000\"\n  OAUTH2_ISSUER_URL: http://192.168.99.100.nip.io\n  OAUTH2_LOGIN_URL: http://192.168.99.100.nip.io/login\n  OAUTH2_CONSENT_URL: http://192.168.99.100.nip.io/consent\n  OAUTH2_ERROR_URL: http://192.168.99.100.nip.io/error\n  OIDC_SUBJECT_TYPES_SUPPORTED: public,pairwise\nsecrets/hydra.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: hydra\ntype: Opaque\ndata:\n  # postgres://postgres:mysecretpassword@postgres.default.svc.cluster.local:5432/hydra?sslmode=disable\n  DATABASE_URL: cG9zdGdyZXM6Ly9wb3N0Z3JlczpteXNlY3JldHBhc3N3b3JkQHBvc3RncmVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWw6NTQzMi9oeWRyYT9zc2xtb2RlPWRpc2FibGU=\n  # youReallyNeedToChangeThis\n  OIDC_SUBJECT_TYPE_PAIRWISE_SALT: eW91UmVhbGx5TmVlZFRvQ2hhbmdlVGhpcw==\n  # youReallyNeedToChangeThis\n  SYSTEM_SECRET: eW91UmVhbGx5TmVlZFRvQ2hhbmdlVGhpcw==\nSo that everything can get merged in the deployment by leveraging this to Kubernetes using the envFrom:\n[...]\n      containers:\n      - image: docker.io/oryd/hydra:v1.0.0-beta.9-alpine\n        name: hydra\n        args: [\"serve\", \"all\", \"--dangerous-force-http\"]\n        envFrom:\n        - configMapRef:\n            name: hydra\n        - secretRef:\n            name: hydra\n        ports:\n        - containerPort: 8080\n          name: public\n[...]\nThat's all.\n. apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: envoy\ndata:\n  envoy.yaml: |\n    static_resources:\n      listeners:\n      - address:\n[...]\nAnd the deployment:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: envoy\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: envoy\n  template:\n    metadata:\n      labels:\n        app: envoy\n    spec:\n      containers:\n      - image: docker.io/envoyproxy/envoy-alpine:v1.7.0\n        name: envoy\n        ports:\n        - containerPort: 8080\n          name: http\n        command: [\"envoy\"]\n        args:\n        - --config-path /etc/envoy/envoy.yaml\n        - --log-level debug\n        - --v2-config-only\n        volumeMounts:\n        - name: envoy\n          mountPath: /etc/envoy\n          readOnly: true\n      volumes:\n      - name: envoy\n        configMap:\n          name: envoy\nThat's all.. Are those tests related to my change?. Fantastic, thanks for merging!. > I really want to avoid having another migration table like here.\nThe idea is to have the same migration table as the postgres one, I'm aligned with you here.\n\nI also suspect that the two issues you mentioned wont be the only ones.\n\nCockroachDB is working hard making everything pg-compat so if something doesn't work it should be fixed in the upstream and not here.\n\nI'm not sure how well CockroachDB works with SQL and specifically more complex join and lock statements.\n\nCan you point me to concrete SQL sentences, the more complex one you can think of?\n\nAs most cloud providers support manages postgres and mysql at very low cost (but not cockroach)\n\nYeah, but CockroachDB is open-source (at least most of its features) and with a growing user base. Great PostgreSQL compatibility, automatic sharding (world-wide capable), NoSQL capabilities, Geo-Partitioning and cloud-native philosophy (no need for an operator to run inside a k8s cluster, for example) makes this a great database to start with.\n\nadding cockroach is not a priority for this project.\n\nWould you be open to do some reviews of further PRs at least?\nThanks for your time.. > Of course, this is a particularly nasty one.\nIt can be more or less performant due to joins but I think that should work. Inner joins with a pattern matching which is also supported.\n\nWith pg-flavoured SQL-compatibility it should be no work to get it working with this project. How far away are they from achieving that?\n\nThey are fixing the issues one by one but my feeling is that they are not too far from having a huge list of statement compatibilities. Take a look to a list of database management tools here.\n\nReview yes but no guarantee of merging. This is not about \"oh I don't like nothing that isn't MySQL or PostgreSQL\" or \"I dismiss the upsides of the project\". Instead the issue is that including this in master implies that we:\nWrite and test proper migrations for feature versions for another database\nAre able to support people who use CDB and have issues with our database layer due to whatever (e.g. unsupported syntax)\nActually know how to maintain and use CDB because we officially support it\nWork around issues in CDB which clutter the proper/easier to read SQL but might stay there because we are not following the project and don't know when specific issues will be addressed.\nNone of these four things are something we can currently afford wrt to resources. Depending on the PR it may be possible that we have an \"implicit\" compatibility with CDB, but if CDB specific issues are addressed in a new migration \"table\"/instruction or existing migrations change (would bring serious trouble) this can't be merged.\n\nIMHO merging doesn't mean official support, as you said what about just implicit compatibility and test it out explicitly adding a note saying that \"[...] although it seems CockroachDB to be working properly no official support is given\"?\n\nI am however happy to review a PR regarding this, maybe it's much less stuff that changes than I think it is.\n\nCool, no much time ATM but will do as soon as I can, lets discuss on the PR(s). Making proposals without promises are the most comforting jobs after all ;)\nThanks again,. The expand and contract pattern is a way to handle with breaking changes to persistent data without downtime. Take a look to this document.\nBut basically it would require ORY Hydra to follow these steps:\n\n\nIntroduce new structure\n\nCreate the new structure.\nChange any writing code to write to both places (old and the new structures). Under normal circumstances such duplication is bad, but it's only a temporary measure. Everything will be properly normalised when finished.\n\n\n\nMigrate Data\n    Once that code is successfully live everywhere, you can then run a migration on all the existing data.\n\n\nOperate on new structure\n    Once you're sure that both tables are perfectly in sync, and are staying that way, you can start to migrate all code that reads to use the new table.\n\n\nStop writing on old structure \n    When you're sure that no code reads from the old table you can remove the old code that writes to it, leaving, of course, the code that writes to the new table.\n\n\nDelete old structure\n    Once that's live everywhere, you can delete the old structure.\n\n\nDo you think this is something that you wouldn't consider?. ",
    "baboons": "I'm trying to do the same thing but I don't understand how to get the envoy.yml in the configmap to a volume, is it possible to share a full example on how you did that?. ",
    "LandonSchropp": "@arekkas Our team uses Bash scripts to run docker-compose commands to set up our environment. In our case, the $DATABASE_URL environment variable is stored in the docker-compose but isn't available in the Bash scripts. It would be really handy if this value could be read out of the environment.. ",
    "lpxxn": "my environment is win10 x64. @arekkas \n$ go version\ngo version go1.9 windows/amd64\n. ",
    "TheTitanrain": "Same issue.\ngo1.9, win10 x64.. ",
    "ducky427": "My bad. I can't seem to produce this.\nThanks!. ",
    "ckong1991": "I'm more in favor of option 2.\nFor me, most of the time was spent learning about hydra's api and how the consent flow worked (e.g. which endpoints I needed to spin up, and how the data passed between hydra and the consent app) - writing my own functions didn't take too long, so although an SDK in option 1 would be useful, its benefits might not be game changing - the network roundtrips is a definite downside.\nOption 2 removes a developer's time needed to figure out how to get hydra and the consent app talking to each other, and in my opinion a shared secret isn't that much of a degradation in security - many services are built that way anyways. But the benefit of removing the JWT complexity as well as reducing the network roundtrips is huge.\n. @arekkas ah I see. does this mean you're going to implement option 1?. ",
    "ljagiello": "Fixed here: https://github.com/ory/hydra/pull/592. ",
    "dragon3": "@arekkas Thanks!\nAre you going to release 0.10.0-alpha.8 with this fix soon?\n. ",
    "ishuah": "@arekkas I'd like to help with this :). No worries. ",
    "blockloop": "~~I can look into this~~. ",
    "zerodivisi0n": "I can't find any queries with limit/offset in hydra project in master and v0.9.x branches. However, I found one in dependent ladon project there: manager_sql.go. Does it require the fix?. ",
    "abusaidm": "I am seeing this on the docs http://docs.hydra13.apiary.io/#reference/oauth2/clientsid/update-an-oauth-2.0-client\nI don't know what version this is!. ah I see, thank you. I thought you are referring to the docs version.. done.. Hey,\nI got it working thank you.\nThis turned out to be one part of the problem, the other part is in the the consent app demo https://github.com/ory/hydra-consent-app-express/blob/master/routes/index.js.\nI changed the following:\nconst scope = 'hydra.consent hydra.consent.*'\nto\nconst scope = 'hydra.consent'\nand this removed the follwing error:\nlevel=error msg=\"An error occurred\" error=\"The client is not allowed to request scope hydra.consent.*: The requested scope is invalid, unknown, or malformed\"\nIt seems there are many breaking changes in the new 0.10 and you stated in the change log that I think it warrants a re-write of the installation guide to better explain the concepts.. no problem.\nI wanted to find out where hydra stores its core scopes as I didn't find them in the database, and if I could pick your brains a little to better understand the system when I have question, I would like to write a documentation detailing this and we could publish it if you wanted.. I mean, how does hydra know about hydra.consent ?. ok, I updated this.. is v0.9.12 the latest stable version?. ",
    "gr-eg": "It looks like this has potentially regressed in v0.10.10.\nIf a % is present in the client secret then invalid_client is raised from: https://github.com/ory/fosite/blob/master/access_request_handler.go#L87\nI guess the problem is largely mitigated due to % not being present in the charset for secret generation but It's still possible to manually pass a failing secret via hydra clients create.. ",
    "wojciechce": "Hi there.\nSeems like the problem mentioned in this issue is still valid. We are looking forward to hearing your opinion on that. Thank you in advance!\nSummary:\nSpecial characters like '%Q', '%n' in client_secret are causing Hydra returns 400.\nSteps to reproduce:\n1. Follow the 5 minute tutorial\n2. Create a client with password containing '%Q' or '%n':\ndocker exec -it hydra_hydra_1 \\\n    hydra clients create \\\n    --endpoint http://localhost:4445 \\\n    --id percent-sign-client \\\n    --secret 'foo%Qbar' \\\n    --grant-types authorization_code,refresh_token \\\n    --response-types code,id_token \\\n    --scope openid,offline \\\n    --callbacks http://127.0.0.1:5555/callback\n3. Setup home route on http://127.0.0.1:5555/ (tutorial)\n4. Open http://127.0.0.1:5555/ in your browser.\n5. Stop serving home route by pressing CTRL+C.\n6. Authenticate, login and when your browser served an error, copy 'code' from params of URL.\n7. Prepare POST request, replace {{code}} with code from URL:\nPOST /oauth2/token HTTP/1.1\nHost: localhost:4444\nAuthorization: Basic cGVyY2VudC1zaWduLWNsaWVudDpmb28lUWJhcg==\nCache-Control: no-cache\nContent-Disposition: form-data; name=\"grant_type\" authorization_code\nContent-Disposition: form-data; name=\"code\" {{code}}\nContent-Disposition: form-data; name=\"redirect_uri\" http://127.0.0.1:5555/callback\nContent-Disposition: form-data; name=\"refresh_token\"\n8. Execute request.\n9. Hydra responds with error:\n{\n    \"error\": \"invalid_request\",\n    \"error_description\": \"The request is missing a required parameter, includes an invalid parameter value, includes a parameter more than once, or is otherwise malformed\",\n    \"error_hint\": \"The client secret in the HTTP authorization header could not be decoded from \\\"application/x-www-form-urlencoded\\\".\",\n    \"status_code\": 400,\n    \"error_debug\": \"invalid URL escape \\\"%Qb\\\"\"\n}\n. @aeneasr \nAs you wrote above, I created new client:\ndocker exec -it hydra_hydra_1 \\\n    hydra clients create \\\n    --endpoint http://localhost:4445 \\\n    --id percent-sign-client \\\n    --secret 'foo%Qbar' \\\n    --grant-types authorization_code,refresh_token \\\n    --response-types code,id_token \\\n    --scope openid,offline \\\n    --callbacks http://127.0.0.1:5555/callback\nThen I extecuted request:\n```\nPOST /oauth2/token HTTP/1.1\nHost: localhost:4444\nAuthorization: Basic cGVyY2VudC1zaWduLWNsaWVudCUzQWZvbyUyNVFiYXI=\nCache-Control: no-cache\nContent-Disposition: form-data; name=\"grant_type\" authorization_code\nContent-Disposition: form-data; name=\"code\" {{code}}\nContent-Disposition: form-data; name=\"redirect_uri\" http://127.0.0.1:5555/callback\nContent-Disposition: form-data; name=\"refresh_token\"\nAnd then Hydra returns:\n{\n    \"error\": \"invalid_request\",\n    \"error_description\": \"The request is missing a required parameter, includes an invalid parameter value, includes a parameter more than once, or is otherwise malformed\",\n    \"error_hint\": \"Client credentials missing or malformed in both HTTP Authorization header and HTTP POST body.\",\n    \"status_code\": 400\n}\n``\nPlease confirm that is correct Hydra behaviour or I did something wrong (maybeclient_secretin Hydra should be urlEncoded too). . It works! Great!\nI confirm. Solution isbase64(urlencode(client_id):urlencode(client_secret))`.\n@aeneasr Thank you for your time.. ",
    "michalwojciechowski": "@aeneasr please confirm if my understanding is correct:\nhttps://tools.ietf.org/html/rfc6749#appendix-B assumes that our credentials represent a valid octet sequence and treats all percentage sings as the special unicode signs (followed by other characters). Since this is not always true, we need to escape all special characters with e.g. urlencode.. Thank you! Wasn't aware that this is such a big deal in OAuth world. We will definitely take your recommendation into account, perhaps this is the most convenient way for everyone. . This is exactly what I was going to suggest, good job!\nI fully agree, both ways should be available to us, especially since we might need to have full control over the creation of the \"external subject\". This is an option I would prefer to follow in the first place, hoping that Hydra wouldn't validate nor enforce the given value (Hydra shouldn't know anything about the algorithm we are using, right?).\nWhen it comes to the topic of supporting both types (public, pairwise) at the same time, I can't find a valid use case for now, perhaps it may come handy in the future? If you decide to support both types at the same time per client, we would need a flag to determine which subject_type is used during the authentication phase.\nI don't mind becoming a beta tester of this future. Thanks!.  @arekkas I've just took a sneak peek at the referenced commits, it looks solid! I'm wondering which option you are going to follow in the first place? Supporting the \"externally provided\" subject passed directly to hydra?. Hello @aeneasr,\nI would like to join the discussion & extend the scope of this issue. I'm after reading https://community.ory.sh/t/high-availability-and-scaling/664/10 and https://www.ory.sh/docs/guides/master/performance/1-hydra. Is there a way to expose more detailed metrics that may point us to the exact location of the possible bottlenecks, possibly on sql connections management? We are suffering from a degradation of response times from hydra if the number of requests/s is greater 50, the investigation is still ongoing though. Any advises/additional hints on performance investigation will be greatly welcome. Thank you!. Re max_conn param, according to SetMaxOpenConns, the default value is unlimited. Will let you know once we gather the metrics from the underlying DB to see if it's actually true. Also, you may expect from us more detailed insight about the distribution of traffic to the REST endpoints in the next days. Stay tuned!. ",
    "duaneking": "I used the word \"defect\" in the general \"thing I'm posting about\" usage.  Word changed to \"issue\".\nAs for your question on if I would do this:  I'm in an odd situation.  I'm currently looking for an oauth2/OIDC solution that fits our needs that we can leverage and is not powered by anything that requires Auth0 in any way (As Auth0 is far too expensive with our number of users); So the solution we find that fits our requirements is going to be the one we will commit to, and as a result will get all of the dev cycles of the team in terms of support and whatever fixes we need to contribute to it in order for the project to continue meet our needs.   I have been told by our CTO that this includes upstream patches etc; I just have not found such a solution yet and this lack of python support is one of the things that make this project not a fit for us. I'm not able to commit myself or the team to any work for a project that doesn't already fit our needs in a basic way.\n. Thank you for that response!\nI have been trying to get people to understand all of this themselves.. but you said exactly what I  have been saying for a week now means its not just me saying it!. Fully understand, and if my wording seemed odd my apologies but I'm working with expectations from others that seem.. unrealistic.. to me at this point.  Its good to have you say so if only because of the sweet validation it gives me on what I have done so far.\nWe have enough users that paying per month for them is out of the question, so sadly Cognito isn't a possibility.  We can - and I suspect, will - have our own registration and management system to deal with IDP, but my big issue atm is making sure that external services can actually use our OAuth2/identity server and integrate with systems using a JWT that doesn't have to make a call back to a central single point of failure to validate the token, and can do so using Python, Golang, etc and not Java/PHP or their ilk.. Everybody seems to want to sell an auth solution, yet people who want one don't want to buy it.\nDo you have anything I can toss up the ladder on the JWT stuff being an antipattern?  I appreciate that we are off topic at this point but I'm interested in understanding why JWT's are an issue when tokens themselves expire and should not have data in them that should be considered \"insecure\" to lose anyway.. Thanks!\n. ",
    "hiway": "Interesting discussion so far. \nJust found out this project exists; still reading up but already like how hydra tackles integrating oAuth with existing systems. I'm keen on Python3 integration for 'Sanic' for a personal project, will give it a try this week.. ",
    "mabruneau": "OK, thank you for the detailed explanation. \nI was following the tutorial (https://ory.gitbooks.io/hydra/content/tutorial.html) and got bugged down to the line where it's requested to connect in the container.. ",
    "jamesnicolas": "Cool, created #665, should fix it.. ",
    "elliots": "Apologies for the +1 but metrics for prometheus would be great for us too.. ",
    "sboulkour": "Hey @arekkas, regarding the stability of the Prometheus protocol, it is currently the de facto standard for kubernetes deployments monitoring. Prometheus and Kubernetes are part of the CNCF (https://www.cncf.io/) and are here to stay for some time from my point of view.. ",
    "dimitertodorov": "Did you actually fix consent_strategy.go?\nThat is the one that was giving me trouble.\nStill not fixed on Master.. ",
    "Rio": "It could be just me not understanding Hydra well enough while developing against it. But right now to get our developers setup quickly using only a docker-compose up I need to run, in order, a migrate, clients create and a policies create just to get a consent app going. Since the hydra container has been rebased onto scratch, I can't just chain those commands using bash within a hydra-init container. Instead I need to chain completely separate containers, each with their own entry in docker-compose.yml, just to get a single uri to point to the correct location of where my callback is listening.\nThis would solve it neatly in my opinion as it fits with the already established FORCE_ROOT_CLIENT_CREDENTIALS env var.\nI'm ok with not merging this but I'd like to see how people handle the quick setup and teardown of hydra when developing against it :). The docker example you give is how we're doing it right now. But because of the way docker-compose works and the lack of a scripting lang inside of the hydra container I need to spin up a separate docker-compose service for each hydra command I want to run. \nBtw hydra import doesn't seem to exist, I think you meant hydra clients import. Sadly this doesn't exist for policies so that will still need to be a separate command.\nThe init.d sollution would be an ok route to go as it gives you a good amount of flexibility for dev setup.\nI've also been considering to create a small go binary built off the hydra sdk that does the setup but if I'm doing that I'm inclined to just add it to the hydra cli... hydra host --dev or something.\nI'll setup a minimal docker compose file as an example including a reverse proxy so we have something to talk about. And that way you can point out any glaring mistakes I'm making ;)\nLet me here what you think.. Ah my bad for missing the policies import equiv.\nI'm sorry if I'm not being clear enough. Our problem is not not being able to connect to the containers that part is fine. Our problem is with the assumption that our callback is running on http://localhost:4445/callback as it is set in the root client. The callback is running on some equivalent of http://projectx.localhost/api/auth/callback.\nSo in order to get the client to actually get to the callback it has to be routed through a reverse proxy just like all our other services. This is a reflection as how our production environment is running but locally with docker-compose.\nIn order to get to that point and setup the redirect uri for the client I need to go through all the configuration steps of setting up migrations, creating a client, creating a policy, and then create another client and policy to be able to complete the OAuth2 flow. Usually I'd just string those commands together within the hydra container using bash. But now because there is no more bash in the container there is not easy way to run those commands without having the developer install hydra on their machine and running a shell script. Or as I said before building a custom go binary that uses the SDK to do the setup.\nI hope this explains it a bit better. . I've just finished a docker-compose file that sort of reflects our setup based on https://ory.gitbooks.io/hydra/content/install.html I haven't tested if it actually works and it's missing the consent app and consumer app.. ```docker-compose\nversion: \"3.3\"\nservices:\n  traefik:\n    image: docker.io/traefik\n    command:\n      - --web\n      - --accesslog\n      - --file\n      - --file.filename=/etc/traefik/rules.toml\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./traefik:/etc/traefik:z\npostgres:\n    image: docker.io/postgres\n    environment:\n      POSTGRES_USER: $POSTGRES_USER\n      POSTGRES_PASSWORD: $POSTGRES_PASSWORD\n      POSTGRES_DB: $POSTGRES_DB\nhydra-init:\n    image: $HYDRA_IMAGE_TAG\n    command: migrate sql postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@postgres:5432/$POSTGRES_DB?sslmode=disable\n    depends_on:\n      - postgres\nhydra:\n    image: $HYDRA_IMAGE_TAG\n    command: host --dangerous-force-http\n    depends_on:\n      - hydra-init\n    environment:\n      SYSTEM_SECRET: $SYSTEM_SECRET\n      DATABASE_URL: postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@postgres:5432/$POSTGRES_DB?sslmode=disable\n      ISSUER: http://projectx.localhost/api/auth\n      CONSENT_URL: http://projectx.localhost/api/rest/v1alpha1/consent\n      FORCE_ROOT_CLIENT_CREDENTIALS: $HYDRA_ROOT_CLIENT_ID:$HYDRA_ROOT_CLIENT_SECRET\n      DISABLE_TELEMETRY: \"1\"\nhydra-create-consent-client:\n    image: $HYDRA_IMAGE_TAG\n    command: clients create --id $CONSENT_APP_CLIENT_ID --secret $CONSENT_APP_CLIENT_SECRET --name \"Consent App Client\" --grant-types client_credentials --response-types token --allowed-scopes hydra.consent\n    depends_on:\n      - hydra\n    environment:\n      CLUSTER_URL: $HYDRA_CLUSTER_URL\n      CLIENT_ID: $HYDRA_ROOT_CLIENT_ID\n      CLIENT_SECRET: $HYDRA_ROOT_CLIENT_SECRET\nhydra-create-consent-policy:\n    image: $HYDRA_IMAGE_TAG\n    command: policies create --actions get,accept,reject --allow --id concent-app-policy --resources \"rn:hydra:oauth2:consent:requests:<.*>\" --subjects $CONSENT_APP_CLIENT_ID\n    depends_on:\n      - hydra-create-consent-client\n    environment:\n      CLUSTER_URL: $HYDRA_CLUSTER_URL\n      CLIENT_ID: $HYDRA_ROOT_CLIENT_ID\n      CLIENT_SECRET: $HYDRA_ROOT_CLIENT_SECRET\nhydra-create-consumer-client:\n    image: $HYDRA_IMAGE_TAG\n    command: clients create --id $CONSUMER_CLIENT_ID --secret $CONSUMER_CLIENT_SECRET --name \"Consumer App Client\" --callbacks http://projectx.localhost/api/callback --grant-types authorization_code,refresh_token,client_credentials --response-types token,id_token,code --allowed-scopes openid,offline,hydra.clients\n    depends_on:\n      - hydra\n    environment:\n      CLUSTER_URL: $HYDRA_CLUSTER_URL\n      CLIENT_ID: $HYDRA_ROOT_CLIENT_ID\n      CLIENT_SECRET: $HYDRA_ROOT_CLIENT_SECRET\nhydra-create-openid-id_token-policy:\n    image: $HYDRA_IMAGE_TAG\n    command: policies create --actions get --allow --id openid-id_token-policy --resources \"rn:hydra:keys:hydra.openid.id-token:public\" --subjects \"<.*>\"\n    depends_on:\n      - hydra\n    environment:\n      CLUSTER_URL: $HYDRA_CLUSTER_URL\n      CLIENT_ID: $HYDRA_ROOT_CLIENT_ID\n      CLIENT_SECRET: $HYDRA_ROOT_CLIENT_SECRET\n``. Here is the accompanyingtraefik/rules.tomlfile and.env`.\n```bash\nHYDRA_IMAGE_TAG=docker.io/oryd/hydra:v0.10.7\nSYSTEM_SECRET=very-secure-and-quite-long-system-secret-that-should-not-change-between-runs\nHYDRA_CLUSTER_URL=http://hydra:4444\nHYDRA_ROOT_CLIENT_ID=admin\nHYDRA_ROOT_CLIENT_SECRET=admin-secret\nPOSTGRES_USER=hydra-user\nPOSTGRES_PASSWORD=hydra-password\nPOSTGRES_DB=hydra\nCONSENT_APP_CLIENT_ID=consent-app\nCONSENT_APP_CLIENT_SECRET=consent-app-secret\nCONSUMER_CLIENT_ID=consumer-app\nCONSUMER_CLIENT_SECRET=consumer-app-secret\n```\n```toml\n[backends]\n    [backends.traefik]\n        [backends.traefik.servers.server1]\n        url = \"http://traefik:8080\"\n[backends.hydra]\n    [backends.hydra.servers.server1]\n    url = \"http://hydra:4444\"\n\n[frontends]\n    [frontends.traefik]\n    backend = \"traefik\"\n    passHostHeader = true\n        [frontends.traefik.routes.route1]\n        rule = \"Host: traefik.projectx.localhost\"\n[frontends.hydra]\nbackend = \"hydra\"\n    [frontends.hydra.routes.route1]\n    rule = \"PathPrefixStrip: /api/auth\"\n\n``. That would help a quite a bit. reducing setup to justhydra migrate sqlandhydra import ./thingy.json`.\nBut I think you see now why I went the adding an override for the root client's redirect uri route ;)\nAlso adding a simple /bin/sh implementation in the container would help in the short term as well because we could string all those commands in a single docker run statement like you suggested also in that comment but currently doesn't work.. oh and mind you, this is just setting up hydra and traefik. We've also got minio, cockroach, mysql, mailhog, jaeger just to name a few supporting services. Not even mentioning our own 20+ services.... > We could add an -alpine image to the docker build chain.\nThat would be a solution that wouldn't need any actual code changes. And people could opt in to it. . This is way better now thanks!\n```\n  hydra:\n    image: $HYDRA_IMAGE_ALPINE\n    entrypoint: [\"/bin/sh\", \"-c\"]\n    command: |\n      'hydra migrate sql $$DATABASE_URL &&\n       hydra host --dangerous-force-http'\n    depends_on:\n      - postgres\n    environment:\n      SYSTEM_SECRET: $SYSTEM_SECRET\n      DATABASE_URL: postgres://$POSTGRES_USER:$POSTGRES_PASSWORD@postgres:5432/$POSTGRES_DB?sslmode=disable\n      ISSUER: http://projectx.localhost/api/auth\n      CONSENT_URL: http://projectx.localhost/api/rest/v1alpha1/auth/consent\n      FORCE_ROOT_CLIENT_CREDENTIALS: $HYDRA_ROOT_CLIENT_ID:$HYDRA_ROOT_CLIENT_SECRET\n      DISABLE_TELEMETRY: \"1\"\nhydra-init:\n    image: $HYDRA_IMAGE_ALPINE\n    entrypoint: [\"/bin/sh\", \"-c\"]\n    command: |\n      'hydra clients import /etc/hydra/thingy.json &&\n       hydra policies create -f /etc/hydra/other-thingy.json'\n    depends_on:\n      - hydra\n    environment:\n      CLUSTER_URL: http://hydra:4444\n      CLIENT_ID: $HYDRA_ROOT_CLIENT_ID\n      CLIENT_SECRET: $HYDRA_ROOT_CLIENT_SECRET\n    volumes:\n      - ./hydra:/etc/hydra:z\n``. Nice, i was actually doing the same thing but I noticed you were using build args so I just changed theFROM scratchintoFROM $base_imageand added anotherdocker buildcommand. I tend to DRY alot :P . Ah sorry my bad, doesn't seem to work withFROM` statements.... ",
    "andreasblomqvist": "Could this be a custom condition ?\nFor example someone wants to do a lookup on them self on a user-service. We want to check that the subject is the same as in the resource\n. If we have a service: users\nThat returns all users for /user/ that would only be allowed for admins\nThat returns a specific user for /user/id that would be allowed for admins OR if you are the user that you are querying for\nHow do we do the check that you are the user you are quering for? is that best done as a custom condition ?. Is there a Slack for Hydra ?\n. ",
    "devdavidkarlsson": "What I wanted to know initially was: If I have \"groups:thing-{tada}-admins\"\nwhere {tada} varies (1-1000) yielding a couple of 1000 different groups.\ngroups:thing-1-admins\ngroups:thing-2-admins\ngroups:thing-3-admins\n..\ngroups:thing-n-admins\nWhere  the groups would allow access to :\"resources:olt:things:{tada}:users\"\nalso here {tada} indicating 1-1000.\nie. each group should get allowed to access it's own users.\ngroups:thing-1-admins --->\"resources:olt:things:1:users\" allowed\ngroups:thing-2-admins --->\"resources:olt:things:2:users\" allowed\n...\ngroups:thing-n-admins --->\"resources:olt:things:n:users\" allowed\nWould I need to create a policy for each of the 1000 different groups?\n. Is it correct that all \"conditions\" are based upon a context? \nYou can't write conditions based on subject->resource only.\n. ",
    "GRoguelon": "Hi @arekkas,\nI know you excluded the AWS Lambda previously in the conversation.\nJust to inform there is an easy way to get the AWS Lambda support to an existing API by using this project: https://github.com/awslabs/aws-lambda-go-api-proxy\nHydra already uses something pretty standard: a http.Handler.\nFor instance:\n```go\npackage main\nimport (\n    \"log\"\n    \"os\"\n\"github.com/aws/aws-lambda-go/events\"\n\"github.com/aws/aws-lambda-go/lambda\"\n\"github.com/awslabs/aws-lambda-go-api-proxy/handlerfunc\"\n\"github.com/ory/hydra/cmd\"\n\"github.com/ory/hydra/cmd/server\"\n\"github.com/pkg/profile\"\n\n)\nvar initialized = false\nvar handlerfuncLambda *handlerfunc.HandlerFuncAdapter\nfunc Handler(req events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {\n    if os.Getenv(\"PROFILING\") == \"cpu\" {\n        defer profile.Start(profile.CPUProfile).Stop()\n    } else if os.Getenv(\"PROFILING\") == \"memory\" {\n        defer profile.Start(profile.MemProfile).Stop()\n    }\ncmd.Execute()\n\nif !initialized {\n    // stdout and stderr are sent to AWS CloudWatch Logs\n    log.Printf(\"Handler function cold start\")\n\n    handlerfuncLambda = handlerfunc.New(server.HttpHandler.ServeHTTP)\n    initialized = true\n}\n\n// If no name is provided in the HTTP request body, throw an error\nreturn handlerfuncLambda.Proxy(req)\n\n}\nfunc main() {\n    lambda.Start(Handler)\n}\n```\nIn the code, we just need a way to keep a reference on https://github.com/ory/hydra/blob/master/cmd/server/handler.go#L117, I did by keeping a refence on corsHandler: HttpHandler = corsHandler (dirty way).\nIt's just a quick implemantation without any tests. I will try to make it cleaner, let me know if you are interested to keep an eye on it.\nThank you\n. ",
    "allcloud-jonathan": "I guess the idea would be to not have a permanent running Hydra container but have it run completely Serverless on Lambda. There is no benefit in having lambda act as a reverse proxy calling out to a running Hydra container. ",
    "zepatrik": "Is there some central storage, like a .hydra config file in ~ so I can check whether an email address is already submitted?. Yes, then someone else looking into logs could also sign himself up, good point.\nIs it better to store only whether it is submitted or which email address? I think a boolean would be sufficent. not quite ready to merge, just for review if I am doing it right. shouldn't this function (and the next one) be non capital because it is not checking the request at all, it is just a helper right?. ready for review @arekkas . so should it be handled or should there be just the field showing a 0?. Does goveralls run the test or is it in it's own command? Is replacing this line with something like\nbash\n[ -z \"$CIRCLE_PR_NUMBER\" ] && goveralls -service=circle-ci -coverprofile=coverage.txt -repotoken=$COVERALLS_REPO_TOKEN || echo \"forks are not allowed to push to coveralls\"\nenough?\nIn the goveralls repo it says that goveralls runs the test suit.. Sure, as you can see in your link above CIRCLE_PR_NUMBER, CIRCLE_PR_REPONAME and CIRCLE_PR_USERNAME are only available in forked PR builds. So checking if any of these variables is set should determine if the build is from a fork.. The coveralls api reference says the token is required. Trying the bash test approach for the moment.. isn't it better to always first check the request?. missing comment. check if rollbacks are correct. Oh now I got it, I thought that errors.WithStack(err) just has to be called once to get the whole stacktrace.. A transaction is a sequence of requests I would rather say.. I think I'm going for UpdateGroupMembers because the http PUT url is GroupsHandlerPath + \"/:id/members\" so only one group is affected, not all of them. So this should be actually without a stacktrace?. https://godoc.org/github.com/pkg/errors#WithStack\nI looked it up it works as expected. I may not have changed everything correctly when copying the comments. ",
    "rjw57": "Thanks for writing this up. Some comments based on our (University of Cambridge) experiences with Hydra.\nWe're moving forward with deploying hydra in production for an internal service. Although an internal service, we have in the 10s of thousands of users and a mature SSO web UI solution. For us, the UI-less nature of hydra is an absolute god send since it lets us make the plumbing used by the OAuth2 provider invisible to the user.\nAs a secondary advantage, we are finding the option to be a little non-conformant with the consent app is useful for our initial roll-out where the use of an OAuth2 server is essentially an implementation detail. (Having a single \"token\" allows us to pass user authentication around our various backend services using hydra as a single point of validation.) For this case we appreciate the option of making the user experience just like our other web SSO based services where the user is re-directed to our login portal and then back to the webapp. \"Consent\", in these applications, is inferred from the user being willing to provide authorisation credentials. (This would not, of course, be true in general but a) this service is for internal users only and b) we have a controlled set of OAuth2 clients.)\nWe very much appreciate the clear desire to be standards compliant and the attention to detail provided within hydra which is why we're willing to move forward with an internal production deployment at this stage.\nWe find the current consent flow to provide a good amount of control over the consent process in a place we would like it: our consent app. It also has the advantage of being very quick and easy to implement.\nFrom our perspective we'd like to retain the UI-less option and have the flow diagram in the issue replicated in the hydra docs as a example of how to interpret the mustAuthenticateUser, etc options hydra would provide.\nSo, as a concrete suggestion, perhaps a good mid-ground would be to have a \"blessed\" UI-containing consent app implementation which redirects to the LP? Maybe as a separate container or as a configuration option? Then one has the two options:\n\n\nIf you just want to integrate an existing identity provider, use \"hydra\" + \"hydra consent\" app. Blessed consent app uses existing consent flow but redirects to user-provided LP for authentication and LP redirects back to consent app as in the final diagram. This would be the OpenID Connect-friendly way.\n\n\nIf you have more subtle needs, you have the option of implementing your own consent app using something like the existing consent flow.\n\n\nThis way hydra proper can remain UI-less, the consent flow can remain similar to how it is at the moment (which I find to be a sweet-spot on the complex/powerful axis). The combination of \"hydra\" + \"hydra consent\" is then OpenID Connect Certifiable but power-users can opt to implement their own consent app.\nThanks once again for hydra. We evaluated a number of options internally before settling on hydra and the fact that it did everything but the UI for us was one of the strongest selling points.. > Do you want to implement the consent screen, where you select the scopes, yourself - or is it ok if Hydra handles that. Again, the log in screen will not be touched.\nUsual caveats aside, I think we would like to implement the display and selection of scopes ourselves. Some scope grants may be implied or mandated by a subject's role within the organisation, for example, which is probably not capturable in a template based workflow.\nSo, if I understand correctly and this change were to become something like splitting what is now called a \"consent app\" into a \"show and select scopes\" app and a, possibly, separate \"login provider app\", I think that could work for us. Presumably hydra would take care of tracking whether the token subject logged in before and what scopes have and have not been previously granted for the client?. While we're at it, I suppose there could also be a dedicated error reporting endpoint. So the hydra configuration now contains URLs pointing to a \"select and show scopes\" endpoint, a \"perform user login\" endpoint and a \"display error\" endpoint. The select and show scopes and error endpoints could default to UI apps provided by hydra.. But advanced users can provide their own endpoints for all three. (Sorry, on mobile and hit \"submit\" a bit early.). > In conclusion: Now that you have a better understanding, what's your take at this? I really see that the no-ui approach is something that propelled Hydra to what it is today and also to what it sets apart from the competition. I am actually sort of drifting in direction of having separate login, consent, and error endpoints (with default state of the art apps), but the flow has to be air tight.\nIf it took the form outlined in this discussion, then I quite like the idea of the separate login, consent (aka show and select scopes) and error endpoints. It seems a neat way of delegating the UI while retaining control over the logic. The UI-less nature of Hydra really is a USP in some quarters, including ours.. I think the three endpoint (AS, AE, CE) case seems superior. Especially if Hydra implements or provides a default CE implementation. The default CE implementation can then be \"lightly\" template-able for simple use cases but still provides flexibility for advanced users. This reduces the likely pressure on the default CE endpoint to implement feature X or template hook Y.\nThe three endpoint case is also conceptually simpler since OAuth is essentially \"authentication\", \"authorisation\" and \"plumbing to allow said\". Hydra then neatly fits as the \"plumbing\".\nThe two endpoint case (AS, AE) is also workable but is likely to open some flood gates w.r.t. feature requests for improvements to templating/customisation/etc which might dilute hydra's \"small, simple, easy to grok\" nature.. No probs. I'm subscribed to the issue but also feel free to @-tag me if I seem to have missed it.. > With the above scenarios and mitigations, I established a flow that would look like the following graph. A flow diagram will follow as well to properly document decisions with regards to these scenarios.\nI've not properly had a change to think about the flow from a security perspective but from a functionality perspective this looks to be the right shape of things for us.. So I've had time to have a look at the flow proposed above. It seems sensible but, of course, the proof is in the implementation. I see that lessons from issues discovered in the current consent flow have been folded in which is good.\nIt looks like the consensus is falling on the three-endpoint solution and I'm going to echo @pnicolcev-tulipretail and @dtt101's enthusiasm for it from a UI-less perspective. (And, @dtt101, waves at Pi towers.)\nThanks, once again, @arekkas for engaging on this issue.. > No, it's still in development\nAnd that's absolutely fine. It's great that the design work is being done in such an open way. Am I right in thinking that anyone interested in getting a \"sneak peek\" at this should be looking for commits landing in the 1.0.x branch?. ",
    "dtt101": "@arekkas - thanks for sharing this process - very valuable to read your thoughts, and the contributions from other users (especially @rjw57 - we are also based in Cambridge, UK!)\nFirstly a \ud83d\udc4d on the UI-less nature of hydra at the moment - building our own consent app has enabled us to implement many features that would be very complex to support if Hydra was responsible for serving the UI, custom messaging, branding (including serving different messaging for different client applications) and being able to present something 100% consistent with the rest of our web estate, (I am basically restating the case that @rjw57 and @pnicolcev-tulipretail have made).\nI also prefer the three endpoints approach - our current approach of bundling the consent flow and user auth into one application has introduced a degree of complexity.\nA couple of things would be useful if hydra is responsible for maintaining previous app authorization:\n\nA way to present back to a user what applications they have previously consented to, and to revoke consent on a per application basis\nA way to revoke all application consents at once (for example if we believe a user account has been compromised)\n\nFinally - for developers new to the Hydra project a 'blessed' implementation (similar to the existing express and go consent example apps) for all endpoints would allow people to get up and running with Hydra with minimal effort. We would be happy to contribute.\n. ",
    "sandrom": "Did you consider a use case, that giving consent to certain scopes or even everytime getting another token might require a second factor of a user or even a fresh login in this concept? currently integrating a 2dn factor at least for consent on specific scopes is easy, but it would not be that easy anymore with this change. is it thinkable to make an optional consent app possible anyway? Otherwise very specific requirements might make hydra harder to use or you'll have to integrate 2nd factor logic stuff into hydra (which might be different very often)\nlet me be more precise: we would need 2nd factor after a successful login to give consent, meaning it has to be something possible \"in the middle or as a requirement for consent\". splitting identity provider and consent app up would be ok, but it would still need to support that way of handling it for us. @arekkas \nYes it sounds reasonable. Actually if we could have the session optionally not-sticky and with a rather low timeout (important to distinguish between maximum lifetime and idletimeout though) we could implement all the necessary workflows. only a small percentage of users would ever have an issue with that, and that would be fine :) . hm i understand the reasoning on why you want people to subscribe, but its also kind of weird at the same time. a notice, thats annoyingly posted in blink red/green for a couple seconds to users might still be an option, but that might also alienate people, unless you add some flying unicorns! so ok, i get it :). yes actually having a note on why this newsletter is so important for everyone and why you care so much (meaning you don't wanna sell anything but simply tell them about security updates) would probably make a lot of difference. great!. @arekkas While I understand your point, hope vs reality is different beasts at time. For us here its not possible to change from json easily as changing anything the customers are currently doing is a big issue and they do json right now. One battle at a time. Furthermore its not that uncommon to use json for doing exactly that, see https://auth0.com/docs/api-auth/tutorials/client-credentials\nWhile I understand, that its possibly not favorite, for us using hydra means just adding a service in front to translate from json to forms if that feature can not be mapped by hydra and I see already people questioning the use of hydra then. The age old problem of kiss vs reality. :(. funny, that API article was already posted by our team as one of the many desperate attempts to introduce some kind of any version management around, which currently is non-existent. tell me about it :)\nanyway, no problem, we can solve it and I know where you're coming from standing for that (usually it's one of us waving IETF specs around that should be considered instead of another ruby-halfbaked-iknoweverythingbetter-solution). Just had to make sure as there are still many other battles to fight and our time is simply rather limited. I'd also rather get rid of simple client_credentials flows generally, but that's another story altogether.\nnevermind and thank you a lot for taking the time!. ",
    "p-bakker": "Very interesting read this topic, clarifies a bunch of things for me, while currently trying to figure out whether Hydra fits our needs or not.\nOne thing I'll add to the discussion that having good documentation & samples would be a must, regardless of the approach taken. Am currently finding it quite hard to figure out exactly how to get Hydra and the consent flow going: documentation seems a bit scattered and out of date or requires you to anylise the NodeJS/Go code\n@arekkas any approximate timeline for having the stuff discussed in this issue available in the product? As I mentioned we're evaluating whether Hydra fits our needs (seems so). If the whole consent flow will be replaced with the approach outlined in this case, depending on the timeline, it might be better for us to hold off on implementing Hydra with the current consent flow and wait for the new approach to be available. @arekkas\nTnx for the update on planning.\nAs for docs: will share my findings/thoughts on how to improve the docs. ",
    "kavuri": "I agree with @p-bakker on a sample app for consent flow (with a reference UI) for a quick start will immensely help to get a grasp of the internal details. Are these API end-points available now? I am looking at hydra-consent-app-express for a quick start. ",
    "genesis32": "Super late to the party but I'll throw my 2 cents in here.  We are currently going live with a number of large customers.  The consent app has been great because we control all of the authentication/authorization logic and hydra is basically just a trusted bridge between our IDP and our API's.  \nThere was a note back when 0.10 was released that said \"We know that these are a lot of changes, but we highly recommend upgrading to this version. It will be the last before releasing 1.0.0.\"  We did the work to upgrade to the new consent flow (well worth it in my opinion).  \nMaking breaking changes at this point in time could push us behind other product timelines and we have more important things to be doing.\nI'm all for improvement but there needs to be some backwards compatibility or an extended timeline for support on the functionality that constitutes the 0.11 branch. I would prefer to not fork this project and have to apply any bug fixes there.\nGreat work on this by the way! It's been awesome to use.. ",
    "Detrous": "@arekkas hello!\nCan i skip screen \"An application requests access to your data!\" ? I need only authorize user and use his token to requesting API through Oathkeeper+Keto. App have't scopes, only rules and roles in Oathkeeper+Keto. @arekkas how I can do this \"skip\" ?. ",
    "mdziemianko": "seems like that might break compatibility with some standard python librariees like flask oidc (it uses itsdangerous see https://github.com/pallets/itsdangerous/blob/master/itsdangerous.py)\n. ",
    "nigeltiany": "Just came across https://github.com/ory/hydra/issues/772. It discusses a feature that introduces a hydra scope that allows apps to skip the consent screen. I think that is a better approach.. ",
    "ManassehZhou": "Yes, and it can reproduce in the latest release on docker hub and my own build. ",
    "bogdanvarlamov": "I definitely like the Warden API. If it is being developed on it's own and enhanced with additional functionality, I like that too. I would just hope that few functionality doesn't make it more complicated to get started using it--sometimes that happens when there are 300 pages of docs for the 20 ways to do something, and it's just too many options.. ",
    "YannickB": "Very well, this may cause some incompatibility with some react application I fear, using history/createHashHistory. But if it's part of the standard it can't be help.\nAnyway, I ended up finding the difference between history/createHashHistory and history/createBrowserHistory, this solved my use case and hopefully others too. I find we can close.. ",
    "bdudelsack": "That works. Thank you!. ",
    "dolbik": "@arekkas Maybe this article can help https://blog.alexellis.io/prometheus-monitoring/. @arekkas Looks like a have finished code according discussion. . @arekkas Are any actions needed from my side? . I'll back it to old place as we decide to separate Prometheus and telemetry flag. https://prometheus.io/docs/concepts/metric_types/\nHistogramVec is used for request durations for example.\nName of the counter should be like https://prometheus.io/docs/practices/naming/ and we can change it accoring rules in doc. I agree with you. Some configurable value can be added (for example CLUSTER_NAME, default hydra) for naming. In this case metrics name will be CLUSTER_NAME_response_time_seconds for example. By default prometheus client gathers information about:\n\nNumber of goroutines that currently exist.\nA summary of the GC invocation durations\nNumber of bytes allocated and still in use\nTotal number of bytes allocated, even if freed\nNumber of bytes obtained by system. Sum of all system allocations\nTotal number of pointer lookups\nTotal number of mallocs\nTotal number of frees\nNumber of heap bytes allocated and still in use\nNumber of heap bytes obtained from system\nNumber of heap bytes waiting to be used\nNumber of heap bytes that are in use\nTotal number of heap bytes released to OS\nNumber of allocated objects\nNumber of bytes in use by the stack allocator\nNumber of bytes obtained from system for stack allocator\nNumber of bytes in use by mspan structures\nNumber of bytes used for mspan structures obtained from system\nNumber of bytes in use by mcache structures\nNumber of bytes used for mcache structures obtained from system\nNumber of bytes used by the profiling bucket hash table\nNumber of bytes used for garbage collection system metadata\nNumber of bytes used for other system allocations\nNumber of heap bytes when next garbage collection will take place\nNumber of seconds since 1970 of last garbage collection\nTotal user and system CPU time spent in seconds\nNumber of open file descriptors\nMaximum number of open file descriptors\nVirtual memory size in bytes\nResident memory size in bytes\nStart time of the process since unix epoch in seconds\n\nAll other metrics should be added manually. Thats why i added 2 metrics that may be needed for users\n. In this case new middleware does not make sense. New endpoint will be added into \"health\".\nShould i leave middleware as skeleton for future or it can be deleted?. I propose to leave a empty middleware for prometheus with examples. It is given ability to simple add custom metrics if needed. I propose to leave a empty middleware for prometheus with examples. It is given ability to simple add custom metrics if needed. @arekkas I left this part practically unchanged. Server reports stay as is. Prometheus middleware is always enabled https://github.com/ory/hydra/pull/827/files#diff-34e2a4fce852fbba1d689b617c6d4a94R114. ",
    "JesseFinch": "427 characters\nthis is jwt payload. so my question is why hydra_consent_request table has a dimensionless subject field? . oh, it.s ok. but where should i store my JWT? \ud83d\udc51 . thx. ",
    "smyrgl": "This would be a very nasty way to go on iOS because the security model is moving towards using SFAuthenticationSession (iOS11) and ASWebAuthenticationSession (iOS12+) which create out-of-process (sandboxed) Safari instances that the app has no control over.  Thus there is no way to invisibly call an iframe and the cookies themselves that are used for tracking the session are not directly accessible.  The only feasible means to do session management assuming this model is adopted is having a way to manually revoke the token which would also kill the session remember token.. That would be my preference and I don\u2019t see any other way that would really work.  They aren\u2019t mutually exclusive though so have a revoke endpoint that purges the session could be done for use cases like admin or mobile.  \nIt might be good though to keep these separate.  An admin endpoint would want to arbitrarily revoke sessions (token or users) but a POST to a /logout for a given session could simply use the Authorization header and return a 204 thus only expiring the session token associated with the given user.. ",
    "4ichpich": "Version:    dev-master\nGit Hash:   undefined\nBuild Time: 2018-05-02 11:54:47.033295477 +0000 UTC m=+0.004540814\nit's was from docker oryd/hydra:latest\nI can't tell what version it was excactly. The bug is still existing in v0.11.12\nI'm using v0.11.12-alpine. ",
    "prateek1192": "I have started working on this and would update my findings in some time.. Thanks @aeneasr :). ",
    "bbulczynski": "How would you suggest to do that? Maybe using claims and setting value?\n. 1. How do you plan to alter pairwise subject functionality to cooperate with that?\n2. Do you mind interchangeability of id_token between clients?\n3. How about client deciding about which of his auds should be visible to other? I think aud content should be decided per client by user on consent page. . ok, i should have order 2. before 1. to make it clear, so let me explain that...\nDo you think that id token could be shared between clients from aud list? Otherwise bother putting list of aud into token, ok client can check if that is intended for him, but why put there other aud values? I could imagine situation where third parties share id token, that is signed and can be verified, and pass information about user among themselves that way.\nThe open spec of aud explains rest.\nThank you.\n. OK, thanks for sharing. . i think i made a mistake in authorisation request here passing acr_value instead of acr_values - that can be the couse why i dont see acr_values in oidc_context.\nBut acr setting is still not working... I'm gona check that today and fix issue decription if that is the case.. You ware right, i have retested the case. With proper acr_values parameter, acr is allways set to \"0\". I have Updated descrion and how to replicate it. Please give it a second look.. > Thank you, I'll investigate this.\n...how is it going any clues?. ok, thanks :D\nczw., 20 wrz 2018 o 09:49 hackerman notifications@github.com napisa\u0142(a):\n\nBut feel free to investigate yourself & supply a PR :)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory/hydra/issues/1032#issuecomment-423077977, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AijM5LRkhIFDWSEtGBsbIqo_-4etXSvXks5uc0iWgaJpZM4WoP2L\n.\n. Ok, I understand your point of view. I understand functional diference between those urls, still... when you share url without path part the convention is to ommit singular / sign. Look at what OpenID Connect has to say about issuer identifier\n16.15.  Issuer Identifier\nOpenID Connect supports multiple Issuers per Host and Port combination. The issuer returned by discovery MUST exactly match the value of iss in the ID Token.\nOpenID Connect treats the path component of any Issuer URI as being part of the Issuer Identifier. For instance, the subject \"1234\" with an Issuer Identifier of \"https://example.com\" is not equivalent to the subject \"1234\" with an Issuer Identifier of \"https://example.com/sales\".\nIt is RECOMMENDED that only a single Issuer per host be used. However, if a host supports multiple tenants, multiple Issuers for that host may be needed.\n\neven the spec is giving example without trailing /\nalso same spec at Terminoogy part states that path part is optional and your decision makes it obligatory in at least \"/\" form\n\nIssuer Identifier\nVerifiable Identifier for an Issuer. An Issuer Identifier is a case sensitive URL using the https scheme that contains scheme, host, and optionally, port number and path components and no query or fragment components.\n\nPlease reconsider distinguishing behavior when issuer is defined with and without path part in uri.\n. 1. What problem does it solve?\n2. Will there be possibility to enforce wider aud for certain clients?\n3. In case od scopes you refer to default scopes described in https://tools.ietf.org/html/rfc6749#section-3.3 last paragraph?. Thanks,\n\nCan you elaborate?\n\nI meant, will clients have possibility to overwrite default either by hydra client definition or authorization request.\n\nYes, the OAuth 2.0 Scope, as it exists today in ORY Hydra\n\nI meant, according to source, there can be possibility of serving request with no scopes with default one. Currently hydra is not supporting that, right?. ",
    "Aggouri": "\nWhile modifying the audience of an ID Token is not desirable, specifying the audience of an OAuth 2.0 Access Token is.\nORY Hydra implements this feature, which is not defined as an IETF Standard but is\nconsidered good practice in certain environments.\nTo use the audience feature, you must specify the intended audiences in the OAuth 2.0 Client's metadata on a per-client basis:\n\nWhile I don't necessarily have the best writing skills, I think this would be slightly more clear:\n\nWhile modifying the audience of an ID Token is not desirable, specifying the audience of an OAuth 2.0 Access Token is. This is not defined as an IETF Standard but is considered good practice in certain environments. \nFor this reason, Hydra allows you to control the aud claim of the access token. To do so, you must specify the intended audiences in the OAuth 2.0 Client's metadata on a per-client basis:\n. nit: TestPKCEReuqest -> TestPKCERequest. \n",
    "husio": "I looked at the code and here's rough idea of how it could work https://github.com/ory/hydra/compare/master...husio:healthcheck_proposal\nEach hard dependency implements HealthChecker interface and is registered as such. List of all dependencies is passed to health handler to be used when requested. As an optimization, background check task can be periodically performed for each health checker.\nI'm not sure how to expose list of dependencies to the health check endpoint, nor how to properly format error response, but I think those are minor issues. \nWhat do you think about the approach?. I should have communicated better. \nI was working on proper solution (what I have provided so far was more of a pseudo code), including @pnicolcev-tulipretail suggestion, but if you say you will finish this, than that's great as well. Thanks!. ",
    "clausdenk": "in-memory. I understand this might not be of highest priority right now, but it might even have legal issues. With the new GDPR, a user should have the right to know what permissions he gave to a certain app. Right now I don't see a way to implement this. Or can I query the last consent attributes somehow? (without prompt=consent?)\nAlso, have in mind that the certain circumstances you mention usually are the most probable situation, api permissions in most cases are very long lived and consent is given on first use of the app. So after the very first visit to the app the certain circumstances almost always are given.. An endpoint to query the users current active (or last active) consent would solve the problem, as we could access this endpoint before showing the consent UI. Something like this will also be necessary if I want to display a list of all apps that the user gave permissions to, in this case as a UI the API service offers to the user. . Would it be possible to associate some user data to the login and/or consent requests? I guess the use case proposed by @davidf-uc3m would need something like that so he could identify where the consent request came from.. Maybe my suggestion was not explained well enough. I suggested to introduce a user defined (unique) key, which can be associated with the consent request. Then, when retrieving all consent requests I also would get my keys so that I can identify each consent request:\n\nkey1 -> consent data 1\nkey2 -> consent data 2\n\nOf course, the user could use remote ip, user agent etc. to construct this key (and thus \"recover\" the desired consent) but this is not hydra's task. The key should just not be too short and the user puts what he wants (even empty key) in it.. Yes, this would be possible, but it would require persistence for the consent app. As all requests are stored within hydra, it would be nice to be able to attach some user data, this would make the consent app much simpler to implement. And it should be easy to implement in hydra (add an extra optional \"user\" parameter to the AcceptConsentRequest structure which will be handed back with the consent requests?).\nNote that for my use case this is not necessary, I would only need a list of not expired consents. Even the last not expired consent would do. . Exactly!. My guess is that a protection based on endpoint url paths (done by the user) would be more flexible. How about an example setup of an nginx reverse proxy to go with hydra? I'd personally prefer this. Would it be done in a way that user and admin endpoints can be mapped to the same port?. I guess you want hydra serve to serve both for backward compatibility? With this in mind it would seem more natural to use hydra serve -only-public or whatever for reduced setups.. With hydra serve public and hydra serve control I would probably expect hydra serve public control to give the full server and hydra serve to throw an error (missing arg). With \"only\" you express that the additional arg is a reduction of the full command.. @arekkas But in this case older Dockerfiles (that use hydra serve) will stop to work.. I find hydra serve public control a bit long for what is probably the default action, but it is expressive. I can imagine two possibilities, one reductive, one additive:\nhydra serve + hydra serve --only-public + hydra serve --only-control\nhydra serve all (or  hydra serve public control) + hydra serve public + hydra serve control\nBut the syntax should express if we reduce or add. Agree 100% with breaking and getting a good expressive syntax.. Sounds good then. It also is more flexible in case you split another port :). ",
    "davidf-uc3m": "What's happen when the user opens the app from mobile and choose some scopes, and at the same time open same app on desktop and select different ones?\nHow can you identify both flows to show different custom consent pages?  Is there a way to identify which flow are tied to each scope selection? Does what I'm saying make sense?\nThanks!. We have a use case where we should identify at login time if the user is impersonated (and by whom) in order to detect if is a real user or not. This information is needed at consent time to build the id_token with this extra information. As @clausdenk suggested, remote ip, user agent, etc. would be enough in order to trace the users and their requests.\nI think it would be enough and 'ext' field to add custom properties to the message accepting the login, in order to recover it when requesting consent challenge data.\n. Even both :-). I prefer require an \"introspect\" scope and keep the endpoint open. Brute force attack could be done only using valid credentials. Brute force attacks can be detected by other means that could lead to invalidate those client credentials. \nKeep in mind that some Resource Servers could be a third party api developed outside validateing scopes from tkoens issued by our Hydra. Those 3rd party apis should be able to call introspect endpoint.. Thank you for the link. I'll review it more concisely.\n. Ok. In case the introspect endpoint were deployed as administrative endpoint.....no extra security would be checked by Hydra (neither basic auth nor bearer)....Am I right?. And requiring \"hydra.introspect\" as scope?  I think it's a good approach, this way it forces (as now does) to register the resource server as hydra client (in order to keep all resource servers tracked). Ok, it's true. . I agree: It should be exposed in both ways.. ",
    "decoomanj": "Why don't you expose the path on the public AND the admin part? On the public one, the client needs clientID/secret  (as the specs suggest), and on the admin part there is no security necessary (since this would be a Hydra thing).. Normally seen, nobody will expose the admin-interface over the API-gateway unless they really know what they are doing. In our case, only other internal services will communicate with Hydra (just as they do with Cognito). I don't see a reason why an admin-endpoint would ever be exposed without an additional layer protecting it.\nI think it would be ok when the public introspection endpoint would be exposed. It is protected by default and adheres to the spec. I understand that there is a risk involved here too, but if you strive for your own OIDC certification, you may probably need this?? Anyway, the admin introspection endpoint is protected in that sense that it is only accessible from within your own network.\nThe fact that you expose sensitive data is in the nature of OIDC. You documented it already well in the code. \nFor my own use-case, I would use the (unprotected) admin-introspection first, and then see if my clients are in need of the public endpoint. When yes, I will expose it on the gateway.\nBut maybe there is also another difference between public and admin. When my gateway wants to validate a token, it will send it to the introspection endpoint. There will be no clientID or whatever there. The gateway just needs to know if the token is valid.\nOn the public endpoint, the client can probably only check the validity of tokens issued to him, right? This would make a subtle difference IMHO.. Ok, this was a false assumption from my side then (probably mixed it up with userinfo which is in well-known). Nevertheless I think exposing it on public and admin makes sense. Then it is easy to expose it to clients when needed, and you can use the admin safely in your own environment.. will do. hang on :-). ",
    "boydgreenfield": "@arekkas I like cleanly separating privileged vs. public endpoints. One feature that would make hydra much more usable out-of-the-box would also be supporting basic auth protection for the privileged endpoints, e.g., via a PRIVILEGED_BASIC_AUTH_USER and PRIVILEGED_BASIC_AUTH_PASSWORD environment variable or flag.[1]\nFor context, we've deployed Hydra to a PaaS (Aptible, but this would apply to Heroku or most others) and unfortunately couldn't use the direct Hydra Docker images because these endpoints are unprotected and we're not using an API gateway (nor is that easy to do/common with those setups).[2]\nIn many PaaS environments, this addition would let users get set up much more quickly in a secure way.[3] Just my two cents. Thanks for all the great work on this project! \ud83d\udc4f \n\n[1] I realize this is a slippery slope towards requiring a multitude of auth schemes... But the alternative is requiring users without API gateways to roll their own in order to deploy Hydra, so built-in basic auth seems like a pretty good fallback option.\n[2] Our solution was to set up an NGINX proxy with basic auth for all of the privileged endpoints. Separating the endpoints is a big win as we don't have to keep the list of routes in sync (just protect one port and not the other) but it'd still be very nice to be able to use the ory/hydra Docker images directly vs. re-packaging and increasing the friction around updates.\n[3] Ps. One other note is that many of these environments also handle TLS termination. May be worth noting in the docs that this requires the --dangerous-force-http flag and that's it OK in that context (it's a reasonably, but very alarming flag name :smile:).. @MOZGIII Well, glad to hear that now as we're only running it in a staging environment (and it's on a separate network)! Do you know what one is supposed to do? Without that flag, the server was just refusing all of our connections (but maybe I didn't set the HYDRA_URL correctly?).... @arekkas OK thanks. I'm not 100% certain if we are guaranteed to know the IP range for HTTPS_ALLOW_TERMINATION_FROM to work properly but will investigate. \nRegarding basic auth, that seems reasonable \u2013\u00a0I understand not wanting to clutter the core, especially since you have a separate service for this. The only downsides are, of course, that you end up then needing to run Oathkeeper for a very limited subset of its functionality and you end up with a 2 process Docker container (begging some questions about health checks, etc. on a PaaS). It'd certainly be nice to just be able to use a TLS Client Cert! \ud83d\ude04 \nEdit after seeing @MOZGIII's comment: Regarding TLS, I just meant it'd be nice if our load balancers supported them; this is not a request to build that into Hydra!\n. ",
    "tpoxa": "I added debug code here\njwt_strategy.go\n```\nlog.Println(j.privateKey.PublicKey)\n    log.Println(j.publicKey)\n    log.Println(j.privateKey.PublicKey != j.publicKey)\nif j.privateKey.PublicKey != *j.publicKey {\n    return errors.New(\"public and private key pair fetched from store does not match\")\n}\n\n```\nso it prints this\n```\nhydra_1          | time=\"2018-06-29T17:34:10Z\" level=info msg=\"Connecting with postgres://:@postgresd:5432/hydra?sslmode=disable\"\nhydra_1          | time=\"2018-06-29T17:34:10Z\" level=info msg=\"Connected to SQL!\"\nhydra_1          | 2018/06/29 17:34:10 {909068191641614038972173687245400607803051550688112345729429010992701732833139633906430094930993281622394925244506797629431046046095286320678127113339135618422520002732190343963874150786114667107122624300907513129732754849134202354163677787108400397587785732902589304146095079116203067034944326739644240269747026477162619365980317773564115476527185996359870180337506152302821629682312332846874611312697398776506084266152249613054604905066349667054047446122373117707568235773846427185407581609399037375085334113120155634323197164599510689874977778333245173698318147789801935675843357726978354904207881540182789442923069391524755110307795850533824577850528531927161525148756085746531690236843274875171076322348063997113969256990549128993972226638507517228500179910616490532467237910120582371977390895215749213010611127320016539907078482160863031453944033146342329791683493422957949215811023504317954171862417427435301388191048457827772197626583015999396766256437819875224070939984153461808894996944913685078129743842551451055991543081556375147683777274245210646582493208561269676124316303943551660237709695234354317227184816650735432284793836827239483863489175534384780513046261510792021902700696020537391693044922709797491658510491257 65537}\nhydra_1          | 2018/06/29 17:34:10 {909068191641614038972173687245400607803051550688112345729429010992701732833139633906430094930993281622394925244506797629431046046095286320678127113339135618422520002732190343963874150786114667107122624300907513129732754849134202354163677787108400397587785732902589304146095079116203067034944326739644240269747026477162619365980317773564115476527185996359870180337506152302821629682312332846874611312697398776506084266152249613054604905066349667054047446122373117707568235773846427185407581609399037375085334113120155634323197164599510689874977778333245173698318147789801935675843357726978354904207881540182789442923069391524755110307795850533824577850528531927161525148756085746531690236843274875171076322348063997113969256990549128993972226638507517228500179910616490532467237910120582371977390895215749213010611127320016539907078482160863031453944033146342329791683493422957949215811023504317954171862417427435301388191048457827772197626583015999396766256437819875224070939984153461808894996944913685078129743842551451055991543081556375147683777274245210646582493208561269676124316303943551660237709695234354317227184816650735432284793836827239483863489175534384780513046261510792021902700696020537391693044922709797491658510491257 65537}\nhydra_1          | 2018/06/29 17:34:10 true\nhydra_1          | 2018/06/29 17:34:10 public and private key pair fetched from store does not match\nhydra_1          | Could not fetch private signing key for OpenID Connect - did you forget to run \"hydra migrate sql\" or forget to set the SYSTEM_SECRET?\n```\nI guess not really good idea to compare struct objects with pointers? No?. ",
    "axife": "I experience same bug. . ",
    "manhdaovan": "And add GO111MODULE=on before go install with go version 1.11+.. ",
    "jbpin": "\n. it's working nicely with 0.11.12-alpine. I hope you will get it. BTW, thanks for your job guys. I really like hydra. . I'll check it and let you know. Ok It's working now on v0.11.14. Thanks. Fixed. ",
    "Entrio": "After performing those queries, hydra generated new keys but my client now fails to authenticate with the following error:\nClient supports client authentication method \\\"client_secret_basic\\\", but method \\\"client_secret_post\\\" was requested.. For those like me, the issue was that I needed to update the property of the client in hydra.\nUsing standard PUT method, change \"token_endpoint_auth_method\": \"client_secret_post\"\nI think this issue can now be considered closed. ",
    "tangkhaiphuong": "@arekkas I set up on my computer with docker installation, I close all browser, clear cache/cookie, the problem still occurs. I try another browser and issue doesn't go :(\nThere is minor log on Postgres I found:\nPostgreSQL init process complete; ready for start up.\n2018-07-12T07:14:55.854514700Z \n2018-07-12 07:14:55.860 UTC [1] LOG:  listening on IPv4 address \"0.0.0.0\", port 5432\n2018-07-12 07:14:55.861 UTC [1] LOG:  listening on IPv6 address \"::\", port 5432\n2018-07-12 07:14:55.872 UTC [1] LOG:  listening on Unix socket \"/var/run/postgresql/.s.PGSQL.5432\"\n2018-07-12 07:14:55.904 UTC [45] LOG:  database system was shut down at 2018-07-12 07:14:55 UTC\n2018-07-12 07:14:55.913 UTC [1] LOG:  database system is ready to accept connections\n2018-07-12 09:13:16.574 UTC [53] ERROR:  duplicate key value violates unique constraint \"hydra_oauth2_authentication_request_handled_pkey\"\n2018-07-12 09:13:16.574 UTC [53] DETAIL:  Key (challenge)=(525284388392497892f6a8256a9072d8) already exists.\n2018-07-12 09:13:16.574 UTC [53] STATEMENT:  INSERT INTO hydra_oauth2_authentication_request_handled (challenge, subject, remember, remember_for, error, requested_at, authenticated_at, acr, was_used) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)\n. @arekkas I think the problem comes from Docker on Windows. I remove all containers (Postgress/Hydra). Restart docker and setup step by step again then it works.\n. ",
    "Earth-43": "@aeneasr I am getting same error \nERRO[2141] An error occurred  debug=\"The CSRF value from the token does not match the CSRF value from the data store\" \ndescription=\"The request is not allowed\" \nerror=request_forbidden hint=\"You are not allowed to perform this action.\"\nI have started the oauth2 flow in two tabs simultaneously , one flow successfully completed and one is failed .hydra is running in windows with binary not with docker and it is not behind any proxy server \nversion : 1.0.0-rc.5+oryOS.10. ",
    "zikes": "Apologies, the error occurs while using the Swagger Go SDK. I mistakenly believed the SQLManager example would be a minimal case. A more appropriate example would be \nsdk, _ := hydra.NewSDK(&hydra.Configuration{\n  EndpointURL: hydraURL,\n})\nclient := &swagger.OAuth2Client{\n  ClientId: \"my-client\",\n  Name: \"My Client\",\n}\nsdk.CreateOAuth2Client(client)\nI have tested using Id rather than ClientId in the above scenario and that does work as expected.. That test case is using the client.MemoryManager, whereas the bug is in client.SQLManager.. ",
    "JamesnaW": "1.0.0-beta.6 and I already set SYSTEM_SECRET. Its the same as I using in version 0.11.10.\nSYSTEM_SECRET=\"ASLDHIUqwhdfsjc2345ute0rgQ!R@WTQ(shgj\". Thanks for quick reply. I have try to use beta.4 and it fail too. So I try DELETE FROM hydra_jwk WHERE sid='hydra.openid.id-token' and it work. By the way is it will has affect to the system?. Thanks @arekkas .. @arekkas you already PR right?. Ok thanks, I just see the comment.. Im not sure is #1225  related to this issue. ",
    "robotlovesyou": "The root cause of this is that in registerRoutes in cmd/server/handler.go the injectConsentManager is called before the store is created by injectFositeStore. Changing the code so that those functions are called the other way around fixes the issue and the tests still pass. I would submit a patch but I don't have time to work out how to write a meaningful test right now. Sorry!. ",
    "gsagula": "Please, Let me know if you need help with this integration.. I think that's a great starting point. We can span all the rest later. Please feel free to assign it to me if you are happy with the suggestion.. I'm glad you mentioned it. I was about starting this work. Sorry for the delay on that btw. Yes, good point! Let me take a look into that.. @aaslamin has kindly offered to take care of this issue. I'm handing the work to him.\ncc @arekkas. ",
    "aaslamin": "I should have a PR up soon to get some early feedback @aeneasr. I will include instructions for how to run everything locally.\nExample trace created hitting POST /clients:\n\n. Update:\n\u2139\ufe0f Added some basic unit tests around setting up the tracer. Update:\n\u2022 Added unit tests for the tracing middleware to ensure the expected number of spans are being created along with the desired tags.. @aeneasr I am ready for another review! \ud83d\ude4f . @aeneasr addressed latest feedback re: error handling \ud83d\udc4d . Unit tests pass for me locally. . Yes, it definitely does. Would you like me to do this in this PR @aeneasr?\nEdit: I'll just jump on it!. \u2139\ufe0f Update: \n\u2022 Client manager and handler have been updated to pass along context\n\u2022 All consumers have also been updated accordingly\nRemaining handlers (will check these on Monday):\n\u2022\u00a0Consent\n\u2022 JWK. @aeneasr at this point I am a bit concerned that the PR is getting too large \ud83d\ude2c. Could you review this as is and let me know if you want me to proceed with the Consent and JWK handlers in here or as a separate PR. \nThey can be \ud83d\ude80'ed independently.. @aeneasr it's all good, i'll do it all in this PR.\nTackling through this now - I shall keep posting updates here as I make progress or find out new things that need doing.\n. Update: \n\u2022 JWK manager and all of it's clients have been updated \u2705 \nComing up:\n\u2022 Updating the JWTStrategy to pass along context where appropriate - (See comment below)\n\u2022 Updating Consent Manager (this is a biggie \ud83d\ude28) \u2705 \n. @aeneasr I believe the JWTStrategy interface in fosite needs to be updated to take in a context.\nWhy?\nThe implementation of this interface in Hydra makes calls to the db to fetch the latest keys:\n\nhttps://github.com/ory/hydra/blob/master/jwk/jwt_strategy.go#L75\nhttps://github.com/ory/hydra/blob/master/jwk/jwt_strategy.go#L83\nhttps://github.com/ory/hydra/blob/master/jwk/jwt_strategy.go#L91\n\nThe oauth handler consumes the Generate method.\nCould you please confirm if this makes sense before I proceed with the plumbing? If so I believe this would require:\n\na PR in fosite to update the interface and any tests that break as a result\na PR in Hydra to pull in the new version of fosite and update the JWTStrategy interface as necessary. Update:\n\nConsent Manager and all of its clients have been updated to pass along context. All that is left is the JWT Strategy which I have outlined a plan for above. If that makes sense, I can jump on it.\n@aeneasr ready for another review \ud83d\ude4f . Hey @aeneasr if you are thinking of API versioning for the admin endpoints, does this mean you intend on keeping older versions of an endpoint (marked as deprecated or something) for a few releases before completely removing them?\nThis would make upgrading more palatable as folks will be able to be leverage the latest & greatest Hydra and upgrade their API consumption slowly (if they had built some kind of API portal/admin interface, etc.).. The CI failure is the result of a flaky test\nEdit: triggering re-build\nEdit: the CI gods are happy once again!  \ud83c\udf89 \nCircle CI be like:\n. > Stupid flaky tests. I'll fix this one, really annoying. Was it the pseudo-random one again? Tracked as #1053\nNo, it was another one. I didn't capture the output from the CI before triggering a re-build (via a force push), my bad \ud83d\ude2d . Sounds good @aeneasr \ud83d\udcaf \nPrior to working on documentation (and a development environment guide for contributors), we still need to instrument our db calls as they are going to be the most valuable spans we can provide. Most of the work for the context propagation has already been done \ud83e\udd1e, so I just need to figure out the cleanest way of instrumenting the db calls.\nI feel after that would be a suitable time to start publicizing our efforts and getting people to use it. I am hoping the community can provide us with more feedback once it is in the wild about any missing spans which should be trivial to add.\nWe're almost there \ud83d\ude04 . @michalwojciechowski in the tests that you are running, are you hitting the token endpoint heavily? If so, what you are seeing is expected given how expensive bcrypt is. The token endpoint is the most costly endpoint and must be protected via rate-limiting given how CPU intensive it is.\nYou can adjust the work factor for bcrypt via an environment variable to see if that makes a difference. . I can raise a PR tomorrow @aeneasr. I wasn't sure if you had a naming convention for indices. Please let me know if you would like me to update the names.\nTo test the migrations, I applied them on both postgres and mysql using the supplied docker-compose setup. . @aeneasr maybe I am being stupid \ud83d\ude05, but I am not sure how adding the test to https://github.com/ory/hydra/blob/master/client/manager_0_sql_migrations_test.go will work? That test seems to be specifically around migrations related to the client manager?. Thanks for the feedback! Will address in the morning \ud83d\ude4c . #### Update:\n\u2022 Changed index to a unique index on the request_id column\n\u2022 Investigating failing tests as a result of that change now. #### Update\n\u2022 Fixed broken test - there was a test that was inserting multiple records with the same request_id. The system works \ud83d\ude0e . #### Update:\n\u2022 Added new test coverage to cover the unique constraints placed on the request_id column in the hydra_oauth2_access & hydra_oauth2_refresh tables.\nThis PR is ready for potentially a final review @aeneasr  \ud83e\udd1d . Nice! Thanks for fixing these @aeneasr! \n\ud83d\udcaf \ud83c\udfc6 . docker-compose.yml file you can use to test out this branch - https://gist.github.com/aaslamin/b7fdbb06d09cbf1015d30f2a111a0b36. Thanks for the feedback @aeneasr @someone1, looking into them now \ud83d\ude4c . \u2139\ufe0fUpdate:\n-  Added configuration for setting up distributed tracing to provided docker-compose. related: https://github.com/ory/docs/pull/65\n@aeneasr . Thank you!. Test failure(s) in CI unrelated to change.. Working on a PR for this right now. Before reviewing/merging this PR, please check to see if go 1.11.4 has been released as we can go straight to that and avoid the regression. At the time of this message, the docker image for 1.11.4 has yet not been published . My colleague, @michaelwagler, has decided to take this issue on for his first contribution to Hydra \ud83c\udfc6 . I think this may be a bug/oversight @aeneasr - the response only returns the expiration of the access token:\nhttps://github.com/ory/hydra/blob/master/oauth2/handler.go#L435\nInstead I believe it should examine the token type and return the correct expiry based on the type of the token being introspected.\nYea?. Feel free to assign this to me unless @pr0head wants to take it on.\nI will dish out some time for this in coming weeks.. Thanks for taking this on @pr0head! \ud83c\udfc6  . FYI: https://github.com/golang/go/wiki/Modules#why-does-installing-a-tool-via-go-get-fail-with-error-cannot-find-main-module. With the current setup, the opentracing.GlobalTracer() will be set to the NoopTracer if one does not provide any tracing config (or if they provide invalid tracing config) when booting up Hydra. It is disabled by default.\nI use the IsLoaded helper later to determine as to whether to append the tracer middleware.\n. Exactly - or if you provide garbage config (I log the error incase they want to debug). Good point, will update.. Good idea \ud83d\udc4d, will update. @aeneasr should it be a fatal error in this case if someone misconfigured their tracing config? \nThe rest of Hydra can still run so I am not sure if we want to bring down everything. Maybe logging at error level is more appropriate?\n. I am sure that this is the negroni response writer because of https://github.com/urfave/negroni/blob/master/negroni.go#L96\nhttps://github.com/urfave/negroni/blob/master/response_writer.go#L31\nWith that said, to be extra defensive, I capture the boolean returned from the type assertion to verify if the ResponseWriter is indeed of type negroini.ResponseWriter. All of this is so we can add the tag in our span for the http status that was returned: \n\n. Sounds good! We can include instructions for how to bring up tracing somewhere in the docs?\n~I will comment out the tracing specific config and remove the jaeger container from the docker-compose file.~\nUpdate: actually on second thought, I guess I should remove all of the config for tracing from the default docker-compose file.. Added unit tests to cover above.. At this point, a tracer would have been configured so it would not be possible for it to have an error - recall how we now exit if an error has occurred on boot up.\nAlthough, for safety, incase future refactoring happens by other contributors, it's probably best to do error checking. Will add it in \ud83d\udc4d . I am going to update the Hasher unit tests in Fosite to use test tables as well. I think they are much easier to read and follow Go best practices - https://github.com/golang/go/wiki/TableDrivenTests\n@aeneasr thoughts?. Note: the second return value here is a context object built around the returned span which you can use for further propagation. Not applicable in this case as we have no need to propagate further hence the _.. Done \u2705 . This was a bug I believe. I fixed it since I was knee deep in the code at this point already.\nm.db.Exec is not going to be done in the TX created above.. Same here \ud83d\udc1b . @aeneasr I had to keep them separate because I only wanted to create an index on the requested_at column on the hydra_oauth2_access table. \nI guess I could add a semicolon and add another statement to migration 5?. Nice catch \ud83d\udc4d . Re: OmitSQLArgsFromTracingSpans I was following some of the concerns that Google identified in Dapper for not releasing potentially sensitive details in traces. Perhaps in some organizations, the engineers that have access to look at traces should not be able to view such data for compliance/privacy reasons.\nI can remove this config until we get a feature request.. Sweet, that sounds good to me. I will leave this option on by default and remove the config and if people ask for it be included, they can create an issue so we can re-introduce it.. Should be exported now. I was completely unaware of the plugin use case. You're correct. Exported options should be generic enough for any type of connector, not just SQL (e.g. redis, mongo, etc).\nWill be addressed in subsequent commit.. Please take another looksy now  \ud83d\udc40 . I could have done something like os.Getenv(\"OMIT_SQL_ARGS_FROM_TRACES\") to give advanced users the option, but I felt dirty doing it? \u00af_(\u30c4)_/\u00af. \ud83d\udc40 . Yes, that was completely my bad. I was not aware of the plugin use case. It makes sense to me \ud83d\udc4d . > I also noticed that this is kinda duplicated with here. I also noticed that hasher might be null if tracing is disabled. So instead this should use the bcrypt from the config (here)\nIf Hasher is nil it gets set by fosite when Compose is called https://github.com/ory/fosite/blob/master/compose/compose.go#L56\n. \ud83d\udc4d on DRYing up the check to see if tracing has been loaded. I will clean that up.. What about the lifetime of authorization codes and id_tokens? Perhaps fetching the expiry can be extracted to a non-exported helper somewhere within this package or file.. Also, it is possible for refresh tokens to not expire if the value of the lifespan has been set to -1. In that case, perhaps it is best to omit the expiry field in the response payload.\n@aeneasr thoughts?. Ah right! \ud83d\udcaf . ",
    "ayZagen": "Thanks for the fast response. I followed 5 minute tutorial https://www.ory.sh/docs/guides/latest/hydra/1-tutorial/ used docker. Ok, thanks. . \nI checked postgres and they seem active. But when I try to introspect it returns false.. Alright my bad. I was sending in refresh_token field. It should be token instead. Could you improve response output ? :). Taken from Auth0 \n\nAllowed Origins are URLs that will be allowed to make requests from JavaScript to Auth0 API (typically used with CORS). By default, all your callback URLs will be allowed. This field allows you to enter other origins if you need to. You can specify multiple valid URLs by comma-separating them or one by line, and also use wildcards at the subdomain level (e.g.: https://*.contoso.com). Notice that querystrings and hash information are not taking into account when validating these URLs.. Also /oauth2/auth ?. \n",
    "geekyme": "@arekkas, I did a little digging. It seems like the Session does not get initialized with the extra fields I specified. \nSee https://github.com/ory/hydra/blob/00fd517fbf92289c447e3b106f267fbb35d2ee88/oauth2/handler.go#L483\nIf I add the line commented, I get my \"azp\" field:\n```\nif accessRequest.GetGrantTypes().Exact(\"client_credentials\") {\n        session.Subject = accessRequest.GetClient().GetID()\n        for _, scope := range accessRequest.GetRequestedScopes() {\n            if h.ScopeStrategy(accessRequest.GetClient().GetScopes(), scope) {\n                accessRequest.GrantScope(scope)\n            }\n        }\n    }\n// session.Claims.Extra[\"azp\"] = \"auth-code-client\"\n\naccessResponse, err := h.OAuth2.NewAccessResponse(ctx, accessRequest)\nif err != nil {\n    pkg.LogError(err, h.L)\n    h.OAuth2.WriteAccessError(w, accessRequest, err)\n    return\n}\n\nh.OAuth2.WriteAccessResponse(w, accessRequest, accessResponse)\n\n``. Solved the issue.acceptConsentRequest` works, it just needs to be invoked only after the user is authenticated.. ",
    "damian0o": "Both solutions sound good to me. \nAs your note stated if first option is used and hydra does not know anything about underlying algorithm, some functionalities could break within hydra. On the other hand if second option will be follow services that are receiving sub sent by a client to fulfill some requirements (without access token) could not match resource owner. It would be great to have option to get \"external subject\" from hydra in that case.. I believe additional flow is that when 3rd party developer is calling token introspection endpoint and get full access token. Subjects between access token and id token should match.. Well played card with mentioning Google, Microsoft others. I believe some of our clients can also turn into 3rd party resources providers and in this case we would like to preserve this pairwise algorithm in access tokens as well. . Just a side note on Access token subject field. How this should work with OAUTH2_ACCESS_TOKEN_STRATEGY=jwt.. ",
    "kingjan1999": "Thanks for your help @arekkas !  I hope I have implemented all your proposals. \nWhen Swagger generated the SDK, some files (concerning JSONWebKeys) appeared for unknown reasons, which I have now simply commited.. Thanks for your naming suggestion @arekkas ! I've implemented it accordingly.\n. Thanks, I adapted it. However, I was a bit unsure in consent/manager_memory.go as FindPreviouslyGrantedConsentRequests depends now on the newly created FindPreviouslyGrantedConsentRequestsByUser (which requires a limit and offset now) and does not support limit and offset. As you'll see, I've used a little workaround that I'm personally not 100% satisfied with.. I called it HandledConsentRequestResponse now but other suggestions are very welcome . Thanks for your help and your feedback! I have gladly implemented your suggestions. \nHowever, I'm a little unsure at this point and need your help: Does db.Select really return an ErrNoRows error if no rows could be found? According to my understanding of SQLX / Go SQL documentation, this does not happen here. I have not been able to force such behaviour in my experiments.\nOr did I misunderstand and the manager should generate and return an sqlcon.ErrNoRows?. ",
    "liguobao": "also use web api .. Thanks.. https://openid.net/specs/openid-connect-core-1_0.html\nSubject Identifier Types\nA Subject Identifier is a locally unique and never reassigned identifier within the Issuer for the End-User, which is intended to be consumed by the Client. Two Subject Identifier types are defined by this specification:\npublic\nThis provides the same sub (subject) value to all Clients. It is the default if the provider has no subject_types_supported element in its discovery document.\npairwise\nThis provides a different sub value to each Client, so as not to enable Clients to correlate the End-User's activities without permission.\nThe OpenID Provider's Discovery document SHOULD list its supported Subject Identifier types in the subject_types_supported element. If there is more than one type listed in the array, the Client MAY elect to provide its preferred identifier type using the subject_type parameter during Registration.\nsorry!!!\nThat is our bug...\n. > Please use the provided issue template to describe your problem.\nSo sorry,I  had updated.. run  docker image : v1.0.0-beta.9\n~ docker run --rm -it \\\n  -e HYDRA_ADMIN_URL=https://xxxx.org \\\n  --network hydraguide \\\n  oryd/hydra:v1.0.0-beta.9 \\\n  clients create --skip-tls-verify \\\n    --id lemon-novel-test \\\n    --secret babelchain.org \\\n    --grant-types authorization_code,refresh_token,client_credentials,implicit \\\n    --response-types token,code,id_token \\\n    --scope userinfo \\\n    --callbacks http://127.0.0.1:5000/v1/user/token\nYou should not provide secrets using command line flags. The secret might leak to bash history and similar systems.\nCommand failed because calling \"POST https://xxxx.org/clients\" resulted in error \"invalid character 'p' after top-level value\" occurred.\n404 page not found\nPS:https://xxxx.org is our domain.\n@aeneasr \n. on beta.7 ,hydra log like that:\n```\ntime=\"2018-09-15T16:36:40Z\" level=info msg=\"started handling request\" method=GET remote=114.91.68.137 request=/clients request_id=90a119bd266a8af73e9b1cc352b0752c\ntime=\"2018-09-15T16:36:40Z\" level=info msg=\"completed handling request\" measure#https://mydomain.com\n latency=2505374 method=GET remote=114.91.68.137 request=/clients request_id=90a119bd266a8af73e9b1cc352b0752c status=200 text_status=OK took=2.505374ms\non beta.9 ,hydra log like that:\ntime=\"2018-09-15T16:33:54Z\" level=info msg=\"started handling request\" method=GET remote=114.91.68.137 request=/clients request_id=953081257a40206153e800d04a53da94\ntime=\"2018-09-15T16:33:54Z\" level=info msg=\"completed handling request\" measure#https://mydomain.com .latency=102896 method=GET remote=114.91.68.137 request=/clients request_id=953081257a40206153e800d04a53da94 status=404 text_status=\"Not Found\" took=\"102.896\u00b5s\"\n```\n@aeneasr \n. ",
    "mindcrash": "After re-checking my consent code I noticed this crash was triggered because I forgot to add the following two fields to the consent payload: remember and remember_for \nMaybe some payload validation (and logging) could come in handy here since it is quite easy to overlook things like this in custom endpoints.... ",
    "Multiply": "For the migration part, would it hurt too badly to add a new column with the right settings, move data from old to new column, remove old column and rename new column to old's name?. So far it only seems to be hydra_client.\nAnother problem I stumbled into is changing primary keys, which doesn't seem to be supported by Cockroach either. (unless I'm doing something entirely wrong)\nSo my current take on the issue, would be to create new tables and migrate data over, which seems silly.\nEssentially what I had to do, to make Hydra work with Cockroach, was to run the migrations on a normal Postgres installation, and then export the structure. Not ideal, but good enough for my use-case for now.. Migrations causing trouble:\n1. All columns with the ALTER COLUMN ... SET NOT NULL as mentioned in the ticket.\n2. All migrations dropping primary keys. Example. Another problem I had while trying to figure out which migrations failed, is the fact that it's not telling me which line/query in the migration that failed, so I had to narrow it down myself.\nExample right now:\nApplying `jwk` SQL migrations...\nApplied 0 `jwk` SQL migrations.\nApplying `client` SQL migrations...\nApplied 0 `client` SQL migrations.\nApplying `consent` SQL migrations...\nAn error occurred while running the migrations: could not apply consent SQL migrations: Could not migrate sql schema, applied 0 migrations: pq: no data source matches prefix: hydra_oauth2_consent_request handling 7\nI can easily find the file, but since it's a migration on the 'large' side, it's a bit tough to easily spot the failing one. I basically just run each query one by one, and fix it manually.. ",
    "AmosMoses82": "Unsubscribe\nOn Tue, Aug 21, 2018, 4:13 AM hackerman notifications@github.com wrote:\n\nMerged #993 https://github.com/ory/hydra/pull/993 into master.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory/hydra/pull/993#event-1799639269, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AofxNq-RkbBt7r07X_9oBqsWiZcc5xgFks5uS89GgaJpZM4WFW_z\n.\n. Unsubscribe\n\nOn Tue, Aug 21, 2018, 4:57 AM hackerman notifications@github.com wrote:\n\nThis patch introduces environment variable CORS_ENABLED which toggles\nCORS.\nCloses #996 https://github.com/ory/hydra/issues/996\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/ory/hydra/pull/997\nCommit Summary\n\ncmd: Disable CORS by default\n\nFile Changes\n\nM UPGRADE.md https://github.com/ory/hydra/pull/997/files#diff-0\n   (7)\nM cmd/serve.go https://github.com/ory/hydra/pull/997/files#diff-1\n   (5)\nM cmd/server/handler.go\n   https://github.com/ory/hydra/pull/997/files#diff-2 (8)\n\nPatch Links:\n\nhttps://github.com/ory/hydra/pull/997.patch\nhttps://github.com/ory/hydra/pull/997.diff\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory/hydra/pull/997, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AofxNlIqIE07OrehtC-swqD1Hhd6grIiks5uS9mGgaJpZM4WFd0i\n.\n. Unsubscribe\n\nOn Tue, Aug 21, 2018, 5:13 AM hackerman notifications@github.com wrote:\n\nMerged #997 https://github.com/ory/hydra/pull/997 into master.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/ory/hydra/pull/997#event-1799766570, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AofxNiVT_t8QSQyOWJqGY89tLTFRhBSHks5uS902gaJpZM4WFd0i\n.\n. \n",
    "ionutzp": "\n{\"code\":400,\"details\":{},\"error\":\"Can not remember consent because no user interaction was required\",\"level\":\"error\",\"msg\":\"An error occurred while handling a request\",\"reason\":\"\",\"request-id\":\"\",\"status\":\"\",\"time\":\"2018-08-22T09:15:35Z\",\"trace\":\"Stack trace: \\ngithub.com/ory/hydra/consent.(*Handler).AcceptConsentRequest\\n\\t/go/src/github.com/ory/hydra/consent/handler.go:501\\ngithub.com/ory/hydra/consent.(*Handler).AcceptConsentRequest-fm\\n\\t/go/src/github.com/ory/hydra/consent/handler.go:71\\ngithub.com/ory/hydra/vendor/github.com/julienschmidt/httprouter.(*Router).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/julienschmidt/httprouter/router.go:299\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.Wrap.func1\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:46\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:29\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(middleware).ServeHTTP-fm\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1947\\ngithub.com/ory/hydra/cmd/server.(*Handler).rejectInsecureRequests\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:260\\ngithub.com/ory/hydra/cmd/server.(*Handler).(github.com/ory/hydra/cmd/server.rejectInsecureRequests)-fm\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:58\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:29\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(middleware).ServeHTTP-fm\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\ngithub.com/ory/hydra/vendor/github.com/ory/metrics-middleware.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/ory/metrics-middleware/middleware.go:160\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(middleware).ServeHTTP-fm\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(middleware).ServeHTTP-fm\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\ngithub.com/ory/hydra/vendor/github.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/meatballhat/negroni-logrus/middleware.go:136\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:38\\ngithub.com/ory/hydra/vendor/github.com/urfave/negroni.(*Negroni).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/urfave/negroni/negroni.go:96\\ngithub.com/ory/hydra/vendor/github.com/rs/cors.(*Cors).Handler.func1\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/rs/cors/cors.go:200\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1947\\ngithub.com/ory/hydra/vendor/github.com/gorilla/context.ClearHandler.func1\\n\\t/go/src/github.com/ory/hydra/vendor/github.com/gorilla/context/context.go:141\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1947\\nnet/http.serverHandler.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:2694\\nnet/http.(*conn).serve\\n\\t/usr/local/go/src/net/http/server.go:1830\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:2361\",\"writer\":\"JSON\"}\n\n. @arekkas can help with more details, if you let me know what's needed. this is indeed the consent part of the flow. should i understand this is expected behaviour as I never show the consent screen to the user?. ",
    "struhtanov": "I have very similar problem. I'm working on multi-tenant application, where tenant is retrieved from host. Similar to slack, where you go to a.slack.com or b.slack.com, depending on your organization. \nI want to have one url to give to my oauth clients. Let it be auth.slack.com (in our slack example). When client is redirected to login-consent app(by hydra), I show screen to select organization. After that I redirect user to login screen, then to consent screen. In the end I want to put information about  organization that user has entered into oauth token(using session field of acceptConsentRequest params). When client is making requests to my server with oauth token in headers, I can check if organizations in the token and in the url match.\nSimilar to @MOZGIII I need somehow store information between login and consent requests. In my case I want to store information about selected organization. As everything is going through hydra by redirects, I have no other options than to store some kind of session in my login-consent app. This looks error-prone to me, because hydra has session (using cookies) and it could be possible that I'm redirected to consent screen without visiting login screen(because there is already session in hydra). So there will be no place to get organization info.. ",
    "singlewind": "@k-lepa You actually can implement your own logic. \n1. Your app's logout redirect to OP with return_url as query params, eg  /signout where you record the return_url from query into session\n2. /signout redirect the user the /oauth2/sessions/login/revoke \n3. Then OP will redirect to OAUTH_LOGOUT_REDIRECT_URL which can be, eg /signout-redirect fetch the return_url from the session. And redirect the user back where they come from.. thanks @aeneasr that was the issue. In the documentation, it says body is not required. So I thought it was optional. . ",
    "condemil": "Yes MySQL.. Then hydra can redirect to URL that can be a part of login, consent or other provider. And that provider render page according to other OAuth2 implementations that support oob.. I see that other OAuth2 providers, such as Azure, also have it. The use-case for that is when you don't have a web-server, like a CLI utility that shares a link to start OAuth2 flow and wants you to paste back the code once flow is over.. I propose to consider pagination tokens instead of offsets, this way you prevent the case when some data will be added/deleted between requests and will be returned twice or some rows will be skipped in between. The idea is that you specify amount of items you want in request and you receive token back. By using this token you will get next amount of items. Here is more info: https://use-the-index-luke.com/no-offset. Here is more info how to do that with SQL: https://use-the-index-luke.com/blog/2013-07/pagination-done-the-postgresql-way. I think the indexed creation date is the way to go. Normally you expect the data paginated from newest to oldest (or alphabetically) in such cases.. I see error in Hydra logs, I expect errors to be something that should be fixed in code or do Hydra app use some different approach?\nlevel=error msg=\"An error occurred while handling a request\" code=409. Another problem I am facing is that when I receive the 409 error the redirect_to is not available in the response and I cannot redirect user back properly. Imagine the situation when the first request was handled and connection broke before consent provider received the response and consent provider is re-sending it once again.. Actually I just checked and see the same error for PUT /oauth2/auth/requests/consent/{id}/accept call too.. The better way is to add another DNS argument (to be consistent with postgres), get it from query as you get other options in here and add it to SQLConnection struct. Later when we do mysql connection we can check that path to tls certificate is specified in SQLConnection.. ?tlsCAPath or some other parameter on DSN sound better than my initial idea with config / environment.. The only other idea I have how to make it better without hardcoded check here against mysql is to file another feature request on mysql driver to support it tough DNS the way postgres driver does it.. Created issue https://github.com/go-sql-driver/mysql/issues/926. ",
    "apognu": "I just saw that this is actually handled in fosite, do you want me to open the issue there instead? Any configuration would be done on hydra, but handling would happen in fosite.. And this was apparently discussed already in ory/fosite#273 as wontfix.\nShould have searched better beforehand.. I understand that letting a way to do insecure thing is globally a bad thing, because people tend to choose the easy way over the secure one. If that's your stance, I totally understand it and will not argue this further.\nFor my particular situation, we do not mirror the public production domain. We have subdomain, unresolvable from the Internet, routable only from private networks and VPNs, that is used for development machines.\n.localhost is a bit annoying because it does resolve to the current machine (as I said, through nss-myhostname, enabled on systemd hosts), and does not even allow a Hydra instance in a Docker container.\nIf the way of not allowing whitelisting domains is kept, I'll continue using a patched fork that adds my internal domain to fosite for my development host, that is not a big deal. :). ",
    "pierredavidbelanger": "TL;DR\nI think that if you can manage to not use a the vendored object here, it will be sufficient for swagger to not pull the uppercase version of JSONWebKey and JSONWebKeySet into the final doc.\nExplication\nWhat I can see right now, is that definitions for JsonWebKey and JsonWebKeySet ends up being written two times in the api.swagger.json file.\nHere is the stripped down api.swagger.json file that shows the double definitions:\njson\n{\n  ...\n  \"definitions\": {\n    \"JSONWebKey\": {\n      \"type\": \"object\",\n      \"title\": \"JSONWebKey represents a public or private key in JWK format.\",\n      \"properties\": {...},\n      \"x-go-package\": \"github.com/ory/hydra/vendor/gopkg.in/square/go-jose.v2\"\n    },\n    \"JSONWebKeySet\": {\n      \"type\": \"object\",\n      \"title\": \"JSONWebKeySet represents a JWK Set object.\",\n      \"properties\": {...},\n      \"x-go-package\": \"github.com/ory/hydra/vendor/gopkg.in/square/go-jose.v2\"\n    },\n    ...\n    \"jsonWebKey\": {\n      \"type\": \"object\",\n      \"properties\": {...},\n      \"x-go-name\": \"swaggerJSONWebKey\",\n      \"x-go-package\": \"github.com/ory/hydra/jwk\"\n    },\n    \"jsonWebKeySet\": {\n      \"type\": \"object\",\n      \"properties\": {...},\n      \"x-go-name\": \"swaggerJSONWebKeySet\",\n      \"x-go-package\": \"github.com/ory/hydra/jwk\"\n    }\n    ...\n  }\n}\nYou can see that the uppercase versions came from the vendored objects, JSONWebKey for example.\nThe only place that the uppercase versions are referenced (then pulled in to the doc), is in the oAuth2Client's jwks property, this property pulls on #/definitions/JSONWebKeySet, then in turn JSONWebKeySet pulls on #/definitions/JSONWebKey.\nHere the stripped down api.swagger.json file that shows the oAuth2Client definition:\njson\n{\n  ...\n  \"definitions\": {\n    ...\n    \"oAuth2Client\": {\n      \"type\": \"object\",\n      \"title\": \"Client represents an OAuth 2.0 Client.\",\n      \"properties\": {\n        ...\n        \"jwks\": {\n          \"$ref\": \"#/definitions/JSONWebKeySet\"\n        },\n        ...\n      },\n      \"x-go-name\": \"Client\",\n      \"x-go-package\": \"github.com/ory/hydra/client\"\n    },\n    ...\n  }\n}. Now, having said that, it will not be an easy task to get rid of jose.JSONWebKeySet, since it is not the same as your own swaggerJSONWebKeySet. Also jose.JSONWebKeySet end up marshalled into the DB, so changing the model here will break current installations.\nI guess, it may be a bug in swagger-codegen, I see no reason why it was not able to correctly create all those model objects JSONWebKeySet AND JsonWebKeySet ... alter all they ARE different objects. I am sorry, I was thinking out loud here, but no, it is not a bug in swagger-codegen. Because java is supporting OSes with case insensitive file systems, new File(\"JSONWebKey.java\") and new File(\"JsonWebKey.java\") point to the same file (the first that was created)..\nSo the explication here is simple: swagger-codegen first generate the model file for the class JSONWebKey in a file named JSONWebKey.java, then it encounters JsonWebKey, so it opens the same old JSONWebKey.java file and generate the JsonWebKey model class in it.\nThat explains this:\nJSONWebKey.java: class JsonWebKey is public, should be declared in a file named JsonWebKey.java\nSo, I guess it is not a good idea to have two model objects with the same name (case insensitive).\n. Ok I am starting to understand, you created type swaggerJSONWebKey, to be able to expose all properties of the private jose type rawJSONWebKey in the doc... \nI guess there is a way to tell go-swagger that Client's JSONWebKeys property must be exposed in the doc as a swaggerJSONWebKeySet and not as a jose.JSONWebKeySet, but keeping the internal representation/implementation.. I think I have something.\nI guess it will need a little cleanup before merging (I dont like having two public struct in jwk/doc.go for exemple), obviously only if you want to merge :)\nI pushed the fix in two commits, one that touches the code only (to help you find what I have modified), then an other one for everything that changed after running ./scripts/run-gensdk.sh.\nEssentially this fix remove *jose.JSONWebKeySet from the Client (and thus from the surface API, cleaning at the same time a BUNCH of unused model objects), replacing it with your swaggerJSONWebKeySet that I renamed JSONWebKeySet.\nEvery other code changes I made are there to make this happen.\nafter this patch, go test ./... is all ok ( if you also apply #1039 ;) ). You are absolutely right. I will try this.. Oh, it's harder than I thought, client.Client is referenced else where in the API, here in the consent.AuthenticationRequest and here in the consent. ConsentRequest. \nThose two structs are not for the doc purpose only .. they are use in places hard to refactor, for example here in consent.GetConsentRequest.\nI will think about this a little.. The PR #1045 contains an alternative (more hacky) way of dealing with the same problem.\nI will let you decide which one you prefer, or I you want to fix this at all :). @laibulle this is also exactly what I have done to workaround the problem. This is why I know the fix works.\n@aeneasr If this file is indeed generated, maybe I should check with swagger-codegen then, we dont want to manually edit a file now and have the same problem appear later when we finally use the generated version.. @lanshipeng I am sorry, I did not contributed to this project lately, you should try the chat and see with them if you should open a new issue for this.\nBut , as a workaround, try to not let go choose the version for you (it will maybe not choose the right one), and target a specific version instead, one that we know this bug is fixed in.\nfor example, this is the last commit in the master branch:\ngo get github.com/ory/hydra@55654c084cc24a49d333e62773295cbf8bf5b31d\n. indeed, i am sorry, hahaha, since i am using go mod, I forgot about dep,\n. I do not know why I had to manually edit Gopkg.toml, but it should work now.\nI really am a newbe with Go dep. Yeah, this function is weird and not trivial now, but I used the fact that your - now named - jwk.JSONWebKeySet is JSON 100% compatible with jose.JSONWebKeySet.. ",
    "retendo": "Pros for 2:\nThere seems to be a security concern for returning plain arrays in responses:\nhttps://haacked.com/archive/2008/11/20/anatomy-of-a-subtle-json-vulnerability.aspx/\nAlso, the response would be better suited for future extension, for example if you would want to return a totalCount or something like that next to the actual data.. ",
    "fredbi": "you can't: for swagger, it is a different endpoint.. Since you are generating spec it should be possible to include this endpoint as pure comment or in an add-on seed spec containing this description.. IMHO, this request for enhancement unduly puts additional burden on hydra's configuration tasks.\nIt is rather straightforward to configure Postgres and avoid any disclosure of credentials in the connection string by using password files. You are then free to use K8 secrets (or in my case, just docker secrets) to store these files.\nExample:\nyaml\n    - PGPASSFILE=/var/certs/pgpass\n    - DATABASE_URL=postgres://dbuser@postgres:5432/accesscontroldb?sslmode=verify-full&sslrootcert=/var/certs/ca.crt \nAnd your pgpass file contains the credentials for your user.. > The entrypoint in the dockerfile does not simply support variable substitution. We plan look at overriding the entrypoint to do the variable substitution in the container, but it will be a hack and take us further from the default use cases.\nYes you can substitute variables at build time: docker build -e DB_USER=dbuser ... \nAnd in Dockerfile:\nENV DATABASE_URL=postgres://$DB_USER:$DB_PASSWORD@$DB_HOST:$DB_PORT. Same as TLS certs, keys: all crypto material should be configurable either directly from env or from ext file (which may then be a secret on your favorite container platform).\nThis offers more possibilities to build configuration.\nFinally, even if platforms are getting better, it is still a lot of env hack to do for every such parameter.. BTW, the CI failure is really strange, given the limited scope of my changes.\nI suspect another failure:\n```\n!/bin/bash -eo pipefail\n./scripts/test-sdk.sh\n/go/src/github.com/ory/hydra/cmd/cli/handler_migrate.go:26:2: could not import github.com/ory/x/cmdx (cannot find package \"github.com/ory/x/cmdx\" in any of:\n    /go/src/github.com/ory/hydra/vendor/github.com/ory/x/cmdx (vendor tree)\n    /usr/local/go/src/github.com/ory/x/cmdx (from $GOROOT)\n    /go/src/github.com/ory/x/cmdx (from $GOPATH))\ncouldn't load packages due to errors: github.com/ory/hydra/cmd/cli\nExited with code 1\n``` . The difference with #1079  is that in this particular issue, Postgres provides everything to build your\nconfiguration the way you want. In this PR, I am addressing the same kind of issue, but for hydra-specific parameters.. Here is my source of inspiration. This is a Postgres init script for docker: \nhttps://github.com/docker-library/postgres/blob/eed67ed0f33435bffd1e78d27b389e0492d30599/9.6/docker-entrypoint.sh#L7\n. Yes undocumented exports cause go lint to croak. But this is not just about go lint: there is a whole lotta static analysis tools.\nTry it out: github.com/golangci/golangci-l\u00eent\n. Here is a bot. It relies on webhooks as well.\nhttps://github.com/Falconerd/discord-bot-github/blob/develop-es6/README.md\n. Github services are deprecated not webhooks\nhttps://developer.github.com/v3/guides/replacing-github-services/. ",
    "laibulle": "As a temporary workaround, I am running\nsudo sed -i -e 's/\"github.com\\/go-resty\\/resty\"/resty \"gopkg.in\\/resty.v1\"/g' \\\n    `$GOPATH/pkg/mod/github.com/ory/hydra@v1.0.0-beta.9/sdk/go/hydra/swagger/api_client.go`. ",
    "lanshipeng": "@pierredavidbelanger , need your help.  error on loading resty package with go modules. when  i use go mod tidy or go build . it's not succeed. \n\n. ",
    "k-lepa": "Oh, sorry about the duplicate issue! I'll try to fix the problem.. Done. Ok. I'll add it. ",
    "bretep": "@pvsr Did you figure this out?\nI'm having the same issue.\nRequest:\n```\"/oauth2/auth?client_id=a-ffl-dev\nredirect_uri=https://app.example.com/silent_renew\nresponse_type=token id_token\nscope=offline openid paffl\nstate=18734f28648749ae9288695a60288ec5\nnonce=1c5e8178aa1845399e61ec0adc8e4f81\nprompt=none\nid_token_hint=eyJhbGciOiJSUzI1NiIsImtpZCI6InB1YmxpYzpjNmM0MDc3ZC01ZDU4LTRlNjItYTExNi0xNW.......KUR0RlMG-ans-dI-XRljAe6RTIadjW6YwPsH8lIxdpgclFXt4t450RbuOry-wftFEOXfRpz60JJ1VFtWQiKPMiNEndsaUiFYMS9tQ496vwpIkST7CZ0pMGs2HudevANdMa___nHfPQHD4HWZjy60gKwXn3bxl1buRXaIyPh5YGbzjBuB4k5pmFr5Yg3UU3onsDKa2tbJclCLXieLAiGPLTXDsP6hxWPRjVm86_spNDuGOv-u_2j8Bkq5VHmWTVLgDFrkFTxGq0HnKTBPMzq0skG1nVGr_6KYL9gloO-C_UG320zuXiD8FO8HShEQypq02i4\nacr_values=oauth2\"\nHydra error:\nINFO[1026] started handling request                      method=GET remote= request=/.well-known/openid-configuration\nINFO[1026] completed handling request                    measure#https://account.example.com.latency=199562 method=GET remote= request=/.well-known/openid-configuration status=200 text_status=OK took=\"199.562\u00b5s\"\nINFO[1026] started handling request                      method=GET remote= request=\"/oauth2/auth?client_id=a-ffl-dev&redirect_uri=https%3A%2F%2Fapp.example.com%2Fsilent_renew&response_type=token%20id_token&scope=offline%20openid%20paffl&state=18734f28648749ae9288695a\n60288ec5&nonce=1c5e8178aa1845399e61ec0adc8e4f81&prompt=none&id_token_hint=eyJhbGciOiJSUzI1NiIsImtpZCI6In.......OXfRpz60JJ1VFtWQiKPMiNEndsaUiFYMS9tQ496vwpIkST7CZ0pMGs2HudevANdMa___nHfPQHD4HWZjy60gKwXn3bxl1buRXaIyPh5YGbzjBuB4k5pmFr5Yg3UU3onsDKa2tbJclCLXieLAi\nGPLTXDsP6hxWPRjVm86_spNDuGOv-u_2j8Bkq5VHmWTVLgDFrkFTxGq0HnKTBPMzq0skG1nVGr_6KYL9gloO-C_UG320zuXiD8FO8HShEQypq02i4&acr_values=oauth2\"\nERRO[1026] An error occurred                             debug=\"Prompt \\\"none\\\" was requested, but no existing login session was found\" description=\"The Authorization Server requires End-User authentication\" error=login_required\nDEBU[1026] Stack trace:\ngithub.com/ory/hydra/consent.(DefaultStrategy).forwardAuthenticationRequest\n        /go/src/github.com/ory/hydra/consent/strategy_default.go:192\ngithub.com/ory/hydra/consent.(DefaultStrategy).requestAuthentication\n        /go/src/github.com/ory/hydra/consent/strategy_default.go:118\ngithub.com/ory/hydra/consent.(DefaultStrategy).HandleOAuth2AuthorizationRequest\n        /go/src/github.com/ory/hydra/consent/strategy_default.go:602\ngithub.com/ory/hydra/oauth2.(Handler).AuthHandler\n        /go/src/github.com/ory/hydra/oauth2/handler.go:610\ngithub.com/ory/hydra/oauth2.(Handler).AuthHandler-fm\n        /go/src/github.com/ory/hydra/oauth2/handler.go:173\ngithub.com/julienschmidt/httprouter.(Router).ServeHTTP\n        /go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/router.go:334\ngithub.com/urfave/negroni.Wrap.func1\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\ngithub.com/urfave/negroni.middleware.ServeHTTP\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\nnet/http.HandlerFunc.ServeHTTP\n        /usr/local/go/src/net/http/server.go:1964\ngithub.com/ory/hydra/cmd/server.(Handler).RejectInsecureRequests\n        /go/src/github.com/ory/hydra/cmd/server/handler.go:297\ngithub.com/ory/hydra/cmd/server.(Handler).RejectInsecureRequests-fm\n        /go/src/github.com/ory/hydra/cmd/server/handler.go:62\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\ngithub.com/urfave/negroni.middleware.ServeHTTP\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/ory/hydra/metrics/prometheus.(MetricsManager).ServeHTTP\n        /go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\ngithub.com/urfave/negroni.middleware.ServeHTTP\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/meatballhat/negroni-logrus.(Middleware).ServeHTTP\n        /go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\ngithub.com/urfave/negroni.middleware.ServeHTTP\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/urfave/negroni.(Negroni).ServeHTTP\n        /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\ngithub.com/gorilla/context.ClearHandler.func1\n        /go/pkg/mod/github.com/gorilla/context@v1.1.1/context.go:141\nnet/http.HandlerFunc.ServeHTTP\n        /usr/local/go/src/net/http/server.go:1964\nnet/http.serverHandler.ServeHTTP\n        /usr/local/go/src/net/http/server.go:2741\nnet/http.(conn).serve\n        /usr/local/go/src/net/http/server.go:1847\nruntime.goexit\n        /usr/local/go/src/runtime/asm_amd64.s:1333. My client config:\n{\n    \"client_id\": \"a-ffl-dev\",\n    \"grant_types\": [\n        \"refresh_token\",\n        \"authorization_code\",\n        \"implicit\",\n        \"password\"\n    ],\n    \"jwks\": {},\n    \"redirect_uris\": [\n        \"https://app.example.com/callback\",\n        \"https://app.example.com/silent_renew\"\n    ],\n    \"response_types\": [\n        \"token\",\n        \"code\",\n        \"id_token\",\n        \"token id_token\"\n    ],\n    \"scope\": \"profile openid offline offline_access paffl\",\n    \"subject_type\": \"public\",\n    \"token_endpoint_auth_method\": \"client_secret_basic\",\n    \"userinfo_signed_response_alg\": \"none\"\n}\n``. This would be nice to have since the oidc-client-js I use also discoversrevocation_endpoint`. Will hardcode for now.. I\u2019ll work on it today. . ",
    "slax0rr": "I do not have enough in-depth knowledge in your SDK yet, but I guess I would simply add the PublicPath to the configuration, with a new NewOAuth2Api method that would accept either a whole Configuration instance or both BasePath and PublicPath, and then let each func decide which path to use for the call.\nEdit: if this would be acceptable, I can prepare a PR.. ",
    "atbentley": "Ah ok then, it might be helpful to update the help message for CORS_ALLOWED_ORIGINS. It might be a bit misleading until this is implemented:\n- CORS_ALLOWED_ORIGINS: A list of origins (comma separated values) a cross-domain request can be executed from.\n    If the special * value is present in the list, all origins will be allowed. An origin may contain a wildcard (*)\n    to replace 0 or more characters (i.e.: http://*.domain.com). Usage of wildcards implies a small performance penality.\n    Only one wildcard can be used per origin. The default value is *.\n    Example: CORS_ALLOWED_ORIGINS=http://*.domain.com,http://*.domain2.com. ",
    "keirl": "\nYou could just store the database url in the secret. That's one less secret and env var you have to configure.\n\nYes, you could, but that couples your username, password, and host.  In many production and environments, credential management is done separately from deployment management.  It seems like the best practice would be to optionally allow them as separate env variables.. @aeneasr The entrypoint in the dockerfile does not simply support variable substitution.  We plan look at overriding the entrypoint to do the variable substitution in the container, but it will be a hack and take us further from the default use cases.. > > The entrypoint in the dockerfile does not simply support variable substitution. We plan look at overriding the entrypoint to do the variable substitution in the container, but it will be a hack and take us further from the default use cases.\n\nYes you can substitute variables at build time: docker build -e DB_USER=dbuser ...\nAnd in Dockerfile:\n\n\nThe entrypoint in the dockerfile does not simply support variable substitution. We plan look at overriding the entrypoint to do the variable substitution in the container, but it will be a hack and take us further from the default use cases.\n\nYes you can substitute variables at build time: docker build -e DB_USER=dbuser ...\nAnd in Dockerfile:\nENV DATABASE_URL=postgres://$DB_USER:$DB_PASSWORD@$DB_HOST:$DB_PORT\n\nThis substitution is at build time.  I need it at runtime passed in through Kubernetes.  I don't want the credentials baked into the image.. > IMHO, this request for enhancement unduly puts additional burden on hydra's configuration tasks.\n\nI disagree based on looking at the source code.  But I'm not the maintainer.\nIt is rather straightforward to configure Postgres and avoid any disclosure of credentials in the connection string by using password files. You are then free to use K8 secrets (or in my case, just docker secrets) to store these files.\nExample:\nyaml\n    - PGPASSFILE=/var/certs/pgpass\n    - DATABASE_URL=postgres://dbuser@postgres:5432/accesscontroldb?sslmode=verify-full&sslrootcert=/var/certs/ca.crt\nAnd your pgpass file contains the credentials for your user.\n\nThis may be a viable option in Kubernetes, we'll try it out.\nThe other option of storing the DATABASE_URL should also work.. > > I disagree based on looking at the source code. But I'm not the maintainer.\n\nIt's not about the changes in the code, those are easily done within a few lines. But we already have a bunch of environment variables that configure things, I really want to avoid adding more and more stuff to accommodate every use case. The solution for the task you're facing is either env substitution (see my previous comment) or storing the DATABASE_URL as a whole or using TLS. All of those are viable solutions and I agree that we should have better integration with kubernetes. But we shouldn't add more and more config to the already (kinda) bloated config, instead we should opt to reduce it.\n\nWe will make one of these work. And thank you for the productive conversation.  I still think the suggestion would work better with Kubernetes.  Unfortunately environment variables are the way these things are done, so it will be a challenge to reduce them.. ",
    "dudedad": "\nWe have this which uses RSA private/public keypairs. I don't think x.509 client certificates are something that can be added in reasonable time.\n\nYes.   This is our go-to plan at this point.  \nAt some point, mTLS would be cool, and I might do a PR to implement (after discussions).. IMHO... there should be the capability to set a exp on a refresh token.\nOkta does it nicely where you can define the  AT to expire after \"X\" seconds/minutes/days and the RT to expire after \"Z\" s/m/d but to automatically expire the RT earlier  if there has not been any activity (of the AT) in \"Y\" s/m/d. ",
    "tomberek": "Where is this? What support or assistance is needed?. ",
    "niwenhao": "Thank you for the advice.. ",
    "pcdummy": "+1\n. I see an use case for it.\nLet's say an user of Hydra created a SPA where the SPA Logs the user in, the refresh_token will then be saved in the browsers local store, as a security measure i want to enforce re-authorization with the Authorization Server periodically.\nI know Hydra also saves data in a cookie, but this is another case.\nHope you see my reasoning,\nRen\u00e9. ",
    "Flaque": "^ Solid point. Sorry about that. Just going to close this and fade away. . Whoops sorry about that. I was having a stressful / generally bad day. Sorry for being not helpful around this; it's really not like me. \ud83d\ude15\nThe version I was running was v1.0.0-beta.9, but that error message came from a previous version (not sure which).\nThough, I don't think that error message is particularly bad. My concern was as a new user reading through the docs, you're told that the entry point for the application is /oauth2/auth. \nIn the docs, it lists out the flow and then says:\n\nThe flow itself works as follows:\n1. The OAuth 2.0 Client initiates an Authorize Code, Hybrid, or Implicit flow. The user's user agent is redirect to http://hydra/oauth2/auth?client_id=...&....\n\nSo that leads me as a newb to believe I need to create this URL, so I'll go to look at the REST docs for /oauth2/auth (https://www.ory.sh/docs/api/hydra/). But on that doc, it just says that it's not documented because we shouldn't build our own implementation. Instead we should use a client. And that's fine, that makes sense.\nSo I'll go type in oauth2 client javascript into google, and click on the first thing that pops up. But if that client library doesn't immediately work as expected, there's no solid recourse for debugging except greping through the code of hydra, the client library and the OAuth2 spec. And that kind of defeats the point of the docs. \ud83d\ude15\n. ",
    "jcxplorer": "Thanks for looking at this so quickly, and for the pointers!\nI've rebased, and also added the LoginChallenge assertion to compareConsentRequest. However, adding an assertion for LoginSessionID causes a bunch of test failures. I know that a login session ID is only provided in certain cases, but unsure of how to add it to the test. Any idea how to proceed?. Found the issue. There were two struct fields with the same tag of db:\"login_session_id\" in sqlAuthenticationRequest and sqlConsentRequest. Since sqlConsentRequest embeds sqlAuthenticationRequest it ended up having both fields with the same tag. When mapping from the DB to the struct, it was only setting the value to sqlAuthenticationRequest.SessionID (first struct field it finds with tag).\nWhat I've done was rename sqlAuthenticationRequest.SessionID to sqlAuthenticationRequest.LoginSessionID and remove sqlConsentRequest.LoginSessionID. I think this reflects the database structure better.\nI've also added the missing test for session ID in the authentication request and also fixed that converter.. And thank you @aeneasr for handling this so quickly. This feature makes Hydra really flexible for us. :+1:. You're right, it's not in the spec. Unfortunately it seems like some other providers have started adding it to their GET /.well-known/openid-configuration endpoints:\n\nhttps://developer.okta.com/docs/api/resources/oidc#well-knownopenid-configuration\nhttps://accounts.google.com/.well-known/openid-configuration\n\nI guess this is why AppAuth has also decided to start looking for it.\nHowever, you're correct that it's not in the spec, so it makes sense to not implement it. It's easy enough to workaround from our apps.\nFeel free to close if you believe Hydra shouldn't implement it, and thanks for the awesome work and incredibly fast replies! \ud83d\ude4c . ",
    "zyclonite": "i did exactly the commands from the docker section in the hydra-login-consent-node repo...\ni decode the tokens at jwt.io, so the claims were definitely not there\nbefore that i had used simply the api, running serv in a container, with my own impl were i actually discovered this. you are right, i did only mark the lines for the getConsent\ni redid the test from scratch (uncomment the claims for getConsent and acceptConsent), correct container version (no own build, your hub version)\ninteresting is: if i use scope openid i get the id token with the set claim but the access token does not get the claim (like in any other scope configuration)\nthis proves at least that i did change the consent code in the right place\nbut it still does not explain why the access token is always empty. @aeneasr i did set session.access_token and it does NOT work, i can record you a screencast if that proves it ;). this was the missing piece! when i set the strategy to jwt it works, thank you. let me verify both scenarios.... both work now, so nothing to fix on your side\nthe only hurdle i had, the introspect endpoint is on the admin port which i did not map to the public on my reverse proxy.... but how should a third party app be able to get the subject of that token it requested?\nin my case it is anyway all internal... and not \"really\" public but it would be good to know who logged in.... would it make sense to support basic auth for that endpoint? client_id and client_secret are used by most public providers as it seems\nhttps://tools.ietf.org/html/rfc7662#section-2.1. ok, makes sense\nthank you for the clarification!. ",
    "JiaLiPassion": "@aeneasr, thanks! Oh, I see, so we need to handle the wellknow endpoints with the helper cors too. Got it.\nBut it looks like the Wellknown route in oauth2 already been handled by the cors helper you provided. https://github.com/ory/hydra/blob/master/cmd/server/handler_oauth2_factory.go#L226-L227\nI will debug into it.. @aeneasr, got it, I will run go get ./... and go test. @aeneasr, now the test failed because e2e test.\nunknown shorthand flag: 'C' in -CgL8JuF6_g6g_tRCd9fRr9xGXhR5jPLD0zP5TyBU2k.NEtVUqesrmtvIXr15_6jPMOrzKAiYqs2rEA4DGeQc-0\nWill continue to debug.. ",
    "dlienko": "Yes, looks like FindPreviouslyGrantedConsentRequests is the problem.\nBut how we can use any limit? What if the given consent we are looking for is 51st?. We do send remember=true for the mentioned user (in fact, for this particular client).\nI'm not that familiar with the Hydra code and golang itself, but I'm just thinking: FindPreviouslyGrantedConsentRequests is used ultimately for matchScopes. Would it be enough to store the unique sets of ever consented scopes per user rather than the whole history?. Just to be sure: only the recent consent counts? Or any ever given consent? :). RIght.\nCould you please also describe the difference between FindPreviouslyGrantedConsentRequests and FindPreviouslyGrantedConsentRequestsByUser?\nAny reason why the latter one has LIMIT ? OFFSET ? and not the former?. Thanks for the explanation and fast responses :). ",
    "sredxny": "@aeneasr hello, is there a way to find the version? I can tell you that I installed it like 11-12 months ago. @aeneasr correct, it's not the last version. I entered to the container to check the version but I get:\n/go/src/github.com/ory/hydra # hydra version\nVersion:    dev-master\nGit Hash:   undefined\nBuild Time: 2018-10-31 21:00:38.848791968 +0000 UTC\n. @aeneasr ok, thank you very much. Then I think that I will proceed with the migration to the updated version. I will maintain informed if this happen again. Again, thanks!. ",
    "sawadashota": "Thank you for review! I will try anothor issue.. OK,\nthis PR solves following issue\nSet old system secret as environment variable ROTATED_SYSTEM_SECRET however hydra doesn't validate access token created before rotated system secret  \nI found 2 causes\n\nPackage cmd doesn't load environment variable ROTATED_SYSTEM_SECRET\nNo codes inject HMACStrategy.RotatedGlobalSecrets rotated system secret\n\nTherefore I created this PR!. Sorry for my poor description...\nI will write more detail or create issue first next time!. Thank you for your review.\nI will try fix it after I learn where's docs generate SDK with your pointing out.. To pass circleci, we should fix 2 problems.\n\nupgrade crypto package at go.sum\npoint where to install gometalinter expressly\n\nSo that I close this PR and add same commit for #1271 . Yes, it works but I think this is not better in the sense of HTTPS_ALLOW_TERMINATION_FROM option.\nThis option seems to mean \"set TLS termination proxy's IP then trust it and check X-Forwarded-Proto header\".\nTherefore, I think it better to ensure TLS termination proxy's IP.\nhttps://github.com/ory/hydra/blob/aa6ab26908ea5fc856c67c2650c2124d3331e184/cmd/serve.go#L186-L190\nIn addition my case, using AWS, TLS termination proxy and proxy are different subnet.\nWhen I set HTTPS_ALLOW_TERMINATION_FROM to the IP of nginx, it works but I want to change to ALB IP.\nClient -> ALB (TLS termination) -> nginx on ECS -> hydra on ECS. OK! I will try it :). Sorry, this was meaningless test.... Oops... I fixed!. Exactly! Have added :). ",
    "pixelblend": "Postgres 10.5. Logs:\nauth_1      | time=\"2018-12-06T14:08:34Z\" level=info msg=\"started handling request\" method=GET remote=\"172.22.0.1:43768\" request=/oauth2/auth/sessions/consent/018ae5e7-cdd2-4218-9c6b-a253541bb150\nauth_1      | time=\"2018-12-06T14:08:34Z\" level=info msg=\"completed handling request\" measure#http://localhost:9000/.latency=12635900 method=GET remote=\"172.22.0.1:43768\" request=/oauth2/auth/sessions/consent/018ae5e7-cdd2-4218-9c6b-a253541bb150 status=200 text_status=OK took=12.6359ms\nJSON export of table:\n```json\n[\n  {\n    \"challenge\": \"bcfaf290bc7d4fdebbbaff174f145b67\",\n    \"verifier\": \"6bb42f66b19a46a586c1209a0b51a82d\",\n    \"client_id\": \"XXX\",\n    \"subject\": \"018ae5e7-cdd2-4218-9c6b-a253541bb150\",\n    \"request_url\": \"http://localhost:9000/oauth2/auth?brand=codeclub&client_id=union-dev&redirect_uri=http%3A%2F%2Flocalhost%3A3333%2Fcb&response_type=code&scope=openid+email+profile+force-consent&state=b63450d7ffab76cf61da52ba2f1a626224a54d7f5dd9e03a\",\n    \"skip\": false,\n    \"requested_scope\": \"openid|email|profile|force-consent\",\n    \"csrf\": \"7ecca06501184ed78a4405711e2f487d\",\n    \"authenticated_at\": \"2018-12-06 14:35:41.26738\",\n    \"requested_at\": \"2018-12-06 14:35:37.320656\",\n    \"oidc_context\": \"{}\",\n    \"forced_subject_identifier\": \"\",\n    \"login_session_id\": null,\n    \"login_challenge\": \"7559294f0dc145f4accc6dfd9741c616\",\n    \"requested_at_audience\": \"\",\n    \"acr\": \"\"\n  }\n]\n```. Database is Postgres 10.5. > Cool, that is really helpful. Could you do me another favor and give the output of:\n\nand print the (redacted) output here?\n\njson\n[\n  {\n    \"granted_scope\": \"openid|email|profile|force-consent\",\n    \"remember\": false,\n    \"remember_for\": 3600,\n    \"error\": \"{}\",\n    \"session_access_token\": \"{}\",\n    \"session_id_token\": \"{\\\"email\\\":\\\"jane.doe@example.com\\\",\\\"email_verified\\\":true,\\\"name\\\":\\\"Jane Doe\\\",\\\"nickname\\\":\\\"Jane\\\",\\\"picture\\\":\\\"http://localhost:3000/profile/018ae5e7-cdd2-4218-9c6b-a253541bb150/avatar\\\",\\\"profile\\\":\\\"http://localhost:3000/profile\\\",\\\"uuid\\\":\\\"018ae5e7-cdd2-4218-9c6b-a253541bb150\\\"}\",\n    \"was_used\": true,\n    \"granted_at_audience\": \"\",\n    \"challenge\": \"bcfaf290bc7d4fdebbbaff174f145b67\",\n    \"verifier\": \"6bb42f66b19a46a586c1209a0b51a82d\",\n    \"client_id\": \"XXX\",\n    \"subject\": \"018ae5e7-cdd2-4218-9c6b-a253541bb150\",\n    \"request_url\": \"http://localhost:9000/oauth2/auth?brand=XXX&client_id=SSS&redirect_uri=http%3A%2F%2Flocalhost%3A3333%2Fcb&response_type=code&scope=openid+email+profile+force-consent&state=b63450d7ffab76cf61da52ba2f1a626224a54d7f5dd9e03a\",\n    \"skip\": false,\n    \"requested_scope\": \"openid|email|profile|force-consent\",\n    \"csrf\": \"7ecca06501184ed78a4405711e2f487d\",\n    \"authenticated_at\": \"2018-12-06 14:35:41.26738\",\n    \"requested_at\": \"2018-12-06 14:35:37.320656\",\n    \"oidc_context\": \"{}\",\n    \"forced_subject_identifier\": \"\",\n    \"login_session_id\": null,\n    \"login_challenge\": \"7559294f0dc145f4accc6dfd9741c616\",\n    \"requested_at_audience\": \"\",\n    \"acr\": \"\"\n  }\n]\n. Thanks, I'll give that a try.. ",
    "davidfergo": "Running rc2 miggrate database we received this:\nApplying jwk SQL migrations...\nApplied 1 jwk SQL migrations.\nApplying client SQL migrations...\nApplied 3 client SQL migrations.\nApplying consent SQL migrations...\nAn error occurred while running the migrations: could not apply consent SQL migrations: Could not migrate sql schema, applied 3 migrations: pq: se ha denegado el permiso para cambiar la opci\u00f3n \u00absession_replication_role\u00bb handling 7\n(Last part translated: permission denied to change option \"session_replication_role\"). Thanks!\nWe 've solved it making hydra db user SUPERUSER.\nAfter migrating, we've removed the permission.\nDoes it worth reflect this circumstance in the docs? . ",
    "paxswill": "Closing, resolved by #1195 . ",
    "RikiyaFujii": "please review.. Because I thought there was no uniformity in the code.. ",
    "Takuto88": "I'll be happy to fix this right up for you but unfortunatly, I could not find the composer.json file in any of Ory's github repositories.. Duh :man_facepalming: . A PR is comming right up :). Thank you for your awesomely quick response. I am really impressed :+1: . ",
    "ngrigoriev": "My lack of familiarity with Go makes a bit more difficult, but I have not given up yet :). I have narrowed it down to https://github.com/ory/fosite/issues/345. ",
    "RazerM": "Sure, then it should be documented, which contradicts the part I already quoted:\n\nOne-off admin processes should be run in an identical environment as the regular long-running processes of the app. They run against a release, using the same codebase and config\n\nIf it was documented I would have the hydra database and tables owned by a superuser and granted permissions to the Hydra user from the start.. What about using ALTER TABLE ... DISABLE/ENABLE TRIGGER ALL instead?. Never mind, that requires superuser privileges too:\n\nThis requires superuser privilege if any of the triggers are internally generated constraint triggers such as those that are used to implement foreign key constraints or deferrable uniqueness and exclusion constraints.. My general feeling is that the migration should not require superuser \u2014 it's nice to know that Hydra's migration can only affect the database it has permissions for.\n\nI would tend to think that the performance of verifying the foreign keys doesn't matter too much for a one-time migration. But of course you'll have more information than me about that \ud83d\ude04. ",
    "chrissachs": "I ran into the same issue. My hydra database is a postgresql database at google cloud, and the user can't be granted the SUPERUSER privilege: https://cloud.google.com/sql/docs/postgres/users  . yes, for me it failed because of the session_replication_role:\nhydra migrate sql -e\nApplying `jwk` SQL migrations...\nApplied 0 `jwk` SQL migrations.\nApplying `client` SQL migrations...\nApplied 0 `client` SQL migrations.\nApplying `consent` SQL migrations...\nAn error occurred while running the migrations: could not apply consent SQL migrations: Could not migrate sql schema, applied 0 migrations: pq: permission denied to set parameter \"session_replication_role\" handling 7\nand no worries - thank you for the quick response . ",
    "tback": "related to #1185 . I assume you meant #1209 ?. ",
    "pluservice": "From what I read in the documentation client creation rest api does not allow to specify custom claims or subject ..\nFor my experience it is very useful to be able to configure a service account to be associated with the client \n. Ok sorry here is the new feature request\nhttps://github.com/ory/hydra/issues/1221. This feature is related to the \"Client Credential flow\" , it is not a new flow. \nIt's  about the subject returned inside the access token.\nIn keycloak the access token returned after a \"Client Credential Flow\" login contains the subject of a built-in service account and its claims and scopes can be customized at will. \nGoogle allows creation of custom service accounts.\n. What is missing is the possibility to set claims.\nThat is to set the properties of service accounts which are used only in the context \nof a \"Client Credential flow\".\n. I mean public or private claims ie name,  email\nregistered public claims  https://www.iana.org/assignments/jwt/jwt.xhtml\nOIDC\nhttps://openid.net/specs/openid-connect-core-1_0.html#IANA\n. Access token may contain some claims , I put links to explain what claims are, I did not mean to\nput identity claims on the access token, \nkeycloak allow to set custom claims in the access token response for a \"Client Credential Flow\"\nI find it a useful thing , \nAccording to oAuth\nThe token may denote an identifier used to retrieve the authorization\n information or may self-contain the authorization information in a\n verifiable manner (i.e., a token string consisting of some data and a\n signature).\n. By the way, given the access token obtained with the \"Client Credential Flow\"  ,\nKeycloak OAuth 2.0 UserInfo Endpoint allows to retrieve user information (Claims \nabout the authenticated End-User) that in this case is the service account , the claims\nreturned by the userinfo invocation are the ones supplied during client creation.\nThe useful thing of this feature is that the application layer does not have to worry about\nhow the token it is handling has been obtained (which flow) because they are all the same\nand contain the same claims set and can be used the same way (ie invoke the standard  userinfo \nendpoint) .\nFor each claim Keycloak allows to choose whether to include it in ID Token , Access Token or User Info, see the screenshot\n\n. I'm glad that we managed to understand each other, the proposal wanted to go in the direction of enriching hydra with advanced features but I respect your decisions. ",
    "jklmjklmjklmjklm": "I encountered an error when I use that syntax. I am using docker to run hydra.\nsh: -c: line 0: syntax error near unexpected token `('\nsh: -c: line 0: `docker run -it --rm --network hydra oryd/hydra:v1.0.0-rc.6_oryOS.10 migrate sql mysql://root:secret@tcp(mysqld:3306)/mysql?parseTime=true'. ",
    "ermik": "It is both. I assume that HTTPS_ALLOW_TERMINATION_FROM would be enough to achieve a secure environment as long as the Envoy issue with XFP headers is fixed. But past that, there are questions about what affordances could be made when the internal environment assumes TLS termination (such as allowing http:// redirect to resources that are not called \"localhost\"). I will try to get my thoughts together and stub an additional section to hydra Production use document in the docs that will cover this.. ",
    "popey456963": "Apologies, it appears I was using the 'latest' tag, which was last updated 13 months ago.  You are indeed correct that the latest images are much smaller.. ",
    "es-lab": "@aeneasr The last 3 weeks it was just integration of hydra in an existing system. I started with version oryd/hydra:v1.0.0-rc.2_oryOS.9 initially, sql migration did ran successfully from the first time. \nThen came a lot of clients create/update/delete/recreate because of development/prototyping of different use-cases. \nThere was also a change to the Access Token type from the time I started. Could this change the way migrations run, and that now that it's jwt it expects some different schema/indexes?\nAlso, I still can not reproduce this on my localhost, the current issues happens on a staging (https) environment.\nI did the upgrade to oryd/hydra:v1.0.0-rc.5_oryOS.10 3 days ago, just though it may solve the issue, but it did not. SQL migrations did run successfully though.\nWhat I did not try to do is a clean install of hydra db. I will try this one and hope to come back with more useful info.. I'm using postgres 9.6. I've just done a clean db installation. Here are the outputs:\nMigration output\nApplying `jwk` SQL migrations...\nApplied 4 `jwk` SQL migrations.\nApplying `client` SQL migrations...\nApplied 12 `client` SQL migrations.\nApplying `consent` SQL migrations...\nApplied 7 `consent` SQL migrations.\nApplying `oauth2` SQL migrations...\nApplied 9 `oauth2` SQL migrations.\nMigration successful! Applied a total of 32 SQL migrations.\nMigration successful!\nFirst deploy after migration output\n```\nThank you for using ORY Hydra v1.0.0-rc.5+oryOS.10!\nTake security seriously and subscribe to the ORY Security Newsletter. Stay on top of new patches and security insights.                                                                                                \n\n\nSubscribe now: http://eepurl.com/di390P <<\ntime=\"2018-12-17T09:13:10Z\" level=info msg=\"Setting up tracing middleware\"\ntime=\"2018-12-17T09:13:10Z\" level=info msg=\"No tracer configured - skipping tracing setup\"\ntime=\"2018-12-17T09:13:10Z\" level=info msg=\"Connecting with postgres://:@iam_oauth_db:5432/hydra?sslmode=disable\"\ntime=\"2018-12-17T09:13:10Z\" level=info msg=\"Connected to SQL!\"\ntime=\"2018-12-17T09:13:10Z\" level=info msg=\"JSON Web Key Set hydra.openid.id-token does not exist yet, generating new key pair...\"\ntime=\"2018-12-17T09:13:11Z\" level=info msg=\"JSON Web Key Set hydra.jwt.access-token does not exist yet, generating new key pair...\"\ntime=\"2018-12-17T09:13:13Z\" level=info msg=\"Enabled CORS\"\ntime=\"2018-12-17T09:13:13Z\" level=warning msg=\"Could not parse login and consent request lifespan value (). Defaulting to 15m\"\ntime=\"2018-12-17T09:13:13Z\" level=info msg=\"Enabled CORS\"\ntime=\"2018-12-17T09:13:13Z\" level=info msg=\"Setting up Prometheus middleware\"\ntime=\"2018-12-17T09:13:13Z\" level=info msg=\"JSON Web Key Set hydra.https-tls does not exist yet, generating new key pair...\"\ntime=\"2018-12-17T09:13:21Z\" level=info msg=\"Enabled CORS\"\ntime=\"2018-12-17T09:13:21Z\" level=info msg=\"Setting up http server on :4445\"\ntime=\"2018-12-17T09:13:21Z\" level=warning msg=\"HTTPS disabled. Never do this in production.\"\ntime=\"2018-12-17T09:13:21Z\" level=info msg=\"Setting up http server on :4444\"\ntime=\"2018-12-17T09:13:21Z\" level=warning msg=\"HTTPS disabled. Never do this in production.\"\n```\n\n\nCommand used to create clients\nhydra clients create --id client_id_here --grant-types authorization_code,refresh_token --response-types code --endpoint http://localhost:4445 --scope offline,oauth_auto_consent --callbacks https://client_host_here/oauth/redirect,http://another_client_host_here/oauth/redirect --token-endpoint-auth-method none --audience some_audience_here\nIt works now, but as I said, I don't know how to reproduce and don't know if/when it will reappear now.. @aeneasr I've reproduced it!! Finally!! \nSteps to reproduce:\n1) Create 2 clients (public clients (SPAs) in my case):\n    - clientX\n    - clientY\n2) Go to clientX page, and it will redirect you to hydra/oauth2/auth?client_id=clientX&grant_type=code&...\n3) Hydra will redirect to login, a login page show up and you login, here the login request in hydra is added into the database without a reference to login session id, as no session existed in the browser before\n4) The user logins and the login challenge is accepted with remember true and a remember for duration, and then is redirected to hydra and then to the consent provider\n5) The user arrives on the consent provider and the consent request is accepted automatically with remember true (as these are first party apps), to note here that the consent is also added into the database without the reference to login session id\n6) Now the user is redirected back to the client with the authorization code and everything is fine\n7) Now go to clientY page, you will be redirected on hydra/oauth2/auth?client_id=clientY&grant_type=code&...\n8) Hydra will redirect on login, but now the login request has skip=true, and it gets accepted automatically, here the login challenge is added to the database with a reference to the login session id\n9) Then the user is redirected by hydra to the consent provider and the consent request is accepted automatically with remember true (as these are first party apps), to note here that the consent is added into the database with the reference to login session id\n10) Now the user is redirected back to the client with the authorization code and everything is fine\n11) Now when the user logs out: here the user is redirected to hydra/oauth2/auth/sessions/login/revoke to clean the hydra session from the browser, the login session is removed from the database, and with it also disappears the login request that had referenced the login session, now the interesting part is that the consent that had referenced the login session id is not deleted, but the column with login challenge is NULL as its login challenge was deleted.\n12) The user tries to login on clientY again\n13) the login request is accepted, but, when redirecting to hydra the database query fails because the login_challenge is NULL and it can not scan a NULL value form postgres.\nNow this user can never authorize the clientY again. It gets redirected back to the client with /oauth/redirect?error=error&error_description=The+error+is+unrecognizable. \nIf you delete the consent for the user/clientY from the table the client will be authorized successfully and it will work fine.. @aeneasr I think there are some other ways to get to the issue, but I've found these way to get to it consistently, I've also noticed that this does not happen if in the database already exists a consent for the user/client, it somehow does not query the one with the NULL login_challenge and it does not fail.. @aeneasr It works! Thank you!\nI'll stay with the image built & pushed into my repo for now. Will this be released with the RC6 or the 1.0.0?. ",
    "sum2000": "Yes, I figured that part. But when we provide public hydra URL, this error is due to JSON parsing. I guess the method looks for JSON in the response body but gets 404 code instead. A more helpful error message can be something like \"You are providing public URL for an Admin Command\". ",
    "cisco90": "ok perfect, I just update hydra from version 0.11.12 to v1.0.0-rc.5_oryOS.10, previously I didn't notice this error, as you know, something change on postgres connection?. Yes, I guess the problem may be the connection between containers went in idle status and needs to be recreated. I will working on it.\nThanks. ",
    "michaelwagler": "Yup \ud83d\udc4d. @aeneasr  \ud83d\udc40when you get a chance. @aeneasr sounds good. I just added a whole bunch of tests, let me know if you have suggestions.\nThere's a lot of repetition so I wrote helpers that take the methods being tested as parameters. I think it mostly works, but there are a couple things that are a bit ugly:\n-For the Access token and Refresh token tests, I call doTestCommit and do doTestRollback twice each, to account for them having both a revoke and delete method\n-The OpenIdConnectSession tests couldn't use the helper functions, since GetOpenIDConnectSession has a different signature than all the other getter methods.. ",
    "jshearer": "Hi @aeneasr, thank you for the prompt response! I finally came up with the reproduction. The problem, it seems, is setting OAUTH2_ACCESS_TOKEN_STRATEGY=\"jwt\". When I run hydra with that environment variable set, all token introspection errors with the following stack trace:\nERRO[0001] An error occurred                             debug=\": not_found\" description=\"The request could not be authorized\" error=request_unauthorized hint=\"Check that you provided valid credentials in the right format.\"\nDEBU[0001] Stack trace:\ngithub.com/ory/fosite.(*Fosite).IntrospectToken\n    /go/pkg/mod/github.com/ory/fosite@v0.28.0/introspect.go:69\ngithub.com/ory/hydra/oauth2.(*Handler).IntrospectHandler\n    /go/src/github.com/ory/hydra/oauth2/handler.go:419\ngithub.com/ory/hydra/oauth2.(*Handler).IntrospectHandler-fm\n    /go/src/github.com/ory/hydra/oauth2/handler.go:186\ngithub.com/julienschmidt/httprouter.(*Router).ServeHTTP\n    /go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/router.go:334\ngithub.com/urfave/negroni.Wrap.func1\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\ngithub.com/urfave/negroni.middleware.ServeHTTP\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\nnet/http.HandlerFunc.ServeHTTP\n    /usr/local/go/src/net/http/server.go:1964\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests\n    /go/src/github.com/ory/hydra/cmd/server/handler.go:292\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests-fm\n    /go/src/github.com/ory/hydra/cmd/server/handler.go:62\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\ngithub.com/urfave/negroni.middleware.ServeHTTP\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\n    /go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\ngithub.com/urfave/negroni.middleware.ServeHTTP\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\n    /go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\ngithub.com/urfave/negroni.middleware.ServeHTTP\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\ngithub.com/urfave/negroni.(*Negroni).ServeHTTP\n    /go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\ngithub.com/gorilla/context.ClearHandler.func1\n    /go/pkg/mod/github.com/gorilla/context@v1.1.1/context.go:141\nnet/http.HandlerFunc.ServeHTTP\n    /usr/local/go/src/net/http/server.go:1964\nnet/http.serverHandler.ServeHTTP\n    /usr/local/go/src/net/http/server.go:2741\nnet/http.(*conn).serve\n    /usr/local/go/src/net/http/server.go:1847\nruntime.goexit\n    /usr/local/go/src/runtime/asm_amd64.s:1333\nBut without it, introspection works as expected. Does this help?. I think this is my fault. I ~didn't~ still don't quite understand Oauth, and thought that I could request a refresh token by changing my respone_type to code, so the token I was trying to introspect was an access code, not a token (does that sound right? I'm still not 100% clear on the terminology). I'm changing to request the offline scope and see if that gives me a token that I can introspect.. Yep, thanks!. ",
    "woutor": "Hi @aeneasr, thank you for your reply. I am using docker on Heroku and was able to migrate the Hydra database. However the application exits with the following log messages:\n2019-01-05T17:46:57.100170+00:00 app[web.1]: time=\"2019-01-05T17:46:57Z\" level=info msg=\"Setting up http server on :4445\"\n2019-01-05T17:46:57.104093+00:00 app[web.1]: time=\"2019-01-05T17:46:57Z\" level=info msg=\"Setting up http server on :4444\"\n2019-01-05T17:47:03.183184+00:00 heroku[web.1]: Error R10 (Boot timeout) -> Web process failed to bind to $PORT within 60 seconds of launch. Hi @pmn4, I also needed a nudge ;)\nThis is my Dockerfile:\n```Dockerfile\nFROM oryd/hydra:v1.0.0-rc.6_oryOS.10-alpine\nCOPY run.sh /\nRUN chmod a+x /run.sh\nENTRYPOINT [\"/bin/sh\"]\nCMD [\"/run.sh\"]\n```\nWith the following run.sh file\n```sh\n!/bin/sh\nexport PUBLIC_PORT=$PORT; \nhydra serve public\n```\nUse this file to build a docker image, then tag and push it to Heroku. Also set the correct environment variables. For the admin server the process is similar, with a different run.sh file. . ",
    "pmn4": "@woutor would you mind providing a sample Dockerfile? I am new to a project that uses Hyrda and I'd like to deploy on Heroku (also new to docker... the struggle is real).\n...\n(sorry to make noise on a closed issue, but maybe this will help others googling for help with hydra on heroku). thank you @woutor! \n2019-03-04T20:42:39.665958+00:00 app[web.1]: time=\"2019-03-04T20:42:39Z\" level=info msg=\"Setting up http server on :59072\"\n . @woutor did you have any trouble with TLS handshakes when you deployed to heroku?\nI can curl and see that heroku responds with an appropriate handshake\n$ curl -kvI https://secure.brewline.io/\n*   Trying 52.2.175.150...\n* TCP_NODELAY set\n* Connected to secure.brewline.io (52.2.175.150) port 443 (#0)\n* ALPN, offering h2\n* ALPN, offering http/1.1\n* Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH\n* successfully set certificate verify locations:\n*   CAfile: /etc/ssl/cert.pem\n  CApath: none\n* TLSv1.2 (OUT), TLS handshake, Client hello (1):\n* TLSv1.2 (IN), TLS handshake, Server hello (2):\n* TLSv1.2 (IN), TLS handshake, Certificate (11):\n* TLSv1.2 (IN), TLS handshake, Server key exchange (12):\n* TLSv1.2 (IN), TLS handshake, Server finished (14):\n* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):\n* TLSv1.2 (OUT), TLS change cipher, Client hello (1):\n* TLSv1.2 (OUT), TLS handshake, Finished (20):\n...\nthe secure connection from the client to heroku server looks good, however, something is lost before the request gets to the go layer:\napp[web.1]: 2019/03/19 10:06:15 http: TLS handshake error from 172.17.68.89:43517: EOF. ",
    "paulrostorp": "Fixed in rc-6, my bad.\nDuplicate of #1240 . I was able to trace the error:\ntime=\"2019-03-01T09:25:51Z\" level=debug msg=\"Stack trace: \\ngithub.com/ory/fosite/handler/oauth2.(*RefreshTokenGrantHandler).PopulateTokenEndpointResponse\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/handler/oauth2/flow_refresh.go:129\\ngithub.com/ory/fosite.(*Fosite).NewAccessResponse\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/access_response_writer.go:36\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:572\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler-fm\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:172\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/rs/cors.(*Cors).Handler.func1\\n\\t/go/pkg/mod/github.com/rs/cors@v1.6.0/cors.go:207\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/julienschmidt/httprouter.(*Router).Handler.func1\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/params_go17.go:26\\ngithub.com/julienschmidt/httprouter.(*Router).ServeHTTP\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/router.go:334\\ngithub.com/urfave/negroni.Wrap.func1\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:297\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests-fm\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:62\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\\n\\t/go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.(*Negroni).ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\\ngithub.com/gorilla/context.ClearHandler.func1\\n\\t/go/pkg/mod/github.com/gorilla/context@v1.1.1/context.go:141\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\nnet/http.serverHandler.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:2741\\nnet/http.(*conn).serve\\n\\t/usr/local/go/src/net/http/server.go:1847\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1333\". I updated the initial post. I had only removed the hostname but now you have it. Keep in mind everything works perfectly except refreshing the token in the background, which I do using \"openid-client\" node.js package (https://github.com/panva/node-openid-client) from my external authentication service through ambassador. Is there any other information you might need ?. From the code in my Authservice the only error I get is the gateway timeout error from openid-client (which I get several times, which I assume is because of automatic retries from the library). However here are the headers of the incoming request :\nHeaders:  { host: 'polluxis.me',\n  'content-length': '189',\n  'x-forwarded-for': '91.151.49.42, 127.0.0.1,10.135.139.91,10.244.92.6',\n  'x-forwarded-proto': 'https',\n  'user-agent':\n   'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36',\n  cookie:\n   'connect.sid=s%3AwwXH4FMkyLIMbZR6D8oKrDQghRSo-hHy.yDVsXzd3LK4xy8IkzXUct3J83LoYFIfIz4ORuTRXPuo; openid=eyJhbGciOiJSUzI1NiIsImtpZCI6InB1YmxpYzo3MjlkNTJiZi02M2RiLTRhZTgtYjkwMC1hMTZkZmZiMTY3ODAiLCJ0eXAiOiJKV1QifQ.eyJhdF9oYXNoIjoiN2V3dVpQa08yeVJWbGJQdF9NeVN0dyIsImF1ZCI6WyIzNjZjZWIwNC03NTg1LTRiNzktODQ1ZC1iMzUyMjAzMjc5OWUiXSwiYXV0aF90aW1lIjoxNTUxNDMyMTYwLCJleHAiOjE1NTE0Mzc4NjYsImlhdCI6MTU1MTQzNDI2NiwiaXNzIjoiaHR0cHM6Ly9vYXV0aDIucG9sbHV4aXMubWUvIiwianRpIjoiYzIyOGU5NTQtZWJlNC00MGFmLTkyOWMtOGE2MDJhMTEyMjJlIiwibm9uY2UiOiIiLCJyYXQiOjE1NTE0MzQyNjAsInN1YiI6IjVjMzVjNzdjOTc2ZjA3NDk3YTRkYmU2MiJ9.SPvlydCbNuCOLBia-pK835RZ5brCba60WRP1yQTQnGJ_2sULzqOsEOVWLX8VRfemUqxC2JdsUbxzjLt5yT77qY0g6LO6Pe3BHi5MUshdiwD2DhBrKX9gFVvxLuZfytfHNTmNRwOVkpG8vzwoOHlCUQxu36Q27AhSBxEaxnik9JxrPTPGV1rL7PJ4QGVq6m4sQWff8EKCZNXF2CipBo38eILcXrdvtXT7t8qD5Y3gj9tQ_Bnuh6zu5hbeA9ralAmWYtFGxT8vSSRXCbLcyzmBOyvHTMMTOy2gN_38Xs2zhI9oK-LRYNFO-8rI1an1MxxrtuJ3_KySq8M9Wb9wOKM0LZJpv7XKk3WcLwUjj0aWfgMSSMRP3HyMfzxuI8oUCMDQHIZHfRALFZ5HSx87egarUX0kUP_1dQ0iWHjN-iCG5kjchl0NsSLiv9zjOyhjcppcTeTlAXwaDDuse8QAE5TnGKo7O900wZuQbGnBzSKx3yviU1hJHstC9k_ZOUO2ZLlCb8wc-7YYaKjB4-6OP8kfW-NdrJMHOngXaL_47WAI0lxyYPGhK77AkKkBuTiN2gG2flj_88LgLyZ6hcr6McehM7-ubyVWwv3ZqDShPeWHuKAfhTLqbrM836QsNUwKC1v3QBJPW8XiBCIUKm_xjCxWAhV0Phh6tzFo-QXLvIAcPOI',\n  'x-envoy-internal': 'true',\n  'x-envoy-expected-rq-timeout-ms': '5000' }\nHere is a more complete log of the hydra pod, as you can see the error occurs 5 times from 5 simultaneous calls:\ntime=\"2019-03-01T09:57:47Z\" level=info msg=\"completed handling request\" measure#https://oauth2.polluxis.me/.latency=45610597 method=GET remote=\"10.244.5.5:53290\" request=/.well-known/jwks.json request_id=be0fec60-fae6-4512-b6a3-01eb6347285f status=200 text_status=OK took=45.610597ms\ntime=\"2019-03-01T09:57:47Z\" level=info msg=\"started handling request\" method=GET remote=\"10.244.92.0:54476\" request=/userinfo request_id=22fd24fa-8e37-4a72-b153-2cc632f86cf2\ntime=\"2019-03-01T09:57:47Z\" level=info msg=\"completed handling request\" measure#https://oauth2.polluxis.me/.latency=90443026 method=GET remote=\"10.244.92.0:54476\" request=/userinfo request_id=22fd24fa-8e37-4a72-b153-2cc632f86cf2 status=200 text_status=OK took=90.443026ms\ntime=\"2019-03-01T10:03:12Z\" level=info msg=\"started handling request\" method=POST remote=\"10.244.92.0:56390\" request=/oauth2/token request_id=00b257f0-a29e-444c-8410-5a5c082b204a\ntime=\"2019-03-01T10:03:12Z\" level=info msg=\"started handling request\" method=POST remote=\"10.244.5.5:55476\" request=/oauth2/token request_id=81c5bb85-8557-4683-b26d-658b873291ba\ntime=\"2019-03-01T10:03:12Z\" level=info msg=\"started handling request\" method=POST remote=\"10.244.5.6:48620\" request=/oauth2/token request_id=7ea6fd23-b30f-4459-abf6-819c2ccde087\ntime=\"2019-03-01T10:03:12Z\" level=info msg=\"started handling request\" method=POST remote=\"10.244.5.5:55480\" request=/oauth2/token request_id=bc02654b-d9ab-4d8c-aa15-8b845b97af1b\ntime=\"2019-03-01T10:03:12Z\" level=info msg=\"started handling request\" method=POST remote=\"10.244.5.5:55482\" request=/oauth2/token request_id=4272ce6c-98ce-486e-b44a-324a5c25647e\ntime=\"2019-03-01T10:03:16Z\" level=error msg=\"An error occurred\" debug=\"context canceled\" description=\"The authorization server encountered an unexpected condition that prevented it from fulfilling the request\" error=server_error\ntime=\"2019-03-01T10:03:16Z\" level=debug msg=\"Stack trace: \\ngithub.com/ory/fosite/handler/oauth2.(*RefreshTokenGrantHandler).PopulateTokenEndpointResponse\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/handler/oauth2/flow_refresh.go:129\\ngithub.com/ory/fosite.(*Fosite).NewAccessResponse\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/access_response_writer.go:36\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:572\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler-fm\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:172\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/rs/cors.(*Cors).Handler.func1\\n\\t/go/pkg/mod/github.com/rs/cors@v1.6.0/cors.go:207\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/julienschmidt/httprouter.(*Router).Handler.func1\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/params_go17.go:26\\ngithub.com/julienschmidt/httprouter.(*Router).ServeHTTP\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/router.go:334\\ngithub.com/urfave/negroni.Wrap.func1\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:297\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests-fm\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:62\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\\n\\t/go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.(*Negroni).ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\\ngithub.com/gorilla/context.ClearHandler.func1\\n\\t/go/pkg/mod/github.com/gorilla/context@v1.1.1/context.go:141\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\nnet/http.serverHandler.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:2741\\nnet/http.(*conn).serve\\n\\t/usr/local/go/src/net/http/server.go:1847\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1333\"\ntime=\"2019-03-01T10:03:16Z\" level=info msg=\"completed handling request\" measure#https://oauth2.polluxis.me/.latency=3945804798 method=POST remote=\"10.244.92.0:56390\" request=/oauth2/token request_id=00b257f0-a29e-444c-8410-5a5c082b204a status=500 text_status=\"Internal Server Error\" took=3.945804798s\ntime=\"2019-03-01T10:03:16Z\" level=error msg=\"An error occurred\" debug=\"context canceled\" description=\"The authorization server encountered an unexpected condition that prevented it from fulfilling the request\" error=server_error\ntime=\"2019-03-01T10:03:16Z\" level=debug msg=\"Stack trace: \\ngithub.com/ory/fosite/handler/oauth2.(*RefreshTokenGrantHandler).HandleTokenEndpointRequest\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/handler/oauth2/flow_refresh.go:66\\ngithub.com/ory/fosite.(*Fosite).NewAccessRequest\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/access_request_handler.go:89\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:535\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler-fm\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:172\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/rs/cors.(*Cors).Handler.func1\\n\\t/go/pkg/mod/github.com/rs/cors@v1.6.0/cors.go:207\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/julienschmidt/httprouter.(*Router).Handler.func1\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/params_go17.go:26\\ngithub.com/julienschmidt/httprouter.(*Router).ServeHTTP\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/router.go:334\\ngithub.com/urfave/negroni.Wrap.func1\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:297\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests-fm\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:62\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\\n\\t/go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.(*Negroni).ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\\ngithub.com/gorilla/context.ClearHandler.func1\\n\\t/go/pkg/mod/github.com/gorilla/context@v1.1.1/context.go:141\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\nnet/http.serverHandler.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:2741\\nnet/http.(*conn).serve\\n\\t/usr/local/go/src/net/http/server.go:1847\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1333\"\ntime=\"2019-03-01T10:03:16Z\" level=info msg=\"completed handling request\" measure#https://oauth2.polluxis.me/.latency=4435322103 method=POST remote=\"10.244.5.5:55476\" request=/oauth2/token request_id=81c5bb85-8557-4683-b26d-658b873291ba status=500 text_status=\"Internal Server Error\" took=4.435322103s\ntime=\"2019-03-01T10:03:16Z\" level=error msg=\"An error occurred\" debug=\"context canceled\" description=\"The authorization server encountered an unexpected condition that prevented it from fulfilling the request\" error=server_error\ntime=\"2019-03-01T10:03:16Z\" level=debug msg=\"Stack trace: \\ngithub.com/ory/fosite/handler/oauth2.(*RefreshTokenGrantHandler).HandleTokenEndpointRequest\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/handler/oauth2/flow_refresh.go:66\\ngithub.com/ory/fosite.(*Fosite).NewAccessRequest\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/access_request_handler.go:89\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:535\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler-fm\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:172\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/rs/cors.(*Cors).Handler.func1\\n\\t/go/pkg/mod/github.com/rs/cors@v1.6.0/cors.go:207\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/julienschmidt/httprouter.(*Router).Handler.func1\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/params_go17.go:26\\ngithub.com/julienschmidt/httprouter.(*Router).ServeHTTP\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/router.go:334\\ngithub.com/urfave/negroni.Wrap.func1\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:297\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests-fm\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:62\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\\n\\t/go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.(*Negroni).ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\\ngithub.com/gorilla/context.ClearHandler.func1\\n\\t/go/pkg/mod/github.com/gorilla/context@v1.1.1/context.go:141\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\nnet/http.serverHandler.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:2741\\nnet/http.(*conn).serve\\n\\t/usr/local/go/src/net/http/server.go:1847\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1333\"\ntime=\"2019-03-01T10:03:16Z\" level=info msg=\"completed handling request\" measure#https://oauth2.polluxis.me/.latency=4525815836 method=POST remote=\"10.244.5.5:55480\" request=/oauth2/token request_id=bc02654b-d9ab-4d8c-aa15-8b845b97af1b status=500 text_status=\"Internal Server Error\" took=4.525815836s\ntime=\"2019-03-01T10:03:16Z\" level=error msg=\"An error occurred\" debug=\"context canceled\" description=\"The authorization server encountered an unexpected condition that prevented it from fulfilling the request\" error=server_error\ntime=\"2019-03-01T10:03:16Z\" level=debug msg=\"Stack trace: \\ngithub.com/ory/fosite/handler/oauth2.(*RefreshTokenGrantHandler).HandleTokenEndpointRequest\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/handler/oauth2/flow_refresh.go:66\\ngithub.com/ory/fosite.(*Fosite).NewAccessRequest\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/access_request_handler.go:89\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:535\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler-fm\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:172\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/rs/cors.(*Cors).Handler.func1\\n\\t/go/pkg/mod/github.com/rs/cors@v1.6.0/cors.go:207\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/julienschmidt/httprouter.(*Router).Handler.func1\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/params_go17.go:26\\ngithub.com/julienschmidt/httprouter.(*Router).ServeHTTP\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/router.go:334\\ngithub.com/urfave/negroni.Wrap.func1\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:297\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests-fm\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:62\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\\n\\t/go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.(*Negroni).ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\\ngithub.com/gorilla/context.ClearHandler.func1\\n\\t/go/pkg/mod/github.com/gorilla/context@v1.1.1/context.go:141\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\nnet/http.serverHandler.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:2741\\nnet/http.(*conn).serve\\n\\t/usr/local/go/src/net/http/server.go:1847\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1333\"\ntime=\"2019-03-01T10:03:16Z\" level=info msg=\"completed handling request\" measure#https://oauth2.polluxis.me/.latency=4718861143 method=POST remote=\"10.244.5.5:55482\" request=/oauth2/token request_id=4272ce6c-98ce-486e-b44a-324a5c25647e status=500 text_status=\"Internal Server Error\" took=4.718861143s\ntime=\"2019-03-01T10:03:17Z\" level=error msg=\"An error occurred\" debug=\"context canceled\" description=\"The authorization server encountered an unexpected condition that prevented it from fulfilling the request\" error=server_error\ntime=\"2019-03-01T10:03:17Z\" level=debug msg=\"Stack trace: \\ngithub.com/ory/fosite/handler/oauth2.(*RefreshTokenGrantHandler).PopulateTokenEndpointResponse\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/handler/oauth2/flow_refresh.go:129\\ngithub.com/ory/fosite.(*Fosite).NewAccessResponse\\n\\t/go/pkg/mod/github.com/ory/fosite@v0.28.0/access_response_writer.go:36\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:572\\ngithub.com/ory/hydra/oauth2.(*Handler).TokenHandler-fm\\n\\t/go/src/github.com/ory/hydra/oauth2/handler.go:172\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/rs/cors.(*Cors).Handler.func1\\n\\t/go/pkg/mod/github.com/rs/cors@v1.6.0/cors.go:207\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/julienschmidt/httprouter.(*Router).Handler.func1\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/params_go17.go:26\\ngithub.com/julienschmidt/httprouter.(*Router).ServeHTTP\\n\\t/go/pkg/mod/github.com/julienschmidt/httprouter@v0.0.0-20180715161854-348b672cd90d/router.go:334\\ngithub.com/urfave/negroni.Wrap.func1\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:46\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:297\\ngithub.com/ory/hydra/cmd/server.(*Handler).RejectInsecureRequests-fm\\n\\t/go/src/github.com/ory/hydra/cmd/server/handler.go:62\\ngithub.com/urfave/negroni.HandlerFunc.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:29\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/ory/hydra/metrics/prometheus.(*MetricsManager).ServeHTTP\\n\\t/go/src/github.com/ory/hydra/metrics/prometheus/middleware.go:26\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.middleware.ServeHTTP-fm\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/meatballhat/negroni-logrus.(*Middleware).ServeHTTP\\n\\t/go/pkg/mod/github.com/meatballhat/negroni-logrus@v0.0.0-20170801195057-31067281800f/middleware.go:136\\ngithub.com/urfave/negroni.middleware.ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:38\\ngithub.com/urfave/negroni.(*Negroni).ServeHTTP\\n\\t/go/pkg/mod/github.com/urfave/negroni@v1.0.0/negroni.go:96\\ngithub.com/gorilla/context.ClearHandler.func1\\n\\t/go/pkg/mod/github.com/gorilla/context@v1.1.1/context.go:141\\nnet/http.HandlerFunc.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:1964\\nnet/http.serverHandler.ServeHTTP\\n\\t/usr/local/go/src/net/http/server.go:2741\\nnet/http.(*conn).serve\\n\\t/usr/local/go/src/net/http/server.go:1847\\nruntime.goexit\\n\\t/usr/local/go/src/runtime/asm_amd64.s:1333\"\ntime=\"2019-03-01T10:03:17Z\" level=info msg=\"completed handling request\" measure#https://oauth2.polluxis.me/.latency=4890533254 method=POST remote=\"10.244.5.6:48620\" request=/oauth2/token request_id=7ea6fd23-b30f-4459-abf6-819c2ccde087 status=500 text_status=\"Internal Server Error\" took=4.890533254s\nI unfortunately cannot provide postgre logs as I am using a external hosted service which doesn't provide me with logs. If necessary, I can setup a local instance and get the logs.. The sql query call does take some time but not as much as the bcrypt function...\n\nThis time it doesn't even make it past the bcrypt call\n\nWhen I trigger the refresh token method from a client outside the cluster ( through dummy express function) it looks like this:\n\nI'll setup another pg setup so I can look at the logs \n. Just for reference, it would seem like the timeout issue was only a symptom of the real problem, which was that my background function was calling the openid-client refresh token method multiple times (which I mistook for the retry mechanism of the library). Regardless this issue was not directly related to hydra. Thank you @aeneasr  for your aid in helping me track down the issue. . ",
    "kewde": "I ran into the same/similar issue but with DIFFERENT CHALLENGE IDs.\nThis occurs when consent remember is set to true and consent has been granted.\nA second new request will have the consent information with skiptrue.\nI was unable to accept  the consent and redirect the user.\nI'm using an in-memory cookie jar which gets destroyed each run. Occurs over different consent challenges.. Thanks, that solved it indeed!. Perhaps an issue in Fosite.\nThe exact line in Fosite where the ID token is generated and the field gets set:\nhttps://github.com/ory/fosite/blob/4e4121bac5cda8efa7d3eb6aaf7720f3ff59c329/handler/openid/strategy_jwt.go#L233\nThe Audience is retrieved from the \"Claim\". I've tried including it in \"aud\" field in the claim, but it seems (understandably so) to have gotten filtered out somewhere but not replace with the granted audiences.. > You're setting the access token audience but expect the id token audience to be different\nI was actually setting the access token audience array (using the granted option through consent accept) and expecting the id token audience array to be the same.\n. Hmm, what options do I have to set id token audience in hydra? I can get around it, but I'd like to adhere to the terminology of the spec.\nI have a single page application (clientid=website) which wants to interact with a resource server (clientid=secrets). website retrieves the ID Token and want to use it to authenticate to secrets.\n\nRelying Party (RP)\n   OAuth 2.0 Client application requiring End-User Authentication and Claims from an OpenID Provider. \n\nMy relying party is not the requester (website) but secrets, a resource server. \n\nazp\n   OPTIONAL. Authorized party - the party to which the ID Token was issued. If present, it MUST contain the OAuth 2.0 Client ID of this party. This Claim is only needed when the ID Token has a single audience value and that audience is different than the authorized party.\n\nThe authorized party (field=azp) is in my case the client website.\n. I'll close the issue, thanks for the information.\nThe secrets only allows inbound connections for a specific port, no outbound connections are allowed so it can not retrieve the id token from Hydra using the access token. (I intended to have the JWKs/Signing keys preloaded).\nI could setup exceptions in the firewall but the statelessness of the OIDC tokens is an interesting property I want to maintain. . ",
    "xiven": "I'm running into an issue where when I make the login request I notice that the login_challenge is not getting set on the response.  I'm thinking this may be why I always have skip set to false on the accept consent response when I log in again even though I set the remember flag to true from the consent form.  I'm not sure if that is related to #1165.\nWhy would the login_challenge not be getting set on login?. ",
    "satran": "No worries. \nIf it were up to me I wouldn\u2019t want to have :. But we are supporting PSD2, Berlin Group standard and they have a requirement of using scopes separated by :.. ",
    "ovidius72": "Well, obviously I already read the API documentation page. I was looking for help because the response in not what one expects. The documentation about the /oauth2/token endpoint doesn't provide much information about that.. ",
    "jredville": "I just spent an hour debugging this because I'm trying to put Hydra behind a proxy that is converting form parameters to json, would it be possible to update the api docs to point out that this endpoint only accepts form params? I understand that a client library should do this automatically, but it would be helpful to have that documented for people trying to debug like myself. Thanks for the reply. I do agree that the proxy shouldn't be doing that and I'm going to open an issue on them as well (fastify-reply-from). In the meantime finding this issue finally helped me figure it out so I could override the proxy.\nThe headers on that page would have definitely helped, so I appreciate that. . ",
    "dushyantgohil": "can you please provide a chat link?. ",
    "alien0matic": "Yes, the client is there, you can see that se second call is working.\nI don't see any errors in the database logs.\nThis ist the db config string.\npostgres://user:password@10.0.0.65:5432/hydra?sslmode=disable\". Both, hydra and Postgres are running as docker containers on my machine. (I could supply both and a small Java project triggering the error if you like)\nRunning \"SELECT * FROM hydra_client WHERE id='mailservice'\" through pgAdmin docker container is always returning the one expected row.. I'm sorry, I caught a pretty severe cold and am back at the office today, I just started to create your minimal example.. ",
    "KishanRavindran": "Hi, @aeneasr can you please elaborate on the \"some of the requests and doing AJAX requests where the browser should be used\" what I am trying to do is just a log token which can communicate to ory hydra and return be back with an access token for that. And I have posted this question in the community https://community.ory.sh/t/can-consent-flow-be-done-without-csrf-token/926 . Hi, @aeneasr I have gone through the link which you have given and I find that I stuck in the part where after the user login's successfully how to make a call to thehttp://hydra/oauth2/auth?client_id can you please guide me.. I figured this out I don't know how I missed this so much embarrassed.. Hi @aeneasr I understand that this is not a bug or feature request I just need to know how can I change the callback url from 127.0.0.1:4446/callback to something of my own localhost when i try to change the callback url to locahost:4200 and when I run it and hit the 127.0.0.1:4446/callback it is not loading for me can you guide me on this.. I figured this out so closing it myself.. ",
    "jgiles": "@aeneasr rebased. ",
    "pr0head": "1295663ada908dd431d7ffc9927feb6e2606b724. I updated to the latest version - c174f96e6e8ab31aa362c7a5d32e5637984aab5b, but the problem has not been fixed. > Also, does this affect only the response of token introspection?\nYes, the expiration time for the access token is returned correctly. When the ACCESS_TOKEN_LIFESPAN parameter is changed, the expiration time also changes correctly.\ncurl -X POST \\\n  http://192.168.5.12:4445/oauth2/introspect \\\n  -H 'Postman-Token: 50e3be92-4917-4fc7-ae68-d789e82f17fc' \\\n  -H 'cache-control: no-cache' \\\n  -d 'token=0KuBIL84xrL0cy72OcuWP_sVu8e3NzJ4447-ziwEadk.eUGZskTbVlWl_U_NQjjP00ScOz_K_ehgrn3PTvOHQTs&undefined='\n{\"active\":true,\"scope\":\"openid offline\",\"client_id\":\"5c7d930a02429c10c0864511\",\"sub\":\"5c7d934002429c10c0864513\",\"exp\":1551744293,\"iat\":1551733492,\"iss\":\"http://192.168.5.12:4444/\",\"token_type\":\"refresh_token\"}. @aaslamin I'll try ). Sorry, new PR created. Couldn't do the tests, I'll try later.. > Why is golang.org/x/... so f* annoying. Use go mod tidy to update... :)\nBut I did not make any new dependencies, did not change the go.mod and go.sum. Maybe I do not understand something, could you explain to me?. > What about the lifetime of authorization codes and id_tokens? Perhaps fetching the expiry can be extracted to a non-exported helper somewhere within this package or file.\nThe introspection point serves access or update tokens. Other tokens are outside the specification. \nhttps://tools.ietf.org/html/rfc7662#section-2.1. ",
    "drkhosla": "Thanks aeneasr. Error show that, it unable to resolve the network or sometime timeout I tried multiple time in different network at different location, but it fails every time. Now with another network I get following errors..\ngo: finding github.com/pborman/uuid v1.2.0\ngo: google.golang.org/api@v0.0.0-20180910000450-7ca32eb868bf: unrecognized import path \"google.golang.org/api\" (https fetch: Get https://google.golang.org/api?go-get=1: dial tcp 172.217.160.177:443: i/o timeout)\ngo: finding github.com/google/martian v2.1.0+incompatible\ngo: finding github.com/gobuffalo/packd v0.0.0-20181028162033-6d52e0eabf41\ngo: finding github.com/jtolds/gls v4.2.1+incompatible\ngo: finding github.com/asaskevich/govalidator v0.0.0-20180720115003-f9ffefc3facf\ngo: finding github.com/spf13/jwalterweatherman v1.0.0\ngo: finding github.com/Microsoft/go-winio v0.4.11\ngo: finding contrib.go.opencensus.io/exporter/stackdriver v0.7.0\ngo: google.golang.org/appengine@v1.2.0: unrecognized import path \"google.golang.org/appengine\" (https fetch: Get https://google.golang.org/appengine?go-get=1: dial tcp 172.217.160.177:443: i/o timeout)\ngo: golang.org/x/sync@v0.0.0-20180314180146-1d60e4601c6f: unrecognized import path \"golang.org/x/sync\" (https fetch: Get https://golang.org/x/sync?go-get=1: dial tcp 172.217.160.177:443: i/o timeout)\ngo: go.uber.org/atomic@v1.3.2: unrecognized import path \"go.uber.org/atomic\" (https fetch: Get https://go.uber.org/atomic?go-get=1: dial tcp 172.217.166.179:443: i/o timeout)\ngo: golang.org/x/sys@v0.0.0-20180906133057-8cf3aee42992: git fetch -f origin refs/heads/*:refs/heads/* refs/tags/*:refs/tags/* in /go/pkg/mod/cache/vcs/76a8992ccba6d77c6bcf031ff2b6d821cf232e4ad8d1f2362404fbd0a798d846: exit status 128:\n    fatal: unable to access 'https://go.googlesource.com/sys/': Failed to connect to go.googlesource.com port 443: Operation timed out\ngo: golang.org/x/sys@v0.0.0-20180909124046-d0be0721c37e: unknown revision d0be0721c37e\ngo: golang.org/x/sys@v0.0.0-20180905080454-ebe1bf3edb33: unknown revision ebe1bf3edb33\ngo: error loading module requirements\nERROR: Service 'hydra-migrate' failed to build: The command '/bin/sh -c go mod download' returned a non-zero code: 1\nIf I try\n```\n[xxx@localhost hydra]$ wget -O - https://go.uber.org/atomic?go-get=1:\n--2019-03-06 12:55:37--  https://go.uber.org/atomic?go-get=1:\nResolving go.uber.org (go.uber.org)... 2404:6800:4009:80b::2013, 172.217.160.211\nConnecting to go.uber.org (go.uber.org)|2404:6800:4009:80b::2013|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 579 [text/html]\nSaving to: \u2018STDOUT\u2019\n0% [                                                                                                             ] 0           --.-K/s              <!DOCTYPE html>\n\n\n\n\n\n\n\n        Nothing to see here. Please move along.\n    \n\n100%[============================================================================================================>] 579         --.-K/s   in 0s      \n2019-03-06 12:55:37 (42.4 MB/s) - written to stdout [579/579]\n[xxx@localhost hydra]$ \nDoes it require a new updated url. I want some customisation in docker compose file. But I am unable to build it from default compose file.. I think the problem lies in go.sum file and when it try to verify modules it fails. Need to update go.sum file with current version of modules available.. sorry it is not working...\n[localhost ~]$git clone https://github.com/ory/hydra.git\nCloning into 'hydra'...\nremote: Enumerating objects: 26, done.\nremote: Counting objects: 100% (26/26), done.\nremote: Compressing objects: 100% (26/26), done.\nremote: Total 20179 (delta 6), reused 0 (delta 0), pack-reused 20153\nReceiving objects: 100% (20179/20179), 37.69 MiB | 571.00 KiB/s, done.\nResolving deltas: 100% (12642/12642), done.\n[localhost ~]$cd hydra/\n[localhost hydra]$git checkout tags/v1.0.0-rc.6+oryOS.10\nNote: checking out 'tags/v1.0.0-rc.6+oryOS.10'.\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by performing another checkout.\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -b with the checkout command again. Example:\ngit checkout -b new_branch_name\nHEAD is now at bdb6634... docker: Bump base docker image versions (#1243)\n[localhost hydra]$git tag|tail\nv1.0.0-beta.6\nv1.0.0-beta.7\nv1.0.0-beta.8\nv1.0.0-beta.9\nv1.0.0-rc.1+oryOS.9\nv1.0.0-rc.2+oryOS.9\nv1.0.0-rc.3+oryOS.9\nv1.0.0-rc.4+oryOS.9\nv1.0.0-rc.5+oryOS.10\nv1.0.0-rc.6+oryOS.10\n[localhost hydra]$go mod tidy\n[localhost hydra]$sudo docker-compose -p hydra up --build -d\n[sudo] password for xxx: \nBuilding hydra-migrate\nStep 1/17 : FROM golang:1.11.4-alpine\n ---> f56365ec0638\nStep 2/17 : ARG git_tag\n ---> Using cache\n ---> 39026b0993c4\nStep 3/17 : ARG git_commit\n ---> Using cache\n ---> 27537281cc16\nStep 4/17 : RUN apk add --no-cache git build-base\n ---> Using cache\n ---> 628780d7d65b\nStep 5/17 : WORKDIR /go/src/github.com/ory/hydra\n ---> Using cache\n ---> 6a23d2ddfff2\nStep 6/17 : ENV GO111MODULE=on\n ---> Using cache\n ---> 699388cf88d6\nStep 7/17 : ADD ./go.mod ./go.mod\n ---> Using cache\n ---> d3eab4c7840c\nStep 8/17 : ADD ./go.sum ./go.sum\n ---> Using cache\n ---> e712ec7087ea\nStep 9/17 : RUN go mod download\n ---> Running in 92e9f7284a3d\ngo: finding github.com/phayes/freeport v0.0.0-20171002181615-b8543db493a5\ngo: finding github.com/mohae/deepcopy v0.0.0-20170929034955-c48cc78d4826\ngo: finding github.com/ory/dockertest v3.3.2+incompatible\ngo: finding github.com/golang/mock v1.1.1\ngo: finding github.com/urfave/negroni v1.0.0\ngo: finding github.com/toqueteos/webbrowser v0.0.0-20150720201625-21fc9f95c834\ngo: finding github.com/gobwas/glob v0.2.3\ngo: finding github.com/sirupsen/logrus v1.1.1\ngo: github.com/sirupsen/logrus@v1.1.1: unknown revision v1.1.1\ngo: finding github.com/gobuffalo/packd v0.0.0-20181029140631-cf76bd87a5a6\ngo: finding golang.org/x/oauth2 v0.0.0-20181003184128-c57b0facaced\ngo: finding gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127\ngo: finding github.com/go-sql-driver/mysql v1.4.0\ngo: finding github.com/rs/cors v1.6.0\ngo: finding github.com/gorilla/sessions v0.0.0-20160922145804-ca9ada445741\ngo: finding github.com/lib/pq v1.0.0\ngo: finding github.com/gtank/cryptopasta v0.0.0-20170601214702-1f550f6f2f69\ngo: finding golang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9\ngo: finding golang.org/x/net v0.0.0-20181029044818-c44066c5c816\ngo: finding github.com/prometheus/client_golang v0.8.0\ngo: finding github.com/ziutek/mymysql v1.5.4\ngo: finding github.com/oleiade/reflections v1.0.0\ngo: finding github.com/jmoiron/sqlx v0.0.0-20180614180643-0dae4fefe7c0\ngo: finding gopkg.in/resty.v1 v1.9.1\ngo: finding gopkg.in/yaml.v1 v1.0.0-20140924161607-9f9df34309c0\ngo: finding github.com/ory/x v0.0.33\ngo: finding github.com/ory/herodot v0.4.1\ngo: finding gopkg.in/square/go-jose.v2 v2.1.9\ngo: finding github.com/ory/go-convenience v0.1.0\ngo: finding github.com/julienschmidt/httprouter v0.0.0-20180715161854-348b672cd90d\ngo: finding github.com/rubenv/sql-migrate v0.0.0-20180704111356-ba2c6a7295c59448dbc195cef2f41df5163b3892\ngo: finding github.com/spf13/cobra v0.0.3\ngo: finding go.uber.org/atomic v1.3.2\ngo: finding github.com/uber/jaeger-client-go v2.15.0+incompatible\ngo: finding github.com/meatballhat/negroni-logrus v0.0.0-20170801195057-31067281800f\ngo: finding github.com/pborman/uuid v1.2.0\ngo: finding github.com/ory/graceful v0.1.0\ngo: finding github.com/pkg/errors v0.8.0\ngo: finding github.com/ory/sqlcon v0.0.7\ngo: finding github.com/stretchr/testify v1.2.2\ngo: finding github.com/imdario/mergo v0.0.0-20171009183408-7fe0c75c13ab\ngo: finding github.com/spf13/viper v1.2.1\ngo: finding github.com/gorilla/securecookie v0.0.0-20160422134519-667fe4e3466a\ngo: finding github.com/ory/fosite v0.28.0\ngo: finding github.com/mendsley/gojwk v0.0.0-20141217222730-4d5ec6e58103\ngo: finding github.com/uber-go/atomic v1.3.2\ngo: finding github.com/dgrijalva/jwt-go v3.2.0+incompatible\ngo: finding github.com/gorilla/context v1.1.1\ngo: finding github.com/opentracing/opentracing-go v1.0.2\ngo: error loading module requirements\nERROR: Service 'hydra-migrate' failed to build: The command '/bin/sh -c go mod download' returned a non-zero code: 1\n[localhost hydra]$\n. After an hour I again try to build and it WORKED for me..\n[localhost hydra]$cat go.sum \ncloud.google.com/go v0.23.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.31.0 h1:o9K5MWWt2wk+d9jkGn2DAZ7Q9nUdnFLOpK9eIkDwONQ=\ncloud.google.com/go v0.31.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncontrib.go.opencensus.io/exporter/stackdriver v0.7.0 h1:pmo1ol3uPcrLmvOET8bEbu5sialRZDDSHqJso0vo28o=\ncontrib.go.opencensus.io/exporter/stackdriver v0.7.0/go.mod h1:hNe5qQofPbg6bLQY5wHCvQ7o+2E5P8PkegEuQ+MyRw0=\ngit.apache.org/thrift.git v0.0.0-20180902110319-2566ecd5d999/go.mod h1:fPE2ZNJGynbRyZ4dJvy6G277gSllfV2HJqblrnkyeyg=\ngithub.com/Azure/go-ansiterm v0.0.0-20170929234023-d6e3b3328b78 h1:w+iIsaOQNcT7OZ575w+acHgRric5iCyQh+xv+KJ4HB8=\ngithub.com/Azure/go-ansiterm v0.0.0-20170929234023-d6e3b3328b78/go.mod h1:LmzpDX56iTiv29bbRTIsUNlaFfuhWRQBWjQdVyAevI8=\ngithub.com/BurntSushi/toml v0.3.1 h1:WXkYYl6Yr3qBf1K79EBnL4mak0OimBfB0XUf9Vl28OQ=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/Microsoft/go-winio v0.4.11 h1:zoIOcVf0xPN1tnMVbTtEdI+P8OofVk3NObnwOQ6nK2Q=\ngithub.com/Microsoft/go-winio v0.4.11/go.mod h1:VhR8bwka0BXejwEJY73c50VrPtXAaKcyvVC4A4RozmA=\ngithub.com/Nvveen/Gotty v0.0.0-20120604004816-cd527374f1e5 h1:TngWCqHvy9oXAN6lEVMRuU21PR1EtLVZJmdB18Gu3Rw=\ngithub.com/Nvveen/Gotty v0.0.0-20120604004816-cd527374f1e5/go.mod h1:lmUJ/7eu/Q8D7ML55dXQrVaamCz2vxCfdQBasLZfHKk=\ngithub.com/asaskevich/govalidator v0.0.0-20180720115003-f9ffefc3facf h1:eg0MeVzsP1G42dRafH3vf+al2vQIJU0YHX+1Tw87oco=\ngithub.com/asaskevich/govalidator v0.0.0-20180720115003-f9ffefc3facf/go.mod h1:lB+ZfQJz7igIIfQNfa7Ml4HSf2uFQQRzpGGRXenZAgY=\ngithub.com/aws/aws-sdk-go v1.15.31/go.mod h1:mFuSZ37Z9YOHbQEwBWztmVzqXrEkub65tZoCYDt7FT0=\ngithub.com/beorn7/perks v0.0.0-20180321164747-3a771d992973 h1:xJ4a3vCFaGF/jqvzLMYoU8P317H5OQ+Via4RmuPwCS0=\ngithub.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24TaqPxmxbtue+5NUziq4I4S80YR8gNf3Q=\ngithub.com/bmizerany/assert v0.0.0-20160611221934-b7ed37b82869 h1:DDGfHa7BWjL4YnC6+E63dPcxHo2sUxDIu8g3QgEJdRY=\ngithub.com/bmizerany/assert v0.0.0-20160611221934-b7ed37b82869/go.mod h1:Ekp36dRnpXw/yCqJaO+ZrUyxD+3VXMFFr56k5XYrpB4=\ngithub.com/cenkalti/backoff v2.0.0+incompatible h1:5IIPUHhlnUZbcHQsQou5k1Tn58nJkeJL9U+ig5CHJbY=\ngithub.com/cenkalti/backoff v2.0.0+incompatible/go.mod h1:90ReRw6GdpyfrHakVjL/QHaoyV4aDUVVkXQJJJ3NXXM=\ngithub.com/codahale/hdrhistogram v0.0.0-20161010025455-3a0bb77429bd h1:qMd81Ts1T2OTKmB4acZcyKaMtRnY5Y44NuXGX2GFJ1w=\ngithub.com/codahale/hdrhistogram v0.0.0-20161010025455-3a0bb77429bd/go.mod h1:sE/e/2PUdi/liOCUjSTXgM1o87ZssimdTWN964YiIeI=\ngithub.com/containerd/continuity v0.0.0-20181003075958-be9bd761db19 h1:HSgjWPBWohO3kHDPwCPUGSLqJjXCjA7ad5057beR2ZU=\ngithub.com/containerd/continuity v0.0.0-20181003075958-be9bd761db19/go.mod h1:GL3xCUCBDV3CZiTSEKksMWbLE66hEyuu9qyDOOqM47Y=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/dgrijalva/jwt-go v3.2.0+incompatible h1:7qlOGliEKZXTDg6OTjfoBKDXWrumCAMpl/TFQ4/5kLM=\ngithub.com/dgrijalva/jwt-go v3.2.0+incompatible/go.mod h1:E3ru+11k8xSBh+hMPgOLZmtrrCbhqsmaPHjLKYnJCaQ=\ngithub.com/docker/go-connections v0.4.0 h1:El9xVISelRB7BuFusrZozjnkIM5YnzCViNKohAFqRJQ=\ngithub.com/docker/go-connections v0.4.0/go.mod h1:Gbd7IOopHjR8Iph03tsViu4nIes5XhDvyHbTtUxmeec=\ngithub.com/docker/go-units v0.3.3 h1:Xk8S3Xj5sLGlG5g67hJmYMmUgXv5N4PhkjJHHqrwnTk=\ngithub.com/docker/go-units v0.3.3/go.mod h1:fgPhTUdO+D/Jk86RDLlptpiXQzgHJF7gydDDbaIK4Dk=\ngithub.com/elazarl/goproxy v0.0.0-20181003060214-f58a169a71a5/go.mod h1:/Zj4wYkgs4iZTTu3o/KG3Itv/qCCa8VVMlb3i9OVuzc=\ngithub.com/fsnotify/fsnotify v1.4.7 h1:IXs+QLmnXW2CcXuY+8Mzv/fWEsPGWxqefPtCP5CnV9I=\ngithub.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/ghodss/yaml v1.0.0/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=\ngithub.com/go-ini/ini v1.25.4/go.mod h1:ByCAeIL28uOIIG0E3PJtZPDL8WnHpFKFOtgjp+3Ies8=\ngithub.com/go-sql-driver/mysql v1.4.0 h1:7LxgVwFb2hIQtMm87NdgAVfXjnt4OePseqT1tKx+opk=\ngithub.com/go-sql-driver/mysql v1.4.0/go.mod h1:zAC/RDZ24gD3HViQzih4MyKcchzm+sOG5ZlKdlhCg5w=\ngithub.com/gobuffalo/envy v1.6.7 h1:XMZGuFqTupAXhZTriQ+qO38QvNOSU/0rl3hEPCFci/4=\ngithub.com/gobuffalo/envy v1.6.7/go.mod h1:N+GkhhZ/93bGZc6ZKhJLP6+m+tCNPKwgSpH9kaifseQ=\ngithub.com/gobuffalo/packd v0.0.0-20181028162033-6d52e0eabf41 h1:Y3YNlzzY4xoVlEWqOS9lBT49x9qF8S1rqHfhMFYjfgg=\ngithub.com/gobuffalo/packd v0.0.0-20181028162033-6d52e0eabf41/go.mod h1:Yf2toFaISlyQrr5TfO3h6DB9pl9mZRmyvBGQb/aQ/pI=\ngithub.com/gobuffalo/packd v0.0.0-20181029140631-cf76bd87a5a6 h1:qyhnjK1xyp4xqyP12n8vBQDRgZe6fOXkITcCxN9zX2o=\ngithub.com/gobuffalo/packd v0.0.0-20181029140631-cf76bd87a5a6/go.mod h1:Yf2toFaISlyQrr5TfO3h6DB9pl9mZRmyvBGQb/aQ/pI=\ngithub.com/gobuffalo/packr v1.16.0 h1:s0cqMbFDbio+Z3YxLeDOKRjLW2JKh9QVud0O7+j1fiQ=\ngithub.com/gobuffalo/packr v1.16.0/go.mod h1:Yx/lcR/7mDLXhuJSzsz2MauD/HUwSc+EK6oigMRGGsM=\ngithub.com/gobwas/glob v0.2.3 h1:A4xDbljILXROh+kObIiy5kIaPYD8e96x1tgBhUI5J+Y=\ngithub.com/gobwas/glob v0.2.3/go.mod h1:d3Ez4x06l9bZtSvzIay5+Yzi0fmZzPgnTbPcKjJAkT8=\ngithub.com/golang/gddo v0.0.0-20180828051604-96d2a289f41e h1:8sV50nrSGwclVxkCGHxgWfJhY6cyXS2plGjGvUzrMIw=\ngithub.com/golang/gddo v0.0.0-20180828051604-96d2a289f41e/go.mod h1:xEhNfoBDX1hzLm2Nf80qUvZ2sVwoMZ8d6IE2SrsQfh4=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b h1:VKtxabqXZkF25pY9ekfRL6a582T4P37/31XEstQ5p58=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/mock v1.1.1 h1:G5FRp8JnTd7RQH5kemVNlMeyXQAztQ3mOWV95KxsXH8=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/protobuf v1.1.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.2.0 h1:P3YflyNX/ehuJFLhxviNdFxQPkGK5cDcApsge1SqnvM=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/google/go-cmp v0.2.0 h1:+dTQ8DZQJz0Mb/HjFlkptS1FeQ4cWSnN941F8aEG4SQ=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/martian v2.1.0+incompatible h1:/CP5g8u/VJHijgedC/Legn3BAbAaWPgecwXBIDzw5no=\ngithub.com/google/martian v2.1.0+incompatible/go.mod h1:9I4somxYTbIHy5NJKHRl3wXiIaQGbYVAs8BPL6v8lEs=\ngithub.com/google/uuid v1.0.0 h1:b4Gk+7WdP/d3HZH8EJsZpvV7EtDOgaZLtnaNGIu1adA=\ngithub.com/google/uuid v1.0.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/googleapis/gax-go v2.0.0+incompatible h1:j0GKcs05QVmm7yesiZq2+9cxHkNK9YM6zKx4D2qucQU=\ngithub.com/googleapis/gax-go v2.0.0+incompatible/go.mod h1:SFVmujtThgffbyetf+mdk2eWhX2bMyUtNHzFKcPA9HY=\ngithub.com/gopherjs/gopherjs v0.0.0-20181004151105-1babbf986f6f/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gorilla/context v1.1.1 h1:AWwleXJkX/nhcU9bZSnZoi3h/qGYqQAGhq6zZe/aQW8=\ngithub.com/gorilla/context v1.1.1/go.mod h1:kBGZzfjB9CEq2AlWe17Uuf7NDRt0dE0s8S51q0aT7Yg=\ngithub.com/gorilla/mux v1.6.2 h1:Pgr17XVTNXAk3q/r4CpKzC5xBM/qW1uVLV+IhRZpIIk=\ngithub.com/gorilla/mux v1.6.2/go.mod h1:1lud6UwP+6orDFRuTfBEV8e9/aOM/c4fVVCaMa2zaAs=\ngithub.com/gorilla/securecookie v0.0.0-20160422134519-667fe4e3466a h1:YH0IojQwndMQdeRWdw1aPT8bkbiWaYR3WD+Zf5e09DU=\ngithub.com/gorilla/securecookie v0.0.0-20160422134519-667fe4e3466a/go.mod h1:ra0sb63/xPlUeL+yeDciTfxMRAA+MP+HVt/4epWDjd4=\ngithub.com/gorilla/sessions v0.0.0-20160922145804-ca9ada445741 h1:OuuPl66BpF1q3OEkaPpp+VfzxrBBY62ATGdWqql/XX8=\ngithub.com/gorilla/sessions v0.0.0-20160922145804-ca9ada445741/go.mod h1:+WVp8kdw6VhyKExm03PAMRn2ZxnPtm58pV0dBVPdhHE=\ngithub.com/gotestyourself/gotestyourself v2.1.0+incompatible h1:JdX/5sh/7yF7jRW5Xpvh1wlkAlgZS+X3HVCMlYqlxmw=\ngithub.com/gotestyourself/gotestyourself v2.1.0+incompatible/go.mod h1:zZKM6oeNM8k+FRljX1mnzVYeS8wiGgQyvST1/GafPbY=\ngithub.com/grpc-ecosystem/grpc-gateway v1.5.0/go.mod h1:RSKVYQBd5MCa4OVpNdGskqpgL2+G+NZTnrVHpWWfpdw=\ngithub.com/gtank/cryptopasta v0.0.0-20170601214702-1f550f6f2f69 h1:7xsUJsB2NrdcttQPa7JLEaGzvdbk7KvfrjgHZXOQRo0=\ngithub.com/gtank/cryptopasta v0.0.0-20170601214702-1f550f6f2f69/go.mod h1:YLEMZOtU+AZ7dhN9T/IpGhXVGly2bvkJQ+zxj3WeVQo=\ngithub.com/hashicorp/hcl v1.0.0 h1:0Anlzjpi4vEasTeNFn2mLJgTSwt0+6sfsiTG8qcWGx4=\ngithub.com/hashicorp/hcl v1.0.0/go.mod h1:E5yfLk+7swimpb2L/Alb/PJmXilQ/rhwaUYs4T20WEQ=\ngithub.com/imdario/mergo v0.0.0-20171009183408-7fe0c75c13ab h1:k/Biv+LJL35wkk0Hveko1nj7as4tSHkHdZaNlzn/gcQ=\ngithub.com/imdario/mergo v0.0.0-20171009183408-7fe0c75c13ab/go.mod h1:2EnlNZ0deacrJVfApfmtdGgDfMuh/nq6Ok1EcJh5FfA=\ngithub.com/inconshreveable/mousetrap v1.0.0 h1:Z8tu5sraLXCXIcARxBp/8cbvlwVa7Z1NHg9XEKhtSvM=\ngithub.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=\ngithub.com/jmespath/go-jmespath v0.0.0-20160202185014-0b12d6b521d8/go.mod h1:Nht3zPeWKUH0NzdCt2Blrr5ys8VGpn0CEB0cQHVjt7k=\ngithub.com/jmoiron/sqlx v0.0.0-20180614180643-0dae4fefe7c0 h1:5B0uxl2lzNRVkJVg+uGHxWtRt4C0Wjc6kJKo5XYx8xE=\ngithub.com/jmoiron/sqlx v0.0.0-20180614180643-0dae4fefe7c0/go.mod h1:IiEW3SEiiErVyFdH8NTuWjSifiEQKUoyK3LNqr2kCHU=\ngithub.com/joho/godotenv v1.3.0 h1:Zjp+RcGpHhGlrMbJzXTrZZPrWj+1vfm90La1wgB6Bhc=\ngithub.com/joho/godotenv v1.3.0/go.mod h1:7hK45KPybAkOC6peb+G5yklZfMxEjkZhHbwpqxOKXbg=\ngithub.com/jtolds/gls v4.2.1+incompatible/go.mod h1:QJZ7F/aHp+rZTRtaJ1ow/lLfFfVYBRgL+9YlvaHOwJU=\ngithub.com/julienschmidt/httprouter v0.0.0-20180715161854-348b672cd90d h1:of6+TpypLAaiv4JxgH5aplBZnt0b65B4v4c8q5oy+Sk=\ngithub.com/julienschmidt/httprouter v0.0.0-20180715161854-348b672cd90d/go.mod h1:SYymIcj16QtmaHHD7aYtjjsJG7VTCxuUUipMqKk8s4w=\ngithub.com/konsorten/go-windows-terminal-sequences v0.0.0-20180402223658-b729f2633dfe h1:CHRGQ8V7OlCYtwaKPJi3iA7J+YdNKdo8j7nG5IgDhjs=\ngithub.com/konsorten/go-windows-terminal-sequences v0.0.0-20180402223658-b729f2633dfe/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/kr/pretty v0.1.0 h1:L/CwN0zerZDmRFUapSPitk6f+Q3+0za1rQkzVuMiMFI=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/text v0.1.0 h1:45sCR5RtlFHMR4UwH9sdQ5TC8v0qDQCHnXt+kaKSTVE=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/lib/pq v1.0.0 h1:X5PMW56eZitiTeO7tKzZxFCSpbFZJtkMMooicw2us9A=\ngithub.com/lib/pq v1.0.0/go.mod h1:5WUZQaWbwv1U+lTReE5YruASi9Al49XbQIvNi/34Woo=\ngithub.com/luna-duclos/instrumentedsql v0.0.0-20181127104832-b7d587d28109 h1:SSbnT1UH/TdSedRIy8XVB1dsVUOFP8iHaa/+QE0/q2k=\ngithub.com/luna-duclos/instrumentedsql v0.0.0-20181127104832-b7d587d28109/go.mod h1:PWUIzhtavmOR965zfawVsHXbEuU1G29BPZ/CB3C7jXk=\ngithub.com/magiconair/properties v1.8.0 h1:LLgXmsheXeRoUOBOjtwPQCWIYqM/LU1ayDtDePerRcY=\ngithub.com/magiconair/properties v1.8.0/go.mod h1:PppfXfuXeibc/6YijjN8zIbojt8czPbwD3XqdrwzmxQ=\ngithub.com/markbates/oncer v0.0.0-20181014194634-05fccaae8fc4 h1:Mlji5gkcpzkqTROyE4ZxZ8hN7osunMb2RuGVrbvMvCc=\ngithub.com/markbates/oncer v0.0.0-20181014194634-05fccaae8fc4/go.mod h1:Ld9puTsIW75CHf65OeIOkyKbteujpZVXDpWK6YGZbxE=\ngithub.com/mattn/go-sqlite3 v1.9.0 h1:pDRiWfl+++eC2FEFRy6jXmQlvp4Yh3z1MJKg4UeYM/4=\ngithub.com/mattn/go-sqlite3 v1.9.0/go.mod h1:FPy6KqzDD04eiIsT53CuJW3U88zkxoIYsOqkbpncsNc=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1 h1:4hp9jkHxhMHkqkrB3Ix0jegS5sx/RkqARlsWZ6pIwiU=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1/go.mod h1:D8He9yQNgCq6Z5Ld7szi9bcBfOoFv/3dc6xSMkL2PC0=\ngithub.com/meatballhat/negroni-logrus v0.0.0-20170801195057-31067281800f h1:V6GHkMOIsnpGDasS1iYiNxEYTY8TmyjQXEF8PqYkKQ8=\ngithub.com/meatballhat/negroni-logrus v0.0.0-20170801195057-31067281800f/go.mod h1:Ylx55XGW4gjY7McWT0pgqU0aQquIOChDnYkOVbSuF/c=\ngithub.com/mendsley/gojwk v0.0.0-20141217222730-4d5ec6e58103 h1:Z/i1e+gTZrmcGeZyWckaLfucYG6KYOXLWo4co8pZYNY=\ngithub.com/mendsley/gojwk v0.0.0-20141217222730-4d5ec6e58103/go.mod h1:o9YPB5aGP8ob35Vy6+vyq3P3bWe7NQWzf+JLiXCiMaE=\ngithub.com/mitchellh/mapstructure v1.0.0 h1:vVpGvMXJPqSDh2VYHF7gsfQj8Ncx+Xw5Y1KHeTRY+7I=\ngithub.com/mitchellh/mapstructure v1.0.0/go.mod h1:FVVH3fgwuzCH5S8UJGiWEs2h04kUh9fWfEaFds41c1Y=\ngithub.com/mohae/deepcopy v0.0.0-20170929034955-c48cc78d4826 h1:RWengNIwukTxcDr9M+97sNutRR1RKhG96O6jWumTTnw=\ngithub.com/mohae/deepcopy v0.0.0-20170929034955-c48cc78d4826/go.mod h1:TaXosZuwdSHYgviHp1DAtfrULt5eUgsSMsZf+YrPgl8=\ngithub.com/moul/http2curl v0.0.0-20170919181001-9ac6cf4d929b/go.mod h1:8UbvGypXm98wA/IqH45anm5Y2Z6ep6O31QGOAZ3H0fQ=\ngithub.com/oleiade/reflections v1.0.0 h1:0ir4pc6v8/PJ0yw5AEtMddfXpWBXg9cnG7SgSoJuCgY=\ngithub.com/oleiade/reflections v1.0.0/go.mod h1:RbATFBbKYkVdqmSFtx13Bb/tVhR0lgOBXunWTZKeL4w=\ngithub.com/opencontainers/go-digest v1.0.0-rc1 h1:WzifXhOVOEOuFYOJAW6aQqW0TooG2iki3E3Ii+WN7gQ=\ngithub.com/opencontainers/go-digest v1.0.0-rc1/go.mod h1:cMLVZDEM3+U2I4VmLI6N8jQYUd2OVphdqWwCJHrFt2s=\ngithub.com/opencontainers/image-spec v1.0.1 h1:JMemWkRwHx4Zj+fVxWoMCFm/8sYGGrUVojFA6h/TRcI=\ngithub.com/opencontainers/image-spec v1.0.1/go.mod h1:BtxoFyWECRxE4U/7sNtV5W15zMzWCbyJoFRP3s7yZA0=\ngithub.com/opencontainers/runc v0.1.1 h1:GlxAyO6x8rfZYN9Tt0Kti5a/cP41iuiO2yYT0IJGY8Y=\ngithub.com/opencontainers/runc v0.1.1/go.mod h1:qT5XzbpPznkRYVz/mWwUaVBUv2rmF59PVA73FjuZG0U=\ngithub.com/opentracing/opentracing-go v1.0.2 h1:3jA2P6O1F9UOrWVpwrIo17pu01KWvNWg4X946/Y5Zwg=\ngithub.com/opentracing/opentracing-go v1.0.2/go.mod h1:UkNAQd3GIcIGf0SeVgPpRdFStlNbqXla1AfSYxPUl2o=\ngithub.com/openzipkin/zipkin-go v0.1.1/go.mod h1:NtoC/o8u3JlF1lSlyPNswIbeQH9bJTmOf0Erfk+hxe8=\ngithub.com/ory/dockertest v3.3.2+incompatible h1:uO+NcwH6GuFof/Uz8yzjNi1g0sGT5SLAJbdBvD8bUYc=\ngithub.com/ory/dockertest v3.3.2+incompatible/go.mod h1:1vX4m9wsvi00u5bseYwXaSnhNrne+V0E6LAcBILJdPs=\ngithub.com/ory/fosite v0.25.0 h1:GELSEQc6OIDsfvtx1nC0snzPpFF14W/f6MeMXPEiZ9I=\ngithub.com/ory/fosite v0.25.0/go.mod h1:uttCRNB0lM7+BJFX7CC8Bqo9gAPrcpmA9Ezc80Trwuw=\ngithub.com/ory/fosite v0.28.0 h1:LxCkLXeU5PxYh9d/VbfGVn8GTKkSdOZfrHWdjmIE//c=\ngithub.com/ory/fosite v0.28.0/go.mod h1:uttCRNB0lM7+BJFX7CC8Bqo9gAPrcpmA9Ezc80Trwuw=\ngithub.com/ory/go-convenience v0.1.0 h1:zouLKfF2GoSGnJwGq+PE/nJAE6dj2Zj5QlTgmMTsTS8=\ngithub.com/ory/go-convenience v0.1.0/go.mod h1:uEY/a60PL5c12nYz4V5cHY03IBmwIAEm8TWB0yn9KNs=\ngithub.com/ory/graceful v0.1.0 h1:zilpYtcR5vp4GubV4bN2GFJewHaSkMFnnRiJxyH8FAc=\ngithub.com/ory/graceful v0.1.0/go.mod h1:zqu70l95WrKHF4AZ6tXHvAqAvpY6M7g6ttaAVcMm7KU=\ngithub.com/ory/herodot v0.4.1 h1:XXzBJX6wt3xJ+rrlyiK7lot6CoO+a3hjx9rOvrptiyk=\ngithub.com/ory/herodot v0.4.1/go.mod h1:3BOneqcyBsVybCPAJoi92KN2BpJHcmDqAMcAAaJiJow=\ngithub.com/ory/sqlcon v0.0.7 h1:PQl4ihs11Xzw9wyFk0YQmQEnPL0icdJjiStQNaoRTmM=\ngithub.com/ory/sqlcon v0.0.7/go.mod h1:oOyCmOJWAs8F0bnGmmIvGA9/4K1JqVL0D9JgvAaVc3U=\ngithub.com/ory/x v0.0.33 h1:Hfy1Xe+oKvOG8BN+B3ArM0eVfoCH7FElOmMzO0J/c0Q=\ngithub.com/ory/x v0.0.33/go.mod h1:U7SUjn+NSVmHbWlS0LBSxbBk1hdPDmc2AJk9gZZZedA=\ngithub.com/parnurzeal/gorequest v0.2.15/go.mod h1:3Kh2QUMJoqw3icWAecsyzkpY7UzRfDhbRdTjtNwNiUE=\ngithub.com/pborman/uuid v1.2.0 h1:J7Q5mO4ysT1dv8hyrUGHb9+ooztCXu1D8MY8DZYsu3g=\ngithub.com/pborman/uuid v1.2.0/go.mod h1:X/NO0urCmaxf9VXbdlT7C2Yzkj2IKimNn4k+gtPdI/k=\ngithub.com/pelletier/go-toml v1.2.0 h1:T5zMGML61Wp+FlcbWjRDT7yAxhJNAiPPLOFECq181zc=\ngithub.com/pelletier/go-toml v1.2.0/go.mod h1:5z9KED0ma1S8pY6P1sdut58dfprrGBbd/94hg7ilaic=\ngithub.com/phayes/freeport v0.0.0-20171002181615-b8543db493a5 h1:rZQtoozkfsiNs36c7Tdv/gyGNzD1X1XWKO8rptVNZuM=\ngithub.com/phayes/freeport v0.0.0-20171002181615-b8543db493a5/go.mod h1:iIss55rKnNBTvrwdmkUpLnDpZoAHvWaiq5+iMmen4AE=\ngithub.com/pkg/errors v0.8.0 h1:WdK/asTD0HN+q6hsWO3/vpuAkAr+tw6aNJNDFFf0+qw=\ngithub.com/pkg/errors v0.8.0/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/profile v1.2.1 h1:F++O52m40owAmADcojzM+9gyjmMOY/T4oYJkgFDH8RE=\ngithub.com/pkg/profile v1.2.1/go.mod h1:hJw3o1OdXxsrSjjVksARp5W95eeEaEfptyVZyv6JUPA=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prometheus/client_golang v0.8.0 h1:1921Yw9Gc3iSc4VQh3PIoOqgPCZS7G/4xQNVUp8Mda8=\ngithub.com/prometheus/client_golang v0.8.0/go.mod h1:7SWBe2y4D6OKWSNQJUaRYU/AaXPKyh/dDVn+NZz0KFw=\ngithub.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910 h1:idejC8f05m9MGOsuEi1ATq9shN03HrxNkD/luQvxCv8=\ngithub.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/common v0.0.0-20180801064454-c7de2306084e h1:n/3MEhJQjQxrOUCzh1Y3Re6aJUUWRp2M9+Oc3eVn/54=\ngithub.com/prometheus/common v0.0.0-20180801064454-c7de2306084e/go.mod h1:daVV7qP5qjZbuso7PdcryaAu0sAZbrN9i7WWcTMWvro=\ngithub.com/prometheus/procfs v0.0.0-20180725123919-05ee40e3a273 h1:agujYaXJSxSo18YNX3jzl+4G6Bstwt+kqv47GS12uL0=\ngithub.com/prometheus/procfs v0.0.0-20180725123919-05ee40e3a273/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/rs/cors v1.6.0 h1:G9tHG9lebljV9mfp9SNPDL36nCDxmo3zTlAf1YgvzmI=\ngithub.com/rs/cors v1.6.0/go.mod h1:gFx+x8UowdsKA9AchylcLynDq+nNFfI8FkUZdN/jGCU=\ngithub.com/rubenv/sql-migrate v0.0.0-20180704111356-3f452fc0ebeb h1:lAOy8O8yKU3unXE92z9pfE7ylDwXr3202BLskpOaUcA=\ngithub.com/rubenv/sql-migrate v0.0.0-20180704111356-3f452fc0ebeb/go.mod h1:WS0rl9eEliYI8DPnr3TOwz4439pay+qNgzJoVya/DmY=\ngithub.com/rubenv/sql-migrate v0.0.0-20180704111356-ba2c6a7295c59448dbc195cef2f41df5163b3892 h1:dKonk0uAnxXkHVWh5vGV3rD3NKkLvuhhJN4zpicBc/M=\ngithub.com/rubenv/sql-migrate v0.0.0-20180704111356-ba2c6a7295c59448dbc195cef2f41df5163b3892/go.mod h1:WS0rl9eEliYI8DPnr3TOwz4439pay+qNgzJoVya/DmY=\ngithub.com/segmentio/analytics-go v3.0.1+incompatible h1:W7T3ieNQjPFMb+SE8SAVYo6mPkKK/Y37wYdiNf5lCVg=\ngithub.com/segmentio/analytics-go v3.0.1+incompatible/go.mod h1:C7CYBtQWk4vRk2RyLu0qOcbHJ18E3F1HV2C/8JvKN48=\ngithub.com/segmentio/backo-go v0.0.0-20160424052352-204274ad699c h1:rsRTAcCR5CeNLkvgBVSjQoDGRRt6kggsE6XYBqCv2KQ=\ngithub.com/segmentio/backo-go v0.0.0-20160424052352-204274ad699c/go.mod h1:kJ9mm9YmoWSkk+oQ+5Cj8DEoRCX2JT6As4kEtIIOp1M=\ngithub.com/sirupsen/logrus v1.0.6 h1:hcP1GmhGigz/O7h1WVUM5KklBp1JoNS9FggWKdj/j3s=\ngithub.com/sirupsen/logrus v1.0.6/go.mod h1:pMByvHTf9Beacp5x1UXfOR9xyW/9antXMhjMPG0dEzc=\ngithub.com/sirupsen/logrus v1.1.1 h1:VzGj7lhU7KEB9e9gMpAV/v5XT2NVSvLJhJLCWbnkgXg=\ngithub.com/sirupsen/logrus v1.1.1/go.mod h1:zrgwTnHtNr00buQ1vSptGe8m1f/BbgsPukg8qsT7A+A=\ngithub.com/smartystreets/assertions v0.0.0-20180927180507-b2de0cb4f26d/go.mod h1:OnSkiWE9lh6wB0YB77sQom3nweQdgAjqCqsofrRNTgc=\ngithub.com/smartystreets/goconvey v0.0.0-20180222194500-ef6db91d284a/go.mod h1:XDJAKZRPZ1CvBcN2aX5YOUTYGHki24fSF0Iv48Ibg0s=\ngithub.com/spf13/afero v1.1.2 h1:m8/z1t7/fwjysjQRYbP0RD+bUIF/8tJwPdEZsI83ACI=\ngithub.com/spf13/afero v1.1.2/go.mod h1:j4pytiNVoe2o6bmDsKpLACNPDBIoEAkihy7loJ1B0CQ=\ngithub.com/spf13/cast v1.2.0 h1:HHl1DSRbEQN2i8tJmtS6ViPyHx35+p51amrdsiTCrkg=\ngithub.com/spf13/cast v1.2.0/go.mod h1:r2rcYCSwa1IExKTDiTfzaxqT2FNHs8hODu4LnUfgKEg=\ngithub.com/spf13/cobra v0.0.3 h1:ZlrZ4XsMRm04Fr5pSFxBgfND2EBVa1nLpiy1stUsX/8=\ngithub.com/spf13/cobra v0.0.3/go.mod h1:1l0Ry5zgKvJasoi3XT1TypsSe7PqH0Sj9dhYf7v3XqQ=\ngithub.com/spf13/jwalterweatherman v1.0.0 h1:XHEdyB+EcvlqZamSM4ZOMGlc93t6AcsBEu9Gc1vn7yk=\ngithub.com/spf13/jwalterweatherman v1.0.0/go.mod h1:cQK4TGJAtQXfYWX+Ddv3mKDzgVb68N+wFjFa4jdeBTo=\ngithub.com/spf13/pflag v1.0.2 h1:Fy0orTDgHdbnzHcsOgfCN4LtHf0ec3wwtiwJqwvf3Gc=\ngithub.com/spf13/pflag v1.0.2/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=\ngithub.com/spf13/pflag v1.0.3 h1:zPAT6CGy6wXeQ7NtTnaTerfKOsV6V6F8agHXFiazDkg=\ngithub.com/spf13/pflag v1.0.3/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=\ngithub.com/spf13/viper v1.2.1 h1:bIcUwXqLseLF3BDAZduuNfekWG87ibtFxi59Bq+oI9M=\ngithub.com/spf13/viper v1.2.1/go.mod h1:P4AexN0a+C9tGAnUFNwDMYYZv3pjFuvmeiMyKRaNVlI=\ngithub.com/stretchr/testify v1.2.2 h1:bSDNvY7ZPG5RlJ8otE/7V6gMiyenm9RtJ7IUVIAoJ1w=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/toqueteos/webbrowser v0.0.0-20150720201625-21fc9f95c834 h1:50zdZDIkpLHFgs1Kirqz44KPbrR75pHSF6V9PTIEfgs=\ngithub.com/toqueteos/webbrowser v0.0.0-20150720201625-21fc9f95c834/go.mod h1:Hqqqmzj8AHn+VlZyVjaRWY20i25hoOZGAABCcg2el4A=\ngithub.com/uber-go/atomic v1.3.2 h1:Azu9lPBWRNKzYXSIwRfgRuDuS0YKsK4NFhiQv98gkxo=\ngithub.com/uber-go/atomic v1.3.2/go.mod h1:/Ct5t2lcmbJ4OSe/waGBoaVvVqtO0bmtfVNex1PFV8g=\ngithub.com/uber/jaeger-client-go v2.15.0+incompatible h1:NP3qsSqNxh8VYr956ur1N/1C1PjvOJnJykCzcD5QHbk=\ngithub.com/uber/jaeger-client-go v2.15.0+incompatible/go.mod h1:WVhlPFC8FDjOFMMWRy2pZqQJSXxYSwNYOkTr/Z6d3Kk=\ngithub.com/uber/jaeger-lib v1.5.0 h1:OHbgr8l656Ub3Fw5k9SWnBfIEwvoHQ+W2y+Aa9D1Uyo=\ngithub.com/uber/jaeger-lib v1.5.0/go.mod h1:ComeNDZlWwrWnDv8aPp0Ba6+uUTzImX/AauajbLI56U=\ngithub.com/urfave/negroni v1.0.0 h1:kIimOitoypq34K7TG7DUaJ9kq/N4Ofuwi1sjz0KipXc=\ngithub.com/urfave/negroni v1.0.0/go.mod h1:Meg73S6kFm/4PpbYdq35yYWoCZ9mS/YSx+lKnmiohz4=\ngithub.com/xtgo/uuid v0.0.0-20140804021211-a0b114877d4c h1:3lbZUMbMiGUW/LMkfsEABsc5zNT9+b1CvsJx47JzJ8g=\ngithub.com/xtgo/uuid v0.0.0-20140804021211-a0b114877d4c/go.mod h1:UrdRz5enIKZ63MEE3IF9l2/ebyx59GyGgPi+tICQdmM=\ngithub.com/ziutek/mymysql v1.5.4 h1:GB0qdRGsTwQSBVYuVShFBKaXSnSnYYC2d9knnE1LHFs=\ngithub.com/ziutek/mymysql v1.5.4/go.mod h1:LMSpPZ6DbqWFxNCHW77HeMg9I646SAhApZ/wKdgO/C0=\ngo.opencensus.io v0.15.0/go.mod h1:UffZAU+4sDEINUGP/B7UfBBkq4fqLu9zXAX7ke6CHW0=\ngo.opencensus.io v0.18.0 h1:Mk5rgZcggtbvtAun5aJzAtjKKN/t0R3jJPlWILlv938=\ngo.opencensus.io v0.18.0/go.mod h1:vKdFvxhtzZ9onBp9VKHK8z/sRpBMnKAsufL7wlDrCOA=\ngo.uber.org/atomic v1.3.2 h1:2Oa65PReHzfn29GpvgsYwloV9AVFHPDk8tYxt2c2tr4=\ngo.uber.org/atomic v1.3.2/go.mod h1:gD2HeocX3+yG+ygLZcrzQJaqmWj9AIm7n08wl/qW/PE=\ngolang.org/x/crypto v0.0.0-20180830192347-182538f80094 h1:rVTAlhYa4+lCfNxmAIEOGQRoD23UqP72M3+rSWVGDTg=\ngolang.org/x/crypto v0.0.0-20180830192347-182538f80094/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20180904163835-0709b304e793/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20181001203147-e3636079e1a4 h1:Vk3wNqEZwyGyei9yq5ekj7frek2u7HUfffJ1/opblzc=\ngolang.org/x/crypto v0.0.0-20181001203147-e3636079e1a4/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9 h1:mKdxBk7AujPs8kU4m80U72y/zjbZ3UcXC7dClwKbUI0=\ngolang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/net v0.0.0-20180530234432-1e491301e022/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180611182652-db08ff08e862 h1:JZi6BqOZ+iSgmLWe6llhGrNnEnK+YB/MRkStwnEfbqM=\ngolang.org/x/net v0.0.0-20180611182652-db08ff08e862/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181005035420-146acd28ed58 h1:otZG8yDCO4LVps5+9bxOeNiCvgmOyt96J3roHTYs7oE=\ngolang.org/x/net v0.0.0-20181005035420-146acd28ed58/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181023162649-9b4f9f5ad519 h1:x6rhz8Y9CjbgQkccRGmELH6K+LJj7tOoh3XWeC1yaQM=\ngolang.org/x/net v0.0.0-20181023162649-9b4f9f5ad519/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181029044818-c44066c5c816 h1:mVFkLpejdFLXVUv9E42f3XJVfMdqd0IVLVIVLjZWn5o=\ngolang.org/x/net v0.0.0-20181029044818-c44066c5c816/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/oauth2 v0.0.0-20180603041954-1e0a3fa8ba9a/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20181003184128-c57b0facaced h1:4oqSq7eft7MdPKBGQK11X9WYUxmj6ZLgGTqYIbY1kyw=\ngolang.org/x/oauth2 v0.0.0-20181003184128-c57b0facaced/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f h1:wMNYb4v58l5UBM7MYRLPG6ZhfOqbKu7X5eyFl8ZhKvA=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sys v0.0.0-20180831094639-fa5fdf94c789/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180906133057-8cf3aee42992/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e h1:o3PsSEY8E4eXWkXrIP9YJALUkVZqzHJT5DOasTyn8Vs=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/text v0.3.0 h1:g61tztE5qeGQ89tm6NTjjM9VPIm088od1l6aSorWRWg=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/time v0.0.0-20180412165947-fbb02b2291d2 h1:+DCIGbF/swA92ohVg0//6X2IVY3KZs6p9mix0ziNYJM=\ngolang.org/x/time v0.0.0-20180412165947-fbb02b2291d2/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngoogle.golang.org/api v0.0.0-20180603000442-8e296ef26005/go.mod h1:4mhQ8q/RsB7i+udVvVy5NUi08OU8ZlA0gRVgrF7VFY0=\ngoogle.golang.org/api v0.0.0-20180910000450-7ca32eb868bf h1:rjxqQmxjyqerRKEj+tZW+MCm4LgpFXu18bsEoCMgDsk=\ngoogle.golang.org/api v0.0.0-20180910000450-7ca32eb868bf/go.mod h1:4mhQ8q/RsB7i+udVvVy5NUi08OU8ZlA0gRVgrF7VFY0=\ngoogle.golang.org/appengine v1.0.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.2.0 h1:S0iUepdCWODXRvtE+gcRDd15L+k+k1AiHlMiMjefH24=\ngoogle.golang.org/appengine v1.2.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/genproto v0.0.0-20180601223552-81158efcc9f2/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20180831171423-11092d34479b h1:lohp5blsw53GBXtLyLNaTXPXS9pJ1tiTw61ZHUoE9Qw=\ngoogle.golang.org/genproto v0.0.0-20180831171423-11092d34479b/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/grpc v1.12.0/go.mod h1:yo6s7OP7yaDglbqo1J04qKzAhqBH6lvTonzMVmEdcZw=\ngoogle.golang.org/grpc v1.14.0 h1:ArxJuB1NWfPY6r9Gp9gqwplT0Ge7nqv9msgu03lHLmo=\ngoogle.golang.org/grpc v1.14.0/go.mod h1:yo6s7OP7yaDglbqo1J04qKzAhqBH6lvTonzMVmEdcZw=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 h1:qIbj1fsPNlZgppZ+VLlY7N33q108Sa+fhmuc+sWQYwY=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/gorp.v1 v1.7.1 h1:GBB9KrWRATQZh95HJyVGUZrWwOPswitEYEyqlK8JbAA=\ngopkg.in/gorp.v1 v1.7.1/go.mod h1:Wo3h+DBQZIxATwftsglhdD/62zRFPhGhTiu5jUJmCaw=\ngopkg.in/resty.v1 v1.9.1 h1:Lq4EIBZ5e2J4ZWp22W2hVOYc0X1qwDDki/nNVchRbdw=\ngopkg.in/resty.v1 v1.9.1/go.mod h1:vo52Hzryw9PnPHcJfPsBiFW62XhNx5OczbV9y+IMpgc=\ngopkg.in/square/go-jose.v2 v2.1.9 h1:YCFbL5T2gbmC2sMG12s1x2PAlTK5TZNte3hjZEIcCAg=\ngopkg.in/square/go-jose.v2 v2.1.9/go.mod h1:M9dMgbHiYLoDGQrXy7OpJDJWiKiU//h+vD76mk0e1AI=\ngopkg.in/yaml.v1 v1.0.0-20140924161607-9f9df34309c0 h1:POO/ycCATvegFmVuPpQzZFJ+pGZeX22Ufu6fibxDVjU=\ngopkg.in/yaml.v1 v1.0.0-20140924161607-9f9df34309c0/go.mod h1:WDnlLJ4WF5VGsH/HVa3CI79GS0ol3YnhVnKP89i0kNg=\ngopkg.in/yaml.v2 v2.2.1 h1:mUhvW9EsL+naU5Q3cakzfE91YhliOondGd6ZrsDBHQE=\ngopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngotest.tools v2.1.0+incompatible h1:5USw7CrJBYKqjg9R7QlA6jzqZKEAtvW82aNmsxxGPxw=\ngotest.tools v2.1.0+incompatible/go.mod h1:DsYFclhRJ6vuDpmuTbkuFWG+y2sxOXAzmJt81HFBacw=\n[localhost hydra]$cat go.mod \nmodule github.com/ory/hydra\nrequire (\n    github.com/dgrijalva/jwt-go v3.2.0+incompatible\n    github.com/go-sql-driver/mysql v1.4.0\n    github.com/gobuffalo/packd v0.0.0-20181029140631-cf76bd87a5a6 // indirect\n    github.com/gobwas/glob v0.2.3\n    github.com/golang/mock v1.1.1\n    github.com/gorilla/context v1.1.1\n    github.com/gorilla/securecookie v0.0.0-20160422134519-667fe4e3466a\n    github.com/gorilla/sessions v0.0.0-20160922145804-ca9ada445741\n    github.com/gtank/cryptopasta v0.0.0-20170601214702-1f550f6f2f69\n    github.com/imdario/mergo v0.0.0-20171009183408-7fe0c75c13ab\n    github.com/jmoiron/sqlx v0.0.0-20180614180643-0dae4fefe7c0\n    github.com/julienschmidt/httprouter v0.0.0-20180715161854-348b672cd90d\n    github.com/lib/pq v1.0.0\n    github.com/meatballhat/negroni-logrus v0.0.0-20170801195057-31067281800f\n    github.com/mendsley/gojwk v0.0.0-20141217222730-4d5ec6e58103\n    github.com/mohae/deepcopy v0.0.0-20170929034955-c48cc78d4826\n    github.com/oleiade/reflections v1.0.0\n    github.com/opentracing/opentracing-go v1.0.2\n    github.com/ory/dockertest v3.3.2+incompatible\n    github.com/ory/fosite v0.28.0\n    github.com/ory/go-convenience v0.1.0\n    github.com/ory/graceful v0.1.0\n    github.com/ory/herodot v0.4.1\n    github.com/ory/sqlcon v0.0.7\n    github.com/ory/x v0.0.33\n    github.com/pborman/uuid v1.2.0\n    github.com/phayes/freeport v0.0.0-20171002181615-b8543db493a5\n    github.com/pkg/errors v0.8.0\n    github.com/prometheus/client_golang v0.8.0\n    github.com/rs/cors v1.6.0\n    github.com/rubenv/sql-migrate v0.0.0-20180704111356-ba2c6a7295c59448dbc195cef2f41df5163b3892\n    github.com/sirupsen/logrus v1.1.1\n    github.com/spf13/cobra v0.0.3\n    github.com/spf13/viper v1.2.1\n    github.com/stretchr/testify v1.2.2\n    github.com/toqueteos/webbrowser v0.0.0-20150720201625-21fc9f95c834\n    github.com/uber-go/atomic v1.3.2 // indirect\n    github.com/uber/jaeger-client-go v2.15.0+incompatible\n    github.com/urfave/negroni v1.0.0\n    github.com/ziutek/mymysql v1.5.4 // indirect\n    go.uber.org/atomic v1.3.2 // indirect\n    golang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9\n    golang.org/x/net v0.0.0-20181029044818-c44066c5c816 // indirect\n    golang.org/x/oauth2 v0.0.0-20181003184128-c57b0facaced\n    gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 // indirect\n    gopkg.in/resty.v1 v1.9.1\n    gopkg.in/square/go-jose.v2 v2.1.9\n    gopkg.in/yaml.v1 v1.0.0-20140924161607-9f9df34309c0\n)\n[localhost hydra]$sudo docker-compose -p hydra up --build -d\nBuilding hydra-migrate\nStep 1/17 : FROM golang:1.11.4-alpine\n ---> f56365ec0638\nStep 2/17 : ARG git_tag\n ---> Using cache\n ---> 39026b0993c4\nStep 3/17 : ARG git_commit\n ---> Using cache\n ---> 27537281cc16\nStep 4/17 : RUN apk add --no-cache git build-base\n ---> Using cache\n ---> 628780d7d65b\nStep 5/17 : WORKDIR /go/src/github.com/ory/hydra\n ---> Using cache\n ---> 6a23d2ddfff2\nStep 6/17 : ENV GO111MODULE=on\n ---> Using cache\n ---> 699388cf88d6\nStep 7/17 : ADD ./go.mod ./go.mod\n ---> Using cache\n ---> d3eab4c7840c\nStep 8/17 : ADD ./go.sum ./go.sum\n ---> Using cache\n ---> e712ec7087ea\nStep 9/17 : RUN go mod download\n ---> Running in 7156229c45f7\ngo: finding github.com/phayes/freeport v0.0.0-20171002181615-b8543db493a5\ngo: finding github.com/ory/graceful v0.1.0\ngo: finding github.com/mohae/deepcopy v0.0.0-20170929034955-c48cc78d4826\ngo: finding github.com/gobwas/glob v0.2.3\ngo: finding github.com/ory/dockertest v3.3.2+incompatible\ngo: finding github.com/ory/go-convenience v0.1.0\ngo: finding github.com/urfave/negroni v1.0.0\ngo: finding github.com/sirupsen/logrus v1.1.1\ngo: finding golang.org/x/net v0.0.0-20181029044818-c44066c5c816\ngo: finding golang.org/x/oauth2 v0.0.0-20181003184128-c57b0facaced\ngo: finding github.com/go-sql-driver/mysql v1.4.0\ngo: finding github.com/rs/cors v1.6.0\ngo: finding golang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9\ngo: finding github.com/lib/pq v1.0.0\ngo: finding go.uber.org/atomic v1.3.2\ngo: finding github.com/gtank/cryptopasta v0.0.0-20170601214702-1f550f6f2f69\ngo: finding github.com/toqueteos/webbrowser v0.0.0-20150720201625-21fc9f95c834\ngo: finding github.com/uber-go/atomic v1.3.2\ngo: finding github.com/prometheus/client_golang v0.8.0\ngo: finding golang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33\ngo: finding github.com/ory/herodot v0.4.1\ngo: finding github.com/pborman/uuid v1.2.0\ngo: finding github.com/uber/jaeger-client-go v2.15.0+incompatible\ngo: finding github.com/golang/mock v1.1.1\ngo: finding github.com/pkg/errors v0.8.0\ngo: finding gopkg.in/yaml.v1 v1.0.0-20140924161607-9f9df34309c0\ngo: finding github.com/mendsley/gojwk v0.0.0-20141217222730-4d5ec6e58103\ngo: finding github.com/julienschmidt/httprouter v0.0.0-20180715161854-348b672cd90d\ngo: finding github.com/gorilla/mux v1.6.2\ngo: finding github.com/ory/sqlcon v0.0.7\ngo: finding golang.org/x/crypto v0.0.0-20180830192347-182538f80094\ngo: finding github.com/gorilla/context v1.1.1\ngo: finding github.com/dgrijalva/jwt-go v3.2.0+incompatible\ngo: finding github.com/google/uuid v1.0.0\ngo: finding github.com/pmezard/go-difflib v1.0.0\ngo: finding github.com/jmoiron/sqlx v0.0.0-20180614180643-0dae4fefe7c0\ngo: finding github.com/spf13/viper v1.2.1\ngo: finding github.com/meatballhat/negroni-logrus v0.0.0-20170801195057-31067281800f\ngo: finding github.com/ory/x v0.0.33\ngo: finding gopkg.in/square/go-jose.v2 v2.1.9\ngo: finding github.com/oleiade/reflections v1.0.0\ngo: finding github.com/davecgh/go-spew v1.1.1\ngo: finding github.com/rubenv/sql-migrate v0.0.0-20180704111356-ba2c6a7295c59448dbc195cef2f41df5163b3892\ngo: finding github.com/sirupsen/logrus v1.0.6\ngo: finding github.com/opentracing/opentracing-go v1.0.2\ngo: finding github.com/stretchr/testify v1.2.2\ngo: finding golang.org/x/text v0.3.0\ngo: finding github.com/magiconair/properties v1.8.0\ngo: finding github.com/golang/gddo v0.0.0-20180828051604-96d2a289f41e\ngo: finding golang.org/x/crypto v0.0.0-20180904163835-0709b304e793\ngo: finding github.com/Azure/go-ansiterm v0.0.0-20170929234023-d6e3b3328b78\ngo: finding gopkg.in/yaml.v2 v2.2.1\ngo: finding github.com/segmentio/backo-go v0.0.0-20160424052352-204274ad699c\ngo: finding go.opencensus.io v0.18.0\ngo: finding github.com/gorilla/securecookie v0.0.0-20160422134519-667fe4e3466a\ngo: finding github.com/spf13/afero v1.1.2\ngo: finding github.com/spf13/cast v1.2.0\ngo: finding github.com/uber/jaeger-lib v1.5.0\ngo: finding golang.org/x/sys v0.0.0-20180831094639-fa5fdf94c789\ngo: finding golang.org/x/time v0.0.0-20180412165947-fbb02b2291d2\ngo: finding contrib.go.opencensus.io/exporter/stackdriver v0.7.0\ngo: finding gopkg.in/resty.v1 v1.9.1\ngo: finding github.com/gobuffalo/packd v0.0.0-20181029140631-cf76bd87a5a6\ngo: finding github.com/kr/pretty v0.1.0\ngo: finding golang.org/x/crypto v0.0.0-20181001203147-e3636079e1a4\ngo: finding github.com/mitchellh/mapstructure v1.0.0\ngo: finding github.com/ory/fosite v0.28.0\ngo: finding github.com/gotestyourself/gotestyourself v2.1.0+incompatible\ngo: finding github.com/containerd/continuity v0.0.0-20181003075958-be9bd761db19\ngo: finding github.com/hashicorp/hcl v1.0.0\ngo: finding cloud.google.com/go v0.31.0\ngo: finding github.com/matttproud/golang_protobuf_extensions v1.0.1\ngo: finding gotest.tools v2.1.0+incompatible\ngo: finding github.com/google/martian v2.1.0+incompatible\ngo: finding github.com/prometheus/common v0.0.0-20180801064454-c7de2306084e\ngo: finding github.com/bmizerany/assert v0.0.0-20160611221934-b7ed37b82869\ngo: finding github.com/Microsoft/go-winio v0.4.11\ngo: finding github.com/spf13/pflag v1.0.2\ngo: finding github.com/BurntSushi/toml v0.3.1\ngo: finding github.com/opencontainers/runc v0.1.1\ngo: finding google.golang.org/api v0.0.0-20180910000450-7ca32eb868bf\ngo: finding gopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405\ngo: finding golang.org/x/oauth2 v0.0.0-20180603041954-1e0a3fa8ba9a\ngo: finding golang.org/x/net v0.0.0-20180906233101-161cd47e91fd\ngo: finding github.com/gorilla/sessions v0.0.0-20160922145804-ca9ada445741\ngo: finding golang.org/x/net v0.0.0-20180611182652-db08ff08e862\ngo: finding github.com/mattn/go-sqlite3 v1.9.0\ngo: finding github.com/Nvveen/Gotty v0.0.0-20120604004816-cd527374f1e5\ngo: finding golang.org/x/net v0.0.0-20181005035420-146acd28ed58\ngo: finding github.com/luna-duclos/instrumentedsql v0.0.0-20181127104832-b7d587d28109\ngo: finding github.com/cenkalti/backoff v2.0.0+incompatible\ngo: finding github.com/elazarl/goproxy v0.0.0-20181003060214-f58a169a71a5\ngo: finding golang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f\ngo: finding github.com/docker/go-connections v0.4.0\ngo: finding github.com/googleapis/gax-go v2.0.0+incompatible\ngo: finding golang.org/x/net v0.0.0-20180530234432-1e491301e022\ngo: finding github.com/jtolds/gls v4.2.1+incompatible\ngo: finding github.com/docker/go-units v0.3.3\ngo: finding gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127\ngo: finding github.com/spf13/cobra v0.0.3\ngo: finding github.com/prometheus/procfs v0.0.0-20180725123919-05ee40e3a273\ngo: finding github.com/spf13/jwalterweatherman v1.0.0\ngo: finding github.com/grpc-ecosystem/grpc-gateway v1.5.0\ngo: finding github.com/google/go-cmp v0.2.0\ngo: finding github.com/gobuffalo/packr v1.16.0\ngo: finding golang.org/x/sys v0.0.0-20180909124046-d0be0721c37e\ngo: finding github.com/golang/glog v0.0.0-20160126235308-23def4e6c14b\ngo: finding github.com/kr/text v0.1.0\ngo: finding github.com/codahale/hdrhistogram v0.0.0-20161010025455-3a0bb77429bd\ngo: finding github.com/konsorten/go-windows-terminal-sequences v0.0.0-20180402223658-b729f2633dfe\ngo: finding github.com/fsnotify/fsnotify v1.4.7\ngo: finding google.golang.org/genproto v0.0.0-20180831171423-11092d34479b\ngo: finding git.apache.org/thrift.git v0.0.0-20180902110319-2566ecd5d999\ngo: finding github.com/gobuffalo/envy v1.6.7\ngo: finding golang.org/x/sys v0.0.0-20180906133057-8cf3aee42992\ngo: finding github.com/golang/protobuf v1.1.0\ngo: finding google.golang.org/grpc v1.14.0\ngo: finding github.com/gobuffalo/packd v0.0.0-20181028162033-6d52e0eabf41\ngo: finding github.com/xtgo/uuid v0.0.0-20140804021211-a0b114877d4c\ngo: finding google.golang.org/appengine v1.2.0\ngo: finding github.com/markbates/oncer v0.0.0-20181014194634-05fccaae8fc4\ngo: finding github.com/rubenv/sql-migrate v0.0.0-20180704111356-3f452fc0ebeb\ngo: finding google.golang.org/grpc v1.12.0\ngo: finding github.com/ory/fosite v0.25.0\ngo: finding github.com/gopherjs/gopherjs v0.0.0-20181004151105-1babbf986f6f\ngo: finding go.opencensus.io v0.15.0\ngo: finding google.golang.org/appengine v1.0.0\ngo: finding github.com/joho/godotenv v1.3.0\ngo: finding github.com/ghodss/yaml v1.0.0\ngo: finding github.com/aws/aws-sdk-go v1.15.31\ngo: finding google.golang.org/api v0.0.0-20180603000442-8e296ef26005\ngo: finding github.com/smartystreets/assertions v0.0.0-20180927180507-b2de0cb4f26d\ngo: finding github.com/golang/protobuf v1.2.0\ngo: finding github.com/spf13/pflag v1.0.3\ngo: finding cloud.google.com/go v0.23.0\ngo: finding github.com/segmentio/analytics-go v3.0.1+incompatible\ngo: finding github.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910\ngo: finding github.com/pkg/profile v1.2.1\ngo: finding google.golang.org/genproto v0.0.0-20180601223552-81158efcc9f2\ngo: finding github.com/pelletier/go-toml v1.2.0\ngo: finding github.com/opencontainers/go-digest v1.0.0-rc1\ngo: finding github.com/opencontainers/image-spec v1.0.1\ngo: finding github.com/smartystreets/goconvey v0.0.0-20180222194500-ef6db91d284a\ngo: finding github.com/parnurzeal/gorequest v0.2.15\ngo: finding github.com/beorn7/perks v0.0.0-20180321164747-3a771d992973\ngo: finding github.com/moul/http2curl v0.0.0-20170919181001-9ac6cf4d929b\ngo: finding github.com/openzipkin/zipkin-go v0.1.1\ngo: finding github.com/imdario/mergo v0.0.0-20171009183408-7fe0c75c13ab\ngo: finding github.com/asaskevich/govalidator v0.0.0-20180720115003-f9ffefc3facf\ngo: finding golang.org/x/net v0.0.0-20180724234803-3673e40ba225\ngo: finding github.com/kr/pty v1.1.1\ngo: finding github.com/inconshreveable/mousetrap v1.0.0\ngo: finding golang.org/x/net v0.0.0-20181023162649-9b4f9f5ad519\ngo: finding github.com/ziutek/mymysql v1.5.4\ngo: finding gopkg.in/gorp.v1 v1.7.1\ngo: finding github.com/jmespath/go-jmespath v0.0.0-20160202185014-0b12d6b521d8\ngo: finding github.com/go-ini/ini v1.25.4\nRemoving intermediate container 7156229c45f7\n ---> f207ceb74d5b\nStep 10/17 : ADD . .\n ---> e038ddd126b0\nStep 11/17 : RUN go mod verify\n ---> Running in 14dbb71f38f3\nall modules verified\nRemoving intermediate container 14dbb71f38f3\n ---> ee7e6b4fbbd1\nStep 12/17 : RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags \"-s -X github.com/ory/hydra/cmd.Version=$git_tag -X github.com/ory/hydra/cmd.BuildTime=TZ=UTC date -u '+%Y-%m-%dT%H:%M:%SZ' -X github.com/ory/hydra/cmd.GitHash=$git_commit\" -a -installsuffix cgo -o hydra\n ---> Running in 29a50786a61d\nRemoving intermediate container 29a50786a61d\n ---> 9c165a1a235a\nStep 13/17 : FROM scratch\n ---> \nStep 14/17 : COPY --from=0 /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/\n ---> 245af4d0cae1\nStep 15/17 : COPY --from=0 /go/src/github.com/ory/hydra/hydra /usr/bin/hydra\n ---> c6aa4744a35a\nStep 16/17 : ENTRYPOINT [\"hydra\"]\n ---> Running in aece328d97e6\nRemoving intermediate container aece328d97e6\n ---> 827e9cb5aabf\nStep 17/17 : CMD [\"serve\", \"all\"]\n ---> Running in 1e044a7a162e\nRemoving intermediate container 1e044a7a162e\n ---> 474e5171f349\nSuccessfully built 474e5171f349\nSuccessfully tagged hydra_hydra-migrate:latest\nBuilding hydra\nStep 1/17 : FROM golang:1.11.4-alpine\n ---> f56365ec0638\nStep 2/17 : ARG git_tag\n ---> Using cache\n ---> 39026b0993c4\nStep 3/17 : ARG git_commit\n ---> Using cache\n ---> 27537281cc16\nStep 4/17 : RUN apk add --no-cache git build-base\n ---> Using cache\n ---> 628780d7d65b\nStep 5/17 : WORKDIR /go/src/github.com/ory/hydra\n ---> Using cache\n ---> 6a23d2ddfff2\nStep 6/17 : ENV GO111MODULE=on\n ---> Using cache\n ---> 699388cf88d6\nStep 7/17 : ADD ./go.mod ./go.mod\n ---> Using cache\n ---> d3eab4c7840c\nStep 8/17 : ADD ./go.sum ./go.sum\n ---> Using cache\n ---> e712ec7087ea\nStep 9/17 : RUN go mod download\n ---> Using cache\n ---> f207ceb74d5b\nStep 10/17 : ADD . .\n ---> Using cache\n ---> e038ddd126b0\nStep 11/17 : RUN go mod verify\n ---> Using cache\n ---> ee7e6b4fbbd1\nStep 12/17 : RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags \"-s -X github.com/ory/hydra/cmd.Version=$git_tag -X github.com/ory/hydra/cmd.BuildTime=TZ=UTC date -u '+%Y-%m-%dT%H:%M:%SZ' -X github.com/ory/hydra/cmd.GitHash=$git_commit\" -a -installsuffix cgo -o hydra\n ---> Using cache\n ---> 9c165a1a235a\nStep 13/17 : FROM scratch\n ---> \nStep 14/17 : COPY --from=0 /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/\n ---> Using cache\n ---> 245af4d0cae1\nStep 15/17 : COPY --from=0 /go/src/github.com/ory/hydra/hydra /usr/bin/hydra\n ---> Using cache\n ---> c6aa4744a35a\nStep 16/17 : ENTRYPOINT [\"hydra\"]\n ---> Using cache\n ---> 827e9cb5aabf\nStep 17/17 : CMD [\"serve\", \"all\"]\n ---> Using cache\n ---> 474e5171f349\nSuccessfully built 474e5171f349\nSuccessfully tagged hydra_hydra:latest\nPulling consent (oryd/hydra-login-consent-node:v1.0.0-rc.5)...\nv1.0.0-rc.5: Pulling from oryd/hydra-login-consent-node\n8e3ba11ec2a2: Pull complete\nfa1fb33fda79: Pull complete\nc3fd48190d00: Pull complete\nb3d91f58a68b: Pull complete\naee5f82fee0d: Pull complete\nCreating hydra_postgresd_1     ... done\nDigest: sha256:f1f564e10eb315bd6c01cfcd3ec2fa0b17e346b0beb19de684e09fdfcc187a38\nCreating hydra_hydra-migrate_1 ... done\nCreating hydra_postgresd_1     ... \nCreating hydra_hydra_1         ... done\nCreating hydra_hydra_1         ... \nCreating hydra_consent_1       ... done\n[localhost hydra]$\nI don't know the reason, it may bego mod tidy`` may require time to resolve the dependency.\nAnyway Thank you aeneasr for your help.. ",
    "svett": "It's very early version. I don't even have tests. Let me add good tests coverage prior to forking it. Also I may move it into separate repository dedicated to hydra. It's up to you.. ",
    "RomanMinkin": "Thank you @aeneasr !. ",
    "lopezator": "I think it fits better in another PR, but would you be open to a migration to v3? It's much cleaner.. Sorry, I deleted/closed this without intention.. You can merge to correct the bug if you wish and I'll send the update to v3, sometime in the next week in an other PR.\nOr directly close, whatever you prefer/consider cleaner.. ",
    "blazed": "Shouldn't this be a GET request? (https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfigurationRequest). ",
    "jayme-github": "httpRouter panics when trying to register a path twice.. "
}