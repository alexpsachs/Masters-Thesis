{
    "bolinfest": "@rowillia Even with a buck init command or something, I think it's still important to have readable documentation that can help people see how everything fits together. I'll reopen and assign to myself.\n. The Quick Start is deliberately light on details that would be considered distracting. If you are checking out a project from GitHub, presumably you have some familiarity with Git.\nThe more detailed instructions at http://facebook.github.io/buck/setup/install.html already list Git as a requirement.\nFinally, we are likely switching to Jython so that Buck will not be required to run \"unpacked,\" in which case both Git and Python will go away as requirements.\n. @dreiss Does this meet your/our needs? I'm on mobile so I can't\ninvestigate, but my hypothesis is no.\nOn May 19, 2014 1:44 PM, \"Shawn Wilsher\" notifications@github.com wrote:\n\nClosed #3 https://github.com/facebook/buck/issues/3.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/3#event-122590875\n.\n. Closed by https://github.com/facebook/buck/commit/e7bd3e573be673f69ecb4c122db3fa571b4b57ec\n. Fixed by 98484ddbca1f1a3f3c765a1c83c9fdf634b734da.\n. Thanks for filing: this is definitely an oversight on our part. Buck is meant to be able to support \"pure Java\" projects, as well as Android projects.\n. I have a fix for this internally, but I'm waiting for a code review :(\n\nOn Wed, May 1, 2013 at 10:02 AM, Shawn O. Pearce\nnotifications@github.comwrote:\n\nIf you are interested in looking at a real world pure Java project's usage\nof Buck, see\nhttps://gerrit.googlesource.com/gerrit/+/57a4d597cd1111ebabf9bbf495ecd45324e7acddas it contains a complete, non-trivial \"pure Java\" project build system\nalongside of the existing Maven build.\nI unfortunately had to use 22 genrules() to provide a number of hacks for\nfeatures missing from Buck. The worst hack of all was committing\nlocal.properties to work around the Android SDK. :-)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/7#issuecomment-17292098\n.\n. Fixed:\nhttps://github.com/facebook/buck/commit/ef014b357fa3c9adf3d517fcbcfe0ef5b18ab3c0\n. Hi Shawn, we're just getting started with our contributor workflow for Buck. I consulted with our legal team, and all contributors have to digitally sign our CLA, so could you please let me know when you've done that https://developers.facebook.com/opensource/cla\n\nThanks!\nMichael\n. Should we reopen this assuming we get the CLA stuff figured out?\n. I'm told we updated the CLA: PTAL?\n. Why was this pull request closed?\n. As a quick fix, try running:\nbuck audit classpath --dot \nI often write the stdout to a file and then do some textual searching in there to figure this out.\n. This is a known issue and it does need to get fixed; HOWEVER, I would also consider these downsides about data-driven tests:\nhttp://googletesting.blogspot.com/2008/09/tott-data-driven-traps.html\nGenerally, you're better off avoiding @Parameters, but we should still make Buck a fully-compliant JUnit test runner.\n. Fixed in https://github.com/facebook/buck/commit/04d334d3e1bb253c70f4956b3b6193c8847ca96b.\n. This commit removes the mention of the jar:\nhttps://github.com/facebook/buck/commit/a5c89c7c612fcd64124eeab2c2460705c8265913\nYou could (and should!) programmatically request the location of the outputs using buck targets --show_output:\nhttp://facebook.github.io/buck/command/targets.html\n. Hi Shawn, sorry, I know it has been awhile. Are all of these commits up-to-date? That is, are they based off a relatively recent version of Buck? If so, I'll start cranking through them.\n. Since I can't tell from GitHub's UI: which is the first diff in this stack? Is it \"Reset compressed size...\" or \"include source of duplicate path...\"?\n. Ah, I believe \"Reset compressed size when combining JAR/ZIP archives\" is the first one given that its parent is \"Convert AndroidManifestRule to a Buildable (AndroidManifest).\"?\n. I accepted three of these so far:\nhttps://github.com/facebook/buck/commit/a4fa69137e085b5ec36729074671a0bd9556c436\nhttps://github.com/facebook/buck/commit/2aef43194c808b25034ce15fe4b9f32e1d3c78c7\nhttps://github.com/facebook/buck/commit/a9ae26136e8def54c682977dfa82f8938f707186\n. Fixed by https://github.com/facebook/buck/commit/4c5ff21ab6bb1dad6c336b9c8d833e90cfef0868.\n. @spearce Is this on Mac or Linux? And with an encrypted hard drive or not encrypted?\n. Fixed! 1023858a6a702a91269bdc82b0111daab78124a7\n. Actually, I believe it should just be:\ncmd = 'python basic_to_full_manifest.py AndroidManifest.xml'\nis that not working for you?\n. Ah, yes, now I am feeling your pain. I just made it possible to build the Closure Compiler using Buck, and I had to do some hacky things, as well (see  /closure/closure-compiler/BUCK):\nhttp://code.google.com/p/plovr/source/detail?r=50a647db8b87f361efcf382491790f0a582ce49f\n. I believe this is fixed now: http://facebook.github.io/buck/rule/genrule.html\nThough the section on deps mentions the old curly-brace pattern, but I'll send out a fix for that now.\n. https://github.com/facebook/buck/commit/a9ae26136e8def54c682977dfa82f8938f707186\n. @nickpalmer We fixed your specific case with a custom rule that does smart things: http://facebook.github.io/buck/rule/android_build_config.html\n. @nickpalmer We fixed your specific case with a custom rule that does smart things: http://facebook.github.io/buck/rule/android_build_config.html\n. Don't assume: I'm pretty sure this is not fixed. Read the note about\nIntelliJ bugs at the bottom of the quick start docs.\nOn May 19, 2014 1:31 PM, \"Shawn Wilsher\" notifications@github.com wrote:\n\nClosed #23 https://github.com/facebook/buck/issues/23.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/23#event-122585400\n.\n. I think the crux of the bug is: project created by buck quickstart does\nnot import cleanly into IntelliJ and does not build.\nOn May 19, 2014 1:56 PM, \"Shawn Wilsher\" notifications@github.com wrote:\n@bolinfest https://github.com/bolinfest I saw those, but it didn't look\nat all related to what @mkurutin https://github.com/mkurutin or\n@BrianBal https://github.com/BrianBal listed as issues.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/23#issuecomment-43542268\n.\n. https://github.com/facebook/buck/commit/2fb0fce8b878b1c3d6883c31189bb2b4cd761c30 fixes this if you have been updating your SDK by running android sdk. If you downloaded a fresh SDK from the web site, then you will need another fix that is currently pending.\n. Fixed by https://github.com/facebook/buck/commit/8c597fb8bccadb937ee7b09d7b719f031a4d0a18.\n. We deliberately do not do this because we create temporary values that we do not want to risk being inlined.\n\nThe only case where I have seen this matter is when you want to use a field of R.java as an annotation. It's lame, but you can do:\nprivate static final String MY_ID = R.id.the_id;\nand then use MY_ID as the annotation value.\nAlso, why did you close this?\n. This is not the way to fix this: I have a real fix coming. This is effectively the same issue as https://github.com/facebook/buck/issues/24.\n. Fixed by https://github.com/facebook/buck/commit/8c597fb8bccadb937ee7b09d7b719f031a4d0a18.\n. I'm not sure what you mean.\nIf you have Java code that does not depend on anything in the Android SDK (i.e., the ordinary JDK), then use a java_library() rule to build that code.\nIf you have Java code that uses classes from the Android SDK, then compile it with an android_library() rule.\nandroid_library() rules can depend on java_library() rules.\n. I believe that you could have everything in one tree. You just might have folders in the root like:\njava/common/\njava/android/\njava/j2se/\nor something like that. The BUCK files in the java/android/ and java/j2se/ folders would reference the ones in java/common/ as deps, assuming the dependencies are only one-way.\nIf the deps are two-way, then I would create a macro for each java_library rule in java/common/ that creates two rules: one that depends on the java/android/ versions of your deps and another that depends on the java/j2se/ versions. So you might have something like:\n```\nDefine this in a DEFS file that you list under includes in .buckconfig:\nhttp://facebook.github.io/buck/concept/buckconfig.html\ndef create_both_versions(name, srcs, deps):\n  for type in ['j2se', 'android']:\n    rule_name = '%s_%s' % (name, type)\n    rule_deps = []\n    for dep in deps:\n      if dep.startswith('//java/XXX'):\n        rule_deps.append(dep.replace('//java/XXX', '//java/XXX' + type))\n      else:\n        rule_deps.append(dep)\n    java_library(\n      name = rule_name,\n      srcs = srcs,\n      deps = rule_deps,\n      visibility = [ 'PUBLIC' ],\n    )\n```\nThen under //java/common/analytics, you might do:\n```\nThis creates both //java/common/analytics:analytics_j2se and\n//java/common/analytics:analytics_android\ncreate_both_versions(\n  name = 'analytics',\n  srcs = glob(['*.java']),\n  deps = [\n    '//java/XXX/base:base',\n  ],\n)\n```\nSo in //java/android/analytics, you can do:\nandroid_library(\n  name = 'analytics',\n  srcs = glob(['*.java']),\n  deps = [\n    '//java/common/analytics:analytics_android',\n  ],\n)\nIt's not exactly how Buck is meant to be used, but it may be a useful workaround for you. Ultimately, we would like to support the idea of \"flavors\" of build rules, which would make this less awkward.\n. This is the expected behavior: javac cannot process .aidl files on its own. For .aidl files, you should be using gen_aidl():\nhttp://facebook.github.io/buck/rule/gen_aidl.html\nAs the documentation mentions, we plan to fix things so that android_library() handles .aidl files. I apologize, as the docs should have an example of how to use it. For now, I'll include one here:\n```\nThis creates IAnalyticsService.java as a genfile.\ngen_aidl(\n  name = 'IAnalyticsService',\n  aidl = 'src/com/facebook/analytics/IAnalyticsService.aidl',\n  import_path = 'src/com/facebook/analytics/',\n)\nandroid_library(\n  name = 'analytics',\n  srcs = glob(['src/*/.java']) + \\\n      # Also include the generated .java files as sources.\n      [genfile(f) for f in [\n          'src/com/facebook/analytics/IAnalyticsService.java']],\n  deps = [\n    ':IAnalyticsService',\n  ],\n  visibility = [\n    'PUBLIC',\n  ],\n)\n```\n. Internally, we have legacy code that writes to buck-bin and buck-gen directories. Up until now, we have kept the public version of Buck clear of this using MOE:begin_strip, but apparently we missed some places.\nI want to assign this to Jim (who is responsible for the buckd stuff), but GitHub doesn't seem to let me do that.\n. I believe this is fixed by 1dbf40725e2d358a559447b04c8a9f7afa49892c where we eliminated the use of buck-bin and buck-gen internally. Please reopen if this is not the case.\n. David: whose legal department?\nOn Jun 20, 2013 2:06 AM, \"David Pursehouse\" notifications@github.com\nwrote:\n\nThe Corporate CLA has been signed, but now I still have to wait for the\nlegal dept to approve this patch :(\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/pull/32#issuecomment-19738822\n.\n. For the record, this is a case where submitting a patch/pull request works against you. I realize that sounds harsh and counterintuitive, but let me explain.\n\nIf you file a bug report with a repro case and no patch, then the team is free to fix it however we like. We can also do it quickly because we do not have to wait for a CLA to get signed, cross-check with legal to make sure it got signed, etc. Further, when the code is created internally first, we can put it through our own submit queue, use our internal review tools (Phabricator is far superior to GitHub, IMHO), and the process goes very quickly.\nIf you file a bug report with a patch, then the first thing I do is freak out a little. In short, I don't want to look at your patch until I know that the CLA has been signed. I don't want to be in a situation where we happen to implement it the same way as you did in your patch without a CLA because then it might look like we \"stole your code\" (or worse, your employer's) without the proper consent in place. I may now be in a position where I am actively avoiding your bug because I am waiting for the CLA.\nThat said, I don't want to discourage people from making contributions to Buck. If you think that we need to do a more serious architectural change, or introduce a new concept, then a pull request is probably the best way to explain what you mean. However, to get a one-line fix into Buck, submitting a patch is probably the worst way. In those cases, it's more effective to report an issue that identifies the problem area and trust that the team is smart enough to fix it than it is to go through the CLA cycle. That said, if you've already signed the CLA, the process will go a lot faster when you submit a patch, but for folks making one-off contributions, the bug report will be more expedient.\nIn many ways, our situation is similar to Guava's as described in https://plus.google.com/113026104107031516488/posts/ZRdtjTL1MpM. (I thought I linked to this in our public docs, but apparently I have not. We don't yet have any public docs on our policy on contributions.)\nLike I said, I realize this sounds harsh, but I am trying to be honest about how things appear from our side. If you look at our issue history on GitHub, I believe we have been pretty quick about closing the issues that have been tagged as bugs (i.e., please give us a chance to fix it before submitting a patch). Though if you are hoping to become a more frequent contributor to Buck, then that's a different story, and all of the overhead of CLAs and pull requests will certainly be worth it in the long-term.\n. It is likely to be accepted, but now you've caught us in the middle of a\npeer review cycle, so not a lot of code being moved around this week.\nOn Jul 11, 2013 6:01 AM, \"David Pursehouse\" notifications@github.com\nwrote:\n\nBTW can you confirm that you've actually received the signed CLA?\nAnd if so, is this patch likely to be accepted?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/pull/32#issuecomment-20801306\n.\n. This does not sound like a good idea to me because it will make it hard for your res/ directory work with other tools. Just move your build rule up a directory and do:\n\nres = 'res',\ninstead.\n. I just pushed a new version of Buck last night: have you pulled?\nOn Jul 24, 2013 7:36 AM, \"Ruenzuo\" notifications@github.com wrote:\n\nI'm having problems with Quick Start, when I try to build the APK I get\nthis:\nRenzos-Mac-mini:my-first-buck-project renzocrisostomo$ buck build //apps/myapp:app\nException in thread \"pool-2-thread-1\" com.facebook.buck.util.HumanReadableException: Unable to parse build file:\nTraceback (most recent call last):\n  File \"",
    "nickpalmer": "You can write this yourself using bucks genrule to generate the required file.\nThe catch is that you have to use genfile to find the file and add it back to the sources and combine the lists, since glob returns an array and srcs expects an array.\n``` python\ngenrule(\n  name = 'BuildConfig',\n  out = 'BuildConfig.java',\n  cmd = 'bash -c \\'echo \"package com.my.package; public final class BuildConfig { public final static boolean DEBUG = false; }\" > $OUT \\' ',\n)\nandroid_library(\n  name = 'my-library',\n  srcs = [genfile('BuildConfig.java')] + glob(['src/*/.java']),\n  deps = [\n    ':BuildConfig',\n  ],\n)\n```\n. You can write this yourself using bucks genrule to generate the required file.\nThe catch is that you have to use genfile to find the file and add it back to the sources and combine the lists, since glob returns an array and srcs expects an array.\n``` python\ngenrule(\n  name = 'BuildConfig',\n  out = 'BuildConfig.java',\n  cmd = 'bash -c \\'echo \"package com.my.package; public final class BuildConfig { public final static boolean DEBUG = false; }\" > $OUT \\' ',\n)\nandroid_library(\n  name = 'my-library',\n  srcs = [genfile('BuildConfig.java')] + glob(['src/*/.java']),\n  deps = [\n    ':BuildConfig',\n  ],\n)\n```\n. This is also an issue for generating BuildConfig.java files. I am currently using:\ngenrule(\n  name = 'BuildConfig',\n  out = 'BuildConfig.java',\n  cmd = 'bash -c \\'echo \"package some.pacakge; public final class BuildConfig { public final static boolean DEBUG = false; }\" > $OUT \\' ',\n)\nBut I cannot have BuildConfig-Debug and BuildConfig-Release that generate the same file in two different modes.\n. This is also an issue for generating BuildConfig.java files. I am currently using:\ngenrule(\n  name = 'BuildConfig',\n  out = 'BuildConfig.java',\n  cmd = 'bash -c \\'echo \"package some.pacakge; public final class BuildConfig { public final static boolean DEBUG = false; }\" > $OUT \\' ',\n)\nBut I cannot have BuildConfig-Debug and BuildConfig-Release that generate the same file in two different modes.\n. Note that I signed the CLA already. Let me know if there are any issues there.\n. Note that I signed the CLA already. Let me know if there are any issues there.\n. Nice optimization. I am glad Facebook gives you guys the time to focus on these issues! :+1: \n. Note that calling:\nbuck clean && buck build app:update_version && build build app\ndoes not trigger the exception, since the genfile has already been generated.\n. As a work around you can change the order of operations so that the genrule operates on the generated android manifest.\n. Thanks. That makes sense, but will that also work for srcs parameter of android_library?\nI am currently adding the BuildConfig.java we generate with this:\nhttps://github.com/facebook/buck/pull/95\nvia genfile:\nandroid_library(\n  name = 'some-library',\n  srcs = [genfile('__build_config__/BuildConfig.java')] + glob(['src/main/java/**/*.java']),\n  manifest = 'AndroidManifest.xml',\n  deps = [\n    ':build_config',\n  ]\n)\n. Thanks. That makes sense, but will that also work for srcs parameter of android_library?\nI am currently adding the BuildConfig.java we generate with this:\nhttps://github.com/facebook/buck/pull/95\nvia genfile:\nandroid_library(\n  name = 'some-library',\n  srcs = [genfile('__build_config__/BuildConfig.java')] + glob(['src/main/java/**/*.java']),\n  manifest = 'AndroidManifest.xml',\n  deps = [\n    ':build_config',\n  ]\n)\n. ",
    "spearce": "If you are interested in looking at a real world pure Java project's usage of Buck, see https://gerrit.googlesource.com/gerrit/+/57a4d597cd1111ebabf9bbf495ecd45324e7acdd as it contains a complete, non-trivial \"pure Java\" project build system alongside of the existing Maven build.\nI unfortunately had to use 22 genrules() to provide a number of hacks for features missing from Buck. The worst hack of all was committing local.properties to work around the Android SDK. :-)\n. On Mon, Apr 29, 2013 at 10:41 PM, bolinfest wrote:\n\nhttps://developers.facebook.com/opensource/cla\n\nHmm, this may take a while. I don't have a Facebook account, and my employer owns first rights to my work, so I need to get a VP or SVP to sign the CLA for me.\n. Yup, I see the new text. I'm forwarding it along within my org for approval.\n. I moved the change to the master branch in my fork and there are now 4 commits outstanding for Gerrit Code Review's needs, not one. Its been replaced by pull request #16.\n. Didn't know about the --dot flag; this is indeed useful. Still would be nice to have a compact tree printed to standard out, but until someone has time to build and contribute that --dot and searching is an interim replacement.\n. I already rewrote the offending test class, but filed the bug anyway.\n. FYI https://github.com/facebook/buck/pull/16 is trying to resolve this.\n. Ping. I have click-signed the CLA, so it should be safe to look at these commits now.\n. I rebased last week, but this has been a conflict prone series. :-(\nOn Sep 25, 2013 12:55 PM, \"bolinfest\" notifications@github.com wrote:\n\nHi Shawn, sorry, I know it has been awhile. Are all of these commits\nup-to-date? That is, are they based off a relatively recent version of\nBuck? If so, I'll start cranking through them.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/pull/16#issuecomment-25119379\n.\n. On Wed, Sep 25, 2013 at 1:16 PM, bolinfest notifications@github.com wrote:\nAh, I believe \"Reset compressed size when combining JAR/ZIP archives\" is the first one given that its parent is \"Convert AndroidManifestRule to a Buildable (AndroidManifest).\"?\n\nYes, this is the first commit in my series.\n. Everything was either merged or we reworked that part of the Gerrit build to not require it anymore. So this pull request has been dead for some time.\n. Linux version 3.2.5, looks like its an unencrypted ext4 filesystem on local disk.\n. buckd helps, but not as much as I would like to see. :-)\nMacOS 10.8.3 (encrypted disk, java 1.7.0_21)\n  no-op without buckd: 8s\n  no-op with buckd: 3s\nIt seems like buckd has roughly gained back the latency loss caused by switching to Jython. But this is at the expense of a lot more complexity. Thus far the only thing we have really gained is removing a dependency on the local system Python, but that falls flat if your project uses a genrule() that runs a python_application().\n. buckd's security model also isn't viable in all environments; you really have to trust every process on your machine in order to run buckd. Given that nailgun uses a native C binary as the client I'm surprised they don't have a version that uses UNIX domain sockets.\n. Well, this was a reminder to fix the documentation. :-)\nAnd it doesn't work if the name is a genfile().\n. What about having a macro inside of the cmd string like \"$(location //x:y)\" to give you the location of a srcs entry named \"//x:y\". If //x:y is e.g. a java_library() this is the JAR it produces, if its a java_application() again its only the JAR it makes and not the execution command line, if its a genrule() its the out file. Such references in srcs should also automatically be added to the dep list so its not necessary to repeat them in deps.\nBuck already seems to do this with ${//x:y} for the name of the tool to execute, but that expansion isn't suitable because it creates things like \"java -classpath ...\" or \"PYTHONPATH= ...\" which isn't suitable in all contexts. $(location //x:y) would expand only to the path of the source file.\n. Fixed by $(location) being available in genrule().\n. I worked around this in my build by running git describe from Python instead of the genrule:\n```\ndef git_describe():\n  import subprocess\n  cmd = ['git', 'describe', '--match', 'v[0-9].*', '--dirty']\n  p = subprocess.Popen(cmd, stdout = subprocess.PIPE)\n  v = p.communicate()[0].strip()\n  r = p.returncode\n  if r != 0:\n    raise subprocess.CalledProcessError(r, ' '.join(cmd))\n  return v\ngenrule(\n  name = 'gen_version',\n  cmd = ';'.join([\n    'cd $TMP',\n    'mkdir -p com/google/gerrit/common',\n    'echo \"%s\" >com/google/gerrit/common/Version' % git_describe(),\n    'zip -9Dqr $OUT .',\n  ]),\n  out = 'version.jar',\n)\n```\nnickpalmer, maybe you can create two top level build targets that add in the BuildConfig.java at the last minute? Something like this:\njava_application(name = 'release', deps = [':app', ':BuildConfig-release'])\njava_application(name = 'debug', deps = [':app', ':BuildConfig-debug'])\n. I worked around this in my build by running git describe from Python instead of the genrule:\n```\ndef git_describe():\n  import subprocess\n  cmd = ['git', 'describe', '--match', 'v[0-9].*', '--dirty']\n  p = subprocess.Popen(cmd, stdout = subprocess.PIPE)\n  v = p.communicate()[0].strip()\n  r = p.returncode\n  if r != 0:\n    raise subprocess.CalledProcessError(r, ' '.join(cmd))\n  return v\ngenrule(\n  name = 'gen_version',\n  cmd = ';'.join([\n    'cd $TMP',\n    'mkdir -p com/google/gerrit/common',\n    'echo \"%s\" >com/google/gerrit/common/Version' % git_describe(),\n    'zip -9Dqr $OUT .',\n  ]),\n  out = 'version.jar',\n)\n```\nnickpalmer, maybe you can create two top level build targets that add in the BuildConfig.java at the last minute? Something like this:\njava_application(name = 'release', deps = [':app', ':BuildConfig-release'])\njava_application(name = 'debug', deps = [':app', ':BuildConfig-debug'])\n. As described in issue #30, buck-out is the correct directory name.\n. I would suggest adding compile_deps to java_library(), e.g.:\njava_library(\n    name = 'api',\n    srcs = glob(...),\n    deps = ['//lib:guava'],\n    compile_deps = ['//lib:servlet-api'],\n  )\ndeps is transitive, while compile_deps is only passed to the javac\ninvocation and is not exposed to java_binary() that includes this\nlibrary.\n. On Tue, Dec 3, 2013 at 10:12 AM, bolinfest notifications@github.com wrote:\n\nI'm a little torn about how to resolve this issue. Buck has been an Android tool first, and until recently, it only supported up to Java 6.\n\nMaybe a preference in .buckconfig to set what the default source and\ntarget is for a java_library() that doesn't specify it?\nContinue to default Buck to Java 6 for Android support, but make it\neasier for Java projects like Gerrit to select 7 by default?  We\nmanaged to pick 7 by default by renaming the build rules using a\nbuildfile includes that has:\noriginal_java_library = java_library\ndef java_library(\n    name,\n    srcs=[],\n    resources=[],\n    source='7',\n    target='7',\n    proguard_config=None,\n    deps=[],\n    exported_deps=[],\n    visibility=[],\n    ):\n  original_java_library(...)\n:-)\n. On Fri, Apr 25, 2014 at 7:50 AM, Simon Stewart notifications@github.com wrote:\n\nOK. Understanding you now. How about a general \"provided_deps\" parameter for java rules?\n\nprovided_deps would work. :-)\n. I am having trouble using this:\nTypeError: java_library() got an unexpected keyword argument 'provided_deps'\nThis is my rule:\njava_library(\n  name = 'init-base',\n  srcs = INIT_BASE_SRCS,\n  resources = INIT_BASE_RSRCS,\n  deps = [\n    ':init-api',\n    ...  ],\n  provided_deps = ['//gerrit-launcher:launcher'],\n  visibility = [\n    '//gerrit-war:',\n    '//gerrit-acceptance-tests/...',\n  ],\n)\n. Never mind, I am an idiot, I forgot to recompile Buck.\n. On Thu, Apr 24, 2014 at 10:15 AM, Simon Stewart notifications@github.comwrote:\n\nThe only time I've seen this be a problem in practice has been when\npulling in BouncyCastle, which uses a signed, sealed jar. @spearcehttps://github.com/spearce,\nwhile I can see the theoretical point, I'm curious to know if this is an\nactual problem you've encountered, or a code cleanliness thing?\nThis was an actual problem for Gerrit plugins. Some of our plugins did not\npopulate every field that the Gerrit web UI displays from the manifest,\ne.g. it omitted Implementation-Vendor. When the uberjar was built\nImplementation-Vendor came in from an Apache library. So the Gerrit server\nshows:\n\nName:  replication\n  Vendor:  Apache Software Foundation\n  Version: 1.0\nIf this is not a problem then we will have to continue our current hack of\nbuilding the application with java_application() and then stripping the\nmanifest out with a genrule() and putting in a correct manifest.\nTo be fair Google Blaze has the same problem but in the opposite direction,\nit refuses to put anything into the manifest. Instead I always have a\ncompletely empty tiny default manifest that appears to be a constant file.\nSo again there I have to use a genrule() to fix up my manifest. Maybe its\ntoo much to ask for a java type target to handle the manifest.\n\nHow would you suggest we cope with things such as the \"Class-Path\"\nmanifest entries? Or related ones to do with SPIs? To be fair, we don't\nhandle those well right now, but it seems like something that should be\ndealt with.\nLets tackle Class-Path first.\n\nWhat does Buck do today with Class-Path? IIRC one of the values wins and\nthe others are discarded. Should it merge these instead? Is it likely that\nuser code compiled with Buck was able to compile successfully against a\nprebuilt_jar() that uses Class-Path to reference other JARs, without those\nother JARs also being somehow in the deps graph?\nIf Class-Path should be left alone and carried into the final JAR then\nClass-Path should also be honored in the rest of the Buck build graph so it\ncan actually be relied upon by developers using Buck. IIRC its not.\n. I handle this in Gerrit by having the Python BUCK file generate a new value\nto embed into the genrule's cmd string:\ngenrule(\n  name = 'gen_version',\n  cmd = ';'.join([\n    'cd $TMP',\n    'mkdir -p com/google/gerrit/common',\n    'echo \"%s\" >com/google/gerrit/common/Version' % git_describe(),\n    'zip -9Dqr $OUT .',\n  ]),\n  out = 'version.jar',\n)\ndef git_describe():\n  import subprocess\n  cmd = ['git', 'describe', '--match', 'v[0-9].*', '--dirty']\n  p = subprocess.Popen(cmd, stdout = subprocess.PIPE)\n  v = p.communicate()[0].strip()\n  r = p.returncode\n  if r != 0:\n    raise subprocess.CalledProcessError(r, ' '.join(cmd))\n  return v\nhttps://gerrit.googlesource.com/gerrit/+/HEAD/gerrit-war/BUCK\nhttps://gerrit.googlesource.com/gerrit/+/HEAD/tools/git.defs\n. On Tue, Apr 29, 2014 at 12:06 PM, bolinfest notifications@github.comwrote:\n\nThe Gerrit project (which uses Buck!) has defined gwt_module() and\ngwt_application() macros in\nhttps://gerrit.googlesource.com/gerrit/+/master/tools/default.defs.\nThe comments from Brian and Thomas about needing a dual graph are correct.\nGerrit has to define a dual graph for some libraries, for example:\n\nhttps://gerrit.googlesource.com/gerrit/+/HEAD/gerrit-gwtexpui/BUCK\nWe define a java_library(name='server') that has some overlap in srcs with\ngwt_module() in the same BUCK file. This is awkward to use but mostly\nsensical. From a gwt_module() or gwt_application() we link to a\ngwt_module(), from a java_library() or java_application() we link to the\njava_library().\nFor us gwt_module() is defined as a simple rule to collect the sources into\na JAR for inclusion in a CLASSPATH later when the GWT compiler is invoked.\nFor performance reasons we do not invoke javac here and instead defer Java\nlanguage verification to the GWT compiler. The dual graph means the same\nsource files may be built in parallel by a java_library() that does invoke\njavac. This is one reason we don't run javac from a gwt_module() rule.\nFor runtime \"edit-reload-test\" cycle our application server knows how to\nreinvoke buck to regenerate the JavaScript code for the page:\nhttps://gerrit.googlesource.com/gerrit/+/HEAD/gerrit-pgm/src/main/java/com/google/gerrit/pgm/http/jetty/JettyServer.java\n  see ~line 568 method useDeveloperBuild()\nWe have a genrule() in buck output a properties file that the server can\nread passing it the environment necessary to relaunch buck. We run Buck in\na filter on the URL that serves the JS, allowing Buck to verify the JS is\nup-to-date after an edit before serving. In a draft mode compile this is\nO(22 seconds) after edit to serve the JS. Sluggish but preserves the\nedit-refresh cycle developers are used to.\n. I am no longer able to trust the output of buck.\nA successful rebuild may not have actually rebuilt.\nA successful test run may no longer have tested what I have in my directory.\nYes watchman+buckd is faster than neither. But its more important that I can trust the build than the build going fast and giving me inconclusive results.\n. ",
    "hashar": "And watching this thread since Wikimedia needs the changes :-)\n. A Debian package by Azatoth has been reviewed and is available at https://git.wikimedia.org/commit/operations%2Fdebs%2Fbuck\n. Fair enough :-)\n. ",
    "facebook-github-bot": "@spearce updated the pull request.\n. @spearce updated the pull request.\n. @aulanov updated the pull request.\n. @dpursehouse updated the pull request.\n. @verticalpalette updated the pull request.\n. Thank you for reaching out to us and we'd like to first apoligize for not getting back to you sooner. We're closing out older issues since updates to the project may address the issue you opened or they may no longer be relevant. If you're still experiencing the problem, please reopen the issue - thanks!\n. @Dominator008 updated the pull request.\n. @denizt updated the pull request.\n. @wt updated the pull request.\n. @wt updated the pull request.\n. @davido updated the pull request.\n. @georgepapas updated the pull request.\n. @dpursehouse updated the pull request.\n. @dpursehouse updated the pull request.\n. @saper updated the pull request.\n. @dpursehouse updated the pull request.\n. @dpursehouse updated the pull request.\n. @dpursehouse updated the pull request.\n. @dpursehouse updated the pull request.\n. @davido updated the pull request.\n. @davido updated the pull request.\n. @davido updated the pull request.\n. @mread updated the pull request.\n. @nickpalmer updated the pull request.\n. @dpursehouse updated the pull request.\n. @JasonGitHub updated the pull request.\n. @jamesgpearce updated the pull request.\n. @jamesgpearce updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. @jacobjennings updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @cakoose updated the pull request.\n. @davido updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @davcamer updated the pull request.\n. @clonetwin26 updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @sk- updated the pull request.\n. @mread updated the pull request.\n. @dpursehouse updated the pull request.\n. @mread updated the pull request.\n. @mread updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @kchodorow updated the pull request.\n. @davido updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @bayandin updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @saleeh93 updated the pull request.\n. @dcposch updated the pull request.\n. @mread updated the pull request.\n. @davido updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @jhansche updated the pull request.\n. @FrancisToth updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. @edisonw updated the pull request.\n. @edisonw updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @zhchang updated the pull request.\n. @shs96c updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @dakkad updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @plinehan updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @tgummerer updated the pull request.\n. @mikekap updated the pull request.\n. @tgummerer updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @liuyang-li updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @ttsugriy updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @mread updated the pull request.\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @tgummerer updated the pull request.\n. @tgummerer updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1534072876882849/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1534072876882849/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1534072876882849/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1534072876882849/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1534072876882849/int_phab to review.\n. @mikekap updated the pull request.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @scrawlings updated the pull request.\n. @mread updated the pull request.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @jimpurbrick to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @jimpurbrick to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/407143926162269/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/407143926162269/int_phab to review.\n. @liuyang-li updated the pull request.\n. @liuyang-li updated the pull request.\n. @liuyang-li updated the pull request.\n. @liuyang-li updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/407143926162269/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/407143926162269/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @marcinkosiba and @scrawlings to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @marcinkosiba and @scrawlings to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @strangemonad updated the pull request.\n. By analyzing the blame information on this pull request, we identified @mikekap to be a potential reviewer.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/903847883032306/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/903847883032306/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @dreiss, @shs96c and @andrewjcg to be potential reviewers.\n. @liuyang-li updated the pull request.\n. By analyzing the blame information on this pull request, we identified @dreiss to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @marcinkosiba and @scrawlings to be potential reviewers.\n. @strangemonad updated the pull request.\n. @strangemonad updated the pull request.\n. @strangemonad updated the pull request.\n. By analyzing the blame information on this pull request, we identified @shs96c and @bolinfest to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @shs96c and @bolinfest to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1722299147990133/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1722299147990133/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @beefon, @none and @yiding to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @beefon, @none and @yiding to be potential reviewers.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/172764146404073/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/172764146404073/int_phab to review.\n. @adamhowardprice updated the pull request.\n. @adamhowardprice updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1182061531821672/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1182061531821672/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @shs96c, @bolinfest and @ryu2 to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @shs96c, @bolinfest and @ryu2 to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1522025994778510/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1522025994778510/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @dreiss, @tgummerer and @shs96c to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/789563047856946/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @tgummerer to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @shs96c and @scrawlings to be potential reviewers.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1638457293089073/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1638457293089073/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @bolinfest and @natthu to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @bolinfest and @natthu to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1637299413191607/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1637299413191607/int_phab to review.\n. @grumpyjames updated the pull request.\n. By analyzing the blame information on this pull request, we identified @scrawlings, @shs96c and @dkgi to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @scrawlings, @shs96c and @dkgi to be potential reviewers.\n. @grumpyjames updated the pull request.\n. By analyzing the blame information on this pull request, we identified @shs96c, @andrewjcg and @bolinfest to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @shs96c, @andrewjcg and @bolinfest to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/880687528717279/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/880687528717279/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @k21, @shs96c and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @k21, @shs96c and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1637539753164250/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1637539753164250/int_phab to review.\n. @grumpyjames updated the pull request.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @mread and @bhamiltoncx to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @mread and @bhamiltoncx to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/160791447608781/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/160791447608781/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/760785267383531/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/760785267383531/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. By analyzing the blame information on this pull request, we identified @mikekap to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @mikekap to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1495614397402186/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1495614397402186/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @dcolascione, @shs96c and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @dcolascione, @shs96c and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/431461457057074/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/431461457057074/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @scrawlings, @shs96c and @dkgi to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @scrawlings, @shs96c and @dkgi to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @scrawlings, @shs96c and @dkgi to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @scrawlings, @shs96c and @dkgi to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1643374832583464/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1643374832583464/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @marcinkosiba to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @marcinkosiba to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @grumpyjames, @shs96c and @natthu to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @grumpyjames, @shs96c and @natthu to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/652946524808716/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/652946524808716/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg and @bhamiltoncx to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg and @bhamiltoncx to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @rhencke updated the pull request.\n. @rhencke updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1520650698252939/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1520650698252939/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @bhamiltoncx and @rhencke to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @bhamiltoncx and @rhencke to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/961116003960853/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @bolinfest and @dreiss to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1526143244368200/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/995881483801622/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @mikekap and @bhamiltoncx to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @shs96c and @jkeljo to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1487256974917033/int_phab to review.\n. @davido updated the pull request.\n. @davido updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/606020106203409/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @marcinkosiba and @k21 to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. By analyzing the blame information on this pull request, we identified @k21, @sdwilsh and @mikekap to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/624811147657303/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @natthu, @andrewjcg and @bolinfest to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @andrewjcg and @shs96c to be potential reviewers.\n. @davido updated the pull request.\n. By analyzing the blame information on this pull request, we identified @shs96c, @andrewjcg and @dcolascione to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @shs96c, @k21 and @dcolascione to be potential reviewers.\n. @LegNeato updated the pull request.\n. @LegNeato updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1481323322175324/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1481323322175324/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @bhamiltoncx to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @bhamiltoncx to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/414461402089694/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/414461402089694/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/414461402089694/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/414461402089694/int_phab to review.\n. @LegNeato updated the pull request.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @marcinkosiba to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @marcinkosiba to be potential reviewers.\n. @LegNeato updated the pull request.\n. @LegNeato updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/452073824976283/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/452073824976283/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @marcinkosiba and @sdwilsh to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @marcinkosiba and @sdwilsh to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @kalgynirae, @bolinfest and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/436036906594457/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1707327602831692/int_phab to review.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1068061776571814/int_phab to review.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1068061776571814/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/478632348990799/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/478632348990799/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/478632348990799/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/478632348990799/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @bolinfest and @shs96c to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/944221425626766/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/944221425626766/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/869820446472158/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @mogers and @sdwilsh to be potential reviewers.\n. Thank you for your pull request.  As you may know, we require contributors to sign our Contributor License Agreement, and we don't seem to have you on file and listed as active anymore.  In order for us to review and merge your code, please email cla@fb.com with your details so we can update your status.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @davido and @shs96c to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/495964490583440/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @grumpyjames, @shs96c and @andrewjcg to be potential reviewers.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/572220102926312/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @mikekap to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/734887833312475/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @mikekap to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/421283794737739/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @mikekap to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/452681318258953/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @mikekap, @andrewjcg and @shs96c to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/460901814120370/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/460901814120370/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @bhamiltoncx, @andrewjcg and @dcolascione to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1663950170525995/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @sdwilsh to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1652587595008609/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @sdwilsh, @bolinfest and @andrewjcg to be potential reviewers.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/810950265681472/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/810950265681472/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @beefon to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/947852258596684/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @mikekap and @jimevans to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @mikekap and @jimevans to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/116871295358869/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/116871295358869/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @grumpyjames, @shs96c and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @grumpyjames, @shs96c and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @mikekap, @shs96c and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @mikekap, @shs96c and @andrewjcg to be potential reviewers.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. @grumpyjames updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/426467974228847/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @sdwilsh to be a potential reviewer.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1015606688477992/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @sdwilsh, @marcinkosiba and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1527953244170473/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @shs96c, @natthu and @bolinfest to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @none and @bolinfest to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1023684464337696/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @shs96c, @andrewjcg and @k21 to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1645643909029284/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1645643909029284/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @grumpyjames to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/531436160372319/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @grumpyjames, @shs96c and @bolinfest to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @grumpyjames, @shs96c and @bolinfest to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @shs96c, @dkgi and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @shs96c, @dkgi and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/534222023424736/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/534222023424736/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @grumpyjames and @WaseemTheDream to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @grumpyjames and @WaseemTheDream to be potential reviewers.\n. @grumpyjames updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/478282755693748/int_phab to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @alsutton to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @shs96c and @alsutton to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1497920807182438/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1497920807182438/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1497920807182438/int_phab to review.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/1497920807182438/int_phab to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @liuyang-li and @shs96c to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @liuyang-li and @shs96c to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @mikekap and @shs96c to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @mikekap and @marcinkosiba to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @shs96c and @mathfac to be potential reviewers.\n. @janicduplessis updated the pull request.\n. @janicduplessis updated the pull request.\n. Thanks for importing. If you are an FB employee go to https://our.intern.facebook.com/intern/opensource/github/pull_request/550227281825626/int_phab to review.\n. @janicduplessis updated the pull request.\n. By analyzing the blame information on this pull request, we identified @Coneko, @andrewjcg and @k21 to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @polycoder updated the pull request.\n. @polycoder updated the pull request.\n. @polycoder updated the pull request.\n. @polycoder updated the pull request.\n. @polycoder updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @mikekap and @shs96c to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @mikekap, @shs96c and @sdwilsh to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. By analyzing the blame information on this pull request, we identified @shs96c, @elliottneilclark and @mathfac to be potential reviewers.\n. @mrkane27 updated the pull request.\n. @mrkane27 updated the pull request.\n. @mrkane27 updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @mrkane27 updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @mikekap and @shs96c to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @sdwilsh, @andrewjcg and @inglorion to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @Coneko, @bolinfest and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @Coneko, @bolinfest and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @liuyang-li, @dcposch and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @liuyang-li, @dcposch and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @sdwilsh, @marcinkosiba and @Coneko to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @sdwilsh, @marcinkosiba and @Coneko to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @dreiss and @shs96c to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @dreiss and @shs96c to be potential reviewers.\n. @polycoder updated the pull request.\n. @polycoder updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @polycoder updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @polycoder updated the pull request.\n. @polycoder updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @shs96c, @EugeneSusla and @mikekap to be potential reviewers.\n. @mrkane27 updated the pull request.\n. By analyzing the blame information on this pull request, we identified @natthu, @Coneko and @shs96c to be potential reviewers.\n. @polycoder updated the pull request.\n. @polycoder updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @mikekap to be a potential reviewer.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @inglorion, @elliottneilclark and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @shs96c, @EugeneSusla and @scrawlings to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. By analyzing the blame information on this pull request, we identified @grp, @bhamiltoncx and @Coneko to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @lucidsheep updated the pull request.\n. @lucidsheep updated the pull request.\n. @lucidsheep updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @shs96c, @Coneko and @bolinfest to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @mikekap and @mread to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @shs96c and @sdwilsh to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. @Piasy updated the pull request.\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @Piasy updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @Piasy updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @Piasy updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @k21, @grumpyjames and @sdwilsh to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @ryu2 to be a potential reviewer.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @mikekap and @sdwilsh to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @mikekap and @sdwilsh to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @borgstrom updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @bocon13 updated the pull request.\n. By analyzing the blame information on this pull request, we identified @marcinkosiba, @grumpyjames and @Coneko to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @alsutton, @ilya-klyuchnikov and @andrewjcg to be potential reviewers.\n. @tonycosentini updated the pull request.\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. @robbertvanginkel updated the pull request - view changes - changes since last import\n. @robbertvanginkel updated the pull request - view changes - changes since last import\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @dcolascione and @cosmin1123 to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @raviagarwal7 updated the pull request - view changes\n. @raviagarwal7 updated the pull request - view changes\n. @raviagarwal7 updated the pull request - view changes\n. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @raviagarwal7 updated the pull request - view changes - changes since last import. @raviagarwal7 updated the pull request - view changes - changes since last import. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @raviagarwal7 updated the pull request - view changes - changes since last import. @raviagarwal7 updated the pull request - view changes - changes since last import. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @andrewzhaosc updated the pull request - view changes\n. @andrewzhaosc updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. @AquaGeek updated the pull request - view changes\n. @fkorotkov updated the pull request - view changes - changes since last import\n. @fkorotkov updated the pull request - view changes - changes since last import\n. @fkorotkov updated the pull request - view changes - changes since last import\n. @fkorotkov updated the pull request - view changes - changes since last import\n. @fkorotkov updated the pull request - view changes - changes since last import\n. @fkorotkov updated the pull request - view changes - changes since last import\n. @fkorotkov updated the pull request - view changes - changes since last import\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @k21, @jkeljo and @kageiit to be potential reviewers.\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @marcinkosiba and @ruibm to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @marcinkosiba and @ruibm to be potential reviewers.\n. @zbsz updated the pull request - view changes\n. @zbsz updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @michsien, @bolinfest and @mzlee to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @michsien, @bolinfest and @mzlee to be potential reviewers.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @ryu2, @yiding and @sdwilsh to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @ryu2, @yiding and @sdwilsh to be potential reviewers.\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @asp2insp, @andrewjcg and @alsutton to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @asp2insp, @andrewjcg and @alsutton to be potential reviewers.\n. Thank you for your pull request.  As you may know, we require contributors to sign our Contributor License Agreement, and we don't seem to have you on file and listed as active anymore.  In order for us to review and merge your code, please email cla@fb.com with your details so we can update your status.\n. Thank you for your pull request.  As you may know, we require contributors to sign our Contributor License Agreement, and we don't seem to have you on file and listed as active anymore.  In order for us to review and merge your code, please email cla@fb.com with your details so we can update your status.\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @LegNeato updated the pull request - view changes\n. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @mkillianey, @marcinkosiba and @jkeljo to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @mkillianey, @marcinkosiba and @jkeljo to be potential reviewers.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @Coneko, @yiding and @jernejstrasner to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @Coneko, @yiding and @jernejstrasner to be potential reviewers.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @ryu2, @mkillianey and @bolinfest to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @ryu2, @mkillianey and @bolinfest to be potential reviewers.\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. @nguyentruongtho updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @Coneko to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @Coneko to be a potential reviewer.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @asp2insp, @pankdm-fb and @aiked to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @asp2insp, @pankdm-fb and @aiked to be potential reviewers.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @dreiss, @yiding and @marcinkosiba to be potential reviewers.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. @fkorotkov updated the pull request - view changes - changes since last import\n. @fkorotkov updated the pull request - view changes - changes since last import\n. @fkorotkov updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @dcolascione to be a potential reviewer.\n. @andrewzhaosc updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @yiding and @beefon to be potential reviewers.\n. @fkorotkov updated the pull request - view changes\n. @fkorotkov updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @zbsz and @yiding to be potential reviewers.\n. @dsyang updated the pull request - view changes\n. @dsyang updated the pull request - view changes\n. @dsyang updated the pull request - view changes\n. @dsyang updated the pull request - view changes\n. By analyzing the blame information on this pull request, we identified @Coneko, @plamenko and @beefon to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @zbsz, @marcinkosiba and @yiding to be potential reviewers.\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @mikekap updated the pull request - view changes - changes since last import\n. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @brettwooldridge updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @k21 to be a potential reviewer.\n. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @shs96c updated the pull request - view changes\n. @shs96c updated the pull request - view changes\n. @shs96c updated the pull request - view changes\n. @shs96c updated the pull request - view changes\n. @shs96c updated the pull request - view changes\n. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. @LegNeato updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @marcinkosiba and @k21 to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @marcinkosiba and @k21 to be potential reviewers.\n. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @yiding and @Dominator008 to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @yiding and @Dominator008 to be potential reviewers.\n. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @mrkane27, @yiding and @bolinfest to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @mrkane27, @yiding and @bolinfest to be potential reviewers.\n. @shs96c updated the pull request - view changes\n. @shs96c updated the pull request - view changes\n. By analyzing the blame information on this pull request, we identified @yiding, @mrkane27 and @Coneko to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @yiding, @mrkane27 and @Coneko to be potential reviewers.\n. @shs96c updated the pull request - view changes. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @yiding, @mrkane27 and @Coneko to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @yiding, @mrkane27 and @Coneko to be potential reviewers.\n. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. By analyzing the blame information on this pull request, we identified @shs96c, @yiding and @Coneko to be potential reviewers.\n. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @korniltsev updated the pull request - view changes\n. @korniltsev updated the pull request - view changes\n. @korniltsev updated the pull request - view changes\n. @korniltsev updated the pull request - view changes\n. @nemith has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @nemith has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @mkillianey, @cosmin1123 and @styurin to be potential reviewers.\n. @korniltsev updated the pull request - view changes\n. @korniltsev updated the pull request - view changes\n. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @yiding, @ryu2 and @marcinkosiba to be potential reviewers.\n. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. @robbertvanginkel updated the pull request - view changes - changes since last import\n. @robbertvanginkel updated the pull request - view changes - changes since last import\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes\n. @marcinkwiatkowski updated the pull request - view changes. @marcinkwiatkowski updated the pull request - view changes. @marcinkwiatkowski updated the pull request - view changes. @marcinkwiatkowski updated the pull request - view changes. @marcinkwiatkowski updated the pull request - view changes. @marcinkwiatkowski updated the pull request - view changes. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @marcinkwiatkowski updated the pull request - view changes - changes since last import. @marcinkwiatkowski updated the pull request - view changes - changes since last import. @marcinkwiatkowski updated the pull request - view changes - changes since last import. @marcinkwiatkowski updated the pull request - view changes - changes since last import. @marcinkwiatkowski updated the pull request - view changes - changes since last import. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @marcinkwiatkowski updated the pull request - view changes - changes since last import. @marcinkwiatkowski updated the pull request - view changes - changes since last import. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @yiding, @k21 and @cjhopman to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @yiding, @k21 and @cjhopman to be potential reviewers.\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @ryu2, @yiding and @nguyentruongtho to be potential reviewers.\n. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @nguyentruongtho, @beefon and @yiding to be potential reviewers.\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes. @shatlykuber updated the pull request - view changes. @shatlykuber updated the pull request - view changes. @shatlykuber updated the pull request - view changes. @shatlykuber updated the pull request - view changes. @shatlykuber updated the pull request - view changes. @shatlykuber updated the pull request - view changes. @shatlykuber updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @marcinkosiba, @yiding and @aiked to be potential reviewers.. By analyzing the blame information on this pull request, we identified @marcinkosiba, @yiding and @aiked to be potential reviewers.. By analyzing the blame information on this pull request, we identified @Coneko, @k21 and @illicitonion to be potential reviewers.. By analyzing the blame information on this pull request, we identified @Coneko, @k21 and @illicitonion to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @yiding, @andrewjcg and @asp2insp to be potential reviewers.. By analyzing the blame information on this pull request, we identified @yiding, @andrewjcg and @asp2insp to be potential reviewers.. By analyzing the blame information on this pull request, we identified @yiding, @styurin and @ilya-klyuchnikov to be potential reviewers.. By analyzing the blame information on this pull request, we identified @yiding, @styurin and @ilya-klyuchnikov to be potential reviewers.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. By analyzing the blame information on this pull request, we identified @dsyang, @yiding and @aiked to be potential reviewers.. By analyzing the blame information on this pull request, we identified @dsyang, @yiding and @aiked to be potential reviewers.. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. By analyzing the blame information on this pull request, we identified @yiding, @beefon and @ryu2 to be potential reviewers.. By analyzing the blame information on this pull request, we identified @yiding, @beefon and @ryu2 to be potential reviewers.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @dreiss to be a potential reviewer.. By analyzing the blame information on this pull request, we identified @dreiss to be a potential reviewer.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. By analyzing the blame information on this pull request, we identified @aiked, @yiding and @dsyang to be potential reviewers.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @yiding, @styurin and @Coneko to be potential reviewers.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @justinmuller updated the pull request - view changes - changes since last import. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. By analyzing the blame information on this pull request, we identified @nguyentruongtho, @beefon and @yiding to be potential reviewers.. By analyzing the blame information on this pull request, we identified @nguyentruongtho, @beefon and @yiding to be potential reviewers.. @robbertvanginkel updated the pull request - view changes. @robbertvanginkel updated the pull request - view changes. @robbertvanginkel updated the pull request - view changes. @robbertvanginkel updated the pull request - view changes. @k21 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @k21 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @andrewjcg, @yiding and @Coneko to be potential reviewers.. By analyzing the blame information on this pull request, we identified @andrewjcg, @yiding and @Coneko to be potential reviewers.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @shs96c updated the pull request - view changes - changes since last import. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @k21, @dsyang and @yiding to be potential reviewers.. By analyzing the blame information on this pull request, we identified @k21, @dsyang and @yiding to be potential reviewers.. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge updated the pull request - view changes - changes since last import. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge updated the pull request - view changes - changes since last import. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh and @marcinkosiba to be potential reviewers.. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. @illicitonion updated the pull request - view changes. By analyzing the blame information on this pull request, we identified @sdwilsh, @marcinkosiba and @illicitonion to be potential reviewers.. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. By analyzing the blame information on this pull request, we identified @illicitonion, @yiding and @andrewjcg to be potential reviewers.. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. @clonetwin26 updated the pull request - view changes. By analyzing the blame information on this pull request, we identified @Coneko, @ilya-klyuchnikov and @illicitonion to be potential reviewers.. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @ryu2, @dreiss and @yiding to be potential reviewers.. @robbertvanginkel updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @yiding to be a potential reviewer.. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @ahmedre and @yiding to be potential reviewers.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @raviagarwal7 updated the pull request - view changes - changes since last import. @raviagarwal7 updated the pull request - view changes - changes since last import. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @dreiss, @Coneko and @kageiit to be potential reviewers.. @splhack updated the pull request - view changes. By analyzing the blame information on this pull request, we identified @yiding, @illicitonion and @Coneko to be potential reviewers.. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @yiding, @k21 and @rmapes to be potential reviewers.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @andrewjcg, @Coneko and @lacker to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @ruibm, @Coneko and @lacker to be potential reviewers.. @sdwilsh updated the pull request - view changes. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh, @Coneko and @lacker to be potential reviewers.. @JoelMarcey updated the pull request - view changes. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @bolinfest, @mikekap and @Coneko to be potential reviewers.. By analyzing the blame information on this pull request, we identified @bolinfest, @mikekap and @Coneko to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh, @Coneko and @lacker to be potential reviewers.. By analyzing the blame information on this pull request, we identified @sdwilsh, @Coneko and @lacker to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @JoelMarcey, @Coneko and @lacker to be potential reviewers.. By analyzing the blame information on this pull request, we identified @JoelMarcey, @Coneko and @lacker to be potential reviewers.. @sdwilsh updated the pull request - view changes. @sdwilsh updated the pull request - view changes. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh updated the pull request - view changes - changes since last import. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @JoelMarcey, @Coneko and @lacker to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh, @Coneko and @lacker to be potential reviewers.. @JoelMarcey updated the pull request - view changes. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @Coneko, @lacker and @ryu2 to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh updated the pull request - view changes - changes since last import. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @yiding, @robbertvanginkel and @k21 to be potential reviewers.. @nguyenhuy updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @nguyenhuy updated the pull request - view changes - changes since last import. @nguyenhuy updated the pull request - view changes - changes since last import. @nguyenhuy updated the pull request - view changes - changes since last import. @nguyenhuy updated the pull request - view changes - changes since last import. @nguyenhuy updated the pull request - view changes - changes since last import. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh, @Coneko and @lacker to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh, @anishpatel and @Coneko to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @bolinfest updated the pull request - view changes. @bolinfest updated the pull request - view changes. By analyzing the blame information on this pull request, we identified @sdwilsh, @anishpatel and @Coneko to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @asp2insp and @kageiit to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh, @anishpatel and @Coneko to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh, @anishpatel and @Coneko to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @JoelMarcey, @Coneko and @lacker to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh, @Coneko and @lacker to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @JoelMarcey, @Coneko and @lacker to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh and @Coneko to be potential reviewers.. By analyzing the blame information on this pull request, we identified @sdwilsh and @Coneko to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh and @Coneko to be potential reviewers.. By analyzing the blame information on this pull request, we identified @sdwilsh and @Coneko to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @JoelMarcey, @Coneko and @lacker to be potential reviewers.. By analyzing the blame information on this pull request, we identified @JoelMarcey, @Coneko and @lacker to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @sdwilsh and @Coneko to be potential reviewers.. By analyzing the blame information on this pull request, we identified @sdwilsh and @Coneko to be potential reviewers.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey updated the pull request - view changes - changes since last import. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @JoelMarcey and @andrewjcg to be potential reviewers.. By analyzing the blame information on this pull request, we identified @JoelMarcey and @andrewjcg to be potential reviewers.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. By analyzing the blame information on this pull request, we identified @ryu2, @illicitonion and @yiding to be potential reviewers.. By analyzing the blame information on this pull request, we identified @sdwilsh to be a potential reviewer.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @fkorotkov updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @raviagarwal7 updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @JoelMarcey has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zayhero updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zayhero updated the pull request - view changes - changes since last import. @zayhero updated the pull request - view changes - changes since last import. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zayhero updated the pull request - view changes. @zayhero updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @raviagarwal7 updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @davido updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @davido updated the pull request - view changes - changes since last import. @davido updated the pull request - view changes - changes since last import. @davido updated the pull request - view changes - changes since last import. @davido updated the pull request - view changes - changes since last import. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @davido updated the pull request - view changes - changes since last import. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @davido updated the pull request - view changes - changes since last import. @davido updated the pull request - view changes - changes since last import. @marcinkosiba has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zayhero updated the pull request - view changes. @zayhero updated the pull request - view changes. @zayhero updated the pull request - view changes. @zayhero updated the pull request - view changes. @jkeljo has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @rspencer01 updated the pull request - view changes. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @rspencer01 updated the pull request - view changes - changes since last import. @rspencer01 updated the pull request - view changes - changes since last import. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @nguyentruongtho updated the pull request - view changes. @nguyentruongtho updated the pull request - view changes. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @nguyentruongtho updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @nguyentruongtho updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @darkforestzero updated the pull request - view changes. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @rmaz updated the pull request - view changes - changes since last import. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @aiked has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @aledalgrande updated the pull request - view changes - changes since last import. @aledalgrande updated the pull request - view changes - changes since last import. @aledalgrande updated the pull request - view changes - changes since last import. @aledalgrande updated the pull request - view changes - changes since last import. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @brettwooldridge updated the pull request - view changes - changes since last import. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @jkeljo has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @mikekap updated the pull request - view changes. @mikekap updated the pull request - view changes. @mikekap updated the pull request - view changes. @mikekap updated the pull request - view changes. @mikekap updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @shs96c updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @illicitonion has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @alanzeino updated the pull request - view changes. @alanzeino updated the pull request - view changes. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @alanzeino updated the pull request - view changes. @alanzeino updated the pull request - view changes. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @raviagarwal7 updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @runningcode updated the pull request - view changes. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. @cpick updated the pull request - view changes. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @raviagarwal7 updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @LegNeato updated the pull request - view changes. @LegNeato updated the pull request - view changes. @LegNeato updated the pull request - view changes. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\nIf you are contributing on behalf of someone else (eg your employer): the individual CLA is not sufficient - use https://developers.facebook.com/opensource/cla?type=company instead. Contact cla@fb.com if you have any questions.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @mikekap updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @runningcode updated the pull request - view changes - changes since last import. @runningcode updated the pull request - view changes - changes since last import. @zpao updated the pull request - view changes. @zpao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zpao updated the pull request - view changes - changes since last import. @zpao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zpao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zpao updated the pull request - view changes - changes since last import. @zpao updated the pull request - view changes - changes since last import. @zpao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ryu2 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @mikekap updated the pull request - view changes. @Coneko has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @runningcode updated the pull request - view changes. @clonetwin26 updated the pull request - view changes. @clonetwin26 updated the pull request - view changes. @clonetwin26 updated the pull request - view changes. @clonetwin26 updated the pull request - view changes. @clonetwin26 updated the pull request - view changes. @clonetwin26 updated the pull request - view changes. @clonetwin26 updated the pull request - view changes. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @clonetwin26 updated the pull request - view changes - changes since last import. @clonetwin26 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @coneko@fb.com has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @coneko@fb.com has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @runningcode updated the pull request - view changes. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @seanabraham updated the pull request - view changes. @seanabraham updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jkeljo has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @brettwooldridge updated the pull request - view changes. @sdwilsh has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @andrewjcg updated the pull request - view changes. @andrewjcg updated the pull request - view changes. @andrewjcg updated the pull request - view changes. @andrewjcg updated the pull request - view changes. @andrewjcg updated the pull request - view changes. @andrewjcg updated the pull request - view changes. @andrewjcg has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @zhan-xiong updated the pull request - view changes. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zpao has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @k21 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @k21 has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @zhan-xiong updated the pull request - view changes. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong has updated the pull request. View: changes, changes since last import. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dreiss has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes. @zhan-xiong updated the pull request - view changes. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @zhan-xiong updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @cwoodwar6 updated the pull request - view changes. @cwoodwar6 updated the pull request - view changes. @cwoodwar6 updated the pull request - view changes. @cwoodwar6 updated the pull request - view changes. @cwoodwar6 updated the pull request - view changes. @cwoodwar6 updated the pull request - view changes. @cwoodwar6 updated the pull request - view changes. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cwoodwar6 updated the pull request - view changes - changes since last import. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cwoodwar6 updated the pull request - view changes. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dsyang has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @kageiit updated the pull request - view changes - changes since last import. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @bertmaher has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @nikhedonia updated the pull request - view changes. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @jbarr21 updated the pull request - view changes. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @styurin has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @jbarr21 updated the pull request - view changes. @brettwooldridge has updated the pull request.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @brettwooldridge has updated the pull request.. @brettwooldridge has updated the pull request.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @robbertvanginkel updated the pull request - view changes - changes since last import. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @robbertvanginkel updated the pull request - view changes - changes since last import. @robbertvanginkel updated the pull request - view changes - changes since last import. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @dinhviethoa has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @robbertvanginkel updated the pull request - view changes - changes since last import. @dinhviethoa has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @robbertvanginkel updated the pull request - view changes - changes since last import. @yiding has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @robbertvanginkel updated the pull request - view changes. @robbertvanginkel updated the pull request - view changes. @milend has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @milend has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @milend has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @milend has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes, changes since last import. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @kageiit updated the pull request - view changes. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @romanoid updated the pull request - view changes. @romanoid updated the pull request - view changes. @romanoid updated the pull request - view changes. @romanoid updated the pull request - view changes. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @romanoid updated the pull request - view changes - changes since last import. @romanoid updated the pull request - view changes - changes since last import. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @kageiit updated the pull request - view changes - changes since last import. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @shs96c updated the pull request - view changes. @asp2insp has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @shs96c updated the pull request - view changes. @ttsugriy has imported this pull request.  If you are a Facebook employee, you can view this diff on Phabricator.. @cwoodwar6 has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes. @robbertvanginkel has updated the pull request. View: changes, changes since last import. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes, changes since last import. @robbertvanginkel has updated the pull request. View: changes, changes since last import. @romanoid has updated the pull request.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @voznesenskym has updated the pull request. View: changes. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @voznesenskym has updated the pull request. View: changes. @voznesenskym has updated the pull request. View: changes, changes since last import. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @shybovycha has updated the pull request. View: changes. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @shybovycha has updated the pull request.. @shybovycha has updated the pull request. View: changes. @shybovycha has updated the pull request. View: changes. @shybovycha has updated the pull request.. @shybovycha has updated the pull request.. @shybovycha has updated the pull request.. @shybovycha has updated the pull request.. @shybovycha has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @clonetwin26 has updated the pull request. View: changes. @clonetwin26 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes. @cwoodwar6 has updated the pull request. View: changes, changes since last import. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @rmaz has updated the pull request. View: changes. @rmaz has updated the pull request. View: changes, changes since last import. @rmaz has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @styurin has updated the pull request.. @styurin has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @styurin has updated the pull request. View: changes. @styurin has updated the pull request. View: changes. @styurin has updated the pull request. View: changes. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @raviagarwal7 has updated the pull request. View: changes. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request. View: changes. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request.. @rmaz has updated the pull request.. @rmaz has updated the pull request.. @rmaz has updated the pull request. View: changes. @robbertvanginkel has updated the pull request. View: changes, changes since last import. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes. @robbertvanginkel has updated the pull request. View: changes. @ttsugriy has updated the pull request. View: changes. @ttsugriy has updated the pull request. View: changes. @ttsugriy has updated the pull request. View: changes. @ttsugriy has updated the pull request. View: changes. @clonetwin26 has updated the pull request. View: changes. @clonetwin26 has updated the pull request. View: changes. @clonetwin26 has updated the pull request.. @clonetwin26 has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes, changes since last import. @robbertvanginkel has updated the pull request.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request.. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @artem-zinnatullin has updated the pull request. View: changes, changes since last import. Sorry, I can't do that @ryu2 - this feature is only supported for non-employees; you can land via the internal pull request dashboard.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @epkugelmass has updated the pull request. View: changes. @epkugelmass has updated the pull request. View: changes. @kageiit has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes, changes since last import. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @rmaz has updated the pull request.. @rmaz has updated the pull request.. @rmaz has updated the pull request.. @rmaz has updated the pull request.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @tinaroh has updated the pull request. View: changes, changes since last import. @tinaroh has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes. @robbertvanginkel has updated the pull request. View: changes. @rmaz has updated the pull request. View: changes. @rmaz has updated the pull request. View: changes. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request.. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request.. @jiangty-addepar has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request.. @jiangty-addepar has updated the pull request.. @jiangty-addepar has updated the pull request.. @kageiit has updated the pull request. View: changes. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request. View: changes, changes since last import. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request.. @jiangty-addepar has updated the pull request. View: changes. @jiangty-addepar has updated the pull request. View: changes, changes since last import. @jiangty-addepar has updated the pull request.. @jiangty-addepar has updated the pull request. View: changes, changes since last import. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @vkalintiris has updated the pull request.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @thalescm has updated the pull request. View: changes. @thalescm has updated the pull request. View: changes, changes since last import. @thalescm has updated the pull request. View: changes, changes since last import. @thalescm has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request. View: changes, changes since last import. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @linzhp has updated the pull request.. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @plinehan has updated the pull request. View: changes. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request. View: changes. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request. View: changes, changes since last import. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @robbertvanginkel has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. Thank you for your pull request. We require contributors to sign our Contributor License Agreement, and yours has expired.\nBefore we can review or merge your code, we need you to email cla@fb.com with your details so we can update your status.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @ttsugriy has updated the pull request.. @romanoid has updated the pull request. View: changes. @robbertvanginkel has updated the pull request.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request. View: changes. @raviagarwal7 has updated the pull request. View: changes, changes since last import. @raviagarwal7 has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request.. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request.. @linzhp has updated the pull request.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @sheldonneuberger has updated the pull request. Re-import the pull request. @sheldonneuberger has updated the pull request. Re-import the pull request. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @monty-uber has updated the pull request. View: changes. @monty-uber has updated the pull request.. @monty-uber has updated the pull request. View: changes. @monty-uber has updated the pull request. View: changes. @monty-uber has updated the pull request. View: changes. @monty-uber has updated the pull request. View: changes. @monty-uber has updated the pull request. View: changes. @monty-uber has updated the pull request. View: changes. @monty-uber has updated the pull request. View: changes, changes since last import. @robbertvanginkel has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request. View: changes. @brettwooldridge has updated the pull request.. @brettwooldridge has updated the pull request.. @brettwooldridge has updated the pull request.. @brettwooldridge has updated the pull request. View: changes, changes since last import. @brettwooldridge has updated the pull request. View: changes, changes since last import. @brettwooldridge has updated the pull request.. @brettwooldridge has updated the pull request.. @brettwooldridge has updated the pull request.. @brettwooldridge has updated the pull request.. @kageiit has updated the pull request.. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request.. @clonetwin26 has updated the pull request.. @clonetwin26 has updated the pull request.. @clonetwin26 has updated the pull request.. @clonetwin26 has updated the pull request.. @clonetwin26 has updated the pull request.. @clonetwin26 has updated the pull request.. @bobyangyf has updated the pull request. View: changes. @bobyangyf has updated the pull request. View: changes. @davidaurelio has updated the pull request.. @davidaurelio has updated the pull request.. @raviagarwal7 has updated the pull request. View: changes. @raviagarwal7 has updated the pull request.. @raviagarwal7 has updated the pull request.. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request. View: changes, changes since last import. @romanoid has updated the pull request. View: changes, changes since last import. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes, changes since last import. @shybovycha has updated the pull request. View: changes. @shybovycha has updated the pull request. View: changes. @shybovycha has updated the pull request. View: changes, changes since last import. @shybovycha has updated the pull request. View: changes, changes since last import. @shybovycha has updated the pull request. View: changes, changes since last import. @shybovycha has updated the pull request. View: changes, changes since last import. @shybovycha has updated the pull request.. @shybovycha has updated the pull request. View: changes, changes since last import. @shybovycha has updated the pull request. View: changes, changes since last import. @shybovycha has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @cwoodwar6 has updated the pull request.. @cwoodwar6 has updated the pull request. View: changes. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request.. @linzhp has updated the pull request. View: changes, changes since last import. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @kageiit has updated the pull request.. @styurin has updated the pull request.. @robbertvanginkel has updated the pull request. View: changes. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @robbertvanginkel has updated the pull request.. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. View: changes, changes since last import. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request. View: changes. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @romanoid has updated the pull request.. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes, changes since last import. @LegNeato has updated the pull request.. @LegNeato has updated the pull request.. @LegNeato has updated the pull request.. @LegNeato has updated the pull request. View: changes. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @ereli has updated the pull request. View: changes. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @LegNeato has updated the pull request.. @LegNeato has updated the pull request.. @LegNeato has updated the pull request.. @LegNeato has updated the pull request.. @LegNeato has updated the pull request.. @linzhp has updated the pull request. View: changes. @styurin has updated the pull request.. @styurin has updated the pull request.. @styurin has updated the pull request.. @styurin has updated the pull request. View: changes. @styurin has updated the pull request.. @styurin has updated the pull request. View: changes. @styurin has updated the pull request. View: changes. @styurin has updated the pull request. View: changes. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. @sheldonneuberger has updated the pull request. View: changes. @sheldonneuberger has updated the pull request. View: changes. @kageiit has updated the pull request. View: changes. @kageiit has updated the pull request. View: changes. @kageiit has updated the pull request. View: changes. @kageiit has updated the pull request. View: changes, changes since last import. @kageiit has updated the pull request.. @rmaz has updated the pull request. View: changes. @rmaz has updated the pull request. View: changes. @linzhp has updated the pull request. View: changes. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @aventadorm has updated the pull request. View: changes, changes since last import. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @styurin has updated the pull request. Re-import the pull request. @styurin has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @ghvg1313 has updated the pull request. Re-import the pull request. @ghvg1313 has updated the pull request. Re-import the pull request. @ghvg1313 has updated the pull request. Re-import the pull request. @ghvg1313 has updated the pull request. Re-import the pull request. @ghvg1313 has updated the pull request. Re-import the pull request. @ghvg1313 has updated the pull request. Re-import the pull request. @ghvg1313 has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @artem-zinnatullin has updated the pull request. Re-import the pull request. @artem-zinnatullin has updated the pull request. Re-import the pull request. @artem-zinnatullin has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @vkalintiris has updated the pull request. Re-import the pull request. @vkalintiris has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @linzhp has updated the pull request. Re-import the pull request. @raviagarwal7 has updated the pull request. Re-import the pull request. @raviagarwal7 has updated the pull request. Re-import the pull request. @raviagarwal7 has updated the pull request. Re-import the pull request. @raviagarwal7 has updated the pull request. Re-import the pull request. @raviagarwal7 has updated the pull request. Re-import the pull request. @raviagarwal7 has updated the pull request. Re-import the pull request. @ghvg1313 has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @rmaz has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @rmaz has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\nIf you have received this in error or have any questions, please contact us at cla@fb.com. Thanks!. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @KapJI has updated the pull request. Re-import the pull request. @kageiit has updated the pull request. Re-import the pull request. @thalescm has updated the pull request. Re-import the pull request. @styurin merged this pull request in facebook/buck@a904068913b3279558929035e9f2e95491ea63a8.. ",
    "natthu": "This was recently fixed by @shs96c.\n. This is fixed now, since buck looks for the '.buckconfig' in the current directory before actually invoking itself.\n. 407855a4b4575e12a18ee9337bf2c1ba617588ed fixed this.\n. f3c85c8b2ee10a16e4bab7d8514e2426fcaa8c65 fixed this.\n. This is because a java_library with empty srcs and resources arguments does not have an output jar. \n. This is because a java_library with empty srcs and resources arguments does not have an output jar. \n. You shouldn't need the Android SDK to just build and run buck. However, if you want to run the buck test suite, you do and IMO should need it.\n. You shouldn't need the Android SDK to just build and run buck. However, if you want to run the buck test suite, you do and IMO should need it.\n. 92709a3bffd199055335df2ed7ccd80fd800c085 fixes this I believe.\n. I should have a fix committed soon. Thanks for the report.\n. I should have a fix committed soon. Thanks for the report.\n. de5bc5db0b566528c9eeb76a502f50cf0634d67a fixes this. \n. de5bc5db0b566528c9eeb76a502f50cf0634d67a fixes this. \n. I have a diff out for review, I should hopefully be able to commit it in a day or two.\n. I have a diff out for review, I should hopefully be able to commit it in a day or two.\n. I don't think this is the right fix. I believe handling different SDK directories in buck is the right fix. There's already an issue open for that https://github.com/facebook/buck/issues/105 which I am working on.\nThanks for reporting the bug.\n. I don't think this is the right fix. I believe handling different SDK directories in buck is the right fix. There's already an issue open for that https://github.com/facebook/buck/issues/105 which I am working on.\nThanks for reporting the bug.\n. 732df26744dacd1af137a1df4f7c4df8d37cb932 is the proper fix.\n. 732df26744dacd1af137a1df4f7c4df8d37cb932 is the proper fix.\n. So here's the issue - newer versions of ADT downloaded directly from http://developer.android.com/ appear to create subdirs of the form android-* which we rank higher than the 1_..* directories. We probably need a hard coded map from android version to API level so that we can correctly handle this.\n. So here's the issue - newer versions of ADT downloaded directly from http://developer.android.com/ appear to create subdirs of the form android-* which we rank higher than the 1._.* directories. We probably need a hard coded map from android version to API level so that we can correctly handle this.\n. There can be a . after ~ too :)\n. Oops, sorry. That doesn't make any sense. Carry on :)\n. Thanks for such a detailed bug report @davido!\n. Thanks for such a detailed bug report @davido!\n. Does including :genrule_jar as a resources in lib_dependencies_bug do the right thing?\n. > What if the genrule is generating java sources that need to be compiled? Like\nIn that case, the dependency should be implicitly added, no? Why do you need to explicitly specify it?\n. Sorry, I did not understand the issue correctly before. A java_library only includes resources from its transitive dependencies of type java_library/android_library/prebuilt_jar, so you must wrap that jar in a prebuilt_jar rule.\n. Sorry, I did not understand the issue correctly before. A java_library only includes resources from its transitive dependencies of type java_library/android_library/prebuilt_jar, so you must wrap that jar in a prebuilt_jar rule.\n. @sdwilsh nah. This is the rulekey computation. I should have a fix ready today.\n. How is the  \"//third_party/safewidget/sqlite3sec:app3\" rule defined?\n. How is the  \"//third_party/safewidget/sqlite3sec:app3\" rule defined?\n. How are you importing the interface defined in A.aidl? Also, BService's import_path should also be java/.\n. How are you importing the interface defined in A.aidl? Also, BService's import_path should also be java/.\n. How are you reading this text file in your application?\nI'd suggest adding the file as an asset to an android_resource() rule and then loading it using the AssetManager system class.\n. How are you reading this text file in your application?\nI'd suggest adding the file as an asset to an android_resource() rule and then loading it using the AssetManager system class.\n. Buck is not self hosting, which is why we have checked in .iml files.\n. Buck is not self hosting, which is why we have checked in .iml files.\n. If source files under ui:res refer to resources that are defined elsewhere, it needs to add that android_resource() rule to its dependencies (in this case, that will be :libs_android-support-v4 or :libs_android-support-v7-appcompat.r19.1.0.jar).\n. If source files under ui:res refer to resources that are defined elsewhere, it needs to add that android_resource() rule to its dependencies (in this case, that will be :libs_android-support-v4 or :libs_android-support-v7-appcompat.r19.1.0.jar).\n. //ui:res should depend on res_android.\n. //ui:res should depend on res_android.\n. Looks like \"@id/android:empty\" is valid. I'll work on a more general fix that'll basically let you use all the system provided resource ids in this manner. Thanks for raising the issue!\n. Looks like \"@id/android:empty\" is valid. I'll work on a more general fix that'll basically let you use all the system provided resource ids in this manner. Thanks for raising the issue!\n. We decided to leave out symbols from transitive dependencies in the resulting R.txt for performance.\n. Yes, this is intended, the motivation being significantly faster build times.\n. Can you please elaborate a bit? \n. No, there is no way to turn on transitive dependencies as of now.\nCan you not instead define another android_resource() rule for the shared resources with package = \"'com.example.app'\"?\nAlso, when compiling android_library() rules, Buck only looks at the first order android_resource dependencies, so if you had an android_library that only depends on :res but has java code that references resources defined in :shared_res, the android library needs to set :shared_res in its dependencies (similar to first order java dependencies).\n. Take a look at the prebuilt_native_library rule for sqlcipher.so and couchbase.so, and the ndk_library rule for your own .so.\nhttp://facebook.github.io/buck/rule/prebuilt_native_library.html\nhttp://facebook.github.io/buck/rule/ndk_library.html\n. You cannot use exopackage with package_type set to release. It only works with debug.\n. Fixed in 755b86bb1cb4db447a3358b03248a3b7ccae8aaa .\n. Fixed in 755b86bb1cb4db447a3358b03248a3b7ccae8aaa .\n. We generate a dummy_r_dot_java rule (for every android_library rule) which only contains the R.java references from resources that the library directly depends on. This dummy R.java is only used for compiling the android library (so that the R.* references are resolved) and not packaged into the jar for the library. As you said, the actual R.java is generated by the uber_r_dot_java rule (which is generated for the android_binary rule).\nIf you want to compile generated code, you should simply use an android_library whose srcs is the list of generated files, and which depends on the android resources.\n. We generate a dummy_r_dot_java rule (for every android_library rule) which only contains the R.java references from resources that the library directly depends on. This dummy R.java is only used for compiling the android library (so that the R.* references are resolved) and not packaged into the jar for the library. As you said, the actual R.java is generated by the uber_r_dot_java rule (which is generated for the android_binary rule).\nIf you want to compile generated code, you should simply use an android_library whose srcs is the list of generated files, and which depends on the android resources.\n. IIUC, there's an assumption that the custom compiler implements the jsr99 spec.\nYou could write a wrapper around kotlinc that filters arguments passed by Buck.\n. IIUC, there's an assumption that the custom compiler implements the jsr99 spec.\nYou could write a wrapper around kotlinc that filters arguments passed by Buck.\n. Hi @tgummerer - sorry for the back and forth on this issue, and thanks for bearing with us.\nFWIW, with just these local changes, I got the first half of your integration test to pass:\n```\ndiff --git a/src/com/facebook/buck/android/AndroidPrebuiltAarDescription.java b/src/com/facebook/buck/android/AndroidPrebuiltAarDescription.java\nindex d5c1cb5..7b30af1 100644\n--- a/src/com/facebook/buck/android/AndroidPrebuiltAarDescription.java\n+++ b/src/com/facebook/buck/android/AndroidPrebuiltAarDescription.java\n@@ -106,7 +106,8 @@ public class AndroidPrebuiltAarDescription\n             pathResolver,\n             ImmutableSortedSet.copyOf(javaDeps)));\n     AndroidResource androidResource = buildRuleResolver.addToIndex(\n-        createAndroidResource(unzipAar, params, pathResolver));\n+        createAndroidResource(unzipAar, params, pathResolver,\n+            AndroidResourceHelper.androidResOnly(buildRuleResolver.getAllRules(args.deps.get()))));\n     return buildRuleResolver.addToIndex(new AndroidPrebuiltAar(\n         / androidLibraryParams / params.copyWithDeps(\n             / declaredDeps / Suppliers.ofInstance(ImmutableSortedSet.of(\n@@ -154,18 +155,18 @@ public class AndroidPrebuiltAarDescription\n   private AndroidResource createAndroidResource(\n       AndroidPrebuiltAarGraphEnhancer.UnzipAar unzipAar,\n       BuildRuleParams params,\n-      SourcePathResolver resolver) {\n+      SourcePathResolver resolver, ImmutableSortedSet buildRules) {\n     BuildRuleParams buildRuleParams = params.copyWithChanges(\n         / buildTarget / BuildTargets.createFlavoredBuildTarget(\n             params.getBuildTarget().checkUnflavored(),\n             ImmutableFlavor.of(\"aar_android_resource\")),\n-        / declaredDeps / Suppliers.ofInstance(ImmutableSortedSet.of()),\n+        / declaredDeps / Suppliers.ofInstance(buildRules),\n         / extraDeps / Suppliers.ofInstance(ImmutableSortedSet.of(unzipAar)));\n return new AndroidResource(\n     /* buildRuleParams */ buildRuleParams,\n     /* resolver */ resolver,\n\n\n/ deps / ImmutableSortedSet.of(),\n/ deps / buildRules,\n         / res / new BuildTargetSourcePath(\n             unzipAar.getBuildTarget(),\n             unzipAar.getResDirectory()),\ndiff --git a/test/com/facebook/buck/android/AndroidPrebuiltAarIntegrationTest.java b/test/com/facebook/buck/android/AndroidPrebuiltAarIntegrationTest.java\nindex 228a191..31fc5c7 100644\n--- a/test/com/facebook/buck/android/AndroidPrebuiltAarIntegrationTest.java\n+++ b/test/com/facebook/buck/android/AndroidPrebuiltAarIntegrationTest.java\n@@ -16,6 +16,9 @@\n\npackage com.facebook.buck.android;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.junit.Assert.assertThat;\n+\n import com.facebook.buck.testutil.integration.DebuggableTemporaryFolder;\n import com.facebook.buck.testutil.integration.ProjectWorkspace;\n import com.facebook.buck.testutil.integration.TestDataHelper;\n@@ -68,4 +71,18 @@ public class AndroidPrebuiltAarIntegrationTest {\n   public void testAndroidPrebuiltAarInDepsIsExported() throws IOException {\n     workspace.runBuckBuild(\"//android_prebuilt_aar-dep:lib\").assertSuccess();\n   }\n+\n+  @Test\n+  public void testPrebuiltRDotTxtContainsTransitiveDependencies() throws IOException {\n+    workspace.runBuckBuild(\"//third-party/design-library:design-library\").assertSuccess();\n+\n+    String appCompatResource = \"TextAppearance_AppCompat_Body2\";\n+\n+    String rDotTxt = workspace.getFileContents(\"buck-out/gen/third-party/design-library/\" +\n+        \"design-library#aar_android_resource_text_symbols/R.txt\");\n+    assertThat(\n+        \"R.txt contains transitive dependencies\",\n+        rDotTxt,\n+        containsString(appCompatResource));\n+  }\n }\ndiff --git a/test/com/facebook/buck/android/testdata/android_prebuilt_aar/third-party/design-library/BUCK b/test/com/facebook/buck/android/testdata/android_prebuilt_aar/third-party/design\nnew file mode 100644\nindex 0000000..19fd727\n--- /dev/null\n+++ b/test/com/facebook/buck/android/testdata/android_prebuilt_aar/third-party/design-library/BUCK\n@@ -0,0 +1,14 @@\n+android_prebuilt_aar(\n+  name = 'design-library',\n+  aar = 'design-22.2.1.aar',\n+  visibility = ['PUBLIC'],\n+  deps = [\n+    ':appcompat',\n+  ],\n+)\n+\n+android_prebuilt_aar(\n+  name = 'appcompat',\n+  aar = 'appcompat-v7-22.2.0.aar',\n+  visibility = ['PUBLIC'],\n+)\ndiff --git a/test/com/facebook/buck/android/testdata/android_prebuilt_aar/third-party/design-library/appcompat-v7-22.2.0.aar b/test/com/facebook/buck/android/testdata/android_prebuilt_aar\nnew file mode 100644\nindex 0000000..c2f9094\nBinary files /dev/null and b/test/com/facebook/buck/android/testdata/android_prebuilt_aar/third-party/design-library/appcompat-v7-22.2.0.aar differ\ndiff --git a/test/com/facebook/buck/android/testdata/android_prebuilt_aar/third-party/design-library/design-22.2.1.aar b/test/com/facebook/buck/android/testdata/android_prebuilt_aar/third\nnew file mode 100644\nindex 0000000..1fe0a82\nBinary files /dev/null and b/test/com/facebook/buck/android/testdata/android_prebuilt_aar/third-party/design-library/design-22.2.1.aar differ\n```\ni.e. \"//third-party/design-library:design-library\" builds fine. \nI still don't understand the \"app crashing\" part. Why should R.java for the design-library include symbols from the appcompat library? IIUC, if some code in design-library is referencing to resources in the appcompat library, it should use the fully qualified name of those resources (i.e. <package name ofappcompatlibrary>.string.resource_name) - is my assumption incorrect?\n. Sorry about the delay again. I've been working on cleaning up how we deal with resources inside prebuilt android AARs, which should hopefully make all of this obsolete. I hope to land it soon.\n. It's coming from https://github.com/facebook/buck/blob/42d1e6c3757e6430cf687a0db71684dcedba066a/src/com/facebook/buck/android/MergeAndroidResourcesStep.java#L291\nI think you can suppress that by setting a .buckconfig property.\n. I was wrong. Currently, you cannot suppress these warnings with any override.\n. mini-aapt generates an empty R.txt file if there are no resources.\nI'd prefer if we instead of this, add a TouchStep after AaptStep in AaptPackageResources, so that we don't have to special case this, and keep it consistent.\n. Thanks for the PR - looks good to me!\n. Thanks for the PR - looks good to me!\n. The Preconditions.checkState() are redundant now.\n. Can you please fix the indentation?\n. Please use an ExpectedException instead (so that you don't need to the try/catch block).\n. Need a comment here to explain why we need the TouchStep.\n. nit: you can use runBuckBuild instead.\n. Since this is a fresh build, this is bound to be true. This isn't testing anything. Please remove.\n. Same.\n. ",
    "shs96c": "I'm looking into this now.\n. I'm looking into this now.\n. There have been some discussions at facebook about sniffing the local system to see if there's a python version that meets the requirements for buck (so Python 2.5 with the imports required for buck.py) and using that in preference to jython if asked.\nRight now, it's gone no further than a discussion, as for a large tree our measurements suggest using jython is an overall speed win.\n. Reviewing now. Thanks for the ping!\n. Sorry about that. We decided to go with the naming convention of adb for identifying which device to target when running tests since we had a clash with \"-e\" between the (un)install commands and the running test one. If you can think of a better short-name to use for \"exclude\", I'd be happy to add something back.\nIf not, is there anything to be done for this issue? I'm not sure if you're requesting us to change it back or just informing us that we should be better at announcing changes (or both)\n. It's a good point about the communication of changes, particularly of our UI. Thanks for bringing it up. @bolinfest, perhaps we should start keeping some sort of changelog?\n. I'm surprised. From the entry you link to, you say that the manifest isn't properly formed. What's the best way to repro the issue? Just run that target? Which entry in particular are you expecting to see in the manifest?\nThe code which generates the final jar for a java_binary can be seen here:\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/java/JarDirectoryStep.java\nIn \"createJarFile\" we pass in a Manifest, which is updated (in \"merge(Manifest, Manifest)\") as each dependent jar is read. The final thing that happens is that we write the manifest entry to the jar. The end result is that the manifest in the generated jar should be the combined manifest.\nAs you can also see, the \"getDescription\" method takes a few liberties about how we represent this process. :)\n. Ah! Now I understand. Yes, it's lame that we do that, and we should fix the behaviour.\n. Getting a patch reviewed for this.\n. I've just landed it on our internal repo, and it'll be out in the next MOE push.\n. Marking as \"closed\" because the code is now in a tree, and just waiting to be pushed out to Real Life.\n. We probably shouldn't be leaking resources. Thanks for the heads up. \n. Looking now.\n. Taking a look now.\n. After discussion on #68 this has been implemented in cea4e34466af532744c5c1ead9f48780c128f047 The documentation can currently be found here:\nhttp://facebook.github.io/buck/rule/java_library.html\n. After discussion on #68 this has been implemented in cea4e34466af532744c5c1ead9f48780c128f047 The documentation can currently be found here:\nhttp://facebook.github.io/buck/rule/java_library.html\n. To clarify, you're asking to have a set of deps that need to be built before you can start compiling, and a second set of dependencies that need to be completed before packaging of the dependent java_binary can start?\n. OK. Understanding you now. How about a general \"provided_deps\" parameter for java rules?\n. I'm working on a fix for this now.\n. This was implemented in cea4e34466af532744c5c1ead9f48780c128f047\n. Out of curiosity, is the provided_deps parameter meeting your needs?\nSimon\nOn Fri, May 2, 2014 at 10:16 PM, Shawn O. Pearce\nnotifications@github.comwrote:\n\nNever mind, I am an idiot, I forgot to recompile Buck.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/pull/68#issuecomment-42079919\n.\n. Great news! Thanks for letting me know :)\n\nSimon\nOn Mon, May 12, 2014 at 9:11 PM, David Ostrovsky\nnotifications@github.comwrote:\n\n@shs96c https://github.com/shs96c Thank you so much for fixing it:\nworks like a charm! We have removed our work around in Gerrit Code Review\n[1] itself and in bucklets buck library [2] that we are using for other\nprojects in Gerrit ecosystem [3].\n[1] https://gerrit-review.googlesource.com/56780\n[2] https://gerrit-review.googlesource.com/56823\n[3] https://gerrit-review.googlesource.com/56824\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/pull/68#issuecomment-42881636\n.\n. The only time I've seen this be a problem in practice has been when pulling in BouncyCastle, which uses a signed, sealed jar. @spearce, while I can see the theoretical point, I'm curious to know if this is an actual problem you've encountered, or a code cleanliness thing?\n\nHow would you suggest we cope with things such as the \"Class-Path\" manifest entries? Or related ones to do with SPIs? To be fair, we don't handle those well right now, but it seems like something that should be dealt with. \n. I landed a flag on java_binary that allows you to take control of whether\nor not manifest merging occurs. After talking with @davido on IRC that\nseemed like the best bet. It should be in the OSS tree RSN.\nOn Fri, May 30, 2014 at 7:25 PM, David Ostrovsky notifications@github.com\nwrote:\n\n@spearce https://github.com/spearce Thanks for checking. It was\nmisunderstanding in our talk in MV from my side and i appologize: I said in\nchat with @shs96c https://github.com/shs96c that Blaze is using special\noption to prevent merging manifest from dependent JARs and would merge them\nwithout this option.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/86#issuecomment-44683455.\n. I'm working on a fix for this and hope to land it soon.\n. Thank you very much for the PR, however I already landed an implementation that does this: 57b64e780c2453f892ed0e28425c6364b78d0d04\n\nCould you please let me know if that works appropriately for you?\n. We're removing genfiles, so it's best to avoid them. Fortunately, there's an alternative! The recommended way to do this is to directly reference the target. For your example:\nandroid_manifest(\n  name = \"app_manifest\",\n  skeleton = \":update_version\",\n  deps = [\n    \"//lib:lib\",\n  ],\n)\n. One of the ideas I've been toying with is making buck itself an\npython_binary. That would allow us to build a versioned artifact to check\ninto a repo (or otherwise put under source control) which would certainly\nsimplify things.\nSimon\nOn Wed, May 7, 2014 at 5:47 AM, David Pursehouse\nnotifications@github.comwrote:\n\nThanks for the suggestions.\nUsing .nobuckcheck is unfortunately not an option as the different\nbranches of Gerrit do have dependencies on the different versions of buck.\nCurrently I am working on 3 branches, each of which uses a different\nversion :(\nI'll see if I can make a script that will automatically set symlinks based\non which branch is checked out.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/102#issuecomment-42389160\n.\n. Fixed in 1ac479f1052d8b28a91edb47d0d7da195a2d2701\n. OK. I've got a diff up that fixes this. Thank you for letting us know, and helping keep us honest :)\n. Both David and I are looking at this.\n. We've landed @dreiss and my fixes. Can you please let us know if these help?\n. Would outputting a wheel be the Right Thing to do here?\n. I've a fix for this to land. The problem was making the \"out\" part of the RuleKey without converting it to a String first.\n. I'll have another look.\n. Got it working. Landing a patch soon.\n. I've not tested with snapshots. If it works as-is, I'd be pleasantly surprised. Do you use them on gerrit?\n. OK. Good to know. \n. I've a patch out for review to fix this. It'll be available soon.\n. If it was just building Buck, this would be a lot easier. :)\n\nDownloading cygwin to my Windows machine now. Does it support symlinking? Or do I need to use the Windows hack to make it work?\n. I've got a diff up for the monotonic_time_nanos() problem, and I've applied the one you linked to on the IRC channel as a second one.\nFor the Python interpreter, have you set the value in \"[tools] -> python\" in your .buckconfig?\n. You're most likely using the Windows Java version rather than a cygwin port. I wonder if you tried something like c:/python27/python.exe whether things would work?\n. Yes, I mean try the native Windows version of Python rather than the cygwin one. You should have some more complete logs in the buck-out/logs directory, which may shed some light on the situation.\n. Do the logs under \"buck-out/log\" contain any more information about the reason the build failed? I'd hope that there would be a stack trace in there.\n. Also digging into this.\n. Not so much an official walk through, but a quick brain dump.\nStart by implementing Description. The type parameter of the Description is referred to as the \"constructor arg\" for historical reasons, but the public fields of the class of the type parameter are used as the parameter names in your Buck files. (Take a look at ExportFileDescription for a lightweight example). The BuildRuleType returned by getBuildRuleType gives you the rule name.\nDescriptions are typically named after the rule that they (uhh..) describe. That is \"GenruleDescription\" is the root of how a Genrule is constructed, \"JavaTestDescription\" is how a JavaTest is constructed and so on. Generally, you can guess the class name by taking the rule name as used in build files, un-snake-casing and appending \"Description\"\nA Description is a factory of BuildRule instances. The Flavor of a BuildTarget can be used to make the Description return a different kind of BuildRule, but in the common case, you don't need to use them. BuildRule implementations typically extend AbstractBuildRule. To keep things simple, you can annotate fields with \"@AddToRuleKey\" on your BuildRule and it'll automatically be added to the RuleKey (which is used to determine whether or not a rule needs to be rebuilt)\nA BuildRule is used to construct Step instances. These are the things that actually do the work, and if you're creating a new type of build rule, it's likely you'll need to add new steps. That's cool.\nWe like unit tests where possible, so go nuts adding them too. We use junit. If you'd like an end to end test, take a look at calling it something ending with \"*IntegrationTest\" (ExportFileIntegrationTest is one example). These tend to use files from \"testdata\" directories to run tiny builds.\nFinal thoughts:\n- Outputs of build rules go in the \"gen\" directory. Scratch files, that aren't outputs, can be found in the \"bin\" directory. You can use BuildTargets.get{Bin,Gen}Path to create a Path to one of these quickly and easily.\n- A \"SourcePath\" is something that could either be a Path on the disk (relative to the project root) or the output of a BuildRule. Use the SourcePathResolver to get a concrete Path out of it.\n- Good luck, and may the Force be with you.\n. buck audit rule-types\n. Thank you!\n. There's someone working on maven interop right now (we should see some diffs land soon). We'll probably either extend \"buck install\" or add a new command to handle pushing artifacts to maven central.\nIf you're interested in hacking on it, I think the first step would be to add an optional \"maven_coord\", \"binary_sha1\" and \"source_sha1\" to \"prebuilt_jar\" and allow us to (optionally) download the jar by adding \"remote_file\" rules into the action graph if necessary.\nThere's still some thinking to be done on minimizing the number of artifacts that we'd push to a maven repo --- naively, you can imagine one artifact per buck target, but that would be a nightmare to maintain, and I'd not want to have to handle versioning :)\nConceptually, Buck is a build tool, rather than SDLC tool. More concretely, \"buck build\" is just for the assembly of artifacts: side-effects break the functional model it's based on. Other phases of an artifact's lifecycle are handled by separate commands, and support side-effects. For example, things like deploying or running commands are handled by \"buck install\", \"buck run\" and \"buck test\" respectively.\n. Reviewing this now. Thank you!\n. Reviewing this now. Thank you!\n. I'm wondering if it's an unexpected interaction between your shell and ant. Looks like you're using zsh? Can you try:\nbash -c ant\n. Also, the inability to infer the generic type looks like Java 6 is being used. Which is deeply quirky. I notice that your JAVA_HOME isn't set in your printenv, though it is in your example build which fails. Wondering whether ant is somehow falling back to the default Apple JDK?\nIf you modify the \"compile-testrunner\" target in the build.xml (line ~222) to specifically target java 7 by setting source=\"7\" target=\"7\" does that make any difference?\n. Does Buck build inside IntelliJ on your machine?\n. I've pinged Roy with an alternative proposal.\n. I'm trying to land a fix for that now. \n. The code for handling java and android has grown somewhat (umm...) organically. Cleaning it up is an excellent idea, and the suggested structures make sense to me. Would be happy to hang out on IRC to help coordinate this, since there are a few of us who are interested. Or I can just review PRs :)\n. Looks like we need to model the GWT compiler as a Tool, and ensure that its transitive deps are added as first order deps of the gwt_binary rules.\n. Looks like we need to model the GWT compiler as a Tool, and ensure that its transitive deps are added as first order deps of the gwt_binary rules.\n. Thanks for the PR!\nThe problem this code was attempting to resolve is that aether appears to merge dependencies. That is, consider the case where libraries \"a\" and \"b\" both depend on library \"z\". You'd want the transitive dependencies of both \"a\" and \"b\" to contain a reference to \"z\". With the way that the results are returned right now, only one of them would iff you collected both the same request.\nThis kind of behaviour ripples all the way down, so the simple solution of a request per command line arg doesn't solve the problem (that is, if \"c\" depends on both \"a\" and \"b\", then only one of these would claim to have a dep on \"z\")\nIf all you're trying to do is setup a classpath, this kind of thing is fine --- after all, you just want the library to be mentioned once and Everything Will Work As Expected. Sadly, that's not what we're actually doing here.\nI'll add a test for this case, and see if your change continues to pass it. If it does, then I'll merge it in pronto! \n. Thanks for the PR!\nThe problem this code was attempting to resolve is that aether appears to merge dependencies. That is, consider the case where libraries \"a\" and \"b\" both depend on library \"z\". You'd want the transitive dependencies of both \"a\" and \"b\" to contain a reference to \"z\". With the way that the results are returned right now, only one of them would iff you collected both the same request.\nThis kind of behaviour ripples all the way down, so the simple solution of a request per command line arg doesn't solve the problem (that is, if \"c\" depends on both \"a\" and \"b\", then only one of these would claim to have a dep on \"z\")\nIf all you're trying to do is setup a classpath, this kind of thing is fine --- after all, you just want the library to be mentioned once and Everything Will Work As Expected. Sadly, that's not what we're actually doing here.\nI'll add a test for this case, and see if your change continues to pass it. If it does, then I'll merge it in pronto! \n. Right now, I'm a little bit crunched for time to look at this, since I'm working on landing the cross-cell support. Someone else on the team may get to this before I do, but this hasn't fallen off my list.\n. Right now, I'm a little bit crunched for time to look at this, since I'm working on landing the cross-cell support. Someone else on the team may get to this before I do, but this hasn't fallen off my list.\n. I added the SrcZipAwareFileBundler to make it easier to work with src zips, which makes option 1 easier to implement. The main thing with the Jsr199Javac is that it avoids the need to start a separate compiler process, which reduces the overhead of dealing with things.. You're not meant to differentiate between cell contexts when handling files, so an absolute path is the right way to handle it.\n. I just ran buck test --all with this change in, and a bunch of tests failed. Looks like the travis build failed with the same problems.\n. I see this too, but only when running the PEX.\n. Java 8. \n. I've not touched the listeners in the events package. It's seems like a problem for autodeps to fail.\n. As an aside, when I wrote the original coercer and reflective magic, I very deliberately chose to avoid forcing people to inherit from a buck class for their parameters. Generally they fall into \"everything has it\", in which case it should just be handled transparently, or \"specific to a rule, but perhaps incredibly common\", in which case having it be on the arg is a Bad Idea.\n. As an aside, when I wrote the original coercer and reflective magic, I very deliberately chose to avoid forcing people to inherit from a buck class for their parameters. Generally they fall into \"everything has it\", in which case it should just be handled transparently, or \"specific to a rule, but perhaps incredibly common\", in which case having it be on the arg is a Bad Idea.\n. You do know the buck internals really well. \nSent from my iPhone\n\nOn 1 Mar 2016, at 23:32, Shawn Wilsher notifications@github.com wrote:\nThis was the solution @marcinkosiba and I came up with for licenses because putting it in BuckPyFunction is rather non-discoverable unless you happen to know Buck internals really well.\n\u2014\nReply to this email directly or view it on GitHub.\n. You do know the buck internals really well. \n\nSent from my iPhone\n\nOn 1 Mar 2016, at 23:32, Shawn Wilsher notifications@github.com wrote:\nThis was the solution @marcinkosiba and I came up with for licenses because putting it in BuckPyFunction is rather non-discoverable unless you happen to know Buck internals really well.\n\u2014\nReply to this email directly or view it on GitHub.\n. Add the test and I'll make sure it passes. Probably should end up as a field on the targetnode. \n\nSent from my iPhone\n\nOn 1 Mar 2016, at 23:53, Coneko notifications@github.com wrote:\nI'm confused, how are you supposed to access the licenses with this change? They're not a field on target node like visibility and they're not a field on the constructor arg like before this change.\nI guess it's @sdwilsh's bad for not adding a test, but buck query \"labels('licenses', deps('buck'))\" should return the list of licenses used in Buck.\n\u2014\nReply to this email directly or view it on GitHub.\n. Add the test and I'll make sure it passes. Probably should end up as a field on the targetnode. \n\nSent from my iPhone\n\nOn 1 Mar 2016, at 23:53, Coneko notifications@github.com wrote:\nI'm confused, how are you supposed to access the licenses with this change? They're not a field on target node like visibility and they're not a field on the constructor arg like before this change.\nI guess it's @sdwilsh's bad for not adding a test, but buck query \"labels('licenses', deps('buck'))\" should return the list of licenses used in Buck.\n\u2014\nReply to this email directly or view it on GitHub.\n. There are no tests. \n. No idea why //test/com/facebook/buck/android:integration fails in Travis. Works fine for me (tm)\n. No idea why //test/com/facebook/buck/android:integration fails in Travis. Works fine for me (tm)\n. I'm doing some clean up of how the selenium fork handles maven, javadoc, and source jars, and this came loose. Sits in a nice diff on its own, and tidies up the main tree.\n. I think it's just autodeps clashing. \n. I think that this fixes the problem seen here on the Selenium CI builds, which don't have pathlib available in their python installs: http://ci.seleniumhq.org:8080/job/Firefox%2038%20Linux%20Javascript%20Tests/2775/console\n. I've not measured the performance delta, but the pywatchman python_library doesn't have the C code as a dep, so it's not used by anything that links against it anyway.\n. I've not measured the performance delta, but the pywatchman python_library doesn't have the C code as a dep, so it's not used by anything that links against it anyway.\n. For an example of this in action:\n\nhttps://github.com/SeleniumHQ/selenium/blob/selenium-3.0.0-beta-3/java/client/src/org/openqa/selenium/BUCK#L23 \n. Added a test\n. Added a test\n. Tests passing :)\n. Rebased for fun and profit.\n. Rebased for fun and profit.\n. This includes some of the building blocks for the maven work. Notably, there's JarShape which makes it easier to handle \u00fcber jars and the like.\n. This includes some of the building blocks for the maven work. Notably, there's JarShape which makes it easier to handle \u00fcber jars and the like.\n. Please land PR #977 first!\n. Took me ages to track down why the test Daniel asked me to write wasn't working. . This is old, tired, and woefully out of date. Abandoning. . I note with interest that autodeps had plenty of unused dependencies. Perhaps an intern could be \"encouraged\" to clean those up through the project?\n. Investigated failures. The go and util tests seem unrelated to this diff. Fixed the other one.. Guess it's safe to ignore Appveyor since it can't even check out the build.. Test failures look unrelated. One is Appveyor crapping out because a path is too long. The other is something choking in Android in an area that's unrelated to logging output.. I kind of expect a few rounds of review on this one, but let's kick off the process. This is the largest delta between Selenium's Buck version and Facebook's. It'd be nice to get us back to using the official Buck release.. The package name is weird because I wrote these for the fork of Buck used by Selenium (org.openqa.selenium is our normal package). I'd be okay changing the package name if it'd make life easy.\nThe only tests that ever existed were the build for selenium.... Writing some sanity checks wouldn't be too hard.. I take it you've seen the maven importer that's part of Buck already? It\nuses the aether libraries to import dependencies from maven into your tree.\nThe original idea was for there to be a command line switch to allow it to\nset the generated BUCK files up to use remote_file instead (or as well),\nbut I never got round to finishing it.\nOn Wed, Nov 1, 2017 at 8:17 AM, Bhagya Nirmaan Silva \nnotifications@github.com wrote:\n\n@sbalabanov https://github.com/sbalabanov Would like to see the\nrequirement for SHA1 specification removed. remote_file is not suited for\nMaven artifacts, since it adds a significant migration overhead.\nAlso the ~/.m2/repository already contains the SHA1 for each Maven\nartifact. maven_library should automatically resolve the SHA1 from the\nMaven local cache.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1607#issuecomment-341030611, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABuRQvM2QXkEvPiUc5RaPebvDnJxsnUks5syCk2gaJpZM4QMpvI\n.\n. Is there a public, stable API that I can use for my plugins? I'll need\nthat, since these appear to be java code.\n\nCan I redefine existing rules?\nHow do I refer to functionality in other plugins from my own? For example,\nif I want to use the FIleBundler from the zip rules, how is this done?\nOn Thu, Nov 16, 2017 at 1:57 PM, Gautam Korlam notifications@github.com\nwrote:\n\nAnother question is if the hash of the cxx module changes, does that mean\nthat java rules will be unaffected upon updating buck?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1626#issuecomment-344930012, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABuRfEZaJTo2LY_FEwasYzZLgUSANtNks5s3D9YgaJpZM4Qfk_j\n.\n. Can extensions be built and loaded as part of a single build?\n\nThe original plans for extensions included allow each cell to define its own extensions. I'm hoping this will be retained.. > > Can extensions be built and loaded as part of a single build?\n\nCould you explain this scenario, please?\n\nI think it'll be something needed to enable extensions to continue working despite a shift in ABI in Buck's core. Right now, Skylark rules in Bazel are immune from changes in Bazel's core since they're interpreted. Given how extensions are being developed here, this won't be the case for Buck.\nMore practically, the Selenium project has rules for packaging Firefox extensions defined as things like \"mozilla_extension\". This doesn't feel like a good fit for Buck itself (as it builds a XPI, which Mozilla have just EOL'd), but it's really useful to be able to refer to these in our own build. Something like this in the BUCK file would be splendid:\n```\nContains the extension definition for mozilla_extension\nload_extension(\"//java/buck/src/org/openqa/buck/mozilla:mozilla\")\nmozilla_extension(name = \"webdriver.xpi\",\n  ...\n)\n```\nI was looking at the rules deleted in 5fcf326a4b8d22fbbd5ce8e593b58fdbe7f7d425 but it doesn't look like that shows injecting a new build rule into KnownBuildRules. > What stops you right now to write custom build rules using Skylark?\nI need to use the zip functionality, and I can't rely on that being installed on the machine, or that the generated zips will be repeatable (with timestamps cleared, etc). In addition, I need this to work on Windows, Linux, and OS X, which makes using genrules a Really Bad Idea.. Python is a PITA. I run training sessions where I tell people to install Python 2.7 and they still install the latest python 3.x. It's also slow as heck on Windows. Fortunately, the skylark build file parser helps an awful lot.. The zip files? It's the FileBundler I'm keen to use. As of the latest versions of Buck, I can start the move to modules, but there's one small problem: some of my Description instances need access to the BuckConfig.\nWriting a simple method to find the longest public constructor and shoving values into it isn't particularly taxing --- it's a handful of lines of code. I'm not quite sure where to hook it in.\nAlso, it'd be nice if there was a PluginManager per Cell rather than globally..... Got this working with Selenium's code base. Lovely.\nThe next shiny it'd be great to have are:\n1/ Provide a stable API to build extensions against (ModernBuildRule, Step,\nand \"anything that transitively leads to these\" are required. Things like\nthe file copying steps are incredibly useful primitives too)\n2/ Allow us to specify a path to extensions in .buckconfig and have these\nbe loaded per-cell.\n3/ Allow a build to bind an extension \"mid-build\"\nThe third case would allow us to ship the extensions to Buck that Selenium\nuses as part of our own tree.\nOn Mon, Nov 27, 2017 at 6:36 PM, Sergey Tyurin notifications@github.com\nwrote:\n\n@shs96c https://github.com/shs96c 2988b70\nhttps://github.com/facebook/buck/commit/2988b70363ef2ae556f37ab244e05c4baf35bce7\nadded an ability to access BuckConfig when creating descriptions.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1626#issuecomment-347280474, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABuRUYN1RDZjhwq8RcV7H54Pxaqpobpks5s6wEegaJpZM4Qfk_j\n.\n. For Java, it makes sense to put the build stamp in the manifest. That should be fine when building an binary from several publishable libraries --- we only need the information once, and for the most recent build.. You may need to kill the buck daemon once you've changed the JAVA_HOME.\nDoes buck kill followed by a buck command work as expected?\n\nOn Mon, Apr 2, 2018 at 8:02 PM, Gautam Korlam notifications@github.com\nwrote:\n\ncc @ttsugriy https://github.com/ttsugriy\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1828#issuecomment-378012203, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AABuRZg3ZLquudygHnKmhlEkDtkM2CwPks5tknXVgaJpZM4TD7hl\n.\n. Currently, buck fails like so:\n\n```\nError: A JNI error has occurred, please check your installation and try again\nException in thread \"main\" java.lang.Error: java.lang.ClassNotFoundException: com.facebook.buck.cli.bootstrapper.filesystem.BuckFileSystemProvider\n    at java.base/java.nio.file.FileSystems$DefaultFileSystemHolder.getDefaultProvider(FileSystems.java:141)\n    at java.base/java.nio.file.FileSystems$DefaultFileSystemHolder$1.run(FileSystems.java:111)\n    at java.base/java.nio.file.FileSystems$DefaultFileSystemHolder$1.run(FileSystems.java:109)\n    at java.base/java.security.AccessController.doPrivileged(Native Method)\n    at java.base/java.nio.file.FileSystems$DefaultFileSystemHolder.defaultFileSystem(FileSystems.java:109)\n    at java.base/java.nio.file.FileSystems$DefaultFileSystemHolder.(FileSystems.java:103)\n    at java.base/java.nio.file.FileSystems.getDefault(FileSystems.java:190)\n    at java.base/java.io.File.toPath(File.java:2290)\n    at java.base/java.util.zip.ZipFile$Source.get(ZipFile.java:1222)\n    at java.base/java.util.zip.ZipFile$CleanableResource.(ZipFile.java:726)\n    at java.base/java.util.zip.ZipFile$CleanableResource.get(ZipFile.java:843)\n    at java.base/java.util.zip.ZipFile.(ZipFile.java:246)\n    at java.base/java.util.zip.ZipFile.(ZipFile.java:176)\n    at java.base/java.util.jar.JarFile.(JarFile.java:346)\n    at java.base/jdk.internal.loader.URLClassPath$JarLoader.getJarFile(URLClassPath.java:804)\n    at java.base/jdk.internal.loader.URLClassPath$JarLoader$1.run(URLClassPath.java:749)\n    at java.base/jdk.internal.loader.URLClassPath$JarLoader$1.run(URLClassPath.java:742)\n    at java.base/java.security.AccessController.doPrivileged(Native Method)\n    at java.base/jdk.internal.loader.URLClassPath$JarLoader.ensureOpen(URLClassPath.java:741)\n    at java.base/jdk.internal.loader.URLClassPath$JarLoader.(URLClassPath.java:716)\n    at java.base/jdk.internal.loader.URLClassPath$3.run(URLClassPath.java:484)\n    at java.base/jdk.internal.loader.URLClassPath$3.run(URLClassPath.java:467)\n    at java.base/java.security.AccessController.doPrivileged(Native Method)\n    at java.base/jdk.internal.loader.URLClassPath.getLoader(URLClassPath.java:466)\n    at java.base/jdk.internal.loader.URLClassPath.getLoader(URLClassPath.java:435)\n    at java.base/jdk.internal.loader.URLClassPath.getResource(URLClassPath.java:304)\n    at java.base/jdk.internal.loader.BuiltinClassLoader.findClassOnClassPathOrNull(BuiltinClassLoader.java:696)\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClassOrNull(BuiltinClassLoader.java:622)\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:580)\n    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)\n    at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)\n    at java.base/java.lang.Class.forName0(Native Method)\n    at java.base/java.lang.Class.forName(Class.java:398)\n    at java.base/sun.launcher.LauncherHelper.loadMainClass(LauncherHelper.java:760)\n    at java.base/sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:655)\nCaused by: java.lang.ClassNotFoundException: com.facebook.buck.cli.bootstrapper.filesystem.BuckFileSystemProvider\n    at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:582)\n    at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)\n    at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:521)\n    at java.base/java.lang.Class.forName0(Native Method)\n    at java.base/java.lang.Class.forName(Class.java:398)\n    at java.base/java.nio.file.FileSystems$DefaultFileSystemHolder.getDefaultProvider(FileSystems.java:131)\n    ... 34 more\n``. This is basically whatSourcePaths.getToBuildTargetSourcePath()does.\n. Probably never, unless there's been a terrible foul up.\n. I can't find a public method that does this. Most irksome. It's not regular enough to use the JavaBeans APIs to introspect over it either. \n. We could, but I'd prefer to do that in a follow-up diff.\n. Done.\n. In Buck and Selenium, running the maven target for the complete source tree is still pretty fast --- it takes longer to create the javadocs by a long shot. Couple this with the fact that the publish command can only publish a single target at a time, and I think that the clarity of this code is okay for now. We can always ask @yiding to do some magic ;)\n. Done.\n. Done.\n. Deleted.\n. Done\n. But now sorted out with something that's easier to read too.. I'm not sure that makes the code more readable. We basically have the fast-path of doing nothing, or something that takes legwork. Theelsekeyword isn't necessary, though.. Done. Done. Well, the parser I've added only understands Java syntax\u2026.. Same logic applies.. Because the only requirement that a java class has is that it's in a file named after the class (e.g. \"com.facebook.buck.step.Step\" must be in \"Step.java\"), the location on the file system doesn't matter (eg. for our example we might findStep.java` in the root of the source tree).\nHowever, when it comes to actually using source jars, the files do need to be in the right place (eg. \"com/facebook/buck/step/Step.java\") in order for the IDEs to not freak out. In a well-behaved tree, the heuristics applied by the DefaultJavaPackageFinder are enough, but they fail in a couple of pretty common cases: if there's a package name called test and one of the java_roots is also test, if the file has been generated (that is, is derived from a BuildTargetSourcePath), or if the file isn't in the \"correct\" directory.\nFortunately, java makes it Really Easy to tell which package a class is in: the package declaration at the top of the file. So the parser I added simply handles enough java source to extract the package. We don't want to parse the entire file, since that's a massive waste of resources, and is cross overkill for what we want, which is why I'm not attempting to load the class into either Java's own class mirror, or the eclipse code we use when trying to provide helpful hints about dependencies.\nTLDR; the mechanisms we have in place for figuring out packages right now either don't work or are doing way too much work and are fragile in the face of evolving java syntax.. This isn't a full blown java parser, it just handles enough to get to the package declaration. Parsing files using regex is generally considered a pretty bad idea, and possibly error-prone since there might be a package declaration in a comment. Put another way, we either need a very complex regex or a simple parser in order to be consistently correct. I opted for a parser.\nGiven that this parser is only used from the JavaSourceJar class, I'm not sure why you mention kotlin, Scala, and groovy. It seems beside the point of this diff.. cf: parsing things with regex: http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454. When we construct source jars for other languages, we can certainly do that.  We don't at the moment. I'd rather be correct in the cases we deal with now, and figure out how to be correct as we add more cases (the obvious thing to do would be to have a strategy be selected based on input file name). Done. Good catch. Done.. Changed to a HumanReadableException and added the file name.. If we never see a package declaration, we're in the default package, and that might happen. We also use the UNKNOWN token to handle the case where we hit anything that might precede a package statement, so interface, class, and enum (and modifiers) all get treated that way. I'd chosen to play it safe for now, and the approach seems to work on both Buck's code and Selenium's. Because we've run out of parseable data, and UNKNOWN is a terminal condition.. Same logic. I could add an EOF token, I guess.. As above.. I thought it might be useful when debugging. Stripped that last character.. If the .asc is missing and signing has been enabled, the check at Publisher.java:322 will cause an exception to be thrown. The test will fail if the executor isn't called, and I've added an assert that every expected command is executed.. Hahaha! I thought the method made the assert already. facepalm. Ha! Ooops. :) Rolled back to master's. Yes. Fixed.. You want people to be able to use a query string that returns either rules or files and have it work in the same way, which makes it easier to iteratively futz with the query string as you tweak a build to get it Just Right.\nIdeally, there would be just a single query macro that works no matter what it is you're trying to do. That's not where we are :). ",
    "sdwilsh": "@spearce - did everything get merged in here or are we missing a few pieces still?\n. We don't want genrule to be able to do this, but I filed an issue for the feature you need out of this.\n. First, I'm really sorry that nobody ever responded to this.  However, it's been nearly a year, and I suspect this issue doesn't exist anymore.  We've recently done some work to improve the quickstart flow, so I'm going to optimistically close this, but please feel free to re-open with any details so we can take a better look.\n. @bolinfest I saw those, but it didn't look at all related to what @mkurutin or @BrianBal listed as issues.\n. Buck doesn't really have a concept of a version short of the .buckversion file in the project that is trying to build it.  Any valid git hash is a valid version for Buck in that sense.\nWe might revisit this in the future, but for the immediate future, I can't see us doing this.\n. Is this still an issue for you @spearce?\n. What's the use case for building just the library?  If you want to export it for others to use, you really want to publish an AAR (which is tracked by #117).\n. Feel free to reopen, but I think you really want #117.\n. 3afdcbd0abcbd7b9f43091b31083f33f2bd3c2de added a buck fetch command.  Are we good here now?\n. Yeah, the closing was a bug.  We'd like to get this, it just hasn't been a priority for the core team.\n. @cakoose - want to cook up a pull request for that?\n. Closed by #115 \n. Do you have a simple, reproducible test case for this by chance?\n. I think this addresses the issue, and the author hasn't responded in six months, so I'm going to close this.\n. If you give Buck a prebuilt jar that is broken, bad things will happen.  @dreiss and @andrewjcg are right; the right way to fix this is to correct the jar.\n. I haven't actively worked on the Buck project in over nine months, so I'm going to cc @Coneko who is my best guess for someone who might be able to respond to you, @brettwooldridge.\n. exopackage now handles multiple dex files: http://facebook.github.io/buck/article/exopackage.html\n. exopackage now handles multiple dex files: http://facebook.github.io/buck/article/exopackage.html\n. @edwardspeyer had advocated a way to not run the android tests if you don't have it installed at one point.\n. @edwardspeyer had advocated a way to not run the android tests if you don't have it installed at one point.\n. I fixed this internally; just waiting for @shs96c to push it out.  We'll no longer require the Android SDK when running tests (we don't currently require it to build).\n. Indeed it is.\n. This option isn't actually useful.  We should probably consider removing it.\n. If you buck build buck now, you'll get a PEX that you can distribute (this is not platform independent though).  At Facebook, we've solved this by using a network mount and writing a small script that looks for the appropriate version based on the .buckversion file.  You could also check that into your tree instead of a .buckversion file if everyone was on the same platform (as much as I hate to suggest checking in binaries).\nThis isn't something we envision Buck doing itself.\n. Actually, it looks like @shs96c never got around to updating these docs.\n. It looks like the documentation largely matches what was found here today.  I'll add @marcinkosiba's example as an example on that page now and add some text to clarify the root.. Hey, @natthu, didn't you already push a fix for this?\n. Hey, @natthu, didn't you already push a fix for this?\n. We now have integration tests for this provided by @shs96c as well.  If someone wanted to submit a pull requests for documentation for these rules, we'd happily take it.\n. We're actually looking at supporting this through the power shell.  Some basic things work now, but it's not in great shape yet.  We'd happily take patches to improve things!\n. What do you need, specifically?  At this point, Android stuff is pretty solid on Windows, but I'm interested to know what you might need.\n. @oconnor663 fixed this; we just didn't close it it would seem.\n. buck build debug would try to build the target debug.  In this case what you probably want to do is have a genrule that creates the debug manifest or just include a debug manifest in your tree and reference it for your debug target.\n. I'm really confused why it made me the author of that commit.  It's true I pushed it, but locally the commit says the author is you.\n. All better now :)\nThanks for the patch!\n. Website didn't actually update with the push. I'm missing something, but I'm not sure what yet.\n. Yeah, I just found that.  Total n00b at doing this, but trial by fire and all.\n. Finally got it to work :)\n. Thanks again for your contribution!  You got mentioned in our update: https://www.facebook.com/buckbuildtool/posts/639627462773633\n. I think it's my fault.  I've been playing with the code backing it, and \nI think I made it too aggressive...\n. We actually backed out the cross repo stuff as it wasn't working correctly anymore.\n. It should be in within a month would be my guess.  You could probably start to play with it seriously as early as next week.\n. Would you be up for writing a test for this behavior too so it doesn't get accidentally broken?\n. @davido - I was talking to @oconnor663 on Friday and he might pick this up and address the one comment on this.\n. @davido - I was talking to @oconnor663 on Friday and he might pick this up and address the one comment on this.\n. I just wanted to make sure you saw my comments on the commit.  I'm happy to merge this once that is addressed.\n. I just wanted to make sure you saw my comments on the commit.  I'm happy to merge this once that is addressed.\n. Sweet!  Thanks for cleaning this up.  I'll push the web changes now.\n. Thanks again for your contribution!  You got mentioned in our update: https://www.facebook.com/buckbuildtool/posts/639627462773633\n. Thanks again for your contribution!  You got mentioned in our update: https://www.facebook.com/buckbuildtool/posts/639627462773633\n. Oh, I now understand your question from last night about one line html pages.  You'll want to update our soy pages under docs and these html pages get generated from that.  There's a README.md file under docs that explains how this works.\n. We should totally fix this.  Good catch!\n. We should totally fix this.  Good catch!\n. While the error message is really bad there, we can't resolve any targets here since we cannot validate that this target can be built since the source files are missing.  I'm not sure this is actually a bug in this case.\n. While the error message is really bad there, we can't resolve any targets here since we cannot validate that this target can be built since the source files are missing.  I'm not sure this is actually a bug in this case.\n. I think we might have to agree to disagree here :)\nBuck cares that BUCK files are always parse-able.  Parsing includes ensuring that files actually exist; this follows the fail fast paradigm so you don't have to wait for your build to get to this point to know it's going to fail.\n. I think we might have to agree to disagree here :)\nBuck cares that BUCK files are always parse-able.  Parsing includes ensuring that files actually exist; this follows the fail fast paradigm so you don't have to wait for your build to get to this point to know it's going to fail.\n. What would you expect to happen if you also had an alias setup for test?  I think there are lots of edge cases here that don't make sense and actually make the tool more confusing.\n. What would you expect to happen if you also had an alias setup for test?  I think there are lots of edge cases here that don't make sense and actually make the tool more confusing.\n. Probably better to use .buckversion?\n. Probably better to use .buckversion?\n. I think we'd be OK supporting buck build :test in this case, but not buck build test.  Does that seem OK @sk-?\n. I think we'd be OK supporting buck build :test in this case, but not buck build test.  Does that seem OK @sk-?\n. The issue here is that Buck, by default, uses first-order dependencies because it results in much faster compilation.  That isn't terribly clear in the docs, however, so I'm going to clean that up.  I suspect your issues will go away if you specify --build-dependencies to be TRANSITIVE in your build command: http://facebook.github.io/buck/command/build.html\nCan you verify that?\n. The issue here is that Buck, by default, uses first-order dependencies because it results in much faster compilation.  That isn't terribly clear in the docs, however, so I'm going to clean that up.  I suspect your issues will go away if you specify --build-dependencies to be TRANSITIVE in your build command: http://facebook.github.io/buck/command/build.html\nCan you verify that?\n. Alright, sounds like I can close this then :)\n. Alright, sounds like I can close this then :)\n. @andrewjcg - do you know how this might happen?\n. @andrewjcg - do you know how this might happen?\n. Hmm, so in this case you generate a jar with a gen rule and then want to merge it with your library rule, yes?\n. @oconnor663 - might this be your dependency injection stuff?\n. @sk-, want to submit a pull request to fix the docs?  I'll be happy to pick it :)\n. @andrewjcg did this in 76178fac5abdb7eacdd04e543d1c7f7890f9c539\n. Once we get the CLA signed I'll be happy to merge this.\nYou might also want to have whatever e-mail address you did the commit with attached to your github account so it attributes it to you properly :)\n. https://github.com/facebook/buck/commit/a408e2dafbc19c2b4274d57c76c5d0f31bc6306b but I totally forgot to reference the pull request in the commit message.\n. Github is making it really hard to see what the actual change is at this point.  Is this still needed?\n. Yeah, I can't actually tell what your change is at this point.  Github is telling me there are 146 commits here, and I don't believe that :)\nI'm trying to get us on top of our pull requests and issues again and stay on top of them this time :)\n. I don't think this is intentional.  In what ways is it incompatible?\n. I think for now, we'd rather not support junit formatting.  If it keeps coming up, we'll revisit it.\n. I think for now, we'd rather not support junit formatting.  If it keeps coming up, we'll revisit it.\n. @mread, we actually generate these docs based on changes under https://github.com/facebook/buck/tree/master/docs (and there's a readme there on how to see your changes).  This change will just get blown away if we take it as-is.\n. @mread, we actually generate these docs based on changes under https://github.com/facebook/buck/tree/master/docs (and there's a readme there on how to see your changes).  This change will just get blown away if we take it as-is.\n. Dupe of #149\n. I believe that @simpleton has answered your question.  If not, please reopen this.\n. I believe you aren't specificing all of your dependencies.  Buck uses first order dependencies, which means you need to specify your deps, your deps deps, and so on.\nhttp://facebook.github.io/buck/concept/what_makes_buck_so_fast.html\n. I believe you aren't specificing all of your dependencies. Buck uses first order dependencies, which means you need to specify your deps, your deps deps, and so on.\nhttp://facebook.github.io/buck/concept/what_makes_buck_so_fast.html\n. Support issues should go to Stack Overflow now (tagged with Buck).  No response from the author now, so I'm going to close this.\n. @bgertzfield recently found a pretty bad situation with watchman where if you change more than 200 files, we end up checking all files again, which might actually impact your original issue and point (4).\n166 sorta covers (1) for you.  I believe @natthu is working on properly making it so we don't require watchman (3).  (5) is covered by #170.\nI don't think we have an issue filed on (2), do you want to file that?\n. @bgertzfield recently found a pretty bad situation with watchman where if you change more than 200 files, we end up checking all files again, which might actually impact your original issue and point (4).\n166 sorta covers (1) for you.  I believe @natthu is working on properly making it so we don't require watchman (3).  (5) is covered by #170.\nI don't think we have an issue filed on (2), do you want to file that?\n. @andrewjcg has a change for this to add a buck kill that will go out once @shs96c pushes our internal changes again.\n. buck kill is the way to do this in the future.\n. This should be fixed as of f4612f23e354cd4c03c3770020012959e71dced8.\n. We also need to update this for the python code, but I'll do that before landing this.  Thanks for the pull request!\n. We also need to update this for the python code, but I'll do that before landing this.  Thanks for the pull request!\n. We now have python_test which I think will help you out a bunch.\n. We now have python_test which I think will help you out a bunch.\n. I'm not necessarily opposed to gentestrule, but I don't think it's something we're planning to do any time soon.  @shs96c has talked about an extension API in the past that would allow for folks to implement unsupported things more easily, but it hasn't been a big priority for us to implement.\n. I'm not necessarily opposed to gentestrule, but I don't think it's something we're planning to do any time soon.  @shs96c has talked about an extension API in the past that would allow for folks to implement unsupported things more easily, but it hasn't been a big priority for us to implement.\n. Upon further thought, we don't want to support this.  There are too many nobs and dials to support in a generic way, and it'd be much better to either a) support specific test rules that are needed, or b) have an extension API that could implement rules.\n. @shs96c, possibly, yeah, although we wouldn't want to produce that as part of a build unless this was what you targeted.\n. After surveying a number of command line tools, I'm inclined to agree with @bolinfest.  There's no clear consensus, and I don't see a compelling reason to change our behavior.\n. After surveying a number of command line tools, I'm inclined to agree with @bolinfest.  There's no clear consensus, and I don't see a compelling reason to change our behavior.\n. Closing per my previous comment.\n. I think we have to be careful of the slippery slope fallacy here.  Buck is a build tool, and we do testing as well, but because it's a pretty natural extension (and code coverage is a natural extension of testing).  I'm not sure lint meets that same bar, but I don't have a strong opinion here.\n. Nobody on the core team is working on this currently, but we'd be happy to help someone put together a pull request.\n. 99a728cf4c4b35380d48ab1e6603dc8fe28e5842 made it so we automatically have watchman ignore any paths in your [project] ignore_dirs section.  I'm going to go ahead and make us also automatically not watch buck-out, and buck-cache.\n. 99a728cf4c4b35380d48ab1e6603dc8fe28e5842 made it so we automatically have watchman ignore any paths in your [project] ignore_dirs section.  I'm going to go ahead and make us also automatically not watch buck-out, and buck-cache.\n. What would still be left to do is to have Buck warn/error when .watchmanconfig isn't configured correctly.  @natthu, want to help with that?\n. What would still be left to do is to have Buck warn/error when .watchmanconfig isn't configured correctly.  @natthu, want to help with that?\n. Even better, 53f2b609d15abd56f4005293b59c7c343ff22ef7 made us ignore buck-out and buck-cache, so we just need to verify that the .watchmanconfig is correct, and surface any issues to the user.\n. Even better, 53f2b609d15abd56f4005293b59c7c343ff22ef7 made us ignore buck-out and buck-cache, so we just need to verify that the .watchmanconfig is correct, and surface any issues to the user.\n. To be clear, we don't need to verify that .watchmanconfig is correct, because Buck now tells watchman what it can safely ignore.  You don't need a .watchmanconfig file unless you have other tools (like hg) that also use watchman.\n. Can you update the pull request with only the actual change (and not the formatting changes)?\n. @mkonicek is totally revamping our IntelliJ stuff and making it much better.  It's behind an experimental flag right now, but it's probably worth checking out so you don't have to have a post-process script.\n. It sure would.  I also meant to tag @marcinkosiba...\n. The Travis build failure looks like it may be related: https://travis-ci.org/facebook/buck/builds/34247801#L3025\n. The Travis build failure looks like it may be related: https://travis-ci.org/facebook/buck/builds/34247801#L3025\n. Is it possible this change has caused us to use more memory when running tests?  (I think it's the JVM that has hit it's limit)\n. Is it possible this change has caused us to use more memory when running tests?  (I think it's the JVM that has hit it's limit)\n. Good catch!  I'm going to merge this internally, and @oconnor663 should have a push later this week (we use MOE, sadly, and a commit recently broke it so exporting is on hold until we get it fixed).\n. Good catch!  I'm going to merge this internally, and @oconnor663 should have a push later this week (we use MOE, sadly, and a commit recently broke it so exporting is on hold until we get it fixed).\n. @davido, can you verify that and close this if it has fixed your issue please?\n. @davido, can you verify that and close this if it has fixed your issue please?\n. I've done a lot of work to get Buck working well with Power Shell.  Do you hit the same issues there?\n. Honestly, I'm pretty tempted to wontfix this.  Supporting cygwin is a huge mess because sometimes it uses Windows semantics, and sometimes Unix, and it doesn't feel very consistent.\n. The error says Access Denied.  Do you not have permission the run the binary, by chance?\n. The error says Access Denied.  Do you not have permission the run the binary, by chance?\n. Yeah, the supported way to do this is to use the environment variable.\n. Yeah, the supported way to do this is to use the environment variable.\n. There is some debate on this internally; @andrewjcg has a diff up that does basically the same thing.\n. There is some debate on this internally; @andrewjcg has a diff up that does basically the same thing.\n. The diff appears to have stalled; I'll poke it.  Sorry about that!\n. The diff appears to have stalled; I'll poke it.  Sorry about that!\n. @dreiss - can you take a look at this?\n. I've been meaning to actually take a look at this this month if you still want to get it merged in.  I've been trying to get our older pull requests cleaned up.\nLet me know!\n. It sounds like we aren't caching empty directories properly then from an unzip step.  The good news is that it should be easy to write a unit test the demonstrate this!\n. It sounds like we aren't caching empty directories properly then from an unzip step.  The good news is that it should be easy to write a unit test the demonstrate this!\n. @jhansche - are you interested in getting the right fix in for this?  If not, feel free to close this and file an issue on us.\n. Closing this in favor of fixing #234 \n. What version of Buck are you running?\n. What version of Buck are you running?\n. #166 address the need for a buck kill command.  @bgertzfield fixed a bunch of issues with buckd such that we are pretty sure hangs like this are gone now.\n. It hasn't been a priority for the core team, to be perfectly honest.  If someone wanted to work on a PR, I'd be help to help get it merged in.\n. I think this method is responsible: https://github.com/facebook/buck/blob/f0759b0bfff1368bc715371c383dfd8c873f9991/src/com/facebook/buck/java/CopyResourcesStep.java#L84\n. Are you still seeing this @mread?\n. One of @Coneko's two changes are the likely culprits here: https://github.com/facebook/buck/commits/f0759b0bfff1368bc715371c383dfd8c873f9991/src/com/facebook/buck/java/CopyResourcesStep.java\nNeither of e0b54ac8bf0cc7a7d6cb5925cc36faab8da37d78 or da29cbe8c2bfcd9627ac229b5655d8da3940dc2d look particularly suspicious to me, however.\n. Although, I'm wondering if this wasn't getting picked up before by accident.  We've not had any filtering code there.  Are you passing include_dot_files in your glob?  http://buckbuild.com/function/glob.html\n. If you want to give me a patch for a test, that will certainly help me get it fixed :)\n. That'll do it.  Probably won't get to this until next week, however.\n. @FrancisToth - did you intend to close this?\n. Thanks for the pull request!\n. You can still use them in your main project; you just have to declare all of your dependencies and your dependencies dependencies.\n. See #375 \n. Thanks for the report.  It'd be great if you can confirm this fixes the issue for you.\n. Thanks for the report.  It'd be great if you can confirm this fixes the issue for you.\n. @marcinkosiba is currently reworking our project generation to be much better\n. @nicks, TLDR: Ant and Gradle structure Java sources differently from Buck.\nAnt and Gradle have a concept of \"application code\" and \"libraries\", but Buck only has libraries.  The application code gets one special privilege, however: its resource ids are constants, which means that they can be used in switch statements and annotations.  Realistically, this wouldn't be too hard to support with Buck.  I'll morph this issue for that.\nNote at this still won't work with library code: https://github.com/JakeWharton/butterknife/issues/100\n. Without seeing the code, it's hard to help you.\n. I think you meant f3b6cd48bab0247e8bf85ef3c52afd9b7e26dd95 (you added a q to the end).  I just hit this as well, but there's nothing useful in buck-out/logs.\n. I stand corrected.  The call to buck.py is missing --build_file_name, which is highly suspicious.\n. I'm still seeing it even after restarting\n. I'm still seeing it even after restarting\n. Martin is working on revamping our project generation.  It's hidden behind an experimental flag right now, but it should be much better than what we have today.\n. @FrancisToth, have you had a chance to try out the new project behavior?\n. @strangemonad - @alsutton has done a lot of work on this an the project flow is now vastly improved.\n@nsharma-git - that's probably worth raising with the gerrit project.  That's a special rule that they have and is unrelated to Buck.\n. Yeah, you are hitting the 65k dex limit, and it's unrelated to the version of dx.  We are working on updating it to a newer version, however!\n. I fixed this; I just forgot to do a push this week.  I'll start one now.\n. I fixed this; I just forgot to do a push this week.  I'll start one now.\n. I think this was fixed with 6037895d56a5beca65faefadf0165d7c5cda97a6\n. I think this was fixed with 6037895d56a5beca65faefadf0165d7c5cda97a6\n. Thanks for the report!\n. Thanks for the report!\n. ab71ab189d528f8504251dc16e146193bfcf3dd7 may have resolved this too?\n. ab71ab189d528f8504251dc16e146193bfcf3dd7 may have resolved this too?\n. I wonder if it's safe to use no escaper on Windows here?\n. I'm pretty sure this is working now.  I'm pretty sure I depend on this in some tests that are now passing on Windows.  Can you confirm @davido?\n. Can you possibly translate that error for me?\n. Can you possibly translate that error for me?\n. Nevermind; I'll put up a fix for that since I'm pretty sure I know what causes it.  I'm going to close this out.\n. Nevermind; I'll put up a fix for that since I'm pretty sure I know what causes it.  I'm going to close this out.\n. This is working just fine for me in Power Shell.  It looks like you are trying to use it from within cygwin?\n. This is working just fine for me in Power Shell.  It looks like you are trying to use it from within cygwin?\n. I'm running 4.0\n. @robarnold actually fixed this a few weeks ago; I'm working on pushing the changes right now, and I'll update that commit message to reference this (and close it).\n. @robarnold actually fixed this a few weeks ago; I'm working on pushing the changes right now, and I'll update that commit message to reference this (and close it).\n. Regarding the casefolding part: https://msdn.microsoft.com/en-us/library/aa365247%28v=vs.85%29.aspx is the spec, and it says:\n\nDo not assume case sensitivity. For example, consider the names OSCAR, Oscar, and oscar to be the same, even though some file systems (such as a POSIX-compliant file system) may consider them as different. Note that NTFS supports POSIX semantics for case sensitivity but this is not the default behavior.\n\nAre you, by chance, on a case-sensitive file system on Windows?  We might have to add some config check or something to support that non-default state.\nAs for the path separator, I agree that we should just use unix-style in BUCK files.  It looks like it should work, so I'm wondering if you are failing this check: https://github.com/facebook/buck/blob/master/third-party/py/pathlib/pathlib.py#L595\n. That only addresses the exclude issue, and not the case issue, right?\n. So it's not blocking you, but we don't have a fix here yet ;)\n. I'm trying to understand why the case difference matters.  Simply not casefolding, as your suggested patch does, isn't okay because pathlib may need to compare paths, and that's how it does so on Windows because the file system isn't case sensitive.  java/org/ostrovsky/buck/Main.java and java/org/ostrovsky/buck/main.java should be equivalent on Windows.\nWhat bug are you actually seeing?\n. This is a test case that reproduces your bug, however:\n``` diff\ndiff --git a/src/com/facebook/buck/parser/buck_test.py b/src/com/facebook/buck/parser/buck_test.py\nindex 13e47c6..215d109 100644\n--- a/src/com/facebook/buck/parser/buck_test.py\n+++ b/src/com/facebook/buck/parser/buck_test.py\n@@ -258,6 +258,25 @@ class TestBuck(unittest.TestCase):\n         finally:\n             shutil.rmtree(d)\n\ndef test_case_preserved(self):\nd = tempfile.mkdtemp()\ntry:\nsubdir = os.path.join(d, 'java')\nos.makedirs(subdir)\nopen(os.path.join(subdir, 'Main.java'), 'w').close()\nself.assertEquals(\n[\nos.path.join('java', 'Main.java'),\n],\nglob_internal(\nincludes=['java/Main.java'],\nexcludes=[],\ninclude_dotfiles=False,\nallow_empty=False,\nsearch_base=Path(d)))\nfinally:\nshutil.rmtree(d)\n+\n``\n. In your case, you can just stop usingglobsince you are specifying files anyway.  I'm looking at fixing pathlib here, but if you don't needglob, you shouldn't use it to list yoursrcsanyway.\n. In your case, you can just stop usingglobsince you are specifying files anyway.  I'm looking at fixing pathlib here, but if you don't needglob, you shouldn't use it to list yoursrcsanyway.\n. The proper fix for this actually does involve removing those lines you commented out, but other changes are needed for it to be the right fix still.  I just landed this internally; should go out tomorrow at some point.\n. The proper fix for this actually does involve removing those lines you commented out, but other changes are needed for it to be the right fix still.  I just landed this internally; should go out tomorrow at some point.\n. Yes, and at some point we'll get our set of fixes we've done to the library there, but for now, getting it in here is good enough.  If you want to help get it upstream, that'd be really nice, but not expected.\n. Yes, and at some point we'll get our set of fixes we've done to the library there, but for now, getting it in here is good enough.  If you want to help get it upstream, that'd be really nice, but not expected.\n. Generally, we use the--jsonargument of commands to get JSON output.\n. Generally, we use the--jsonargument of commands to get JSON output.\n. @marcinkosiba - I believe you or @alsutton are looking at the plugin now.  Would this be needed still?\n. Can't create . folders on Windows, so https://github.com/facebook/buck/blob/e8190a34ff10bdb55729a8a50669805f833f6a85/src/com/facebook/buck/rules/BuildInfo.java#L48 is no good.  I'm assuming we want it hidden on Windows, so we'd need to get aDosFileAttributeViewand set it to hidden and not call it.whatever. Thanks for your contribution!\n. Thanks for your contribution!\n. Agreeing with @Coneko.\n. Sorry this took so long for us to get it in.  Thanks!\n. Can you accomplish this today withgenrule?\n. You should just be able to specify'//path/to/genrule:rulename'in yoursrcs`, and I think it'll work.\n. Cool, should we close this then?  I'm not sure we want to add explicit support (although at some point we'll add an extension API and you could add the rule to do this via that if you wanted).\n. That one is pretty old, and things may have changed a bit since then.  More recently there's https://github.com/facebook/buck/commit/be18959e6c32b59d4b490a7c7bfead115f150db0.\n\nIf you do implement your own rule, and wanted to add documentation on how to do it for future folks, we'd be happy to take that pull request :)\n. That one is pretty old, and things may have changed a bit since then.  More recently there's https://github.com/facebook/buck/commit/be18959e6c32b59d4b490a7c7bfead115f150db0.\nIf you do implement your own rule, and wanted to add documentation on how to do it for future folks, we'd be happy to take that pull request :)\n. It also sounds like you might want flavours - we use this for thrift when a cxx_library depends on a thrift_library - we use the {rule}#cxx (or something like that) version of the rule.\n. It also sounds like you might want flavours - we use this for thrift when a cxx_library depends on a thrift_library - we use the {rule}#cxx (or something like that) version of the rule.\n. Thanks for the report!  The updated docs are now live.\n. Thanks for the report!  The updated docs are now live.\n. (\u256f\u00b0\u25a1\u00b0\uff09\u256f\ufe35 \u253b\u2501\u253b\nYeah, we are moving to a world where we get things upstreamed first.  @bgertzfield and I both missed that in the review of picking in upstream.\n. I think I can see @jimpurbrick in the office today, so I'll try to get that merged and then update our copy of nailgun.\n. I think I can see @jimpurbrick in the office today, so I'll try to get that merged and then update our copy of nailgun.\n. It was merged, but it broke compilation on OSX, so I haven't updated Buck yet.  martylamb/nailgun#58 fixes that, and then I can update us.\n. Happy to update nailgun again, but we'd need to get that fix upstream first.\n. Thanks for your contribution!\n. Thanks for your contribution!\n. Buck does expand $ENV_VAR to that variables contents on Windows so you can try to share today.  As for ln, I'm not sure I like \"just copy if we are on Windows\" to be honest.  Zip is also something that doesn't exist on Windows by default, but we've solved that in our own tests by creating a small python_binary and using python's built in zip functionality.\nIn general, I've found that whenever I want to avoid this, I just write a small python function, which is usually more maintainable and even testable than some shell scripting.\n. We now have zip_file rule, which covers a bit of what you are asking.  The bonus here is that it produces a zip that is actually cacheable (doesn't have timestamps in it, etc).\nhttps://buckbuild.com/rule/zip_file.html\n. You know that genrule can also output a directory, right?\n. > I also proposed monkeypatching genrule() in Gerrit's build to make that work for us since it may be more project specific that we need so many of these ln -s genrules and we prefer not to copy everything on *NIX.\nI think this might be a better solution.\nI'm going to close this since it would be hard to write something that would work for all platforms.  If you have specific things you'd like to see, we should file issues on each of those, but as written this task is done or you should hack up in your own repo.\n. We switched to jacoco for code coverage, and you can output an xml file, but I'm not sure that's very readable.  We don't really want to write a UI for this, however.\n. I cleaned it up a bit more before landing it, but thanks for your contribution!\n. I cleaned it up a bit more before landing it, but thanks for your contribution!\n. This might be silly, but what if you set import_path to src/?  That slash might actually matter.\n. This is the bit that makes me think that import_path is off: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/GenAidl.java#L122\n. No response from @amitkot.  If we get one, we can reopen this.\n. @marcinkosiba might have so ideas on how to fix it then to help you submit a PR :)\n. This doesn't feel worth doing.\n. Thanks for your contribution!\n. Thanks for your contribution!\n. Whoops.  I'm pretty sure we only tested that for buck build.\n. Whoops.  I'm pretty sure we only tested that for buck build.\n. http://buckbuild.com/command/fetch.html\nhttp://buckbuild.com/rule/remote_file.html\n. Thanks for your contribution!\n. Thanks for your contribution!\n. Yup, it's intentional that those aren't documented.  You can use them, and file issues about them, but we don't want to encourage their use yet by documenting them.\n. We're using it internally for various parts at Facebook, but there's a long-tail of issues.  We're hoping to have something out there soon that folks can start to provide feedback on.\n. I totally missed the fact that you updated this since github didn't send mail.  I'm running this through our own internal CI now and it should go out Wednesday next week assuming it all checks out :)\n. Yeah, we'd take something like that, but I think we'd want to go with prebuilt_python_library or to match what we do with other platforms, and then just pull it from the list of deps instead of adding a new requirements.  Feel free to send a pull request our way (I'll ask for docs to be added too if you do add that).\n. Note that your change introduced some lint errors (identified with ant lint).  Travis keeps dying because of the NDK, so I'm going to remove that, sadly.\nI'll fix those before merging in your change.\n. No problem.  I'll be adding it to Travis tomorrow so you won't have to know until it fails :)\n. Thanks for your contribution!\n. Thanks again for your fix!  This made it into our weekly update post: https://www.facebook.com/buckbuildtool/posts/813592978710413\n. Thanks for the fix!\n. Your change got mentioned in our update too :)\nhttps://www.facebook.com/buckbuildtool/posts/794685890601122\n. It seems like somehow our PYTHONPATH overrides aren't working correctly.\ncc @davido in case he has any ideas\n. I don't think anybody on the core team is going to get to this any time soon, but we'd take a pull request.\n. This was closed by bb4dd83190a80217aa2cbd89a5dccd9fc5c8a7bb\n. I apparently missed the update here.  I'll try to get this merged in for our sync on Wednesday.\n. Thanks again!\n. Thanks for the fix!\n. Can we close this now that the pull request has landed?\n. I'm going to go ahead an close this here and answer on stack overflow since you asked there too, and then morph this into us not really documenting this at all.\nhttp://stackoverflow.com/questions/29787623/how-to-specify-the-gtest-dependency-for-a-cxx-test-target-when-using-buck\n. Thanks for the report!\n. I think @vovkab is right.  This looks like a support issue too, which we are trying to use Stack Overflow for.  If you have further questions, feel free to ask there (tag it with Buck), and feel free to link back to it here.\n. I'm a little worried this is a foot-gun still.  I'm not coming up with a good way to prevent sharing of buck-out if we did this.\n. I'm a little worried this is a foot-gun still.  I'm not coming up with a good way to prevent sharing of buck-out if we did this.\n. It might actually be okay.  Even if someone tried to share it, the rule keys should keep us from having conflicts.\n. I'm pretty sure @andrewjcg has a WIP patch to make ... work on the command line.\n. You'll need to rebase your changes for us to merge this.  I commented on your change about a few minor things too.  It'd also be nice to add docs for this command (under docs/command).\n@shs96c, do you have any opinions on what to call this command?  I think it's useful.\n. @luser - any chance you might be up for rebasing and addressing the comment from @shs96c?\n. Long term, we'll want to build tooling to help folks not over-specify header changes, but for now, @andrewjcg is working on adding support for dep file tracking.\n. @luser - this should be a lot better now if you wanted to check it out again.\n. Hurray!\n. Hurray!\n. You can create a .buckjavaargs file next to your .buckconfig that contains arguments to Java.  In your case, you'd want it to contain -Xmx2g.\nI'm going to morph this issue into documenting that.\n. Interesting.  Want to make a pull request to add an option for controlling the memory of invoking proguard too?  If not, please file a new issue for that.\n. @joshzana - if you can't get to it, could you file a new issue about not being able to control that?\n. Thanks for the pull request!\n. What kind of a test rule is that?\n. Yeah, the only tests that actually do any filtering is java_test.\n. Are you still blocked on this?\n. groan\nYes, I had forgotten about that.  I'm going to be away for the next week, so I won't be able to help much, but I'll let the rest of the team know they should watch out and try to help :)\n. Thanks so much for this!\n. We currently only support it for exopackage.  At the time we wrote it, Android didn't support split dexes natively. With Lollipop that changed.  We didn't document it, because it wasn't possible for non-FB people to use the feature, and we didn't want to open source our split dex loading code.\nI'm not sure if the support library handles this now, or if it just works with Lollipop and newer devices.\n. I'm going to close this in favor of #309\n. We currently only support it for exopackage. At the time we wrote it, Android didn't support split dexes natively. With Lollipop that changed. We didn't document it, because it wasn't possible for non-FB people to use the feature, and we didn't want to open source our split dex loading code.\nI'm not sure if the support library handles this now, or if it just works with Lollipop and newer devices.\n. Nice!  One thing that I see missing from this is documentation.  Can you follow the README.md under docs/ to update those and also add docs for the new rule?\n. Looking at the commit, it looks like the email address you used to commit it isn't attached to your github account (wanted to make sure you were aware of it so you can get credit for it).\n. Looking at the commit, it looks like the email address you used to commit it isn't attached to your github account (wanted to make sure you were aware of it so you can get credit for it).\n. Also, this made our weekly update notes.  Thanks again!\nhttps://www.facebook.com/buckbuildtool/posts/823959861007058\n. Also, this made our weekly update notes.  Thanks again!\nhttps://www.facebook.com/buckbuildtool/posts/823959861007058\n. Hmm, I'm not seeing this with Java 1.7\n. Hmm, I'm not seeing this with Java 1.7\n. Whoops.  I almost had the right fix there.  If you modify that script to replace the last line with java -jar plovr-81ed862.jar soyweb --dir . --globals docs/globals.json, that should unblock you.  I'll get a fix out soon.\n. Whoops.  I almost had the right fix there.  If you modify that script to replace the last line with java -jar plovr-81ed862.jar soyweb --dir . --globals docs/globals.json, that should unblock you.  I'll get a fix out soon.\n. Actually, that should just be java -jar plovr-81ed862.jar soyweb --dir . --globals globals.json\n. Actually, that should just be java -jar plovr-81ed862.jar soyweb --dir . --globals globals.json\n. Yeah, the fix should go out tomorrow and the commit will close the issue.  Sorry about that!\n. Yeah, the fix should go out tomorrow and the commit will close the issue.  Sorry about that!\n. Thanks for the fix!\n. Thanks for the fix.  After chatting with @andrewjcg, we went with a slightly different solution (using exported_deps, but I still attributed you for the fix.\n. Understatement of the century.  Last I checked, it was close to 300 test failures (many of which we just need to add the appropriate assumption tests to)\n. Thanks for your contribution!\n. Thanks!  This is now live at http://buckbuild.com/javadoc/com/facebook/buck/cli/QuickstartCommand.html\n. Thanks for the fix!\n. Aye, if you wanted to do a pull request to fix that up, we'd take it.  If not, one of us will get to it eventually.\n. This isn't the first time they have broken this for us.  I'll get a fix up soon.\n. Through a series of patches, I have the fix landed internally.  It'll go out Wednesday.\n. Thanks for the report.  Let me know if you are having trouble with it still.\n. @kargs - what version of Buck are you using?\n. @kargs - what version of Buck are you using?\n. deps should work today.  What are you seeing when doing this?\n. I'm guessing you need :dependant-core also in whatever libraries need :dependant, yeah?  If so, we'll need to add exported_deps to the rule and you'd want to use that.\n. Can you apply https://gist.github.com/sdwilsh/3d4645edc5d4f3bbf0a1 locally and see if it fixes it for you?  Writing a test is going to take a while for this, but if this unblocks you, I can just get it in.\n. Alright, the naive fix won't do it.  Hopefully I can get this resolved next week.  For now, just include both in the deps of dependent libraries (which sucks, I know).\n. Also, do you happen to have an example AAR that does this?\n. @rallat - looking over the pom, that seems to depend on twitter-core, but I'm not seeing that available for download on that site.  Any pointers?\n@edisonw - if you want to give https://gist.github.com/sdwilsh/f98020f4573e506705b6 a try, I think it may do the trick in a way that doesn't fail like the above (I missed something with that quick diff last week).  The thing that I don't think will work, although I'm not sure if it matters, is that android resources won't be exported, so you likely wouldn't be able to use them in your libraries without declaring a first-order dependency.  I haven't used AARs much, so I'm wondering what you would expect the expected behavior to be in that situation.\n. Ahh, so you have a android_prebuilt_aar that has prebuilt_jars in its dependency chain?  That requires a bit more code than what I have, but I can make that work too.\nDo you have some sample code that would use the right bits to demonstrate the bug?  I'm worried that I'm not going to write an integration test for this that will make sure we don't regress this behavior for you.\n. I believe, without tests still, that https://gist.github.com/sdwilsh/b0e7ca14bda617041c11 should solve this.  Basically, the android_prebuilt_aar needs to export and classes.jar and any prebuilt_jars that exist in its deps, which is what that change should do.\nI'll spend some time today cleaning that up and getting it merged in.\n. That's probably not going to work 100% either, but I just talked with @natthu and have a good idea on what the right fix is.\n. I filed #332 to track the prebuilt_jar case, which is actually a lot easier to deal with.\n. What we have in the tree now might be enough for you, but it's not 100% fixed yet.\n. #391 is going to close out the remaining piece of this\n. While #391 isn't closed, it's just adding tests now.  @natthu fixed the remaining part of this in 4cf0eb7a744c9583cc3f45f7952ef3aa6ae8afae.\n. @edisonw and @rallat: note that the right fix for this may not do what you wanted, but there is a bug with Buck here.\nWhat I'm going to fix is the case of having an android_library (let's call it A) depending on an android_prebuilt_aar (let's call it B), which depends on a prebuilt_jar (let's call it C).  Today, C isn't visible to A, but I've got a fix for that which will go out today.\nIf C has any dependencies, they won't be visible to A.  That's how prebuilt_jar works today, and it's intentional.  If you wanted that to work, you'd have to change build.build_dependencies (which isn't documented; I'll file an issue on that) or use --build-dependencies=transitive on the command line.\n. #333 covers the documentation of that.\n. Yeah, if A needs C to compile, you should be doing that.  I just wanted to make it clear that this won't make all transitive deps work (unless you change that build setting).\n. @bolinfest while true, it's certainly causing a lot of problems for people (like @Piasy) so probably worth doing.  It's unfortunate we consider android_binary to be frozen.\n. Hmm, this ended up pulling in both of your changes.\n. Hmm, this ended up pulling in both of your changes.\n. Oh GitHub.  I'll merge your change shortly, so it should be easy to \nrebase and make that issue go away.\n. Oh GitHub.  I'll merge your change shortly, so it should be easy to \nrebase and make that issue go away.\n. Thanks for pulling this out!\n. Thanks for pulling this out!\n. Thanks!\n. Thanks!\n. Any luck adding the skipped result type @liuyang-li?\n. Thanks for pulling this out and fixing it!\n. Thanks for pulling this out and fixing it!\n. Thanks for pulling this out and fixing it!\n. Thanks for pulling this out and fixing it!\n. The current project generation is...lacking.  @marcinkosiba is reworking it all, but that's hidden behind the --experimental-ij-generation flag of buck project.  Does that help at all?\n. The current project generation is...lacking.  @marcinkosiba is reworking it all, but that's hidden behind the --experimental-ij-generation flag of buck project.  Does that help at all?\n. @marcinkosiba is the best person to answer that, but he's mostly away this week.\n. @marcinkosiba is the best person to answer that, but he's mostly away this week.\n. Correct!\n. https://buckbuild.com/command/project.html\n. https://buckbuild.com/command/project.html\n. https://buckbuild.com/command/project.html\n. On 6/17/2015 2:52 PM, Anthony Uccello wrote:\n\nHowever my project has only one module, so I don't need multiple BUCK\nfiles or anything.\nCan I set it to just get ALL Java files in my /java folder, or, as its\nshown in the example from the quickstart, do I need to manually specify\nevery single file with a fullpath?\nYou'd still need an android_library rule, which you can keep in the \nsame BUCK file if you'd like.  If you have any resources, you'd also \nneed to have an android_resource rule.  The docs on those have \nexamples of how to use the glob method to get all your source files.\n\nCheers,\nShawn\n. On 6/17/2015 2:52 PM, Anthony Uccello wrote:\n\nHowever my project has only one module, so I don't need multiple BUCK\nfiles or anything.\nCan I set it to just get ALL Java files in my /java folder, or, as its\nshown in the example from the quickstart, do I need to manually specify\nevery single file with a fullpath?\nYou'd still need an android_library rule, which you can keep in the \nsame BUCK file if you'd like.  If you have any resources, you'd also \nneed to have an android_resource rule.  The docs on those have \nexamples of how to use the glob method to get all your source files.\n\nCheers,\nShawn\n. http://buckbuild.com/article/exopackage.html has some commands to \ncheckout our forked version of AtennaPod that uses Buck.\n. Hey, thanks for this!  We can't pull it in until you sign our CLA though: https://code.facebook.com/cla (there's a bot that is supposed to tell you that, but it appears to be busted)\n. Hey, thanks for this!  We can't pull it in until you sign our CLA though: https://code.facebook.com/cla (there's a bot that is supposed to tell you that, but it appears to be busted)\n. Thanks for the PR!\n. Thanks for the PR!\n. It's at http://buckbuild.com/article/exopackage.html\n. It's at http://buckbuild.com/article/exopackage.html\n. What phone are you running on?  Samsung devices, in particular, do \nthings very differently than everything else out there :/\n. What phone are you running on?  Samsung devices, in particular, do \nthings very differently than everything else out there :/\n. @natthu - any idea why the agent isn't already available?\n. @natthu - any idea why the agent isn't already available?\n. Thanks so much for doing this.  This will be a big help :)\n. Thanks so much for doing this.  This will be a big help :)\n. Sorry it took me so long to get this review to you!  I've been out the past week.\n. Sorry it took me so long to get this review to you!  I've been out the past week.\n. Thanks!\n. Thanks!\n. Thanks again for your fix.  It made our weekly update post: https://www.facebook.com/buckbuildtool/posts/836733013063076\n. Okay, I got your first commit in.  I had to fix up some lint and java doc issues.  Can you rebase this so I can get the second one in too?\n. Okay, I got your first commit in.  I had to fix up some lint and java doc issues.  Can you rebase this so I can get the second one in too?\n. If you run ant lint verify-javadoc, you should be good.\n. If you run ant lint verify-javadoc, you should be good.\n. Do you have a test repo that demonstrates this so we can reproduce it?\n. Do you have a test repo that demonstrates this so we can reproduce it?\n. Is this resolved?\n. We've got a sample one at \ntest/com/facebook/buck/java/testdata/missing_test_deps/\n. We've got a sample one at \ntest/com/facebook/buck/java/testdata/missing_test_deps/\n. I can't apply this cleanly, and when I did what I thought was redoing the work, I got this error when actually running tests with code coverage enabled:\nError occurred during initialization of VM\nagent library failed to init: instrument\nCan you rebase and retest you changes?  Can you also add the source jar of the agent while you are here?\n. I can't apply this cleanly, and when I did what I thought was redoing the work, I got this error when actually running tests with code coverage enabled:\nError occurred during initialization of VM\nagent library failed to init: instrument\nCan you rebase and retest you changes?  Can you also add the source jar of the agent while you are here?\n. Travis keeps failing because it's killing us while we build.  I've actually disabled it recently.\nIt's possible I messed something up when trying to rebase your diff, so let me see if the updated version just works :)\n. Travis keeps failing because it's killing us while we build.  I've actually disabled it recently.\nIt's possible I messed something up when trying to rebase your diff, so let me see if the updated version just works :)\n. Thanks :)\n. Thanks :)\n. Thanks again for your fix.  It made our weekly update post: https://www.facebook.com/buckbuildtool/posts/836733013063076\n. Where are those resources declared?\n. Where are those resources declared?\n. You are hitting the remaining part of #328, I believe.  We don't currently export resources, and @natthu and I aren't sure it's a good idea since it will slow down build times.  As a work around, you should declare it as a first-order dep on the libraries that need it.\nGradle works here because it happily walks all of your transitive deps, which we don't do because it turns out to slow down build times.\nAs an aside, your use of glob to declare your library rules isn't going to play well with buckd if you happen to add more libraries.\n. You are hitting the remaining part of #328, I believe.  We don't currently export resources, and @natthu and I aren't sure it's a good idea since it will slow down build times.  As a work around, you should declare it as a first-order dep on the libraries that need it.\nGradle works here because it happily walks all of your transitive deps, which we don't do because it turns out to slow down build times.\nAs an aside, your use of glob to declare your library rules isn't going to play well with buckd if you happen to add more libraries.\n. This will be closed by #391 \n. This should be resolved by the latest version of Buck.  @reondz or @sdfzq123, can you confirm that it's fixed for you?\n. Correct.  The resource isn't defined in reon.me.helloworld, and Buck doesn't do transitive dependencies (because they slow down the build).\n. @marcinkosiba should finish the review soon.  @tdrhq told me he was happy with this diff already.\n. @marcinkosiba should finish the review soon.  @tdrhq told me he was happy with this diff already.\n. You can put whatever you want in the commit message.  I promise to keep \nit :)\n. You can put whatever you want in the commit message.  I promise to keep \nit :)\n. Hmm, I'm getting a build failure (this could be due to an older base revision on your end).  Also possible that the commit that added this isn't in open source yet (I'm doing a push right now):\n[mkdir] Created dir: /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes\n [copy] Copying 1 file to /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes/com/facebook/buck/json\n[javac] Compiling 27 source files to /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes\n[javac] Compiling 17 source files to /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes\n[javac] Compiling 1095 source files to /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes\n[javac] [compiled 175671 lines in 6707 ms: 26192.1 lines/s]\n[javac] [2077 .class files generated]\n[javac] ----------\n[javac] 1. ERROR in /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/src/com/facebook/buck/android/AndroidInstrumentationTestDescription.java (at line 36)\n[javac]     public class AndroidInstrumentationTestDescription\n[javac]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[javac] The type AndroidInstrumentationTestDescription must implement the inherited abstract method Description<AndroidInstrumentationTestDescription.Arg>.createBuildRule(TargetGraph, BuildRuleParams, BuildRuleResolver, A)\n[javac] ----------\n[javac] 2. ERROR in /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/src/com/facebook/buck/android/AndroidInstrumentationTestDescription.java (at line 58)\n[javac]     public <A extends Arg> AndroidInstrumentationTest createBuildRule(\n[javac]       BuildRuleParams params,\n[javac]       BuildRuleResolver resolver,\n[javac]       A args) {\n[javac]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[javac] The method createBuildRule(BuildRuleParams, BuildRuleResolver, A) of type AndroidInstrumentationTestDescription must override or implement a supertype method\n[javac] ----------\n[javac] 2 problems (2 errors)\n. Hmm, I'm getting a build failure (this could be due to an older base revision on your end).  Also possible that the commit that added this isn't in open source yet (I'm doing a push right now):\n[mkdir] Created dir: /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes\n [copy] Copying 1 file to /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes/com/facebook/buck/json\n[javac] Compiling 27 source files to /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes\n[javac] Compiling 17 source files to /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes\n[javac] Compiling 1095 source files to /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/classes\n[javac] [compiled 175671 lines in 6707 ms: 26192.1 lines/s]\n[javac] [2077 .class files generated]\n[javac] ----------\n[javac] 1. ERROR in /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/src/com/facebook/buck/android/AndroidInstrumentationTestDescription.java (at line 36)\n[javac]     public class AndroidInstrumentationTestDescription\n[javac]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[javac] The type AndroidInstrumentationTestDescription must implement the inherited abstract method Description<AndroidInstrumentationTestDescription.Arg>.createBuildRule(TargetGraph, BuildRuleParams, BuildRuleResolver, A)\n[javac] ----------\n[javac] 2. ERROR in /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/src/com/facebook/buck/android/AndroidInstrumentationTestDescription.java (at line 58)\n[javac]     public <A extends Arg> AndroidInstrumentationTest createBuildRule(\n[javac]       BuildRuleParams params,\n[javac]       BuildRuleResolver resolver,\n[javac]       A args) {\n[javac]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[javac] The method createBuildRule(BuildRuleParams, BuildRuleResolver, A) of type AndroidInstrumentationTestDescription must override or implement a supertype method\n[javac] ----------\n[javac] 2 problems (2 errors)\n. We general prefer to point people at stackoverflow.com and tag the question with \"Buck\" for support issues these days.\nThanks @tgummerer for answering this!\n. We general prefer to point people at stackoverflow.com and tag the question with \"Buck\" for support issues these days.\nThanks @tgummerer for answering this!\n. We can, but I don't think we'd do it until it's out of beta (since we'll have to reverse engineer how Gradle works with it).\n. We can, but I don't think we'd do it until it's out of beta (since we'll have to reverse engineer how Gradle works with it).\n. I suspect the project would accept a pull request, but nobody on the core team has a need for it so it is unlikely to be done by the core team.\n. I suspect the project would accept a pull request, but nobody on the core team has a need for it so it is unlikely to be done by the core team.\n. Nothing has changed since March 1st with regards to the core team having a need for this, so no, there are no updates :)\n. Negative.  As far as I know, this isn't used at Facebook, which makes it unlikely that anybody there is going to add it.  Uber has started to use Buck pretty heavily and contributing quite a bit, but I'm guessing they don't use this either because they've sent zero PRs over about this.\nSomeone from the community is likely going to need to step up to do this if they care enough about it.\n. Negative.  As far as I know, this isn't used at Facebook, which makes it unlikely that anybody there is going to add it.  Uber has started to use Buck pretty heavily and contributing quite a bit, but I'm guessing they don't use this either because they've sent zero PRs over about this.\nSomeone from the community is likely going to need to step up to do this if they care enough about it.\n. Just so I understand it, you have an xml file that just contains <?xml version=\"1.0\" encoding=\"utf-8\"?>?\n. Just so I understand it, you have an xml file that just contains <?xml version=\"1.0\" encoding=\"utf-8\"?>?\n. He already accepted it, and I already merged it internally.  It'll go out later today :)\nThanks!\n. Thanks again for your fix.  It made our weekly update post: https://www.facebook.com/buckbuildtool/posts/836733013063076\n. I think 0cbe56eaa53ed346bc51d122099de3fa1530d8c1 will fix this for you, but let us know!\n. It's hard to comment on that as-is, but I think it's probably close to what we need.  It might even fix some of those issues you mentioned.\n. It'll be easier for me to look at once it's in an actual request so I can see more context.  I started to look at this, but had to keep jumping between my IDE and github, which got old fast :)\nNo rush; take your time.\n. The first two are OK, but the last three changes create a change in behaviour by putting JarOutputStream & IndentingWriter in a t-w-r the underlying stream gets closed when the t-w-r block is left, which will cause problems for other parts of the code (e.g. the call to closeOutput in the case of the JarOutputStream change)\n. Thanks for fixing this up!\n. Thanks for fixing this up!\n. Thanks for fixing this up and getting it in :)\n. Thanks for fixing this up and getting it in :)\n. @Coneko - not sure why you removed the needs-revision tag when you want changes still :)\n. @Coneko - not sure why you removed the needs-revision tag when you want changes still :)\n. Thanks for updating your pull request!\n. Thanks for updating your pull request!\n. Thanks again; this made our weekly update post!\nhttps://www.facebook.com/buckbuildtool/posts/846856528717391\n. Thanks again; this made our weekly update post!\nhttps://www.facebook.com/buckbuildtool/posts/846856528717391\n. Thanks for the pull request!\n. This made the weekly update: https://www.facebook.com/buckbuildtool/posts/840981252638252\nThanks again!\n. Do you mean it's not in the $(classpath ) macro in the genrule?\n. Yeah, we do not generate it until the very end.  The dummy_r_dot_java stuff is an optimization that we've done to improve build times.  It might have what you need.  @natthu, do you know why we don't add those to the class path?\nWhat does your genrule do, by chance?\n. Interesting.  I wonder if you could use the android_library rule here and just set the compiler that @shs96c added (which unfortunately was not documented).\n. Does that unblock you?  If you were feeling ambitious, you could try to \nimplement rules for Kotlin.\n. Alright, should we close this then?\n. Well, it may have been at first :)\n. This is what we wrote https://github.com/facebook/buck/blob/master/bin/buck.ps1 for.  Any reason you are using cmd.exe instead of Power Shell?\n. Today I learned.  Thanks!\n. We've got an internal change that I need to push out for this too.  This is a Java 8-only bug.\n. Thanks for reporting this, however :)\n. Is this working for you now?\n. It's quite possible we only work with Java 7 right now (we don't have any CI verifying Java 8 builds).\n. What does your $CLASSPATH and $JAVA_HOME variables look like?\n. I'm stumped, to be honest.  I'm hoping @shs96c can help you tomorrow when it isn't a holiday in London.\n. Hmm, you might want to try setting JAVA_HOME and see if that helps though: http://stackoverflow.com/questions/1348842/what-should-i-set-java-home-to-on-osx\n. Haven't heard back from @MarkehMe, and we can't reproduce this issue, so closing the issue.\n. If you do hit it again, feel free re-open or file a new task :)\n. I can confirm this is still a bug.\n. I can confirm this is still a bug.\n. I'm just curious if you used a tool to spot these or came across them by hand?\n. I'll fix those so I don't have to import again.\n. cc @jkeljo who authored the original commit\n. @jkeljo - any other ideas?\n. ping @jkeljo \n. Fun fact: at Facebook, we don't use buckd in CI because it was too flaky.\nWith that said, @bhamiltoncx has recently switched Buck over to use unix domain sockets instead of tcp sockets.  What version of buck are you running, and is this a recent development?\n. It leaks memory or doesn't give it up?  We've been doing lots of perf fixes around how much memory it uses, but we've found the jvm doesn't like to free much up to the host OS.\nWe could probably make it so that you can use watchman as the glob provider, but, for larger repos especially, a lot of the wins come from the caches that buckd keeps around between builds and the improved cache hit rate in the jvm.\n. Are you specifying any -Xmx in .buckjavaargs?  For larger applications, you may need to bump this up (we use -Xmx3g for our Android stuff).\n. The benefit is that you can check that in and everyone uses that value.\n. Have you set download.maven_repo (which appears to be undocumented) in your .buckconfig?  I believe it doesn't require it to be set as long as it is set there.\n. Sounds like we were missing a test case then :/\n. Closed by #411.\n. Is this a recent regression?  Looks like you are using the unix domain socket version of buckd here.\n. Oh man, there have been a lot of changes since then.  For a sanity \ncheck, can you update to before \n3f8af8ea22f6ebf8a9020e2d5b942f523bdc077b?  This will let us rule out the \nUnix domain sockets to be sure (I realize it'll take a day to evaluate).\nIs there anything interesting in the log?\n. Thanks for the report!\n\nFrom: Matt Readmailto:notifications@github.com\nSent: \u200e9/\u200e10/\u200e2015 2:38\nTo: facebook/buckmailto:buck@noreply.github.com\nCc: Shawn Wilshermailto:sdwilsh@fb.com\nSubject: Re: [buck] connection reset by peer if buckd left running overnight (#409)\nAppears to be fixed with the latest code, perhaps it was related to the race condition in nailgun shutdown. Thanks for your help.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/409#issuecomment-139184612.\n. Confirmed.  Something about our build.xml file doesn't play nice with spaces.\n. @shs96c and I would like to see a test for this\n. com.facebook.buck.java.MissingSymbolsHandlerIntegrationTest now fails with this change.  Can you patch it up to deal with the change in output?\n. This should be as simple as adding a new entry in NdkCxxPlatforms, if \nyou happen to feel mildly ambitious.\n. 4abf4af792d8bfd48e08148f2433431916135676 is an example of how to add another platform as well.\n. the android_resource for A depends on resources defined in B, but you don't declare a dependency.  This fixes it for me:\n`````` diff\n--- a/a/BUCK\n+++ b/a/BUCK\n@@ -5,6 +5,9 @@ android_resource(\n   name = 'res',\n   res = 'res',\n   package = 'com.example.a',\n+  deps = [\n+    '//b:res',\n+  ],\n   visibility = ['PUBLIC'],\n )\n@@ -34,7 +37,6 @@ android_binary(\n   keystore = ':debug_keystore',\n   package_type = 'debug',\n   deps = [\n-    '//b:res',\n     '//b:src',\n     ':res',\n     ':src',``\n``````\n. Per http://stackoverflow.com/questions/3441396/defining-custom-attrs, your namespace should behttp://schemas.android.com/apk/res-auto, nothttp://schemas.android.com/apk/res/com.example.b`.  That works locally for me.\n. @rowillia can you confirm that it's fixed for you in the latest version?\n. I'm presuming this is closed.  Please comment if it isn't resolved for you.\n. sigh\nIt is supposed to be mandatory!\nhttp://tools.android.com/tech-docs/new-build-system/aar-format\n. We'll have to make Buck tolerate it.  It's possible we can just add a TouchStep to create a classes.jar file if it doesn't exist.\n. @nemith is working on driving this in\n. Just a heads up that the address you used to author this isn't attached to your github account so you didn't get credit for it on your profile @mikekap.\n. @shs96c is trying to better namespace genrule so this isn't a problem, but yeah, it's a collision.\n. It should go out today.\n. https://github.com/facebook/buck/commit/c92ef212b53fff08a8452649b4d4faadc6b89b11 should do it.\n. Can you rebase this?  It's not applying cleanly and I don't want to get the fix wrong.\n. Hmm, I think @bhamiltoncx is in the process of pushing out some changes that might cause it then.\n. @natthu raised a good point internally.  We should just get rid of this warning and put it as a LOG.debug now.  It was only really useful when mini-aapt first landed.  Thoughts?\n. Seems reasonable\n. I'm guessing we are not packaging this properly, @Coneko.  Of course our tests do it from in-tree so we wouldn't have seen this.\n@vhbit, if you do the manual setup and install process it should work for you.\n. If you update to the head of Buck with homebrew, this should work for you.  Thanks for the report!\n. @petersibley, can you provide more details?  @marcinkosiba can hopefully help you out tomorrow.\n. @tgummerer beat me to this.  This is the same as #410.\n. We don't currently have any plans around this.  We'd happily help someone get it in, but we don't have a need for it internally yet.\n. I don't believe anybody is actively working on it, so if you wanted to try and pick up @bhamiltoncx's work and drive it forward, I'm pretty sure that would be okay.\n. If you are interested in continuing that work, @Coneko has a good write up of how Buck uses graphs, which is a good primer for one of our core pieces of architecture: https://www.facebook.com/notes/uri-baghin/architecture-of-buck-1-graphs/1660525917559134\n. Buck only works with python 2.6 and 2.7: https://buckbuild.com/setup/install.html\n\nFrom: Andro Babumailto:notifications@github.com\nSent: \u200e9/\u200e20/\u200e2015 13:28\nTo: facebook/buckmailto:buck@noreply.github.com\nSubject: [buck] Python syntax error at buck.py and buck_tool.py (#424)\nOS : Windows 8\nE:\\ProgramFiles\\Android\\buck>javac -version\njavac 1.7.0_25\nE:\\ProgramFiles\\Android\\buck>ant -version\nApache Ant(TM) version 1.9.2 compiled on July 8 2013\nE:\\ProgramFiles\\Android\\buck>py -V\nPython 3.5.0\nE:\\ProgramFiles\\Android\\buck>ant\n...\n...\nSuccess\nE:\\ProgramFiles\\buck\\bin>buck --help\nTraceback (most recent call last):\nFile \"E:\\ProgramFiles\\buck\\bin..\\programs\\buck.py\", line 9, in\nfrom buck_tool import BuckToolException, RestartBuck\nFile \"E:\\ProgramFiles\\buck\\programs\\buck_tool.py\", line 228\nexcept OSError , e:\n^\nSyntaxError: invalid syntax\nE:\\ProgramFiles\\buck\\bin>\nHelp me please\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/424.\n. groan\nThis code is already pretty complicated because Google keeps moving stuff around: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/AndroidPlatformTarget.java#L278\nI guess we'd have to do something like ANDROID_VERSION_PREFIX here: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/AndroidPlatformTarget.java#L343\n. @Coneko has been looking at something related to this I think.  I'm pretty sure that deps are ignored on genrule, but I don't recall the reasoning.  How do you depend on file1.txt but don't use it in the command?\n. That stacktrace is truncated.  Can you get the full stacktrace from the log?\n. Glad to be of assistance :)\n. Can you elaborate?  I'm not sure what buck test is missing.\n. Something like buck test --interactive might be okay then?\n. Something like buck test --interactive might be okay then?\n. I mean, we could probably do that too.  I don't think it would be too \nhard to make happen (you just have to implement the right interface and \nbuck run should work).\n. Thanks for the solid issue; lots of details and steps to reproduce!  @Coneko should be able to help you out early tomorrow.\n. Can you explain in a bit more details what you mean by a path (an example would probably be sufficient, but I want to make sure I understand the report)?\n. @marcinkosiba has fixed this internally, so I should get it out tomorrow.  Thanks for the report.\n. Is it possible for us to have some concrete base class that both Java and this could use?  This might make it easier for someone like @bkase to support Kotlin.\n. An abstract class would be correct.  I work in too many languages sometimes and used a horribly misleading word there.\n. It does not currently.\n. That's correct.  If there's some specific thing you are trying to do, we might be able to tell you about a better way (or how to change Buck to do what you need), but that's the generic hammer :)\n. I'll fix those comments up before merging.\n. Set to this:\nA fast build system that encourages the creation of small, reusable modules over a variety of platforms and languages.\n. https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/aapt/MiniAapt.java#L444 is the spot that needs to be fixed, if you'd like to do a PR.\n. I don't doubt we have a bug.  Based on what you already provided, it looks like we just need to convert . to _ like Gradle and Ant do in the method I linked to above.\n. Hey @congling, we added a test yesterday that would have hit the issue you describe but it passes.  Can you make a reproducible test case so we can try to resolve this for you?\n. Hey @congling, we added a test yesterday that would have hit the issue you describe but it passes.  Can you make a reproducible test case so we can try to resolve this for you?\n. I think it was https://github.com/facebook/buck/commit/ddba2954e0f936d60011dc3cafdc501613435287\n. Yeah, our MOE config had some issues and I was oncall this week.  I'm working on getting some of those changes out right now.  Thanks though!\n. Yeah, @natthu did the reverse in 501b311bd361f72394aae575a7935385996dc000.  Looking at internal conversations about this (bleh), the concern of not doing this was that ant clean could fail, and we wouldn't remove this (in part because sometimes users would run buck as root, which messes up everything.  @ttsugriy has tried to fix that a few times but ran into issues.  I think we can't take this until we get a resolution on that.\n. Yeah, @natthu did the reverse in 501b311bd361f72394aae575a7935385996dc000.  Looking at internal conversations about this (bleh), the concern of not doing this was that ant clean could fail, and we wouldn't remove this (in part because sometimes users would run buck as root, which messes up everything.  @ttsugriy has tried to fix that a few times but ran into issues.  I think we can't take this until we get a resolution on that.\n. I think @ttsugriy is taking one more stab at it, so all you'd have to do is update this to do the right thing when ant clean is run.\n. I think @ttsugriy is taking one more stab at it, so all you'd have to do is update this to do the right thing when ant clean is run.\n. The latter.  @ttsugriy's change just checks to make sure Buck isn't running as some user it shouldn't (with some smarts).\n. The latter.  @ttsugriy's change just checks to make sure Buck isn't running as some user it shouldn't (with some smarts).\n. I plan to reach out when I get back from time off (next week) and see if we can smooth over some of the bumps too.\n. This isn't really an issue per-se.  @Piasy has been fixing stuff and making it better.\n. You'll want to run ant lint on this as it currently fails.\nAs for code coverage, it's set on the ExecutionContext; can you use that to do the right thing?\n. Oh, you need to change things while building the action graph.  We'd have to change that code to feed it through to the descriptions, which probably isn't awful, but it'd be a large change.  I wouldn't do it as a part of this PR.\n. I've been on vacation this whole week and haven't been around to nag people for reviews.  I'm only doing a half day today and I'm back 100% next week.  I'll try to poke the reviewers now though.\n. I can tell you two things though:\n- Your new file doesn't pass the license test (run buck test -f LicenseCheckTest)\n- Your new test doesn't have an assumption check to make sure the needed go binary is available, so if it isn't, it fails.  Rust and D both have code to check for the needed binaries before running tests so they don't fail on systems that don't have them.\nCan you get those two things fixed up while I prod for the rest of the code to be reviewed?\n. Yeah, that's safer to do, so let's do that.\n. Yeah, that's safer to do, so let's do that.\n. Should be able to get this merged in today if you get the CI passing :)\nYou might also want to rebase as I just got a few more changes to the CI out (shouldn't actually impact your diff, but we cover more things now).\n. Should be able to get this merged in today if you get the CI passing :)\nYou might also want to rebase as I just got a few more changes to the CI out (shouldn't actually impact your diff, but we cover more things now).\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Whoops; I forgot to fixup the commit message before pushing the changes.  Let me fix that...\n. Whoops; I forgot to fixup the commit message before pushing the changes.  Let me fix that...\n. Hmm, I haven't been updating the tag in https://github.com/facebook/homebrew-fb/blob/master/buck.rb because I hadn't realized I had to.\n@Coneko, could you take a look into this tomorrow?\n. @beefon changed this, IIRC, but it looks like we missed updating it.\n. Homebrew is super easy because we can just point it at a tag and it gets that version.  Making it work in apt-get is a fair bit more work, which is why it hasn't been done yet (same with a Windows installer).\n. If you look in buck-out/logs there will be a log file with more information.  @Coneko is working on making that error message better.\n. deps on a prebuilt_jar are already treated as exported_deps.  Can you provide an example that fails?\n. @hujin1860 - that repo is missing files/directories, and I haven't been able to hack it up enough to get it to build.  Can you please try to reproduce it in that repo?\n. @hujin1860 - that repo is missing files/directories, and I haven't been able to hack it up enough to get it to build.  Can you please try to reproduce it in that repo?\n. Whoops, I did get to that point yesterday.  I got this issue mixed up with another, so when I hit that build error, I thought it was more broken.\nSo I can reproduce this.  I'm not sure why it's not working though.\n. Whoops, I did get to that point yesterday.  I got this issue mixed up with another, so when I hit that build error, I thought it was more broken.\nSo I can reproduce this.  I'm not sure why it's not working though.\n. What version of Buck are you using (the githash or the tag you are using would be sufficient)?\n. What version of Buck are you using (the githash or the tag you are using would be sufficient)?\n. Possibly related to #208, but we should be ignoring this already: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/AaptStep.java#L55\n. That sounds awesome!\n. @Coneko would probably be the best person to look at this.\n. @Coneko would probably be the best person to look at this.\n. @davido, do you want to try and make a PR with what @shs96c suggested?\n. Ha, is this why lint always dies on this file?  I've been meaning to look into this, but haven't had the cycles.\n. Ha, is this why lint always dies on this file?  I've been meaning to look into this, but haven't had the cycles.\n. Buck doesn't generate the R.class file until we produce the APK, I believe.  This might not actually be possible.\nWith that said, how we do Java-like languages has been refactored (there's now a jvm module), so it might be a lot easier to add Kotlin support natively into Buck, which would remove the need for some of the hacks folks currently have to do.\n. Buck doesn't generate the R.class file until we produce the APK, I believe.  This might not actually be possible.\nWith that said, how we do Java-like languages has been refactored (there's now a jvm module), so it might be a lot easier to add Kotlin support natively into Buck, which would remove the need for some of the hacks folks currently have to do.\n. I think the only way you are going to be able to do this is to implement Kotlin in Buck.  The good news is that @mikekap and @grumpyjames have been doing a lot of work to make it possible to add new JVM-backed languages.\n. I'm guessing you resolved this?\n. I'm guessing you resolved this?\n. Thank @tgummerer and @natthu more than me!  I just helped make sure it all got in :)\n. Thank @tgummerer and @natthu more than me!  I just helped make sure it all got in :)\n. This probably fixes things on Windows too!  Thanks!\n. This probably fixes things on Windows too!  Thanks!\n. @facebook-github-bot import\n. @facebook-github-bot import\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. I really wish github handled stacked diffs better...\n. Good news: we've got CI again!\nBad news: I had to disable the Go integration tests to get it passing because we need this PR (and its dep).  I referenced this PR so you can see the commit above.  When you rebase this (because you'll have to), could you re-enable the test too?  That'll be a good way to verify that the fix works too :)\n. Good news: we've got CI again!\nBad news: I had to disable the Go integration tests to get it passing because we need this PR (and its dep).  I referenced this PR so you can see the commit above.  When you rebase this (because you'll have to), could you re-enable the test too?  That'll be a good way to verify that the fix works too :)\n. Can you rebase this so that it is easier to review please?  Your other PR is in :)\n. Can you rebase this so that it is easier to review please?  Your other PR is in :)\n. I'm going to wait for the Travis results, but I suspect it'll be fine.\n. I'm going to wait for the Travis results, but I suspect it'll be fine.\n. I don't know why the JDK7 tests fails in Travis.  It doesn't in my test repo.  Clearly I should just remove it.\n. I don't know why the JDK7 tests fails in Travis.  It doesn't in my test repo.  Clearly I should just remove it.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Do you have local changes @symphony2512?  I don't see anything like what that error is talking about in https://github.com/facebookarchive/AntennaPod.\n. No response from the author, and I think @tgummerer answered this.\n. Setting android_sdk_proguard_config to 'none' looks suspicious.  Your comment there implies to tried setting to to something else; was that 'optimized'?\n. Setting android_sdk_proguard_config to 'none' looks suspicious.  Your comment there implies to tried setting to to something else; was that 'optimized'?\n. I think that was the expected behavior.  If you set it to 'none', the default configuration isn't going to be loaded at all.\n. I think that was the expected behavior.  If you set it to 'none', the default configuration isn't going to be loaded at all.\n. Do you have a lot of methods?  Creating the dex is going to scale with the number of methods you have (although I've never seen it take this long).\n. There's nothing in buck-out/logs/?  We should have the command we are running in there at the very least.\n. There's nothing in buck-out/logs/?  We should have the command we are running in there at the very least.\n. No response from @rambowding, so I'm closing this.\n. Did you do a recursive clone?  That looks like one of the submodules is \nmissing some files.\nCheers,\nShawn\n. Did you do a recursive clone?  That looks like one of the submodules is \nmissing some files.\nCheers,\nShawn\n. I don't have a lot of insight into Gradle errors unfortunately.  Is it possible that you need to use a newer JDK?\n. I don't have a lot of insight into Gradle errors unfortunately.  Is it possible that you need to use a newer JDK?\n. I'm not sure what's wrong, and I think you've gotten through this, so I'm going to close this.\n. @facebook-github-bot import\n. @facebook-github-bot shipit\n. It looks like short of modifying apk_builder, the answer is no.\n. It looks like short of modifying apk_builder, the answer is no.\n. I wonder if this is a bug with args4j :/\n. I wonder if this is a bug with args4j :/\n. I believe that @Coneko will look at this tomorrow when he gets in.\n. I believe that @Coneko will look at this tomorrow when he gets in.\n. The important diffs from that log you linked to:\nChange details for [//ios:SPTSmallBuckClientBinary#iphonesimulator-x86_64]\n  (destinations.appendableSubKey):\n    -[ruleKey(sha1=819206430cccf02442865351c574e74e8d33a39d)]\n    +[ruleKey(sha1=deadd8c67d89bd1c7df2a438f92906d232968736)]\nChange details for [//ios:SPTSmallBuckClientBinary#binary,iphonesimulator-x86_64]\n  (buck.deps.appendableSubKey):\n    -[ruleKey(sha1=da39a3ee5e6b4b0d3255bfef95601890afd80709)]\n    +[ruleKey(sha1=98d356db75e24a7346ae94f6db31657585bfcbe4)]\nChange details for [//ios:SPTSmallBuckClientBinary#binary,iphonesimulator-x86_64]\n  (.buck.appendableSubKey):\n    -[ruleKey(sha1=da39a3ee5e6b4b0d3255bfef95601890afd80709)]\n    +[ruleKey(sha1=98d356db75e24a7346ae94f6db31657585bfcbe4)]\ndestinations.appendableSubKey would differ if any of these are different on the machines.\nbuck.deps.appendableSubKey is likely different because //ios:SPTSmallBuckClientBinary#iphonesimulator-x86_64 had a different rule key.\nI think .buck.appendableSubKey may be different for the reason that buck.deps.appendableSubKey is different too.\n. The important diffs from that log you linked to:\nChange details for [//ios:SPTSmallBuckClientBinary#iphonesimulator-x86_64]\n  (destinations.appendableSubKey):\n    -[ruleKey(sha1=819206430cccf02442865351c574e74e8d33a39d)]\n    +[ruleKey(sha1=deadd8c67d89bd1c7df2a438f92906d232968736)]\nChange details for [//ios:SPTSmallBuckClientBinary#binary,iphonesimulator-x86_64]\n  (buck.deps.appendableSubKey):\n    -[ruleKey(sha1=da39a3ee5e6b4b0d3255bfef95601890afd80709)]\n    +[ruleKey(sha1=98d356db75e24a7346ae94f6db31657585bfcbe4)]\nChange details for [//ios:SPTSmallBuckClientBinary#binary,iphonesimulator-x86_64]\n  (.buck.appendableSubKey):\n    -[ruleKey(sha1=da39a3ee5e6b4b0d3255bfef95601890afd80709)]\n    +[ruleKey(sha1=98d356db75e24a7346ae94f6db31657585bfcbe4)]\ndestinations.appendableSubKey would differ if any of these are different on the machines.\nbuck.deps.appendableSubKey is likely different because //ios:SPTSmallBuckClientBinary#iphonesimulator-x86_64 had a different rule key.\nI think .buck.appendableSubKey may be different for the reason that buck.deps.appendableSubKey is different too.\n. We call Resources.getResource for the script in ProjectGenerator, but I don't see us adding it as a resource anywhere.  Are we just failing to package this?\n. We call Resources.getResource for the script in ProjectGenerator, but I don't see us adding it as a resource anywhere.  Are we just failing to package this?\n. I'm wrong; we include it in //src/com/facebook/buck/apple:rules as a resource.\n. I'm wrong; we include it in //src/com/facebook/buck/apple:rules as a resource.\n. We'll have to do a separate PR.  I'm just about to push the scrubbed changes out; this was landed in our internal tree yesterday morning, alas.\nIt should be easy to do a PR though once you rebase :)\n. We'll have to do a separate PR.  I'm just about to push the scrubbed changes out; this was landed in our internal tree yesterday morning, alas.\nIt should be easy to do a PR though once you rebase :)\n. I'll let @Coneko merge this in since he already started looking at it.\n. I'll let @Coneko merge this in since he already started looking at it.\n. sigh  No, that's probably a bug somewhere.  I'm sure it wasn't meant to be empty.\n. sigh  No, that's probably a bug somewhere.  I'm sure it wasn't meant to be empty.\n. No, it shouldn't crash it (it doesn't for me or anyone else that I'm aware of).\n. No, it shouldn't crash it (it doesn't for me or anyone else that I'm aware of).\n. Still a valid issue; we'll get to the bottom of it soon.  Our importer seems to drop binary artifacts, so we never pulled the right file in from @tgummerer's PR.  Although, the fact that the test passes despite the empty file is a bit concerning...\n. No response from @symphony2512, so I'm closing this.\n. @JoelMarcey has basically done this with our new getting started page.. Not currently, no.  This just came up in our discussion group as well: https://groups.google.com/forum/#!topic/buck-build/6uQ0yhqqR0I\n. Did you bisect to that?  That change doesn't have anything that would make anything you are using more verbose.  What I am seeing there is that you have a test failure, and those have been verbose in Buck for as long as I can remember.\n. Are you sure a change to gerrit didn't cause the logs to be more verbose?  I'm quite positive we haven't changing anything here with Buck.\n. @facebook-github-bot shipit\n. #506 will be landing soon.  Note to any other Facebook people: we can't use the normal import flow for this because it's broken for binary jars.\n. I've imported this, but making sure it passes CI before landing it.\n. I've imported this, but making sure it passes CI before landing it.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. It should take an xml file or an android_manifest rule, much like android_library.\n. It should take an xml file or an android_manifest rule, much like android_library.\n. I don't understand the build failure at all.  It looks like Travis is (once again) killing our tests (exit code 173 is SIGKILL).  The only android-related changes that went in were @tgummerer's tests, and those passed when the PR was there.\n. I don't understand the build failure at all.  It looks like Travis is (once again) killing our tests (exit code 173 is SIGKILL).  The only android-related changes that went in were @tgummerer's tests, and those passed when the PR was there.\n. Almost certainly is.  I'm going to try and split up that target.\n. Almost certainly is.  I'm going to try and split up that target.\n. @andrewjcg, I think we talked about this very issue a week or two ago.  Also, @dreiss, your recent soname changes missed prebuilt_cxx_library.\n. @andrewjcg, I think we talked about this very issue a week or two ago.  Also, @dreiss, your recent soname changes missed prebuilt_cxx_library.\n. Oh hey, we actually say that in the docs too: https://buckbuild.com/rule/prebuilt_cxx_library.html\nI think my brain, when I was shown this problem in the first place, automatically mapped it to the \"right\" text.\n. Oh hey, we actually say that in the docs too: https://buckbuild.com/rule/prebuilt_cxx_library.html\nI think my brain, when I was shown this problem in the first place, automatically mapped it to the \"right\" text.\n. @facebook-github-bot import\n. @facebook-github-bot import\n. Can you do one of the following:\n- Pull in a newer version wholesale so we aren't patching this\n- Update https://github.com/facebook/buck/blob/master/third-party/py/setuptools/README.facebook to include this change and why\n. Can you do one of the following:\n- Pull in a newer version wholesale so we aren't patching this\n- Update https://github.com/facebook/buck/blob/master/third-party/py/setuptools/README.facebook to include this change and why\n. Oof.  I'd like that (it might be easier to update the PEX code first/with it too), but if it ends up being a lot of work, I'm okay with just a patch for now.\n. Oof.  I'd like that (it might be easier to update the PEX code first/with it too), but if it ends up being a lot of work, I'm okay with just a patch for now.\n. @andrewjcg or @bhamiltoncx - you two are probably the most qualified to review this.\n. @andrewjcg or @bhamiltoncx - you two are probably the most qualified to review this.\n. @andrewjcg is on PTO for a bit.  Since @bhamiltoncx is okay with this, let's ship it.\n@facebook-github-bot shipit\n. @andrewjcg is on PTO for a bit.  Since @bhamiltoncx is okay with this, let's ship it.\n@facebook-github-bot shipit\n. I ran this in our internal CI which is a bit more exhaustive than Travis.  We hit this error:\nFile \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/src/com/facebook/buck/python/make_pex.py\", line 42, in <module>\n  File \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/.bootstrap/pkg_resources/__init__.py\", line 1174, in resource_stream\n    self, resource_name\n  File \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/.bootstrap/pkg_resources/__init__.py\", line 1617, in get_resource_stream\n    return io.BytesIO(self.get_resource_string(manager, resource_name))\n  File \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/.bootstrap/pkg_resources/__init__.py\", line 1620, in get_resource_string\n    return self._get(self._fn(self.module_path, resource_name))\n  File \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/.bootstrap/pkg_resources/__init__.py\", line 1698, in _get\n    return self.loader.get_data(path)\nIOError: [Errno 11] Resource temporarily unavailable: 'pkg_resources.zip'\nAny idea on what's up?  I don't think I'm missing any files for your change internally (and not all builds are failing this way).\n. I ran this in our internal CI which is a bit more exhaustive than Travis.  We hit this error:\nFile \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/src/com/facebook/buck/python/make_pex.py\", line 42, in <module>\n  File \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/.bootstrap/pkg_resources/__init__.py\", line 1174, in resource_stream\n    self, resource_name\n  File \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/.bootstrap/pkg_resources/__init__.py\", line 1617, in get_resource_stream\n    return io.BytesIO(self.get_resource_string(manager, resource_name))\n  File \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/.bootstrap/pkg_resources/__init__.py\", line 1620, in get_resource_string\n    return self._get(self._fn(self.module_path, resource_name))\n  File \"/path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/.bootstrap/pkg_resources/__init__.py\", line 1698, in _get\n    return self.loader.get_data(path)\nIOError: [Errno 11] Resource temporarily unavailable: 'pkg_resources.zip'\nAny idea on what's up?  I don't think I'm missing any files for your change internally (and not all builds are failing this way).\n. I couldn't tell you; the machines take a new job which nukes state once the job is done.\n. I couldn't tell you; the machines take a new job which nukes state once the job is done.\n. I was hoping to dig into this more yesterday or today, but I'm oncall for my team, and it's been a bit crazy.  I might not get to this until next week due to the US holiday, unfortunately.  Maybe @Coneko can help you out if you need this in sooner.\n. I was hoping to dig into this more yesterday or today, but I'm oncall for my team, and it's been a bit crazy.  I might not get to this until next week due to the US holiday, unfortunately.  Maybe @Coneko can help you out if you need this in sooner.\n. Last week I got totally derailed, alas.  I wonder if @andrewjcg has some insight on this failure.\n. I thought I had!  Silly brain misleading me.  @facebook-github-bot import\n. Bah.  The importer had some errors importing the diff.  I'll have to try to import it by hand later today.\n. Alright, I imported this locally this morning, but trying buck build buck failed for me with this:\nTraceback (most recent call last):\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 155, in <module>\n    sys.exit(main())\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 116, in main\n    copy_resources(pex_builder, 'pkg_resources', prefix=pex_builder.BOOTSTRAP_DIR)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 69, in copy_resources\n    os.path.join(prefix, target_path))\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/twitter-commons/src/python\\twitter\\common\\python\\pex_builder.py\", line 104, in add_source\n    self._chroot.link(filename, env_filename, \"source\")\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/twitter-commons/src/python\\twitter\\common\\python\\common.py\", line 283, in link\n    shutil.copyfile(abs_src, abs_dst)\n  File \"C:\\Python27\\lib\\shutil.py\", line 82, in copyfile\n    with open(src, 'rb') as fsrc:\nIOError: [Errno 13] Permission denied: 'c:\\\\users\\\\sdwilsh\\\\appdata\\\\local\\\\temp\\\\tmpy8gqvw'\nTraceback (most recent call last):\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 155, in <module>\n    sys.exit(main())\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 116, in main\n    copy_resources(pex_builder, 'pkg_resources', prefix=pex_builder.BOOTSTRAP_DIR)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 69, in copy_resources\n    os.path.join(prefix, target_path))\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/twitter-commons/src/python\\twitter\\common\\python\\pex_builder.py\", line 104, in add_source\n    self._chroot.link(filename, env_filename, \"source\")\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/twitter-commons/src/python\\twitter\\common\\python\\common.py\", line 283, in link\n    shutil.copyfile(abs_src, abs_dst)\n  File \"C:\\Python27\\lib\\shutil.py\", line 82, in copyfile\n    with open(src, 'rb') as fsrc:\nIOError: [Errno 13] Permission denied: 'c:\\\\users\\\\sdwilsh\\\\appdata\\\\local\\\\temp\\\\tmpijmklt'\n. Alright, I imported this locally this morning, but trying buck build buck failed for me with this:\nTraceback (most recent call last):\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 155, in <module>\n    sys.exit(main())\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 116, in main\n    copy_resources(pex_builder, 'pkg_resources', prefix=pex_builder.BOOTSTRAP_DIR)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 69, in copy_resources\n    os.path.join(prefix, target_path))\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/twitter-commons/src/python\\twitter\\common\\python\\pex_builder.py\", line 104, in add_source\n    self._chroot.link(filename, env_filename, \"source\")\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/twitter-commons/src/python\\twitter\\common\\python\\common.py\", line 283, in link\n    shutil.copyfile(abs_src, abs_dst)\n  File \"C:\\Python27\\lib\\shutil.py\", line 82, in copyfile\n    with open(src, 'rb') as fsrc:\nIOError: [Errno 13] Permission denied: 'c:\\\\users\\\\sdwilsh\\\\appdata\\\\local\\\\temp\\\\tmpy8gqvw'\nTraceback (most recent call last):\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 155, in <module>\n    sys.exit(main())\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 116, in main\n    copy_resources(pex_builder, 'pkg_resources', prefix=pex_builder.BOOTSTRAP_DIR)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 55, in copy_resources\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 69, in copy_resources\n    os.path.join(prefix, target_path))\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/twitter-commons/src/python\\twitter\\common\\python\\pex_builder.py\", line 104, in add_source\n    self._chroot.link(filename, env_filename, \"source\")\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/twitter-commons/src/python\\twitter\\common\\python\\common.py\", line 283, in link\n    shutil.copyfile(abs_src, abs_dst)\n  File \"C:\\Python27\\lib\\shutil.py\", line 82, in copyfile\n    with open(src, 'rb') as fsrc:\nIOError: [Errno 13] Permission denied: 'c:\\\\users\\\\sdwilsh\\\\appdata\\\\local\\\\temp\\\\tmpijmklt'\n. I'm not sure what's up with that error.  The directory exists there, and I'm not sure why it's getting permission denied there, but it looks like that code path is new, so I'm pretty sure it's that change.\n. I'm not sure what's up with that error.  The directory exists there, and I'm not sure why it's getting permission denied there, but it looks like that code path is new, so I'm pretty sure it's that change.\n. Wow, that is special.  I'll import this, make sure it builds on my Windows machine, and then run it through our internal CI.\n. sigh\nSo, I wasn't able to make Travis use python2.6, and our internal CI actually does check that (Buck supports it).  You have some things that make python2.6 unhappy too:\nFile \"/data/sandcastle/boxes/instance-buck-git-buck-verification-linux/src/com/facebook/buck/python/make_pex.py\", line 80\n    with closable_named_temporary_file() as fp, \\\n                                              ^\nSyntaxError: invalid syntax\n  File \"/data/sandcastle/boxes/instance-buck-git-buck-verification-linux/src/com/facebook/buck/python/make_pex.py\", line 80\n    with closable_named_temporary_file() as fp, \\\n                                              ^\nSyntaxError: invalid syntax\n  File \"/data/sandcastle/boxes/instance-buck-git-buck-verification-linux/src/com/facebook/buck/python/make_pex.py\", line 80\n    with closable_named_temporary_file() as fp, \\\n                                              ^\nSyntaxError: invalid syntax\nI'm pretty sure this is the \"can't have more than one thing in a with statement\" issue.\n. I've kicked off internal CI again with your changes.\n. If we were to support this, we'd have to declare each and every output.  We have a hacky way we did this internally that basically redefines genrule to be something that generates a genrule for each output.\n. If we were to support this, we'd have to declare each and every output.  We have a hacky way we did this internally that basically redefines genrule to be something that generates a genrule for each output.\n. Internally, that'd probably create an export_file rule addressable by the flavor like you have there.\ncc @shs96c and @Coneko for design feedback there, but I think we'd take a PR for this if you wanted to make it official.\n. Internally, that'd probably create an export_file rule addressable by the flavor like you have there.\ncc @shs96c and @Coneko for design feedback there, but I think we'd take a PR for this if you wanted to make it official.\n. @mikekap, if you want to take a stab at this, I think we've given you a bunch of design direction.  If not, that's okay too. :)\n. @mikekap, if you want to take a stab at this, I think we've given you a bunch of design direction.  If not, that's okay too. :)\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Good catch!\n. Good catch!\n. We'd be happy to take a PR to clean up the is_dirty stuff too.  Thanks!\n. We'd be happy to take a PR to clean up the is_dirty stuff too.  Thanks!\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. I think the latter case is the one we care about.  The former feels potentially error-prone still.\n. I think the latter case is the one we care about.  The former feels potentially error-prone still.\n. ping @spierce7 \n. Sorry for the delay @zlwen!  Can you provide us with a more detailed example please?\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. The Travis failures aren't your fault (suddenly aapt is no longer available).\n. The Travis failures aren't your fault (suddenly aapt is no longer available).\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Do you have an android_build_config rule too?\n. Do you have an android_build_config rule too?\n. I'm at a loss then.  @marcinkosiba, any ideas?\n. I'm at a loss then.  @marcinkosiba, any ideas?\n. Oh, I wonder if we can fix that to work better (cc @alsutton in addition to @marcinkosiba who was already cc'd)\n. @AnthonyUccello, can this be closed then?\n. Hmm, I think the Buck plugin for IntelliJ might hide that for you (@alsutton would know).  No idea if that works with Android Studio, however.\n. We, unfortunately, don't have any docs on how to use the plugin, and I'm not sure myself as I haven't worked on it.\n. @alsutton might be able to point you at docs\n. buck build app works for me in your sample repository.  What are you actually running to hit that error?\n. Hmm, this is odd.  It's ending up in the buck-out/gen/bucklib/__lib-res_text_symbols__/R.txt file Buck generates:\nint dimen activity_horizontal_margin 0x7f020001\nint dimen activity_vertical_margin 0x7f020002\nint id action_settings 0x7f050001\nint layout activity_lib 0x7f040002\nint layout activity_main 0x7f040001\nint menu menu_main 0x7f030001\nint string action_settings 0x7f010003\nint string app_name 0x7f010001\nint string hello_world 0x7f010002\nint string lib_src 0x7f010004\nYou are properly depping on the android_resource so I'm confused why it's not available.  Maybe @andrewjcg or @marcinkosiba have an idea.\n. This might be as easy as setting cache.mode = dir in the .buckconfig file of the repo.  If that helps, do you mind submitting a PR?\n. Keep in mind that cross-cell could point to something completely outside of the tree, so I don't think we'd ever put out buck-out/gen/lib/jgit/jgit_src.jar as the path to the output.\n. Ah, yeah.  When using the $(exe ) macro, Buck automatically adds the python invocation line for you, so you ended up having it twice.  That code is here: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/python/PythonPackagedBinary.java#L87\n. Oh, whoops.  Yeah, when I change this behavior a while ago I didn't even realize there was an example that used it!  Can you either submit a PR to update the docs or file an issue please? :)\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @andrewjcg is probably the best person to help with that.\n. These looks like locale-specific failures.  @bhamiltoncx, what's the best way to test this type of stuff in a locale-aware way?\n. That non-intrusive change sounds sensible to me.\n. That non-intrusive change sounds sensible to me.\n. @marcinkosiba, do you think you could help @davido look into the Android failures tomorrow?\n. @shs96c helped me get this working.  It turns outtools.jarwas not on my classpath for IntelliJ.  If you click on the buck module, and then hitF4, you can then go to the SDKs area and make sure it is in your classpath.\n. Hmm, still seeing a number of test failures (mostly Android) due to this change in Travis.\n. Hmm, still seeing a number of test failures (mostly Android) due to this change in Travis.\n. Correct, those tests will be assumption failures and won't be reported as test failures.  You can install the android sdk and they'll run.\n. Correct, those tests will be assumption failures and won't be reported as test failures.  You can install the android sdk and they'll run.\n. I think you just need to worry about the SDK for the tests that are failing, FWIW.\n. I think you just need to worry about the SDK for the tests that are failing, FWIW.\n. @facebook-github-bot import\n. You've gotroot.resolve(Paths.get(...))in a lot of places now where you could just doroot.resolve(...)instead in the tests.  I'd like you to do the latter.  Otherwise, this is good and I'll land it first thing tomorrow if you update it later today.\n. You've gotroot.resolve(Paths.get(...))in a lot of places now where you could just doroot.resolve(...)` instead in the tests.  I'd like you to do the latter.  Otherwise, this is good and I'll land it first thing tomorrow if you update it later today.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. If you are feeling ambitious, #518 would solve this for you as well if you wanted to submit a PR.\n. @Coneko started a month of PTO, so I'm not sure he'll be around to respond.  I'm going to jump in and try to answer some of your questions.\n\nIs there any discussion around this, or way to track it so that I could follow it and see what's decided? I'd like to better understand the pros / cons.\n\nI think these have mostly been in-person discussions.  I'm not aware of anything internally or externally available, unfortunately (and I don't know the details myself, but @shs96c might).\n\nIt's trying to read buck-out/gen/rxjava/rx/Observable.m/rx/Observable.m as the file, but that is actually the folder containing the file, which is what's causing the error. buck-out/gen/rxjava/rx/Observable.m/rx/Observable.m/Observable.m is actually the file that it needs to be reading.\n\nBecause you call mkdir -p $OUT, your output will be a variable, not a file.  I think this should do what you want:\ndef objcGenRule(objc_filename):\n  genrule(\n    name = objc_filename,\n    cmd = 'cp $(location :objc-generate)/' + objc_filename + ' $OUT',\n    out = objc_filename,\n  )\nYou might also try using ln -s which will probably take up less space any might even be faster.\n. I think we can close this now :)\n. I think we can close this now :)\n. @facebook-github-bot import\n. > CI, but with extras: two new tests only provide coverage when\n\nGROOVY_HOME is set; we recommend this be added to CI.\n\nI strongly suggest you do this, as you are more likely to get it right than any of us :)\nThe travis config isn't too hard to modify.\n. Memo to myself: fix the Android stuff that randomly broke.\n@facebook-github-bot shipit\n. Indeed, our Travis build has gone green again.\n. actually, you have lint failures that travis would catch if you rebase (the travis build is green on master)\n. @facebook-github-bot shipit\n. @facebook-github-bot import\n. Hmm, I do need the bot to approve this however...\n. @facebook-github-bot shipit\n. Whoops, this should have updated .classpath and .idea/modules/buck_lib.iml too.  I'll fix it myself.\n. @facebook-github-bot shipit\n. cc @rowillia since he'll probably find this useful.\n. Fantastic.  Hopefully we can get all those merged in today before I have to leave on a flight (I really wish GitHub made it easier to do stacked pull requests).\n. Sorry this took so long to get in.  We are having some infra issues internally that prevented it from automatically happening.\n. I think @andrewjcg is on a plane today, but he might be jet lagged enough to look at this when he lands :)\n. I think @andrewjcg is on a plane today, but he might be jet lagged enough to look at this when he lands :)\n. @facebook-github-bot import\n. @facebook-github-bot import\n. @facebook-github-bot import\n. @facebook-github-bot import\n. It looks like @andrewjcg reverted this in https://github.com/facebook/buck/commit/a03737b3e2e31e833e30e9013052dad7a936e5cb, but I don't see a comment here about it.\n. It looks like @andrewjcg reverted this in https://github.com/facebook/buck/commit/a03737b3e2e31e833e30e9013052dad7a936e5cb, but I don't see a comment here about it.\n. I think @andrewjcg has a diff up to fix that test failure, so I'll go review that next.\n. @facebook-github-bot shipit\n. Isn't this a dupe of #371?\n. We don't really have an FAQ page, but we'd take a PR to add one!\n. Sweet; thanks @brettwooldridge :D. I'm fine with not documenting this until we (well, you) feel it is more solid.\n. @facebook-github-bot shipit\n. The revert should go out soon.  Pretty much everyone on the team was on PTO, so we had a slow response time here and I feel bad about that.\n. @facebook-github-bot shipit\n. You've got a lint failure that Travis caught:\n/home/travis/build/facebook/buck/src/com/facebook/buck/jvm/groovy/GroovycStep.java:105: Line is longer than 100\n. I'm otherwise happy with this, and can merge it in once you fix the lint error.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. I failed to test this after you did the \"actually use it\" PR.  On Windows, I'm getting this error:\nTraceback (most recent call last):\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 167, in <module>\n    sys.exit(main())\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 128, in main\n    copy_package(pex_builder, 'pkg_resources', prefix=pex_builder.BOOTSTRAP_DIR)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 67, in copy_package\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 67, in copy_package\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 67, in copy_package\n    os.path.join(resource, entry), prefix)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\src\\com\\facebook\\buck\\python\\make_pex.py\", line 81, in copy_package\n    os.path.join(prefix, target_path))\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/pex\\pex\\pex_builder.py\", line 143, in add_source\n    self._copy_or_link(filename, env_filename, \"source\")\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/pex\\pex\\pex_builder.py\", line 347, in _copy_or_link\n    self._chroot.link(src, dst, label)\n  File \"C:\\Users\\sdwilsh\\code\\buck\\third-party/py/pex\\pex\\common.py\", line 273, in link\n    os.link(abs_src, abs_dst)\nAttributeError: 'module' object has no attribute 'link'\n. Okay, there is more wrong than that.  I'm going to comment in #605 and I'm going to have to revert using the new PEX, alas.\n. @facebook-github-bot shipit\n. 1) That API is correct, and there's some ad-hoc docs here: http://stackoverflow.com/questions/32915721/documentation-for-annotation-processors-buck\n2) We'd like to move to Bazel's API of declaring a java_plugin for these, and it wouldn't be hard to do; it's just a matter of doing the work for it and documenting it.  It hasn't been the highest priority.\nFor what it's worth, the current API is used quite extensively at Facebook, so even if it were to change it, we'd support the old API for a while I suspect (and at the very least, we'd announce it in our release notes if we did change it).\n. I think I already answered this for you, so I'm going to close it.  If you disagree, please reopen and clarify what you feel is unresolved.\n. I think I already answered this for you, so I'm going to close it.  If you disagree, please reopen and clarify what you feel is unresolved.\n. I'm actually a little surprised this doesn't already work.  It looks like we already do the downloading as part of the remote_file rule when it is executed, and that should be cached because we cache the output of that build rule.\n. It's possible the rule keys are always different and that could be what is invalidating the cache for you.\n. Assuming the key is the same, it should be available from the cache.  Do the rule keys differ?\n. Correct, but if you downloaded it at that version, it'd be saved too.\n. @facebook-github-bot shipit\n. @alisdair04 added that in da121e36ffa7879c5c7d2ad5776b1d82f0f04faf\n. I know exactly what is causing this...\n. https://github.com/facebook/buck/blob/master/src/com/facebook/buck/parser/ParallelPerBuildState.java#L396\nI'm probably not going to get a fix for that in today, but tomorrow is promising!  Feel free to get a PR up if you want it fixed sooner.  That constant can go down, and we probably need to re-evaluate how we kill that off too.\n. @facebook-github-bot import\n. @facebook-github-bot shipit\n. I'll let you do the deletion in another PR.\n. I deeply regret not testing this on Windows first, and now I'm going to have to revert it.  I've got some changes that get it further along, but when I'm building Buck with Buck, python ends up crashing, which is a bit surprising.  I've spent about half my day on trying to resolve it, but at this point, I'm going to have to revert it.\nThe changes I've got are in https://gist.github.com/sdwilsh/ccb90fbc6a60d885a326 if you want to try to figure out why on Earth it crashes python.\n. Setting up CI for Windows has been on my short list for a while \n(especially since I develop on Windows so breaking it means I'm stuck). \n  Sadly, it hasn't made it to the top of that list yet.\n. Setting up CI for Windows has been on my short list for a while \n(especially since I develop on Windows so breaking it means I'm stuck). \n  Sadly, it hasn't made it to the top of that list yet.\n. Let me cherrypick the change and see how it goes for me and then I'll re-land it.\n. Bah, that didn't attribute to you.  I can fix that if you'd like; just let me know.\n. There's an undocumented sh_test that you can use.  It's undocumented because it has a pretty rubbish API, but you could probably use it.  The arguments are the snake_case version of these: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/shell/ShTestDescription.java#L101\n. Hehe, yeah, I keep meaning to make a page for projects that use Buck.  The big one is Gerrit.\n. Buck is based on many of the same design ideas.  Both are based on \nGoogle's internal build tool called Blaze.  In the end, it depends on \nwhat is best for your project, IMO.\n. Yeah, we use Buck for React Native internally.  Still working on making the open source support good enough that we are happy with it.\n. No, and those types of commands sound a bit outside that of a build tool (we are more aligned with the unix philosophy of having a tool do one thing and do it well).  That sounds like you want a project lifecycle management tool, which a lot of people use Maven for.  You could still have the build command call into Buck for that to get the better build experience.\n. If you run into more issues, feel free to file them here or post \nquestions to Stack Overflow with the Buck tag :)\n. @facebook-github-bot shipit\n. Thanks for the fix!\n. Clearly I never tested this with a no-op case :)\n. @facebook-github-bot shipit\n. Nearly there!  You missed one comment from last time, plus I spotted a few more things that I missed.\n. Nearly there!  You missed one comment from last time, plus I spotted a few more things that I missed.\n. You missed one minor thing :)\n. You missed one minor thing :)\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. I was looking at the commit for this while writing the release notes, and I noticed the email address you've been using isn't associated with your github account.  That may be intentional, but I thought I'd call it out :)\n. > We have ClojureScript module which we are thinking to build using genrule which will generate JAR files, but how we can pass it to the other ClojureScript modules?\nYou already found the $(location ) macro, which is what you'd want to use here.\n\nAnother example could be static blog site that depends one one module which generates markdown files and another once which is a CSS/HTML wrappers\n\nYou can use the same as above for this, right?\n. > location macro is available only inside bash command, isn't it? Can I somehow get location of a deps inside a python and then pass it to my bash script and avoid ugly string manipulations?\nNo, it isn't possible to use inside of Python; your build rules shouldn't need to know the exact output location of a build rule.  Your example also looks like it doesn't actually do anything concrete; what is the intent of static_site?\n\nWhat is a right approach to share python macro function (static_site in this case) between multiple modules? Where I should put it?\n\nSee include_defs\n. Just want you to address the first comment.  Thanks!\n. Just want you to address the first comment.  Thanks!\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. That should be out later today :)\n. cc @wez, although you might want to file this with the facebook/watchman project instead.\n. cc @wez, although you might want to file this with the facebook/watchman project instead.\n. Just some drive-bys there.  I'm going to let someone else actually review this.\n. Just some drive-bys there.  I'm going to let someone else actually review this.\n. @facebook-github-bot shipit\n. lib_dir is currently a String type in Java, which means it won't resolve the name of the target.  We'd have to make that a SourcePath for that to work here: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/cxx/PrebuiltCxxLibraryDescription.java#L417\n. ...but that likely won't work right because we check for existence of the libraries when we create our action graph for building.  We'd have to change the interface to accomplish this.\nI'll get @andrewjcg to comment on a possible API design.\n. @facebook-github-bot shipit\n. It should work just fine for Android, Java, and Python.  Other things may work, but haven't been tested yet.  Native code is not currently supported.\nIf you are seeing a specific problem, you should file a specific issue about it.\n. For the second option, couldn't we just make a java_library and dep it so you don't have to worry about adding a new field?\n. @bhamiltoncx would probably be a good reviewer on this.\n. @facebook-github-bot shipit\n. Hmm, getting this error in CI (I'll look into it more later):\nTraceback (most recent call last):\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \"/usr/lib64/python2.6/contextlib.py\", line 34, in __exit__\n    self.gen.throw(type, value, traceback)\n  File \".bootstrap/_pex/pex.py\", line 223, in patch_pkg_resources\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \".bootstrap/_pex/pex.py\", line 253, in _wrap_coverage\n  File \".bootstrap/_pex/pex.py\", line 285, in _wrap_profiling\n  File \".bootstrap/_pex/pex.py\", line 363, in _execute\n  File \".bootstrap/_pex/pex.py\", line 421, in execute_entry\n  File \".bootstrap/_pex/pex.py\", line 426, in execute_module\n  File \"/usr/lib64/python2.6/runpy.py\", line 140, in run_module\n    fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"__test_main__.py\", line 374, in <module>\n  File \"__test_main__.py\", line 370, in main\n  File \"__test_main__.py\", line 345, in run\n  File \"__test_main__.py\", line 331, in get_test_names\n  File \"__test_main__.py\", line 331, in get_test_names\n  File \"__test_main__.py\", line 336, in get_test_names\nValueError: zero length field name in format\nWithout looking into the actual failure, I suspect it's a py2.6 issue given the machines it failed on.\n. Yeah, I couldn't get travis to use 2.6 for our CI unfortunately so it only gets flagged when I import it.\nHere's hoping that the import won't have conflicts like it did last time...\n. @facebook-github-bot import\n. Yeah, it spammed a lot of PRs.  This might actually land tonight, finally.\n. I had a hunch your python change was for this :)\n. > FAILURE //test/com/facebook/buck/parser:parser main: //test/com/facebook/buck/parser:parser failed with exit code 137\nsigh.  Once again, Buck is getting killed.  Let me throw up a change so they aren't all in one binary and see if that helps.\n. We should probably make this error message better.\n. buckd doesn't work on Windows (yet - @bhamiltoncx has some patches in progress).  If you set NO_BUCKD=1 in your environment ($env:NO_BUCKD=1 in powershell), you should be able to get past that.\n. @janicduplessis - do you have the \"Android Support Repository\" and \"Google Repository\" downloaded from the SDK Manager under the extras section?\n. Those should both be on-disk maven downloaders from the SDK.  For me, that library is located under $ANDROID_HOME\\extras\\android\\m2repository\\com\\android\\support\\support-v4\\23.0.1\\support-v4-23.0.1.aar.  Does that file exist for you?\n. @janicduplessis, can you upload your full log please?  Feel free to toss it in a gist.\n. That'd be great!  We're about to get CI soon for Windows via #647, so hopefully we can start enabling more tests on Windows too.\n. In the past we had source_under_test for references like this.  However, we have stopped doing that because it doesn't scale for large code bases.  This feels pretty similar to that.\nI'm interested to hear what @Coneko thinks.\n. In the past we had source_under_test for references like this.  However, we have stopped doing that because it doesn't scale for large code bases.  This feels pretty similar to that.\nI'm interested to hear what @Coneko thinks.\n. I would almost prefer to see something like a $(package ) macro that you could use in the package field instead the more I think about this.  That could possible be useful elsewhere too (and not just for Go).  I don't use Go though, so I'm interested in your thoughts and still what @Coneko has to say.\n. I would almost prefer to see something like a $(package ) macro that you could use in the package field instead the more I think about this.  That could possible be useful elsewhere too (and not just for Go).  I don't use Go though, so I'm interested in your thoughts and still what @Coneko has to say.\n. Back to you for the suggestion that @Coneko offered (since I think that's actually a good idea).  This looks good otherwise.\n. @facebook-github-bot shipit\n. We can deal with the go_binary stuff in a future PR/change :)\n. @facebook-github-bot import\n. Could you also add a test for this?  You can create a new class, OnDiskMavenDownloaderIntegrationTest, and write a simple test that downloads from the SDK.  I want to make sure we don't regress this again or on Unix systems now.\n. Could you also add a test for this?  You can create a new class, OnDiskMavenDownloaderIntegrationTest, and write a simple test that downloads from the SDK.  I want to make sure we don't regress this again or on Unix systems now.\n. That looks good; just fix the two comments please :)\n. That looks good; just fix the two comments please :)\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Whoops.  You've got some lint failures that you can see if you run ant lint.  CI is busted right now, but @bolinfest is looking into getting that resolved.\n. Whoops.  You've got some lint failures that you can see if you run ant lint.  CI is busted right now, but @bolinfest is looking into getting that resolved.\n. @facebook-github-bot import\n. @facebook-github-bot import\n. Well, we didn't doc the other gradle-specific stuff that @dreiss added because we really don't want people to use it.  It's a stopgap to help people convert and nothing more as I understand it.\n. It doesn't.  One of Buck's big things is repeatable builds, and using a snapshot is not repeatable (if someone else were to check out the same revision as you and fetch and build, they could end up with a completely different binary).  When you run clean, you are clearing out buck-out where the downloaded artifact is stored, so you have to get an updated copy.\n. That's true, but that means it shouldn't download it every time either \n(it would be cached if it was not changed).\n. What version of Java are you running, by chance?\n. Looking at the internal change, it looks like the diff failed to apply when @Coneko imported it.  It's possible rebasing would help, but it might also require more manual intervention which is why @Coneko hasn't landed it yet.\n. This was the solution @marcinkosiba and I came up with for licenses because putting it in BuckPyFunction is rather non-discoverable unless you happen to know Buck internals really well.\n. This was the solution @marcinkosiba and I came up with for licenses because putting it in BuckPyFunction is rather non-discoverable unless you happen to know Buck internals really well.\n. > You do know the buck internals really well.\nI thought I did, but trying to add licenses proved that to not be totally true!\n. > You do know the buck internals really well.\nI thought I did, but trying to add licenses proved that to not be totally true!\n. These should both probably be HumanReadableExceptions since they are actionable by the end user.  Could you also add a test so this doesn't regress?\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. It looks like all the CI is broken for Buck right now.  \"yay\"\n. It looks like all the CI is broken for Buck right now.  \"yay\"\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. You are, we just wouldn't suggest you do it that way because of things like this :)\n. It works mostly fine.  Not everything (native code compilation is a bit one) works, but in general, yes it works :)\n. @bviktor, Buck actually works pretty well on Windows.  It's even covered in the getting started guide.  This piece is just some old cruft that hasn't been removed.  I think I'll do so today.. > multiple Maven repositories at the same time\nDon't we already have that with this?  https://buckbuild.com/concept/buckconfig.html#maven_repositories\nI guess it's a little hard to understand what this is doing because there are no documentation changes :)\n. Documentation would be fantastic to have.  People have asked about this, and I keep forgetting it exists.  You can do that in a follow-up PR if you'd like though.  Documenting it does mean your work can be used more widely. ;)\n. An integration test would be nice to have too, at least using a local maven repo.\n. I think the manifest code is actually imported from AOSP.  It's possible that updating it might relax that constraint (see #299).  This isn't a priority for the core team though, but they'd probably take a PR :)\n. You'll also need to update https://github.com/facebook/buck/blob/master/third-party/py/setuptools/README.facebook to include the new addition.\n. I guess I'm blind today...\n. @facebook-github-bot import\n. Also, you should line wrap at 100 characters (I didn't count, but some of those lines look long)\n. Please also indent inside the <p />.  I realize the rest of the file might not, but it's the standard way we are documenting things now, so new stuff should do it :)\n. You don't actually need to use a force push because we'll just squash all your commits anyway :)\n. @facebook-github-bot shipit\n. This looks good.  We can import it once the CLA is signed :)\n. @marcinkosiba or @dreiss would be better.  I've changed teams and I'm not actively hacking on Buck these days.\n. @marcinkosiba or @dreiss would be better.  I've changed teams and I'm not actively hacking on Buck these days.\n. I got pinged about this by someone else, so I'm chime in anyway.  In my \ncomment on #223, what I was trying to say is that the best way to fix \nthat is to have a srcs attribute on android_binary that would make \nthe special library code with final ids.  I don't think exposing this UI \nin the build file is a good idea because it'll be easy to set as \ncopy-pasta and you end up slowing your build way down.\nHowever, we can take the srcs from an android_binary and graph \nenhance it to produce an android_library with forceFinalResourceIds \nset to true.  It's a bigger change, but it's the safer one and I think \n@marcinkosiba would be okay with that.  I'm pretty sure I've talked with \nhim or @dreiss about that very solution (but never had time to code it up).\n. I got pinged about this by someone else, so I'm chime in anyway.  In my \ncomment on #223, what I was trying to say is that the best way to fix \nthat is to have a srcs attribute on android_binary that would make \nthe special library code with final ids.  I don't think exposing this UI \nin the build file is a good idea because it'll be easy to set as \ncopy-pasta and you end up slowing your build way down.\nHowever, we can take the srcs from an android_binary and graph \nenhance it to produce an android_library with forceFinalResourceIds \nset to true.  It's a bigger change, but it's the safer one and I think \n@marcinkosiba would be okay with that.  I'm pretty sure I've talked with \nhim or @dreiss about that very solution (but never had time to code it up).\n. I just checked with @dreiss.  We'd have to graph-enhance an android_library from the srcs on the android_binary rule and have it depend on the aapt_package rule and it needs to compile against the final uber R.java file (and not the normal dummy R.java file).\n. If an app doesn't specify any srcs, I don't think we'd have to do this.  Am I misunderstanding you?\n. Sorry, it looks like I was ambiguous before.  We'd have to add srcs to android_binary, and only those would be subject to this.  Libraries would work as they do today.  Obviously this means that if you need to use butterknife, it needs to be a src of the binary, and not part of a library.\n. @zecke, do you plan on updating this? :)\n. cc @mzlee who has been touching this code recently.\n. @bolinfest - this is almost certainly due to baf394d8a442e40257ef61875e2a7ed0a0d47628.  Can you either revert that or fix Travis?\n. @bolinfest - this is almost certainly due to baf394d8a442e40257ef61875e2a7ed0a0d47628.  Can you either revert that or fix Travis?\n. I developed Buck for over a year on Windows.  We have a .cmd and a \n.ps1 file in the bin folder to be able to run on Windows, and we \nhave CI here on GitHub for PRs that run on Windows :)\n. Sorry, I meant a .bat file, not .cmd.\nCI = continuous integration\nPRs = pull requests\n. You are pretty much out of luck here.  What might help you fix this is moving our source try to something higher in the directory tree (even the root).  IIRC, the max length of file names is 255 characters.\n. I don't think I understand what you are asking.  Can you try to elaborate?\n. @marcinkosiba - it looks like the bot wasn't working when you tried to ship this.\n. The problem is that Buck isn't parsing the build file (it's parsed in \nPython), so it has no idea about any of the contents.  It just gets a \nJSON-like representation of the build rules.\n. The command that is going to be ran isn't even a factor when parsing \nbuild files, so it'd be have to be passed in.  It'd be a lot of work to \nmake something like this possible given how the code is constructed today.\n. Currently you can build Buck on any platform and it should run on any \nother platform (there are no binary components).  It'd be unfortunate if \nwe had to regress that.\nAside: we use JNA in Buck today, but I'm not sure that makes things any \neasier.\n. Do you have something referencing :LoveFreshBeen?\n. Wouldn't this be better set in the .buckconfig?\n. I think this is okay, but I haven't worked on Buck code in about six months, so I'm not comfortable accepting this.  With that said, it might be good to get an integration test to use this in a BUCK file too, and the docs for the rule need to be updated as well.\nMaybe @marcinkosiba can look at it once you do that.\n. @mlostekk - we don't currently have anything for that.  There might be some code in tests in the react-native project itself.  Reaching out there might be best, as that's more specific to that domain than to Buck.\n. We should probably bump the default version if newer NDKs do not contain it.\n. This basically reverts 91cab95a67ed695bc8d554c2585c2ab022d1f06e, but uses the Facebook Open Source account instead of @bolinfest's own account.\n. @facebook-github-bot shipit\n. cc @wez\n. Can you add a test to handle the case where you pass this in as well?  It looks like all tests you touched just handle the Optional.absent() case.\n. There was a bug before where we never prompted former employees to sign the individual CLA.  That bug has been fixed, but we don't have one of those on file for you.  @caabernathy should be able to help you after you email :)\nAdditionally, the bot tells you to email because the form isn't going to work if you already have signed the CLA before (via an org or individually).  Long story on why we haven't fixed that yet...\n. The corporate CLA process tends to take a bit longer (it's a manual process for lawyers on both ends), but the bot will comment once we have the data that it's been signed :)\n. \n. > I noticed that the daemon occasionally restarts which means the cache\n\ndirectory might not be cleaned. Might it be worth adding a directory\nclean at buckd startup?\nThat could lead to a bad experience if we have to cleanup a lot.  But I \nguess we already have that risk with commands contending for the single \ndaemon.\n. @dreiss or @marcinkosiba should probably be the ones to look at this.\n. A bunch, but not all, builds failed with this: Error generating manifest file: Manifest merger failed with multiple errors, see logs.  Unfortunately, I don't see anything in the logs that gives me more details, so it's a bit difficult to tell what's wrong here.. @bhamiltoncx's favorite kind of bug.  I suspect we need to use Unicode strings throughout our python code to make this work.. Of course cb7da2cb43ce64e407389a6941629bde2030f966 just landed as I put this up.... The second pound sign in the target shouldn't be there.  My guess is that somewhere the project generation isn't merging flavors properly.  I'm guessing that buck build --show-output --report-absolute-paths //StaticLib:StaticLib#iphonesimulator-x86_64,static,dwarf-and-dsym,iphonesimulator-i386,iphonesimulator-x86_64 will work.. The second pound sign in the target shouldn't be there.  My guess is that somewhere the project generation isn't merging flavors properly.  I'm guessing that buck build --show-output --report-absolute-paths //StaticLib:StaticLib#iphonesimulator-x86_64,static,dwarf-and-dsym,iphonesimulator-i386,iphonesimulator-x86_64 will work.. I really don't know Buck's Apple stuff very well.  @ryu2 or @Coneko might be able to answer your question.. @davido, once this lands feel free to add a PR for Gerrit here.  I wanted to populate this with something other than Facebook apps to start with, and these three people were around to ask :). cc @AnthonyUccello in case you want to add PumpUp. What are the contents of /usr/local/Cellar/android-sdk/24.1.1_1?. No problem.  My usual trick is to ls $ANDROID_SDK and that will fail if it's the wrong path :). Yeah, I understand.  Do you mind if I sit on this over the weekend to figure out a way to accommodate your use case as well as more single-app places?. Okay, I've thought it over and talked to some others.  I think we have a decent plan forward here, but I won't have time until tomorrow to actually implement the changes to make this work.  After that, you can rebase and adjust and continue to add apps under your section if you'd like :). My plans for the week got a bit derailed.  We got a lot of rain recently, and water appeared in our basement, so I've had to take some time off to deal with that.  I'll get to it as soon as I can!. @darkforestzero I've uploaded a PR that should land today that will let you rebase and be unblocked :D. @darkforestzero I've uploaded a PR that should land today that will let you rebase and be unblocked :D. @darkforestzero ping?. You'd need to take a dependency on the appropriate jars by either vendoring them in or using a prebuilt_java_libarary rule wrapping a remote_file rule.\n\nhttps://developer.android.com/studio/build/dependencies.html#view_the_dependency_tree shows an example dependency tree as a result; you'd need to specify this with Buck.. You'd need to take a dependency on the appropriate jars by either vendoring them in or using a prebuilt_java_libarary rule wrapping a remote_file rule.\nhttps://developer.android.com/studio/build/dependencies.html#view_the_dependency_tree shows an example dependency tree as a result; you'd need to specify this with Buck.. Oh hey, that's documented!  https://buckbuild.com/rule/android_binary.html#includes_vector_drawables. Oh hey, that's documented!  https://buckbuild.com/rule/android_binary.html#includes_vector_drawables. That looks like PEX code which is part of twitter-commons.. That looks like PEX code which is part of twitter-commons.. You should be able to already do this with remote_file rules and genrule to do the unzipping for you (or write some python to work cross-platform).. You should be able to already do this with remote_file rules and genrule to do the unzipping for you (or write some python to work cross-platform).. You could write specific genrules to unpack and then reference in other rules, but there's nothing general.  This would be a pretty big change in Buck since it'd require a second stage of parsing.. You could write specific genrules to unpack and then reference in other rules, but there's nothing general.  This would be a pretty big change in Buck since it'd require a second stage of parsing.. I don't believe gradle runs dx in-process like Buck does.\n. I don't believe gradle runs dx in-process like Buck does.\n. @bhamiltoncx, was this a known limitation of the watchman glob?. @bhamiltoncx, was this a known limitation of the watchman glob?. In the past, I've pulled tests out to run serially that were causing \nproblems like this (via run_tests__separately IIRC).\n. ndk_library is there for compatibly reasons.  It's how Buck used to suggest doing native code for Android, but these days folks should be using cxx_library instead.. cxx_library, like java_library and android_library, requires one to specify the sources, etc.  If one wants to invoke cmake, one should probably use a genrule.\nI strongly suspect the team will choose to not fix this.. @andrewjcg mentioned doing a build definition approach here: https://github.com/facebook/buck/commit/5f1432e502f9a04db08361f8b5c565b8048dd8b6#commitcomment-18220864\nI think @philipjameson is working on open sourcing this as part of another project.. @andrewjcg mentioned doing a build definition approach here: https://github.com/facebook/buck/commit/5f1432e502f9a04db08361f8b5c565b8048dd8b6#commitcomment-18220864\nI think @philipjameson is working on open sourcing this as part of another project.. This was a little broken, so I just put up https://github.com/facebook/buck/pull/1248. cc @darkforestzero as an FYI. @darkforestzero, the problem with linking on your server is that you have no SSL configured, and Buck's documentation pages all use SLL, so end users will get a mixed-content warning if we use images elsewhere.\nAs for resolution; we can use a higher resolution image pretty trivially by changing the URL parameters (I believe; I haven't actually checked the DPI), but we're trying to keep image size down as well so this page doesn't take an eternity to load.\nAs for local testing, see the test plan in this change (there's a unix script named very similarly in the same folder).. I'm going to land this as-is, @darkforestzero, so we can have a non-broken page.  Why don't you put up a PR with your suggested changes once this lands and we'll figure out the best path forward :). We should clean up the docs to specify python2.  @JoelMarcey can probably help with that.. Buck doesn't currently support native code compilation on Windows.. \"merge\" means someone actually used the merge button in the GitHub UI. \nThat will never happen with this project, so PRs always show up as \"closed\".\n. It looks like @aiked has been doing those for Buck.. @alanzeino - the CI failures appear to be because of this change (doc-related test failures).. Make sure you load the page in your browser (the readme under docs has instructions on how to test these changes).. Make sure you load the page in your browser (the readme under docs has instructions on how to test these changes).. I think the last time we did this we just relied on tests and hoped for \nthe best.  Not the best, but we do have decent test coverage.\n. I think the last time we did this we just relied on tests and hoped for \nthe best.  Not the best, but we do have decent test coverage.\n. Oh man, this is sweet!. Did you build it with ant first?  Although, that error message seems to imply that programs/buck.py in the repository doesn't exist, and it should if you have a clean git working copy.. Wow, that's subtle!  Good find!\n. I don't think this actually helped: https://ci.appveyor.com/project/Facebook/buck/build/1.0.3860. I've filed a support ticket since this is also impacting facebook/flow: http://help.appveyor.com/discussions/problems/6848-webhooks-failing-due-to-rate-limits-causing-specify-a-project-or-solution-file-the-directory-does-not-contain-a-project-or-solution-file. cc @andrewjcg. This used to work, even with NDK stuff.  If it's not working anymore, \nthat'd be a regression.\n. It doesn't look like this is passing travis.  Do we need to make changes to Buck?. It will never be automatic for Buck.  One of the core principles of Buck is build reproduciblity, which means you need to know that the bits you download from the Internet are what you expect them to be (hence the sha1) and how to get it (hence the url).. I'm just going to assume @dreiss or @bertmaher should be the ones to look at this.. Last time I tried this, building the PEX on one platform worked on all \nplatforms.  I'm not sure if Buck has shifted to a model where there is \nnative code, but if not, this might be easy to produce a PEX and upload \nthat in addition to the steps we do for macOS.\n. Facebook also uses cells pretty heavily now as part of BuckIt (using it for what @shs96c original meant it for), so @asp2insp, I suggest chatting with @philipjameson :D. A poorly documented experimental thing, but it should let us start to \nbuild with Buck in more of our open source projects: \nhttps://github.com/facebookexperimental/buckit/\n. I'm guessing we don't have the right dependencies installed there.\n. Wow.  That is broken I think.  @ilya-klyuchnikov might know what's up with that.. Did you see https://buckbuild.com/rule/remote_file.html?\n. You need to list all of your dependencies and their dependencies, etc. \nThat's just how Buck works.\n. You need to list all of your dependencies and their dependencies, etc. \nThat's just how Buck works.\n. Option five (eww about four): rename your BUCK files to something else and set this to something different: https://buckbuild.com/concept/buckconfig.html#buildfile.name. Option five (eww about four): rename your BUCK files to something else and set this to something different: https://buckbuild.com/concept/buckconfig.html#buildfile.name. If I had to guess, Buck isn't using the ExecutableFinder properly in NdkCxxPlatforms.. If I had to guess, Buck isn't using the ExecutableFinder properly in NdkCxxPlatforms.. Done.\n. Isn't this like cxx_library in that we don't build anything because we \ndon't know the target platform?  If that's true, you include this in a \nbinary, it should build.\n. Isn't this like cxx_library in that we don't build anything because we \ndon't know the target platform?  If that's true, you include this in a \nbinary, it should build.\n. Buck requires you to declare your dependencies and sources.  If you want \nlog.rs to be part of the crate, you need to include it in your srcs. \n  If it's meant to be something you need to depend on, you need to \nensure you have a rust_library that you add to your deps that \nincludes it as a source.\nI don't know how the rust stuff interacts with the apple rules, but I \nwouldn't be surprised if it's untested, and therefore doesn't work.\n. Buck requires you to declare your dependencies and sources.  If you want \nlog.rs to be part of the crate, you need to include it in your srcs. \n  If it's meant to be something you need to depend on, you need to \nensure you have a rust_library that you add to your deps that \nincludes it as a source.\nI don't know how the rust stuff interacts with the apple rules, but I \nwouldn't be surprised if it's untested, and therefore doesn't work.\n. I'll have to defer to @jsgf on this.  It's been a while since I've \nlooked at Buck's rust support.\n. I'll have to defer to @jsgf on this.  It's been a while since I've \nlooked at Buck's rust support.\n. Buck has historically not documented things that are not stable or the \nproject isn't sure it won't likely change in the future.  Basically, if \nit's not documented, you can use it, but the API may change in the future.\n. Why this change over using remote_file?. If that's true, the target sdk version isn't in the rule key, which \nwould cause it to be a cache hit and not get rebuilt.  I would be \nsurprised if that's intended, but I don't know Buck's iOS support very well.\n. cc @ilya-klyuchnikov who landed that. I'm going to close this since we all seem to think that @bgertzfield has fixed this.  If you want to add a test to make sure we don't regress it, we'll happily take it!\n. It should.  By the time the androidBinaryRule has run, all of its deps should have run, which means this Path should exist.\n. If yes, an integration test would be great.  If not, we should raise a HumanReadableException if that is what we are given.\n. I think you could replace both of these constructors that just take an AndroidBinary, right?\n. This line is over 100 characters (can be spotted with ant lint).  Can you please fix that?\n. @Coneko left this comment on our internal tracker but forgot to put it here so you can address it.\nThe TargetGraph from here should be used to generate the project as well instead of creating a new one using the targets below.\n. nit: this line is now too long and fails ant lint\n. These were the last two uses of assertTrue, so ant lint fails here.\n. Should this only be android_resource deps like we filter out javaDeps above?\n. I'd be fine with this being inline below\n. With that said, this undoes an optimization @natthu did to require first-order deps for android resources.  The issue you are trying to address is the last part of #328 that I haven't gotten to yet, and it's tricky.\nI think the right way to do this is in AndroidLibraryGraphEnhancer.getBuildableForAndroidResources, look for any AARs as a dep, and then add the aar_android_resource flavor as a dep and all of its deps (because those should be considered as exported deps) so it actually gets packaged.  That should then package up what you need to prevent that compiler error you were seeing.\n. It occurred to me this morning that you'll also need to hook up any deps that are android_resource rules to the android_resource of the AAR (including reach inside any other AARs).  The easiest way to do that is likely to expose it on AndroidPrebuiltAAR.\n. Let's take a AndroidLibraryGraphEnhancer.ResourceDependencyMode instead of a boolean here\n. You don't need to fix this unless @natthu has any suggested changes, but this is unused.\n. Well, I really just need to get some decent CI up here so machines can tell us when it's broken :)\n. You have an get() call without checking presence.  I did this instead:\ndiff\n-  .get();\n+  .orNull();\nAnd then...\n. diff\n+ .filter(Predicates.notNull())\n. Today I learned this was valid in Python.  Fancy.\n. This should also be annotated with @Nullable.  Infer caught this internally.\n. @natthu spotted that we don't make sure these are available with top-down-building (the default).  I've got a fix locally, but @natthu wants to try to fix something in the graph enhancement that will make my fix less awful, I think.  We should be able to get this in real soon.\n. This is a compilation error since directory must be null when you reference it the second time (after the &&)\n. You have an ant lint error here because you don't use result.  I'll clean this up before landing.\n. Hmm, actually, I'm not sure what you wanted to happen here.  That set appears to be empty, which I don't think is the right behavior.\n. Also, this doesn't compile.  On line 411 below we have int result, which introduces a duplicate variable name.\n. Fun fact: with this, and the change below, we now have an unused import of this class which fails ant lint.\n. I should have said that I fixed it locally; it should go out later today.\nOur internal CI roughly does this to verify: ant clean default lint && ./bin/buck build buck && ./bin/buck test\n. It's okay; we don't have great docs on this and we had to stop using Travis because we'd just get OOMs in random places of the build/setup.  Normally I try to fix things up on my own, but I've been a bit swamped today.\n. I guess writing a test for this would be rather difficult, wouldn't it?\n. Why are we using the $ here and not below?\n. Yeah; pick something for this change, and then do another PR to clean it up?\n. Nice, but unrelated to this change.  Want to pull it out?\n. This is no longer Nullable\n. You hate Windows, don't you? :P\n. This shouldn't be Nullable\n. No need to merge.  I can squash later.\n\nFrom: Miguel Oliveiramailto:notifications@github.com\nSent: \u200e10/\u200e1/\u200e2015 4:09\nTo: facebook/buckmailto:buck@noreply.github.com\nCc: Shawn Wilshermailto:sdwilsh@fb.com\nSubject: Re: [buck] Add dot parameter description to buck query docs. (#431)\nIn docs/command/query.soyhttps://github.com/facebook/buck/pull/431#discussion_r40901955:\n\n{literal}\n-buck query \"allpaths(//foo:bar, //foo/bar/lib:baz)\" --dot > result.dot\n-dot -Tpng result.dot -o image.png\n+$ buck query \"allpaths(//foo:bar, //foo/bar/lib:baz)\" --dot > result.dot\n+$ dot -Tpng result.dot -o image.png\n\nSorry for the delay. I added the $ below.\nIt's my first upstream PR. I had some conflicts and ended up with 5 commits. Do I need to merge them into one?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/pull/431/files#r40901955.\n. That would probably be best.\n. Don't we need to remove this file when we start a build in case it fails?\n. (see the HasTests interface for those)\n. I don't think you have to worry about that.\n. You aren't using this import (flagged by ant lint).\n. It would be prefered if you did this in the .travis.yml file where we also setup Android: https://github.com/facebook/buck/blob/master/.travis.yml#L18\n. This did not work as expected (the build failed with both of these failing).  Based on the help text, I think you can just pass these both like so: --test-selectors '!GoBinaryIntegrationTest' '!GoTestIntegrationTest'\n. Alternatively, we can just add a new file like scripts/travisci_test_filters.txt and have one test per line on there and pass --test-selectors @scripts/travisci_test_filters.txt here.\n. I think the first option is best.  We cannot rely on /usr/bin/env since that doesn't exist on Windows.  I'll let you do that in a follow-up, and we'll be sure to get it in quick so we don't have to worry about merge hell.\n. We need to only run when the android sdk is present.  I'll add the appropriate assume statement here.\n. We should use splitlines instead of split here so this works on Windows too.\n. ...and this isn't Python, so we'll just have to make the Java smarter.\n. Can you add a test for Windows-style newlines as well please?\n. We generally prefer assertThat with a Matcher as the test below the two new ones you've added.\n. I should have flagged that in your last iteration, so let me import this and fix it up myself.\n. I realize this doesn't change the checked out files, but should we pass --dry-run here as well?  Not 100% clear to me from the man page.\n. I glossed right over the part about writing over the file.  That's what I get for looking at changes right when I get in :)\nThis is fine as-is.\n. What about adding some padding here and using both (in case the executable does hang)?\n. It would be better to use Optional.transform here which handles the absent case already.\n. Hmm, @shs96c is not going to be happy about having a util library.  What about putting this under a resources package instead?\n. Can you add the newline please :)\n. I don't think this TODO makes much sense anymore now that we've moved it, so feel free to nuke it.\n. one argument per line, please\n. I should have looked at the travis build.  This is an unused import, so ant lint fails.\n. @dreiss just pushed 7c2311282079c9e06117974b1d025b0079452d19 which conflicts with this, and I want to make sure that the end result should still be the same here.\n. lol\n. How would you feel about calling this JvmLibraryArg instead?  I can make that change before landing it, but @marcinkosiba  suggested it, and I think it is more clear and inline with how we name things.\n. We really should upstream some of this code one day...\n. nit: the formatting here is off.  filesystem.getAbsolutifier()); should be on a line after },.\n. I believe it works.\n. Do we not need to worry about removing this stuff if we aren't a zipfile?\n. I don't understand this comment, especially when looking at the code.  I realize that this is somewhat copypasta, but it should still make sense, and I don't think it does right now.\n. nit: 2016 now\n. nit: 2016\n. Two things:\n- This change looks spurious\n- We shouldn't be adding new uses of ProcessBuilder in the codebase.  You didn't do this here, but I'm letting you know.  We should be using ProcessExecutor or ListeningProcessExecutor instead.\n. Again, this isn't wrong in this diff since you just moved the code, but we shouldn't hardcode : here, but instead use File.pathSeparator so this works on Windows too.\n. otherwise?  It seems like some text might be missing here or it is misleading me how it is worded.\n. when you say \"all paths\", what do you mean?\n. nit: please use complete sentences, which means you need capital letters and punctuation at the end.\n. This also adds support for file, right?  Care to update the message and README.facebook to be more clear?\n. Yup.  I'm just blind.  I think I should stop reviewing code today :)\n. We totally should, but I'd rather spend that effort on getting Windows CI which would catch this in the first place (ProcessBuilder doesn't properly escape the arguments on Windows, so you might be okay, but you might also fail in a non-obvious way.  The other two classes work around that issue.)\n. Same as above; Windows CI would have caught this for us, and I'm not sure how to write a lint rule that would be context-aware enough to know when : is safe to use and when it isn't.\n. small nit (that I'd love if we could lint for): we keep the closing paren after args\n. nit: a tiny bit of a spurious change still :)\n. This logic might be a tiny bit clearer if you just did a return in the if block and afterwards had the common case.\n. If you can figure that out, and it's something we can check into the project, we'd take a PR for that :)\n. I would not mark this as frozen now.\n. {call buck.java_library /}\n. {call buck.java_library /}\n. {call buck.java_library /}\n. {call buck.java_library /}\n. {call buck.java_library /}\n. {call buck.java_library /}\n. {call buck.java_library /}\n. {call buck.java_library /}\n. It's better to do <p> before each example and have each one in its own box, IMO\n. We can actually avoid this path entirely if we just modify the code in src/com/facebook/buck/python/make_pex.py to prefer to copy on Windows.  I had originally wrote something like this, but @andrewjcg suggested changing Buck's code so it was fewer changes to PEX itself.\n. I'll have to try this when I get into the office, but when I was using something like, this, I was getting an exception with the call to remove because the subprocess call hadn't finished closing it yet.\n. Good find.  I wasn't familiar with this issues, and I'm curious how you came across it; care to elaborate here (just on Github; the code is fine as-is).\n. I missed this last time, but you don't need to use the raw_example macro here.  Just do {param example_value: '/path/to/groovy_home /} and put it above the description.  See the section above you for an example.\n. You only need one newline here :)\n. Use {call buck.java_library /} here when mentioning java_library please\n. Use {call buck.java_library /} here when mentioning java_library please\n. Can you plop this on top of the description please to be consistent with the rest of the file? :)\n. You rock!\n. please remove this TODO\n. this seems like a spurious change.  Can you please revert it back to how it was please?\n. spurious change\n. why don't we call this absoluteClassPath instead to make it more clear?\n. It is 2016 now!\n. 2016!\n. That's a little bit terrifying.  I wonder if this would also help fix https://github.com/facebook/buck/issues/638\n. also cc @bhamiltoncx \n. We actually do jdk8 now for Travis, so we should do the same for Windows.\n. I guess this misses all the android stuff too, but it's better than nothing.  We can go in and add more things to this as needed.\n. I actually made the changes recently to allow Buck to be built on Linux and be usable on Windows (and I suspect OS X).  I didn't test the other way around, however!\n. Hmm, if we used an ExectuableFinder, it would do this for us (and also handle the case where someone may have wrapped it in a .bat or some other script first).\n. sigh\nThis one hits home.\n. That's a bummer, but I'd prefer if we kept to java8 since that's what we are testing elsewhere (and there are differences).\n. ExecutableFinder's constructor lets you pass in the env, so if you know where it should be, you can do something like this:\ntoolPath = new ExecutableFinder().getOptionalExectuable(\n    Paths.get(toolname),\n    goToolDirSupplier.get());\nThis has the added advantage of making sure it's executable on unix systems.  But I also agree that all this can be done in a different PR.\n. groan\nThat has to be a bug.  I can't imagine any reason why we'd want to do that.\n. Note that argparse is python2.7+, and Buck supports python2.6+.  If we did this, we'd have to import the package for 2.6.\n. no need for the space after {sp}\n. I wouldn't bother with this comment; the name implies this.\n. nit: use assertThat(result, Matchers.equals(\"cake\"));\n. you don't need the space after {sp}.\n. ant lint fails here because the line is too long.  Travis would have told you this if Travis was working properly...\n. I think you need to add a dep for this.  buck build //test/com/facebook/buck/android: should reproduce a build failure here.\n. You'll need to add the traditional copyright header to this file.\n. I /think/ the Buck project is trying to standardize on Jackson, but @Coneko would know for sure.\n. It's not clear from this if it's meant to be Buck's root or the project's Buck root (as in where the .buckconfig lives)\n. If we're using args4j, it'd be better to just support @ files here unless there's a lot of value in supporting JSON.\n. The help text doesn't make that clear to me then :)\n. 2016, not 2012 :)\n. 2016, BTW\n. I missed this before; why do you have a - before each of the words?\n. \n. 2016\n. In the build files, we use a buildr format, so you'd have the artifact type before the version.  Why did you decide to drop that here?\n. Note: you can use the {literal} tag here to use actual < and > so this is more readable\n. There are actually a variety of ways to set the NDK.  However, it would be best for you to link to https://buckbuild.com/setup/install.html\nAlso, a nit, but you should indent inside the <p></p> one level.\n. I didn't spot this before because the line was so long :)\nInstead of adding the space inside the <code /> tag, you should put {sp} before it (or at the line before it if there is space).\n. likewise here.  Use {sp} instead of artificially padding what text the link has.\n. Can you add docs for this so others can also know how to use ButterKnife with Buck?\n. Some people don't like to pass in passwords on the command line (it shows up in history).  Is there a way to provide an option to prompt for it too (I'm not sure if buckd is going to rain heavily on this idea).\n. I just imported it so he should have some results when he gets in that he can look at.. This should have been done when Groovy was added too, but can you add a comment above this?  The native code tests comment above applies to the libraries above this, but not this one you are adding.. Notably, this is why I think assertThat is better (plus it gives better error messages).  I thought the team was encouraging the use of that instead?. We should probably remove these files if we aren't going to need them anymore.. @felipecsl, do you have a blog post you'd want to link to?. @kageiit, do you have a blog post you'd like to link to?. @marcinkwiatkowski, do you have a blog post you'd want to link to?. You now know where to add one when you have one!. I'm trying to limit this to just one (although we should start sharing more stuff on our Facebook Page and Twitter account).  If you could only pick one, which would it be?. I'm going to push an update that supports multiple entries, but I'm going to hold off on adding anything for Uber for now.. I'd do this instead:\nvar isMac = navigator.platform.toLowerCase().indexOf('mac') !== -1;\nvar isWindows = navigator.platform.toLowerCase().indexOf('win') !== -1;. Globally, we should avoid using <br />.  Instead, wrap each paragraph in <p></p>.. cc @bolinfest for autodeps stuff. You should actually have used {call buck.prebuilt_cxx_library /} here.. We serve our pages over SSL, and having a non-SSL image url will break that and show mixed content warnings.  This is why the Facebook stuff references images from the play store instead of some other random place.  Can you please find an SSL-served image?. ditto. ditto. ditto. Travis failure is because you didn't close out the {param} for the .item here (and below).. You can use the 100 wide image like the others so it's less of a download for folks (here and below). You should link to this (even if it's directly below it today, a link will always work even if code moves away).  We have a macro to construct links to config entries.. link to it. link to it. link to it. You should link to the actual src_roots section to make it easier for end-users to find.. likewise. Which setting do the extra arguments come from?. does this make sense?  Does kotlin even use prebuilt_jars?. Please don't add a link link this.  Add a new entry in __common.soy file, and then just replace this link with {call buck.kotlin_library /}.. It would be easier for the end user if you had the text here.  You can create a new __kotlin_common.soy file and put common arguments in there and just call the templates.. ditto. We don't usually mark new rules as frozen since we might be changing them as we flesh them out.. We don't usually mark new rules as frozen since we might be changing them as we flesh them out.. There's already __jvm_common.soy that would be a good place to pull some of the common stuff out.. Does this actually render correctly?  Soy usually has issues if you have braces, and you have to tend to use {lb} and {rb}.. {call buckconfig.kotlin_kotlinc /}. Care to link to https://kotlinlang.org/ here?. It would be best here to do a {call jvm_common.provided_deps} here, like we do in java_library.soy.  I suspect, but haven't verified, that we want this to apply for android_binary and not java_binary, which is what java_library says.. ",
    "jimpurbrick": "Thanks for this. I've seen Jython being a significant win for big projects, but I've just timed buck build buck again before and after Jython and seen a slowdown, so I'll see if I can reduce the overhead.\n. Using buckd should significantly reduce latency of all buck commands and dramatically reduce the duration of no-op incremental builds of complex projects as build files are cached between builds.\n. f158d62 has a buck_common script which isn't MOE scrubbed, which is why it's using the internal buck-{bin.gen} directories. CleanCommand.java in that commit is correctly scrubbed, which is why clean isn't removing buck-{bin,gen}. I fixed the export scripts to properly scrub the new buck_common and buckd scripts last night, so if you use any of the commits exported yesterday you should see the old buck-out/gen behaviour and clean working properly. Alternatively manually removing the MOE block from buck_common in f158d62 should fix it for you.\n. What does your .buckd/buckd.log say?\n. I think this was a problem with the new Python scripts which has been fixed\nand should be pushed soon.\nI agree that supporting normal daemon command syntax would be nice, but\nbuckd --kill should always do what you need.\nOn 25 July 2014 10:09, Matt Read notifications@github.com wrote:\n\nbuckd -kill appears to unwedge when that happens, my guess is nailgun has\ndied but not cleaned up the pid.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/166#issuecomment-50177489.\n. IIRC the maximum latency I was seeing from watchman was <20ms. I was unable\nto save a file, exit emacs and rerun buck without the change being seen\nwhen testing Buck with watchman, so it should work for your intellij\nscenario. The only situation where watchman might be too slow is if some\nscript was changing files and then immediately running buck, but our\nautomation scripts generally check out a specific revision and then build\nit with a fresh Buck daemon, so it isn't an issue for us.\n\nOn 1 August 2014 03:08, Matt Read notifications@github.com wrote:\n\n@bolinfest https://github.com/bolinfest That's useful to know, thanks.\nDo you have measurements for the latency you're seeing with watchman? I\nthink we're going to have to dig deep into this as the team are alt-tabbing\naway from intellij and running a buck build expecting it to see their\nchanges immediately. I'm still suspicious that the --ignore-paths aren't\nbeing correctly configured in watchman (as well as the initial tree walk)\nwhich could be exacerbating the problem. Any insight would be very helpful!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/pull/167#issuecomment-50868863.\n. There are inotify and file descriptor config suggestions in the watchman\nsetup documentation https://facebook.github.io/watchman/docs/install.html\n\nWhen using watchman with automation it's important to always delete watches\nwhen you're done with a directory to avoid exhausting the OS resources.\nOn 1 August 2014 08:52, Matt Read notifications@github.com wrote:\n\nA higher, lower or about the same would probably give me enough to think\nabout for now - we're at about 40,000 here, or perhaps 90,000 if the ignore\npaths aren't working.\nWe're linux (fc20). I've checked the inotify watch limit to make sure it's\nok and we don't seem to have problems there - it fails very explicitly when\nthat's set too low.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/pull/167#issuecomment-50900733.\n. There are inotify and file descriptor config suggestions in the watchman\nsetup documentation https://facebook.github.io/watchman/docs/install.html\n\nWhen using watchman with automation it's important to always delete watches\nwhen you're done with a directory to avoid exhausting the OS resources.\nOn 1 August 2014 08:52, Matt Read notifications@github.com wrote:\n\nA higher, lower or about the same would probably give me enough to think\nabout for now - we're at about 40,000 here, or perhaps 90,000 if the ignore\npaths aren't working.\nWe're linux (fc20). I've checked the inotify watch limit to make sure it's\nok and we don't seem to have problems there - it fails very explicitly when\nthat's set too low.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/pull/167#issuecomment-50900733.\n. Do you currently have a .watchmanconfig in your project root? It should contain at least an ignore_dirs setting which excludes output directories from the set of directories being watched:\n  {\n    \"ignore_dirs\": [\n    \"buck-out\",\n    \"buck-cache\",\n    \".buckd\" ]\n  }. We're currently working on a way to avoid the need for this file, but it should help you out in the meantime.\n. Do you currently have a .watchmanconfig in your project root? It should contain at least an ignore_dirs setting which excludes output directories from the set of directories being watched:\n  {\n    \"ignore_dirs\": [\n    \"buck-out\",\n    \"buck-cache\",\n    \".buckd\" ]\n  }. We're currently working on a way to avoid the need for this file, but it should help you out in the meantime.\n. Glad to hear that you're seeing the benefits now. We have work in progress that should avoid the need for .watchmanconfig so hopefully won't need to add documentation for that, but I think we should make sure we point people to the watchman system preparation documentation, so I'll look in to that.\n. Glad to hear that you're seeing the benefits now. We have work in progress that should avoid the need for .watchmanconfig so hopefully won't need to add documentation for that, but I think we should make sure we point people to the watchman system preparation documentation, so I'll look in to that.\n. The temp_files setting (http://facebook.github.io/buck/concept/buckconfig.html) should stop changes to temporary files causing reevaluation of build files. We're currently looking at making Watchman ignore changes to these files too.\n. The temp_files setting (http://facebook.github.io/buck/concept/buckconfig.html) should stop changes to temporary files causing reevaluation of build files. We're currently looking at making Watchman ignore changes to these files too.\n. \n",
    "Coneko": "@spearce That might not work because buckd caches the build files in memory.\nHas that not been a problem?\n. @spearce That might not work because buckd caches the build files in memory.\nHas that not been a problem?\n. genfile doesn't even exist anymore.\n. genfile doesn't even exist anymore.\n. Thanks for the report, this has been fixed, Buck will now create an empty R.txt.\n. It works now.\nI tested it by adding throw new NoClassDefFoundError(); to test/com/facebook/buck/ddplist/DdPlistTest.java.\nThe xml file gets created both in buck-out without --xml and wherever --xml specifies with it.\nLet us know if this is still an issue.\n. I'll cc @shs96c and @ryandm since I have no idea about maven.\n. These are now available:\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/JavaLibraryDescription.java#L329\nThey're still undocumented though.\n. cc @jkeljo . cc @jkeljo . I think it was by adding jUnit assumptions so that the tests would be ignored if you didn't have the prerequisites?\n. This should be fixed now.\n. This should be fixed now.\n. @davido: I've opened a new issue for that: #239\nI think this one can be closed now that GWT rules are in.\n. @davido: I've opened a new issue for that: #239\nI think this one can be closed now that GWT rules are in.\n. Support for power shell is improving. We can now run Buck's tests! Most of them still fail though.\n. Windows support is not finished yet but it's now at the point where we can file issues for specific bugs and features with it.\n. You'd have to check out the remote repo locally, maybe as a submodule or something like that.\n. You'd have to check out the remote repo locally, maybe as a submodule or something like that.\n. We're still planning on adding it, we just decided we are better off rewriting it from scratch.\n. We have this now with android_aar and android_prebuilt_aar.\n. We recently added build target pattern support from the command line, so specifying relative build and test targets would be even more confusing.\nWe're going to leave it be.\n. I suppose we never documented it, but I think that is how it's determined in the code.\nThis issue is about CWD relative targets.\nOpen a new one for targets relative to the current build file.\n. Did that work? Can this be closed now?\n. Did that work? Can this be closed now?\n. I think it's not supposed to have ...:..., but just ....\nThe extra ... is probably because of this:\n\nFinally, if the final path element matches the value specified after the colon, it can be omitted from the command line:\n```\nThis is treated as //java/com/facebook/share:share.\nbuck build java/com/facebook/share/\n```\n. I think I figured it out: the docs say:\nA build target pattern is a string that describes a set of one or more build targets to match. These are used in the list of strings passed to the visibility argument of a build rule.\n\nSo I think the patterns are only supported there, and not on the command line. The error message could be a bit clearer about that though.\n. @bolinfest But only build target patterns can end in ... and : right?\n. Have you solved this issue? Can we close this now?\n. Have you solved this issue? Can we close this now?\n. I'm closing this as the issue has been resolved.\nFollow ups are:\n172 to print warnings when the inotify limits are too low.\n330 to remove the need for users to configure .watchmanconfig.\n. Buck just prints out what watchman prints out, you should file an issue in https://github.com/facebook/watchman/ .\n. Thanks for catching this issue!\nThe root of the problem seems to be at https://github.com/facebook/buck/blob/master/src/com/facebook/buck/cli/GenericBuckOptions.java#L115:\njava\n  private int execute() throws IOException {\n    if (showHelpScreen()) {\n      return SHOW_MAIN_HELP_SCREEN_EXIT_CODE;\n    } else if (showVersion()) {\n      stdOut.println(\"buck version \" + getBuckVersion());\n      return 0;\n    }\n    return SHOW_MAIN_HELP_SCREEN_EXIT_CODE;\n  }\nGenericBuckOptions#execute() returns the same exit code when it's called with --help and when it's called with an option it doesn't know about!\n. Thanks for catching this issue!\nThe root of the problem seems to be at https://github.com/facebook/buck/blob/master/src/com/facebook/buck/cli/GenericBuckOptions.java#L115:\njava\n  private int execute() throws IOException {\n    if (showHelpScreen()) {\n      return SHOW_MAIN_HELP_SCREEN_EXIT_CODE;\n    } else if (showVersion()) {\n      stdOut.println(\"buck version \" + getBuckVersion());\n      return 0;\n    }\n    return SHOW_MAIN_HELP_SCREEN_EXIT_CODE;\n  }\nGenericBuckOptions#execute() returns the same exit code when it's called with --help and when it's called with an option it doesn't know about!\n. This is the correct link:\nhttps://facebook.github.io/watchman/docs/troubleshooting.html#poison-inotify-add-watch\nCan you check the permissions on those files?\nCould it be buck is trying to get watchman to watch a file on which it does not have read permission?\ncc @wez\n. Closing, the commits @sdwilsh mentions should have fixed this.\nLet us know if it happens again.\n. Could you give more information about what you're trying to do and what issues you're hitting?\nIs buck's output not being interpreted correctly by your terminal?\nAre you trying to use buck's output from a script?\n. I'm not familiar with how the IntelliJ project generation works, so I don't quite understand the issue.\nShould it show directories that aren't referenced in a project_config rule? If yes, what is the difference between a module referenced by a project_config rule and one that isn't?\n. I'm not familiar with how the IntelliJ project generation works, so I don't quite understand the issue.\nShould it show directories that aren't referenced in a project_config rule? If yes, what is the difference between a module referenced by a project_config rule and one that isn't?\n. I understand now, thanks for explaining.\n@bolinfest do you know what could be the issue? The change I made @mread linked to removed the assumption that project_config rules were always defined in the same BUCK file as the rules they referenced, and looked for them anywhere in the repo.\n. I understand now, thanks for explaining.\n@bolinfest do you know what could be the issue? The change I made @mread linked to removed the assumption that project_config rules were always defined in the same BUCK file as the rules they referenced, and looked for them anywhere in the repo.\n. So the issue is not that buck project now excludes certain directories, it's that it used to include directories it wasn't supposed to in the first place?\n\nFor us this is slightly more than annoying - we can't have a workspace for which source files are not editable.\n\nI agree. Are there source files you cannot edit from the workspace that are included in any declared dependency?\nThe example you gave involved prebuild_jar, and not rules with sources: should Buck consider those as sources in the context of project generation? Can you interact in any meaningful way with prebuilt jars within IntelliJ?\nSorry for questions that might be trivial, but I have no idea how IntelliJ is supposed to be used, or how a correctly set up IntelliJ project would look like.\n. So the issue is not that buck project now excludes certain directories, it's that it used to include directories it wasn't supposed to in the first place?\n\nFor us this is slightly more than annoying - we can't have a workspace for which source files are not editable.\n\nI agree. Are there source files you cannot edit from the workspace that are included in any declared dependency?\nThe example you gave involved prebuild_jar, and not rules with sources: should Buck consider those as sources in the context of project generation? Can you interact in any meaningful way with prebuilt jars within IntelliJ?\nSorry for questions that might be trivial, but I have no idea how IntelliJ is supposed to be used, or how a correctly set up IntelliJ project would look like.\n. Have you tried using Buck in powershell? We're working on support for that rather than cygwin. Does Gerrit need other tools that are only available in cygwin on windows?\n. Have you tried using Buck in powershell? We're working on support for that rather than cygwin. Does Gerrit need other tools that are only available in cygwin on windows?\n. You can set the NO_BUCKD environment variable.\nI wouldn't suggest to put it in your shell config, as you would forget about it and then assume Buck was working as it should when it should be using buckd, but you can prepend it to commands to alias them.\n. You can set the NO_BUCKD environment variable.\nI wouldn't suggest to put it in your shell config, as you would forget about it and then assume Buck was working as it should when it should be using buckd, but you can prepend it to commands to alias them.\n. Thanks @davido!\n@dborowitz: Thanks for the feature request. As mentioned, #102 tracks it. You can subscribe to notifications to that issue so you know when we have updates about it.\nIf you have any other suggestions about it feel free to comment on that issue.\n. Thanks @davido!\n@dborowitz: Thanks for the feature request. As mentioned, #102 tracks it. You can subscribe to notifications to that issue so you know when we have updates about it.\nIf you have any other suggestions about it feel free to comment on that issue.\n. Sorry this slipped through the cracks. Are you still interested in merging this in? If so can you please merge from master?\n. Thanks, I've patched the PR locally and fixed some styling issues.\nIt would be nice if you could add an integration test. Have a look at the ones in ProjectIntegrationTest for examples.\nLet me know if you have trouble figuring out how the test data is supposed to be laid out.\nI will try to push out the style changes so you can merge them into the PR.\n. Thanks, I've patched the PR locally and fixed some styling issues.\nIt would be nice if you could add an integration test. Have a look at the ones in ProjectIntegrationTest for examples.\nLet me know if you have trouble figuring out how the test data is supposed to be laid out.\nI will try to push out the style changes so you can merge them into the PR.\n. I had to do some local changes to get everything to pass.\nWe run linters on CI, some of those failed.\nYou can run ant lint and ant verify-javadoc to run some of those locally.\nI'll try to get my changes merged and put up a branch with both sets of changes.\nThanks for keeping your PR updated, much appreciated!\n. This has been merged internally and will go out in the next push!\nThanks again for your patience!\n. Seems to work now, probably related to the issues we had with watchman when Buck was invoking it incorrectly.\nLet us know if it happens again.\n. What do you mean?\nWe have a plugin checked in in the meantime: https://github.com/facebook/buck/tree/master/src/com/facebook/buck/intellij/plugin\n. Do you have a particular use case in mind?\nIs the default file name conflicting with something in your repo?\nI can see how big open source projects that want to have configurations for multiple build systems might support Buck and Pants with the same files using an option like that.\n. It sounds reasonable enough to me. Would it be possible for you to submit a PR?\n. Yep, new method on BuckConfig is the way to go.\nOption two sounds great: I've just verified all the uses of BuckConstants#BUILD_RULES_FILE_NAME and they're either in contexts with more or less direct access to a BuckConfig or one of its wrappers, or they're using it to print error messages which can be modified to read \"build configuration file\" instead of \"BUCK file\".\nImport statements are arranged however IntelliJ does it.\n@bolinfest You use Eclipse, can you share your configurations for the Buck project?\nAs for the legal aspects the CLA (https://code.facebook.com/cla) should have most answers.\n. Oh that's too bad. I'll do it then.\n. It took a while longer than expected, but I've done this, it's going to be available next time we push to github.\n. Very nice, thank you!\nWe added support for remote files recently, but haven't documented it yet:\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/cli/FetchCommand.java\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/file/RemoteFileDescription.java\nThat will also help.\n. Very nice, thank you!\nWe added support for remote files recently, but haven't documented it yet:\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/cli/FetchCommand.java\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/file/RemoteFileDescription.java\nThat will also help.\n. Can you try running buckd to restart the Buck daemon and see if you still get the same error or a different one?\n. Can you try running buckd to restart the Buck daemon and see if you still get the same error or a different one?\n. Was this fixed?\n. Was this fixed?\n. buck project doesn't generate a misc.xml file, the first file you posted looks like a modules.xml.\n. This has come up before, but we decided against it, even though we support those kind of short hand build targets on the command line.\nThe reason is that unlike the command line, the build files are usually read many more times than they are written to, so it makes sense to optimise for readability.\n. Thanks! :baby_chick: \n. Thanks! :baby_chick: \n. genfile is out, genrule is here to stay.\n. You can define any constant you want in Python syntax in your build definition file, including lists of strings, then unpack them in the visibility argument.\n.buckconfig:\n[buildfile]\n  includes = //core/DEFS\ncore/DEFS:\nTEST_VISIBILITY = ['//test/tests/...', '//test/test-utils/...']\ntest/test-utils/mocking/BUCK:\n...\n  visibility = [TEST_VISIBILITY*, '//test/test-setup:mocking-setup']\n}\nOr something like that. Let me know if it doesn't work.\nMore information at:\nhttp://facebook.github.io/buck/concept/buckconfig.html#buildfile\n. You can define any constant you want in Python syntax in your build definition file, including lists of strings, then unpack them in the visibility argument.\n.buckconfig:\n[buildfile]\n  includes = //core/DEFS\ncore/DEFS:\nTEST_VISIBILITY = ['//test/tests/...', '//test/test-utils/...']\ntest/test-utils/mocking/BUCK:\n...\n  visibility = [TEST_VISIBILITY*, '//test/test-setup:mocking-setup']\n}\nOr something like that. Let me know if it doesn't work.\nMore information at:\nhttp://facebook.github.io/buck/concept/buckconfig.html#buildfile\n. cxx_library doesn't produce any output by default, you have to specify which output you want, and the platform to use, for example //lib/mylibrary:mylibrary#static,default for a static library built with the system platform or //lib/mylibrary:mylibrary#shared,android-arm for a shared library built with the android NDK platform.\n. cxx_library doesn't produce any output by default, you have to specify which output you want, and the platform to use, for example //lib/mylibrary:mylibrary#static,default for a static library built with the system platform or //lib/mylibrary:mylibrary#shared,android-arm for a shared library built with the android NDK platform.\n. Do you mean you set the soname in the BUCK file but the library overrides it when built that way?\n. Do you mean you set the soname in the BUCK file but the library overrides it when built that way?\n. Glad it all worked out. Yeah sorry the cxx stuff's documentation isn't completely accurate because it changes a lot constantly.\n. I think you need --no-results-cache for that.\n. I think you need --no-results-cache for that.\n. The cxx rules still haven't been finalised so the documentation isn't very complete, since everything could still change. I'll see if we can figure out at least some of settings.\n. The cxx rules still haven't been finalised so the documentation isn't very complete, since everything could still change. I'll see if we can figure out at least some of settings.\n. Can you try to install brew install watchman to install the stable version?\n. Can you try to install brew install watchman to install the stable version?\n. Have you tried rebooting your computer?\nWhat does watchman watch-list show?\n. Have you tried rebooting your computer?\nWhat does watchman watch-list show?\n. Is the error reproducible in the same way as #164? \"simply by running buck over and over without making any changes\"? Or is there a different way of reproducing it?\n. Thanks for pointing that out. Would martylamb/nailgun#49 fix it as well?\n. Thanks for pointing that out. Would martylamb/nailgun#49 fix it as well?\n. martylamb/nailgun#57 was merged, so I'm closing this out.\n@benhyland: Let us know if this issue still happens and if martylamb/nailgun#49 is necessary.\n. Confirmed, happens on Buck itself as well.\n. Confirmed, happens on Buck itself as well.\n. Thanks!\n. Thanks!\n. Thanks for the report, I'm fixing it now.\n. That's because the value of deps in that case is the value of deps specified in the target, not necessarily its dependencies.\nbuck audit dependencies --json should include all dependencies.\n. Thanks for spotting it and providing a repro. I'll be looking into this.\n. Oh dear.\nYes, the whole trailing slash situation was pretty messy, and the reason why so much stuff was being done with strings.\nWe have this logic for appending a trailing slash in AbstractUnflavoredBuildTarget already, so as you say it's a good idea to extract it into a method in MorePaths.\nWould you like to send a PR?\n. Yep! Thanks for the fix @mread, let us know if you bump into anything else.\n. You mean buck should allow you to specify in the cxx_library which type of output it should produce by default?\ncxx_library will already automatically select the right type of output depending on what depends on it.\n. Buck doesn't use header deps, so it's going to preprocess all the files any time any of the headers that can be included in them changes. It should then only recompile the post processed files that changed.\nDoes that match the behaviour you see?\n. Thanks!\nI've merged it internally, so it should go out soon.\n. That fixes the build by declaring a transitive dependency as a direct dependency, so it's not the correct fix.\n. That fixes the build by declaring a transitive dependency as a direct dependency, so it's not the correct fix.\n. Just to clarify @shs96c's comment, the maven importer will import a library, all its dependencies and setup all the prebuilt_jar and remote_file targets, including the shas for you, which is probably exactly what you're looking for.\n. I don't think the maven importer creates remove_file rules. There might be an option to run it again if you want to update the dependencies though. Or maybe it was a different flow.\nI'm sorry, @shs96c would know better.\n. I don't think the maven importer creates remove_file rules. There might be an option to run it again if you want to update the dependencies though. Or maybe it was a different flow.\nI'm sorry, @shs96c would know better.\n. Should be done by 99a728cf4c4b35380d48ab1e6603dc8fe28e5842 and 53f2b609d15abd56f4005293b59c7c343ff22ef7.\n. Unfortunately for big projects .watchmanconfig is still necessary: the way Buck passes the ignored directories when querying for changes doesn't prevent watchman from watching those changes in the first place, so while having it or not is functionally equivalent, performance wise it's a big difference.\n. This is going to be removed soon.\n. This is going to be removed soon.\n. We have logic in the parser to not use the in memory cache when symlinks are involved, but it only applies to input files, not to build files themselves.\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/parser/Parser.java#L1138-L1150\nThis is something we should fix in Buck.\n. You can set NO_BUCKD=1 as an environment variable to stop Buck from using watchman, then you won't need to uninstall it.\n. Yes, NO_BUCKD is correct, I edited the comment.\n. There is some metadata associated with each rule saved in buck-out, Buck always assumes the metadata and the built artefacts in buck-out are in a consistent state, so modifying the files in buck-out manually will break Buck in weird ways.\nWhy are you deleting the jar file? Is there a particular use case?\n. Unfortunately there isn't.\nbuck build --no-cache bar lets you ignore the buck-cache directory, but there is no way of ignoring the buck-out directory.\nBuck assumes all rules declare all their inputs and only depend on them. We're about to introduce more advanced caching that absolutely depends on this. Having side effects in rules will always cause problems for Buck.\n. I don't think that script is a good idea: what it's working around is not a design limitation as much as it's a design prerequisite.\nIf you need to do side effects together with the build it's better to do them at the end of the build, outside of Buck, rather than during the build inside the rule executions.\n. It either has to be implemented outside of Buck, or as a separate command.\nYou mention fetch_file, I assume that is the custom rule you implemented in python? Buck's is called remote_file, and only downloads artefacts when you run buck fetch, not during the build.\nI can see a buck publish command, that publishes some artefact to a remote repository.\nThere's also been some discussion of adding an attribute for maven coordinates on prebuilt_jar, or add a prebuilt_java_library with such an attribute, to better integrate fetching and building.\nIn that vein, you could add a maven coordinate to a java_library, and use the hypothetical buck publish command to publish it. It would build the library and publish it to maven or something, I don't know, just throwing darts at the board here.\nI think the main thing here is we absolutely do not want side effects during the build.\nWe can however introduce new operations that depend on building that have side effects. Or new operations that have side effects that have to be run manually before building, and whose effects must be controlled explicitly by the user, so that they can check the results into source control, or do anything they want with them.\nBut the build itself must remain pure.\n. You can run all buck project commands in a project created with buckbone, the two things won't interfere.\nYou cannot use buck quickstart with buckbone, but buck project is a different thing.\n. What terminal and shell are you running?\n. It should be possible by changing getTargetNodeSpecsForIde to take Collection<TargetNodeSpec> instead of Collection<BuildTarget> as parameter.\n. That genrule shouldn't be a problem: if the sources don't change it should not be executed.\nThe fact it outputs a zip with timestamps in it might be annoying for some flows, but it shouldn't be a big problem either.\n. c9f1cb6aeb381860dce101fe02eae0118d2a55c3 should have fixed the last issue.\n. This is what I get:\njson\n[\n    {\n        \"args\": [\n            \"/usr/bin/clang\",\n            \"-g\",\n            \"-std=c11\",\n            \"-fPIC\",\n            \"-g\",\n            \"-std=c11\",\n            \"-I\",\n            \"buck-out/gen/common/hello#default,private-headers.hmap\",\n            \"-I\",\n            \"buck-out/gen/common/hello#default,headers.hmap\",\n            \"-I\",\n            \"buck-out\",\n            \"-Xclang\",\n            \"-fdebug-compilation-dir\",\n            \"-Xclang\",\n            \"./////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\",\n            \"-x\",\n            \"c\",\n            \"-c\",\n            \"-MD\",\n            \"-MF\",\n            \"buck-out/gen/common/hello#compile-pic-hello.c.o,default/hello.c.o.dep.tmp\",\n            \"common/hello.c\",\n            \"-o\",\n            \"buck-out/gen/common/hello#compile-pic-hello.c.o,default/hello.c.o\"\n        ],\n        \"command\": \"/usr/bin/clang -g '-std=c11' -fPIC -g '-std=c11' -I buck-out/gen/common/hello#default,private-headers.hmap -I buck-out/gen/common/hello#default,headers.hmap -I buck-out -Xclang -fdebug-compilation-dir -Xclang .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// -x c -c -MD -MF buck-out/gen/common/hello#compile-pic-hello.c.o,default/hello.c.o.dep.tmp common/hello.c -o buck-out/gen/common/hello#compile-pic-hello.c.o,default/hello.c.o\",\n        \"directory\": \"/Users/coneko/github/fbsamples/bucksamples/cross-platform-scale-2015-demo/common\",\n        \"file\": \"/Users/coneko/github/fbsamples/bucksamples/cross-platform-scale-2015-demo/common/hello.c\"\n    }\n]\nThe strange output in command doesn't seem to be there. What is your LANG set to?\nIs args being there a problem? Does the clang tooling not ignore it? We can remove it if it is.\ncc @bolinfest since https://github.com/facebook/nuclide uses it.\n. > It isn't explicitly forbidden, but if you try accessing the compilation database through the clang tooling API (the one I posted in the original issue) you get a CXCompilationDatabase_CanNotLoadDatabase error.\nI guess we should remove it then.\n. I added them in 1fc71e1d3a95fb02b91c503cff1a9df7ae6531df.\n. Latest Buck master only specifies arguments and not args, so this should be solved.\n. Pull request is the right way. If there is some substantial cleanup to do create smaller pull request we can merge in early in the process so you don't have to keep remerging the changes.\nIf you have some particular issues with how the code is set up and have some high level idea on how to fix it we can discuss it.\nThe java code is not the best as far reusability goes because it wasn't designed with other JVM languages in mind.\n. Sounds reasonable, something like:\nc.f.b.jvm.core (including shared classes for rules, classpath and dependencies)\nc.f.b.jvm.java (java specific)\nc.f.b.jvm.groovy (groovy specific)\nand so forth.\nBuck doesn't allow circular dependencies, so care must be take to avoid them: core shouldn't reference the other packages in jvm.\nWe would also prefer smaller increments, it's easier to review.\n@shs96c, @marcinkosiba You guys know more about jvm languages, how does that sound at a high level?\n. Ok, back to you @mread.\n. #buck on freenode\n. I assume this PR is being superseded by the smaller PRs coming in, can we close it?\n. I'm sure @jspahrsummers would love to add Buck support to Carthage.\n. You can already create dynamic frameworks by using apple_bundle and setting its binary attribute to refer to a apple_library with the #shared flavour.\nWe are planning to make the interface nicer though.\n. prebuilt_cxx_library helps you a bit there, but in practice it's only supported in the cxx workflow, not in the iOS workflow, so project generation and so on won't work.\nMost likely not what you're looking for there, sorry.\n. There is a hacky workaround we use, I mentioned it here: https://github.com/facebook/buck/issues/660#issuecomment-202884912\n. Back to @andrewjcg for @rowillia's comment.\n. cc @marcinkosiba \n. @bhamiltoncx tried to do this once, but I think there were complications with the launcher script or something.\n. This was done in 707646a84826e59c45525e2a1db72837d42f99ca.\n. That looks really interesting, thanks for posting it here, we will have a look!\n. Looks ok, some parts of the code are based on patterns we are deprecating, mainly using system properties for resources and source under test.\nBack to you.\n. @facebook-github-bot import\n. > Error: Unable to access jarfile /home/travis/android-sdk-linux/tools/proguard/lib/proguard.jar\nThat doesn't seem related to the PR, let me import it and run it on out internal CI.\n. > Error: Unable to access jarfile /home/travis/android-sdk-linux/tools/proguard/lib/proguard.jar\nThat doesn't seem related to the PR, let me import it and run it on out internal CI.\n. @facebook-github-bot import\n. @facebook-github-bot import\n. Did you install Xcode or the Developer Command Line Tools?\nI think you need them to install brew, but you might have uninstalled them.\n. brew install buck would use the bottle I think, not build it from source, so you wouldn't need Xcode or the Developer Command Line Tools.\nThe most popular brew formulae have bottles, so it's hard to tell if your setup is working.\n. Fix is ready and will go out during the next sync.\n. Buck already supports both Windows and Linux. If there are specific issues with Windows or Linux support please open issues for those.\n. Looks good, I'll try to cherry pick it.\n. We've fixed this, the fix will be out in the next sync. I think you can get the error message by passing a different verbosity level with the -v option.\n. Fixed in ef5cafc5cec1f9d96081b4a36e3ef61fff24892d.\n. Fixed in ef5cafc5cec1f9d96081b4a36e3ef61fff24892d.\n. Did you solve this issue? Did you find out how to repro it?\n. Did you solve this issue? Did you find out how to repro it?\n. Try creating a project with a target that isn't at the top level of your repo, so instead of buck project //:targetName it ends up with buck project //Apps:targetName.\nThere are some weird issues with creating projects with targets in the root of the repo, we should probably make it fail with an error message.\n. Try creating a project with a target that isn't at the top level of your repo, so instead of buck project //:targetName it ends up with buck project //Apps:targetName.\nThere are some weird issues with creating projects with targets in the root of the repo, we should probably make it fail with an error message.\n. Yeah sorry, it's a funny bug.\n. Yeah sorry, it's a funny bug.\n. Sure, PRs are always welcome.\nGenerally send out a draft of the PR first so we can comment on general approach and high level design. No need to flesh it out we know which direction we should go in.\nFor project generation specifically look at the --combined-project and --build-with-buck flags, those are the future in some sense.\n. Sure, PRs are always welcome.\nGenerally send out a draft of the PR first so we can comment on general approach and high level design. No need to flesh it out we know which direction we should go in.\nFor project generation specifically look at the --combined-project and --build-with-buck flags, those are the future in some sense.\n. Is plugin-lib.jar itself changing? If it's the same as before broken will not be run even though the dependencies of plugin-lib changed.\n. Is plugin-lib.jar itself changing? If it's the same as before broken will not be run even though the dependencies of plugin-lib changed.\n. If plugin-lib.jar in your example isn't changing, the genrule will not be executed because its inputs have been recomputed, but turned out to be same as before, so even if you were to execute the genrule, the result would be the same as far as Buck can tell.\nIf all the inputs to the genrule are the same, why would the result of the genrule be different? How are you reading in files from the genrule's command?\nI'll have a look at the repro if you don't mind. It sounds like you're trying to use genrule as a way to inject side effects into the build, which we've never supported, and as we optimise Buck further we'll end up breaking a lot of workarounds that would make it possible to do that in the past.\n. If plugin-lib.jar in your example isn't changing, the genrule will not be executed because its inputs have been recomputed, but turned out to be same as before, so even if you were to execute the genrule, the result would be the same as far as Buck can tell.\nIf all the inputs to the genrule are the same, why would the result of the genrule be different? How are you reading in files from the genrule's command?\nI'll have a look at the repro if you don't mind. It sounds like you're trying to use genrule as a way to inject side effects into the build, which we've never supported, and as we optimise Buck further we'll end up breaking a lot of workarounds that would make it possible to do that in the past.\n. I saw the repro you sent to the mailing list: https://github.com/davido/buck_genrule_changed_caching_behaviour_143646f and how you fixed the issue in gerrit: https://gerrit-review.googlesource.com/#/c/71650/ .\nI think this is working as intended, but it's certainly too easy to create a genrule that uses inputs Buck isn't tracking by using the buck audit or query command.\nWe really need to sandbox better, probably starting by preventing recursive buck invocation of any kind, and adding macros that would provide the functionality you need.\nFor example you call buck audit classpath libs in your genrule's script, but you could pass the same information in with the $(classpath ) macro I think right?\nThat would let Buck know that your genrule is using the inputs exported in the classpath, and it should be rerun if any of those change.\n. I saw the repro you sent to the mailing list: https://github.com/davido/buck_genrule_changed_caching_behaviour_143646f and how you fixed the issue in gerrit: https://gerrit-review.googlesource.com/#/c/71650/ .\nI think this is working as intended, but it's certainly too easy to create a genrule that uses inputs Buck isn't tracking by using the buck audit or query command.\nWe really need to sandbox better, probably starting by preventing recursive buck invocation of any kind, and adding macros that would provide the functionality you need.\nFor example you call buck audit classpath libs in your genrule's script, but you could pass the same information in with the $(classpath ) macro I think right?\nThat would let Buck know that your genrule is using the inputs exported in the classpath, and it should be rerun if any of those change.\n. Thanks! I removed the deps from the example as well.\n. Thanks! I removed the deps from the example as well.\n. We used to add the header symlinks to the search paths as well, but it turned out to slow down Xcode too much.\nWould an Alcatraz plugin to enable that be acceptable? \n. We used to add the header symlinks to the search paths as well, but it turned out to slow down Xcode too much.\nWould an Alcatraz plugin to enable that be acceptable? \n. We support building without header maps anyway, so it should be easy to add support back in for Xcode.\nI'll get back to you.\n. We support building without header maps anyway, so it should be easy to add support back in for Xcode.\nI'll get back to you.\n. Ok, we're going to add a switch to have the generated project be backed by header symlink trees as well as header maps.\n. @facebook-github-bot import\n. @facebook-github-bot import\n. Does it fail for you when running in ant, Buck or IntelliJ?\nIt seems to be failing with different configurations when running locally, but it always passes both with Buck and ant when running on CI.\n. > add /include/darwin to the parameters\nI did that and it fixed the building on some of the configurations.\nThe final issue I think we cannot solve: it has to do with El Capitan stripping DYLD_LIBRARY_PATH, which is necessary for running tests with JNI as we do it right now, if System Integrity Protection is enabled:\nhttp://www.oracle.com/technetwork/java/javase/8u66-relnotes-2692847.html\n\nWhen running on OSX 10.11 \"El Capitan\", when SIP is enabled, certain environment variables intended for debugging applications, such as DYLD_LIBRARY_PATH, may be stripped from the environment when running Java from the command line or when double-clicking a JAR file. Applications should not rely on these variables in a production environment, they are only intended for debugging during development.\n\nI think after adding the header search path the test should pass when run with Buck, but not in ant or IntelliJ.\nLet me know if it doesn't.\n. @facebook-github-bot  import\n. That means your ssh keys aren't set up correctly, you can refer to https://help.github.com/articles/generating-ssh-keys/ for instructions on how to set them up, or you can clone from the https link instead of the git link.\n. No, it's because we parse the verbosity with VerbosityParser.parse.\nI'm not sure why it exists.\n. No, it's because we parse the verbosity with VerbosityParser.parse.\nI'm not sure why it exists.\n. Can you find a fix_uuid.py script in your Buck installation? It's supposed to call that.\n. Can you find a fix_uuid.py script in your Buck installation? It's supposed to call that.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. \n. \n. Looks good to me, and changing all the instances in one PR is fine too.\n. Looks good to me, and changing all the instances in one PR is fine too.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. That's because the BUCK file is in the root of the repo probably, try to move it into a subdirectory.\n. That's because the BUCK file is in the root of the repo probably, try to move it into a subdirectory.\n. @bhamiltoncx is changing some stuff with regards with logging in tests, it's probably because of that.\nDon't think 1b03b4313b91b634bd604fc3487a05f877e59dee is the right commit though.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Do you have an android sdk in ~/Library/Android/sdk? If not, unset the ANDROID_HOME environment variable.\n. Do you have an android sdk in ~/Library/Android/sdk? If not, unset the ANDROID_HOME environment variable.\n. There's a failure in the tests: setting the source level and target level isn't reflected in the key correctly.\n. There's a failure in the tests: setting the source level and target level isn't reflected in the key correctly.\n. Sounds good, I'm looking at the rest of the changes in the meantime.\n. Sounds good, I'm looking at the rest of the changes in the meantime.\n. Ok, high level the changes seem ok, will review in depth after the tests are fixed.\nI would like you to split some of the commits out into their own PR though, so that they have their own commit after they're imported.\n. Ok, high level the changes seem ok, will review in depth after the tests are fixed.\nI would like you to split some of the commits out into their own PR though, so that they have their own commit after they're imported.\n. > The changes you mention actually look pleasantly orthogonal\nYes, that is why I asked them to be pulled out: it's not really about the size of the changes in a PR, it's more about whether the changes are part of a single unit or not.\n. > The changes you mention actually look pleasantly orthogonal\nYes, that is why I asked them to be pulled out: it's not really about the size of the changes in a PR, it's more about whether the changes are part of a single unit or not.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. We've discussed this before and we want the syntax to be with brackets like rule[file].\nWe won't get around implementing it anytime soon though.\n. We've discussed this before and we want the syntax to be with brackets like rule[file].\nWe won't get around implementing it anytime soon though.\n. We've discussed this before and we want the syntax to be with brackets like rule[file].\nWe won't get around implementing it anytime soon though.\n. Note this is just a UI improvement, it would still be functionally equivalent to creating a genrule for each file, minus the copy.. You need to know the names of the files in advance and write them in the build files.\nYou can do that using a python loop if you wish, but you cannot list files in the output directory.\nThe same limitation exists with the new syntax.. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. If the final result of this PR is to remove DefaultJavaLibrary.getJavacOptions() 8bcd2cc and a9c3087 don't seem to be related.\n. If the final result of this PR is to remove DefaultJavaLibrary.getJavacOptions() 8bcd2cc and a9c3087 don't seem to be related.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot import\n. @facebook-github-bot import\n. Ok, just those two notes, the rest looks good.\n. Ok, just those two notes, the rest looks good.\n. I'll fix them up then ship this, you don't need to update this unless you have the changes ready.\n. I'll fix them up then ship this, you don't need to update this unless you have the changes ready.\n. You shouldn't be writing or modifying files in buck-out, it will cause problems in general.\nCan you change your eclipse project to output to a directory that isn't in buck-out?\nIt's pretty silly of Buck to be parsing build files in there though.\n. You shouldn't be writing or modifying files in buck-out, it will cause problems in general.\nCan you change your eclipse project to output to a directory that isn't in buck-out?\nIt's pretty silly of Buck to be parsing build files in there though.\n. Good point.\n@shs96c something else to keep in mind for how the new FileHashCache should work.\n. Good point.\n@shs96c something else to keep in mind for how the new FileHashCache should work.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. I don't think that will work since the buck launcher script will build with ant, not with buck.\n. Natively Buck doesn't support swift yet, but if you use the Xcode project generation can add swift sources to apple_library and apple_binary, the generated Xcode project will do the right thing.\nCreating a framework target is the same as an app target, but with a different extension, and the binary should be specified as #shared.\npython\napple_bundle(\n  name = 'MyFramework',\n  binary = ':MyLibrary#shared',\n)\nSee docs at https://buckbuild.com/rule/apple_bundle.html.\nThere's a couple of issues with them though.\nWhy do you want to build a framework? Those issues might or might not affect you depending on what you're trying to do.\n. Thanks for finding the root cause of the issue.\nTo make sure this doesn't happen again, change all the methods on JavaLibraryClasspathProvider that take Optional<Path> outputJar to take Optional<SourcePath> outputJar instead.\nSourcePaths are much safer because they encapsulate the project filesystem. That way we know they can always be resolved correctly.\nSee https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/AndroidPackageableCollector.java#L193 for example.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Why did you create a new PR instead of updating the existing one?\n. There's a lot of failing tests.\nThe Travis build is currently broken for other reasons, but if you run buck test locally you'll see.\nTESTS FAILED: 12 FAILURES\nFailed target: //test/com/facebook/buck/android:unit\nFAIL com.facebook.buck.android.AndroidBinaryTest\nFailed target: //test/com/facebook/buck/jvm/java:java\nFAIL com.facebook.buck.jvm.java.DefaultJavaLibraryTest\nFAIL com.facebook.buck.jvm.java.DefaultSuggestBuildRulesTest\nFailed target: //test/com/facebook/buck/cli:cli\nFAIL com.facebook.buck.cli.AuditClasspathCommandTest\n. It could be a problem with the test.\nLooking at the source it doesn't seem to be constructing a correct resolver, it adds actions to buildRuleIndex, but then never reads them from there.\nWhen it creates the action in createJavaLibraryRule it passes in an empty resolver (new SourcePathResolver(\n              new BuildRuleResolver(\n                  TargetGraph.EMPTY,\n                  new BuildTargetNodeToBuildRuleTransformer()))), that resolver won't be able to resolve anything.\n. Note that the tests that are failing when your run all tests are not included in the android tests, because they're integration tests not unit tests.\nThat might also explain why they're using API 21 instead of 23: the integration tests probably aren't reading your .buckconfig, and they shouldn't either.\nYou can install API 21 to run them, or maybe fix them so they write out a .buckconfig that contains the right version.\n. Note that the tests that are failing when your run all tests are not included in the android tests, because they're integration tests not unit tests.\nThat might also explain why they're using API 21 instead of 23: the integration tests probably aren't reading your .buckconfig, and they shouldn't either.\nYou can install API 21 to run them, or maybe fix them so they write out a .buckconfig that contains the right version.\n. It's a big complicated because genrule can output directories, but very few target types that read files can also read directories containing those files.\nWhat we do is end up creating a genrule to generate the files in a directory, then other genrules to export every single file from that directory. You can use some python to make that easy, for example:\n``` python\nthis would be ['src/Foo.java', 'src/Bar.java']\nJAVA_SRCS = glob(['src/*.java'])\nthis would be ['Foo.m', 'Bar.m'], you can adjust it to also include a header for each source file\nor add a prefix or whatever you want\nOBJC_FILENAMES = [get_objc_filename(x) for x in JAVA_SRCS]\ngenrule(\n  name = 'generate-objc-sources',\n  srcs = JAVA_SRCS,\n  cmd = '$(exe :generator) -o $OUT $SRCS',\n  out = 'output',\n)\nthis is will generate a genrule for each source file that will copy the file out of the directory, like:\ngenrule(\nname = 'Foo.m',\ncmd = 'cp buck-out/gen/.../generate-objc-sources/output/Foo.m buck-out/gen/.../Foo.m/Foo.m'\nout = 'Foo.m',\n)\nfor objc_filename in OBJC_FILENAMES:\n  genrule(\n    name = objc_filename,\n    cmd = 'cp $(location :generate-objc-sources)/{}'.format(objc_filename) $OUT,\n    out = objc_filename,\n  )\nthis will create a library that uses the sources exported by the above genrules, like:\napple_library(\nname = 'library',\nsrcs = [':Foo.m', ':Bar.m'],\n...\n)\napple_library(\n  name = 'library',\n  srcs = [':' + x for x in OBJC_FILENAMES],\n  ...\n)\n```\nIf you need help debugging this stuff you can use buck audit rules path/to/BUCK, it will print out how Buck is interpreting the functions in the file.\n. Yeah you need to use prebuilt_cxx_library to use a prebuilt static library in your application. We build everything from source so that workflow isn't well tested, and it's not supported in project generation.\n. Yeah you need to use prebuilt_cxx_library to use a prebuilt static library in your application. We build everything from source so that workflow isn't well tested, and it's not supported in project generation.\n. You can do the same thing as subdir_glob by specifying a dictionary instead of a list for headers: the key will be the path with which you can include the header, the value is the reference to the header itself.\nAs long as the keys are different you should be fine. The keys default to the name if you use a list, so having multiple headers with the same name won't work, although multiple headers with the same name in the same target might not work anyway, I'm not sure right now.\nAs for the code generation not knowing the number and names of the files being generated, there's no way to solve that in Buck. All the actions have to be determined before they are executed. It's a pretty hard limitation to deal with and we're not happy with it either, but that's how it is right now.\n. You can do the same thing as subdir_glob by specifying a dictionary instead of a list for headers: the key will be the path with which you can include the header, the value is the reference to the header itself.\nAs long as the keys are different you should be fine. The keys default to the name if you use a list, so having multiple headers with the same name won't work, although multiple headers with the same name in the same target might not work anyway, I'm not sure right now.\nAs for the code generation not knowing the number and names of the files being generated, there's no way to solve that in Buck. All the actions have to be determined before they are executed. It's a pretty hard limitation to deal with and we're not happy with it either, but that's how it is right now.\n. Yeah it can be a reference to a target. It should work as you suggested.\nThe limitation is part of the design. We know how to change the design to support that by making it more like shake, but we haven't yet decided whether we want to.\nIf you need to support very complex code generation you could look into implementing a target type directly in Buck.\nThere are some docs on how to do it on the website, and I'm posting some helpful notes on Facebook.\nLook at the react native target types after you read the docs to get started.\n. Yeah it can be a reference to a target. It should work as you suggested.\nThe limitation is part of the design. We know how to change the design to support that by making it more like shake, but we haven't yet decided whether we want to.\nIf you need to support very complex code generation you could look into implementing a target type directly in Buck.\nThere are some docs on how to do it on the website, and I'm posting some helpful notes on Facebook.\nLook at the react native target types after you read the docs to get started.\n. cc @grumpyjames @davido @mikekap @mread @tgummerer \n. We added licenses to all target types, that could help: https://github.com/facebook/buck/commit/d0223d9d1e5710b38e72ae696517a5e94ce5ded8 .\n. Yep, it is.\n. We can do it both ways: either add a setting in .buckconfig to be able to specify watchman and buckd should not be used in a project, or have watchman refuse to work and Buck handle that gracefully.\n@wez What would you prefer? The former doesn't require any changes in watchman but the latter could support other use cases where watchman could decide whether it wants to enable a watch or not.\n. I know nothing about groovy but the code looks fine.\nJust two comments.\n. We've been discussing something similar to support system libraries in prebuilt_cxx_library, so I think it makes sense.\ncc @andrewjcg \n. @Qix- that's unrelated, can you open a new issue for that?\n. > We could remove lots of tedious step code by always having buck-out/(gen|bin|res|annotation)/${buildTarget}/ already exist\nAs @k21 mentioned, I have a series of changes to do that. It's a bit harder than expected, and going towards it actually highlights the issue opposite to the one you noticed: while it's true we create more mkdir steps than strictly necessary, we also don't create some we should, because we assume the directories already exist.\nI'll try to pick those changes back up.\nI'll close this in the meantime, I agree not having to create these directories would be best, but we cannot remove the uses where it works by coincidence without setting up the infrastructure beforehand.\n. There some information about that here and in similar stackoverflow questions: http://stackoverflow.com/questions/33910859/buck-exopackage-multi-dex-support\nYou can also see examples in the tests:\nhttps://github.com/facebook/buck/blob/master/test/com/facebook/buck/android/AndroidBinaryIntegrationTest.java\nhttps://github.com/facebook/buck/tree/master/test/com/facebook/buck/android/testdata/android_project\n. What version of java are you using? java -version will tell you.\n. I'm not sure this is the exact way we would expose such a feature, but we have hit this issue internally as well.\n. @facebook-github-bot import\n. Is the python testing change require to make the test selectors work? If not please separate it in another PR.\n. @facebook-github-bot shipit\n. It's failing because you have the same header both in public and in private headers.\n. It's failing because you have the same header both in public and in private headers.\n. I think this is fine.\nThe big problem we have with source_under_test is that buck test library supports finding the tests that have library in source_under_test, which is really really slow, this doesn't support that so it's ok.\nAlternatively if you want to make sure there is no confusion, add a check for library.test containing all the tests that specify library in library.\n. Yes, I meant the former.\nIt's a bit clunky because it means that if you want to make an internal test you have to update the definition of the library as well, and you can't make internal tests for a library for which you cannot edit the BUCK file, but maybe that makes sense, as you should be creating an external test then?\n. Yes, I meant the former.\nIt's a bit clunky because it means that if you want to make an internal test you have to update the definition of the library as well, and you can't make internal tests for a library for which you cannot edit the BUCK file, but maybe that makes sense, as you should be creating an external test then?\n. @facebook-github-bot shipit\n. This was blocked internally because it changes all libraries, not just the ones used in pexes.\ncc @andrewjcg \n. I'm not sure if @andrewjcg had any idea how to fix it, but the problem here is that the rpath is embedded in every DSO, regardless of whether we use it in a python binary with the pex package style or not.\n. I'm not sure if @andrewjcg had any idea how to fix it, but the problem here is that the rpath is embedded in every DSO, regardless of whether we use it in a python binary with the pex package style or not.\n. Oh yes, frameworks and libraries can only refer to system frameworks and libraries, not prebuilt ones.\nWe need to add support for frameworks to prebuilt_cxx_library.\n. Here's a workaround you can use.\nAssuming the prebuilt framework is a static framework called Framework:\n``` python\nlike export_file, but xcode project generator can actually use this\ngenrule(\n  name = 'SDKBinary',\n  srcs = ['Framework.framework/Versions/A/Framework'],\n  out = 'libFramework.a',\n  bash = 'cp $SRCS $OUT',\n)\napple_resource(\n  name = 'FrameworkResources',\n  dirs = ['Framework.framework/FrameworkResources.bundle'],\n  files = [],\n  variants = [],\n)\napple_library(\n  name = 'FrameworkSDK',\n  srcs = ['src/dummy.c'],\n  supported_platforms_regex = '^(iphoneos|iphonesimulator).*',\n# instructs buck based builds to conditionally link the library.\n  # in xcode, $(location ...) is not resolved, so this is a no-op\n  exported_linker_flags = [\n    '$(location :SDKBinary)',\n  ],\n# In xcode these build settings take effect\n  # Instruct xcode to conditionally link the static library into this library.\n  # for buck based builds, this option is ignored and this library is effectively empty.\n  configs = {\n    'Debug': {\n      'OTHER_LIBTOOLFLAGS[sdk=iphone*]': '$(inherited) $(REPO_ROOT)/FrameworkSDK/Framework.framework/Versions/A/Framework',\n    },\n  },\ndeps = [\n    ':SDKBinary',\n    ':FrameworkResources',\n  ],\n  exported_headers = subdir_glob(\n    [\n      ('Framework.framework/Versions/A/Headers', '*.h'),\n    ],\n    prefix='Framework'\n  ),\n  visibility = [\n    'PUBLIC',\n  ],\n)\n``\n.remote_filerequiressha1. You would have to change that to match the new version anyway, then when you runbuck fetchit should get it.\n. Transitive dependencies is not planned, but you can look at https://github.com/facebook/buck/blob/master/src/com/facebook/buck/maven/Resolver.java which helps you set up aremote_file` target for each dependency.\nWhat do you mean by authentication? That sounds like something we should support, and maybe already do.\n. > I could try writing it and sending a PR, if it seems reasonable.\nYeah, that does sound like something we should support.\nWe have https://buckbuild.com/concept/buckconfig.html#maven_repositories as a buckconfig section, so something there would make sense, like:\nini\n[maven_repositories]\ncentral = https://repo1.maven.org/maven2\ncentral_user = user\ncentral_pass = pass\nor something like that.\n. > Would the resolver need to be invoked before every build to regenerate the rules?\nI think so. It's sort of like having submodules or any kind of dependencies that are pinned to certain versions: updating them is an explicit operation.\n. Oh yes, I keep forgetting about that.\nYou should document the new .buckconfig options here: https://github.com/facebook/buck/blob/master/docs/concept/buckconfig.soy#L1424\nYou can run docs/soyweb-local.sh to host the documentation locally and preview your changes.\n. I assume because the pull requests have been merged this has been resolved, let me know if there's anything left.. @facebook-github-bot shipit\n. I'd rather not add a new set of targets that use the cxx style graph enhancement and a new set of no-op rules.\nI've described the different types of graph enhancement we do in Buck here: https://www.facebook.com/notes/uri-baghin/architecture-of-buck-1-graphs/1660525917559134 .\nWe're trying to make new graph enhancements use requireRule and requireMetadata.\nIn this case GoLibraryDescription would return a NoopBuildRule, not a subclass of it, and return a list of GoLibraryLinkable from createMetadata (see MetadataProvidingDescription), then the code in GoDescriptors can call requireMetadata exactly like it's calling requireRule now.\nCompatibility with the cxx targets can be implemented by returning native linkables from their createMetadata (they already implement that method, but it's only used for compilation databases.\n. The createMetadata implementations can be a bit annoying because of all the mess with the flavours, but their essentially the same as dealing with createBuildRule and flavours.\nLet me know if you need more information.\n. I would prefer switching on class type, but sometime flavours are used as well, for distinguishing different metadata that have the same class.\nI don't mind either way.\n. Yes, this is exactly it.\nAs an aside, what do you think of the requireMetadata API? Which parts of it are good and which parts of it are clunky? I've noticed the fact it returns an optional was a bit of an annoyance in some parts.\n. > Optional isn't very useful in this case.\nIt's not useful in most cases. The issue is deps really: sometimes you want a certain metadata from all your deps, but you have no idea which of your deps can provide that metadata because deps is heterogenous. If we had linked_deps, resource_deps and so on it would be easier to deal with them. We've noticed deps being heterogenous and being treated differently (getDeclaredDeps() vs getExtraDeps()) are at the root of various awkward parts of the APIs so we might revisit it at some point.\n\nIn general I think there's a problem between how \"macro\"-like descriptions interact\n\nI don't understand this part, can you expand on it?\n. > Optional isn't very useful in this case.\nIt's not useful in most cases. The issue is deps really: sometimes you want a certain metadata from all your deps, but you have no idea which of your deps can provide that metadata because deps is heterogenous. If we had linked_deps, resource_deps and so on it would be easier to deal with them. We've noticed deps being heterogenous and being treated differently (getDeclaredDeps() vs getExtraDeps()) are at the root of various awkward parts of the APIs so we might revisit it at some point.\n\nIn general I think there's a problem between how \"macro\"-like descriptions interact\n\nI don't understand this part, can you expand on it?\n. True, every target type does that kind of thing differently.\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/apple/ApplePackageDescription.java#L93 does it like you're suggesting, by using findDepsForTargetFromConstructorArgs.\nAll the approaches have pros and cons, I'm mostly advocating requireRule and requireMetadata because ideally once everything uses that we can get rid of BuildRuleParams creating dependencies eagerly.\nTo make that easier we're planning on implementing coercing for flavour convertibles as well, like description's Arg types.\nI'd really like to do something about that metadataClass, but I have no idea what.\nEven createBuildRule and consequently requireRule currently return something you end up casting a lot of the time. It's so bad.\n. True, every target type does that kind of thing differently.\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/apple/ApplePackageDescription.java#L93 does it like you're suggesting, by using findDepsForTargetFromConstructorArgs.\nAll the approaches have pros and cons, I'm mostly advocating requireRule and requireMetadata because ideally once everything uses that we can get rid of BuildRuleParams creating dependencies eagerly.\nTo make that easier we're planning on implementing coercing for flavour convertibles as well, like description's Arg types.\nI'd really like to do something about that metadataClass, but I have no idea what.\nEven createBuildRule and consequently requireRule currently return something you end up casting a lot of the time. It's so bad.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Let's see if it works...\n. Let's see if it works...\n. Can you add a test for this?\n. Yeah I think the approach is fine, just fix that last thing and I'll import it.\n. @facebook-github-bot shipit\n. Bah, Travis failed apt-get so it didn't show test results, but this is what I get from the internal CI:\nFAILURE com.facebook.buck.file.HttpDownloaderTest shouldAddAuthenticationHeader: \n  Expectation failure on verify:\n    HttpURLConnection.addRequestProperty(\"Authorization\", capture(Nothing captured yet)): expected: 1, actual: 0\njava.lang.AssertionError: \n  Expectation failure on verify:\n    HttpURLConnection.addRequestProperty(\"Authorization\", capture(Nothing captured yet)): expected: 1, actual: 0\n    at org.easymock.internal.MocksControl.verify(MocksControl.java:241)\n    at org.easymock.EasyMock.verify(EasyMock.java:2100)\n    at com.facebook.buck.file.HttpDownloaderTest.shouldAddAuthenticationHeader(HttpDownloaderTest.java:93)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout$1.call(SameThreadFailOnTimeout.java:45)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout$1.call(SameThreadFailOnTimeout.java:41)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\n. @facebook-github-bot shipit\n. Wow that was fast, @andrewjcg was looking into reverting the revert with a fix, so I'll assign this to him.\n. @facebook-github-bot shipit\n. This is landed internally. There's some issues with our git hooks that is preventing the commit to be published to open source, but we hope to solve it soon.\n. Sorry it took so long, I kept getting pulled away by other stuff.\n. It's not possible to do that because of how java works: classes in the same compilation unit might have cyclical dependencies.\nBut splitting the target into smaller ones should help.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. It seems like it should be possible to split the work into three rules, the compilation rule for go sources, the assembling rule for assembly and the packing rules to put them together.\nThat way you would get higher caching granularity and parallelism.\n. It seems like it should be possible to split the work into three rules, the compilation rule for go sources, the assembling rule for assembly and the packing rules to put them together.\nThat way you would get higher caching granularity and parallelism.\n. Ok, sounds good.\n. Ok, sounds good.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Hmm, the patch doesn't apply, can you rebase on master?\n. Hmm, the patch doesn't apply, can you rebase on master?\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. I'm confused, how are you supposed to access the licenses with this change? They're not a field on target node like visibility and they're not a field on the constructor arg like before this change.\nI guess it's @sdwilsh's bad for not adding a test, but buck query \"labels('licenses', deps('buck'))\" should return the list of licenses used in Buck.\n. I'm confused, how are you supposed to access the licenses with this change? They're not a field on target node like visibility and they're not a field on the constructor arg like before this change.\nI guess it's @sdwilsh's bad for not adding a test, but buck query \"labels('licenses', deps('buck'))\" should return the list of licenses used in Buck.\n. Yeah the order of parameters can change, as new ones are added or old ones are removed.\nAlways use named parameters.\n. Yeah the order of parameters can change, as new ones are added or old ones are removed.\nAlways use named parameters.\n. I don't think the docs mention any of this, they just never mention you can create targets without using named parameters in the first place.\n. I don't think the docs mention any of this, they just never mention you can create targets without using named parameters in the first place.\n. cc @grumpyjames \n. Seems good, only one comment and I'm not even sure I'm right on it.\nI'll import it tomorrow if you haven't answered by then.\n. @facebook-github-bot shipit\n. Assuming that fixed it.. @facebook-github-bot shipit\n. Had to revert the test timeouts, they were causing deadlocks, but the rest should be landing soon.\n. Do you get notified on inline comments now? I remember we used to have to ping with emojis back in my day.\n. @facebook-github-bot shipit\n. I don't get what is going on, I'm getting this error on CI internally:\n[javadoc] Constructing Javadoc information...\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/composition/DefaultDependencyManagementImporter.class): warning: Cannot find annotation method 'role()' in type 'Component': class file for org.codehaus.plexus.component.annotations.Component not found\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/management/DefaultDependencyManagementInjector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/management/DefaultPluginManagementInjector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/plugin/DefaultPluginConfigurationExpander.class): warning: Cannot find annotation method 'role()' in type 'Component'\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/profile/DefaultProfileSelector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/profile/DefaultProfileSelector.class): warning: Cannot find annotation method 'role()' in type 'Requirement': class file for org.codehaus.plexus.component.annotations.Requirement not found\n  [javadoc] Standard Doclet version 1.7.0_45\n  [javadoc] Building tree for all the packages and classes...\n  [javadoc] Building index for all the packages and classes...\n  [javadoc] Building index for all classes...\n  [javadoc] Generating /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/javadoc-all/help-doc.html...\n  [javadoc] 6 warnings\n     [exec] Unexpected Javadoc errors (7):\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/composition/DefaultDependencyManagementImporter.class): warning: Cannot find annotation method 'role()' in type 'Component': class file for org.codehaus.plexus.component.annotations.Component not found\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/management/DefaultDependencyManagementInjector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/management/DefaultPluginManagementInjector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/plugin/DefaultPluginConfigurationExpander.class): warning: Cannot find annotation method 'role()' in type 'Component'\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/profile/DefaultProfileSelector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/profile/DefaultProfileSelector.class): warning: Cannot find annotation method 'role()' in type 'Requirement': class file for org.codehaus.plexus.component.annotations.Requirement not found\n     [exec]   [javadoc] 6 warnings\nRunning ant verify-javadoc but I cannot repro it locally. Any ideas?\n. I don't get what is going on, I'm getting this error on CI internally:\n[javadoc] Constructing Javadoc information...\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/composition/DefaultDependencyManagementImporter.class): warning: Cannot find annotation method 'role()' in type 'Component': class file for org.codehaus.plexus.component.annotations.Component not found\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/management/DefaultDependencyManagementInjector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/management/DefaultPluginManagementInjector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/plugin/DefaultPluginConfigurationExpander.class): warning: Cannot find annotation method 'role()' in type 'Component'\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/profile/DefaultProfileSelector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n  [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/profile/DefaultProfileSelector.class): warning: Cannot find annotation method 'role()' in type 'Requirement': class file for org.codehaus.plexus.component.annotations.Requirement not found\n  [javadoc] Standard Doclet version 1.7.0_45\n  [javadoc] Building tree for all the packages and classes...\n  [javadoc] Building index for all the packages and classes...\n  [javadoc] Building index for all classes...\n  [javadoc] Generating /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/build/javadoc-all/help-doc.html...\n  [javadoc] 6 warnings\n     [exec] Unexpected Javadoc errors (7):\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/composition/DefaultDependencyManagementImporter.class): warning: Cannot find annotation method 'role()' in type 'Component': class file for org.codehaus.plexus.component.annotations.Component not found\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/management/DefaultDependencyManagementInjector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/management/DefaultPluginManagementInjector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/plugin/DefaultPluginConfigurationExpander.class): warning: Cannot find annotation method 'role()' in type 'Component'\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/profile/DefaultProfileSelector.class): warning: Cannot find annotation method 'role()' in type 'Component'\n     [exec]   [javadoc] /data/sandcastle/boxes/instance-buck-git-buck-verification-linux/third-party/java/maven/maven-model-builder-3.2.5.jar(org/apache/maven/model/profile/DefaultProfileSelector.class): warning: Cannot find annotation method 'role()' in type 'Requirement': class file for org.codehaus.plexus.component.annotations.Requirement not found\n     [exec]   [javadoc] 6 warnings\nRunning ant verify-javadoc but I cannot repro it locally. Any ideas?\n. cc @jspahrsummers, @ndfred\n. Looks good, just a couple of notes.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Yes, I think it would be faster if you were to submit a PR.\n. --experimental-ij-generation ignores project_config entirely.\n. cc @marcinkosiba, @alsutton\n. @facebook-github-bot shipit\n. ```\nFAIL      4.0s  4 Passed   0 Skipped   1 Failed   com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest\nFAILURE com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest testPrebuiltJarGenruleDirectory: Expected exit code 0 but was 1.\njava.lang.AssertionError: Expected exit code 0 but was 1.\n    at org.junit.Assert.fail(Assert.java:88)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertExitCode(ProjectWorkspace.java:649)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertSuccess(ProjectWorkspace.java:610)\n    at com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest.testPrebuiltJarGenruleDirectory(PrebuiltJarIntegrationTest.java:101)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout$1.call(SameThreadFailOnTimeout.java:45)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout$1.call(SameThreadFailOnTimeout.java:41)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\n====STANDARD OUT====\n====DEBUG LOGS====\n[2016-05-31 02:51:45.068][warn ][tid:4770][com.facebook.buck.apple.AppleConfig] Could not execute xcode-select, continuing without developer dir.\n[2016-05-31 02:51:45.095][info ][tid:5041][com.facebook.buck.event.listener.LoggingBuildListener] Build started at 2016-05-31 02:51:45.094\n[2016-05-31 02:51:45.206][info ][tid:4770][com.facebook.buck.rules.ActionGraphCache] ActionGraph cache miss. Cache was empty.\n[2016-05-31 02:51:45.210][warn ][tid:4770][com.facebook.buck.python.PythonBinaryDescription] //:unzip: parameter main is deprecated, please use main_module instead.\n[2016-05-31 02:51:45.558][warn ][tid:5041][com.facebook.buck.event.listener.LoggingBuildListener] No Android platform target specified. Using default: Google Inc.:Google APIs:23\n[2016-05-31 02:51:45.734][warn ][tid:5041][com.facebook.buck.event.listener.LoggingBuildListener] Traceback (most recent call last):\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \"/usr/lib64/python2.6/contextlib.py\", line 34, in exit\n    self.gen.throw(type, value, traceback)\n  File \".bootstrap/_pex/pex.py\", line 223, in patch_pkg_resources\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \".bootstrap/_pex/pex.py\", line 253, in _wrap_coverage\n  File \".bootstrap/_pex/pex.py\", line 285, in _wrap_profiling\n  File \".bootstrap/_pex/pex.py\", line 363, in _execute\n  File \".bootstrap/_pex/pex.py\", line 421, in execute_entry\n  File \".bootstrap/_pex/pex.py\", line 426, in execute_module\n  File \"/usr/lib64/python2.6/runpy.py\", line 140, in run_module\n    fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"unzip.py\", line 39, in \n  File \"unzip.py\", line 35, in main\nAttributeError: ZipFile instance has no attribute 'exit'\n[2016-05-31 02:51:45.736][warn ][tid:5041][com.facebook.buck.event.listener.LoggingBuildListener] BUILD FAILED: //:genjardir failed with exit code 1:\ngenrule\nstderr: Traceback (most recent call last):\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \"/usr/lib64/python2.6/contextlib.py\", line 34, in exit\n    self.gen.throw(type, value, traceback)\n  File \".bootstrap/_pex/pex.py\", line 223, in patch_pkg_resources\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \".bootstrap/_pex/pex.py\", line 253, in _wrap_coverage\n  File \".bootstrap/_pex/pex.py\", line 285, in _wrap_profiling\n  File \".bootstrap/_pex/pex.py\", line 363, in _execute\n  File \".bootstrap/_pex/pex.py\", line 421, in execute_entry\n  File \".bootstrap/_pex/pex.py\", line 426, in execute_module\n  File \"/usr/lib64/python2.6/runpy.py\", line 140, in run_module\n    fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"unzip.py\", line 39, in \n  File \"unzip.py\", line 35, in main\nAttributeError: ZipFile instance has no attribute 'exit'\n[2016-05-31 02:51:45.737][info ][tid:5041][com.facebook.buck.event.listener.LoggingBuildListener] Build finished at 2016-05-31 02:51:45.736\n[2016-05-31 02:51:45.738][info ][tid:4770][com.facebook.buck.cli.Main] Awaiting termination of HTTP Write executor service. Waiting for all jobs to complete, or up to maximum of 1800 seconds...\n[2016-05-31 02:51:45.738][info ][tid:4770][com.facebook.buck.cli.Main] Awaiting termination of CounterAggregatorExecutor executor service. Waiting for all jobs to complete, or up to maximum of 20 seconds...\n[2016-05-31 02:51:45.739][info ][tid:4770][com.facebook.buck.cli.Main] Awaiting termination of CPU executor service. Waiting for all jobs to complete, or up to maximum of 60 seconds...\n[2016-05-31 02:51:45.739][info ][tid:4770][com.facebook.buck.cli.Main] Awaiting termination of NETWORK executor service. Waiting for all jobs to complete, or up to maximum of 60 seconds...\n[2016-05-31 02:51:45.739][info ][tid:4770][com.facebook.buck.cli.Main] Awaiting termination of Disk IO executor service. Waiting for all jobs to complete, or up to maximum of 10 seconds...\n[2016-05-31 02:51:45.740][warn ][tid:4770][com.facebook.buck.event.listener.ScubaBuildListener] Still have 1 thread remaining.  Dropping results.\n====STANDARD ERR====\nWARNING: Cannot find ConsoleHandler log handler. Logs printed to console will likely be lost.\nWARNING: Cannot find ConsoleHandler log handler. Logs printed to console will likely be lost.\n=== Expected exit code 0 but was 1. ===\n=== STDERR ===\n[-] PARSING BUCK FILES...FINISHED 0.0s [100%]\nBUILT //:unzip (1/3 JOBS)\nNo Android platform target specified. Using default: Google Inc.:Google APIs:23\nTraceback (most recent call last):\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \"/usr/lib64/python2.6/contextlib.py\", line 34, in exit\n    self.gen.throw(type, value, traceback)\n  File \".bootstrap/_pex/pex.py\", line 223, in patch_pkg_resources\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \".bootstrap/_pex/pex.py\", line 253, in _wrap_coverage\n  File \".bootstrap/_pex/pex.py\", line 285, in _wrap_profiling\n  File \".bootstrap/_pex/pex.py\", line 363, in _execute\n  File \".bootstrap/_pex/pex.py\", line 421, in execute_entry\n  File \".bootstrap/_pex/pex.py\", line 426, in execute_module\n  File \"/usr/lib64/python2.6/runpy.py\", line 140, in run_module\n    fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"unzip.py\", line 39, in \n  File \"unzip.py\", line 35, in main\nAttributeError: ZipFile instance has no attribute 'exit'\nBUILD FAILED: //:genjardir failed with exit code 1:\ngenrule\nstderr: Traceback (most recent call last):\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \"/usr/lib64/python2.6/contextlib.py\", line 34, in exit\n    self.gen.throw(type, value, traceback)\n  File \".bootstrap/_pex/pex.py\", line 223, in patch_pkg_resources\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \".bootstrap/_pex/pex.py\", line 253, in _wrap_coverage\n  File \".bootstrap/_pex/pex.py\", line 285, in _wrap_profiling\n  File \".bootstrap/_pex/pex.py\", line 363, in _execute\n  File \".bootstrap/_pex/pex.py\", line 421, in execute_entry\n  File \".bootstrap/_pex/pex.py\", line 426, in execute_module\n  File \"/usr/lib64/python2.6/runpy.py\", line 140, in run_module\n    fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"unzip.py\", line 39, in \n  File \"unzip.py\", line 35, in main\nAttributeError: ZipFile instance has no attribute 'exit'\n[-] BUILDING...FINISHED 0.6s [100%]\n=== STDOUT ===\n====ERROR LOGS====\n[2016-05-31 02:51:45.068][warn ][tid:4770][com.facebook.buck.apple.AppleConfig] Could not execute xcode-select, continuing without developer dir.\n[2016-05-31 02:51:45.210][warn ][tid:4770][com.facebook.buck.python.PythonBinaryDescription] //:unzip: parameter main is deprecated, please use main_module instead.\n[2016-05-31 02:51:45.558][warn ][tid:5041][com.facebook.buck.event.listener.LoggingBuildListener] No Android platform target specified. Using default: Google Inc.:Google APIs:23\n[2016-05-31 02:51:45.734][warn ][tid:5041][com.facebook.buck.event.listener.LoggingBuildListener] Traceback (most recent call last):\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \"/usr/lib64/python2.6/contextlib.py\", line 34, in exit\n    self.gen.throw(type, value, traceback)\n  File \".bootstrap/_pex/pex.py\", line 223, in patch_pkg_resources\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \".bootstrap/_pex/pex.py\", line 253, in _wrap_coverage\n  File \".bootstrap/_pex/pex.py\", line 285, in _wrap_profiling\n  File \".bootstrap/_pex/pex.py\", line 363, in _execute\n  File \".bootstrap/_pex/pex.py\", line 421, in execute_entry\n  File \".bootstrap/_pex/pex.py\", line 426, in execute_module\n  File \"/usr/lib64/python2.6/runpy.py\", line 140, in run_module\n    fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"unzip.py\", line 39, in \n  File \"unzip.py\", line 35, in main\nAttributeError: ZipFile instance has no attribute 'exit'\n[2016-05-31 02:51:45.736][warn ][tid:5041][com.facebook.buck.event.listener.LoggingBuildListener] BUILD FAILED: //:genjardir failed with exit code 1:\ngenrule\nstderr: Traceback (most recent call last):\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \"/usr/lib64/python2.6/contextlib.py\", line 34, in exit\n    self.gen.throw(type, value, traceback)\n  File \".bootstrap/_pex/pex.py\", line 223, in patch_pkg_resources\n  File \".bootstrap/_pex/pex.py\", line 320, in execute\n  File \".bootstrap/_pex/pex.py\", line 253, in _wrap_coverage\n  File \".bootstrap/_pex/pex.py\", line 285, in _wrap_profiling\n  File \".bootstrap/_pex/pex.py\", line 363, in _execute\n  File \".bootstrap/_pex/pex.py\", line 421, in execute_entry\n  File \".bootstrap/_pex/pex.py\", line 426, in execute_module\n  File \"/usr/lib64/python2.6/runpy.py\", line 140, in run_module\n    fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"unzip.py\", line 39, in \n  File \"unzip.py\", line 35, in main\nAttributeError: ZipFile instance has no attribute 'exit'\n[2016-05-31 02:51:45.740][warn ][tid:4770][com.facebook.buck.event.listener.ScubaBuildListener] Still have 1 thread remaining.  Dropping results.\n``\n. @facebook-github-bot shipit\n. Looks good, just one note.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. What test is it? We have some helper classes for tests so that mocking is usually not necessary.\n. Fixing it in #762.\n. Fixing it in #762.\n. Can you try--no-results-cache`? Test results have a separate caching mechanism that is much less reliable than the one used for builds, because tests are not assumed to be deterministic.\nIf that works, this would be a bug in that logic.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. cc @marcinkosiba, @michath \nI think we didn't want to modify the manifest merger since it comes from upstream, but I could be wrong.\n. cc @marcinkosiba, @michath \nI think we didn't want to modify the manifest merger since it comes from upstream, but I could be wrong.\n. cc @ryu2 \n. cc @ryu2 \n. Sorry cygwin isn't really supported.\nYou can run buck on Windows with cmd or powershell.\n. You should ask in the gerrit project, sorry.\n. cc @cotizo, @cosmin1123 \n. Appveyor looks green to me.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Thanks! \ud83d\udc36 \n. Thanks! \ud83d\udc36 \n. I think this is a known issue.\nSee also #795.\ncc @marcinkosiba, @michath \n. I think this is a known issue.\nSee also #795.\ncc @marcinkosiba, @michath \n. I wish I could move issues across repos, anyway this should be the right one: https://github.com/davido/bucklets .\nAs far as the error message goes, the formatting is a bit confusing, as BUILD FAILED: //lib/commons:codec__download_bin failed with exit code 1: makes it look like the reason for why it failed is genrule but it's actually the whole stack trace above.\ngenrule is a target type that is used to execute arbitrary code during the build, used to integrate tools that do not have native Buck integration (https://buckbuild.com/rule/genrule.html). Since Buck cannot interpret the output of the command it runs it will just print it out.\nI hope this explains everything, if it doesn't feel free to ask for clarifications, I will close the issue in the meantime as there is no action for us to take.\n. I wish I could move issues across repos, anyway this should be the right one: https://github.com/davido/bucklets .\nAs far as the error message goes, the formatting is a bit confusing, as BUILD FAILED: //lib/commons:codec__download_bin failed with exit code 1: makes it look like the reason for why it failed is genrule but it's actually the whole stack trace above.\ngenrule is a target type that is used to execute arbitrary code during the build, used to integrate tools that do not have native Buck integration (https://buckbuild.com/rule/genrule.html). Since Buck cannot interpret the output of the command it runs it will just print it out.\nI hope this explains everything, if it doesn't feel free to ask for clarifications, I will close the issue in the meantime as there is no action for us to take.\n. Found the issue, working on a fix now, thanks for pointing it out.\n. I thought the SDKs are now checked only if you build android. cc @michath \n. I don't remember the whole story behind that hack, but there are some differences in how Xcode and Buck see targets because for Xcode a target can only be built for a certain platform, but Buck can build them for any platform (macOS vs iOS for example).\n. cc @alsutton \n. cc @marcinkosiba \n. That's strange, I don't think genrule, apple_resource or remote_file do anything with symlinks.\nI'll try to repro.\n. That's strange, I don't think genrule, apple_resource or remote_file do anything with symlinks.\nI'll try to repro.\n. @mikekap, @grumpyjames: Could you take a look at this?\n. The Appveyor failure is a path limit issue, I've got some internal patches to address those but it's all a mess because the windows path limit is really really too short.\nYou can merge master into this PR, when we import it we'll rebase it anyway.\n. Just a couple of pointers, I'll import it and run our internal tests in the meantime.\n. @facebook-github-bot shipit\n. Sounds good.\nAre the framework destinations the same between macOS and iOS or do those need to be split as well? Can you double check?\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. cc @shs96c \n. Maybe zip appends .zip to the file automatically, so even if you set the output to be edit.src.jar you end up with edit.src.jar.zip?\nWe used export_file to rename the files from .zip to .jar.\n. Oh I see what is going on: you have a genrule creating a source jar and use it both as sources and as binary in a prebuilt_jar.\nLet's see what we can do.\n. cc @marcinkosiba, @shs96c \n. That's intended: it reflects the level of cache invalidations.\nSee f5ddbd3448bac2f36c2bb1dd1fd9b89bd1f730b8.\n. cc @dreiss \n. Does 83a0d0ab08f975d79933ab1da9942e17810b6e71 fix it for you?\n. Does 83a0d0ab08f975d79933ab1da9942e17810b6e71 fix it for you?\n. Very nice! Just a couple of small comments.\n. Thank you!\n. TESTS FAILED: 2 FAILURES\nFailed target: //test/com/facebook/buck/parser:parser\nFAIL com.facebook.buck.parser.ParserTest\n[Tue, 06 Sep 2016 08:18:10] Step \"Testing with Buck\" failed with: Summary (beta): \nFAILURE com.facebook.buck.parser.ParserTest resolveTargetSpecsPreservesOrder[2]: Unable to unpack pywatchman-archive.zip\n[CONTEXT] java.lang.RuntimeException: Unable to unpack pywatchman-archive.zip\n[CONTEXT]   at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:140)\n[CONTEXT]   at com.facebook.buck.util.PackagedResource.access$000(PackagedResource.java:44)\n[CONTEXT]   at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:74)\n[CONTEXT]   at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:71)\n[CONTEXT]   at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:131)\n[CONTEXT]   at com.facebook.buck.util.PackagedResource.get(PackagedResource.java:81)\n[CONTEXT]   at com.facebook.buck.json.BuckPythonProgram.newInstance(BuckPythonProgram.java:96)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.getPathToBuckPy(ProjectBuildFileParser.java:616)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.buildArgs(ProjectBuildFileParser.java:251)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.init(ProjectBuildFileParser.java:207)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.initIfNeeded(ProjectBuildFileParser.java:192)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesInternal(ProjectBuildFileParser.java:353)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesAndMetaRules(ProjectBuildFileParser.java:342)\n[CONTEXT]   at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:117)\n[CONTEXT]   at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:107)\n[CONTEXT]   at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n[CONTEXT]   at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n[CONTEXT]   at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n[CONTEXT]   at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n[CONTEXT]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[CONTEXT]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[CONTEXT]   at java.lang.Thread.run(Thread.java:744)\nFAILURE com.facebook.buck.parser.ParserTest resolveTargetSpecsDoesNotHangOnException[2]: \n[CONTEXT] Expected: (an instance of com.facebook.buck.json.BuildFileParseException and exception with message a string containing \"Parse error for build file\" and exception with message a string containing \"bar/BUCK\")\n[CONTEXT]      but: an instance of com.facebook.buck.json.BuildFileParseException <java.lang.RuntimeException: Unable to unpack pywatchman-archive.zip> is a java.lang.RuntimeException\n. TESTS FAILED: 2 FAILURES\nFailed target: //test/com/facebook/buck/parser:parser\nFAIL com.facebook.buck.parser.ParserTest\n[Tue, 06 Sep 2016 08:18:10] Step \"Testing with Buck\" failed with: Summary (beta): \nFAILURE com.facebook.buck.parser.ParserTest resolveTargetSpecsPreservesOrder[2]: Unable to unpack pywatchman-archive.zip\n[CONTEXT] java.lang.RuntimeException: Unable to unpack pywatchman-archive.zip\n[CONTEXT]   at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:140)\n[CONTEXT]   at com.facebook.buck.util.PackagedResource.access$000(PackagedResource.java:44)\n[CONTEXT]   at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:74)\n[CONTEXT]   at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:71)\n[CONTEXT]   at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:131)\n[CONTEXT]   at com.facebook.buck.util.PackagedResource.get(PackagedResource.java:81)\n[CONTEXT]   at com.facebook.buck.json.BuckPythonProgram.newInstance(BuckPythonProgram.java:96)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.getPathToBuckPy(ProjectBuildFileParser.java:616)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.buildArgs(ProjectBuildFileParser.java:251)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.init(ProjectBuildFileParser.java:207)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.initIfNeeded(ProjectBuildFileParser.java:192)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesInternal(ProjectBuildFileParser.java:353)\n[CONTEXT]   at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesAndMetaRules(ProjectBuildFileParser.java:342)\n[CONTEXT]   at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:117)\n[CONTEXT]   at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:107)\n[CONTEXT]   at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n[CONTEXT]   at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n[CONTEXT]   at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n[CONTEXT]   at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n[CONTEXT]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[CONTEXT]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[CONTEXT]   at java.lang.Thread.run(Thread.java:744)\nFAILURE com.facebook.buck.parser.ParserTest resolveTargetSpecsDoesNotHangOnException[2]: \n[CONTEXT] Expected: (an instance of com.facebook.buck.json.BuildFileParseException and exception with message a string containing \"Parse error for build file\" and exception with message a string containing \"bar/BUCK\")\n[CONTEXT]      but: an instance of com.facebook.buck.json.BuildFileParseException <java.lang.RuntimeException: Unable to unpack pywatchman-archive.zip> is a java.lang.RuntimeException\n. This message has one more level:\nFAILURE com.facebook.buck.parser.ParserTest resolveTargetSpecsPreservesOrder[2]: Unable to unpack pywatchman-archive.zip\njava.lang.RuntimeException: Unable to unpack pywatchman-archive.zip\n    at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:140)\n    at com.facebook.buck.util.PackagedResource.access$000(PackagedResource.java:44)\n    at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:74)\n    at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:71)\n    at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:131)\n    at com.facebook.buck.util.PackagedResource.get(PackagedResource.java:81)\n    at com.facebook.buck.json.BuckPythonProgram.newInstance(BuckPythonProgram.java:96)\n    at com.facebook.buck.json.ProjectBuildFileParser.getPathToBuckPy(ProjectBuildFileParser.java:616)\n    at com.facebook.buck.json.ProjectBuildFileParser.buildArgs(ProjectBuildFileParser.java:251)\n    at com.facebook.buck.json.ProjectBuildFileParser.init(ProjectBuildFileParser.java:207)\n    at com.facebook.buck.json.ProjectBuildFileParser.initIfNeeded(ProjectBuildFileParser.java:192)\n    at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesInternal(ProjectBuildFileParser.java:353)\n    at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesAndMetaRules(ProjectBuildFileParser.java:342)\n    at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:117)\n    at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:107)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n    at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n    at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.nio.file.NoSuchFileException: /tmp/junit-temp-path545007687376792998/buck-out/res/com.facebook.buck.json.BuckPythonProgram/pywatchman/pywatchman/__init__.py\n    at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n    at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n    at java.nio.file.Files.newByteChannel(Files.java:315)\n    at com.facebook.buck.io.ProjectFilesystem.newUnbufferedFileOutputStream(ProjectFilesystem.java:832)\n    at com.facebook.buck.io.ProjectFilesystem.newFileOutputStream(ProjectFilesystem.java:824)\n    at com.facebook.buck.zip.Unzip.extractZipFile(Unzip.java:97)\n    at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:125)\n    ... 21 more\n. This message has one more level:\nFAILURE com.facebook.buck.parser.ParserTest resolveTargetSpecsPreservesOrder[2]: Unable to unpack pywatchman-archive.zip\njava.lang.RuntimeException: Unable to unpack pywatchman-archive.zip\n    at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:140)\n    at com.facebook.buck.util.PackagedResource.access$000(PackagedResource.java:44)\n    at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:74)\n    at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:71)\n    at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:131)\n    at com.facebook.buck.util.PackagedResource.get(PackagedResource.java:81)\n    at com.facebook.buck.json.BuckPythonProgram.newInstance(BuckPythonProgram.java:96)\n    at com.facebook.buck.json.ProjectBuildFileParser.getPathToBuckPy(ProjectBuildFileParser.java:616)\n    at com.facebook.buck.json.ProjectBuildFileParser.buildArgs(ProjectBuildFileParser.java:251)\n    at com.facebook.buck.json.ProjectBuildFileParser.init(ProjectBuildFileParser.java:207)\n    at com.facebook.buck.json.ProjectBuildFileParser.initIfNeeded(ProjectBuildFileParser.java:192)\n    at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesInternal(ProjectBuildFileParser.java:353)\n    at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesAndMetaRules(ProjectBuildFileParser.java:342)\n    at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:117)\n    at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:107)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n    at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n    at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.nio.file.NoSuchFileException: /tmp/junit-temp-path545007687376792998/buck-out/res/com.facebook.buck.json.BuckPythonProgram/pywatchman/pywatchman/__init__.py\n    at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n    at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n    at java.nio.file.Files.newByteChannel(Files.java:315)\n    at com.facebook.buck.io.ProjectFilesystem.newUnbufferedFileOutputStream(ProjectFilesystem.java:832)\n    at com.facebook.buck.io.ProjectFilesystem.newFileOutputStream(ProjectFilesystem.java:824)\n    at com.facebook.buck.zip.Unzip.extractZipFile(Unzip.java:97)\n    at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:125)\n    ... 21 more\n. And the other test fails because a different underlying issue:\nFAILURE com.facebook.buck.parser.ParserTest resolveTargetSpecsDoesNotHangOnException[2]: \nExpected: (an instance of com.facebook.buck.json.BuildFileParseException and exception with message a string containing \"Parse error for build file\" and exception with message a string containing \"bar/BUCK\")\n     but: an instance of com.facebook.buck.json.BuildFileParseException <java.lang.RuntimeException: Unable to unpack pywatchman-archive.zip> is a java.lang.RuntimeException\nStacktrace was: java.lang.RuntimeException: Unable to unpack pywatchman-archive.zip\n    at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:140)\n    at com.facebook.buck.util.PackagedResource.access$000(PackagedResource.java:44)\n    at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:74)\n    at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:71)\n    at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:131)\n    at com.facebook.buck.util.PackagedResource.get(PackagedResource.java:81)\n    at com.facebook.buck.json.BuckPythonProgram.newInstance(BuckPythonProgram.java:96)\n    at com.facebook.buck.json.ProjectBuildFileParser.getPathToBuckPy(ProjectBuildFileParser.java:616)\n    at com.facebook.buck.json.ProjectBuildFileParser.buildArgs(ProjectBuildFileParser.java:251)\n    at com.facebook.buck.json.ProjectBuildFileParser.init(ProjectBuildFileParser.java:207)\n    at com.facebook.buck.json.ProjectBuildFileParser.initIfNeeded(ProjectBuildFileParser.java:192)\n    at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesInternal(ProjectBuildFileParser.java:353)\n    at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesAndMetaRules(ProjectBuildFileParser.java:342)\n    at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:117)\n    at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:107)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n    at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n    at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.nio.file.DirectoryNotEmptyException: /tmp/junit-temp-path604876482490844403/buck-out/res/com.facebook.buck.json.BuckPythonProgram/pywatchman\n    at sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:242)\n    at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)\n    at java.nio.file.Files.delete(Files.java:1077)\n    at com.facebook.buck.io.MoreFiles$3.postVisitDirectory(MoreFiles.java:193)\n    at com.facebook.buck.io.MoreFiles$3.postVisitDirectory(MoreFiles.java:176)\n    at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:224)\n    at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:69)\n    at java.nio.file.Files.walkFileTree(Files.java:2600)\n    at java.nio.file.Files.walkFileTree(Files.java:2633)\n    at com.facebook.buck.io.MoreFiles.deleteRecursivelyWithOptions(MoreFiles.java:201)\n    at com.facebook.buck.io.MoreFiles.deleteRecursivelyIfExists(MoreFiles.java:104)\n    at com.facebook.buck.io.ProjectFilesystem.deleteRecursivelyIfExists(ProjectFilesystem.java:740)\n    at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:116)\n    ... 21 more\n. And the other test fails because a different underlying issue:\nFAILURE com.facebook.buck.parser.ParserTest resolveTargetSpecsDoesNotHangOnException[2]: \nExpected: (an instance of com.facebook.buck.json.BuildFileParseException and exception with message a string containing \"Parse error for build file\" and exception with message a string containing \"bar/BUCK\")\n     but: an instance of com.facebook.buck.json.BuildFileParseException <java.lang.RuntimeException: Unable to unpack pywatchman-archive.zip> is a java.lang.RuntimeException\nStacktrace was: java.lang.RuntimeException: Unable to unpack pywatchman-archive.zip\n    at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:140)\n    at com.facebook.buck.util.PackagedResource.access$000(PackagedResource.java:44)\n    at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:74)\n    at com.facebook.buck.util.PackagedResource$1.get(PackagedResource.java:71)\n    at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:131)\n    at com.facebook.buck.util.PackagedResource.get(PackagedResource.java:81)\n    at com.facebook.buck.json.BuckPythonProgram.newInstance(BuckPythonProgram.java:96)\n    at com.facebook.buck.json.ProjectBuildFileParser.getPathToBuckPy(ProjectBuildFileParser.java:616)\n    at com.facebook.buck.json.ProjectBuildFileParser.buildArgs(ProjectBuildFileParser.java:251)\n    at com.facebook.buck.json.ProjectBuildFileParser.init(ProjectBuildFileParser.java:207)\n    at com.facebook.buck.json.ProjectBuildFileParser.initIfNeeded(ProjectBuildFileParser.java:192)\n    at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesInternal(ProjectBuildFileParser.java:353)\n    at com.facebook.buck.json.ProjectBuildFileParser.getAllRulesAndMetaRules(ProjectBuildFileParser.java:342)\n    at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:117)\n    at com.facebook.buck.parser.ProjectBuildFileParserPool$1.apply(ProjectBuildFileParserPool.java:107)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n    at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n    at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\nCaused by: java.nio.file.DirectoryNotEmptyException: /tmp/junit-temp-path604876482490844403/buck-out/res/com.facebook.buck.json.BuckPythonProgram/pywatchman\n    at sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:242)\n    at sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:103)\n    at java.nio.file.Files.delete(Files.java:1077)\n    at com.facebook.buck.io.MoreFiles$3.postVisitDirectory(MoreFiles.java:193)\n    at com.facebook.buck.io.MoreFiles$3.postVisitDirectory(MoreFiles.java:176)\n    at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:224)\n    at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:69)\n    at java.nio.file.Files.walkFileTree(Files.java:2600)\n    at java.nio.file.Files.walkFileTree(Files.java:2633)\n    at com.facebook.buck.io.MoreFiles.deleteRecursivelyWithOptions(MoreFiles.java:201)\n    at com.facebook.buck.io.MoreFiles.deleteRecursivelyIfExists(MoreFiles.java:104)\n    at com.facebook.buck.io.ProjectFilesystem.deleteRecursivelyIfExists(ProjectFilesystem.java:740)\n    at com.facebook.buck.util.PackagedResource.unpack(PackagedResource.java:116)\n    ... 21 more\n. You seem to have merged in a lot of commits from master by mistake.\n. You seem to have merged in a lot of commits from master by mistake.\n. You have failing tests.\n. You have failing tests.\n. I don't quite understand how the umbrella header support relates to supporting project generation for frameworks. If they are orthogonal features please split the PR.\n. I don't quite understand how the umbrella header support relates to supporting project generation for frameworks. If they are orthogonal features please split the PR.\n. What are the performance implications of this? If it's a non-trivial performance regression please add a .buckconfig option to disable this.\nAlso you need to rebase.\n. Is this still relevant or is it getting split up and resubmitted as part of the other changes?. Tests failing.\n. Seems ok, will import once you sign the CLA.\n. Seems ok, will import once you sign the CLA.\n. This should work correctly if you use buck project --build-with-buck.\n. This should work correctly if you use buck project --build-with-buck.\n. Please don't, that way leads to madness, and divergence of Xcode vs Buck builds.\n. cc @yiding, @asp2insp this is most likely related to the recent refactorings.\n. cc @yiding, @asp2insp this is most likely related to the recent refactorings.\n. Seems good, can you split it in two separate PRs: one for adding SwiftPlatform and related refactoring, and one for adding the version config.\n. cc @mkillianey \n. cc @mkillianey \n. Was already fixed, should sync to open source in a bit.\n. Was already fixed, should sync to open source in a bit.\n. Thanks for the quick response though!\n. Thanks for the quick response though!\n. c27128a7bf83c63750f4cf6b71d297ddbbec3f91\n. c27128a7bf83c63750f4cf6b71d297ddbbec3f91\n. cc @kageiit, @grumpyjames \n. It seems to me there isn't a big advantage to hiding Maven: many of the features would have a very specific mapping to the Maven features, and package managers for other languages might have different ways of implementing those features, or not having them at all.\nSupporting everything Maven supports would just mean all the information that can be specified in a Maven file could be specified in Buck's build files and then be used to generate the Maven file. I think that's the approach Bazel takes.\nI don't see that as hiding any implementation details, it's just being able to write the information in a python syntax rather than xml.\n. It seems to me there isn't a big advantage to hiding Maven: many of the features would have a very specific mapping to the Maven features, and package managers for other languages might have different ways of implementing those features, or not having them at all.\nSupporting everything Maven supports would just mean all the information that can be specified in a Maven file could be specified in Buck's build files and then be used to generate the Maven file. I think that's the approach Bazel takes.\nI don't see that as hiding any implementation details, it's just being able to write the information in a python syntax rather than xml.\n. cc @aiked, I thought this was changed to only use the Android toolchain if needed?\n. cc @aiked, I thought this was changed to only use the Android toolchain if needed?\n. cc @andrewjcg \nAccording to https://github.com/facebook/buck/blob/master/src/com/facebook/buck/cxx/Linkers.java#L40 we should be using -Wlinker when the argument contains ,, not -Wl.\nCan you add instructions on how to repro this?\n. cc @andrewjcg \nAccording to https://github.com/facebook/buck/blob/master/src/com/facebook/buck/cxx/Linkers.java#L40 we should be using -Wlinker when the argument contains ,, not -Wl.\nCan you add instructions on how to repro this?\n. Is this still relevant now that #917 has been merged?. cc @ilya-klyuchnikov \n. cc @ilya-klyuchnikov \n. Back to you for the rule split.\n. Rather than having CxxCreateArgFileStep and CxxCreateFileListStep encode so much information about the specifics of their use case, making them very unintuitive to use, merge them into a single class that is more reusable and behaves more like a normal step: don't delete the output before writing out the new one, and pass in an optional escaper to use.\nAlso you still have to address the issue of splitting SwiftCompile.\n. I mean add a step that takes a list of args, a path to a file and an optional escaper, and writes out the args to the file optionally using the escaper, and change the code to use this generic step instead of having the two new steps.\nThis should be done in a separate PR, then rebase this PR on that one.\n. It's fine to split it into two steps, I'm saying make it two instances of the same step class, instead of making two different step classes.\n. This looks good but is blocked on the test failure in #944.\n. Back to you to rebase after #944 lands.\n. Seems like it's not merging cleanly.\n. Thanks for the report, I will update the docs.\n. Thanks for the report, I will update the docs.\n. Thanks!\n. Thank you! \ud83d\udc36 \n. Thank you! \ud83d\udc36 \n. I put the PR back on your queue to respond to @JonShemitz's comment, since you have I'll restart the import.\n. Seems good, but split out the changes to remove the language and use the file extensions into a separate PR.\n. Buck was initially developed for use in a monorepo, and is still pretty biased towards it.\nWe currently use cross cell with a flat hierarchy of cells, so I'm not sure how well it works with nested cells, but at least in theory it should as long as each cell only refers to its child cells, and not other descendants or ancestors.\nIn your example repo, I applied this patch:\ndiff --git a/.buckconfig b/.buckconfig\nindex e69de29..612c65d 100644\n--- a/.buckconfig\n+++ b/.buckconfig\n@@ -0,0 +1,2 @@\n+[repositories]\n+names=ext/names\ndiff --git a/BUCK b/BUCK\nindex 9ebe9f4..c372eda 100644\n--- a/BUCK\n+++ b/BUCK\n@@ -1,5 +1,5 @@\n genrule(\n        name='reversed',\n-       srcs=['//ext/names:all'],\n+       srcs=['names//:all'],\n        out='reversed.names',\n        cmd='cat $SRCS | rev > $OUT')\ndiff --git a/ext/names/.buckconfig b/ext/names/.buckconfig\nindex e69de29..205fa39 100644\n--- a/ext/names/.buckconfig\n+++ b/ext/names/.buckconfig\n@@ -0,0 +1,2 @@\n+[repositories]\n+compiler=ext/compiler\ndiff --git a/ext/names/BUCK b/ext/names/BUCK\nindex 6fc3742..068beaa 100644\n--- a/ext/names/BUCK\n+++ b/ext/names/BUCK\n@@ -5,5 +5,5 @@ genrule(\n     name='all',\n     srcs=['a.names', 'b.names'],\n     out='all.names',\n-    cmd='$(exe //ext/compiler:compiler) $SRCS > $OUT',\n+    cmd='$(exe compiler//:compiler) $SRCS > $OUT',\n     visibility=['PUBLIC'])\nNow you can build it:\nlog-mbp:nested-buck coneko$ NO_BUCKD=1 buck build //:reversed --show-output\nNot using buckd because NO_BUCKD is set.\n[-] PROCESSING BUCK FILES...FINISHED 0.7s [100%] \ud83d\udc33  New buck daemon\n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...0.4s [0%] (0/1 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\n |=> //:reversed...  0.0s (checking local cache)\n |=> IDLE\n |=> IDLE\n |=> IDLE\nThe outputs are:\n//:reversed buck-out/gen/reversed/reversed.names\nlog-mbp:nested-buck coneko$ cat buck-out/gen/reversed/reversed.names\nxelA\nnitsuA\nnairdA\nlA\nkcuB\nylliB\nboB\npmurB\necniboB\nDoes this feature fit your needs?\n. Very nice!\n. Tests are failing.\n. Tests are still failing.\nCan you please run the tests locally before submitting the PR?\n. Restarting the job doesn't seem to be helping.\n. com.facebook.buck.crosscell.InterCellIntegrationTest.xCellCxxLibraryBuildsShouldBeHermetic is failing.\nDid it not fail for you locally?\n. Still getting FAILURE com.facebook.buck.crosscell.InterCellIntegrationTest xCellCxxLibraryBuildsShouldBeHermetic: Expected exit code 0 but was 1.:\n```\n[2016-10-14 06:58:44.875][warn ][tid:984][com.facebook.buck.event.listener.LoggingBuildListener] g++: no input files\n[2016-10-14 06:58:44.876][warn ][tid:984][com.facebook.buck.event.listener.LoggingBuildListener] BUILD FAILED: //:bin#binary failed with exit code 1:\nc++ link\nstderr: g++: no input files\n```\n. This wasn't on Travis, it was on our internal CI. I can't repro it either because I don't have gcc.\n. Are you sure you were using actual gcc and not the apple gcc that just calls clang?\n. cc @jkeljo, @asp2insp \n. Closing since it seems the initial issue has been solved. Create a new issue to discuss the code coverage being broken.. I'm not quite sure what is going on in the test, but as noted in the commit, you can pass\nvm_args = '-Djava.io.tmpdir=/whatever',\nto the java_test to change the temporary directory, maybe something other than /tmp will work? Or maybe it needs to be in buck-out?\n. What do you mean? Did you run the build in IntelliJ? Some classes are generated as part of it.\nIs there a specific instance of a class not being indexed even though you ran a successful build?\n. Buck running from source or from pex?\n. Buck running from source or from pex?\n. Are you sure? It's supposed to be looking at source.properties as well: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/DefaultAndroidDirectoryResolver.java#L49 .\n. I see, sounds good.\n. cc @shs96c \n. Oh sorry, I didn't even realise because we have realpath installed with brew.\n@aarongable Any idea here?\n. There's several things that don't work without combined preprocess and compile on clang, we're removing the other preprocessing mode as soon as possible, just use combined.. I don't think this will work: target node specs aren't generally equatable, and in particular the ones returned by CommandLineTargetNodeSpecParser are TargetNodePredicateSpec with lambdas as predicates so they'll never be equal.. #1019 might help with this.. buck build supports --show_output as well.\nIs that acceptable?. buck build supports --show_output as well.\nIs that acceptable?. Yes hg style aliases are something we've always wanted, alas they're always bumped back by some more important work.\nChanging the output of --show-output is something we could gate behind a config setting.. Yes hg style aliases are something we've always wanted, alas they're always bumped back by some more important work.\nChanging the output of --show-output is something we could gate behind a config setting.. Thanks!. Thanks!. Tests are failing since they weren't updated to reflect the changes.. Tests are failing since they weren't updated to reflect the changes.. Oh this is very nice, thanks!. This won't work on BSDs though because -r is a gnu extension.. Thanks for pushing this forward @davido !. So excited for this! Will look after the changes split out of it have landed.. There is a build failure in smart dexing step.. I've imported the fixes to the issues detected with error prone, and I've verified it works correctly on our CI.\nI'm not convinced we want to bundle error prone with Buck for consumers.\nTaking a step back can we fix whatever issue you hit when trying to specify the error prone compiler to be a remote_file from maven?\nOrthogonal to that having Buck itself be built using error prone is nice, so if you want you can change this PR to do that instead. I've had to edit the project to make it work in IntelliJ though, and I've deleted the 2.0.17 jars you've left in.\nAlso even when the Buck build is configured to use error prone the ant build isn't, would be better to have that one reflect the change as well so they don't disagree.. Assuming this will be merged from the fork together with the rest of the changes, closing for inactivity.. //test/com/facebook/buck/rules:rules - inputBasedRuleKeyCacheHitAvoidsBuildingLocally is failing.. It's slated to be removed, and infer will integrate through the cxx compilation database.. In general using infer is done through the infer command line tool, one would never invoke the Buck infer integration directly.. Nope, but it can be made an Either<SourcePath, String>.. You can use prefix_header to specify the prefix header. I guess it's not documented either.. Correct, tests will build using Xcode even when using --build-with-buck, so if the build is set up correctly only for Buck, they won't work, but you can run them on the command line.. I believe this has been merged internally.. It's not faster than Xcode on a single machine. You need to use the distributed cache for Buck to be faster.. It's not faster than Xcode on a single machine. You need to use the distributed cache for Buck to be faster.. That's because you're adding the same headers both to headers and exported_headers. Each header can only be in one of the two at the time.. That's because both https://github.com/facebook/buck/blob/master/test/com/facebook/buck/apple/testdata/simple_app_with_extension/DemoExtension/Info.plist#L10 and https://github.com/facebook/buck/blob/master/test/com/facebook/buck/apple/testdata/simple_app_with_extension/Info.plist#L10 are com.example.DemoApp, the second one should probably be com.example.DemoAppExtension or something like that.\nFeel free to send a PR.. What files are in /Users/FSF/Library/Developer/CoreSimulator/Devices/31479CE8-5233-4EAE-8D1A-AD7666A58A64/data/Library/Caches/com.apple.containermanagerd/Bundle/Application/E89580FD-0757-467D-BE37-8E33B6FD3DA2/DemoAppWithExtension.app/PlugIns/DemoExtension.appex/? It should be looking for a DemoExtension file there, not DemoApp. You need to update the Info.plist to reflect that.. You might be using a version of Buck that is too old: try to build Buck from master and use that.. See https://buckbuild.com/function/include_defs.html .. You can specify multiple includes as a space separated list:\n[buildfile]\nincludes = //A //B. Is your android NDK installed and configured correctly? Is the $ANDROID_NDK environment variable pointing to it? Is the version of the ndk specified in .buckconfig the correct one?. Does the same issue happen on master?. cc @sdwilsh . Did you write the BUCK files yourself or did you use OkBuck?. Did you write the BUCK files yourself or did you use OkBuck?. If you wrote them yourself can you upload a small repro project?\nIf you used OkBuck can you open an issue ok OkBuck and figure out if it's an issue with the generation of the build files?. If you wrote them yourself can you upload a small repro project?\nIf you used OkBuck can you open an issue ok OkBuck and figure out if it's an issue with the generation of the build files?. You mean it's a regression? Can you bisect to find out where it was introduced?. This failed the lint:\n```\nsrc/com/facebook/buck/parser/DaemonicParserState.java\nError   (com.puppycrawl.tools.checkstyle.checks.whitespace.FileTabCharacterCheck) at line 233\ntest/com/facebook/buck/testutil/MoreAssertsTest.java\nWarning (ANTPMDEmptyCatchBlock) Empty Code at line 33\n``. Are you sure that's all you have in your target? That error happens when you specify the same header inheadersandexported_headerstoo I think.. Sorry it's not documented because it's not supported and we're planning on removing it.. Did you setcheck_package_boundary` to false?. cc @nguyentruongtho . Travis is still red after the latest update, I see some timeouts still happening.. Latest run's failures don't seem to be any of the usual ones, and might in fact be a legit failure that was never noticed because Travis was always red anyway.\nImporting.. Approximate translation:\nChanges to a public static final String are not being reflected in the built APK.\nCan you post a a github repo with a repro? Are you using buckd?. Can you explain what this change is for?. cc @dreiss, @cjhopman . This seems like it's the dx invocation running out of memory, not Buck.\nAre you sure you set the max_heap_size setting correctly? Buck will not fail if you have a typo or put it in the wrong section.\nhttps://buckbuild.com/concept/buckconfig.html#dx.max_heap_size. Sorry, the thrift target types have been removed recently (7f1fc34d28b6a76813279d751b5cb243398519f2).\nTo ease migration, you can update to fed2a70b17025de19aa8d2bbf3bb120b9a432c9d and set the project.thrift_target_types_enabled setting to false in .buckconfig.\nIf you use thrift in your project you can implement the thrift target types with genrule.. Sorry we're not adding them again, we implemented them in build defs in our repos where we use thrift.\nI don't know if we can easily post them anywhere, @andrewjcg ? Maybe even in a non-working state as a reference implementation?. Sorry we're not adding them again, we implemented them in build defs in our repos where we use thrift.\nI don't know if we can easily post them anywhere, @andrewjcg ? Maybe even in a non-working state as a reference implementation?. cc @andrewjcg, @yiding. cc @yiding . It's not documented but the build.allow_empty_globs setting does exactly that.\nYou can set it in your .buckconfig as:\nini\n[build]\nallow_empty_globs = false. You can set the credentials for maven here: https://buckbuild.com/concept/buckconfig.html#credentials but I don't think you can set them for the proxy.. You will need to change the Buck code to support it.\nThe code lives here: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/cli/DownloadConfig.java#L36 .. cc @asp2insp . Merging directly without importing since it's not on master.. This usually means you need to run ant clean and rebuild Buck from scratch.\nDoes this happen if you use Buck built with Buck?. This usually means you need to run ant clean and rebuild Buck from scratch.\nDoes this happen if you use Buck built with Buck?. Should be fixed in 8617a746f2cce396bf3e11f5d9a41869fdd3cb30.. You can generate the AndroidManifest.xml file from a genrule and do whatever you want as far as I can tell: https://buckbuild.com/rule/genrule.html\nAlternatively this might be what you are looking for: https://buckbuild.com/rule/android_binary.html#manifest_entries. You can generate the AndroidManifest.xml file from a genrule and do whatever you want as far as I can tell: https://buckbuild.com/rule/genrule.html\nAlternatively this might be what you are looking for: https://buckbuild.com/rule/android_binary.html#manifest_entries. Oh I just noticed it's not documented: manifest_entries can contain a placeholders value, which is a map of placeholder names to placeholder values.. Oh I just noticed it's not documented: manifest_entries can contain a placeholders value, which is a map of placeholder names to placeholder values.. You can run https://github.com/google/google-java-format on the files to format them automatically and remove spurious unrelated changes.. It was merged as 800d5a9669417d5a8b4bc455e34a629422ed1ff1.. Thanks for letting us know!\nI don't remember the specifics, but I remember something similar was brought up before.\nUnfortunately we're deprecating the self-building feature of Buck in favour of using the built PEX, so we probably won't be looking at this, sorry.. Thanks for letting us know!\nI don't remember the specifics, but I remember something similar was brought up before.\nUnfortunately we're deprecating the self-building feature of Buck in favour of using the built PEX, so we probably won't be looking at this, sorry.. The jars are added as a resource, see https://github.com/facebook/buck/blob/master/programs/BUCK .. The jars are added as a resource, see https://github.com/facebook/buck/blob/master/programs/BUCK .. If you rebase on master Travis should go green.. If you rebase on master Travis should go green.. Have you increased the open file limit on your machines? I assume this is on macOS machines, which has an extremely low value as the default.. Have you increased the open file limit on your machines? I assume this is on macOS machines, which has an extremely low value as the default.. What is the command you are running? This might only work if you explicitly run buck build target#linux-x86_64.. What is the command you are running? This might only work if you explicitly run buck build target#linux-x86_64.. I don't know, depends on whether it works if you expand it manually. If it doesn't it could be another issue.. I don't know, depends on whether it works if you expand it manually. If it doesn't it could be another issue.. Yep, then it's what I mentioned above.\ncc @andrewjcg, @Ktwu was either of you two looking at this?. Yep, then it's what I mentioned above.\ncc @andrewjcg, @Ktwu was either of you two looking at this?. cc @mzlee as well.. cc @mzlee as well.. I believe this is related to the fact google has changed how the NDK and SDK identify versions several times: both in how to find the version string, and how the version string is to be interpreted.\nIdeally we'd have the users specify what version is installed where in the config, rather than doing the whole find installed versions ourselves voodoo, but that is probably not happening anytime soon.\ncc @aiked, @marcinkosiba . I believe this is related to the fact google has changed how the NDK and SDK identify versions several times: both in how to find the version string, and how the version string is to be interpreted.\nIdeally we'd have the users specify what version is installed where in the config, rather than doing the whole find installed versions ourselves voodoo, but that is probably not happening anytime soon.\ncc @aiked, @marcinkosiba . cc @dinhviethoa. cc @dinhviethoa. This is a known issue but I don't know what our plans for this are.. This is a known issue but I don't know what our plans for this are.. CI fails.. CI fails.. Still failing. If you rebase on master the go test will be fixed.. Still failing. If you rebase on master the go test will be fixed.. Still failing.. Still failing.. Appveyor should be green on master, but yeah the failure doesn't seem related.\nThis one on the other hand:\nFailed target: //test/com/facebook/buck/maven:maven\nFAIL com.facebook.buck.maven.PublisherTest. Appveyor should be green on master, but yeah the failure doesn't seem related.\nThis one on the other hand:\nFailed target: //test/com/facebook/buck/maven:maven\nFAIL com.facebook.buck.maven.PublisherTest. There's no tests and the package name is weird, but we can fix both up after the initial merge if you're up for that.\nI'll be working under the assumption that if they languish I'll revert the whole thing.. There's no tests and the package name is weird, but we can fix both up after the initial merge if you're up for that.\nI'll be working under the assumption that if they languish I'll revert the whole thing.. This looks like an empty commit, not sure what is going on, I assume you were testing the PR flow.. cc @milend . cc @robbertvanginkel . This took so long to try to land that it got subsumed by the automated refactor.. cc @mzlee . Sorry I'm waiting for some extra telemetry to land internally so we can benchmark this change easily.. Didn't see any big changes on our side, would this address only certain builds?\nAlso I notice there's other JVM args we pass to the buckd invocation but not the invocation without the daemon, should we apply those as well by factoring them out?. cc @mzlee . You can also use sh_binary which is undocumented, it has support for resources.\nYou can use it to wrap the cxx_binary, and run it via buck run.. There's merge conflicts and the builds are failing.. There's merge conflicts and the builds are failing.. Going to close this for inactivity.. Update when ready.. Update when ready.. cc @andrewjcg . Try buck build target#compilation-database.. What do you mean doing a full build? That command will only build the necessary things to make the compilation database meaningful, like generated headers and sources, header maps, symlink trees and sandboxes.\nYou won't be able to create the right clang translation units without them.\nWe used to have a way to create almost equivalent commands skipping many of the steps, but the \"almost\" part of the equivalence meant there were always subtle differences between what our tooling thought the build would be and what the actual build was so we got rid of it.. Mapdb is being removed so we don't need to worry about that.. cc @dreiss @cjhopman . Have a look at the AppVeyor test results, not the Travis. The Travis ones have a couple of issues that should be fixed on master with 00be6ede4e1e584be5cbbf57160781c3778989fd, so if you rebase that might help as well.\nAnyway the kotlin tests are hitting null pointer precondition checks so I don't think it's a CI infrastructure issue.. You can create a single file executable of it by first building it with ant and then running buck build buck --show-output.\nThe resulting file is a self extracting python executable package (https://github.com/pantsbuild/pex).. The idea was to expose the tests' rule keys in the json file passed to the external test runner, so that the external test runner could use them to figure out whether the test was the same as a previous test run or not.\nI'm not sure if it was ever implemented, I haven't worked on the project in a while.\nYou might still be able to call NO_BUCKD=1 buck targets --show-rulekey <target> in your external test runner to get the rule key.\nNote that assuming the same rule key means the test results are going to be the same isn't correct though, and it's the reason test caching was removed: test results can be affected by external factors that buck wouldn't know about, especially if they're integration tests.. cc @dsyang @brettwooldridge . You can specify the inputs to the genrule using $(location ) macros as explained here: https://buckbuild.com/function/string_parameter_macros.html.\nSo for example if you want to copy a bunch of files you can put cp $(location :file1) $OUT && cp $(location :file2) $OUT or something like that.. Note that due to Buck's caching model, thinking of when targets are being run or executed and how to control that using dependencies doesn't map intuitively to how it actually works. It's simpler if you think of inputs and outputs.\nThis is one of the reasons we removed deps from genrule: some users were used to the task based mental model that other build systems use, for example ant, and were using genrules with deps to replicate that but then hitting all sorts of issues with the caching.\nThe location macros make it much more explicit that you're passing the output of certain rules as inputs, so it's less surprising when the output is retrieved from cache and the genrule is never executed.. cc @jkeljo . Done in efd09fbf184be90fdbe01eb93ab2cc7e4274420e.. Yeah it seems to be a bug in AppVeyor: the docs say if the appveyor.yml the web UI settings are ignored, but it's clearly reading from the web UI.. It should be using check_output from here: https://github.com/facebook/buck/blob/master/programs/subprocutils.py#L19.. cc @yiding . Answered on SO.. @dsyang Sorry won't be able to either. @dinhviethoa ?. @dsyang Sorry won't be able to either. @dinhviethoa ?. I'm not sure how Java handles this by default, but normally .+ would match greedily, so any file starting with build. would be matched.\nI think you might need build\\\\..+?\\\\.trace.\nJust to be sure can you add a test to check it won't match a file called build.log?\n. --all is still used.\n. Throw a HumanReadableException if b isn't a GoLinkable, so the user sees something like \"go_binary deps must contain only go_binary or go_library targets\" instead of \"class cast exception 20 lines of stack trace\" if they try to depend on something that isn't GoLinkable.\n. We usually do this kind of visiting logic in the description, then pass the results of the visiting to the BuildRule's constructor.\n. No need for this.\n. As above this kind of logic is usually in the description.\nSince this would be shared between the binary and library descriptions you can extract it into a static method in a GoDescriptions class.\n. This is how we used to add resources in the past, now we specify them in resources in the java_library in the BUCK file.\nSee build-with-buck.st for example.\n. When we need generated build targets we use the existing target and add flavours to it.\nYou should not change the base path or name, as there is no way to guarantee the user hasn't named a directory or a target with that name.\n. One argument per line.\n. One argument per line.\n. Can we use the upstream file? That makes it easier to merge in updates from upstream.\n. Don't add sourceUnderTest, instead add tests to go_library and go_binary.\n. Don't implement HasSourceUnderTest.\n. Ah, I see, we don't have a namespace reserved for generated targets, but maybe we should.\nOne thing is that it's a bit confusing to have a target show up out of nowhere.\n@shs96c Any opinions on this?\n. No that's fine. Just copy the license header from there, add it after the Facebook Apache 2 license:\n// Copyright 2011 The Go Authors.  All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\nAnd copy the LICENSE file into the same directory, and add it as a resource to the java_library.\n. I think this shouldn't append anything to the rule key.\n. This shouldn't use JavacOptionsAmender.RULE_KEY_NAME, it should use its own key.\n. Don't add the code for supporting flavours since it doesn't have any flavours yet, add it when you add the first flavour.\n. These three environment variables aren't necessary, you can remove them.\n. Remove this comment as well.\n. Functions.toStringFunction()\n. Functions.toStringFunction()\n. You should use a MacroHandler to support macros in here.\nYou can do that in a separate PR.\n. Remove sourceUnderTest. I assume you mirrored java_test's interface, but this particular part of it causes issues in practice so we don't want to add it to new types of test targets.\n. You don't need to add test to the resolver since you're returning it from createBuildRule, it will get added by https://github.com/facebook/buck/blob/master/src/com/facebook/buck/rules/TargetGraphToActionGraph.java#L99.\n. Just noticed JavaTestDescription does the same thing, maybe there's a reason why it's like that, maybe there isn't, try to not add it and if you see any issues that might be it.\n. Yeah sounds good. I figured there was a reason for that I just didn't know what.\nLeave it like this for now.\n. Yeah you can see the newer apple_test does not support it either: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/apple/AppleTest.java#L202-L207\nI'm not sure what the plan for java_test is but we definitely don't want to add it to new *_test rules.\nInstead you should specify tests in *_library and *_binary.\n. We are the sources filtered at this stage? They should be sorted much earlier so we don't end up rebuilding stuff when sources that don't contribute change.\nWhy would it even be possible to specify sources that don't get compiled?\n. Can you add a check for the connection being HTTPS? Sending passwords in clear text sounds pretty wrong.\n. You need to specify these as immutable_srcs for autodeps to work correctly.\n. Should be ok as is, I don't think it's an error to have that.\n. Also check that the connections is an instance of https://docs.oracle.com/javase/7/docs/api/javax/net/ssl/HttpsURLConnection.html .\n. I love this, can you move it to https://github.com/facebook/buck/blob/master/src/com/facebook/buck/rules/BuildRuleResolver.java#L74 so we get this by default in all descriptions that implement MetadataProvidingDescription?\nActually let's go one step further: let's do it for all descriptions regardless of whether they implement MetadataProvidingDescription or not, as it's completely general.\nCan you do it in a separate PR though?\n. Can you replace this traversal with requireMetadata as well? You might need to add a recursive component where every description returns the transitive set of GoLinkable that target depends on.\n. Why is this extra check necessary? If getFlags doesn't return an empty list for an empty key maybe it should return an optional, or have a precondition check that the key is not empty.\n. I think you can break here: if they're ordered alphabetically if any string doesn't start with the prefix, any string following it won't start with the prefix either.\n. I get that part, but that's the outer loop right? The inner loop is comparing a candidate, for example a/vendor, with all the paths.\nI'm saying that if you start alphabetically by using tailSet you can also stop alphabetically by using break:\na/b\na/b/c\na/vendor <= tailSet makes you start here\na/vendor/t\na/vendor/u\na/x <= break makes you stop here\na/y\na/z\n. This doesn't seem necessary.\n. This isn't doing anything: you don't have any .expected files in your test data.\n. Add some asserts on where the generated project, workspace and schemes should be.\n. I can confirm.\n. It's missing a space here, I'll add it.\n. You can delete these two lines, we don't leave commented out code in.\n. The indentation makes it look like rootPath is the third argument of Linkers.iXlinker instead of String.format.\nMove each argument to String.format on its own line.\n. Why this change?\n. Why this change?\n. Since this is the only difference between this case and the linux case, can you extract the common parts?\n. I meant the part after this note was in common. I can't highlight multiple lines in line notes on github, sorry if it was confusing.\nI don't think you should rename the two constants to have the same name even though they have the same value.\n. How does this work? I assume it's for removing it from the path, but I can't find any reference for the syntax.\n. Why is this necessary?\n. ant is complaining that you're casting to a parametrised type without specifying the parameter.\n@SuppressWarnings(\"unchecked\") will let you cast to any parameter, but you still have to provide one.\nStill, I don't understand how this is supposed to work: you're passing a list of callables instead of a list of futures?\n. Sorry I still don't understand how this works: why can you call Futures.allAsList on a list of callables?\n. Oh I see, sorry I must have been blind.\n. As noted in the other PR this shouldn't be changed.\n. This also changes the default behaviour.\n. I think this shouldn't change the parser: if you wish to make changes to how the graph is interpreted they should be done in the target graph to action graph transformation phase, not in the parser.\nAn alternative would be to make the transformation in the repo's build files through common include_defs helpers.\n. No need for the or here, the coercer will map an absent to an empty list: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/rules/coercer/ListTypeCoercer.java#L39 .\n. Same as above, no need for the or.\n. You're missing pathResolver.filterBuildRuleInputs(javacOptions.getInputs(pathResolver)) like in https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/JavaLibraryDescription.java#L148 here.\n. You need to sourcePathResolver.getAbsolutePath(source.getSourcePath()) here, like above in filterSwiftSources.\nIn fact since it's the same, extract the common logic.\n. No, the coercer is used by the caller of createBuildRule, so the args object here will have already gone through it.\n. Oh I see, KotlinTestDescription has that as well so I thought it was needed here.\n. The report generator is really self contained, it would be nice to be able to keep it that way.\n. Oh I see, ok.\n. srcs can contain BuildTargetSourcePath: it can refer to files that are outputs of other rules, for example when using genrule to generate sources.\n. I think the approach of always having a fake swift placeholder rule, and just having it do nothing if there are no swift sources, which you used in the previous commit was good.\n. Good points about the project generation. halide_library used to implement findDepsForTargetFromConstructorArgs in a similar way but then we removed it because it was adding complexity for nothing.\nThe dependency on the placeholder swift library can be added in createBuildRule, findDepsForTargetFromConstructorArgs just makes it easier to add, but the additional complexity down the line is not worth it.\nCan you change AppleLibraryDescription.createBuildRule and AppleBinaryDescription.createBuildRule to do that and remove the changes to findDepsForTargetFromConstructorArgs?\n. Note you can use requireRule and the swift-library flavour to get the rule you need, which will go through the same code path as returning the target with that flavour from findDepsForTargetFromConstructorArgs: the only thing that changes is where you add the rule as a dependency, not how you get the rule.\n. I don't think we should ever hit this code path.\n. Revert the whitespace change, one argument per line is the correct formatting.\n. We take the output of the compilation and pass it as an input to the linking in cxx, is there a particular reason for this pattern of delegating the build steps here?\n. Change this to return the args instead of passing in a builder to add them to.\n. Add this method to Linker.LinkableDepType instead of here.\n. The runtime should be flags added to the link, not a NativeLinkable.\nSee CxxPlatform.getRuntimeLdflags().\n. Why this?\n. You can add the method for getting the flags to AppleCxxPlatform and pass them in from SwiftLibraryDescription.\n. The pseudo build target is a problem.\nHow was using the native linkable solving the duplicate flags before they were all using the same pseudo build target?\nWould adding the flags at the binary level work? Although that's going to introduce a massive dependency cycle cxx -> swift -> apple -> cxx.\nAlternatively can we create a type of NativeLinkable that doesn't have a build target? But then how do you identify it to deduplicate it?\nStill thinking about this.\n. I think adding the flags at the binary level would work, and be the best way to do this.\nWe could discover them using requireMetadata, no need to make it a generic mechanism, just find out if any of the dependencies need a swift runtime.\nDo you think it would work?\nGiven that it's a complex undertaking I don't mind it being done in a different PR and merging this one as is, assuming it is a good idea.\n. constructModel already called merge up there.\n. This method is massive, is there really no method in the library to do this?\n. You should use BuildTargets.getGenPath here.\n. This means that configs ends up not having defaultConfig in them, is that intentional?\n. We use assertThat as much as possible so that the failure print outs are consistent.\n. Also note that changing them to assertEquals without flipping the arguments is wrong: assertEquals's order is expected, actual. That's quite unintuitive and another reason we use assertThat.\n. Why is this necessary?\n. This doesn't need to be final, I assume it's a leftover from some earlier version of the code.\n. All the other scala integration tests have increased timeouts because of how long they take on CI. Adjust these accordingly as well.\n. Please extract this change to a separate PR.\n. Use separate output directories. If you need them all in the same directory you will need to create a symlink view of them.\n. This comment seems stale, the PR was merged.\n. --dry-run doesn't work.\n. I think you should be able to change this to ./bin/buck test --num-threads=$BUCK_NUM_THREADS //... to have it resolve all the tests attributes.\n. This doesn't need to be a separate build rule, it can be a step in the compilation rule, at least that's how we do it in all other cases.\n. It's really strange to have the rule behave so differently based on whether it has a source or not, can you split this into two rules?\n. I did, but it had to be reverted, I forgot to remove the docs again, let me do that.\n. Is this going to work for build target source paths?\nIf so, then absolute paths would be in the file list, so it shouldn't be cached (see https://github.com/facebook/buck/blob/master/src/com/facebook/buck/rules/SymlinkTree.java#L198-L205 for example).\nIf not, it should.\n. I see, makes sense.\n. Seems good, but you don't need to create a temporary variable for the return value, can inline it?\nLike\nif (openPtyLibrary.openpty(master, slave, Pointer.NULL, Pointer.NULL, Pointer.NULL) != 0) {\n  throw new RuntimeException(\"Failed to open pty\");\n}\n. Same as above.\n. Hmm, revert it from this PR, and open a new PR for this, we can figure out what is going separately.\n. Instead of removing them outright, make them conditional on os being darwin.\n. 2016\n. 2016\n. It's really strange that this filters out the file list args.\n. No other step deletes its output before writing it, remove this.\n. Same as above.\n. Same as above.\n. You're right, that's already a problem.\n. Still have to break this one per line.\n. One per line.\n. One per line.\n. Do we check this assumption anywhere? If not, we should, and throw a HumanReadableException that explains what is wrong.\n. You need to maintain this functionality though. Move it into CxxLink by adding a new RmStep there.\n. I don't think this needs to be configurable at the tool level: a global configuration option in .buckconfig for migration purposes is ok, but generally worker tools should be safe to persist across multiple commands anyway.\nFrom the tool's perspective there is no difference between being persisted or not.\n. Nice catch!\nCan you split this out in a separate PR?\n. Please split out these changes in a separate PR.\n. Why?\n. Seems like a good change, but please pull it out into a separate PR.\n. What is this change for?\n. Make a separate PR just for this then.\n. But why do you need to wrap it in an IOException?\n. I'm just not sure we guarantee we will run the tools only once with certain inputs during the build to begin with, for example consider a multi platform build.\n. There are other mechanisms that create multiple rules for each target.\nI'm not sure what caching you're thinking of, but in general as long as the executions of the worker process are deterministic everything will be fine regardless of whether they survive across runs or not, and if they're not then we're going to have problems even if they are kept around just one run.\nNote that one run is not the same as one build. For example project generation already executes multiple builds I think.\n. Please compose a single message with all the lines, separated by newlines, and call LOG.error with that.\nTruncate if it's too long, might be worth extracting https://github.com/facebook/buck/blob/master/src/com/facebook/buck/util/ProcessExecutor.java#L462, or even the method that is calling it to format the whole error message.\n. We can leave it a non default for now, but the exact semantics of what executions are going to be done in a single build seem very implementation specific, and not something you can rely on.\nIt really sounds like something that just happens to work right now and could break at any moment.\n. It's weird to have a switch statement with only one case to begin with, change it to an else if instead.. Is the cast here still necessary?. I'm confused by the existing code: it only catches IOException, but then only rethrows unchecked exceptions which IOException is not.\nIt seems it's a mistake in the guava 20 update: it should have added a throw new RuntimeException(e) here.\nI see that's what the new code does, so that's all right, ignore me.. You probably meant prebuilt_apple_framework here.. The link should point to prebuilt_cxx_library.. An Apple framework, not a bundle.. When does this happen?. Rather than accessing the field after the instanceof check add a isAlive method to LaunchedProcess.\nIt's possible the method won't be necessary on the executor at that point.. Sorry ant lint doesn't run google-java-format.. Why this change?. Why this change?. I remember the reason we cached these is that it took so long to install them it would cause jobs to time out.. ",
    "mkurutin": "The same issue here. After following Quick Start instructions and running 'buck project' IntelliJ 12 complains about missing project SDK as well as project output directory.\n. ",
    "jeromeernestgarcia": "I found the workaround for me was to create a directory like the following:\nFP143:17.0.0 jeromegarcia$ pwd\n/Users/jeromegarcia/android-sdk-macosx/build-tools/17.0.0\nFP143:17.0.0 jeromegarcia$ ls -l\ntotal 3888\n-rwxr-xr-x  1 jeromegarcia  staff  1209064 May 22 10:22 aapt\n-rwxr-xr-x  1 jeromegarcia  staff     2603 May 22 10:24 dx\n-rw-r--r--  1 jeromegarcia  staff   771584 Apr  8 10:07 dx.jar\n. Thanks for the quick response and fix. Mine was just a workaround not a fix.\n. Any given module could be compiled for Android or for J2SE. Currently we have an Android directory for Android specific source, a common directory for Java code that can run on anything, and a J2SE directory that has J2SE versions of the code that is in the Android directory. Buck encourages all the code to live in one tree, but having different platform builds complicates that. Is there a best-practices way to organize code of this sort in the buck environment?\n. Ok. Thanks for the quick response.\n. ",
    "jasone": "Buck now requires Java 7 to build.  I'm guessing that you're using an older version.\n. ",
    "dpursehouse": "Note: corporate CLA has been approved and is pending formal signing.\n. The Corporate CLA has been signed, but now I still have to wait for the legal dept to approve this patch :(\n. @bolinfest the CLA is signed by Sony Mobile but I still need to get approval from the parent Sony legal department for each individual contribution.\n. We got legal approval, so this is good to go (if you want to take it).\n. Ping...\n. Thanks for the detailed reply.\nI didn't expect the CLA process to take so long, otherwise I would've just\nsubmitted a bug report like you suggest.  I'm not even going to try to\ncalculate how much effort I spent writing reports and emails compared to\nactually doing the patch...\nHopefully I will be able to contribute more now the CLA is out of the way.\n. BTW can you confirm that you've actually received the signed CLA?\nAnd if so, is this patch likely to be accepted?\n. It seems this change has been taken in with commit 3d9ff36846795c1ea92156f9455fed2035869d2f but the author was changed.  What's going on?\n. For the record:  my question in the previous comment has been answered in the comments on 3d9ff36846795c1ea92156f9455fed2035869d2f.\nClosing this pull request.\n. The corporate CLA is already signed by Sony Mobile and I should be included in the list of allowed committers.\n. Actually, I've just realised there's a mistake in the commit message.  Please hold off until I rewrite it...\n. Thanks!\n. You can do:\n:+1:\nSee here: http://www.emoji-cheat-sheet.com/\n. Thanks for the suggestions.\nUsing .nobuckcheck is unfortunately not an option as the different branches of Gerrit do have dependencies on the different versions of buck.\nCurrently I am working on 3 branches, each of which uses a different version :(\nI'll see if I can make a script that will automatically set symlinks based on which branch is checked out.\n. Thanks for the suggestions.\nUsing .nobuckcheck is unfortunately not an option as the different branches of Gerrit do have dependencies on the different versions of buck.\nCurrently I am working on 3 branches, each of which uses a different version :(\nI'll see if I can make a script that will automatically set symlinks based on which branch is checked out.\n. @shs96c @bolinfest any chance that this can be merged?\n. @shs96c @bolinfest any chance that this can be merged?\n. Thanks!\n. I can't see any way to restart the travis build.\n. It's not necessary to explicitly give the --all option because it's now the\ndefault.\nI forgot to mention this change in the commit message.\nOn Fri, 13 Feb 2015 20:20 Coneko notifications@github.com wrote:\n\nThanks! [image: :baby_chick:]\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/pull/253#issuecomment-74239486.\n. It's not necessary to explicitly give the --all option because it's now the\ndefault.\n\nI forgot to mention this change in the commit message.\nOn Fri, 13 Feb 2015 20:20 Coneko notifications@github.com wrote:\n\nThanks! [image: :baby_chick:]\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/pull/253#issuecomment-74239486.\n. Doesn't look like the build failure is anything to do with this change...\n. Doesn't look like the build failure is anything to do with this change...\n. Aha, yes, that works.  Thanks.\n\n:facepalm:\n. Aha, yes, that works.  Thanks.\n:facepalm:\n. @sdwilsh thanks for the feedback.  I think t-w-r is OK for the first IndentingWriter because the underlying stream is also created in the same method and only used there.  For the other two, I've undone the change in the reworked version and added suppressions instead.\n. Thanks @davido that fixes it.  I'll close this issue.\n. Thanks @shs96c. I've reopened this issue.  When your fix lands I'll upgrade to that version instead of 60a2969. We're currently trying with f2f6d86ba1de544e7fd825a8a6cafe258512a7e4 plus @davido's workaround.\n. I can confirm that it now works as expected.\nThanks for the quick response and fix.\n. > I think @dpursehouse already added this feature request.\nYes. See #102.\n. Thanks. Adding vm_args fixed it.\n. Thanks. Adding vm_args fixed it.\n. /CC @davido \n. /CC @davido \n. Thanks for the investigation @davido ; It would be good if we could put this in the .buckconfig file, but might be difficult since the location of the runtime library isn't going to be the same for everyone.\n. ",
    "BruceZu": "Cool!\n:-)\nAll my time today is cost on setting up temp Gerrit server as local user requirement :(\n/Bruce\nSent from my Sony Xperia\u2122 smartphone\nDavid Pursehouse notifications@github.com wrote:\nNote: corporate CLA has been approved and is pending formal signing.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/pull/32#issuecomment-18666766.\n.  \u201c I don't want to document it on http://facebook.github.io/buck/ until I get some external confirmation that this is the right way to go.\u201d\n@bolinfest\uff1aIs it the time to document it?\n.  \u201c I don't want to document it on http://facebook.github.io/buck/ until I get some external confirmation that this is the right way to go.\u201d\n@bolinfest\uff1aIs it the time to document it?\n. back-out should be the default value of ignore_dirs without need user config it explicitly.\n/Bruce\nSent from my Sony Xperia\u2122 smartphone\n---- David Ostrovsky wrote ----\nLet's list buck-out in .watchmanconfig in its ignore_dirs then [1].\n[1] https://gerrit-review.googlesource.com/59450\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/183#issuecomment-52882175.\n. > have your Python code append to that\n\nExcuse me, will you please explain how to do it, I cannot get the meaning of this sentence here.\n. Cool!  Very helpful for me.\nThanks a lot!\n. \n",
    "chriskonstad": "I think there's been a change that causes this to be an issue again.\nI ran the sample commands from @subtleGradient and got this output for the path with a space:\n\n[chris@mbp][with spaces]$ buck targets\nUsing watchman.\nWarning raised by BUCK file parser: Traceback (most recent call last):\nWarning raised by BUCK file parser:   File \"/Users/chris/Desktop/buckme/with spaces/.buckd/tmp/buck_run.T3zbEu/buck_python_program1011147366125771223/main.py\", line 10, in \nWarning raised by BUCK file parser:     from buck_parser import buck\nWarning raised by BUCK file parser: ImportError: No module named buck_parser\nParse error for build file /Users/chris/Desktop/buckme/with spaces/BUCK:\nNo content to map due to end-of-input\n at [Source: com.google.common.io.CountingInputStream@2164e11d; line: 1, column: 0]\n[-] PARSING BUCK FILES...FINISHED 0.7s\n\nThe output of buck targets in the path without spaces was as normal.\n. ",
    "afturner": "This is still an issue as of v2017.11.16.01\nGives error:\n\nBUILD FAILED: Buck wasn't able to parse /Users/andrew/path with space/Cool/BUCK:\nNo content to map due to end-of-input\n at [Source: com.google.common.io.CountingInputStream@24d1151a; line: 1, column: 0]\n. @ttsugriy yikes! should have checked the commits.. did try building from source but got some compile errors so didn't pursue further lol. Thanks! . Wondering what the status is on this, sorry if I missed something. \n",
    "ttsugriy": "The issue have been resolved by https://github.com/facebook/buck/commit/20cea0d6625a614363ef82a26e2c127a23a9832f but we haven't published new releases since then. I'll try to do this next week.. fix is now available in https://github.com/facebook/buck/releases/tag/v2018.03.26.01 I'm going to publish deb package soon too.. Sigh... Yeah I tried preventing running buck by users with elevated privileges, but first attempt had this check only in Main.java which was too late to prevent temporary files from being created, which, unfortunately, also result in inability to invoke buck as \"normal\" user afterwards. Second attempt was to add this check in buck (bash-only) entry point, but due to internal issues we had to roll it back... Hopefully the change will find its way to github repo by the end of this week.\n. Sigh... Yeah I tried preventing running buck by users with elevated privileges, but first attempt had this check only in Main.java which was too late to prevent temporary files from being created, which, unfortunately, also result in inability to invoke buck as \"normal\" user afterwards. Second attempt was to add this check in buck (bash-only) entry point, but due to internal issues we had to roll it back... Hopefully the change will find its way to github repo by the end of this week.\n. Thank you for your contribution @ultramiraculous!. The reason for current behavior is that platform is matched against a flavor and by default that flavor is default. I don't know a context behind this, so I can't say if it's intentional or not. If nobody picks this task up, I'll try take a look hopefully later this week.. this is still failing. You can repro it by running buck test //test/com/facebook/buck/jvm/kotlin:kotlin --filter KotlinLibraryIntegrationTest#shouldCompileLibraryWithDependencyOnAnother\nFull output:\n```\nBuild should have succeeded. Expected exit code 0 but was 1.\nstacktrace: java.lang.AssertionError: Build should have succeeded. Expected exit code 0 but was 1.\n    at org.junit.Assert.fail(Assert.java:88)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertExitCode(ProjectWorkspace.java:855)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertSuccess(ProjectWorkspace.java:820)\n    at com.facebook.buck.jvm.kotlin.KotlinLibraryIntegrationTest.shouldCompileLibraryWithDependencyOnAnother(KotlinLibraryIntegrationTest.java:58)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout.lambda$new$3(SameThreadFailOnTimeout.java:41)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nstderr: Oct 07, 2017 8:41:58 PM com.facebook.buck.log.Logger warn\nWARNING: Could not execute xcode-select, continuing without developer dir.\nOct 07, 2017 8:41:58 PM com.facebook.buck.log.Logger info\nINFO: HangMonitorAutoStart\nOct 07, 2017 8:41:59 PM com.facebook.buck.log.Logger warn\nWARNING: Could not execute xcode-select, continuing without developer dir.\nOct 07, 2017 8:41:59 PM oshi.util.FileUtil readFile\nWARNING: File not found: /proc/48243/stat\nOct 07, 2017 8:41:59 PM oshi.util.FileUtil readFile\nWARNING: File not found: /proc/48391/stat\nOct 07, 2017 8:41:59 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Build started at %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger info\nINFO: ActionGraph cache miss. Cache was empty.\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: ActionGraph cache assignment. skipActionGraphCache? %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nWARNING: Attempting to add absolute path to rule key. Only using file name: %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nWARNING: Attempting to add absolute path to rule key. Only using file name: %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nWARNING: Attempting to add absolute path to rule key. Only using file name: %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nWARNING: Attempting to add absolute path to rule key. Only using file name: %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nWARNING: Attempting to add absolute path to rule key. Only using file name: %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nWARNING: Attempting to add absolute path to rule key. Only using file name: %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger warn\nWARNING: Buck encountered an internal error\njava.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n    at com.facebook.buck.jvm.kotlin.JarBackedReflectedKotlinc.buildWithClasspath(JarBackedReflectedKotlinc.java:152)\n    at com.facebook.buck.jvm.kotlin.KotlincStep.execute(KotlincStep.java:87)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:45)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.executeCommandsNowThatDepsAreBuilt(CachingBuildRuleBuilder.java:1752)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.run(CachingBuildRuleBuilder.java:1705)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$BuildRulePipelineStage.run(BuildRulePipelinesRunner.java:230)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$BuildRulePipeline.run(BuildRulePipelinesRunner.java:152)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$1.run(BuildRulePipelinesRunner.java:103)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submit$6(WeightedListeningExecutorService.java:104)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submitWithSemaphore$4(WeightedListeningExecutorService.java:78)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:211)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:200)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:988)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.reflect.InvocationTargetException\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at com.facebook.buck.jvm.kotlin.JarBackedReflectedKotlinc.buildWithClasspath(JarBackedReflectedKotlinc.java:143)\n    ... 16 more\nCaused by: java.lang.NoClassDefFoundError: kotlin/reflect/full/KClasses\n    at org.jetbrains.kotlin.cli.common.arguments.ParseCommandLineArgumentsKt.parseCommandLineArguments(parseCommandLineArguments.kt:63)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:48)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:36)\n    ... 21 more\nCaused by: java.lang.ClassNotFoundException: kotlin.reflect.full.KClasses\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    ... 24 more\nWhen running <kotlinc>.\nWhen building rule //com/example/good:example.\n\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Awaiting termination of %s executor service. Waiting for all jobs to complete, or up to maximum of %s seconds...\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Awaiting termination of %s executor service. Waiting for all jobs to complete, or up to maximum of %s seconds...\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Build finished at %s\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Awaiting termination of %s executor service. Waiting for all jobs to complete, or up to maximum of %s seconds...\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Awaiting termination of %s executor service. Waiting for all jobs to complete, or up to maximum of %s seconds...\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Awaiting termination of %s executor service. Waiting for all jobs to complete, or up to maximum of %s seconds...\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Awaiting termination of %s executor service. Waiting for all jobs to complete, or up to maximum of %s seconds...\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Awaiting termination of %s executor service. Waiting for all jobs to complete, or up to maximum of %s seconds...\nOct 07, 2017 8:42:01 PM com.facebook.buck.log.Logger logAppendableLogRecord\nINFO: Failed cleaning log directory. It's possible another concurrent buck command removed the file. Error: %s\n=== Build should have succeeded. Expected exit code 0 but was 1. ===\n=== STDERR ===\nPARSING BUCK FILES... 0.9s (100%)\nCREATING ACTION GRAPH: FINISHED IN 0.1s\nBuck encountered an internal error\njava.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n    at com.facebook.buck.jvm.kotlin.JarBackedReflectedKotlinc.buildWithClasspath(JarBackedReflectedKotlinc.java:152)\n    at com.facebook.buck.jvm.kotlin.KotlincStep.execute(KotlincStep.java:87)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:45)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.executeCommandsNowThatDepsAreBuilt(CachingBuildRuleBuilder.java:1752)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.run(CachingBuildRuleBuilder.java:1705)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$BuildRulePipelineStage.run(BuildRulePipelinesRunner.java:230)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$BuildRulePipeline.run(BuildRulePipelinesRunner.java:152)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$1.run(BuildRulePipelinesRunner.java:103)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submit$6(WeightedListeningExecutorService.java:104)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submitWithSemaphore$4(WeightedListeningExecutorService.java:78)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:211)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:200)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:988)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.reflect.InvocationTargetException\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at com.facebook.buck.jvm.kotlin.JarBackedReflectedKotlinc.buildWithClasspath(JarBackedReflectedKotlinc.java:143)\n    ... 16 more\nCaused by: java.lang.NoClassDefFoundError: kotlin/reflect/full/KClasses\n    at org.jetbrains.kotlin.cli.common.arguments.ParseCommandLineArgumentsKt.parseCommandLineArguments(parseCommandLineArguments.kt:63)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:48)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:36)\n    ... 21 more\nCaused by: java.lang.ClassNotFoundException: kotlin.reflect.full.KClasses\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    ... 24 more\nWhen running <kotlinc>.\nWhen building rule //com/example/good:example.\n\nDOWNLOADED 0.00 BYTES/SEC AVG, 0 ARTIFACTS, 0.00 BYTES\nBUILDING: FINISHED IN 1.9s (100%) 1/2 JOBS, 1 UPDATED, 50.0% CACHE MISS\nBUILD FAILED\n=== STDOUT ===\n====ERROR LOGS====\n[2017-10-07 20:41:58.803][warn ][tid:21][com.facebook.buck.apple.AppleConfig] Could not execute xcode-select, continuing without developer dir.\n[2017-10-07 20:41:59.238][warn ][tid:21][com.facebook.buck.apple.AppleConfig] Could not execute xcode-select, continuing without developer dir.\n[2017-10-07 20:41:59.487][warn ][tid:29][oshi.util.FileUtil] File not found: /proc/48243/stat\n[2017-10-07 20:41:59.494][warn ][tid:29][oshi.util.FileUtil] File not found: /proc/48391/stat\n[2017-10-07 20:42:01.521][warn ][tid:35][com.facebook.buck.rules.keys.RuleKeyBuilder] Attempting to add absolute path to rule key. Only using file name: /tmp/junit-temp-path5993152936061993787/kotlinc/lib/kotlin-runtime.jar\n[2017-10-07 20:42:01.559][warn ][tid:35][com.facebook.buck.rules.keys.RuleKeyBuilder] Attempting to add absolute path to rule key. Only using file name: /tmp/junit-temp-path5993152936061993787/kotlinc/lib/kotlin-compiler.jar\n[2017-10-07 20:42:01.783][warn ][tid:35][com.facebook.buck.rules.keys.RuleKeyBuilder] Attempting to add absolute path to rule key. Only using file name: /tmp/junit-temp-path5993152936061993787/kotlinc/lib/kotlin-runtime.jar\n[2017-10-07 20:42:01.784][warn ][tid:35][com.facebook.buck.rules.keys.RuleKeyBuilder] Attempting to add absolute path to rule key. Only using file name: /tmp/junit-temp-path5993152936061993787/kotlinc/lib/kotlin-compiler.jar\n[2017-10-07 20:42:01.821][warn ][tid:35][com.facebook.buck.rules.keys.RuleKeyBuilder] Attempting to add absolute path to rule key. Only using file name: /tmp/junit-temp-path5993152936061993787/kotlinc/lib/kotlin-runtime.jar\n[2017-10-07 20:42:01.822][warn ][tid:35][com.facebook.buck.rules.keys.RuleKeyBuilder] Attempting to add absolute path to rule key. Only using file name: /tmp/junit-temp-path5993152936061993787/kotlinc/lib/kotlin-compiler.jar\n[2017-10-07 20:42:01.935][warn ][tid:33][com.facebook.buck.event.listener.LoggingBuildListener] Buck encountered an internal error\njava.lang.RuntimeException: java.lang.reflect.InvocationTargetException\n    at com.facebook.buck.jvm.kotlin.JarBackedReflectedKotlinc.buildWithClasspath(JarBackedReflectedKotlinc.java:152)\n    at com.facebook.buck.jvm.kotlin.KotlincStep.execute(KotlincStep.java:87)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:45)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.executeCommandsNowThatDepsAreBuilt(CachingBuildRuleBuilder.java:1752)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.run(CachingBuildRuleBuilder.java:1705)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$BuildRulePipelineStage.run(BuildRulePipelinesRunner.java:230)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$BuildRulePipeline.run(BuildRulePipelinesRunner.java:152)\n    at com.facebook.buck.rules.BuildRulePipelinesRunner$1.run(BuildRulePipelinesRunner.java:103)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submit$6(WeightedListeningExecutorService.java:104)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submitWithSemaphore$4(WeightedListeningExecutorService.java:78)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:211)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:200)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:988)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.reflect.InvocationTargetException\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at com.facebook.buck.jvm.kotlin.JarBackedReflectedKotlinc.buildWithClasspath(JarBackedReflectedKotlinc.java:143)\n    ... 16 more\nCaused by: java.lang.NoClassDefFoundError: kotlin/reflect/full/KClasses\n    at org.jetbrains.kotlin.cli.common.arguments.ParseCommandLineArgumentsKt.parseCommandLineArguments(parseCommandLineArguments.kt:63)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:48)\n    at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:36)\n    ... 21 more\nCaused by: java.lang.ClassNotFoundException: kotlin.reflect.full.KClasses\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    ... 24 more\nWhen running <kotlinc>.\nWhen building rule //com/example/good:example.\n\nstdout:\nstderr:\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option UseSplitVerifier; support was removed in 8.0\n```. Would it be possible for you to use command line arguments for this?\nYou can create a file args/buckaroo with following content:\n--config\nrepositories.<veriable_to_override>=<override_value>\n...\nand can use it when calling buck as follows:\nbuck build @args/buckaroo ...\nThis way it's also easy to use your overrides in any project without having to modify .buckconfig.. well, you can create a buck wrapper script when initializing buckaroo repo, which would call buck and pass appropriate overrides. In fact, it will also give you the maximum flexibility for providing the best experience for buckaroo clients. No matter how many .buckconfig.* options we support, there will always be a potential for tools/clients to override or corrupt an existing config.. @njlr, cell specific overrides should be available via -c cell//foo.bar=baz syntax. Please let me know if it works for you.. FYI: -c *//foo.bar=baz should override config setting for all cells.. @nikhedonia, flag files are used not just for --config so we cannot make any assumptions and skip any requirements, but we can consider adding a separate --config-file flag which would allow clients to pass configuration options in some simpler format, although personally I like explicitness, since every time we try to introduce some syntactic sugar like this, we get questions from engineers about how this \"magic\" works.\n@njlr, internally we use configuration files and our engineers are used to calling buck with @config/some_config which, btw we're going to replace with -f config/some_config very soon, so that there is no confusion about what exactly config/some_config is - namely a command line file.. thank you for your contribution @robbertvanginkel!. cc @runningcode, who added support for mixed Kotlin/Java sources in https://github.com/facebook/buck/pull/1358 in case he has some ideas.. I guess I'm fine either way, but please add a test :). There are a few more changes in flight that we'd like to have in our next release, but we'll create a new release next Monday or Tuesday. Thank you for your patience!. resolved with https://github.com/facebook/buck/releases/tag/v2017.09.04.02. Happy bucking! :). @nikhedonia, that's an excellent question! I'll try to use our recently contributed deb packager genrule to create a debian package soon.. Debian package is now also available at https://github.com/facebook/buck/releases/tag/v2017.09.04.02. Thank you for bringing this up, @njlr! We do have prebuilt binary for macOS on our release page, so it seems fair to provide binaries for Windows as well. @ilya-klyuchnikov, do you happen to know if there are any plans to do so?. @jkeljo, could you please take a look.. I second @jkeljo's suggestion to not put module info work-around in buck's codebase and certainly  not without a big all caps warning and follow-up task to fix this as soon as it's properly supported :). I second @jkeljo's suggestion to not put module info work-around in buck's codebase and certainly  not without a big all caps warning and follow-up task to fix this as soon as it's properly supported :). Looks like these changes break the build, @brettwooldridge :\nBUILD FAILED: //third-party/java/asm:asm#class-abi failed on step calculate_abi_from_classes with an exception:\nnull\njava.lang.RuntimeException\n    at org.objectweb.asm.ClassVisitor.visitModule(ClassVisitor.java:148)\n    at org.objectweb.asm.ClassReader.readModule(ClassReader.java:760)\n    at org.objectweb.asm.ClassReader.accept(ClassReader.java:661)\n    at org.objectweb.asm.ClassReader.accept(ClassReader.java:525)\n    at com.facebook.buck.jvm.java.abi.DirectoryReader.visitClass(DirectoryReader.java:61)\n    at com.facebook.buck.jvm.java.abi.JarReader.visitClass(JarReader.java:53)\n    at com.facebook.buck.jvm.java.abi.StubJarClassEntry.of(StubJarClassEntry.java:55)\n    at com.facebook.buck.jvm.java.abi.StubJarEntry.of(StubJarEntry.java:30)\n    at com.facebook.buck.jvm.java.abi.StubJar.writeTo(StubJar.java:89)\n    at com.facebook.buck.jvm.java.abi.StubJar.writeTo(StubJar.java:69)\n    at com.facebook.buck.jvm.java.CalculateAbiFromClassesStep.execute(CalculateAbiFromClassesStep.java:47)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:45)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.executeCommandsNowThatDepsAreBuilt(CachingBuildRuleBuilder.java:1694)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.run(CachingBuildRuleBuilder.java:1648)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$2(WeightedListeningExecutorService.java:104)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$0(WeightedListeningExecutorService.java:78)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:211)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:200)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:988)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745). Awesome, thank you for working on this, @brettwooldridge! Java 9 was released yesterday, so I was about to start working on this, but I hope that you nailed it :) I'm kicked off internal builds and if they pass, will merge your changes in. Thanks again!. Looks like one test is failing on Linux:\n```\nStub for com/example/buck/A.class is not correct expected:<...tation;() : FIELD, 0[] // invisible\n// ...> but was:<...tation;() : FIELD, 0[;] // invisible\n// ...>\nstacktrace: org.junit.ComparisonFailure: Stub for com/example/buck/A.class is not correct expected:<...tation;() : FIELD, 0[] // invisible\n// ...> but was:<...tation;() : FIELD, 0[;] // invisible\n// ...>\n    at org.junit.Assert.assertEquals(Assert.java:115)\n    at com.facebook.buck.jvm.java.abi.StubJarTest$Tester.checkStubJar(StubJarTest.java:4411)\n    at com.facebook.buck.jvm.java.abi.StubJarTest$Tester.createAndCheckStubJar(StubJarTest.java:4399)\n    at com.facebook.buck.jvm.java.abi.StubJarTest.preservesTypeAnnotationsInFields(StubJarTest.java:1118)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runners.Suite.runChild(Suite.java:128)\n    at org.junit.runners.Suite.runChild(Suite.java:27)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runners.Suite.runChild(Suite.java:128)\n    at org.junit.runners.Suite.runChild(Suite.java:27)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:115)\n    at com.facebook.buck.testrunner.JUnitRunner.run(JUnitRunner.java:97)\n    at com.facebook.buck.testrunner.BaseRunner.runAndExit(BaseRunner.java:272)\n    at com.facebook.buck.testrunner.JUnitMain.main(JUnitMain.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at com.facebook.buck.jvm.java.runner.FileClassPathRunner.main(FileClassPathRunner.java:80)\nstdout:\nstderr:\nJava HotSpot(TM) 64-Bit Server VM warning: ignoring option UseSplitVerifier; support was removed in 8.0\n. I was able to reproduce it on my mac with:\n./bin/buck test //test/com/facebook/buck/jvm/java/abi:abi --filter StubJarTest\n. Looks like it's a trivial test fix. I'll give it a try and rerun all tests again.. @brettwooldridge, sure, no rush. I fixed the test, but now I'm getting many other errors like:\nFailed to calculate ABI for third-party/java/jackson/jackson-core-2.7.8.jar.\njava.lang.IllegalArgumentException\njava.lang.IllegalArgumentException\n    at org.objectweb.asm.ClassVisitor.(ClassVisitor.java:79)\n    at org.objectweb.asm.ClassVisitor.(ClassVisitor.java:64)\n    at org.objectweb.asm.tree.ClassNode.(ClassNode.java:209)\n    at com.facebook.buck.jvm.java.abi.StubJarClassEntry.of(StubJarClassEntry.java:41)\n    at com.facebook.buck.jvm.java.abi.StubJarEntry.of(StubJarEntry.java:30)\n    at com.facebook.buck.jvm.java.abi.StubJar.writeTo(StubJar.java:89)\n    at com.facebook.buck.jvm.java.abi.StubJar.writeTo(StubJar.java:69)\n    at com.facebook.buck.jvm.java.CalculateAbiFromClassesStep.execute(CalculateAbiFromClassesStep.java:47)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:45)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.executeCommandsNowThatDepsAreBuilt(CachingBuildRuleBuilder.java:1708)\n    at com.facebook.buck.rules.CachingBuildRuleBuilder$BuildRuleSteps.run(CachingBuildRuleBuilder.java:1661)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$2(WeightedListeningExecutorService.java:104)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$0(WeightedListeningExecutorService.java:78)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:211)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:200)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:988)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n```\nInvestigating.... hm, looks like this error happens when attempting to build buck with older version of buck - other integration and end to end tests seem to work well. Will try to land this change by the end of day.. yep, @brettwooldridge, the semicolon looks harmless to me. Looks like the issue I pasted above was just an issue with one of the internal jobs we use for static analysis and these changes (+ test fix) are ready to be committed. I'm working on that... :). @dinhviethoa, do you happen to have some thoughts about this?. @dinhviethoa, do you happen to have some thoughts about this?. Well, hopefully by version 17, someone would generalize this method a bit, so that we don't run out of horizontal space :) Thank you for adding version 16 support, @hzsweers!. @shs96c, you're absolutely right! Unfortunately currently there is no tool that automatically detects and removes unused dependencies, this is not entirely uncommon :( Will you send a PR? If not, I already have the changes ready for review.. fixed by https://github.com/facebook/buck/commit/5ac825e0767211778ca0f7d25945297cc1bb91b9. @romanoid, I'm not sure if the issue is related to your changes, but I'll test it internally and will let you know how it goes.. @romanoid, our internal testing didn't reveal any issues, so please consider using multiValued argument instead of option to avoid potential exceptions and make the API easier to use and you'll be all set :). oh, I'm sorry, you're right. But https://github.com/kohsuke/args4j/issues/24#issuecomment-102079165 suggested using StringArrayOptionHandler,  but in your case it should probably be http://args4j.kohsuke.org/apidocs/org/kohsuke/args4j/spi/EnumOptionHandler.html Would that work?. also added @asp2insp to take a look, since he's our query wizard :). sorry about the delay. Looks like ant pmd is failing with\ntest/com/facebook/buck/jvm/java/JarBuilderTest.java:51: This class name ends with Test but contains no test cases\nYou should be able to reproduce it with ant pmd. The problem is that this seems to be a bug in PMD, so I was trying to update PMD and check if it helps, but unfortunately even the latest version of PMD fails with the same error :(. ok, I gave up and reverted to using plain for loop instead of parameterized tests :( With JUnit5 it would be so much nicer... Sigh.... no worries, @kageiit. I just felt bad for asking you to convert from for loop to parameterized test just to discover that it does not work :). @shs96c, it should be @styurin is investigating why it doesn't work :( Sorry for the inconveniences.. @asp2insp, I looked at https://buckbuild.com/setup/getting_started.html and that dot before colon does not seem to make much sense to me :). also, please use google formatter to format your code. Looks like you've broken formatting for test/com/facebook/buck/android/AndroidLibraryIntegrationTest.java. In particular import line has moved to a wrong position.. known problem :( Internally we haven't embraced Java 9 yet, but it's on our radar to fix Java 9 builds :). Thank you, @epkugelmass! This is pretty awesome. I'm going to work on resolving the old AutoValue issue.. Looks like even the latest version of AutoValue still has issues, so I'm going to have to wait until https://github.com/google/auto/pull/563 is merged, new version of AutoValue is released and it's used in Bazel :(. Java 9 is no longer supported by Oracle, so we are unlikely to be supporting it. We may repurposes this for Java 10 support though.. Java 9 is no longer supported by Oracle, so we are unlikely to be supporting it. We may repurposes this for Java 10 support though.. @davido, looks like Bazel is still using autovalue 1.4 https://source.bazel.build/bazel/+/master:third_party/auto/auto-value-1.4.jar :( . @davido, looks like Bazel is still using autovalue 1.4 https://source.bazel.build/bazel/+/master:third_party/auto/auto-value-1.4.jar :( . I'm also fixing a few issues that creeped into Buck's codebase that relied on a different behavior of HashMap#computeIfAbsent which used to allow value computations inside of computeIfAbsent block (despite explicitly saying in javadoc that nobody should do it :) I've already fixed one of such bugs and will try to fix the rest as soon as possible. I'm testing against Java 10 though, since Java 9 is dead :). sorry, wrong link. I was referring to [HashMap#computeIfAbsent's](https://docs.oracle.com/javase/10/docs/api/java/util/HashMap.html#computeIfAbsent(K,java.util.function.Function) which says \n\nThrows:\nConcurrentModificationException - if it is detected that the mapping function modified this map. I will cut a new release today or tomorrow to resolve this and include some important new features like partial support for using buck with Java 9. Thank you for investigating @shybovycha!. @shybovycha, I've pushed the new release to homebrew. Please give it a try and let me know if it works for you and feel free to reopen the task in case it does not.. release was cut from https://github.com/facebook/buck/commit/2025fd74327477728b524eafdd4619a0170a24ea so everything before that commit is in release and everything after - not :) Glad to know that everything works now :). release was cut from https://github.com/facebook/buck/commit/2025fd74327477728b524eafdd4619a0170a24ea so everything before that commit is in release and everything after - not :) Glad to know that everything works now :). Normally in order to add a dependency on resources resources attribute is used, but go_library does not have support for it. Maybe @nemith would have some suggestion or would like to add missing features :). Normally in order to add a dependency on resources resources attribute is used, but go_library does not have support for it. Maybe @nemith would have some suggestion or would like to add missing features :). @DavidGDD, Buck intentionally explicitly requires all inputs to be explicit and you'd have to create targets for every dependency in your Buck repository. This behavior is by design, although we realize that it complicates imports of Maven dependencies. Ideally Buck would provide a tool for importing Maven dependencies similar to https://docs.bazel.build/versions/master/generate-workspace.html but unfortunately we currently do not have bandwidth to do so.. @DavidGDD, Buck intentionally explicitly requires all inputs to be explicit and you'd have to create targets for every dependency in your Buck repository. This behavior is by design, although we realize that it complicates imports of Maven dependencies. Ideally Buck would provide a tool for importing Maven dependencies similar to https://docs.bazel.build/versions/master/generate-workspace.html but unfortunately we currently do not have bandwidth to do so.. thank you for your contribution @shybovycha! It definitely looks like an improvement. Please update address the comments and you'll be good to go.. thank you for your contribution @shybovycha! It definitely looks like an improvement. Please update address the comments and you'll be good to go.. your java version seems pretty old. I'd recommend trying a recent JDK version 1.8.0_144 for example and letting us know how it goes.. ant is using eclipse compiler that is bundled with Buck so it should be less dependent on environment, so it's expected to work always. At this point I can only recommend either using ant or spending some time to understand what is wrong with your local environment.. yes, we enabled watchman on our CI servers a few months ago and all of our builds are using remote caches, so they are trying to be incremental, but we do not preserve any local state between runs, if that's what you meant by incremental.. I'm sorry to hear about this @anoever. You can try using our new experimental parser that uses a Skylark language. It does not use python so should not in any way interfere with python interpreter used for python rules. If you'd like to give it a try you can add following lines to your .buckconfig:\n[parser]\n  polyglot_parsing_enabled=true\nand either make Skylark your default language for build files by appending another parser config entry:\ndefault_build_file_syntax=skylark\nor add a following first line to each build file you'd like to use Skylark parser for:\n```\n\nBUILD FILE SYNTAX: SKYLARK\n. @styurin, do you happen to know who may help here?. @styurin, @mkillianey , do you happen to have any suggestions/ideas about this?. @dinhviethoa could you please take a look with your expert iOS knowledge. are you saying that you cannot import `os.path` directly? It should be possible.. it's supposed to look ugly - using unsafe APIs is strongly discouraged and in our new Skylark parser we won't support any unsafe methods, so please consider not using them ;). using `os.path.exists()` to check for test resources directory is a bad idea, because buck is not aware of this and would have no way to know what exactly should be invalidated and in you can easily end up in a situation with non-reproducible and hard to understand failure. If nothing else you can probably at least use something like:\ntest_resources = glob(['your_pattern'])\nif test_resources:\n  # handle test resources\nelse:\n  # there are no test resources\n``\n. what java version are you using? The error looks like it's caused by usage of some incompatible JRE version. @techyvish currently Buck does not officially support Java 9 - we've fixed some obvious incompatibilities but there are still more to fix. Hopefully this will be addressed as part of https://github.com/facebook/buck/issues/1548 resolution, since at the moment it's not possible to compile buck with Java 9 at all.. sorry for the inconveniences @techyvish and thanks for using Buck!. support fortemp_fileswas removed in favor ofproject.ignoreI'm going to remove a reference to this obsolete configuration option.. I'm not sure what are you usingsh_binaryfor, since having a dependency on agenruleis sufficient to create its output for the rule that depends on it. I think adding anexecutable = Trueto yourgenruleis all you need to use genrules directly.. you're correct, all dependencies must be visible to rules that depend on them. thanks for the report @kageiit! @styurin is going to take care of this. Sorry for the hassle.. you should already be able to use [remote_file](https://buckbuild.com/rule/remote_file.html#url) to download remote files including maven artifacts. In general it's bad for builds to have anything outside of repository, since it can lead to build flakiness. Also, in case you'd like to make a proposal please use a proper format for it, that includes a background with context and proposed solution with APIs and usage examples.. you should already be able to use [remote_file](https://buckbuild.com/rule/remote_file.html#url) to download remote files including maven artifacts. In general it's bad for builds to have anything outside of repository, since it can lead to build flakiness. Also, in case you'd like to make a proposal please use a proper format for it, that includes a background with context and proposed solution with APIs and usage examples.. looks like you're using a very old JDK - older than 1.6. Buck requires JDK 8.. looks like you're using a very old JDK - older than 1.6. Buck requires JDK 8.. @roxma, buck cannot be built with Java 9 yet. We are working on it but do not have an ETA. Please use Java 8 in the meantime.. cc @davidaurelio . David would be able to answer about the original design, but I can say why it does not show the output - it's becauseCommandAliasclass extendsNoopBuldRulethat returnsnullin itsgetSourcePathToOutputmethod and it's the method that Buck uses to determine the rule output. it seems like it's fairly easy to fix this by implementinggetSourcePathToOutputto return something likeplatformDelegates.get(platform).getSourcePathToOutput(), but like I've said I don't know whether it was intentional or not.. thank you for making buck's documentation better, @kant!. @kant, I just realized that this is a change in a third-party code which should only be updated once upstream version is updated. Please consider contributing your changes to the argparse project after which we'll be glad to accept an updated version of argparse library.. thank you for the fix, @artem-zinnatullin!. please accept CLA and I'll be happy to merge your contribution, @artem-zinnatullin.. it's super unfortunate to have flaky tests, but since it's a reality, we are open to PRs withflakyattribute support similar to how it's done in [bazel](https://docs.bazel.build/versions/master/be/common-definitions.html#test.flaky). it's super unfortunate to have flaky tests, but since it's a reality, we are open to PRs withflakyattribute support similar to how it's done in [bazel](https://docs.bazel.build/versions/master/be/common-definitions.html#test.flaky). this would indeed be super useful. We have discussed this for similar reasons that you've discussed, but have not had time to work on it yet :(. Hello, @gugario! In theory since Kotlin libraries [are using](https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/kotlin/KotlinLibraryBuilder.java#L43) Java libraries, which do understand a concept of unused dependencies, under the hood, adding-c java.unused_dependencies_action=warn` may be enough, but since we don't use Kotlin internally, I don't know how well it works in practice :( @kageiit may know more about how well it works for Kotlin :)\nPlease let us know how/if it works for you!. Ideally buck should only provide a core and everything has to be configured separately as an extension, so unused functionality is free, but unfortunately we are still somewhat far from having extensions. More realistic may be using plugins to either have a configuration page where clients can use a checkbox to decide which plugins should end up in downloaded buck or shipping buck with minimum set of plugins and providing a way to download them using some mechanism like command or something else. @styurin, do you think it's realistic?. Yes, I suspect that android is the largest contributor in terms of binary size and is probably the hardest one to disable :(. Hi, @shs96c! Thanks for your feature request! We will not provide a get_base_path function in Skylark parser, but we will provide its alternative package_name(). I forgot to implement it although I have implemented a deprecated variable PACKAGE_NAME, which we will most likely remove soon. Since it's such a trivial function to implement, I should be able to do it by the end of the day, although it might take some time for changes to get reviewed and landed. For this week you should probably be fine using PACKAGE_NAME though :). I sent a revision internally to implement package_name function, so hopefully it will find its way to the github soon.... Apologies for the delay - reviewers are scarce during holidays :) Buck after  https://github.com/facebook/buck/commit/e6718eb4541678a967afe3b034945b4550e92544 has support for package_name() in BUCK files and native.package_name() in .bzl files. Please let me know if there is anything else that is missing for your use cases.. Thanks for reporting this, @barancev! @bertmaher, could you please take a look?. @barancev , the issue should have already been resolved by https://github.com/facebook/buck/commit/a3b0fe723402e67a84eeb23d3f244d3f2e89846e. Are you still experiencing this issue?. @barancev , the issue should have already been resolved by https://github.com/facebook/buck/commit/a3b0fe723402e67a84eeb23d3f244d3f2e89846e. Are you still experiencing this issue?. @jiangty-addepar, there is an issue with our internal build, which we are going to take care of very soon. ETA - EOD.. @jiangty-addepar, there is an issue with our internal build, which we are going to take care of very soon. ETA - EOD.. for some reason //test/com/facebook/buck/android:binary-integration-2 is timing out with this commit. I'm investigating...\n. Update: I'm still trying to figure out why this test is timing out. The weird thing is that failed test runner invocation seems to contain --dry-run flag which I have no idea where it comes from.... So I finally found what the issue is - we use external test runner for running buck tests and it uses --dry-run to list tests before running them. Now that --dry-run command line option is removed test runner tries to interpret --dry-run as a class and fails to do so. I'll have to see if we don't actually need --dry-run internally. @jiangty-addepar, are you sure nobody else is relying on --dry-run's existence?. so far I don't see a quick way for us to remove a dependency on --dry-run :(. @jiangty-addepar, I'm referring to https://github.com/facebook/buck/blob/master/src/com/facebook/buck/testrunner/BaseRunner.java#L235-L237 which you haven't removed in your change, but I believe it's the one that stopped working because of other changes :(. @jiangty-addepar, tests are failing with and without those lines removed - just in different ways - when that line is removed the failure says that it cannot interpret --dry-run as a class name, but with that option tests are simply timing out :(. yes, looks like our internal test runner is relying on --dry-run to list all test cases :( I'll try to follow-up with someone working on the test runner to see if there is a plan to change this.. @jiangty-addepar, in general whenever possible please try to send independent chunks of work in separate PRs. As for no space left, I believe Travis CI has a 20GB limit for hard drive, so we'll have to come up with some way to reduce the number of things we install as well as consider sharing our tests even more :(. very nice, @FuegoFro! Please accept our CLA and I'll be happy to merge your changes.. cc @dreiss . cc @dreiss . Buck does not officially support Java 9, please use a recent version of JDK8.. Thank you for your contribution, @y-higuchi!. which version of JDK are you using? Make sure you're using a recent version of JDK8.. looks like these changes do not compile. Please take a look at https://ci.appveyor.com/project/Facebook/buck/build/5781#L166. looks like github is now complaining about a merge conflict.... Our internal CI fails with the following error for this change:\n```\nstacktrace: java.lang.AssertionError\n    at org.junit.Assert.fail(Assert.java:86)\n    at org.junit.Assert.assertTrue(Assert.java:41)\n    at org.junit.Assert.assertTrue(Assert.java:52)\n    at com.facebook.buck.android.FilterResourcesStepTest.testWhitelistFilter(FilterResourcesStepTest.java:132)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout.lambda$new$3(SameThreadFailOnTimeout.java:41)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nstdout:\n``. could you please rebase the change so that it goes through our newly fixed Travis CI pipeline?. @raviagarwal7, now Travis CI build is broken - https://travis-ci.org/facebook/buck/jobs/343998756#L3128. Thanks for reporting @sslavic! I have pushed the fix andbrew install buck` is warning free.. I also noticed this when trying to run integration tests on MacOS - https://travis-ci.org/facebook/buck/jobs/340362617#L4642 Internally we don't seem to be running integration tests for Go on Mac hence this issue went unnoticed. I'm not sure who would be the best person to update the scrubber to understand Go binaries.. I also noticed this when trying to run integration tests on MacOS - https://travis-ci.org/facebook/buck/jobs/340362617#L4642 Internally we don't seem to be running integration tests for Go on Mac hence this issue went unnoticed. I'm not sure who would be the best person to update the scrubber to understand Go binaries.. References to environment where binaries were produced are intentionally removed by scrubbers since they make remote caching ineffective,  build rules non-hermetic and non-repeatable which is against what Buck was created for. In general IDEs should not force usage of absolute paths and provide a way to configure a CWD when running a debugger.\nMaybe there is a way to solve this problem without making builds non-hermetic, but unfortunately there isn't one on top of my head.. Unfortunately I've never used Android Studio, so I don't know, but I was under impression that lldb 's cwd is easy to control by launching it from that directory or using a platform shell as described in https://stackoverflow.com/a/43351550/1548477.. sorry, I don't know @jiangty-addepar, we have google-format tool integrated with arcanist tool so it happens as part of arc lint workflow :(. sorry, I don't know @jiangty-addepar, we have google-format tool integrated with arcanist tool so it happens as part of arc lint workflow :(. @jiangty-addepar, looks like your changes break the build - https://ci.appveyor.com/project/Facebook/buck/build/5912#L2252. @jiangty-addepar, looks like your changes break the build - https://ci.appveyor.com/project/Facebook/buck/build/5912#L2252. @Nickersoft, the crash happens in a super console, which is only used for interactive sessions, but on CIs a non-interactive (simple) console is used, which which is why you cannot reproduce the issue locally. I think the only way you can reproduce the issue on a CI is by coming up with a repro in SuperConsoleEventBusListenerTest. @Nickersoft, the crash happens in a super console, which is only used for interactive sessions, but on CIs a non-interactive (simple) console is used, which which is why you cannot reproduce the issue locally. I think the only way you can reproduce the issue on a CI is by coming up with a repro in SuperConsoleEventBusListenerTest. the latest update breaks Travis CI build. Please run google-java-format tool to properly format your changes.. @linzhp There are a number of reasons we're doing it this way, but they can be broadly grouped into following:\n- we would like to keep the global namespace pollution as much as possible. It makes it easier to reaon about code without having to scan an entire document to check if function call is for a native rule or a macro. Unfortunately it's not uncommon for macro writers to override/shadow native rules, so having an explicit namespace for them makes this distinction easier.\n- we'd like to be as close to Bazel API as reasonably possible. We've met Google, Twitter and Microsoft and would love to work with them on standardizing extension definitions to democratize them.\nIs there anything we can do to make this transition smooth for you? It was arguably my mistake to allow native rule usages without native. prefix, which was mostly prompted by migration from Python DSL and I'll be happy to help you with any migration issues you have.. It's my bad, @linzhp. Because we are so heavily invested in internal migration to Skylark, I didn't focus much on providing documentation and higher level picture as to how these parsers compare. We have plans to change this and create a dedicated documentation for Skylark on buckbuild.com. I'll try to work on it as soon as I find some cycles (hopefully in the next couple of weeks). We don't plan any large changes for Skylark API anymore, but please let us know if we accidentally introduce some incompatibility. Thank you for using Skylark!. thank you, @kageiit!. thank you, @kageiit!. Thanks for your contribution, @IlyaNaumovich, but it's not really a typo - buck query does indeed support specifying targets without quotes, although some targets have to be quoted in case they contain some special characters.. Sorry for the delay in response - I tried adding you to our slack channel, but looks like you've already joined.. @DavidLaidlaw, the slack channel is invitation only, so you can either contact us or anyone else who's already a member to send an invitation.. The easiest way is to open an issue :)\nOn Tue, Mar 27, 2018, 7:47 AM DavidLaidlaw notifications@github.com wrote:\n\nThe message on the public face of the slack channel says it requires an\ninvitation and to contact an administrator. But it does not list any\nidentity or contact info for an administrator, so I don't know whom to\ncontact or how to do so.\nMy question was how to identify a contact person or administrator.\nThanks,\n-David Laidlaw\nOn Tue, Mar 27, 2018 at 2:49 AM, Taras Tsugrii notifications@github.com\nwrote:\n\n@DavidLaidlaw https://github.com/DavidLaidlaw, the slack channel is\ninvitation only, so you can either contact us or anyone else who's\nalready\na member to send an invitation.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1779#issuecomment-376416144,\nor mute\nthe thread\n<\nhttps://github.com/notifications/unsubscribe-auth/AMV3okMoh0y5tIVrwUL1HFby_60n-jySks5tieEQgaJpZM4SH16z\n.\n\n\n--\nDavid Laidlaw, Professor, Brown Computer Science\nBox 1910, Providence, RI 02912, +1-401-354-2819\nhttp://www.cs.brown.edu/~dhl\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1779#issuecomment-376552915, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAKhBjcc0fI-eoqwIRAQ65wPv-Add9Jxks5tilD8gaJpZM4SH16z\n.\n. I'm sorry to hear that you were not able to get an invitation to Buck Slack channel. As I've previously mentioned, you can file a github issue asking for an invitation and someone from Buck team would sent you an invite. I'm no longer on Buck team, but I have just sent an invitation to @DavidLaidlaw, since his github profile includes the email.. I'm sorry to hear that you were not able to get an invitation to Buck Slack channel. As I've previously mentioned, you can file a github issue asking for an invitation and someone from Buck team would sent you an invite. I'm no longer on Buck team, but I have just sent an invitation to @DavidLaidlaw, since his github profile includes the email.. @msridhar, having error prone support would be awesome! The jar would have to live in Buck repo, but only if it can be generated in a fully automated fashion and accompanied with all relevant licensing information. In fact that's what other build systems that provide error-prone seem to be doing anyways. For example, Bazel bundles jdk9 as well -\n https://source.bazel.build/bazel/+/master:third_party/java/jdk/langtools/ Please give it a try and if it works we could just steal their jar instead of maintaining our own :). @msridhar, we already have an ant uberjar in buck repo that I'm trying to properly integrate with our ant build.  You can find it here - https://github.com/facebook/buck/tree/master/third-party/java/errorprone It needs some cleanup, but the basic idea is the same - all error-prone jars and its dependencies should ultimately be checked in into buck repo.. @msridhar, the class loader concerns you may be valid, which is why for now I've been mostly considering adding as a separate CI ant target where with ECJ compiler replaced by ErrorProne. This way we still make sure that all builds work with standard compilers, but also get useful static analysis suggestions.. @Mehran-Abghari, both JDKs should be supported as long as they are JDK8, since Java 9 is currently not supported.. I'm sorry about the delays with reviews @linzhp - unfortunately nobody on Buck's core team is familiar with Go and it was written by external contributors, it's hard to find good reviewers for your changes :(. @linzhp, I'm sorry for the delay - we had issues with our internal CI, but I'm working on landing it. I'm committed to landing in no more than 2 hours.. According to https://docs.oracle.com/javase/8/docs/jre/api/security/jaas/spec/com/sun/security/auth/module/UnixSystem.html this should exist in Java 8, but does not seem to exist in Java 9, so I bet that you're using Java 9. Please paste the output of java -version. According to https://docs.oracle.com/javase/8/docs/jre/api/security/jaas/spec/com/sun/security/auth/module/UnixSystem.html this should exist in Java 8, but does not seem to exist in Java 9, so I bet that you're using Java 9. Please paste the output of java -version. a lot of bloat is coming from d8 and fastutil :( Hopefully one day we'll be able to drop support of android once it can be implemented with extensions.\ndu -h third-party/java/fastutil/fastutil-7.2.0.jar\n 17M    third-party/java/fastutil/fastutil-7.2.0.jar\n\nIronically d8 itself is way smaller\n2.2M    third-party/java/d8/d8.jar. a lot of bloat is coming from d8 and fastutil :( Hopefully one day we'll be able to drop support of android once it can be implemented with extensions.\ndu -h third-party/java/fastutil/fastutil-7.2.0.jar\n 17M    third-party/java/fastutil/fastutil-7.2.0.jar\nIronically d8 itself is way smaller\n2.2M    third-party/java/d8/d8.jar. after removing some unnecessary deps from testrunner current binary size is ~86M. I don't see an easy way to significantly shrink it without dropping support for some of android features :(. btw, running proguard when creating dx jar to remove all unnecessary classes from fastutil would probably help a lot. looking.... it's a warning and would not affect a build correctness, but it's bad to have it and I'll take care of it asap.. I'm somewhat puzzled because the warning is produced based on the output of java -version invocation and the output you've shared does not mentioned awt anywhere. Can you please modify _get_java_version method in programs/buck.py to dump the raw output of java -version invocation and share it? I suspect that there is something weird with your setup.. so the issue appears when JAVA_TOOL_OPTIONS environment variable is set, since it results in extraneous lines preceding the java version. This implementation was intentional but relied on a wrong assumption about how java -version prints it output. I'm going to send a fix very soon.. sorry for the inconveniences. should be fixed by https://github.com/facebook/buck/commit/2405866ee9bd8e794505a674e76067125b5a726b Thanks for your patience!. I think an easy and a reasonable way to handle this is to use a content hash instead of a temporary file https://github.com/facebook/buck/blob/1ca7183e88f987e6e616fc88c106ccf158a252a1/src/com/facebook/buck/rules/args/WriteToFileArg.java#L53. doh, but the rulekey differs is explicitly saying that the problem is with prefix, which is a hash of inputs and a class name. I'm going to check that instead.. thanks to @kageiit's data we've established that the problem is actually caused by macro inputs being non-determinstic - most likely due to usage of absolute paths.. yes, it really is :). yes, it really is :). v2018.03.26.01 has been pushed to homebrew.. @styurin, given that Python 2.7 is going away soon, I don't think it's unreasonable to fix Buck's code to make it forward compatible with Python 3. If nothing else, we should encourage users to use it, since it brings speed and usability improvements.. the problem is that gen_buck_info.py is using different ways to compute Buck version some of which return str while others return bytes. It's unfortunate that we're using Python, but we'll definitely have to fix this in Buck.. @matanster, it's possible, since not many build Buck from scratch using ant - most people use brew or jitpack to download prebuilt binaries. Have you tried using jitpack?. @matanster, there is no such thing as Buck for Nuclide - there is just Buck. Nuclide can use it underneath for some of its plugins, but it's the same binary and the same set of steps to install.\nAs to why Facebook and all other companies with huge internal repositories use Buck-like build tools instead of Make/Maven/Gradle-like ones, you can read on our main page https://buckbuild.com/ In short - those tools are slow and not scalable, but Buck is fast and scales to huge projects that are built from source.. @matanster, as buckbuild.com says the easiest way to install Buck is to run brew install buck.. Our release page has deb package for Linux in case it works for you and\njitpack works for all OSes and distributions.\nOn Wed, Mar 28, 2018, 6:27 AM matanster notifications@github.com wrote:\n\nYep, on mac. Less so linux, but thanks anyway.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1812#issuecomment-376885975, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAKhBgMythvj-DK2qO2ZmTfWJLUtGwIxks5ti4-jgaJpZM4SzLS2\n.\n. I'm not sure what you mean by passing a variable in the .buckbuild. You probably meant .buckconfig instead. In any case environment variables are super evil and should never be used. That's exactly the reason why buck uses .buckconfig. You can pass a value using -c your_section.your_key=your_value and read it from BUCK file using https://buckbuild.com/function/read_config.html or from Buck using com/facebook/buck/config/BuckConfig.java. oh I see. Some also use .buckconfig.local to pass configuration options, but --config is definitely more preferable. I've sent you an invitation.. I've sent you an invitation.. @R1kk3r, Buck does not currently automatically infer flavors available on a target rule. This information relies on flavorDomains method implemented for every flavored description and as such requires manual code to make it work. You're welcome to send PRs to add support to the rules you're interested in.. I'm pretty sure it's by design and is because JUnit Parameterized infra gives test methods bad names. You can read more about how parameterized test classes are named in https://www.javacodegeeks.com/2013/04/junit-naming-individual-test-cases-in-a-parameterized-test.html. looks like your test didn't fail @bobyangyf (https://travis-ci.org/facebook/buck/jobs/360100023#L5159-L5160) You can manually restart a job a few times to rule out flakiness, but so far it's very promising :). @shybovycha, apologies for this suboptimal experience. Each available Xcode platform is translated internally into a flavor that must be specified when building a binary, since otherwise Buck has no way of knowing which platform your binary should be built for. A default platform can also be specified using a configuration section. Something like:\n[cxx]\n  default_platform = macosx-x86_64\nshould work for your use-case. @carljparker is working on properly documenting flavors and their usage.. @shybovycha, apologies for this suboptimal experience. Each available Xcode platform is translated internally into a flavor that must be specified when building a binary, since otherwise Buck has no way of knowing which platform your binary should be built for. A default platform can also be specified using a configuration section. Something like:\n[cxx]\n  default_platform = macosx-x86_64\nshould work for your use-case. @carljparker is working on properly documenting flavors and their usage.. please format java classes using google-java-format to fix Travis CI build. Thanks for cleaning this up!. looks like this change is breaking Travis CI - https://travis-ci.org/facebook/buck/jobs/365645094#L4850. looks like internally we are still using an older version of Go which uses a different naming convention and as such our integration tests are failing with errors like:\n```\njava.nio.file.NoSuchFileException: /tmp/junit-temp-path2504656573462961498/buck-out/gen/cgo/lib/cgo_lib#cgo-gen-sources,default/gen/double_cgo.cgo2.c\n    at com.facebook.buck.util.cache.impl.StackedFileHashCache.lambda$get$21(StackedFileHashCache.java:199)\n    at java.util.Optional.orElseThrow(Optional.java:290)\n    at com.facebook.buck.util.cache.impl.StackedFileHashCache.get(StackedFileHashCache.java:199)\n    at com.facebook.buck.rules.keys.RuleKeyBuilder.setPath(RuleKeyBuilder.java:232)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyFactory$Builder.setPath(InputBasedRuleKeyFactory.java:190)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyFactory$Builder.setPath(InputBasedRuleKeyFactory.java:154)\n    at com.facebook.buck.rules.keys.RuleKeyBuilder.setSourcePathDirectly(RuleKeyBuilder.java:174)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyFactory$Builder.setSourcePath(InputBasedRuleKeyFactory.java:209)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyFactory$Builder.setSourcePath(InputBasedRuleKeyFactory.java:154)\n    at com.facebook.buck.rules.keys.AbstractRuleKeyBuilder.setReflectively(AbstractRuleKeyBuilder.java:153)\n    at com.facebook.buck.rules.keys.AbstractRuleKeyBuilder.setReflectively(AbstractRuleKeyBuilder.java:53)\n    ... 44 more\n\nWhen adding input with value Pair(//cgo/lib:cgo_lib#cgo-gen-sources,default, buck-out/gen/cgo/lib/cgo_lib#cgo-gen-sources,default/gen/double_cgo.cgo2.c)\nWhen amending input.\nWhen building rule //cgo/lib:cgo_lib#cgo-second-step,compile-double_cgo.cgo2.c.o5051e4bc,default.\n\n```\nAs such I recommend landing the change to make this transition backwards compatible first, since I don't know when can we expect our internal version of Go to be updated :(. I'm sure there will be times that some changes do not have to be included in the changelog, but I believe there is value in having this. Otherwise there is no meaningful information to attach to the release notes :( I think it would not be a too big of a problem to ask people making large changes to include a line describing what they are solving.. Thank you for your for the contribution, @ghvg1313! The change looks great, but Travis CI is failing because you haven't run google-java-format on modified files. Please do so and your changes should be good to go.. Excellent point about the short syntax being accepted in load functions, @romanoid! I'll make a change to disallow it for consistency :). this is most likely because you're probably not using the version 2.7 of Python as mentioned in https://buckbuild.com/setup/getting_started.html\nYou can probably get away with using a different version if you enable Skylark parser instead of Python DSL.. I've sent a PR to enable Skylark parser for all of our buck samples - https://github.com/fbsamples/bucksamples/pull/13/files You can use it to unblock yourself.. no worries, I didn't realize that Python version check in buck was only making sure that older versions are not used, but says nothing about using the newer versions. As we're migrating to Skylark this should probably matter less.. @mzlee, the announcements are created using github issues with announcement tag :) You can land this change internally but only after creating a github issue :). buck has moved over to using immutables for arguments. Please update your code to use them as well.. why is this code commented out?. nit: passing mutable objects like this around makes reasoning about invariants harder, so I would recommend considering separating a mutable builder from final javascript deps representation.. please use a more specific include here and below. . please move this and everything relating to debian packaging into scripts/packages/debian. @nikhedonia, you should be able to use export_file to export license file and add a dependency on it just like on any other rule.. when working with enums it's much more convenient to use EnumSet. this will blow up if coverageReportFormats is an empty array. You can refer to https://stackoverflow.com/questions/22886287/enumset-from-array-shortest-variant for examples of how to avoid it.. is it possible to use multiValued attribute instead? I personally would prefer having something like\n--code-coverage-format=HTML --code-coverage-format=XML to a comma delimited string.. I was referring to http://args4j.kohsuke.org/apidocs/org/kohsuke/args4j/Argument.html#multiValued(). please add a comment explaining why this is necessary. if it should never be empty, please add a check and throw a human readable exception telling users that they should pass the parameter :) Previously it would just throw an enumset exception and now it's going to be completely silent :). awesome, that sounds good!. changes to this build file should be part of an integration test - not production code ;). did you mean $(query_paths ...)?. nit: how about parameterized tests? https://github.com/junit-team/junit4/wiki/parameterized-tests :). in testdata BUCK files should not be used. Instead it has to be BUCK.fixture. I fixed it, but please keep this in mind in future.. looks like this can be replaced with a stream filter operation. nit: please extract the last expression into a local variable, since it's not on the same semantical level as the other argument statements. pleas use MoreCollectors.toImmutableSet() directly. this line also got a following comment from one of our engineers:\nIn the test plan, there are lots of similar platforms. Maybe try to de-dedup as much as possible.\nIn all cases, if the number of items in the list is larger than 4, there should be one item per line.. I think comment author meant that macosx-i386, macosx-x86_64 can be grouped into a single category, but I don't think it's a good thing to do, but writing flavors on separate lines makes sense to me.. please use a cross platform way of generating new lines System.lineSeparator(). nit: you can avoid having to use buck targets --show-output and use buck build --show-output instead.. while I agree using timeout on a suite is not idea, but we should always have timeouts for tests and as such please either add timeouts for test runs or better yet consider using DelegateRunnerWithTimeout. hm, well, I'm fine with any timeouts as long as there are some :) If you're saying that test execution time is already limited - I'm fine with this then :). please revert this change. looks like you're breaking formatting here... Please use google-format to fix all formatting issues. can it really be absolutely anything and not just something like [w+-]?. found an answer in https://developer.android.com/guide/topics/resources/providing-resources.html:\nBecause each resource is defined with its own XML element, you can name the file whatever you want and place different resource types in one file.\nIt's weird but oh well.... why is this commented out?. why is the new line removed?. @linzhp, afaik we have a default goroot in test buck file:\n\"GOROOT\": read_config(\"go\", \"root\", \"/usr/local/go\"),\nso I assume it's the one and as such it should be overridden by the\n[go]\n  root = <some other root>. deterministic builds are extremely important for most of Buck users and one of the core principles behind Buck's philosophy, so this change makes me very uncomfortable. If cgo binaries are important for your project, please consider fixing the scrubber, if not, consider getting rid of them. As a compromise, we can consider adding a flag that controls the behavior in case of scrubber failures which preserves the existing behavior of failing by default but can be switched to a forgiving mode.. @monty-uber, I think in such case it would be best to have a separate scrubber for cgo binaries which does not have to fail in case it does not find anything to scrub :). you should probably also rename this method to something that is technically more correct - setUuidIfPresent. why is this method commented out? Remove?. would it make sense to provide a backwards compatibility for users using an older version of cgo?. nit: use TimeUnit.SECONDS.toMillis(timeout) for readability instead.. instead of passing long which does not include the units, please use Duration instead.. why MorePaths.pathWithUnixSeparators? getFileName should include only the name of the file without separators. is this substring necessary? is there a limit for the variable name length?. this should be coverage_mode = \"set\", according to buildifier. Please fix.. you can simplify by using Strings.isNullOrEmpty. this is not a valid javadoc start marker - it should be /**. should this be an ImmutableSortedSet instead?. ",
    "Ruenzuo": "Yay! That fixed it! Thanks.\n. ",
    "LegNeato": "Can you rebase and sign the Facebook Contributors License Agreement @ http://developers.facebook.com/opensource/cla ? You don't need a Facebook account to sign. FYI, we adopted the Apache Software Foundation's CLA which is also used by Google, RedHat, Zend, and others.\n. Sorry this took so long!\nCan you rebase and sign the Facebook Contributors License Agreement @ http://developers.facebook.com/opensource/cla ? You don't need a Facebook account to sign. FYI, we adopted the Apache Software Foundation's CLA which is also used by Google, RedHat, Zend, and others.\n. Thanks!\nCan you rebase and sign the Facebook Contributors License Agreement @ http://developers.facebook.com/opensource/cla ? You don't need a Facebook account to sign. FYI, we adopted the Apache Software Foundation's CLA which is also used by Google, RedHat, Zend, and others.\n. Can you rebase and sign the Facebook Contributors License Agreement @ http://developers.facebook.com/opensource/cla ? You don't need a Facebook account to sign. FYI, we adopted the Apache Software Foundation's CLA which is also used by Google, RedHat, Zend, and others.\n. Awesome! We'll work on merging this asap.\n. This looks great, thanks!\nCan you sign the Facebook Contributors License Agreement @ http://developers.facebook.com/opensource/cla ? If you don't have a Facebook account we can send you a PDF. FYI, we adopted the Apache Software Foundation's CLA which is also used by Google, RedHat, Zend, and others--pretty standard stuff.\n. Ah, sorry...our tools around this aren't the best :-/\n. I am going to add openjdk to the travis builds, assuming it currently builds\n. I am going to add openjdk to the travis builds, assuming it currently builds\n. Can you check the failing tests?\n. Can you check the failing tests?\n. Can you check on the Travis failure?\n. Can you check on the Travis failure?\n. This is on my personal wishlist for 2014\n. Yuck, yeah this is super unfriendly. @rowillia what do you think, should we create an empty file or just make the message better?\n. Agreed!\n. Do you have the Android SDK installed? There is a known problem right now that the quickstart tests fail if you do not. I have a 1/2 finished patch to make them pass w/o the SDK installed\n. Thanks! If that fixes it this is a known issue...let me know.\n. Cross repo stuff is in now, right?\n. :heart: \n. :heart: \n. :beers: \n. This is fixed, right?\n. More specifically here:\nhttps://github.com/facebook/buck/blob/ad8f8c246535084cd2bbf8d12ae997def76ee7ce/src/com/facebook/buck/android/NdkCxxPlatforms.java#L169\n. @ajtulloch Not currently. Mainly because it has probably bitrotted and I don't have a test project to muck around with to make sure everything works correctly.\n. @ajtulloch Not currently. Mainly because it has probably bitrotted and I don't have a test project to muck around with to make sure everything works correctly.\n. It actually rebased cleanly. I'll PR, do you want me to update the flags? I can't really test anything \ud83d\ude04 \n. It actually rebased cleanly. I'll PR, do you want me to update the flags? I can't really test anything \ud83d\ude04 \n. They do indeed throw an error on unrecognized key:\nhttp://reviews.llvm.org/diffusion/L/browse/cfe/trunk/lib/Tooling/JSONCompilationDatabase.cpp;248984$307\nAlso, would be nice for their docs to mention xctool and buck as supported tools ;-)\nhttp://reviews.llvm.org/diffusion/L/browse/cfe/trunk/docs/JSONCompilationDatabase.rst\n. I added Buck and xctool to the docs (http://reviews.llvm.org/D13327), will put up a patch for the other one hopefully tonight.\n. @bolinfest no need! Looks like they added a structured way for arguments:\nhttp://reviews.llvm.org/rL245036\nIt should be as simple as doing s/args/arguments/ on the key :clap: \n. https://github.com/facebook/buck/commit/46945e4400e649433b079442dec4be98e964360f doesn't appear to set the new arguments value in the clang format?\n. :clap: \n. From what I can gather not really knowing the code, DirectoryTraversal can take ignore paths:\nhttps://github.com/facebook/buck/blob/ad05aa385cfb6d648d61160329b9bf8ae60d3ae5/src/com/facebook/buck/io/DirectoryTraversal.java#L41\nIt looks like some places it is called don't ever put ignore paths in:\nhttps://github.com/facebook/buck/search?utf8=%E2%9C%93&q=DirectoryTraversal%28\nThen again, the project filesystem appears to ignore it:\nhttps://github.com/facebook/buck/blob/5a3ccc0fd51737d8c24861f25cb7ac268d5ab343/src/com/facebook/buck/io/ProjectFilesystem.java#L209\nAnd parsing build files appears to use it:\nhttps://github.com/facebook/buck/blob/fab381234b9e6838b360b284cd28a0f3583682bb/src/com/facebook/buck/model/FilesystemBackedBuildFileTree.java#L81\nMight be a good place to poke around and send in a patch if you find the issue!\n. Patch written with Nuclide :tada: \n. Eh? Git says I am on latest and I don't see lint errors in the travis output\n. Eh? Git says I am on latest and I don't see lint errors in the travis output\n. Ok, I ran lint locally and fixed the issues:\n``` sh\n$ ant lint\nBuildfile: /Users/legnitto/src/github/buck/build.xml\npmd:\ncheckstyle:\n[checkstyle] Running Checkstyle 5.7 on 2145 files\nlint:\nBUILD SUCCESSFUL\nTotal time: 12 seconds\n```\n. Ok, I ran lint locally and fixed the issues:\n``` sh\n$ ant lint\nBuildfile: /Users/legnitto/src/github/buck/build.xml\npmd:\ncheckstyle:\n[checkstyle] Running Checkstyle 5.7 on 2145 files\nlint:\nBUILD SUCCESSFUL\nTotal time: 12 seconds\n```\n. Perhaps this should go into a known issues / FAQ / workarounds page?\n. :point_right: @andrewjcg \n. More info on the warning:\nhttps://developer.apple.com/library/ios/documentation/General/Conceptual/CocoaEncyclopedia/Initialization/Initialization.html#//apple_ref/doc/uid/TP40010810-CH6-SW3\n. Are you using watchman? If so, what version? If not, does the issue go away if you install it?\n. Are you using watchman? If so, what version? If not, does the issue go away if you install it?\n. OK, that makes sense...looks like this needs to be None:\nhttps://github.com/facebook/buck/blob/43ee655dbf0a442fb57ef8cfc04595c0d96c0ecf/programs/buck_tool.py#L250\nin order to not throw on Windows.\n. OK, that makes sense...looks like this needs to be None:\nhttps://github.com/facebook/buck/blob/43ee655dbf0a442fb57ef8cfc04595c0d96c0ecf/programs/buck_tool.py#L250\nin order to not throw on Windows.\n. I think this is no longer needed due to https://github.com/facebook/buck/commit/3972723c49ea0eff00b7e00756a5ec6a47c5860e ?\n. Just hit this compiling Buck itself. Should we add:\nini\n[ndk]\n      gcc_version = 4.9\nTo buck's config? That will that prevent people with only much older NDKs from building buck out of the box, but I think it is more likely people will have a NDK with 4.9 than one without?\n. Just hit this compiling Buck itself. Should we add:\nini\n[ndk]\n      gcc_version = 4.9\nTo buck's config? That will that prevent people with only much older NDKs from building buck out of the box, but I think it is more likely people will have a NDK with 4.9 than one without?\n. I have signed the CLA. Seems to be a bug in the CLA tool (it's throwing an error). I'll email cla@fb.com.\n. I have signed the CLA. Seems to be a bug in the CLA tool (it's throwing an error). I'll email cla@fb.com.\n. If no one cleans this up, adds tests, and adds the right flags I will try to do it next week.\n. If no one cleans this up, adds tests, and adds the right flags I will try to do it next week.\n. FYI, the CLA has now been signed manually. Still need to find time to fix this up a bit...\n. Rebased on latest changes.\nAlso, I removed arm64 from the list of default archs because currently the default platform is android-9, which doesn't have arm64. Happy to revisit that (either by adding it back in or adding it back in + bumping the default platform). Thoughts?\n. Rebased on latest changes.\nAlso, I removed arm64 from the list of default archs because currently the default platform is android-9, which doesn't have arm64. Happy to revisit that (either by adding it back in or adding it back in + bumping the default platform). Thoughts?\n. Travis failure is unrelated:\n```\nFAIL    <100ms  0 Passed   0 Skipped   1 Failed   //test/com/facebook/buck/android:integration\nFAILURE //test/com/facebook/buck/android:integration main: //test/com/facebook/buck/android:integration failed with exit code 137:\njunit\nstderr: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option UseSplitVerifier; support was removed in 8.0\ncom.facebook.buck.step.StepFailedException: //test/com/facebook/buck/android:integration failed with exit code 137:\njunit\nstderr: Java HotSpot(TM) 64-Bit Server VM warning: ignoring option UseSplitVerifier; support was removed in 8.0\nat com.facebook.buck.step.StepFailedException.createForFailingStepWithExitCode(StepFailedException.java:63)\nat com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:65)\nat com.facebook.buck.step.DefaultStepRunner.lambda$0(DefaultStepRunner.java:84)\nat com.facebook.buck.step.DefaultStepRunner$$Lambda$246/748842359.call(Unknown Source)\nat com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$0(WeightedListeningExecutorService.java:77)\nat com.facebook.buck.util.concurrent.WeightedListeningExecutorService$$Lambda$79/547201549.apply(Unknown Source)\nat com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\nat com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\nat com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\nat com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n\n```\n. Ok, I think we are ready to go here.\nIt doesn't feel really \"nice\" though. In order to build arm64 for android, you need to set the following in the [ndk] config section:\n- cpu_abis = arm64 -- because arm64 is not in the default arch set, mainly due to the app platform default being android-9 \n- app_platform = android-21 -- because arm64 was not available before that, and again Buck's app_platform default isandroid-9\nSo to build arm64, your [ndk] section in .buckconfig needs to look like:\nini\n[ndk]\n  # If you want all common ABIs. You could also do a subset.\n  cpu_abis = armv7, arm64, x86, x86_64\n  app_platform = android-21\n  gcc_version = 4.9\n  clang_version = 3.8\nThe last two lines shouldn't be needed as they should switch correctly (gcc, clang), but can't hurt...\nNote that this is not just required for arm64...it is also an issue with x86_64 and to support that abi it needs to be configured the same way.\nSo the question is, is it better to have people make these changes, or is it better to have the default be these values and have the people needing to target older app platforms, compiler versions, and cpu_abis change their config?\n. I'm pretty sure. I'll repro it, perhaps that logic is busted with the way I have my stuff set up (via Homebrew)\n. I'm pretty sure. I'll repro it, perhaps that logic is busted with the way I have my stuff set up (via Homebrew)\n. Actually, I think this was a problem with my setup.\n. Actually, I think this was a problem with my setup.\n. I didn't have the tests be complete opposites (didn't include mips). Let me know if you think I should do that.\n. I didn't have the tests be complete opposites (didn't include mips). Let me know if you think I should do that.\n. Failure is unrelated.\n. Failure is unrelated.\n. @marcinkosiba Sorry about that, should be fixed:\n```\n$ ant checkstyle\nBuildfile: src/buck/build.xml\ncheckstyle:\n[checkstyle] Running Checkstyle 6.16.1 on 2919 files\nBUILD SUCCESSFUL\nTotal time: 14 seconds\n$\n```\n. @marcinkosiba Sorry about that, should be fixed:\n```\n$ ant checkstyle\nBuildfile: src/buck/build.xml\ncheckstyle:\n[checkstyle] Running Checkstyle 6.16.1 on 2919 files\nBUILD SUCCESSFUL\nTotal time: 14 seconds\n$\n```\n. Odd, the failure didn't show locally. I'll fix.\n. Closing this out as the code has changed considerably.. Thanks for the change @brettwooldridge! I am willing to write the unit test, I'll try to get to it today.. I added a test for the second case in https://github.com/LegNeato/buck/commit/5e3ec45a214dae3c4ebb6115c19a9e1a17c91b9c but can't get it to pass. Not sure if it is failing because the behavior is indeed incorrect or that my test is wrong. I'll take another look at it later tonight, but feel free to point out any obvious silliness \ud83d\ude04 . @brettwooldridge ah, I suspected that was the issue and was going to try to fix it today! Thanks for getting it working :-).. What type of rule? This may be relevant:\nhttps://buckbuild.com/rule/prebuilt_cxx_library.html#include_dirs. @aledalgrande the docs are checked in \ud83d\udc4d. Take a look at:\nhttps://github.com/facebook/buck/blob/63ad3bf1874ab6dbbc8a3e3ecbc81fc9ba6809e1/docs/setup/getting_started.soy#L139\nThe README says how to test changes:\nhttps://github.com/facebook/buck/blob/63ad3bf1874ab6dbbc8a3e3ecbc81fc9ba6809e1/docs/README.md. @aledalgrande filed https://github.com/facebook/buck/issues/1268. Looks like there is a script in https://github.com/facebook/buck/blob/master/scripts/updatehomebrew.py. You should be able to just codesign manually later in the dep tree, no?\nhttps://developer.apple.com/library/content/documentation/Security/Conceptual/CodeSigningGuide/Procedures/Procedures.html#//apple_ref/doc/uid/TP40005929-CH4-SW4\nSo it might just be a matter of adding a CodeSignStep after AppleBinary?\nhttps://github.com/facebook/buck/blob/284d8ca33143324876a292d5f520ea8c69061990/src/com/facebook/buck/apple/CodeSignStep.java. You should be able to just codesign manually later in the dep tree, no?\nhttps://developer.apple.com/library/content/documentation/Security/Conceptual/CodeSigningGuide/Procedures/Procedures.html#//apple_ref/doc/uid/TP40005929-CH4-SW4\nSo it might just be a matter of adding a CodeSignStep after AppleBinary?\nhttps://github.com/facebook/buck/blob/284d8ca33143324876a292d5f520ea8c69061990/src/com/facebook/buck/apple/CodeSignStep.java. You can see in https://travis-ci.org/LegNeato/buck/jobs/230848179 the caching now does not time out.. Hmmm, don't merge this as it didn't fix it. Something else is going on.... Nice!. Not sure if this will fix it, as it looks intermittent? \ud83e\udd37\u200d\u2642\ufe0f . Appveyor still built and passed.. I too would be interested in such a feature. I too would be interested in such a feature. Though multiple tools may collide...perhaps just look for a .buckconfig.().generated regex. Though multiple tools may collide...perhaps just look for a .buckconfig.().generated regex. What's buckit? :-). Not sure how supported/extensible they are, but there are some js rules already in Buck that might be of use:\nhttps://github.com/facebook/buck/tree/b404f1321cb0638f004016d5ff529ff33e1cc802/test/com/facebook/buck/js\nSpecifically ios_react_native_library and android_react_native_library look relevant.. RN doesn't want to bump wholesale to 21. I think the risk is acceptable as Google is forcing it.. I guess Buck perhaps needs the concept of a tooling version and a deployment version? It needs to build with 21 due to the new tooling but can target 16.. I commented on the PR with what I believe should be done FWIW. Happy to take a crack at it if you don't have time.. Nope: https://github.com/facebook/buck/issues/1526. @carljparker any update on flavor docs?. I believe per-arch options should be added to https://buckbuild.com/concept/buckconfig.html#ndk.app_platform\nLikely we should copy what https://buckbuild.com/concept/buckconfig.html#halide.target does for the flavor defs.\nThen RN could have something like:\nini\n[ndk]\n  app_platform = android-16\n  app_platform-arm64 = android-21. CI failures look unrelated.. @kageiit haven't 100% looked into it, but I believe so from a quick glance.\nThat being said, I think there is more work to do as it would be pretty crappy for buck to not work by default and need to be configured in order to work with the latest ndk.. Friendly poke \ud83d\udc49 @styurin . Fixed formatting to pass Travis.. @styurin Any pointers on how to check that a particular app platform is used when building? I can definitely write integration tests I just can't reason about how to go about it. I guess I can use this to build for arm64...but then running the tests will require a min version of the NDK installed...is that acceptable? Right now it looks like travis uses r10e.. @styurin Added integration tests that compile and check the symbols. Let me know about your responses to the naming and map stuff and I'll change them if needed...otherwise this is good to go. Not sure what is going on with Travis, it all passes locally.. Travis failure is unrelated and fixed by https://github.com/facebook/buck/pull/1925.. @styurin @bobyangyf this should be ready now!. Hold up, missed some tests. Will fix.\nEdit: Fixed.. @styurin I am not sure I agree about not modifying the tests...if you look at them they are not testing anything arm specific, it just happened to be in the default arch set and thus was chosen to check out of simplicity or completeness. Changing them to check armv7 keeps the intent of the tests the same while allowing people with either v17 or earlier NDKs to run the tests. It also means we don't have to duplicate a ton of tests or abstract out logic to test two sides of the NDK arch divide.\nI of course will add tests to check the new behavior of switching defaults based on NDK versions.. Ping @styurin. I believe this is actually still on me...I was waiting for my other PR to land before I rebased and fixed comments. I believe this is actually still on me...I was waiting for my other PR to land before I rebased and fixed comments. Sweet, thanks!. If the project wants this, happy to put up a PR with the initial content.. This broke travis. This broke travis. Add a lint if that's the case? Not sure how external people would know and this is perfect for lint.\n. Add a lint if that's the case? Not sure how external people would know and this is perfect for lint.\n. Perhaps we copy what the AWS stuff does? It has a multi-layered approach, starting with a file in the homedir, moving to ENV variables, and then finally using values specified on the command line. We could even do he whole AWS_PROFILE jazz for the homedir stuff.\n. Doesn't seem to make it take too long:\nhttps://travis-ci.org/facebook/buck/builds/229837080?utm_source=github_status&utm_medium=notification. Fixed.. Sure, though that is a different change. I'll put up another PR. Also, it would be a breaking change for people not using the latest ndk so I am not sure if that is acceptable or not.. https://github.com/facebook/buck/pull/1894. I thought \"default\" might be confusing as it isn't actually a providing real default in the config sense, that happens further down in the stack. So \"default\" is kinda ambiguous here for callers. I guess I could have used \"fallback\", which feels more correct than default to me as well  (getFallbackAppPlatform or getNdkCpuAbiFallbackAppPlatform). Happy to change it to whatever you want.. Sure, though I did it this way to try to generally be consistent with https://buckbuild.com/concept/buckconfig.html#halide.target. Still want me to change it?. @bobyangyf not exactly sure, can't find an answer as to when that was introduced or removed. Does using # include <sys/cdefs.h> instead fix it with your version? What version of the ndk are you building with?. ",
    "denizt": "I rewrote the commit, before pushing I noticed that my tip was failing 'ant test' so I added a travis job for builds so problems like e793ed7f2eb0803231264327cf29ca57756d12bd can be noticed earlier.\nNDA is in process, I hope to have it ready by tomorrow :)\n. I sent the NDA to James yesterday, so everything should be in order now?\n. I see that travis support is now on main. this is really great :) The reason I made this lazy-load patch was that it was taking a long time for buck to start, even for version queries, since it built the whole file-tree, I believe it's no longer the case. Close the pull?\n. ",
    "davido": "I created the reproducer for the issue above and detailed instructions in README file how to reproduce it:\nhttps://github.com/davido/buck_test\n. Hey, cool, thanks! Can you share the patch?\n. OTOH you could add -Xmx to your BUCK_EXTRA_ARGS definition. Another approach would be to define additional variable BUCK_JVM_ARGS and compare it against \"\" after system wide and/or user specific configuration was read, and use the default values (like it currently the case) if BUCK_JVM_ARGS wasn't defined.\nThe problem for Gerrit Code review is, that we have a lot of memory, but Buck uses hard coded in the buck_common and there is no way to overwrite it.\n. I don't have Facebook account. I wonder how can i sign the Facebook Contributors License Agreement?\n. I think we only discuss if we let that patch in the form it is now or adapt it to use another var like @dreiss suggested, something like BUCK_JAVA_MEMORY_ARGS, so that one can set it, without to interfere with BUCK_EXTRA_ARGS:\ncat > $HOME/.buckrc <<EOF\nexport BUCK_JAVA_MEMORY_ARGS=\"-XX:MaxPermSize=512m \\\n-Xms8000m \\\n-Xmx16000m\"\nEOF\n(And i still can't sign the ACL, because i don't have Facebook account).\n. How cool is that!\n. CR+1\nLooking for a way to say Code-Review+1 on Github....\n. @sdwilsh Looks like we have a regression here: #557.\n. Done in [1].\n[1] https://github.com/davido/buck/commit/2d27e26503ccd4d7c3d8206321bc591c98936824\n. Done in [1].\n[1] https://github.com/davido/buck/commit/2d27e26503ccd4d7c3d8206321bc591c98936824\n. Actually it is already solved as reusable building blocks: bucklets [1]. Just pull and include it in your repository as git submodule. Working example provided [2].\n[1] https://gerrit-review.googlesource.com/#/admin/projects/bucklets\n[2] https://gerrit-review.googlesource.com/#/admin/projects/gitiles\n. Actually it is already solved as reusable building blocks: bucklets [1]. Just pull and include it in your repository as git submodule. Working example provided [2].\n[1] https://gerrit-review.googlesource.com/#/admin/projects/bucklets\n[2] https://gerrit-review.googlesource.com/#/admin/projects/gitiles\n. @bootstraponline transitive dependencies currently not supported in buckles.\n. @bootstraponline transitive dependencies currently not supported in buckles.\n. Well, i am not a big fun of transitive dependencies. Currently we hard code them in maven_jar():\n```\nmaven_jar(\n  name = 'gwt-dev',\n  id = 'com.google.gwt:gwt-dev:' + VERSION,\n  sha1 = 'af3d9ad2fb8be30dc87fdcd6d9a373b2ab675802',\n  license = 'Apache2.0',\n  deps = [\n    ':javax-validation',\n    ':javax-validation_src',\n  ],\n  attach_source = False,\n  exclude = ['org/eclipse/jetty/*'],\n)\nmaven_jar(\n  name = 'javax-validation',\n  id = 'javax.validation:validation-api:1.0.0.GA',\n  bin_sha1 = 'b6bd7f9d78f6fdaa3c37dae18a4bd298915f328e',\n  src_sha1 = '7a561191db2203550fbfa40d534d4997624cd369',\n  license = 'Apache2.0',\n  visibility = [],\n)\n```\nCurrent implementation of maven_jar() [1] is using download_file.py [2] where we can do something funny, like:\n- strip parts from the Maven artifact. This is needed, because recent GWT is shipping old version of Jetty container (8.x) that collides with the version shipped with Gerrit master (9.1):\n[...]\nexclude = ['org/eclipse/jetty/*'],\n[...]\n- strip JAR signing stuff, note unsign = True:\nmaven_jar(\n  name = 'jgit',\n  id = 'org.eclipse.jgit:org.eclipse.jgit:' + VERS,\n  bin_sha1 = '421e66466c7946b8f5e5a841297fe44d2071ab88',\n  src_sha1 = '281dd1817e53814ee055e346d572f687688a8463',\n  license = 'jgit',\n  repository = REPO,\n  unsign = True,\n  deps = [':ewah'],\n)\nAnd as you pointed out, we use already directory cache in Buck, but could easily set up distributed cache instead.\n[1] https://gerrit.googlesource.com/bucklets/+/master/maven_jar.bucklet\n[2] https://gerrit.googlesource.com/bucklets/+/master/tools/download_file.py\n. Well, that's not me. That was extracted from Gerrit Code Review project. So if you would like to say \"Thank you guys for having reusable bucklets library, including maven_jar\", the right place to do that is this forum: [1] ;-)\n[1] https://groups.google.com/forum/#!forum/repo-discuss\n. Not necessarily. It depends how and if Bucklets are integrated in Buck core. Let's assume, that Bucklets are natively supported by Buck as discussed in this thread: [1].\nSo that you can say in .bucklets file in your project:\n```\n[bucklet]\n  gerrit:maven_jar:1.0\n[repository]\n  gerrit = https://gerrit.googlesource.com/bucklets\n```\nAnd you are done: you can now include maven_jar() rule in your BUCK files and it just works.\n[1] https://groups.google.com/d/topic/buck-build/VIgYyJKn088/discussion\n. We are almost there. 9735ae86114977a787672e1a8a84a07f179d4e23 added remote_file() rule to Buck:\n```\nmaven_jar(\nname = 'httpmime',\nid = 'org.apache.httpcomponents:httpmime:4.3.4',\nbin_sha1 = '54ffde537682aea984c22fbcf0106f21397c5f9b',\nsrc_sha1 = '0651e21152b0963661068f948d84ed08c18094f8',\nlicense = 'Apache2.0',\n)\nprebuilt_jar(\n  name = 'httpmime',\n  binary_jar = ':httpmime-jar',\n  source_jar = ':httpmime-src',\n)\nremote_file(\n  name = 'httpmime-jar',\n  sha1 = '54ffde537682aea984c22fbcf0106f21397c5f9b',\n  url = 'mvn:org.apache.httpcomponents:httpmime:jar:4.3.4',\n  out = 'httpmime.jar',\n)\nremote_file(\n  name = 'httpmime-src',\n  sha1 = '0651e21152b0963661068f948d84ed08c18094f8',\n  url = 'mvn:org.apache.httpcomponents:httpmime:src:4.3.4',\n  out = 'httpmime-src.jar',\n)\n```\nFor some reasons it doesn't work: https://github.com/facebook/buck/issues/192\n. Indeed, 3afdcbd fixed it.\n. @rowillia i tried it again and i am failing to login because i don't have Facebook account.\nCan you please send me CLA per mail, or can i sign it somehow without having Facebook acount?\nI am getting this screen:\nhttp://imgur.com/qMwqsmt\nAm i doing something wrong?\nThanks.\n. @rowillia,\n@oconnor663 makes a good point: so either extend a java_library to accept packaging_deps or have a android_library that accepts this parameter.\nTo stay with common src <- java_library <- java_binary chain problem, whith compile (!) time dependencies:\nevery one needs to express for compile time dependencies either they are transitive or not. I fail to see how exported_deps solves that problem in current master.\n. @rowillia,\n@oconnor663 makes a good point: so either extend a java_library to accept packaging_deps or have a android_library that accepts this parameter.\nTo stay with common src <- java_library <- java_binary chain problem, whith compile (!) time dependencies:\nevery one needs to express for compile time dependencies either they are transitive or not. I fail to see how exported_deps solves that problem in current master.\n. @oconnor663 \n\nI don't fully understand the context of this pull request\n\nWhy? How can i improve the description and the reproducer? You have two java_library rules: one with compile_deps param produces plugin.jar with only one file, where the original java_library produces the artifact with  that file + commons-io included.\n. @shs96c Nope. I am asking for compile_deps only. Consider core+plugin pattern. Gerrit exposes plugin-api.jar to create plugins. Obviously the whole plugin-api stuff is in Gerrit core / war file.\nBy compiling plugin.jar it is important to be able to express non transitive dependency:\nExample:\nPlugin foo has Foo.java and depends on 10 MB big gerrit-api.jar\nIn plugin-foo.jar artifact we need one file: Foo.class + MANIFEST:\n```\n java_binary(\n    name = 'plugin',\n    manifest_file = 'resources/MANIFEST.MF',\n    deps = ['//:plugin-library'],\n  )\njava_library(\n    name = 'plugin-library',\n    srcs = glob(...),\n    compile_deps = ['//lib:plugin-api'],\n  )\n```\nWe cannot do it with vanilla Buck today and were forced to create java_library2 [1].\nBecause if we do this:\n```\n java_binary(\n    name = 'plugin',\n    manifest_file = 'resources/MANIFEST.MF',\n    deps = ['//:plugin-library'],\n  )\njava_library(\n    name = 'plugin-library',\n    srcs = glob(...),\n   deps = ['//lib:plugin-api'],\n  )\n```\nWe would get in plugin-foo.jar 10 MB from the gerrit-plugin + one Foo.class file from the plugin.\n[1] https://gerrit.googlesource.com/bucklets/+/master/java_library2.bucklet\n. @shs96c Nope. I am asking for compile_deps only. Consider core+plugin pattern. Gerrit exposes plugin-api.jar to create plugins. Obviously the whole plugin-api stuff is in Gerrit core / war file.\nBy compiling plugin.jar it is important to be able to express non transitive dependency:\nExample:\nPlugin foo has Foo.java and depends on 10 MB big gerrit-api.jar\nIn plugin-foo.jar artifact we need one file: Foo.class + MANIFEST:\n```\n java_binary(\n    name = 'plugin',\n    manifest_file = 'resources/MANIFEST.MF',\n    deps = ['//:plugin-library'],\n  )\njava_library(\n    name = 'plugin-library',\n    srcs = glob(...),\n    compile_deps = ['//lib:plugin-api'],\n  )\n```\nWe cannot do it with vanilla Buck today and were forced to create java_library2 [1].\nBecause if we do this:\n```\n java_binary(\n    name = 'plugin',\n    manifest_file = 'resources/MANIFEST.MF',\n    deps = ['//:plugin-library'],\n  )\njava_library(\n    name = 'plugin-library',\n    srcs = glob(...),\n   deps = ['//lib:plugin-api'],\n  )\n```\nWe would get in plugin-foo.jar 10 MB from the gerrit-plugin + one Foo.class file from the plugin.\n[1] https://gerrit.googlesource.com/bucklets/+/master/java_library2.bucklet\n. @shs96c Thank you so much for fixing it: works like a charm! We have removed our work around in Gerrit Code Review [1] itself and in bucklets buck library [2] that we are using for other projects in Gerrit ecosystem [3].\n[1] https://gerrit-review.googlesource.com/56780\n[2] https://gerrit-review.googlesource.com/56823\n[3] https://gerrit-review.googlesource.com/56824\n. @shs96c Thank you so much for fixing it: works like a charm! We have removed our work around in Gerrit Code Review [1] itself and in bucklets buck library [2] that we are using for other projects in Gerrit ecosystem [3].\n[1] https://gerrit-review.googlesource.com/56780\n[2] https://gerrit-review.googlesource.com/56823\n[3] https://gerrit-review.googlesource.com/56824\n. java.safe_annotation_processors isn't documented either.\nWhat I wonder: FB does use a code review system: (phabricator?) internally? At least we see, \"Reviewed By:\" footer in commit messages.\nSo how comes that those lines: https://github.com/facebook/buck/blame/master/src/com/facebook/buck/jvm/java/JavaBuckConfig.java#L81-L83 added by this commit: https://github.com/facebook/buck/commit/97a8dc08acce6b0bf04820f2d29bc1fb85957ad1 missing documentation bits? Was that intended not to be documented? In which case i would expect that commit message states that this config options intentionally not documented.\n. That's correct. So may be it makes sense to pass a new parameter merge_manifest set to true by default to java_binary() to be able to suppress merging?\nIn our case the problem is only cluttering of the manifest file. That because we are not defining all possible attributes in input manifest_file we are passing to java_binary(). The actually overriding problem was fixed in #44.\nHowever the manifest file in Gerrit plugins are that important to us, that we have to find a solution for cluttering.\n. Gerrit plugin would work correctly. However, as mentioned on mailing list, there are content in plugin's manifest file that is not related to Gerrit (Apache commons-io library). We are trying to prevent this from happen, having only (!) the entries in uberjar manifest that were provided in input manifest_file to java_binary() method. There are four solutions to our problem:\n- Provide a way in Buck to enforce java_binary() to skip merging of manifest files from dependent JARs\n- strip MANIFEST.MF file from all jar files used in Gerrit\n- add all possible attributes to our own manifest_file content supplied to java_binary() method.\n- patch java_binary() result artifact: define java_binary2(), that calls original java_binary() and replace manifest file with the pristine one\nBefore considering the later 3 options we would like to see the option number one implemented ;-)\n. @shs96c i do agree: no technial motivation here. Only disappointment to see this: [1]. The plugin is called replication and Apache Foundation has nothing to do with this project.\nBut, as pointed out in previous comments it can always be fixed by other means: [2], [3].\n[1] https://gerrit.libreoffice.org/plugins/replication/Documentation/index.html\n[2] https://gerrit-review.googlesource.com/#/c/54880\n[3] https://gerrit-review.googlesource.com/#/c/54890\n. @shs96c Any chance we can find a solution for this in Buck, so that we don't have to do this ugly workaround [1] in our build tool chain:\ngenrule(\n  name = name,\n  cmd = 'cd $TMP' +\n     ';unzip -qo $(location %s)'\n     % (':' + broken_manifest_jar) +\n     ';cp $(location %s) META-INF/MANIFEST.MF'\n     % (':' + sane_manifest) +\n     ';zip -9qr $OUT .',\n  out = '%s.jar' % name,\n  deps = [\n    ':' + broken_manifest_jar,\n    ':' + sane_manifest,\n  ],\n  visibility = visibility,\n)\n[1] https://gerrit-review.googlesource.com/57527\n. @spearce Thanks for checking. It was misunderstanding in our talk in MV from my side and i appologize: I said in chat with @shs96c that Blaze is using special option to prevent merging manifest from dependent JARs and would merge them without this option. \n. @shs96c Thanks.\n. @shs96c Thanks.\n. Fixed by @shs96c.\n. Fixed by @shs96c.\n. @natthu Thanks, that explains that.\n. @shs96c Thanks for fixing it in 2f304c6073761a530ad2a9003391235e37ff87e8 . Just woder, why you didn't link to this issue in the commit message? \n. @bolinfest Thanks. Looks good. Performance is OK now. One question, If i'm reading the code correctly the default for local_workers is 2? Why not:\nfactor * Runtime.getRuntime().availableProcessors();\nBefore switch to gwt_binary() we called GWT compiler from python code with:\nstr(cpu_count())\nbut now i think it's more cleaner to do it from gwt_binary() and not to from the client code.\n. @bolinfest OK, using local_workers = cpu_count() for now. The switch to gwt_binary() change is here [1] if this was your question.\n\nI'm curious where the biggest hacks are in the Gerrit build after that lands. I know there's the Maven \nstuff that you do, but are there any other major \n\nYes, Maven stuff, Eclipse support and exposing reusable Buck recipes outside of the Gerrit Code Review project to Gerrit ecosystem: Gerrit plugins, Gitiles, JGit and other projects. We have extracted some rules into Bucklets project [2] and re-using it so far in Gitiles [3] as Git submodule. That works, but we are waiting for native support for reusable recipes in Buck.\n[1] https://gerrit-review.googlesource.com/57160\n[2] https://gerrit.googlesource.com/bucklets/+/master\n[3] https://gerrit.googlesource.com/gitiles/+/master\n. @bolinfest I've noticed that suffix of the gwt_binary() artifact is war:\n./buck-out/gen/gerrit-gwtui/__gwt_binary_ui_safari__/ui_safari.war\nThat's kind of unexpected. war has predefined structure, manifest.mf, etc. I would expect gwt_binary() output to have suffix .zip, that what our old GWT tool chain (compiler.py) was doing.\nAnother issue was to link the output produced by gwt_binary() from subdirectory to parent directory:\ngenrule(\n      name = gwt_zip,\n      cmd = 'ln -s $(location :%s) $OUT' % gwt_name,\n      deps = [':%s' % gwt_name],\n      out = gwt_zip,\n    )\nSo that it can be reached under:\n./buck-out/gen/gerrit-gwtui/ui_safari.zip\nCould gwt_binary() do it per default, without extra linking step on the client side?\n. @bolinfest Thanks for adding -Dgwt.normalizeTimestamps=true and changing the output file to .zip. \n\nAre there any other regressions in moving to gwt_binary()?\n\nI have an issue with recovering from compile errors in GWT code:\n- conduct an error in GWT code\n- compile with buck build //gerrit-gwtui:ui_safari, note that output file is not created.\n- revert the error\n- call the target again:\n$ buck build //gerrit-gwtui:ui_safari && file `buck targets --show_output //gerrit-gwtui:ui_safari | awk '{print $2}'`\nWatchman not found, please install when using buckd.\nSee https://github.com/facebook/watchman for details.\n[-] PARSING BUILD FILES...FINISHED 0,6s\n[-] BUILDING...FINISHED 0,3s\nLog:\nWatchman not found, please install when using buckd.\nSee https://github.com/facebook/watchman for details.\n[-] PARSING BUILD FILES...FINISHED 0,6s\nbuck-out/gen/gerrit-gwtui/__gwt_binary_ui_safari__/ui_safari.zip: ERROR: cannot open `buck-out/gen/gerrit-gwtui/__gwt_binary_ui_safari__/ui_safari.zip' (No such file or directory)\nTo recover from this situation, i've found that only buck clean helps so far:\n$ buck clean \nWatchman not found, please install when using buckd.\nSee https://github.com/facebook/watchman for details.\ndavido@linux-ucwl:~/projects/gerrit (upgrade-buck %)$ buck build //gerrit-gwtui:ui_safari && file `buck targets --show_output //gerrit-gwtui:ui_safari | awk '{print $2}'`\nWatchman not found, please install when using buckd.\nSee https://github.com/facebook/watchman for details.\n[-] PARSING BUILD FILES...FINISHED 0,6s\n[-] BUILDING...FINISHED 1,2s\nWatchman not found, please install when using buckd.\nSee https://github.com/facebook/watchman for details.\n[-] PARSING BUILD FILES...FINISHED 0,6s\nbuck-out/gen/gerrit-gwtui/__gwt_binary_ui_safari__/ui_safari.zip: Zip archive data, at least v1.0 to extract Java Jar file data (zip)\nThe output file seems not to be created from the cache after GWT error. We are using the following caching strategy:\n[cache]\n  mode = dir\n  dir = buck-out/cache\n. > I don't follow: in your first example, I only see one command run.\nOK, first successful buck run was missing:\n- buck build //gerrit-gwtui:ui_safari => successful, output file was created\n- create an error in GWT class\n- compile with buck build //gerrit-gwtui:ui_safari => the error is reported and the output file is removed\n- revert the error\n- repeat buck build //gerrit-gwtui:ui_safari => successful, still output file is missing\n. @bolinfest Exactly. That's what i am saying. It looks like it isn't get compiled new, normal compile time would be around 30 sec. but the third call after revert of my error change is ready after 1 sec. So  i think that something is going wrong with cache handling. If you prefer i could create a reproducer.\n. Unfortunately it doesn't work (yet).\n. @bolinfest \n\nI believe this is not specific to Buck.\n\nYou mean it's not specific to the gwt_binary()?\n\nHa: look at the TODO I wrote for myself on line 224.\n\n// TODO(mbolin): Delete all genfiles and metadata, as they are not guaranteed to be\n// valid at this point?\n;-)\n. @bolinfest Thanks, works like a charm:\n$ git checkout gerrit-gwtui/src/main/java/com/google/gerrit/client/change/ChangeScreen2.ui.xml\n$ buck build safari && file `buck targets --show_output //gerrit-gwtui:ui_safari | awk '{print $2}'`\nWatchman not found, please install when using buckd.\nSee https://github.com/facebook/watchman for details.\n[-] PARSING BUILD FILES...FINISHED 1,1s\n[-] BUILDING...FINISHED 0,8s\nLog:\nWatchman not found, please install when using buckd.\nSee https://github.com/facebook/watchman for details.\n[-] PARSING BUILD FILES...FINISHED 0,6s\nbuck-out/gen/gerrit-gwtui/__gwt_binary_ui_safari__/ui_safari.zip: Zip archive data, at least v1.0 to extract Java Jar file data (zip)\n. > Are you able to run GWT tests with the ordinary java_test() rule? \nWe have only very few GWT specific tests and we are using GWT test utils library [1] :\njava_test(\n  name = 'ui_tests',\n  srcs = glob(['src/test/java/**/*.java']),\n  resources = glob(['src/test/resources/**/*']) + [\n    'src/main/java/com/google/gerrit/GerritGwtUI.gwt.xml',\n  ],\n  deps = [\n    ':ui_module',\n    '//gerrit-common:client',\n    '//gerrit-extension-api:client',\n    '//lib:junit',\n    '//lib/gwt:dev',\n    '//lib/gwt:user',\n    '//lib/gwt:gwt-test-utils',\n    '//lib/jgit:jgit',\n  ],\n  source_under_test = [':ui_module'],\n  vm_args = ['-Xmx512m'],\n  visibility = ['//tools/eclipse:classpath'],\n)\n[1] https://github.com/gwt-test-utils/gwt-test-utils\n. @bolinfest Just to let you know: gwt_binary() migration series was merged tonight. Thanks again!\nThe only three custom Buck hacks in Gerrit itself and its eco systems are:\n- maven_jar(): https://github.com/facebook/buck/issues/64\n- Eclipse import: https://github.com/facebook/buck/issues/65\n- Share Buck rules between different projects: https://github.com/facebook/buck/issues/116\n. I've spent some time to understand why small extension to  Gerrit GWT Plugin API worked as expected in standalone build mode, but failed to compile in Gerrit tree mode: [1]. Classpath of GWT compiler invocation was polluted with dozens of pseudo GWT modules, that interfered with this new extension. \nWhat happened? The easiest way to see the problem is to check the source code: [2].\nIt turns out (it wasn't really clear to me) that the implementation reconstructs GWT modules from the dependency graph. In Gerrit tree build //gerrit-plugin-api:lib that was passed here, resolved to dozens of rules and thus the whole Gerrit server stuff was included as GWT modules and passed to the GWT compiler. Even though we used provided deps.\nIn standalone mode, that makes use of bucklets, the implementation is different: plugin-api.jar is fetched from Central and is used as module deps. Dependency graph here is empty, so nothing is passed in addition to GWT compiler and the classpath wasn't polluted.\nI think that the reachability resolution algorithm should differentiate between provided deps and normal deps. Another option to consider is to make dependency module resolution configurable.\n[1] https://gerrit-review.googlesource.com/#/c/63489\n[2] https://github.com/facebook/buck/blob/master/src/com/facebook/buck/gwt/GwtBinaryDescription.java#L115,L138\n. Interesting.  \n\n@repo//path/to/buck/file:target-name\n\nSo the old code [1] to consume maven_jar() buckler 2 would change from\n```\ninclude_defs('//bucklets/maven_jar.bucklet')\nmaven_jar(\n  name = 'guava',\n  id = 'com.google.guava:guava:17.0',\n)\n```\nto\n```\ninclude_defs('https://github.com/davido/bucklets//maven_jar.bucklet')\nmaven_jar(\n  name = 'guava',\n  id = 'com.google.guava:guava:17.0',\n)\n```\nor even just:\n@https://github.com/davido/maven_jar.bucklet:maven_jar(\n  name = 'guava',\n  id = 'com.google.guava:guava:17.0',\n)\n?\n@https://github.com/davido/maven_jar.bucklet:maven_jar would be too verbose to write. May be provide a .bucklets file with alias/mapping of external targets to internal ones:\n$cat .bucklets\nmaven_jar = @https://github.com/davido/maven_jar.bucklet:maven_jar\nlocal_jar = @https://github.com/davido/local_jar.bucklet:local_jar\n[...]\nIf @https://github.com/davido/maven_jar.bucklet:maven_jar includes only one target\nmaven_jar() may be maven_jar suffix can be omitted?\nAnother question: the backend for maven_jar() is actually download_file.py [3]. Would it work and be seamlessly available from the remote repo in the local build process as well?\nIf you can provide a patch for it, (as a file or branch) i would be happy to give it a try.\n[1] https://gerrit.googlesource.com/gitiles/+/master/lib/BUCK\n[2] https://gerrit.googlesource.com/bucklets/+/master/maven_jar.bucklet\n[3] https://gerrit.googlesource.com/bucklets/+/master/tools/download_file.py\n. > include_defs('@bucklets//bucklets:maven_jar')\nVery promising.\nWhere is the link/mapping between '@bucklets//bucklets:maven_jar' and actual @repo (https://github.com/davido in example above)?\nWhen two different files would reference the same remote target, i. e.:\n```\n$cat lib/guava/BUCK\ninclude_defs('@bucklets//bucklets:maven_jar')\nmaven_jar(\n  name = 'guava',\n  id = 'com.google.guava:guava:17.0',\n)\n$cat lib/gwt/BUCK\ninclude_defs('@bucklets//bucklets:maven_jar')\nmaven_jar(\n  name = 'gwt-dev',\n  id = 'com.google.gwt:gwt-dev:' + VERSION,\n  license = 'Apache2.0',\n  deps = [\n    ':javax-validation',\n    ':javax-validation_src',\n  ],\n  attach_source = False,\n  exclude = ['org/eclipse/jetty/*'],\n)\n```\nWe would get multiple maven_jar() target definitions? One per file where it is used?\n. > Cross repo (or cross cell, as we are going to call it) is currently under development and although preliminary support has landed in the master branch, most build rules do not support it properly yet.\nCan the cell support be extended to non locally cloned repositories? The idea behind plugins or extensions or bucklets concept is to make them first-class citizens in Buck. In similar way, Buck allows to specify what buck version to use in .buckversion file, I would expect to be able to provide some meta data for cell without actually cloning it:\n[cell name = \"bucklets\"]\n    remote =  https://github.com/davido/bucklets\n    version = d2936a48fc559e90b66e83de7ff163202e75486b\n    # optional, with sensible default, e.g.\n    # local = $HOME/.bucklets\nin some configuration file, and without cloning this repo, or adding it to my own project as a submodule. I should be able to say include_defs('//bucklets/gerrit_plugin.bucklet') and just use gerrit_plugin rule. See also how the cross repo rule sharing is implemented in Gerrit plugin by using Git submodule concept: [1]. The problem to solve is, that buck build foo would need to take care for checking and cloning the cell(s) for me and make them accessible (I call this \"mount\") from within build rules, like //foo/bar/baz, where foo is a known cell and also from the shell, because Eclipse project generation is implemented as a standalone Python script: [2] and currently invoked as:\n./bucklets/tools/eclipse.py\nAnother approach would be to add dedicated Buck command to handle that with say buck getcell, something similar is done with Golang's go get: [3] command:\nget download and install packages and dependencies\n[1] https://github.com/davido/gerrit-oauth-provider/blob/master/BUCK#L1,L24\n[2] https://github.com/davido/bucklets/blob/master/tools/eclipse.py\n[3] https://golang.org/cmd/go\n. I started to implement cross cell support in gerrit, to simplify workflow for integration of WIP stuff across project boundaries. One typical example of it include changes in JGit (main Gerrit dependency and Git implementation in Java programming language), Gerrit itself and dedicated plugin, when the feature implementation is split in core and plugin part, like for example LFS support to allow plugin to provide their own specific protocol implementations: [1]. [2], [3].\nI hope that cross cell support, isolating jgit in gerrit project in its own cell, can solve this. It would work as is per default and could be hijacked per CLI option and be routed to JGit development tree. I still have some issues to make it actually work and filed #544 and #545.\nAnother problem I'm facing is the missing support for include_def() across cell boundaries. My hope was, that when fetching of cell is solved, the cross-cell concept would replace git submodules for reusing of Buck build files, see https://github.com/davido/bucklets.\nSo when a plugin is implemented standalone Buck build (outside of gerrit tree), see for example: https://github.com/davido/gerrit-oauth-provider it's basically consuming pre-defined bucklet: [4]\ninclude_defs('//bucklets/gerrit_plugin.bucklet')\nRight now I'm getting error: \"include should start with '//' or some such\" when i was trying to pass cell prefix: @bucklets//gerrit_plugin.buckletto include_def(). Is this something that will be supported in future or cell concept is mainly to share rules and not build files? In which case we still don't have any replacement for git submodules? \n- [1] https://git.eclipse.org/r/61472/\n- [2] https://gerrit-review.googlesource.com/72891\n- [3] https://gerrit-review.googlesource.com/72892\n- [4] https://github.com/davido/bucklets/blob/master/gerrit_plugin.bucklet\n. Two years later, after this issue was created, I've discovered, that Bazel team released the cross project dependency support, with the ability to fetch the deps from remote repositories, \"mount\" and re-use them in build toolchain: [1].\ngit_repository(\n    name = \"io_bazel_rules_scala\",\n    remote = \"https://github.com/bazelbuild/rules_scala.git\",\n    tag = \"0.0.1\",\n)\nload(\"@io_bazel_rules_scala//scala:scala.bzl\", \"scala_repositories\")\nscala_repositories()\n[...]\nThis will download all of the tools the rules need to build Scala programs.\nThen load and use normally from your BUILD files:\nload(\"@io_bazel_rules_scala//scala:scala.bzl\", \"scala_library\")\nscala_library(...)\nWe have extracted Bucklets from Gerrit Code Review build tool chain: [2]. Unfortunately, Buck still doesn't have support for fetching and using external Buck scripts. And it's just annoying to link Bucklets as git submodules to each and every Gerrit Code Review plugin: [3].\n[1] http://www.bazel.io/blog/2016/02/23/0.2.0-release.html\n[2] https://github.com/davido/bucklets\n[3] https://github.com/davido/gerrit-oauth-provider\n. > Would you be up for writing a test for this behavior too so it doesn't get accidentally broken?\nDone\n. @sdwilsh Thanks. Really appreciate your help on it!\n. @sdwilsh Thanks. Really appreciate your help on it!\n. @oconnor663 Thank you for pushing the PR and for polishing it in follow-up change!\n. @shs96c Is this related to discontinuation of genfile() macro, as discussed on this thread [1]?\n[1] https://groups.google.com/forum/#!topic/buck-build/Ci8Y95USD8I\n. @shs96c Thanks! You forgot to mention this issue in the commit message ;-)\n. @shs96c Thanks! You forgot to mention this issue in the commit message ;-)\n. @sdwilsh @natthu Thanks for the quick fix. We have applied it on our tree: [1].\n[1] https://gerrit-review.googlesource.com/#/c/57713\n. @bolinfest According to your post in [1] and provided example there:\ngenrule(\n  name = 'example',\n  srcs = [ 'manifest.txt', ':foo', ':bar' ],\n  cmd = 'some_command $SRCS',\n)\nI probably don't need to use location() macro at all in my javascript minify bucklet [2], and can just use:\ndef js_minify(\n    name,\n    out,\n    srcs,\n    compiler_args = []:\n  cmd = ['$(exe :js_minifier) --js_output_file $OUT']\n    + compiler_args\n    + ['$SRCS']\n  genrule(\n    name = name,\n    cmd = ' '.join(cmd),\n    srcs = srcs,\n    out = out,\n)\n[1] https://groups.google.com/d/topic/buck-build/bJ-UeV_hENw/discussion\n[2] https://gerrit-review.googlesource.com/#/c/57639/3/js_minify.bucklet\n. Yes.\n. Yes.\n. Every one who is targeting java platform has a toolchain that suports and expects junit format. So I would really expect the Buck to povide something like:\nbuck test --xml-junit [..]\nAt very least would you consider to host stylesheet transformation utility, like one in: [1] so that not every project would need to add this bucklet as a git submodule?\n- [1] https://gerrit-review.googlesource.com/69762\n. Every one who is targeting java platform has a toolchain that suports and expects junit format. So I would really expect the Buck to povide something like:\nbuck test --xml-junit [..]\nAt very least would you consider to host stylesheet transformation utility, like one in: [1] so that not every project would need to add this bucklet as a git submodule?\n- [1] https://gerrit-review.googlesource.com/69762\n. I wonder how i can reproduce it? I am asking because if i'm trying to create idea project for Gerrit with buck project, the generated files are almost empty.\n. Thanks @oconnor663. That might be the reason.\n. Shoudn't be native part of Buck.\n. @sdwilsh It still doesn't work. I've updated .buckversion, Buck was rebuilt, but the behaviour is unchanged:\n```\n$ cat .buckversion\n0cd750f6443412992bf1add8a73ad8d914917ff6\n$ buck clean\nShutting down nailgun server...\nUsing watchman.\nUsing buckd.\n$ buck build app\nUsing buckd.\n[-] PROCESSING BUCK FILES...FINISHED 0,1s\n[+] BUILDING...0,0s\nBUILD FAILED: No known output for: //:httpmime-src\n```\nI've update the reproducer repository [1] to reflect Buck update.\n[1] https://github.com/davido/buck_remote_file\n. Great! Any chance to provide some syntactic sugar here, as it almost always would need to say something like:\n```\nmaven_jar(\n   name = 'httpmime',\n   id = 'org.apache.httpcomponents:httpmime:4.3.4',\n   bin_sha1 = '54ffde537682aea984c22fbcf0106f21397c5f9b',\n   src_sha1 = '0651e21152b0963661068f948d84ed08c18094f8',\n   repository = 'http://foo/bar',\n)\n```\nWhere src_sha1 and repository would be optional. I would expect, that the statement above would be translated by Buck to something like:\n```\nprebuilt_jar(\n  name = 'httpmime',\n  binary_jar = ':httpmime-jar',\n  source_jar = ':httpmime-src',\n)\nremote_file(\n  name = 'httpmime-jar',\n  sha1 = '54ffde537682aea984c22fbcf0106f21397c5f9b',\n  url = 'mvn:org.apache.httpcomponents:httpmime:jar:4.3.4',\n  out = 'httpmime.jar',\n)\nremote_file(\n  name = 'httpmime-src',\n  sha1 = '0651e21152b0963661068f948d84ed08c18094f8',\n  url = 'mvn:org.apache.httpcomponents:httpmime:src:4.3.4',\n  out = 'httpmime-src.jar',\n)\n```\nThis can be done later, though.\n. I wonder if path resolution for SNAPSHOT artifacts would work as expected? I think i haven't seen code (and unit test) in related commit that would handle it. Something that would correspond to this if in our maven_jar() bucklet [1]:\nif 'SNAPSHOT' in version and repository == MAVEN_LOCAL:\n    file_version = version\n  else:\n    file_version = version.replace('-SNAPSHOT', '')\n    version = version.split('-SNAPSHOT')[0] + '-SNAPSHOT'\nFor example, would it be possible to fetch this artifact:\nhttps://oss.sonatype.org/content/repositories/google-snapshots/com/google/gwt/gwt-dev/2.7.0-SNAPSHOT/gwt-dev-2.7.0-20140918.053736-55.jar\nwith url defined in this way:\nmvn:com.google.gwt:gwt-dev:2.7.0-SNAPSHOT-20140918.053736-55\n?\n[1] https://gerrit-review.googlesource.com/#/c/59723/1/maven_jar.bucklet\n. > Do you use them on gerrit?\nNormally we don't. But when we are releasing our own dependent libraries, like GWTORM, we publish SNAPSHOT version of it on Google storage bucket first, and then we consume the snapshot version in Gerrit. This way we test first that gerrit works against snapshot version of GWTORM. That why must be able to fetch SNAPSHOT artifacts from Gerrit. When test are OK, we release normal version and change Gerrit to consume release version.\n. Yes, it is. Thanks.\n. Thanks for your help! The Cygwin documentation claims that different symlink options are supported [1]. We would need to figure out what is the best option for Buck@Cygwin combination.\n[1] http://cygwin.com/cygwin-ug-net/using.html#pathnames-symlinks\n. OK, there are number of problems:\n- monotonic_time_nanos() must be defined for every platform\n- path conversion between Cygwin and Windows is missing in buck_repo.py. This is needed because Java is Windows process and it cannot resolve Cygwin specific paths: /cygdrive/c/... so that cygpath utility must be used to perform path conversions\n- Cygwin's Python exe cannot be found from the Java process\n. > I've got a diff up for the monotonic_time_nanos() problem,\nGreat!\n\nFor the Python interpreter, have you set the value in \"[tools] -> python\" in your .buckconfig?\n\nSure i did. With:\n[tools]\n  python = C:/Cygwin/bin/python2.7.exe\ni can successfully execute buck --help on Cygwin. However trying to build Gerrit Code Review project is still failing during parsing of BUCK file (BUILD FAILED).\nUnfortunately i cannot see why, even increasing the verbosity level doesn't seem to help.\n. Yes, i am using Windows Java version. You mean to use native Windows python and not cygwin port?\n. > I wonder if you tried something like c:/python27/python.exe whether things would work?\nit doesn't:\n$ buck build gerrit --verbose 42\n:::\n::: '.nobuckcheck' file is present. Not updating buck.\n:::\nNot using buckd because watchman isn't installed.\n[-] PARSING BUCK FILES...FINISHED 0,1s\nBUILD FAILED: Parse error for BUCK file C:\\Users\\david\\projects\\gerrit\\BUCK: \\cygdrive\\c\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.e8WLbI\\buck1343545243989271392.py\n[2014-09-22 08:49:30.762][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] CommandStarted(build, isDaemon: false)\n[2014-09-22 08:49:30.801][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] ArtifactCacheConnectStarted()\n[2014-09-22 08:49:30.804][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] ArtifactCacheConnectFinished()\n[2014-09-22 08:49:30.804][info ][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] Build started at 2014-09-22 08:49:30.804\n[2014-09-22 08:49:30.806][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] ParseStarted(//:gerrit)\n[2014-09-22 08:49:30.806][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.parser.Parser] Parser invalidating entire cache on default include change.\n[2014-09-22 08:49:30.806][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.parser.Parser] Parser invalidating entire cache on environment change.\n[2014-09-22 08:49:30.806][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.parser.Parser] Parsing BUCK file: C:\\Users\\david\\projects\\gerrit\\BUCK\n[2014-09-22 08:49:30.807][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.json.ProjectBuildFileParser] Creating temporary buck.py instance...\n[2014-09-22 08:49:30.807][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] BuckFilesParseStarted()\n[2014-09-22 08:49:30.900][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] BuckFilesParseFinished()\n[2014-09-22 08:49:30.901][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] ParseFinished(//:gerrit)\n[2014-09-22 08:49:30.901][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] CommandFinished(build, isDaemon: false)\n. But the reason to run Buck@Cygwin was to be able to access Unix commands, like zip and friends that are used by Gerrit build toolchain, not?\n. I will check the logs and post everything i can find there later today.\n. I checked buck-out/logs directory. There are some files, like buck-x.log. In most recent one buck-0.log is almost the same content as reported on the command line:\n[2014-09-22 08:49:30.546][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.cli.Main] Starting up with args: [build, gerrit, --verbose, 42]\n[2014-09-22 08:49:30.762][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] CommandStarted(build, isDaemon: false)\n[2014-09-22 08:49:30.801][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] ArtifactCacheConnectStarted()\n[2014-09-22 08:49:30.804][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] ArtifactCacheConnectFinished()\n[2014-09-22 08:49:30.804][info ][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] Build started at 2014-09-22 08:49:30.804\n[2014-09-22 08:49:30.806][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] ParseStarted(//:gerrit)\n[2014-09-22 08:49:30.806][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.parser.Parser] Parser invalidating entire cache on default include change.\n[2014-09-22 08:49:30.806][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.parser.Parser] Parser invalidating entire cache on environment change.\n[2014-09-22 08:49:30.806][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.parser.Parser] Parsing BUCK file: C:\\Users\\david\\projects\\gerrit\\BUCK\n[2014-09-22 08:49:30.807][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.json.ProjectBuildFileParser] Creating temporary buck.py instance...\n[2014-09-22 08:49:30.807][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] BuckFilesParseStarted()\n[2014-09-22 08:49:30.900][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] BuckFilesParseFinished()\n[2014-09-22 08:49:30.901][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] ParseFinished(//:gerrit)\n[2014-09-22 08:49:30.901][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:11][com.facebook.buck.event.listener.LoggingBuildListener] CommandFinished(build, isDaemon: false)\n[2014-09-22 08:49:30.973][debug][command:78f1a0bd-7fda-d3bc-02e1-5d864e04434e][tid:01][com.facebook.buck.cli.Main] Done.\n. OK, i looked into it: the problem was that i havn't replaced all paths in buck_repo.py with cygpath. One that was missing was tmpdir. So that:\nPath buckDotPy = Files.createTempFile(\"buck\", \".py\");\nwas always failing. With new patch: [1] it does work.\nNow I am getting another parsing error, but now i have stack trace in log directory:\n$ buck build gerrit\n:::\n::: '.nobuckcheck' file is present. Not updating buck.\n:::\nNot using buckd because watchman isn't installed.\nTraceback (most recent call last):\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 1373, in <module>\n    main()\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 698, in main\n    values = buildFileProcessor.process(build_file.rstrip())\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 609, in process\n    implicit_includes=self._implicit_includes)\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 600, in _process_build_file\n    implicit_includes=implicit_includes)\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 564, in _process\n    exec(code, module.__dict__)\n  File \"C:\\Users\\david\\projects\\gerrit\\lib\\codemirror\\BUCK\", line 3, in <module>\n    include_defs('//lib/codemirror/closure.defs')\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 488, in _include_defs\n    implicit_includes=implicit_includes)\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 581, in _process_include\n    implicit_includes=implicit_includes)\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 564, in _process\n    exec(code, module.__dict__)\n  File \"C:\\Users\\david\\projects\\gerrit\\lib/codemirror/closure.defs\", line 29, in <module>\n    deps = [':compiler-jar']\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 90, in invoke\n    return self.func(*args, **updated_kwargs)\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 1186, in java_binary\n    }, build_env)\n  File \"C:\\Users\\david\\projects\\gerrit\\buck-out\\tmp\\buck_run.Wg_JIT\\buck1191013345474708211.py\", line 101, in add_rule\n    .format(rule['type']))\nAssertionError: Cannot use `java_binary()` at the top-level of an included file.\n[2014-09-26 00:42:28.411][error][command:d4ea5abc-c3be-094f-930e-d1b5cf7c13f9][tid:01][com.facebook.buck.json.ProjectBuildFileParser] Process java.lang.ProcessImpl@f67e9 exitedith error code 1\n[-] PARSING BUCK FILES...FINISHED 1,3s\nBUILD FAILED: Parse error for BUCK file C:\\Users\\david\\projects\\gerrit\\lib\\codemirror\\BUCK: java.lang.IllegalStateException: Expected BEGIN_ARRAY but was END_DOCUMENT at line 1column 1\nWhere the lib\\codemirror\\BUCK is [2]. and at line 17 starts this rule:\ngenrule(\n  name = 'css',\n  cmd = ';'.join([\n      ':>$OUT',\n      \"echo '/** @license' >>$OUT\",\n      'unzip -p $(location :zip) %s/LICENSE >>$OUT' % TOP,\n      \"echo '*/' >>$OUT\",\n    ] +\n    ['unzip -p $(location :zip) %s/%s >>$OUT' % (TOP, n)\n     for n in CM3_CSS + CM3_THEMES]\n  ),\n  deps = [':zip'],\n  out = 'cm3.css',\n)\n[1] http://paste.openstack.org/show/115430/\n[2] https://gerrit.googlesource.com/gerrit/+/master/lib/codemirror/BUCK\n. With the latest master (e96d2402b219294aa9a5c13d786f51d088ff86b5) Javac ist not found:\n```\n$ buck build plugin\n:::\n::: '.nobuckcheck' file is present. Not updating buck.\n:::\nNot using buckd because watchman isn't installed.\n[-] PARSING BUCK FILES...FINISHED 0,0s\nBUILD FAILED: //:plugin-lib failed on step javac with an exception:\nIf using JRE instead of JDK, ToolProvider.getSystemJavaCompiler() may be null.\njava.lang.NullPointerException: If using JRE instead of JDK, ToolProvider.getSystemJavaCompiler() may be null.\n        at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:229)\n        at com.facebook.buck.java.JavacInMemoryStep.buildWithClasspath(JavacInMemoryStep.java:131)\n        at com.facebook.buck.java.JavacStep.executeBuild(JavacStep.java:159)\n        at com.facebook.buck.java.JavacStep.execute(JavacStep.java:150)\n        at com.facebook.buck.step.DefaultStepRunner.runStepInternal(DefaultStepRunner.java:98)\n        at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:83)\n        at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:496)\n        at com.facebook.buck.rules.CachingBuildEngine.buildOnceDepsAreBuilt(CachingBuildEngine.java:374)\n        at com.facebook.buck.rules.CachingBuildEngine.access$3(CachingBuildEngine.java:298)\n        at com.facebook.buck.rules.CachingBuildEngine$1.onSuccess(CachingBuildEngine.java:181)\n        at com.facebook.buck.rules.CachingBuildEngine$1.onSuccess(CachingBuildEngine.java:1)\n        at com.google.common.util.concurrent.Futures$5.run(Futures.java:1231)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n        at java.lang.Thread.run(Unknown Source)\n[-] BUILDING...FINISHED 0,3s\n```\nAnd the diff that solves this bug is:\n```\n$ git diff\ndiff --git a/bin/buck b/bin/buck\nindex 8ab44e4..2343b18 100755\n--- a/bin/buck\n+++ b/bin/buck\n@@ -17,8 +17,6 @@ def main():\n         path = os.getenv(\"PATH\", \"\")\n         if java_home:\n             pathsep = os.pathsep\n-            if sys.platform == 'cygwin':\n-                pathsep = ';'\n             os.environ[\"PATH\"] = os.path.join(java_home, 'bin') + pathsep + path\n     tracing_dir = None\n\n```\nThe previous error was reported on test project. Trying to build intermediate Gerrit target produces the following error:\n$ buck build //gerrit-server:server\n:::\n::: '.nobuckcheck' file is present. Not updating buck.\n:::\nNot using buckd because watchman isn't installed.\n[-] PARSING BUCK FILES...FINISHED 0,3s\njava.io.IOException: Cannot run program \"C:\\Users\\david\\projects\\buck\\src\\com\\facebook\\buck\\python\\pex.py\" (in directory \"C:\\Users\\david\\projects\\gerrit\"): CreateProcess error=193, %1 ist keine zul\u2592ssige Win32-Anwendung\n        at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)\n        at com.facebook.buck.shell.ShellStep.execute(ShellStep.java:112)\n        at com.facebook.buck.step.DefaultStepRunner.runStepInternal(DefaultStepRunner.java:98)\n        at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:83)\n        at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:496)\n        at com.facebook.buck.rules.CachingBuildEngine.buildOnceDepsAreBuilt(CachingBuildEngine.java:374)\n        at com.facebook.buck.rules.CachingBuildEngine.access$3(CachingBuildEngine.java:298)\n        at com.facebook.buck.rules.CachingBuildEngine$1.onSuccess(CachingBuildEngine.java:181)\n        at com.facebook.buck.rules.CachingBuildEngine$1.onSuccess(CachingBuildEngine.java:1)\n        at com.google.common.util.concurrent.Futures$5.run(Futures.java:1231)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:722)\nCaused by: java.io.IOException: CreateProcess error=193, %1 ist keine zul\u2592ssige Win32-Anwendung\n        at java.lang.ProcessImpl.create(Native Method)\n        at java.lang.ProcessImpl.<init>(ProcessImpl.java:189)\n        at java.lang.ProcessImpl.start(ProcessImpl.java:133)\n        at java.lang.ProcessBuilder.start(ProcessBuilder.java:1021)\nThe whole truth is:\nhttp://paste.openstack.org/show/120365\n. Great progress on Cygwin. With small diff from previous comment i am able (first time) to build a JAR on Cygwin using this reproducer repository https://github.com/davido/buck_test :+1: \n```\n$ buck build plugin\n:::\n::: '.nobuckcheck' file is present. Not updating buck.\n:::\nNot using buckd because watchman isn't installed.\n[-] PARSING BUCK FILES...FINISHED 0,0s\n[-] BUILDING...FINISHED 1,1s\n$ java -jar buck-out/gen/plugin.jar\nImplementation-Version: 1.0\nExpected Implementation-Version: 1.0\n```\nI will let this issue open to track problems building Gerrit on Cygwin.\n. Actually not, it can be run:\n$ gcc\ngcc: no input files\nBut somehow i managed to run it not on recent master. It turns out it can be built, as the OS is dos and windows and not unix:\n```\n$ ant -v client\nApache Ant(TM) version 1.9.0 compiled on March 5 2013\n[...]\nclient:\n    [mkdir] Skipping C:\\Users\\david\\projects\\buck\\build because it already exists.\nBUILD SUCCESSFUL\nTotal time: 0 seconds\n```\nSorry for the noise.\n. Duplicate of https://github.com/facebook/buck/issues/102\n. It mostly works. This was already reported and tracked in https://github.com/facebook/buck/issues/182. According to comments there, this bug was already fixed and the fix about to land shortly.\n. I probably misread your bug report, but this is unusually that you observe failure on sha1 line. I think exact your setting is up and running in gitiles project. Try pull and bulid it with buck build all and see how it's different from your case: [1]. Note, that gitile is using bucklet as submodule.\n[1] git clone https://gerrit.googlesource.com/gitiles\n. So this works: include this lines in .buckconfig :\n[buildfile]\n  includes = //bucklets.defs\nAnd put this in bucklet.defs:\n```\n$ cat bucklets.defs\nimport os\nimport sys\nd = os.getcwd()\nwhile not os.path.lexists(os.path.join(d, '.buckversion')):\n  d = os.path.dirname(d)\nbd = os.path.join(d, 'bucklets')\nif not os.path.isdir(bd) or not os.listdir(bd):\n  sys.stderr.write(('Bucklets directory is missing or empty: %s\\n'\n                    'Run git submodule update --init') % bd)\n  sys.exit(1)\nbucklets = [\n  'java_doc.bucklet',\n  'java_sources.bucklet',\n  'maven_jar.bucklet',\n  'maven_package.bucklet',\n  'war.bucklet',\n]\nfor bucklet in bucklets:\n  path = os.path.join(bd, bucklet)\n  if not os.path.isfile(path):\n    sys.stderr.write('Missing bucklet: %s\\n' % path)\n    sys.exit(1)\n  include_defs('//bucklets/%s' % bucklet)\n```\nAnd now you don't need any more to include bucklets directly in you BUCK file, but should be able to just say:\nmaven_jar(\n  name = 'junit',\n  id = 'junit:junit:4.11',\n  sha1 = '4e031bb61df09069aeb2bffb4019e7a5034a4ee0'\n)\nOr better say this to reflect hamcrest deps as well:\n```\nmaven_jar(\n  name = 'junit',\n  id = 'junit:junit:4.11',\n  sha1 = '4e031bb61df09069aeb2bffb4019e7a5034a4ee0',\n  deps = [':hamcrest-core'],\n)\nmaven_jar(\n  name = 'hamcrest-core',\n  id = 'org.hamcrest:hamcrest-core:1.3',\n  sha1 = '42a25dc3219429f0e5d060061f71acb49bf010a0',\n  visibility = ['//lib:junit'],\n)\n```\n. Thanks for reporting. Change under review [1].\n[1] https://gerrit-review.googlesource.com/60264\n. Thanks for reporting. Change under review [1].\n[1] https://gerrit-review.googlesource.com/60264\n. It was pointed out in https://github.com/facebook/buck/issues/199 we can potentially have endless loop with one of workarounds.\n. It was pointed out in https://github.com/facebook/buck/issues/199 we can potentially have endless loop with one of workarounds.\n. On most recent master (38350d30da0e13b95f7085c3baf7dca5c5ff8c26) the error message changed:\nCannot use `get_base_path()` at the top-level of an included file.\nSo the question is still what is the best and portable way to figure out the base directory in file sourced from buildfile.includes section in .buckconfig?\n. On most recent master (38350d30da0e13b95f7085c3baf7dca5c5ff8c26) the error message changed:\nCannot use `get_base_path()` at the top-level of an included file.\nSo the question is still what is the best and portable way to figure out the base directory in file sourced from buildfile.includes section in .buckconfig?\n. Apparently \"won't fix\".\n. Apparently \"won't fix\".\n. After upload of this PR i've thought about introducing another method: get_project_root() that works in build and include contexts.\n. After upload of this PR i've thought about introducing another method: get_project_root() that works in build and include contexts.\n. @sdwilsh @andrewjcg Any progress on this PR?\n. @sdwilsh @andrewjcg Any progress on this PR?\n. I was trying shell backticks: it was failing with scary error messages. I probably did something wrong.\n. > Does using \"\\$(dirname ...)\" work?\nYes, that fixed it. Thanks. Documening this would be nice, though.\n. Opps. It actually didn't fix it:\ngenrule(\n  name = 'ui_optdbg',\n  cmd = 'cd $TMP;' +\n    'unzip -q $(location :ui_dbg);' +\n    'mv' +\n    ' gerrit_ui/gerrit_ui.nocache.js' +\n    ' gerrit_ui/dbg_gerrit_ui.nocache.js;' +\n    'unzip -qo $(location :ui_opt);' +\n    'mkdir -p \\$(dirname $OUT);' +\n    'zip -qr $OUT .',\n  deps = [\n    ':ui_dbg',\n    ':ui_opt',\n  ],\n  out = 'ui_optdbg.zip',\n  visibility = ['PUBLIC'],\n)\nWith this resolution\n[\n{\n  \"bash\" : null,\n  \"buck.base_path\" : \"gerrit-gwtui\",\n  \"buck.output_file\" : \"buck-out/gen/gerrit-gwtui/ui_optdbg.zip\",\n  \"cmd\" : \"cd $TMP;unzip -q $(location :ui_dbg);mv gerrit_ui/gerrit_ui.nocache.js gerrit_ui/dbg_gerrit_ui.nocache.js;unzip -qo $(location :ui_opt);mkdir -p \\\\$(dirname $OUT);zip -qr $OUT .\",\n  \"cmdExe\" : null,\n  \"deps\" : [ \":ui_dbg\", \":ui_opt\" ],\n  \"name\" : \"ui_optdbg\",\n  \"out\" : \"ui_optdbg.zip\",\n  \"srcs\" : [ ],\n  \"type\" : \"genrule\",\n  \"visibility\" : [ \"PUBLIC\" ]\n}\n]\nAnd with this error:\n$ buck build gerrit-gwtui:ui_optdbg\nUsing buckd.\n[-] PROCESSING BUCK FILES...FINISHED 0,0s\n[+] BUILDING...4,4s (85/87 JOBS)\n |=> //gerrit-gwtui:ui_opt...  2,4s (checking local cache)\n/bin/bash: -c: line 0: syntax error near unexpected token `('\nBUILD FAILED: //gerrit-gwtui:ui_optdbg failed with exit code 2:\ngenrule\n. OK, shell backticks work.\n. Thanks. We are facing another side effect here. We are still supporting Maven archetypes for plugin skeleton generation. As a part of the generated plugin we generate Buck files. In raw form they are looking something like this:\n```\ninclude_defs('//bucklets/gerrit_plugin.bucklet')\ngerrit_plugin(\n  name = '${pluginName}',\n  srcs = glob(['src/main/java//*.java']),\n  resources = glob(['src/main/resources//*']),\n  manifest_entries = [\n    'Gerrit-PluginName: ${pluginName}',\n    'Gerrit-ApiType: ${gerritApiType}',\n    'Gerrit-ApiVersion: ${gerritApiVersion}',\n    'Gerrit-Module: ${package}.Module',\n    'Gerrit-SshModule: ${package}.SshModule',\n    'Gerrit-HttpModule: ${package}.HttpModule',\n  ],\n)\njava_library(\n  name = 'classpath',\n  deps = [':${pluginName}__plugin'],\n)\n```\nNote: that all ${foo} are replaced by Maven. After this change Buck rejects all this places with macro error. See this change fo more details [1].\n[1] https://gerrit-review.googlesource.com/#/c/61074/4/gerrit-plugin-archetype/src/main/resources/archetype-resources/BUCK\n. > https://gist.github.com/andrewjcg/0b9b18a5b036784092e3 got this working for me.\nI think it interferes also with ${pluginName} constructs.\n. Sorry, my fault. It was failing because of git describe that was fixed by you in the gist. Thanks for doing my job ;-) I ammended the Buck upgrade change and all seems to be fine. Thanks again for your help.\n. @andrewjcg Thanks for quick fix. After upgrading to recent master we were able to eliminate shell back ticks again and switch to escaped macro invocation:\n\\$(dirname $OUT)\n[1] https://gerrit-review.googlesource.com/61204\n. Thanks. Will rename it then.\n. Thx. Monday sounds promising :)\n. Thx, works now again.\n. Yes it did. Thanks.\n. Yes it did. Thanks.\n. Unfortunately not.\n. Unfortunately not.\n. I don't remember last time i tried it, was it on Cygwin or on Powershell. I will recheck again and let you know.\n. OK, I'm not getting this failure any more on recent master. However, something is wrong with tracing file access. Not sure if it's Buck bug or environment problem? Here is screen shot. Windows explorer shows that directory is wrong in the symlink: [1].\n[1] http://i.imgur.com/NSOfIA3.png\n. OK, I'm not getting this failure any more on recent master. However, something is wrong with tracing file access. Not sure if it's Buck bug or environment problem? Here is screen shot. Windows explorer shows that directory is wrong in the symlink: [1].\n[1] http://i.imgur.com/NSOfIA3.png\n. It worth noting, that I'm getting the same tracing file access error when trying to build Buck itself, as reported in another issue. So that's not PEX related.\n. It worth noting, that I'm getting the same tracing file access error when trying to build Buck itself, as reported in another issue. So that's not PEX related.\n. As a temporary workaround, one liner cmd script with the following content:\npython C:\\Users\\david\\projects\\buck\\programs\\buck.py %1 %2 %3 %4 %5 %6\ndoes the job. However, it's failing with tracing and git invocation errors.\nThis diff fixed this, and Buck seems to work:\n```\ndiff --git a/programs/buck.py b/programs/buck.py\nindex d2ef048..ba8f6a7 100755\n--- a/programs/buck.py\n+++ b/programs/buck.py\n@@ -18,8 +18,8 @@ def main(argv):\n         path = os.getenv(\"PATH\", \"\")\n         if java_home:\n             pathsep = os.pathsep\n-            if sys.platform == 'cygwin':\n-                pathsep = ';'\n             os.environ[\"PATH\"] = os.path.join(java_home, 'bin') + pathsep + path\n     tracing_dir = None\n\n@@ -44,7 +44,7 @@ def main(argv):\n             return buck_repo.launch_buck(build_id)\n finally:\n\n\nif tracing_dir:\nif sys.platform != 'win32' and tracing_dir:\n             Tracing.write_to_dir(tracing_dir, build_id)\n\nif name == \"main\":\ndiff --git a/programs/buck_repo.py b/programs/buck_repo.py\nold mode 100644\nnew mode 100755\nindex f4e7600..bcaa917\n--- a/programs/buck_repo.py\n+++ b/programs/buck_repo.py\n@@ -104,7 +104,7 @@ class BuckRepo(BuckTool):\n     dot_git = os.path.join(self._buck_dir, '.git')\n     self._is_git = os.path.exists(dot_git) and os.path.isdir(dot_git) and which('git') and \\\n\n\nsys.platform != 'cygwin'\nsys.platform != 'cygwin' and sys.platform != 'win32'\n         self._is_buck_repo_dirty_override = os.environ.get('BUCK_REPOSITORY_DIRTY') buck_version = buck_project.buck_version\n\n```\n. As a temporary workaround, one liner cmd script with the following content:\n\n\npython C:\\Users\\david\\projects\\buck\\programs\\buck.py %1 %2 %3 %4 %5 %6\ndoes the job. However, it's failing with tracing and git invocation errors.\nThis diff fixed this, and Buck seems to work:\n```\ndiff --git a/programs/buck.py b/programs/buck.py\nindex d2ef048..ba8f6a7 100755\n--- a/programs/buck.py\n+++ b/programs/buck.py\n@@ -18,8 +18,8 @@ def main(argv):\n         path = os.getenv(\"PATH\", \"\")\n         if java_home:\n             pathsep = os.pathsep\n-            if sys.platform == 'cygwin':\n-                pathsep = ';'\n             os.environ[\"PATH\"] = os.path.join(java_home, 'bin') + pathsep + path\n     tracing_dir = None\n\n@@ -44,7 +44,7 @@ def main(argv):\n             return buck_repo.launch_buck(build_id)\n finally:\n\n\nif tracing_dir:\nif sys.platform != 'win32' and tracing_dir:\n             Tracing.write_to_dir(tracing_dir, build_id)\n\nif name == \"main\":\ndiff --git a/programs/buck_repo.py b/programs/buck_repo.py\nold mode 100644\nnew mode 100755\nindex f4e7600..bcaa917\n--- a/programs/buck_repo.py\n+++ b/programs/buck_repo.py\n@@ -104,7 +104,7 @@ class BuckRepo(BuckTool):\n     dot_git = os.path.join(self._buck_dir, '.git')\n     self._is_git = os.path.exists(dot_git) and os.path.isdir(dot_git) and which('git') and \\\n\n\nsys.platform != 'cygwin'\nsys.platform != 'cygwin' and sys.platform != 'win32'\n         self._is_buck_repo_dirty_override = os.environ.get('BUCK_REPOSITORY_DIRTY') buck_version = buck_project.buck_version\n\n```\n. It was failing in Power Shell. Which version of Power Shell are you using?\n. It was failing in Power Shell. Which version of Power Shell are you using?\n. It was failing for me on Windows 7, but was working as expected on Windows 8.1/Windows 10 TP. So closing it for now.\n. This diff fixed this:\n\n\ndiff --git a/third-party/py/pathlib/pathlib.py b/third-party/py/pathlib/pathlib.py\nindex 02448b3..3f43ea1\n--- a/third-party/py/pathlib/pathlib.py\n+++ b/third-party/py/pathlib/pathlib.py\n@@ -1034,7 +1034,7 @@ class Path(PurePath):\n         \"\"\"Iterate over this subtree and yield all existing files (of any\n         kind, including directories) matching the given pattern.\n         \"\"\"\n-        pattern = self._flavour.casefold(pattern)\n+        #pattern = self._flavour.casefold(pattern)\n         drv, root, pattern_parts = self._flavour.parse_parts((pattern,))\n         if drv or root:\n             raise NotImplementedError(\"Non-relative patterns are unsupported\")\n. This diff fixed this:\ndiff --git a/third-party/py/pathlib/pathlib.py b/third-party/py/pathlib/pathlib.py\nindex 02448b3..3f43ea1\n--- a/third-party/py/pathlib/pathlib.py\n+++ b/third-party/py/pathlib/pathlib.py\n@@ -1034,7 +1034,7 @@ class Path(PurePath):\n         \"\"\"Iterate over this subtree and yield all existing files (of any\n         kind, including directories) matching the given pattern.\n         \"\"\"\n-        pattern = self._flavour.casefold(pattern)\n+        #pattern = self._flavour.casefold(pattern)\n         drv, root, pattern_parts = self._flavour.parse_parts((pattern,))\n         if drv or root:\n             raise NotImplementedError(\"Non-relative patterns are unsupported\")\n. Another problem is to be able to specify exclusion set in platform independent way. Currently this doesn't seem to work:\n```\nSRC = 'java/'\nEXCLUDES = [SRC + 'org/ostrovsky/buck/Util.java']\njava_library(\n  name = 'plugin-lib',\n  srcs = glob([SRC + '/*.java'], excludes = EXCLUDES),\n  resources = glob(['java//*.java']),\n  deps = [':commons-io'],\n)\n```\nDoesn't have any effect, Util.java wasn't excluded from the source set:\n[...]\n\"srcs\" : [ \"java\\\\org\\\\ostrovsky\\\\buck\\\\Main.java\", \"java\\\\org\\\\ostrovsky\\\\buck\\\\Util.java\" ],\n[...]\nChanging the path delimiter in exclusion set to :\nSRC = 'java\\\\'\nEXCLUDES = [SRC + 'org\\\\ostrovsky\\\\buck\\\\Util.java']\nfixed this. Now exclusion set does have effect:\n\"srcs\" : [ \"java\\\\org\\\\ostrovsky\\\\buck\\\\Main.java\" ],\nI think that glob() should accept exclusion set with posix like paths and it should work on all supported platforms.\n. Another problem is to be able to specify exclusion set in platform independent way. Currently this doesn't seem to work:\n```\nSRC = 'java/'\nEXCLUDES = [SRC + 'org/ostrovsky/buck/Util.java']\njava_library(\n  name = 'plugin-lib',\n  srcs = glob([SRC + '/*.java'], excludes = EXCLUDES),\n  resources = glob(['java//*.java']),\n  deps = [':commons-io'],\n)\n```\nDoesn't have any effect, Util.java wasn't excluded from the source set:\n[...]\n\"srcs\" : [ \"java\\\\org\\\\ostrovsky\\\\buck\\\\Main.java\", \"java\\\\org\\\\ostrovsky\\\\buck\\\\Util.java\" ],\n[...]\nChanging the path delimiter in exclusion set to :\nSRC = 'java\\\\'\nEXCLUDES = [SRC + 'org\\\\ostrovsky\\\\buck\\\\Util.java']\nfixed this. Now exclusion set does have effect:\n\"srcs\" : [ \"java\\\\org\\\\ostrovsky\\\\buck\\\\Main.java\" ],\nI think that glob() should accept exclusion set with posix like paths and it should work on all supported platforms.\n. So i was able to track down the problem and fix it. There was separator char mismatch between exlusion pattern supplied to the glob() (always posix) and the path that was returned from twitter's pythonlib library (other platform flavour). So the solution is one liner:\n```\ndiff --git a/src/com/facebook/buck/parser/buck.py b/src/com/facebook/buck/parser/buck.py\nindex 0a7f7e6..9859b6d\n--- a/src/com/facebook/buck/parser/buck.py\n+++ b/src/com/facebook/buck/parser/buck.py\n@@ -150,7 +150,7 @@ def glob_internal(includes, excludes, include_dotfiles, allow_empty, search_base\n             non_special_excludes.add(pattern)\n def exclusion(path):\n\n\nif str(path) in non_special_excludes:\nif path.as_posix() in non_special_excludes:\n             return True\n         for pattern in match_excludes:\n             result = path.match(pattern, match_entire=True)\n```\n. Yes. That's because the case issue was solved in this patch: [1].\n\n[1] https://github.com/davido/gerrit-buck-patch/blob/master/buck_gerrit.patch#L113,L134\n. Actually it's blocking me. The plan is to upstream this patch: [1] to support Gerrit build on other platform out of the box [2]. And not to require folks to patch Buck. With the provided reproducer, are you able to reproduce the problem?\n[1] https://github.com/davido/gerrit-buck-patch/blob/master/buck_gerrit.patch\n[2] https://gerrit-review.googlesource.com/65600\n. I wonder if this fix should be done upstream? \n. I looked into the rule key: the key is preserved:\n$ buck.cmd targets --show-rulekey tools:hello\n//tools:hello fd4d7f62f8c1c91fe48f76f3ed74abeb78e36505\nBut new PEX file is generated every time the target is invoked.\n. > I would expect Buck to understand I am referencing a BUCK file in the some/dep folder with a name of \"dep\".\nIn some/dep/BUCK file could be different artifacts you may want to depend on:\ndeps = [\n  '//some/dep:bar',\n  '//some/dep:baz',\n  '//some/dep:qux',\n  [...]\n],\n. Actually this just works, when python executables is on PATH.\n. OK, tracked it down. This is path separator mismatch bug, specific to other platform Genrule.addSymlinkCommands():329:\n[...]\n      // By the time we get this far, all source paths (the keys in the map) have been converted\n      // to paths relative to the project root. We want the path relative to the build target, so\n      // strip the base path.\n      if (entry.getValue().equals(canonicalPath)) {\n        if (localPath.startsWith(basePath)) {\n          localPath = localPath.substring(basePathLength);\n        } else {\n          localPath = canonicalPath.getFileName().toString();\n        }\n      }\n      [...]\nThe values are:\nbasePath = \"gerrit-war/\"\nlocalPath = \"gerrit-war\\src\\main\\webapp\\WEB-INF\\extra\\jetty7\\gerrit-jetty.sh\"\nSo the condition if (localPath.startsWith(basePath)) is erroneously false.\nThis diff fixed this:\n```\ndiff --git a/src/com/facebook/buck/shell/Genrule.java b/src/com/facebook/buck/shell/Genrule.java\nold mode 100644\nnew mode 100755\nindex 2e6e967..e3dd044\n--- a/src/com/facebook/buck/shell/Genrule.java\n+++ b/src/com/facebook/buck/shell/Genrule.java\n@@ -38,6 +38,7 @@ import com.facebook.buck.step.fs.MkdirStep;\n import com.facebook.buck.step.fs.RmStep;\n import com.facebook.buck.util.BuckConstant;\n import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.CharMatcher;\n import com.google.common.base.Function;\n import com.google.common.base.Joiner;\n import com.google.common.base.Optional;\n@@ -317,6 +318,7 @@ public class Genrule extends AbstractBuildRule implements HasOutputName {\n   @VisibleForTesting\n   void addSymlinkCommands(ImmutableList.Builder commands) {\n     String basePath = getBuildTarget().getBasePathWithSlash();\n+    String basePathWithoutTrailingSlash = CharMatcher.is('/').trimTrailingFrom(basePath);\n     int basePathLength = basePath.length();\n // Symlink all sources into the temp directory so that they can be used in the genrule.\n\n@@ -330,7 +332,7 @@ public class Genrule extends AbstractBuildRule implements HasOutputName {\n       // to paths relative to the project root. We want the path relative to the build target, so\n       // strip the base path.\n       if (entry.getValue().equals(canonicalPath)) {\n-        if (localPath.startsWith(basePath)) {\n+        if (localPath.startsWith(basePathWithoutTrailingSlash)) {\n           localPath = localPath.substring(basePathLength);\n         } else {\n           localPath = canonicalPath.getFileName().toString();\n```\n. Fixed meantime by 923579e2089af2972aabe908af90fdba4ec71bf8.\n. Interestingly, the error message is saying:\nBUILD FAILED: //src/com/facebook/buck/rules:types failed with exit code 1:\njavac\nsrc\\com\\facebook\\buck\\rules\\BUCK (:types) is missing deps:\n    '//src/com/facebook/buck/step:step',\nAnd indeed, this diff fixed it:\ndiff --git a/src/com/facebook/buck/rules/BUCK b/src/com/facebook/buck/rules/BUCK\nindex 3bce5a1..30113d9 100644\n--- a/src/com/facebook/buck/rules/BUCK\n+++ b/src/com/facebook/buck/rules/BUCK\n@@ -34,6 +34,7 @@ java_immutables_library(\n     '//src/com/facebook/buck/cxx:rules',\n     '//src/com/facebook/buck/rules/macros:macros',\n     '//src/com/facebook/buck/shell:rules',\n+    '//src/com/facebook/buck/step:step',\n     '//src/com/facebook/buck/thrift:rules',\n     '//src/com/facebook/buck/util:constants',\n     '//src/com/facebook/buck/util:exceptions',\nCan confirm the same failure on Linux (on most recent master: 1cc4747f5a8fa93458cfbd98d8c01c09a9a19950):\n```\n$ javac -version\njavac 1.8.0_40\n$ java -version\nopenjdk version \"1.8.0_40\"\nOpenJDK Runtime Environment (build 1.8.0_40-b22)\nOpenJDK 64-Bit Server VM (build 25.40-b25, mixed mode)\n$ buck build buck\nOpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=256m; support was removed in 8.0\nOpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\n[-] PROCESSING BUCK FILES...FINISHED 0,6s\n[+] BUILDING...10,7s (167/178 JOBS, 167 UPDATED, 0,0% CACHE HITS)\n |=> IDLE\n |=> IDLE\n |=> //src/com/facebook/buck/rules:types...  0,3s (running javac[0,3s])\n |=> IDLE\n |=> IDLE\n |=> IDLE\n |=> //src/com/facebook/buck/java/intellij:intellij...  0,3s (running javac[0,3s])\n |=> IDLE\n |=> IDLE\n |=> IDLE\nLog:\nwarning: [options] bootstrap class path not set in conjunction with -source 1.7\n/home/davido/projects/buck/src/com/facebook/buck/rules/KnownBuildRuleTypes.java:448: error: cannot access com.facebook.buck.step.Step\n                SmartDexingStep.determineOptimalThreadCount(),\n                               ^\n  class file for com.facebook.buck.step.Step not found\nErrors: 1. Warnings: 1.\nBUILD FAILED: //src/com/facebook/buck/rules:types failed with exit code 1:\nsrc/com/facebook/buck/rules/BUCK (:types) is missing deps:\n    '//src/com/facebook/buck/step:step',\n```\n. The issue seems to be OpenJDK specific, as the version reportd here is not matched by this regex:\nre.compile('java version \"1\\.8\\..*').match(version_line)\nas the first line is:\nopenjdk version \"1.8.0_40\"\nTo reproduce, buckd should be shut down:\n$ NO_BUCKD=1 buck build buck\nThe fix is:\ndiff --git a/programs/buck_tool.py b/programs/buck_tool.py\nindex ea844fe..ef33334 100644\n--- a/programs/buck_tool.py\n+++ b/programs/buck_tool.py\n@@ -457,4 +457,4 @@ def which(cmd, mode=os.F_OK | os.X_OK, path=None):\n def is_java8():\n     output = check_output(['java', '-version'], stderr=subprocess.STDOUT)\n     version_line = output.strip().splitlines()[0]\n-    return re.compile('java version \"1\\.8\\..*').match(version_line)\n+    return re.compile('(openjdk|java) version \"1\\.8\\..*').match(version_line)\n. Isn't the variable name is NO_BUCKD?\n. > Why are you deleting the jar file? Is there a particular use case?\nLet's say we have some genrue() with name bar, that depends on foo.jar, with cmd = do_some magic and with out = '__bar__'. Let's assume I executed it once: buck build bar.\nThe magic Python script do_some magic had some side effect(s), for example deployed some stuff to local Maven repository. Now, for some reasons, this side effect was undone. What is the supported way to re-execute only do_some magic python script, by re-invocing the buck build bar? All these attempts don't work:\n- rm buck-out/<...>/bar\n- invalidate rule_key for bar rule\nProbably buck clean or rm -rf buck-out or rm -rf buck-cache followed by buck build bar would work. But shouldn't there be a way to somehow re-execute one single rule, with very little (or without any) impact on already built rules and Buck cache?\n. Thanks for the clarification.\n. I added a Python script to overcome this design limitation and replay Buck command manually: [1]. One improvement for this specific use case would be to add support for '--resolve-macros' option to\nbuck targets --json --resolve-macros //foo:bar\ninvocation.\n@shs96c any comments on this requirement? @sdwilsh suggested to ask you before filing a feature request ;-)\n- [1] https://gerrit-review.googlesource.com/#/c/68722/5/tools/maven/api.py\n. I see your point. In this specific case, we are using python_binary() and deploy to remote or install in local Maven repository built plugin API. As every Buck rule must have some output, we are using fake file in buck-out directory.\nBut let's say that some one would like to contribute built-in Buck rule for Maven deployment, with fetch_file we do have built-in rule for fetching from Maven. So why not push_file for pushing to Maven?\nSo let's assume somehow you are able to configure it to either push to local or remote Maven repository. Let's call the outcome of this operation, the file is under \"$HOME/.m2/repository/...\" or on Google storage bucket, or whatever as a \"side effect\", because we left buck-out directory (that wouldn't be side effect), right?\nI'm curious how this push_file built-in rule can be implemented to be conform with the Buck philosophy:\n- some metadata associated with each rule saved in buck-out\n- rule outcome is cached in Buck cache\n- every side effect breaks Buck in weird way\nSo that a simple use case like this can be done from within Buck:\n$ buck build push_file_foo_to_local_maven_repository\n  $ rm -rf $HOME/.m2/repository/.../foo.jar\n  $ buck build push_file_foo_to_local_maven_repository\nSo that the last buck build invocation will re-push the same (cached and not re-built) artifact to the local maven repository (in this case).\nOr are you saying, that push_file can't be a built-in rule in Buck and must always be implemented outside of the Buck?\n. Opps. I think it works as expected. This has nothing to do with exported deps on itself, rather then how maven_jar()  custom rule is implemented in gerrit core:\nif exported_deps:\n    prebuilt_jar(\n      name = '%s__jar' % name,\n      deps = deps + license,\n      binary_jar = ':%s__download_bin' % name,\n      source_jar = ':%s__download_src' % name if srcjar else None,\n    )\n    java_library(\n      name = name,\n      exported_deps = exported_deps + [':' + name + '__jar'],\n      visibility = visibility,\n    )\n  else:\n    prebuilt_jar(\n      name = name,\n      deps = deps + license,\n      binary_jar = ':%s__download_bin' % name,\n      source_jar = ':%s__download_src' % name if srcjar else None,\n      visibility = visibility,\n    )\nSo when exported_deps provided, java_library is created. This java_library doesn't have any srcs or resources and thus doesn't have the output:\n```\n$ buck targets --show_output //lib/gwt:dev\n//lib/gwt:dev\n$ buck targets --show_output //lib/gwt:user\n//lib/gwt:user buck-out/gen/lib/gwt/user/gwt-user-2.7.0.jar\n```\nThat's why $(location :target) telling us the same here.\n. Fixed with: [1].\n[1] https://gerrit-review.googlesource.com/71620\n. Fixed with: [1].\n[1] https://gerrit-review.googlesource.com/71620\n. The problem remains, when i move the ow2 from exported_deps to deps:\n$ buck targets --json //lib/gwt:dev\nUsing buckd.\n[\n{\n  \"binaryJar\" : \":dev__download_bin\",\n  \"buck.base_path\" : \"lib/gwt\",\n  \"buck.direct_dependencies\" : [ \"//lib/gwt:javax-validation\", \"//lib/gwt:javax-validation_src\", \"//lib/ow2:ow2-asm\", \"//lib/ow2:ow2-asm-analysis\", \"//lib/ow2:ow2-asm-commons\", \"//lib/ow2:ow2-asm-tree\", \"//lib/ow2:ow2-asm-util\", \"//lib:LICENSE-Apache2.0\", \"//lib/gwt:dev__download_bin\" ],\n  \"buck.type\" : \"prebuilt_jar\",\n  \"deps\" : [ \":javax-validation\", \":javax-validation_src\", \"//lib/ow2:ow2-asm\", \"//lib/ow2:ow2-asm-analysis\", \"//lib/ow2:ow2-asm-commons\", \"//lib/ow2:ow2-asm-tree\", \"//lib/ow2:ow2-asm-util\", \"//lib:LICENSE-Apache2.0\" ],\n  \"gwtJar\" : null,\n  \"javadocUrl\" : null,\n  \"mavenCoords\" : null,\n  \"name\" : \"dev\",\n  \"sourceJar\" : null,\n  \"visibility\" : [ \"PUBLIC\" ]\n}\n]\nAs mentioned above, moving the deps to the rule itself or using --deep option solved that.\n. The problem remains, when i move the ow2 from exported_deps to deps:\n$ buck targets --json //lib/gwt:dev\nUsing buckd.\n[\n{\n  \"binaryJar\" : \":dev__download_bin\",\n  \"buck.base_path\" : \"lib/gwt\",\n  \"buck.direct_dependencies\" : [ \"//lib/gwt:javax-validation\", \"//lib/gwt:javax-validation_src\", \"//lib/ow2:ow2-asm\", \"//lib/ow2:ow2-asm-analysis\", \"//lib/ow2:ow2-asm-commons\", \"//lib/ow2:ow2-asm-tree\", \"//lib/ow2:ow2-asm-util\", \"//lib:LICENSE-Apache2.0\", \"//lib/gwt:dev__download_bin\" ],\n  \"buck.type\" : \"prebuilt_jar\",\n  \"deps\" : [ \":javax-validation\", \":javax-validation_src\", \"//lib/ow2:ow2-asm\", \"//lib/ow2:ow2-asm-analysis\", \"//lib/ow2:ow2-asm-commons\", \"//lib/ow2:ow2-asm-tree\", \"//lib/ow2:ow2-asm-util\", \"//lib:LICENSE-Apache2.0\" ],\n  \"gwtJar\" : null,\n  \"javadocUrl\" : null,\n  \"mavenCoords\" : null,\n  \"name\" : \"dev\",\n  \"sourceJar\" : null,\n  \"visibility\" : [ \"PUBLIC\" ]\n}\n]\nAs mentioned above, moving the deps to the rule itself or using --deep option solved that.\n. Fixed with: [1].\n[1] https://gerrit-review.googlesource.com/71623\n. @sdwilsh I'm not sure I quite understand @shs96c's suggestion or I'm not quite understand the consequences. Currently we are consuming the GWT dependencies from the Central and thus have a full control oder what version exactly we are consuming. If it would be provided by Buck, how could we be able to support different GWT versions with the same version of Buck? Say, we would like to use (currently production) 2.7 and upcoming 2.8 on the same Buck version, on different Gerrit Code Review branches?\n. Probably #427 may be related.\nMoving the dependency from deps to $(location :foo) seems to fixed that:\ngenrule(\n  name = 'broken',\n  cmd = ' '.join(['$(exe //tools:pack_me)', '-d', '$(location //:plugin-lib)', '-o', '$OUT']),\n  out = 'broken.out',\n)\n. Probably #427 may be related.\nMoving the dependency from deps to $(location :foo) seems to fixed that:\ngenrule(\n  name = 'broken',\n  cmd = ' '.join(['$(exe //tools:pack_me)', '-d', '$(location //:plugin-lib)', '-o', '$OUT']),\n  out = 'broken.out',\n)\n. Actually it is even worse as I thought it is: it's only working as expected for first order dependencies. When transitive dependencies of foo have changed, the genrule()'s command isn't invoked, even when the dependency foo is moved from deps to $(location :foo) macro in command part of genrule().\nConsider this dependency graph: foo depends transitively on bar, and the broken defined as:\ngenrule(\n  name = 'broken',\n  cmd = ' '.join(['$(exe //tools:pack_me)', '-d', '$(location //:foo)', '-o', '$OUT']),\n  out = 'broken.out',\n)\nand invoking:\nbuck build :broken\nwouldn't call pack_me.py, when some sources from bar were changed. To make the disaster complete: bar is actually rebuilt, but not :broken!\nI think that replacing $(location :foo) macro with $(classpath :foo) macro fixes that:\ngenrule(\n  name = 'broken',\n  cmd = ' '.join(['$(exe //tools:pack_me)', '-d', '$(classpath //:foo)', '-o', '$OUT']),\n  out = 'broken.out',\n)\nSee: [1].\n[1] https://gerrit-review.googlesource.com/71650\n. Actually it is even worse as I thought it is: it's only working as expected for first order dependencies. When transitive dependencies of foo have changed, the genrule()'s command isn't invoked, even when the dependency foo is moved from deps to $(location :foo) macro in command part of genrule().\nConsider this dependency graph: foo depends transitively on bar, and the broken defined as:\ngenrule(\n  name = 'broken',\n  cmd = ' '.join(['$(exe //tools:pack_me)', '-d', '$(location //:foo)', '-o', '$OUT']),\n  out = 'broken.out',\n)\nand invoking:\nbuck build :broken\nwouldn't call pack_me.py, when some sources from bar were changed. To make the disaster complete: bar is actually rebuilt, but not :broken!\nI think that replacing $(location :foo) macro with $(classpath :foo) macro fixes that:\ngenrule(\n  name = 'broken',\n  cmd = ' '.join(['$(exe //tools:pack_me)', '-d', '$(classpath //:foo)', '-o', '$OUT']),\n  out = 'broken.out',\n)\nSee: [1].\n[1] https://gerrit-review.googlesource.com/71650\n. > Is plugin-lib.jar itself changing?\nNo, it's not. But that worked that way for years. Was this changed since bottom-up to top-down graph traversing? I also noticed, that running:\nbuck build --deep gerrit\ndoesn't solve that: pack_war.py isnt' executed, even though, some deps in the chain were rebuilt.\nSo the only way to make it work again (on Buck master) is to use $(classpath :plugin-lib), so that broken will always be executed, when any dependency in transitive dependency chain of plugin-lib was changed?\n. > Is plugin-lib.jar itself changing?\nNo, it's not. But that worked that way for years. Was this changed since bottom-up to top-down graph traversing? I also noticed, that running:\nbuck build --deep gerrit\ndoesn't solve that: pack_war.py isnt' executed, even though, some deps in the chain were rebuilt.\nSo the only way to make it work again (on Buck master) is to use $(classpath :plugin-lib), so that broken will always be executed, when any dependency in transitive dependency chain of plugin-lib was changed?\n. So, i checked, since when it was broken.\nIt worked as expected on: 8204fddf60b25a3c2090f3ef0742fca5d466d562.\nBy working as expected I mean, that when something changed in the transitive dependency chain, and pack-war.py depends among other on gerrit-pgm:pgm:\n$ buck targets --json :gerrit\nUsing buckd.\nAdding watchman root: .\n[\n{\n  \"bash\" : null,\n  \"buck.base_path\" : \"\",\n  \"buck.direct_dependencies\" : [ \"//gerrit-pgm:pgm\", \"//gerrit-war:init\", \"//gerrit-war:log4j-config\", \"//gerrit-war:version\", \"//lib/log:impl_log4j\", \"//lib:postgresql\", \"//gerrit-gwtui:ui_optdbg\", \"//gerrit-main:main_bin\", \"//gerrit-war:webapp_assets\", \"//tools:pack_war\" ],\n  \"buck.type\" : \"genrule\",\n  \"cmd\" : \"$(exe //tools:pack_war) -o $OUT --tmp $TMP --lib //gerrit-war:log4j-config --lib //gerrit-war:init --lib //lib:postgresql --lib //lib/log:impl_log4j --lib //gerrit-war:version --pgmlib //gerrit-pgm:pgm $(location //gerrit-main:main_bin) $(location //gerrit-war:webapp_assets) $(location //gerrit-gwtui:ui_optdbg)\",\n  \"cmdExe\" : null,\n  \"deps\" : [ \"//gerrit-war:log4j-config\", \"//gerrit-war:init\", \"//lib:postgresql\", \"//lib/log:impl_log4j\", \"//gerrit-war:version\", \"//gerrit-pgm:pgm\" ],\n  \"name\" : \"gerrit\",\n  \"out\" : \"gerrit.war\",\n  \"srcs\" : [ ],\n  \"visibility\" : [ ]\n}\n]\nand it depends transitively on many other dependencies:\n$ buck targets --json \"//gerrit-pgm:pgm\"\nUsing buckd.\nAdding watchman root: .\n[\n{\n  \"annotationProcessorDeps\" : [ \"//lib:velocity\", \"//lib/auto:auto-value\", \"//lib/commons:collections\", \"//lib/commons:lang\", \"//lib/commons:oro\" ],\n  \"annotationProcessorOnly\" : null,\n  \"annotationProcessorParams\" : [ ],\n  \"annotationProcessors\" : [ \"com.google.auto.value.processor.AutoAnnotationProcessor\", \"com.google.auto.value.processor.AutoValueProcessor\" ],\n  \"buck.base_path\" : \"gerrit-pgm\",\n  \"buck.direct_dependencies\" : [ \"//gerrit-cache-h2:cache-h2\", \"//gerrit-common:server\", \"//gerrit-extension-api:api\", \"//gerrit-gpg:gpg\", \"//gerrit-gwtexpui:linker_server\", \"//gerrit-gwtexpui:server\", \"//gerrit-httpd:httpd\", \"//gerrit-lucene:lucene\", \"//gerrit-oauth:oauth\", \"//gerrit-openid:openid\", \"//gerrit-pgm:daemon\", \"//gerrit-pgm:http\", \"//gerrit-pgm:init\", \"//gerrit-pgm:init-api\", \"//gerrit-pgm:util\", \"//gerrit-reviewdb:server\", \"//gerrit-server:server\", \"//gerrit-sshd:sshd\", \"//lib/auto:auto-value\", \"//lib/guice:guice\", \"//lib/guice:guice-assistedinject\", \"//lib/guice:guice-servlet\", \"//lib/jgit:jgit\", \"//lib/log:api\", \"//lib/log:jsonevent-layout\", \"//lib/log:log4j\", \"//lib/prolog:cafeteria\", \"//lib/prolog:compiler\", \"//lib/prolog:runtime\", \"//lib:args4j\", \"//lib:guava\", \"//lib:gwtorm\", \"//lib:protobuf\", \"//lib:servlet-api-3_1\", \"//lib/commons:collections\", \"//lib/commons:lang\", \"//lib/commons:oro\", \"//lib:velocity\" ],\n  \"buck.type\" : \"java_library\",\n  \"compiler\" : null,\n  \"deps\" : [ \"//gerrit-common:server\", \"//gerrit-extension-api:api\", \"//gerrit-gwtexpui:linker_server\", \"//gerrit-gwtexpui:server\", \"//gerrit-httpd:httpd\", \"//gerrit-server:server\", \"//gerrit-sshd:sshd\", \"//gerrit-reviewdb:server\", \"//lib:guava\", \"//lib/guice:guice\", \"//lib/guice:guice-assistedinject\", \"//lib/guice:guice-servlet\", \"//lib/jgit:jgit\", \"//lib/log:api\", \"//lib/log:jsonevent-layout\", \"//lib/log:log4j\", \":http\", \":init\", \":init-api\", \":util\", \"//gerrit-cache-h2:cache-h2\", \"//gerrit-gpg:gpg\", \"//gerrit-lucene:lucene\", \"//gerrit-oauth:oauth\", \"//gerrit-openid:openid\", \"//lib:args4j\", \"//lib:gwtorm\", \"//lib:protobuf\", \"//lib:servlet-api-3_1\", \"//lib/auto:auto-value\", \"//lib/prolog:cafeteria\", \"//lib/prolog:compiler\", \"//lib/prolog:runtime\", \":daemon\" ],\n  \"exportedDeps\" : [ ],\n  \"extraArguments\" : [ \"-encoding\", \"UTF-8\" ],\n  \"javaVersion\" : null,\n  \"javac\" : null,\n  \"javacJar\" : null,\n  \"mavenCoords\" : null,\n  \"name\" : \"pgm\",\n  \"postprocessClassesCommands\" : [ ],\n  \"proguardConfig\" : null,\n  \"providedDeps\" : [ ],\n  \"resources\" : [ \"src/main/resources/com/google/gerrit/pgm/ProtoGenHeader.txt\", \"src/main/resources/com/google/gerrit/pgm/Startup.py\" ],\n  \"resourcesRoot\" : null,\n  \"source\" : null,\n  \"srcs\" : [ ],\n  \"target\" : null,\n  \"tests\" : [ ],\n  \"visibility\" : [ \"//:\", \"//gerrit-acceptance-tests/...\", \"//gerrit-gwtdebug:gwtdebug\", \"//tools/eclipse:classpath\", \"//Documentation:licenses.txt\" ]\n}\n]\nAnd one of those dependencies were changed, say //gerrit-server:server,  then gerrit.war is rebuilt (pack_war.py was invoked).\nIt was broken since we upgraded to: d1be554f51fb9b2f090a85fcdbcef3b4dbbef8d7 with this diff: https://github.com/gerrit-review/gerrit/commit/f377aa96debec109671efc07102e2850445be62f.\nTo reproduce: change one file, say gerrit-server/src/main/java/com/google/gerrit/server/WebLinks.java\nthen run buck buid gerrit, Java is compiled, lib was rebuilt, but not gerrit.war.\n$ ls -all buck-out/gen/gerrit-server/lib__server__output/server.jar\n-rw-r--r-- 1 davido users 2799815 Oct 17 13:51 buck-out/gen/gerrit-server/lib__server__output/server.jar\n$ ls -all buck-out/gen/gerrit/gerrit.war \n-rw-r--r-- 1 davido users 38332505 Oct 17 13:50 buck-out/gen/gerrit/gerrit.war\nSince this upgrade our build toolchain is unreliable and the build results are inaccurate.\n[1] https://gerrit-review.googlesource.com/70887\n. So, i checked, since when it was broken.\nIt worked as expected on: 8204fddf60b25a3c2090f3ef0742fca5d466d562.\nBy working as expected I mean, that when something changed in the transitive dependency chain, and pack-war.py depends among other on gerrit-pgm:pgm:\n$ buck targets --json :gerrit\nUsing buckd.\nAdding watchman root: .\n[\n{\n  \"bash\" : null,\n  \"buck.base_path\" : \"\",\n  \"buck.direct_dependencies\" : [ \"//gerrit-pgm:pgm\", \"//gerrit-war:init\", \"//gerrit-war:log4j-config\", \"//gerrit-war:version\", \"//lib/log:impl_log4j\", \"//lib:postgresql\", \"//gerrit-gwtui:ui_optdbg\", \"//gerrit-main:main_bin\", \"//gerrit-war:webapp_assets\", \"//tools:pack_war\" ],\n  \"buck.type\" : \"genrule\",\n  \"cmd\" : \"$(exe //tools:pack_war) -o $OUT --tmp $TMP --lib //gerrit-war:log4j-config --lib //gerrit-war:init --lib //lib:postgresql --lib //lib/log:impl_log4j --lib //gerrit-war:version --pgmlib //gerrit-pgm:pgm $(location //gerrit-main:main_bin) $(location //gerrit-war:webapp_assets) $(location //gerrit-gwtui:ui_optdbg)\",\n  \"cmdExe\" : null,\n  \"deps\" : [ \"//gerrit-war:log4j-config\", \"//gerrit-war:init\", \"//lib:postgresql\", \"//lib/log:impl_log4j\", \"//gerrit-war:version\", \"//gerrit-pgm:pgm\" ],\n  \"name\" : \"gerrit\",\n  \"out\" : \"gerrit.war\",\n  \"srcs\" : [ ],\n  \"visibility\" : [ ]\n}\n]\nand it depends transitively on many other dependencies:\n$ buck targets --json \"//gerrit-pgm:pgm\"\nUsing buckd.\nAdding watchman root: .\n[\n{\n  \"annotationProcessorDeps\" : [ \"//lib:velocity\", \"//lib/auto:auto-value\", \"//lib/commons:collections\", \"//lib/commons:lang\", \"//lib/commons:oro\" ],\n  \"annotationProcessorOnly\" : null,\n  \"annotationProcessorParams\" : [ ],\n  \"annotationProcessors\" : [ \"com.google.auto.value.processor.AutoAnnotationProcessor\", \"com.google.auto.value.processor.AutoValueProcessor\" ],\n  \"buck.base_path\" : \"gerrit-pgm\",\n  \"buck.direct_dependencies\" : [ \"//gerrit-cache-h2:cache-h2\", \"//gerrit-common:server\", \"//gerrit-extension-api:api\", \"//gerrit-gpg:gpg\", \"//gerrit-gwtexpui:linker_server\", \"//gerrit-gwtexpui:server\", \"//gerrit-httpd:httpd\", \"//gerrit-lucene:lucene\", \"//gerrit-oauth:oauth\", \"//gerrit-openid:openid\", \"//gerrit-pgm:daemon\", \"//gerrit-pgm:http\", \"//gerrit-pgm:init\", \"//gerrit-pgm:init-api\", \"//gerrit-pgm:util\", \"//gerrit-reviewdb:server\", \"//gerrit-server:server\", \"//gerrit-sshd:sshd\", \"//lib/auto:auto-value\", \"//lib/guice:guice\", \"//lib/guice:guice-assistedinject\", \"//lib/guice:guice-servlet\", \"//lib/jgit:jgit\", \"//lib/log:api\", \"//lib/log:jsonevent-layout\", \"//lib/log:log4j\", \"//lib/prolog:cafeteria\", \"//lib/prolog:compiler\", \"//lib/prolog:runtime\", \"//lib:args4j\", \"//lib:guava\", \"//lib:gwtorm\", \"//lib:protobuf\", \"//lib:servlet-api-3_1\", \"//lib/commons:collections\", \"//lib/commons:lang\", \"//lib/commons:oro\", \"//lib:velocity\" ],\n  \"buck.type\" : \"java_library\",\n  \"compiler\" : null,\n  \"deps\" : [ \"//gerrit-common:server\", \"//gerrit-extension-api:api\", \"//gerrit-gwtexpui:linker_server\", \"//gerrit-gwtexpui:server\", \"//gerrit-httpd:httpd\", \"//gerrit-server:server\", \"//gerrit-sshd:sshd\", \"//gerrit-reviewdb:server\", \"//lib:guava\", \"//lib/guice:guice\", \"//lib/guice:guice-assistedinject\", \"//lib/guice:guice-servlet\", \"//lib/jgit:jgit\", \"//lib/log:api\", \"//lib/log:jsonevent-layout\", \"//lib/log:log4j\", \":http\", \":init\", \":init-api\", \":util\", \"//gerrit-cache-h2:cache-h2\", \"//gerrit-gpg:gpg\", \"//gerrit-lucene:lucene\", \"//gerrit-oauth:oauth\", \"//gerrit-openid:openid\", \"//lib:args4j\", \"//lib:gwtorm\", \"//lib:protobuf\", \"//lib:servlet-api-3_1\", \"//lib/auto:auto-value\", \"//lib/prolog:cafeteria\", \"//lib/prolog:compiler\", \"//lib/prolog:runtime\", \":daemon\" ],\n  \"exportedDeps\" : [ ],\n  \"extraArguments\" : [ \"-encoding\", \"UTF-8\" ],\n  \"javaVersion\" : null,\n  \"javac\" : null,\n  \"javacJar\" : null,\n  \"mavenCoords\" : null,\n  \"name\" : \"pgm\",\n  \"postprocessClassesCommands\" : [ ],\n  \"proguardConfig\" : null,\n  \"providedDeps\" : [ ],\n  \"resources\" : [ \"src/main/resources/com/google/gerrit/pgm/ProtoGenHeader.txt\", \"src/main/resources/com/google/gerrit/pgm/Startup.py\" ],\n  \"resourcesRoot\" : null,\n  \"source\" : null,\n  \"srcs\" : [ ],\n  \"target\" : null,\n  \"tests\" : [ ],\n  \"visibility\" : [ \"//:\", \"//gerrit-acceptance-tests/...\", \"//gerrit-gwtdebug:gwtdebug\", \"//tools/eclipse:classpath\", \"//Documentation:licenses.txt\" ]\n}\n]\nAnd one of those dependencies were changed, say //gerrit-server:server,  then gerrit.war is rebuilt (pack_war.py was invoked).\nIt was broken since we upgraded to: d1be554f51fb9b2f090a85fcdbcef3b4dbbef8d7 with this diff: https://github.com/gerrit-review/gerrit/commit/f377aa96debec109671efc07102e2850445be62f.\nTo reproduce: change one file, say gerrit-server/src/main/java/com/google/gerrit/server/WebLinks.java\nthen run buck buid gerrit, Java is compiled, lib was rebuilt, but not gerrit.war.\n$ ls -all buck-out/gen/gerrit-server/lib__server__output/server.jar\n-rw-r--r-- 1 davido users 2799815 Oct 17 13:51 buck-out/gen/gerrit-server/lib__server__output/server.jar\n$ ls -all buck-out/gen/gerrit/gerrit.war \n-rw-r--r-- 1 davido users 38332505 Oct 17 13:50 buck-out/gen/gerrit/gerrit.war\nSince this upgrade our build toolchain is unreliable and the build results are inaccurate.\n[1] https://gerrit-review.googlesource.com/70887\n. Created a reproducer (upload in a moment to GH in its own repository) and bisected the problem:\n143646f4ccd8737f73a2667a244c4c38dc18cb89 is the first bad commit\n. Created a reproducer (upload in a moment to GH in its own repository) and bisected the problem:\n143646f4ccd8737f73a2667a244c4c38dc18cb89 is the first bad commit\n. > I think this is working as intended, but it's certainly too easy to create a genrule that uses inputs Buck isn't tracking by using the buck audit or query command.\nAck.\n\nFor example you call buck audit classpath libs in your genrule's script, but you could pass the same information in with the $(classpath ) macro I think right?\n\nYou are right, of course. Thanks for pointing this out. I amended the fix correspondingly.\n. > I think this is working as intended, but it's certainly too easy to create a genrule that uses inputs Buck isn't tracking by using the buck audit or query command.\nAck.\n\nFor example you call buck audit classpath libs in your genrule's script, but you could pass the same information in with the $(classpath ) macro I think right?\n\nYou are right, of course. Thanks for pointing this out. I amended the fix correspondingly.\n. Nope I havn't. It wasn't verbose for us in test failure case AFAICT. Only after recent upgrades it started to behave that way.\n. So, I was able to track it down:\ngood revision: ba9f239f69287a553ca93af76a27484d83693563\nbad revision: 7e153d4a69044d059288d353fc1a442e07cbea58\nLooks like one of these commits broke it:\n- cc05fdbedc0213ebe8ca38a69eeb0b0ea0b8e567\n- a521e6e3e311b92a3904232e97cfcce62f97afb7\nWith offending commits, the verbose output is: http://paste.openstack.org/show/478799, without them, the correct non-verbose output is: http://paste.openstack.org/show/478798.\n. Well, that's sensible and i believe that the default value is wrong. I would expect it to be at least info, if not even warn. I also think developer shouldn't configure anything in .buckconfig to get sane default behaviour, not to mention passing additional parameter(s) to hundreds of java_test() invocations across the code base. So the only way to make it work on latest master and restore the old behaviour is to monkey patch java_test rule:\n```\n  _buck_java_test = java_test\n  def java_test(*args, kwargs):\n    _do_not_spam_std_out(kwargs)\n    _buck_java_test(*args, kwargs)\ndef _do_not_spam_std_out(kwargs):\n    level = 'std_out_log_level'\n    if level not in kwargs:\n      kwargs[level] = 'INFO'\n``\n. Well, that's sensible and i believe that the default value is wrong. I would expect it to be at leastinfo, if not evenwarn. I also think developer shouldn't configure anything in.buckconfigto get sane default behaviour, not to mention passing additional parameter(s) to hundreds ofjava_test()invocations across the code base. So the only way to make it work on latest master and restore the old behaviour is to monkey patchjava_test` rule:\n```\n  _buck_java_test = java_test\n  def java_test(*args, kwargs):\n    _do_not_spam_std_out(kwargs)\n    _buck_java_test(*args, kwargs)\ndef _do_not_spam_std_out(kwargs):\n    level = 'std_out_log_level'\n    if level not in kwargs:\n      kwargs[level] = 'INFO'\n``\n. Thanks for the quick fix.\n. Thanks for the quick fix.\n. We could probably introduceeclipse-outfor that, yes.\n. We could probably introduceeclipse-outfor that, yes.\n. Moving Eclipse output frombuck-out` fixed it. However, I figured out, that Buck even interferes with itself. All you need to shoot yourself in the foot, is to have such innocent rule:\ngenrule(\n  name = 'foo',\n  srcs = glob(['**']),\n  [...]\nNow you are screwed up, because Buck copying all files to foo__srcs, including BUCK file itself, and later, when you are trying to run buck test (note, that buck build * still works) it will complain that\n//buck-out/.../foo: is not there or something\nSo now, all glob(['**']) must be extended with srcs = glob(['**'], excludes = ['BUCK']), as in : [1]. May be this should be added to the documentation? Now it's claiming that:\nBuck automatically excludes its own output, e.g. <code>buck-out</code>,\nhttps://gerrit-review.googlesource.com/#/c/72684/1/polygerrit-ui/app/BUCK@41\n. Moving Eclipse output from buck-out fixed it. However, I figured out, that Buck even interferes with itself. All you need to shoot yourself in the foot, is to have such innocent rule:\ngenrule(\n  name = 'foo',\n  srcs = glob(['**']),\n  [...]\nNow you are screwed up, because Buck copying all files to foo__srcs, including BUCK file itself, and later, when you are trying to run buck test (note, that buck build * still works) it will complain that\n//buck-out/.../foo: is not there or something\nSo now, all glob(['**']) must be extended with srcs = glob(['**'], excludes = ['BUCK']), as in : [1]. May be this should be added to the documentation? Now it's claiming that:\nBuck automatically excludes its own output, e.g. <code>buck-out</code>,\nhttps://gerrit-review.googlesource.com/#/c/72684/1/polygerrit-ui/app/BUCK@41\n. It worth noting, that you could easily reproduce it yourself. All you need is to clone gerrit: [1] and apply this pending Buck upgrade patch: [2].\n- [1] git clone https://gerrit.googlesource.com/gerrit\n- [2] https://gerrit-review.googlesource.com/72684\n. It worth noting, that you could easily reproduce it yourself. All you need is to clone gerrit: [1] and apply this pending Buck upgrade patch: [2].\n- [1] git clone https://gerrit.googlesource.com/gerrit\n- [2] https://gerrit-review.googlesource.com/72684\n. I think @dpursehouse already added this feature request.\n. Probably related to this is similar problem in $(classpath) macro expansion:\ncmd.extend(['--lib', '$(classpath %s)' % '//gerrit-war:init'])\nrenders result relocated in root context of cell container:\n/home/davido/projects/gerrit/buck-out/gen/jgit.jar\nThis file doesn't exist. The correct location is: /home/davido/projects/gerrit/lib/jgit/buck-out/gen/jgit.jar.\nInterestingly, when querying the same from buck audit classpath command, the result is correct:\n$ buck audit classpath //gerrit-war:init | grep -i buck-out/gen/jgit.jar\n/home/davido/projects/gerrit/lib/jgit/buck-out/gen/jgit.jar\nAmd not relocated to the root directory of cell container.\n. > Keep in mind that cross-cell could point to something completely outside of the tree, so I don't think we'd ever put out buck-out/gen/lib/jgit/jgit_src.jar as the path to the output.\nYes, my mistake. It should probably expand to:\n/home/davido/projects/gerrit/lib/jgit/buck-out/gen/jgit_src.jar\nOr, more generally, when repositories.jgit = /path/to/jgit then it should expand to:\n/path/to/jgit/buck-out/gen/jgit_src.jar\nIn any event, this file $(location @jgit//:jgit_src) should be built and accessible.\n. Fixed with 53cdfbc232a6890a13c0d94c40f13e9449c10529.\n. @Coneko I addressed your comments in https://github.com/facebook/buck/pull/552\n. Replaced with: https://github.com/facebook/buck/pull/558\n. Ah, I missed this issue before opening a new one: [1]. The same test is failing for me as well on Linux OpenSUSE.\n- [1] https://github.com/facebook/buck/issues/565 \n. According to this comment, it seems like this is a regression, that was already handled once:\nhttps://github.com/facebook/buck/blob/master/test/com/facebook/buck/event/listener/SuperConsoleEventBusListenerTest.java#L110-L124\n/**\n   * Formats a string with times passed in in seconds.\n   *\n   * Used to avoid these tests failing if the user's locale doesn't use '.' as the decimal\n   * separator, as was the case in https://github.com/facebook/buck/issues/58.\n   */\n  private static String formatConsoleTimes(String template, Double... time) {\n    return String.format(template, (Object[]) FluentIterable.from(ImmutableList.copyOf(time))\n        .transform(new Function<Double, String>() {\n          @Override\n          public String apply(Double input) {\n            return timeFormatter.format(input);\n          }\n        }).toArray(String.class));\n  }\nAnd that now in addition to time elapsed, that is handled correctly, at least in this test file, cache hit/missed ratio was added, that is locale specific:\nExpected: <0.0% CACHE MISS>\nbut: was <0,0% CACHE MISS>\n. Thanks. Trying again on most recent master (ec75fa1102cfa5d4e97fd0db7467031f77414169) still some tests are failing here:\n$ buck test\nShutting down nailgun server...\nUsing watchman.\nWaiting for Watchman command [/home/davido/bin/watchman version]...\nTimed out after 10000 ms waiting for Watchman command [/home/davido/bin/watchman version]. Disabling Watchman.\nFAILURE com.facebook.buck.event.listener.BuildThreadStateRendererTest withMissingInformation: \nExpected: is <[ |=> //:target3...  2.6s (checking local cache),  |=> IDLE,  |=> IDLE]>\n     but: was <[ |=> //:target3...  2,6s (checking local cache),  |=> IDLE,  |=> IDLE]>\nFAILURE com.facebook.buck.event.listener.BuildThreadStateRendererTest commonCase: \nExpected: is <[ |=> //:target2...  4.4s (running step A[2.7s]),  |=> //:target3...  2.6s (checking local cache),  |=> //:target1...  3.3s (checking local cache),  |=> IDLE,  |=> //:target4...  1.2s (running step B[0.5s])]>\n     but: was <[ |=> //:target2...  4,4s (running step A[2,7s]),  |=> //:target3...  2,6s (checking local cache),  |=> //:target1...  3,3s (checking local cache),  |=> IDLE,  |=> //:target4...  1,2s (running step B[0,5s])]>\nFAILURE com.facebook.buck.event.listener.TestThreadStateRendererTest withMissingInformation: \nExpected: is <[ |=> //:target3...  2.6s,  |=> //:target1...  3.3s,  |=> IDLE,  |=> IDLE]>\n     but: was <[ |=> //:target3...  2,6s,  |=> //:target1...  3,3s,  |=> IDLE,  |=> IDLE]>\nFAILURE com.facebook.buck.event.listener.TestThreadStateRendererTest commonCase: \nExpected: is <[ |=> //:target2...  4.4s (running step A[2.7s]),  |=> //:target3...  2.6s (running Test A[2.6s]),  |=> //:target1...  3.3s,  |=> IDLE,  |=> //:target4...  1.2s (running Test B[0.4s])]>\n     but: was <[ |=> //:target2...  4,4s (running step A[2,7s]),  |=> //:target3...  2,6s (running Test A[2,6s]),  |=> //:target1...  3,3s,  |=> IDLE,  |=> //:target4...  1,2s (running Test B[0,4s])]>\nFAILURE com.facebook.buck.python.PythonBinaryIntegrationTest nativeLibsEnvVarIsPreserved[INPLACE]: \nExpected: \"None\"\n     but: was \"/usr/lib64/mpi/gcc/openmpi/lib64\"\nFAILURE com.facebook.buck.python.PythonBinaryIntegrationTest nativeLibsEnvVarIsPreserved[STANDALONE]: \nExpected: \"None\"\n     but: was \"/usr/lib64/mpi/gcc/openmpi/lib64\"\nHere is the list of failing tests:\nFailed target: //test/com/facebook/buck/event/listener:listener\nFAIL com.facebook.buck.event.listener.BuildThreadStateRendererTest\nFAIL com.facebook.buck.event.listener.TestThreadStateRendererTest\nFailed target: //test/com/facebook/buck/python:python\nFAIL com.facebook.buck.python.PythonBinaryIntegrationTest\nHere is more verbose log:\nhttp://paste.openstack.org/show/481381.\n. Thanks. Trying again on most recent master (ec75fa1102cfa5d4e97fd0db7467031f77414169) still some tests are failing here:\n$ buck test\nShutting down nailgun server...\nUsing watchman.\nWaiting for Watchman command [/home/davido/bin/watchman version]...\nTimed out after 10000 ms waiting for Watchman command [/home/davido/bin/watchman version]. Disabling Watchman.\nFAILURE com.facebook.buck.event.listener.BuildThreadStateRendererTest withMissingInformation: \nExpected: is <[ |=> //:target3...  2.6s (checking local cache),  |=> IDLE,  |=> IDLE]>\n     but: was <[ |=> //:target3...  2,6s (checking local cache),  |=> IDLE,  |=> IDLE]>\nFAILURE com.facebook.buck.event.listener.BuildThreadStateRendererTest commonCase: \nExpected: is <[ |=> //:target2...  4.4s (running step A[2.7s]),  |=> //:target3...  2.6s (checking local cache),  |=> //:target1...  3.3s (checking local cache),  |=> IDLE,  |=> //:target4...  1.2s (running step B[0.5s])]>\n     but: was <[ |=> //:target2...  4,4s (running step A[2,7s]),  |=> //:target3...  2,6s (checking local cache),  |=> //:target1...  3,3s (checking local cache),  |=> IDLE,  |=> //:target4...  1,2s (running step B[0,5s])]>\nFAILURE com.facebook.buck.event.listener.TestThreadStateRendererTest withMissingInformation: \nExpected: is <[ |=> //:target3...  2.6s,  |=> //:target1...  3.3s,  |=> IDLE,  |=> IDLE]>\n     but: was <[ |=> //:target3...  2,6s,  |=> //:target1...  3,3s,  |=> IDLE,  |=> IDLE]>\nFAILURE com.facebook.buck.event.listener.TestThreadStateRendererTest commonCase: \nExpected: is <[ |=> //:target2...  4.4s (running step A[2.7s]),  |=> //:target3...  2.6s (running Test A[2.6s]),  |=> //:target1...  3.3s,  |=> IDLE,  |=> //:target4...  1.2s (running Test B[0.4s])]>\n     but: was <[ |=> //:target2...  4,4s (running step A[2,7s]),  |=> //:target3...  2,6s (running Test A[2,6s]),  |=> //:target1...  3,3s,  |=> IDLE,  |=> //:target4...  1,2s (running Test B[0,4s])]>\nFAILURE com.facebook.buck.python.PythonBinaryIntegrationTest nativeLibsEnvVarIsPreserved[INPLACE]: \nExpected: \"None\"\n     but: was \"/usr/lib64/mpi/gcc/openmpi/lib64\"\nFAILURE com.facebook.buck.python.PythonBinaryIntegrationTest nativeLibsEnvVarIsPreserved[STANDALONE]: \nExpected: \"None\"\n     but: was \"/usr/lib64/mpi/gcc/openmpi/lib64\"\nHere is the list of failing tests:\nFailed target: //test/com/facebook/buck/event/listener:listener\nFAIL com.facebook.buck.event.listener.BuildThreadStateRendererTest\nFAIL com.facebook.buck.event.listener.TestThreadStateRendererTest\nFailed target: //test/com/facebook/buck/python:python\nFAIL com.facebook.buck.python.PythonBinaryIntegrationTest\nHere is more verbose log:\nhttp://paste.openstack.org/show/481381.\n. Thx.\n. Thx.\n. @bhamiltoncx Thanks for the analysis. I filed new issue to track this failure: https://github.com/facebook/buck/issues/565. Does it work for you?\nI'm a bit confused. CI is broken, I cannot get test passed on my Linux machine and getting negative reviews because my PR https://github.com/facebook/buck/pull/558 broke some tests. But how should I be able to track down this breakage, when tests are inherently broken on most recent master (ec75fa1102cfa5d4e97fd0db7467031f77414169) anyway? Or this is something that environment dependent?\n. @bhamiltoncx Thanks for the analysis. I filed new issue to track this failure: https://github.com/facebook/buck/issues/565. Does it work for you?\nI'm a bit confused. CI is broken, I cannot get test passed on my Linux machine and getting negative reviews because my PR https://github.com/facebook/buck/pull/558 broke some tests. But how should I be able to track down this breakage, when tests are inherently broken on most recent master (ec75fa1102cfa5d4e97fd0db7467031f77414169) anyway? Or this is something that environment dependent?\n. Fixed in: [1].\n- [1] https://github.com/facebook/buck/pull/567\n. Fixed in: [1].\n- [1] https://github.com/facebook/buck/pull/567\n. Fixed by: 447e59a85a54fc16f5a3ce70ea118d6d79e65267\n. Fixed by: 447e59a85a54fc16f5a3ce70ea118d6d79e65267\n. > Why did you create a new PR instead of updating the existing one?\nOpps. Coming from Gerrit Code Review, I'm not that familiar with PR workflow. Got it now.\n. Thanks for letting me know. The tests were broken for me for other reasons, see #557 . I will re-check later today.\n. I think I understand what happens, but I'm not sure what is the correct way to address it. Currently some classpath entries are rendered with relative paths and some with absolute:\n```\n$ buck audit classpath  //test/com/facebook/buck/jvm/java:testutil\n[+] PROCESSING BUCK FILES...0.2s\n/home/davido/projects/buck-orig/buck-out/gen/third-party/java/ObjCBridge/ObjCBridge.jar\n/home/davido/projects/buck-orig/buck-out/gen/third-party/java/aether/aether-api.jar\n[...]\nbuck-out/gen/src/com/facebook/buck/android/aapt/lib__aapt__output/aapt.jar\nbuck-out/gen/src/com/facebook/buck/android/agent/util/lib__util__output/util.jar\nbuck-out/gen/src/com/facebook/buck/android/lib__exceptions__output/exceptions.jar\n[...]\n```\nThis relative path assumption is also stated in the tests, here example of one failing test:\ntestGetClasspathEntriesMap\nassertEquals(\n        ImmutableSetMultimap.of(\n            getJavaLibrary(libraryOne),\n            Paths.get(\"buck-out/gen/lib__libone__output/libone.jar\"),\n            getJavaLibrary(libraryTwo),\n            Paths.get(\"buck-out/gen/lib__libtwo__output/libtwo.jar\"),\n            getJavaLibrary(parent),\n            Paths.get(\"buck-out/gen/lib__parent__output/parent.jar\")),\n        ((HasClasspathEntries) parent).getTransitiveClasspathEntries());\nI think for cross-cell dependencies to work properly, we always have to use absolute paths and never relative paths.\nThat's because with cells we could aways hijack a cell and route it through different root container. Like it was done in:\nbuck build --config repositories.jgit=../jgit gerrit\nOne non intrusive change could be as follow: still render relative path if we detect that the rule is from the same cell/project file system and render absolute path otherwise. That way probably all tests would still pass, as they currently all from the same cell/project file system.\n. I think I understand what happens, but I'm not sure what is the correct way to address it. Currently some classpath entries are rendered with relative paths and some with absolute:\n```\n$ buck audit classpath  //test/com/facebook/buck/jvm/java:testutil\n[+] PROCESSING BUCK FILES...0.2s\n/home/davido/projects/buck-orig/buck-out/gen/third-party/java/ObjCBridge/ObjCBridge.jar\n/home/davido/projects/buck-orig/buck-out/gen/third-party/java/aether/aether-api.jar\n[...]\nbuck-out/gen/src/com/facebook/buck/android/aapt/lib__aapt__output/aapt.jar\nbuck-out/gen/src/com/facebook/buck/android/agent/util/lib__util__output/util.jar\nbuck-out/gen/src/com/facebook/buck/android/lib__exceptions__output/exceptions.jar\n[...]\n```\nThis relative path assumption is also stated in the tests, here example of one failing test:\ntestGetClasspathEntriesMap\nassertEquals(\n        ImmutableSetMultimap.of(\n            getJavaLibrary(libraryOne),\n            Paths.get(\"buck-out/gen/lib__libone__output/libone.jar\"),\n            getJavaLibrary(libraryTwo),\n            Paths.get(\"buck-out/gen/lib__libtwo__output/libtwo.jar\"),\n            getJavaLibrary(parent),\n            Paths.get(\"buck-out/gen/lib__parent__output/parent.jar\")),\n        ((HasClasspathEntries) parent).getTransitiveClasspathEntries());\nI think for cross-cell dependencies to work properly, we always have to use absolute paths and never relative paths.\nThat's because with cells we could aways hijack a cell and route it through different root container. Like it was done in:\nbuck build --config repositories.jgit=../jgit gerrit\nOne non intrusive change could be as follow: still render relative path if we detect that the rule is from the same cell/project file system and render absolute path otherwise. That way probably all tests would still pass, as they currently all from the same cell/project file system.\n. Thanks. Trying \"to absolutify only in cell context approach\", I'm still seeing some tests failing (much less now). There is still a problem with new approach to use SourcePath and RuleResolver to render the underlying paths. I don't quite understand why, though. Is this a problem with test settings?\nConsider one test failure with most recent version of this patch: DefaultJavaLibraryTest#testAddAnnotationProcessorJar.\nWhen rendering the classpath entries for //tools/java/src/com/facebook/somejava:library\nin this context:\nat com.facebook.buck.jvm.java.JavaLibraryClasspathProvider.absolutifyInCellContext(JavaLibraryClasspathProvider.java:110)\n      at com.facebook.buck.jvm.java.JavaLibraryClasspathProvider.getTransitiveClasspathEntries(JavaLibraryClasspathProvider.java:98)\n      at com.facebook.buck.jvm.java.DefaultJavaLibrary$5.get(DefaultJavaLibrary.java:285)\n      at com.facebook.buck.jvm.java.DefaultJavaLibrary$5.get(DefaultJavaLibrary.java:282)\n      at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:125)\n      - locked <0x57d> (a com.google.common.base.Suppliers$MemoizingSupplier)\n      at com.facebook.buck.jvm.java.DefaultJavaLibrary.getTransitiveClasspathEntries(DefaultJavaLibrary.java:371)\n      at com.facebook.buck.jvm.java.AnnotationProcessingParams$Builder.build(AnnotationProcessingParams.java:209)\n      at com.facebook.buck.jvm.java.DefaultJavaLibraryTest$AnnotationProcessingScenario.createJavaLibraryRule(DefaultJavaLibraryTest.java:1338)\n      at com.facebook.buck.jvm.java.DefaultJavaLibraryTest$AnnotationProcessingScenario.buildAndGetCompileParameters(DefaultJavaLibraryTest.java:1310)\n      at com.facebook.buck.jvm.java.DefaultJavaLibraryTest.testAddAnnotationProcessorJar(DefaultJavaLibraryTest.java:288)\nThe outputJar is:\n```\nPair(//tools/java/src/com/facebook/somejava:library, Optional.of(buck-out/gen/tools/java/src/com/facebook/somejava/lib__library__output/library.jar))\n```\nThe ruleResolver is:\n0 = {java.util.concurrent.ConcurrentHashMap$WriteThroughEntry@1538} \"//tools/java/src/com/facebook/somejava:library#gwt_module\" -> \"//tools/java/src/com/facebook/somejava:library#gwt_module\"\n1 = {java.util.concurrent.ConcurrentHashMap$WriteThroughEntry@1539} \"//tools/java/src/com/facebook/somejava:library\" -> \"//tools/java/src/com/facebook/somejava:library\"\n2 = {java.util.concurrent.ConcurrentHashMap$WriteThroughEntry@1540} \"//tools/java/src/com/facebook/somejava:library#abi\" -> \"//tools/java/src/com/facebook/somejava:library#abi\"\nand the rule can be resolved and the path is rendered correctly:\n{//tools/java/src/com/facebook/somejava:library=[buck-out/gen/tools/java/src/com/facebook/somejava/lib__library__output/library.jar]}\nNote, that with new approach discussed earlier, the path is relative now. However, when rendering the classpath entries for //android/java/src/com/facebook:fbin in thsis context:\nat com.facebook.buck.jvm.java.JavaLibraryClasspathProvider.absolutifyInCellContext(JavaLibraryClasspathProvider.java:110)\n      at com.facebook.buck.jvm.java.JavaLibraryClasspathProvider.getTransitiveClasspathEntries(JavaLibraryClasspathProvider.java:98)\n      at com.facebook.buck.jvm.java.DefaultJavaLibrary$5.get(DefaultJavaLibrary.java:285)\n      at com.facebook.buck.jvm.java.DefaultJavaLibrary$5.get(DefaultJavaLibrary.java:282)\n      at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:125)\n      - locked <0x6a3> (a com.google.common.base.Suppliers$MemoizingSupplier)\n      at com.facebook.buck.jvm.java.DefaultJavaLibrary.getTransitiveClasspathEntries(DefaultJavaLibrary.java:371)\n      at com.facebook.buck.jvm.java.DefaultJavaLibrary.getBuildSteps(DefaultJavaLibrary.java:424)\n      at com.facebook.buck.jvm.java.DefaultJavaLibraryTest$AnnotationProcessingScenario.buildAndGetCompileParameters(DefaultJavaLibraryTest.java:1312)\n      at com.facebook.buck.jvm.java.DefaultJavaLibraryTest.testAddAnnotationProcessorJar(DefaultJavaLibraryTest.java:288)\nThe outputJar is:\nPair(//android/java/src/com/facebook:fb, Optional.of(buck-out/gen/android/java/src/com/facebook/lib__fb__output/fb.jar))\nAnd the `ruleResolver? is empty (size = 0). No wonder that the path cannot be rendered, as the rule cannot be resolved by the empty RuleResolver:\n```\ncom.facebook.buck.util.HumanReadableException: Rule for target '//android/java/src/com/facebook:fb' could not be resolved.\nat com.facebook.buck.rules.BuildRuleResolver.getRule(BuildRuleResolver.java:98)\nat com.facebook.buck.rules.SourcePathResolver.getRule(SourcePathResolver.java:180)\nat com.facebook.buck.rules.SourcePathResolver.getAbsolutePath(SourcePathResolver.java:94)\nat com.facebook.buck.jvm.java.JavaLibraryClasspathProvider.absolutifyInCellContext(JavaLibraryClasspathProvider.java:110)\nat com.facebook.buck.jvm.java.JavaLibraryClasspathProvider.getTransitiveClasspathEntries(JavaLibraryClasspathProvider.java:98)\nat com.facebook.buck.jvm.java.DefaultJavaLibrary$5.get(DefaultJavaLibrary.java:285)\nat com.facebook.buck.jvm.java.DefaultJavaLibrary$5.get(DefaultJavaLibrary.java:282)\nat com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:125)\nat com.facebook.buck.jvm.java.DefaultJavaLibrary.getTransitiveClasspathEntries(DefaultJavaLibrary.java:371)\nat com.facebook.buck.jvm.java.DefaultJavaLibrary.getBuildSteps(DefaultJavaLibrary.java:424)\nat com.facebook.buck.jvm.java.DefaultJavaLibraryTest$AnnotationProcessingScenario.buildAndGetCompileParameters(DefaultJavaLibraryTest.java:1312)\nat com.facebook.buck.jvm.java.DefaultJavaLibraryTest.testAddAnnotationProcessorJar(DefaultJavaLibraryTest.java:288)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\n```\nWhat am I missing?\n. Thanks. Will have to figure out how to fix this and other broken tests, then.\n. @sdwilsh @Coneko PTAL.\nI haven't found a way to differentiate between foreign cell context. So, failing back to always emitting absolute path in classpath resolution. The tests were adjusted correspondingly.\n. @shs96c I addressed your comment and fixed another test. Still some tests are failing.\n. Still one test is failing: [1].\nFAIL      5.5s 12 Passed   0 Skipped   1 Failed   com.facebook.buck.jvm.java.DefaultJavaLibraryIntegrationTest\nFAILURE com.facebook.buck.jvm.java.DefaultJavaLibraryIntegrationTest testBuildJavaLibraryShouldSuggestTransitiveImportsToInclude\nUnfortunately I'm not able to reproduce it from the IDE. I tried to set JAVA_HOME and PATH actually they should be already be set from the system). When i set only java path, then it's saying that Python is missing. When I set Java and Python path, it's telling me again, that JDK is missing:\n```\nConnected to the target VM, address: '127.0.0.1:44375', transport: 'socket'\nDez 18, 2015 12:14:15 AM com.facebook.buck.log.Logger info\nINFO: HangMonitorAutoStart\nDez 18, 2015 12:14:16 AM com.facebook.buck.log.Logger warn\nWARNING: Could not execute xcode-select, continuing without developer dir.\nWARNING: Cannot find ConsoleHandler log handler. Logs printed to console will likely be lost.\nWARNING: Cannot find ConsoleHandler log handler. Logs printed to console will likely be lost.\nDez 18, 2015 12:14:16 AM com.facebook.buck.event.listener.LoggingBuildListener buildStarted\nINFO: Build started at 2015-12-18 00:14:16.464\nDez 18, 2015 12:14:16 AM com.facebook.buck.log.Logger info\nINFO: Awaiting termination of HTTP Write executor service. Waiting for all jobs to complete, or up to maximum of 1800 seconds...\nDez 18, 2015 12:14:16 AM com.facebook.buck.event.listener.LoggingBuildListener handleConsoleEvent\nWARNING: BUILD FAILED: //:blargh failed on step javac with an exception:\nNo system compiler found. Did you install the JRE instead of the JDK?\ncom.facebook.buck.util.HumanReadableException: No system compiler found. Did you install the JRE instead of the JDK?\n    at com.facebook.buck.jvm.java.JdkProvidedInMemoryJavac.createCompiler(JdkProvidedInMemoryJavac.java:66)\n    at com.facebook.buck.jvm.java.Jsr199Javac.buildWithClasspath(Jsr199Javac.java:139)\n    at com.facebook.buck.jvm.java.JavacStep.tryBuildWithFirstOrderDeps(JavacStep.java:141)\n    at com.facebook.buck.jvm.java.JavacStep.execute(JavacStep.java:129)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:63)\n    at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:1090)\n    at com.facebook.buck.rules.CachingBuildEngine.access$900(CachingBuildEngine.java:106)\n    at com.facebook.buck.rules.CachingBuildEngine$4.apply(CachingBuildEngine.java:457)\n    at com.facebook.buck.rules.CachingBuildEngine$4.apply(CachingBuildEngine.java:311)\n    at com.google.common.util.concurrent.Futures$ChainingListenableFuture.run(Futures.java:906)\n    at com.google.common.util.concurrent.Futures$1$1.run(Futures.java:635)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:745)\nDez 18, 2015 12:14:16 AM com.facebook.buck.event.listener.LoggingBuildListener buildFinished\nINFO: Build finished at 2015-12-18 00:14:16.800\nDez 18, 2015 12:14:16 AM com.facebook.buck.log.Logger info\nINFO: Awaiting termination of Disk IO executor service. Waiting for all jobs to complete, or up to maximum of 2 seconds...\n```\n[1] http://paste.openstack.org/show/482241/\n. Thanks for the hint. Will give this another try.\n. @sdwilsh @shs96c Thanks again for helping out with setting the IDE for the DefaultJavaLibraryIntegrationTest to work properly.\nI fixed all issues and all tests are passing now. PTAL.\n. @sdwilsh @shs96c Thanks again for helping out with setting the IDE for the DefaultJavaLibraryIntegrationTest to work properly.\nI fixed all issues and all tests are passing now. PTAL.\n. > Hmm, still seeing a number of test failures (mostly Android) due to this change in Travis.\nThat's strange, I don't see any failures in my local environment (Linux). However, I don't have anything related to Android installed on my machine. Can it be that those tests are skipped for me? Any Android expert around?\n. > Hmm, still seeing a number of test failures (mostly Android) due to this change in Travis.\nThat's strange, I don't see any failures in my local environment (Linux). However, I don't have anything related to Android installed on my machine. Can it be that those tests are skipped for me? Any Android expert around?\n. > You can install the android sdk and they'll run.\nAny hints how to do that? I've never touched anything related to Android.\nAnswering my own question ;-)\nI've found this section in https://buckbuild.com/setup/install.html:\nAndroid SDK and NDK\nIf you plan to use Buck to build Android code, you will need to tell Buck where to find our SDK and NDK. Buck will look at the value of the ANDROID_HOME environment variable to locate the SDK files on your system. Buck will look at ANDROID_NDK to find a specific version of the NDK, and ANDROID_NDK_REPOSITORY to find an appropriate NDK from a directory containing multiple NDK versions.\nAnd SDK can be probably installed from here:\nhttp://developer.android.com/sdk/index.html\n. > You can install the android sdk and they'll run.\nAny hints how to do that? I've never touched anything related to Android.\nAnswering my own question ;-)\nI've found this section in https://buckbuild.com/setup/install.html:\nAndroid SDK and NDK\nIf you plan to use Buck to build Android code, you will need to tell Buck where to find our SDK and NDK. Buck will look at the value of the ANDROID_HOME environment variable to locate the SDK files on your system. Buck will look at ANDROID_NDK to find a specific version of the NDK, and ANDROID_NDK_REPOSITORY to find an appropriate NDK from a directory containing multiple NDK versions.\nAnd SDK can be probably installed from here:\nhttp://developer.android.com/sdk/index.html\n. Thanks. I will give it another try.\n. Thanks. I will give it another try.\n. Still struggling with reproducing Android tests failures.\nI installed the SDK and selected version 23 in the android sdk utility, so that:\n$ $ANDROID_HOME/tools/android list targets --compact\nandroid-23\nGoogle Inc.:Google APIs:23\nThen I updated the .buckconfig file:\n[android]\n  target = Google Inc.:Google APIs:23\nNow when I'm invoking only android tests, it's working:\nhttp://paste.openstack.org/show/483705\nHowever, when I'm invoking all tests, with buck test, it's still failing with obscure error message:\nhttp://paste.openstack.org/show/483706\nLooks like it's ignoring android.target configuration section and tries to access default Android SDK version that wasn't installed? Any idea how to make the tests work with my setup? Override Buck's hard coded default value for Android API version?\n. Still struggling with reproducing Android tests failures.\nI installed the SDK and selected version 23 in the android sdk utility, so that:\n$ $ANDROID_HOME/tools/android list targets --compact\nandroid-23\nGoogle Inc.:Google APIs:23\nThen I updated the .buckconfig file:\n[android]\n  target = Google Inc.:Google APIs:23\nNow when I'm invoking only android tests, it's working:\nhttp://paste.openstack.org/show/483705\nHowever, when I'm invoking all tests, with buck test, it's still failing with obscure error message:\nhttp://paste.openstack.org/show/483706\nLooks like it's ignoring android.target configuration section and tries to access default Android SDK version that wasn't installed? Any idea how to make the tests work with my setup? Override Buck's hard coded default value for Android API version?\n. > You can install API 21 to run them, or maybe fix them so they write out a .buckconfig that contains the right version.\nThanks, the easiest way, to make Android integration tests work, was to install SDK API 21.\nIt was immediately obvious what was still wrong: This diff turned classpath entries to be absolute and not relative any more. As the consequence, classpath entries transformation from relative to absolute was removed in JavacStep. However, what I missed, is the fact that some JVM specific library descriptions could provide additional classpath entries in their ctors. This is what AndroidLibrary did: provided source directory for generated resource file as additional classpath entry. However, this entry was provided as relative and was passed in to the Javac step in non absolutified form and thus generated resource file wasn't resolved. I added transformation in DefaultJavaLibrary ctor to rectify that, with a TODO:\n// TODO(davido): Is there a better place to absolutify additional classpath entries?\n    this.additionalClasspathEntries = FluentIterable\n        .from(additionalClasspathEntries)\n        .transform(getProjectFilesystem().getAbsolutifier())\n        .toSet();\nTravis build was failing another couple of times, but this time because of PDM and style checks breakages and not unit/intergration test failures.\n. @sdwilsh All comments were addressed. Thanks for the quick review.\n. @sdwilsh All comments were addressed. Thanks for the quick review.\n. Nope.\n. There is a workaround, though, to use Bucklets.\n. Check https://github.com/GerritCodeReview/gitiles where it's used (clone recursively).\nThen check this rule in main BUCK file:\nmaven_package(\n  repository = 'gerrit-maven-repository',\n  url = 'gs://gerrit-maven',\n  version = GITILES_VERSION,\n  group = 'com.google.gitiles',\n  jar = {\n    'blame-cache': '//blame-cache:lib',\n    'gitiles-servlet': '//gitiles-servlet:servlet',\n  },\n  src = {\n    'blame-cache': '//blame-cache:src',\n    'gitiles-servlet': '//gitiles-servlet:src',\n  },\n  doc = {\n    'blame-cache': '//blame-cache:javadoc',\n    'gitiles-servlet': '//gitiles-servlet:javadoc',\n  },\n)\nThis is defined in this buckets.\n. Check buck build :mvn_install:\n$  buck targets --json mvn_install \n[+] PARSING BUCK FILES...0.1s\n[\n{\n  \"bash\" : null,\n  \"buck.base_path\" : \"\",\n  \"buck.direct_dependencies\" : [ \"//blame-cache:javadoc\", \"//blame-cache:lib\", \"//blame-cache:src\", \"//bucklets/tools:mvn\", \"//gitiles-servlet:javadoc\", \"//gitiles-servlet:servlet\", \"//gitiles-servlet:src\" ],\n  \"buck.type\" : \"genrule\",\n  \"cmd\" : \"$(exe //bucklets/tools:mvn) -g com.google.gitiles -v 0.1-10 -o $OUT -s gitiles-servlet:jar:$(location //gitiles-servlet:servlet) -s blame-cache:jar:$(location //blame-cache:lib) -s gitiles-servlet:java-source:$(location //gitiles-servlet:src) -s blame-cache:java-source:$(location //blame-cache:src) -s gitiles-servlet:javadoc:$(location //gitiles-servlet:javadoc) -s blame-cache:javadoc:$(location //blame-cache:javadoc) -a install\",\n  \"cmdExe\" : null,\n  \"executable\" : null,\n  \"fully_qualified_name\" : \"//:install\",\n  \"licenses\" : [ ],\n  \"name\" : \"install\",\n  \"out\" : \"install.info\",\n  \"srcs\" : [ ],\n  \"tests\" : [ ],\n  \"visibility\" : [ ]\n}\n]\nBut note, that this is a wrong approach, because the rule will only be executed, when there were changes, but deployments shoud be triggered always. So the correct approach instead is to let build tool chain generate a deployment script from the build data. This was recently implemented in Gerrit Code Review:\n$ ./tools/maven/api.sh install buck\nThis would generate a shell script with this rule:\n$ buck build :gen_api_install\nin this location:\n$ buck targets --show_output //tools/maven:gen_api_install\n  //tools/maven:gen_api_install buck-out/gen/tools/maven/gen_api_install/api_install.sh\nwith this content and execute it.\n. Fixed in: [1].\n- [1] https://github.com/facebook/buck/pull/567\n. Fixed in: [1].\n- [1] https://github.com/facebook/buck/pull/567\n. Duplicate of [1].\n- [1] https://github.com/facebook/buck/issues/555\n. Something went here wrong.\n. Something went here wrong.\n. Test are fixed now.\n. Thanks. This would be very much appreciated.\n. Missed to mention, that lua is installed on this laptop:\n$ lua -v\nLua 5.2.2  Copyright (C) 1994-2013 Lua.org, PUC-Rio\n. Great (and fast)!\n. This diff fixed it:\ndiff --git a/src/com/facebook/buck/rules/macros/ClasspathMacroExpander.java b/src/com/facebook/buck/rules/macros/ClasspathMacroExpander.java\nindex 99b911d..a7570ad 100644\n--- a/src/com/facebook/buck/rules/macros/ClasspathMacroExpander.java\n+++ b/src/com/facebook/buck/rules/macros/ClasspathMacroExpander.java\n@@ -97,11 +97,12 @@ public class ClasspathMacroExpander\n                   @Nullable\n                   @Override\n                   public Path apply(JavaLibrary input) {\n-                    return input.getPathToOutput();\n+                    return input.getPathToOutput() == null\n+                        ? null\n+                        : input.getProjectFilesystem().resolve(input.getPathToOutput());\n                   }\n                 })\n             .filter(Predicates.notNull())\n-            .transform(rule.getProjectFilesystem().getAbsolutifier())\n             .transform(Functions.toStringFunction())\n             .toSortedSet(Ordering.natural()));\n   }\n. After talking to @sdwilsh on the IRC, it turns out to be a symbolic link problem, that was done to make cross-cell stuff work with include_defs() to resolve maven artifacts: [1]. That's because the inlcude in its own cell:\ninclude_defs('//lib/maven.defs')\nis resolved not to gerrit/lib/maven.defs but to gerrit/lib/jgit/lib/maven.defs file. Such file doesn't exist and the build was failing. The attempt to rectify it with symolic links worked unless we were trying to run buck test. And the same failure is repoducable with buck build too:\n$ buck build ...\n:::\n::: '.nobuckcheck' file is present. Not updating buck.\n:::\n[2016-01-05 00:10:39.433][error][command:b0a99aa1-0289-4944-9ba3-fe2a271b2fca][tid:17][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.nio.file.FileSystemLoopException: /home/davido/projects/gerrit/lib/jgit/lib\nCreating symbolic links was a hack to make include_defs() work in cross-cell dependencie context: [2].  But the correct solution here seems to be different: we should migrate our own Maven toolchain to buck fetch and get rid of these includes altogether.\nAnother option would be to teach Buck to be smarter in resolving include_defs() in cross-cell context.\n[1] http://paste.openstack.org/show/482980\n[2] http://paste.openstack.org/show/482988\n. This rises different question, how the buildfile.includes would be resolved in cross-cell context. Consider this .buckconfig content:\n[buildfile]\n  includes = //tools/default.defs\nThis `gwt_module\u00b4 definition in gerrit/tools/default.defs:\n```\ndef gwt_module(gwt_xml=None, **kwargs):\n  kw = copy.deepcopy(kwargs)\n  if 'resources' not in kw:\n    kw['resources'] = []\n  if gwt_xml:\n    kw['resources'] += [gwt_xml]\n  if 'srcs' in kw:\n    kw['resources'] += kw['srcs']\n# Buck does not accept duplicate resources. Callers may have\n  # included gwt_xml or srcs as part of resources, so de-dupe.\n  kw['resources'] = list(set(kw['resources']))\njava_library(**kw)\n```\nNow, when the cell's own BUCK file would try to reference this function:\ngwt_module(\n  name = 'Edit',\n  srcs = [':jgit_edit_src'],\n  deps = [':edit_src'],\n  visibility = ['PUBLIC'],\n)\nThis can't work, because this cell doesn't have .buckconfig file, where buildfile.includes is defined, so that this would fail with: \n$ buck targets //...\n<path>lib/jgit/BUCK\", line 7, in <module>\n    gwt_module(\nNameError: name 'gwt_module' is not defined\nWhen we would define buildfile.includes in <path>/lib/jgit/.buckconfig to be:\n[buildfile]\n  includes = //tools/default.defs\nas it's already the case in main .buckconfig file, then we would get different error:\nParse error for build file <path>/lib/jgit/BUCK: IOError: [Errno 2] No such file or directory: '<path>/lib/jgit/tools/default.defs'\nCreate a symlink is again not a option, because this would try to include and resolve other files from tools and lib directories: [1].\n[1] https://github.com/gerrit-review/gerrit/blob/master/tools/default.defs#L17-L21\n. Turned out, it was symlinks to parent directories problem. Buck doesn't support that.\n. I considered this, but wasn't sure, if this is somehow related to Buck. I do have some BUCK files in LibreOffrice tree (/home/davido/projects/libo/), though.\n. > With that addressed, I think @davido's question is, how can he ask buck not to use watchman for builds in the projects that he doesn't want to commit watch resources against?\nYes exactly. I'm not working currently on LibreOffice, and this is a project with ~100 thousands files (sources + generated) so how could I control what is being watched and what doesn't?\nFrom the user perspective, when i have three project directory:\n/home/davido/projects/proj1\n/home/davido/projects/proj2\n/home/davido/projects/proj3\nAll of them are using Buck build system, how can i restrict my current work (regarding watchman) to project proj1 and let the rest alone?\n. @wez Thanks.\nI added this file:\n$ cat /etc/watchman.json\n{\n  \"root_files\": [\".watchmanconfig\"]\n}\nand upgraded watchman and increased fs.inotify.max_user_watches. After that i executed shutdown-server command, with\n$ watchman shutdown-server\n$ watchman --version\n4.3.0\nNow when I'm trying to use buck build foo I'm getting:\n```\n[2016-01-15 21:32:02.657][error][command:d1bdee7f-a15a-4112-812d-d38f02bfed70][tid:824][com.facebook.buck.util.WatchmanWatcher] Error in Watchman output\ncom.facebook.buck.util.WatchmanWatcherException: unable to resolve root /home/davido/projects/gerrit: directory /home/davido/projects/gerrit is not watched\n    at com.facebook.buck.util.WatchmanWatcher.postEvents(WatchmanWatcher.java:295)\n    at com.facebook.buck.cli.Main$Daemon.watchFileSystem(Main.java:284)\n    at com.facebook.buck.cli.Main$Daemon.access$6(Main.java:273)\n    at com.facebook.buck.cli.Main.getParserFromDaemon(Main.java:792)\n    at com.facebook.buck.cli.Main.executeCommand(Main.java:603)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:452)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:979)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1036)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1065)\n    at sun.reflect.GeneratedMethodAccessor58.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:338)\nWatchman threw an exception while parsing file changes.\n```\nBuck only worked again after I manually said this:\n$ watchman watch /home/davido/projects/gerrit\n{\n    \"version\": \"4.3.0\",\n    \"watch\": \"/home/davido/projects/gerrit\"\n}\nWas there any behavioural change that made this manual intervention necessary?\nI also wonder, if there any way to ask, what project roots watchman is watching on my system? Sorry, if it's obvious how to do that, i couldn't figure out.\n. I'm confused, as for why LibreOffice libo directory was watched, or may be I'm just misunderstading the error from the Poison: inotify_add_watch? That's because this directory has 100k files and I would like to avoid that this project is ever watched, even though it is built with Buck. Here is the libo directory: [1]. Note, that this directory doesn't have .watchmanconfig file.\nI asume, it wouldn't hurt to be explicit about enforcing that .watchmanconfig exists in /etc/watchman.json?\nListing watches produces this:\n{\n    \"version\": \"4.3.0\",\n    \"roots\": [\n        \"/home/davido/projects/gerrit2\",\n        \"/home/davido/projects/gerrit\"\n    ]\n}\nBoth gerrit and gerrit2 are Gerrit Code Review trees: 2\nNow, when I'm going to libo directory and issue buck build it activates wathcing this tree, even though, this directry doesn't have .watchmanconfig and global \n$ buck build api \nBuck is at 79d36de9f5284f6e833cca81867d6088a25685fb, but should be 6659a474fb2ba6e921bb38c1b55d4c9ba6073cfa.\nBuck is updating itself. To disable this, add a '.nobuckcheck'\nfile to your project root. In general, you should only disable\nthis if you are developing Buck.\nBuck does not appear to have been built -- building Buck!\nAll done, continuing with build.\nUsing watchman.\nWaiting for Watchman command [/home/davido/bin/watchman watch-project /home/davido/projects/libo/.]...\nSo that now the watch-list was extended with the directory with 100k files:\n$ watchman watch-list\n{\n    \"version\": \"4.3.0\",\n    \"roots\": [\n        \"/home/davido/projects/libo\",\n        \"/home/davido/projects/gerrit2\",\n        \"/home/davido/projects/gerrit\"\n    ]\n}\nSo that after every single buck invocation i am forced to delete project tree from the watch list manually:\n$ watchman watch-del /home/davido/projects/libo\n{\n    \"version\": \"4.3.0\",\n    \"watch-del\": true,\n    \"root\": \"/home/davido/projects/libo\"\n}\ndavido@linux-ucwl:~/projects/libo (master $%=)$ watchman watch-list\n{\n    \"version\": \"4.3.0\",\n    \"roots\": [\n        \"/home/davido/projects/gerrit2\",\n        \"/home/davido/projects/gerrit\"\n    ]\n}\nOf course I could use NO_BUCKD=1 to ask Buk to skip watchman usage, but this would mean that I always have to think and not to forget it:\n$ NO_BUCKD=1 buck build api \nNot using buckd because NO_BUCKD is set.\n[-] PROCESSING BUCK FILES...FINISHED 0,2s [100%]\n[-] BUILDING...FINISHED 0,3s [100%] (1/19 JOBS, 0 UPDATED, 0,0% CACHE MISS)\ndavido@linux-ucwl:~/projects/libo (master $%=)$ watchman watch-list\n{\n    \"version\": \"4.3.0\",\n    \"roots\": [\n        \"/home/davido/projects/gerrit2\",\n        \"/home/davido/projects/gerrit\"\n    ]\n}\nI think I'm asking for more Buck -> Wathcman integration, and offer a feature, that I selctively can activate or deactivate projects that I'm building with Buck to use watchman or not.\nIn the setting above, watchman should refuse to work, and say something like: watch is deactivated for this tree: /home/davido/projects/libo, by enforcing the presense of .watchmanconfig file in the root project directory (see /etc/watchman.json), but  .watchmanconfig is not present in /home/davido/projects/libo. Buck should be able to recover and build without using watchman, as if the NO_BUCKD=1 would be passed.\nWaiting for Watchman command [/home/davido/bin/watchman watch-project /home/davido/projects/libo/.]...\n[1] http://paste.openstack.org/show/484058\n[2] https://github.com/gerrit-review/gerrit\n. Thanks! We were forced to temporarily remove jgit cross cell support in Gerrit Code Review, as we don't have a workaround for now for: #717. One it's solved we re-consider to add it again.\n. @k21 This is probably gerrit issue. To reproduce, revert https://github.com/gerrit-review/gerrit/commit/08ea694499c79f7ea07d7e704cffcc4649cbc708 on most recent gerrit master and issue:\n$ tools/eclips/project.py\nWhat we are doing is issuing buck audit and then call specific rules that end with src. For cell based rule we replace jgit cell with its own path, \"lib/jgit\" in this case, so that from:\n\"@jgit//org.eclipse.jgit.archive:jgit-archive\" -> \"//org.eclipse.jgit.archive:jgit-archive__download_src\"\nwe are calling:\nbuck build //lib/jgit/org.eclipse.jgit.archive:jgit-archive__download_src\nthis is failing with: [1]. Shouldn't we be able to use '+' cell prefix ?\nbuck build +jgit//org.eclipse.jgit.archive:jgit-archive__download_src\n  BUILD FAILED: Build target path cannot be absolute or contain . or .. (found //+jgit//org.eclipse.jgit.archive:jgit-archive__download_src)\n- [1] http://paste.openstack.org/show/495192\n. @Dominator008 good point. OTOH we are doing something wrong that we don't supposed to do: calling cell based target by rellocating it to the wrong root.\nWe did it in older Buck versions because this was the only workaround to call a cell-based target from CLI. With most recent Buck master, this workaround doesn't work any more, see the exception. That why we are stuck with cross-cell stuf: it's always needed to invoke a cross-based target from CLI.\n. @k21 Thanks for clarifying. Just to check my understanding: the references to the cross cell based targets should be harmonized:\njava_library(\n    name = 'cache-h2',\n    srcs = glob(['src/main/java/**/*.java']),\n    deps = [\n      '//gerrit-common:server',\n      '//gerrit-extension-api:api',\n      '//gerrit-server:server',\n      '//lib:guava',\n      '//lib:h2',\n      '//lib/guice:guice',\n      '//lib/log:api',\n      '@jgit//org.eclipse.jgit:jgit',\n    ],\n    visibility = ['PUBLIC'],\n  )\nSo that the references inside the BUCK file and on the CLI would be the same and in the form jgit//org.eclipse.jgit:jgit:\n[...]\n      '//lib/log:api',\n      'jgit//org.eclipse.jgit:jgit',\n    ],\n    visibility = ['PUBLIC'],\n  )\nand:\n$ buck build jgit//org.eclipse.jgit:jgit\nright?\n. It was fixed by renaming the input file.\n. It's transitive dependency through the java_test rule:\ntools/eclipse:classpath -> //gerrit-httpd:httpd_tests -> //lib:jimfs\nThe workaround is to put //lib:jimfs as a direct dependency to tools/eclipse:classpath, in which case buck audit classpath would work as expected even without '--dot' option: [1]\n$ buck audit classpath tools/eclipse:classpath | grep -i jimfs\n  [-] PARSING BUCK FILES...FINISHED 0.3s [100%]\n  /home/davido/projects/gerrit/buck-out/gen/lib/__jimfs__/jimfs-1.0.jar\n- [1] https://gerrit-review.googlesource.com/86374\n. This is actually a good quesion. I would expect that the command behave in smilar way, no matter what options are passed, unless it's documented that the dependency chain is cut for some edges. But then I would expect that it would be cut in the same way, no matter if I pass specific options or not (unless it's defined to have different semantic for different options).\nSo yes:\n$ buck audit classpath --dot tools/eclipse:classpath | grep gerrit-httpd:httpd_tests\n [-] PARSING BUCK FILES...FINISHED 0.3s [100%]\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib:servlet-api-3_1\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib/joda:joda-time\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib/guice:guice-servlet\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib:jimfs\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib:gson\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//gerrit-util-http:http\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//gerrit-reviewdb:server\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib:junit\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib/easymock:easymock\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//gerrit-util-http:testutil\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//gerrit-extension-api:api\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//gerrit-httpd:httpd\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib:gwtorm\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib:guava\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//gerrit-server:server\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib/guice:guice\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib/jgit/org.eclipse.jgit:jgit\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//gerrit-common:server\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib:truth\";\n  \"//gerrit-httpd:httpd_tests\" -> \"//lib/jgit/org.eclipse.jgit.junit:junit\";\n  \"//tools/eclipse:classpath\" -> \"//gerrit-httpd:httpd_tests\";\nIf I see this line with '--dot' option:\n\"//tools/eclipse:classpath\" -> \"//gerrit-httpd:httpd_tests\";\nit's kind of unexpected to not see the output file for this rule:\n$ buck targets --show_output gerrit-httpd:httpd_tests\n//gerrit-httpd:httpd_tests buck-out/gen/gerrit-httpd/lib__httpd_tests#testsjar__output/httpd_tests#testsjar.jar\nif I remove '--dot' option:\n$ buck audit classpath tools/eclipse:classpath | grep httpd_tests\n[-] PARSING BUCK FILES...FINISHED 0.3s [100%]\nBut then again, i can live with both behaviours as far as it is well defined and documented.\n. I'm not sure I would like to interact with third party build tool chains, like Maven and Gradle (we already need Ant to compile Buck). However, I also think that dependency management in Buck should be improved. But before thinking to introduce something new, I would concentrate on fixing something that is already there: remote_file and buck fetch. There are known issues with it: [1], basically the same, like with maven_jar in Bazel: [2]:\n- Buck version upgrade invalidate the cache\n- rm -rf buck-out remove the world\n- Subsequent clones of the same project in different location (stable branch) and re-build would re-download the whole world again\nFWIW: Bazel team is re-implementing native maven_jar rule as dependency aware Skylark rule [3], using Maven's maven-dependency-plugin behind the scenes.\n[1] #602\n[2] https://github.com/bazelbuild/bazel/issues/1752\n[3] https://bazel-review.googlesource.com/5770\n. I'm not sure I would like to interact with third party build tool chains, like Maven and Gradle (we already need Ant to compile Buck). However, I also think that dependency management in Buck should be improved. But before thinking to introduce something new, I would concentrate on fixing something that is already there: remote_file and buck fetch. There are known issues with it: [1], basically the same, like with maven_jar in Bazel: [2]:\n- Buck version upgrade invalidate the cache\n- rm -rf buck-out remove the world\n- Subsequent clones of the same project in different location (stable branch) and re-build would re-download the whole world again\nFWIW: Bazel team is re-implementing native maven_jar rule as dependency aware Skylark rule [3], using Maven's maven-dependency-plugin behind the scenes.\n[1] #602\n[2] https://github.com/bazelbuild/bazel/issues/1752\n[3] https://bazel-review.googlesource.com/5770\n. > Whats your rationale for not wanting to interact with third party build tool chains?\nMy point is: you would need to know and interact with yet another tool chain. For other needs, like  transitively download non Java artifacts, like say bower_components you would need yet another toolchain (Node, bower, ...).\nBlaze (Bazel), Buck and Pants all use Python for writing build files. What do you need more? My expectation is, that I can just say:\nmaven_jar(\n    name = 'foo',\n    artifact = 'bar:baz:qux-1.0',\n    sha1_bin = '42',\n    sha1_src = '43',\n    transitive = True # per default False, obviously\n  )\nDone. Once downloaded on my local machine (of course this should respect proxies to work in enterprise environment) the artifact should survive Buck upgrade, rm -rf buck-out and downloaded artifact should be re-used when the same projects is cloned multiple times on the same machine.\nIs this too much to expect, that for the requirements above i would like not need to install, configure, not to mention interact (by that I mean edit) with any other build toolchains, like build.xml, pom.xml and build.gradle.\nOne important thing to notice here, that the reason, why Google and Facebook havn't provided until today non broken by design remote_file/maven_jar and buck fetch / bazel fetch implementations out of the box in their build tool chains is because they use monorepo with all third party dependency checked in themself. So, they just don't have this problem. That is not WAI. I'm not adding any dependencies to repo and that why I rely on sane dependency management. (I even agree to resolve transitive dependency chain for my deps on my own.)\nFWIW, the best known maven_jar Bucklet implementation in native Buck that provides all feature mentioned above, except handling transitive dependencies, is provided in Gerrit build tool chain: [1].\n[1] https://github.com/davido/bucklets/blob/master/maven_jar.bucklet\n. > Whats your rationale for not wanting to interact with third party build tool chains?\nMy point is: you would need to know and interact with yet another tool chain. For other needs, like  transitively download non Java artifacts, like say bower_components you would need yet another toolchain (Node, bower, ...).\nBlaze (Bazel), Buck and Pants all use Python for writing build files. What do you need more? My expectation is, that I can just say:\nmaven_jar(\n    name = 'foo',\n    artifact = 'bar:baz:qux-1.0',\n    sha1_bin = '42',\n    sha1_src = '43',\n    transitive = True # per default False, obviously\n  )\nDone. Once downloaded on my local machine (of course this should respect proxies to work in enterprise environment) the artifact should survive Buck upgrade, rm -rf buck-out and downloaded artifact should be re-used when the same projects is cloned multiple times on the same machine.\nIs this too much to expect, that for the requirements above i would like not need to install, configure, not to mention interact (by that I mean edit) with any other build toolchains, like build.xml, pom.xml and build.gradle.\nOne important thing to notice here, that the reason, why Google and Facebook havn't provided until today non broken by design remote_file/maven_jar and buck fetch / bazel fetch implementations out of the box in their build tool chains is because they use monorepo with all third party dependency checked in themself. So, they just don't have this problem. That is not WAI. I'm not adding any dependencies to repo and that why I rely on sane dependency management. (I even agree to resolve transitive dependency chain for my deps on my own.)\nFWIW, the best known maven_jar Bucklet implementation in native Buck that provides all feature mentioned above, except handling transitive dependencies, is provided in Gerrit build tool chain: [1].\n[1] https://github.com/davido/bucklets/blob/master/maven_jar.bucklet\n. > There is no need to actually define a build.gradle file to take advantage of gradle for this. The artifact rule you described above can be translated internally to a model gradle/maven understand and use their core logic to do the rest.\nI agree. I wouldn't care what Buck is using behind the scenes, as far as I don't have to interact with any specifics of third party tool chains. Say edit (or even see) pom.xml and build.gradle.\n\n\nexcept handling transitive dependencies\n\nI think this makes it not very useful as it is almost similar to a vanilla buck fetch with some scripting to figure out where the jar/aar lives on maven central.\n\nYes. That why I said, that dependency management should be improved in Buck itself.\n. > There is no need to actually define a build.gradle file to take advantage of gradle for this. The artifact rule you described above can be translated internally to a model gradle/maven understand and use their core logic to do the rest.\nI agree. I wouldn't care what Buck is using behind the scenes, as far as I don't have to interact with any specifics of third party tool chains. Say edit (or even see) pom.xml and build.gradle.\n\n\nexcept handling transitive dependencies\n\nI think this makes it not very useful as it is almost similar to a vanilla buck fetch with some scripting to figure out where the jar/aar lives on maven central.\n\nYes. That why I said, that dependency management should be improved in Buck itself.\n. FWIW, transitive dependencies was added to Bazel with this bazlets: [1]. The underlying implementaion uses gradle.\n[1] https://github.com/pubref/rules_maven. FWIW, transitive dependencies was added to Bazel with this bazlets: [1]. The underlying implementaion uses gradle.\n[1] https://github.com/pubref/rules_maven. CC @Coneko. Can you have a look? Thanks!\n. CC @Coneko. Can you have a look? Thanks!\n. @finik Can you add Buck version you are using?\n. @finik Can you add Buck version you are using?\n. I think that Buck is confused with ANDROID_HOME and ANDROID_SDK_ROOT. When they are set, Buck expects specific version of SDK present. Just unsetting these env variables should fix the problem, I guess (I don't use Android).\n. I think that Buck is confused with ANDROID_HOME and ANDROID_SDK_ROOT. When they are set, Buck expects specific version of SDK present. Just unsetting these env variables should fix the problem, I guess (I don't use Android).\n. Thanks!. Thanks!. Can we revert this? After pulling new Buck version, build is broken on vanilla Max Os X (El Capitan):\n/Users/davido/bin/buck: line 8: realpath: command not found\nAnd please, don't tell me how i could install realpath.. Can we revert this? After pulling new Buck version, build is broken on vanilla Max Os X (El Capitan):\n/Users/davido/bin/buck: line 8: realpath: command not found\nAnd please, don't tell me how i could install realpath.. java.source_level is respected in Buck. Your example is source level compatible, but you use methods from runtime library that were added only in Java 8. What you want is a different feature called cross-compilation. To achieve that you must provide bootstrap classpath from the target JDK, otherwise you will end up using source JDK, see the warning:\n```\n  $ java -version\njava version \"1.8.0_77\"\nJava(TM) SE Runtime Environment (build 1.8.0_77-b03)\nJava HotSpot(TM) 64-Bit Server VM (build 25.77-b03, mixed mode)\n$ javac -source 7 -target 7 com/exampl/buck/Main.java\nwarning: [options] bootstrap class path not set in conjunction with -source 1.7\n1 warning\n```\nLet's check the Java Compiler specification:\n```\n-bootclasspath bootclasspath\nCross-compiles against the specified set of boot classes. As with the user class path, boot class path entries are separated by colons (:) and can be directories, JAR archives, or ZIP archives.\n\n```\nThere is even an example exactly for this use case, with the explanation:\n```\nExample 5 - Cross Compile\nThis example uses javac to compile code that runs on JVM 1.7.\n\njavac -source 1.7 -target 1.7 -bootclasspath C:\\jdk1.7.0\\lib\\rt.jar ^\n            -extdirs \"\" OldCode.java\n\nThe -source 1.7 option specifies that release 1.7 (or 7) of the Java programming language to be used to compile OldCode.java. The -target 1.7 option ensures that the generated class files are compatible with JVM 1.7.\n\nYou must specify the -bootclasspath option to specify the correct version of the bootstrap classes (the rt.jar library). If not, then the compiler generates a warning:\n\njavac -source 1.7 OldCode.java\nwarning: [options] bootstrap class path not set in conjunction with -source 1.7\n\nIf you do not specify the correct version of bootstrap classes, then the compiler uses the old language rules combined with the new bootstrap classes. This combination can result in class files that do not work on the older platform (in this case, Java SE 7) because reference to nonexistent methods can get included. In this example, the compiler uses release 1.7 of the Java programming language.\n\n```\nIt seems that buck doesn't support custom bootstrap class path yet in buckconfig file:\nhttps://buckbuild.com/concept/buckconfig.html#java.\nNeedless to say that Apache Ant supports this feature:\nbootclasspath   Location of bootstrap class files. (See below for using the -X and -J-X parameters for specifying the bootstrap classpath).\nI modified your example, to include non Java 7 construct, lambda:\nprivate void mainImpl() throws IOException {\n        List<String> myList = Arrays.asList(\"foo\", \"bar\", \"baz\");\n        myList.forEach(new Consumer<String>() {\n                public void accept(String element) {\n                    System.out.println(element);\n                }\n            });\n        myList.forEach((String element) -> System.out.println(element));\n    }\nNow it's failing as expected, but only because of -> construct but not because of non-existing List.forEach method that was added only in Java 8:\n$ javac -source 7 -target 7 com/exampl/buck/Main.java\nwarning: [options] bootstrap class path not set in conjunction with -source 1.7\ncom/exampl/buck/Main.java:16: error: lambda expressions are not supported in -source 1.7\n    myList.forEach((String element) -> System.out.println(element));\n                                    ^\n  (use -source 8 or higher to enable lambda expressions)\n1 error\n1 warning\n. OK, I was wrong. It's there:\n[java]\n  extra_arguments = -g\nSo what you (or GerritForge CI) want to set in .buckconfig.local in the root of Gerrit stable-2.13 tree:\n[java]\n  extra_arguments = -bootclasspath <path to jdk7 rt.jar>\nOne confusing thing is: while this section is called [java] it should probably be called [javac].\n. Setting extra_arguments to:\n[java]\n extra_arguments = \"-bootclasspath /usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rt.jar\"\nis failing with:\n```\ninvalid flag: -bootclasspath /usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rt.jar\njava.lang.IllegalArgumentException: invalid flag: -bootclasspath /usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rt.jar\n    at com.sun.tools.javac.api.JavacTool.processOptions(JavacTool.java:206)\n```\n. So, I figured it out, it should be:\n[java]\n    extra_arguments = -Xbootclasspath/p:/usr/lib64/jvm/java-1.7.0-openjdk-1.7.0/jre/lib/rt.jar\nNow, when I reverting this fix to break stable-2.13 branch again: [1], and building it with Java 8:\n```\n  $ java -version\nopenjdk version \"1.8.0_101\"\nOpenJDK Runtime Environment (IcedTea 3.1.0) (suse-15.1-x86_64)\nOpenJDK 64-Bit Server VM (build 25.101-b13, mixed mode)\n$ buck build gerrit-server:server\n[-] PROCESSING BUCK FILES...FINISHED 0.0s\n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...4.4s [37%] (146/147 JOBS, 0 UPDATED, 0.0% CACHE MISS)\n |=> //gerrit-server:server...  4.3s (running javac_jar[4.2s])\n/home/davido/projects/gerrit/gerrit-server/src/main/java/com/google/gerrit/server/project/ProjectCacheImpl.java:218: error: cannot find symbol\n      return Collections.emptySortedSet();\n                        ^\n  symbol:   method emptySortedSet()\n  location: class java.util.Collections\nErrors: 1. Warnings: 0.\n``\n- [1] https://gerrit-review.googlesource.com/89326\n. Yes, exactly, we cannot do that as the locations may differ.\n. Sorry, I missed it. The usage ofgwt_jar` was even documented in the original commit message:\n| This diff also introduces a gwt_jar argument to prebuilt_jar. This is useful for\n    defining Guava:\nprebuilt_jar(\n      name = 'guava',\n      binary_jar = 'guava-17.0.jar',\n      source_jar = 'guava-17.0-sources.jar',\n      gwt_jar = 'guava-gwt-17.0.jar',\n      visibility = [\n        'PUBLIC',\n      ],\n    )\nThis is imperative when you have an alternative GWT implementation of a Java library.\n    Specifically, when you have one implementation that contains JSNI, and one implementation that\n    contains an implementation that cannot be translated to JS by the GWT compiler.\n. @kageiit Now, that #1019 is merged, is it already possible to seamlessly integrate error prone with Buck?. @kageiit Now, that #1019 is merged, is it already possible to seamlessly integrate error prone with Buck?. @kageiit thanks! it was harder as expected, though. Quoting here my comment on Buck integration feature request on error prone issue tracker: https://github.com/google/error-prone/issues/318.\nSo, it seems, that if I borrow thoses dependencies from Bazel tree (9bde9d09a83cdca2dc884d322ab50f7542c062cf)\n\nthird_party/java/jdk/langtools/javac.jar\nthird_party/error_prone/error_prone_annotations-2.0.13.jar\nthird_party/error_prone/error_prone_annotation-2.0.13.jar\nthird_party/error_prone/error_prone_core-2.0.13.jar\nthird_party/checker_framework_dataflow/dataflow-1.8.10.jar\n\nNow, the other two missing dependencies jformatstring and libchecker_framework_javacutil must be compiled from the source:\n```\n  bazel build third_party/jformatstring:jformatstring\n  cp bazel-bin/third_party/jformatstring/libjformatstring.jar \nbazel build checker_framework_javacutil\n  cp bazel-bin/third_party/checker_framework_javacutil/libchecker_framework_javacutil.jar \n```\nAfter building a uber JARs with all those dependencies above I've added these lines to my .buckconfig.local file in Gerrit Code Review project:\n[tools]\n    javac_jar = lib/error_prone_2.13_all_in_one.jar\n    compiler_class_name = com.google.errorprone.ErrorProneJavaCompiler\nNow, after bumping Buck to the most recent master (45c405cf2ba2735e8c06cf76eed224d6f81d666e) and patching gerrit-server sub-project with this diff: http://paste.openstack.org/show/592031 and building with buck build gerrit-server:server we are getting error prone warnings and errors: http://paste.openstack.org/show/592032.\nSo, error prone activation must be really trivial. Ideally Buck should ship the current version of error-prone-all-in-one.jar, so that all i have to do is to add those three line to my .buckconfig:\n[tools]\n    javac_jar = <??lib??>/error_prone_<current-version>_all_in_one.jar\n    compiler_class_name = com.google.errorprone.ErrorProneJavaCompiler\ndone? Not really. This raises the question, where to put the error_prone_all_in_one.jar dependency? For all non monorepo projects in the wild, it's not an option to add binaries to the repository. Unfortunately Buck doesn't accept an absolute path for tools.javac_jar, so it's also not an option to put it in ~/.buck-missing-dependencies directory, so that setting javac_jar = /home/davido/.buck_missing_dependencies/error_prone_2.13_all_in_one.jar bring us to the next problem:\nCaused by: java.lang.IllegalStateException: Expected path to be relative, not absolute: /home/davido/.buck_missing_dependencies/error_prone_2.13_all_in_one.jar (from /home/davido/.buck_missing_dependencies/error_prone_2.13_all_in_one.jar)\n    at com.google.common.base.Preconditions.checkState(Preconditions.java:199)\n    at com.facebook.buck.rules.SourcePathResolver.getRelativePath(SourcePathResolver.java:146)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setSourcePath(InputBasedRuleKeyBuilderFactory.java:230)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setSourcePath(InputBasedRuleKeyBuilderFactory.java:1)\n    at com.facebook.buck.rules.RuleKeyBuilder.setSingleValue(RuleKeyBuilder.java:368)\n    at com.facebook.buck.rules.RuleKeyBuilder.setReflectively(RuleKeyBuilder.java:239)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setReflectively(InputBasedRuleKeyBuilderFactory.java:184)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setReflectively(InputBasedRuleKeyBuilderFactory.java:1)\n    at com.facebook.buck.rules.RuleKeyBuilder.setReflectively(RuleKeyBuilder.java:249)\n    at com.facebook.buck.rules.RuleKeyBuilder.setReflectively(RuleKeyBuilder.java:204)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setReflectively(InputBasedRuleKeyBuilderFactory.java:184)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setReflectively(InputBasedRuleKeyBuilderFactory.java:1)\n    at com.facebook.buck.jvm.java.JarBackedJavac.appendToRuleKey(JarBackedJavac.java:70)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$1.load(InputBasedRuleKeyBuilderFactory.java:83)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$1.load(InputBasedRuleKeyBuilderFactory.java:1)\n    at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3542)\n    at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2323)\n    at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2286)\n    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2201)\n    ... 71 more\nIOW, it doesn't work.\nEven better, if Buck is going to ship error prone and is aware of it existence, i would expect to have a native integration, by say introducing: tools.user_error_prone = true, in which case buck own shipped buck/third-party/java/error-prone/error_prone_all_in_one.jar should be seamlessly activated and the tools.compiler_class_name is implicitly set to com.google.errorprone.ErrorProneJavaCompiler.\nNext step, when all are happy with having error prone activated by default, so that only projects would need to say:\ntools.user_error_prone = false\nthat would like to not use error prone.\nFWIW: I've uploaded the version of error_prone_2.13_all_in_one.jar.. @kageiit thanks! it was harder as expected, though. Quoting here my comment on Buck integration feature request on error prone issue tracker: https://github.com/google/error-prone/issues/318.\nSo, it seems, that if I borrow thoses dependencies from Bazel tree (9bde9d09a83cdca2dc884d322ab50f7542c062cf)\n\nthird_party/java/jdk/langtools/javac.jar\nthird_party/error_prone/error_prone_annotations-2.0.13.jar\nthird_party/error_prone/error_prone_annotation-2.0.13.jar\nthird_party/error_prone/error_prone_core-2.0.13.jar\nthird_party/checker_framework_dataflow/dataflow-1.8.10.jar\n\nNow, the other two missing dependencies jformatstring and libchecker_framework_javacutil must be compiled from the source:\n```\n  bazel build third_party/jformatstring:jformatstring\n  cp bazel-bin/third_party/jformatstring/libjformatstring.jar \nbazel build checker_framework_javacutil\n  cp bazel-bin/third_party/checker_framework_javacutil/libchecker_framework_javacutil.jar \n```\nAfter building a uber JARs with all those dependencies above I've added these lines to my .buckconfig.local file in Gerrit Code Review project:\n[tools]\n    javac_jar = lib/error_prone_2.13_all_in_one.jar\n    compiler_class_name = com.google.errorprone.ErrorProneJavaCompiler\nNow, after bumping Buck to the most recent master (45c405cf2ba2735e8c06cf76eed224d6f81d666e) and patching gerrit-server sub-project with this diff: http://paste.openstack.org/show/592031 and building with buck build gerrit-server:server we are getting error prone warnings and errors: http://paste.openstack.org/show/592032.\nSo, error prone activation must be really trivial. Ideally Buck should ship the current version of error-prone-all-in-one.jar, so that all i have to do is to add those three line to my .buckconfig:\n[tools]\n    javac_jar = <??lib??>/error_prone_<current-version>_all_in_one.jar\n    compiler_class_name = com.google.errorprone.ErrorProneJavaCompiler\ndone? Not really. This raises the question, where to put the error_prone_all_in_one.jar dependency? For all non monorepo projects in the wild, it's not an option to add binaries to the repository. Unfortunately Buck doesn't accept an absolute path for tools.javac_jar, so it's also not an option to put it in ~/.buck-missing-dependencies directory, so that setting javac_jar = /home/davido/.buck_missing_dependencies/error_prone_2.13_all_in_one.jar bring us to the next problem:\nCaused by: java.lang.IllegalStateException: Expected path to be relative, not absolute: /home/davido/.buck_missing_dependencies/error_prone_2.13_all_in_one.jar (from /home/davido/.buck_missing_dependencies/error_prone_2.13_all_in_one.jar)\n    at com.google.common.base.Preconditions.checkState(Preconditions.java:199)\n    at com.facebook.buck.rules.SourcePathResolver.getRelativePath(SourcePathResolver.java:146)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setSourcePath(InputBasedRuleKeyBuilderFactory.java:230)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setSourcePath(InputBasedRuleKeyBuilderFactory.java:1)\n    at com.facebook.buck.rules.RuleKeyBuilder.setSingleValue(RuleKeyBuilder.java:368)\n    at com.facebook.buck.rules.RuleKeyBuilder.setReflectively(RuleKeyBuilder.java:239)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setReflectively(InputBasedRuleKeyBuilderFactory.java:184)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setReflectively(InputBasedRuleKeyBuilderFactory.java:1)\n    at com.facebook.buck.rules.RuleKeyBuilder.setReflectively(RuleKeyBuilder.java:249)\n    at com.facebook.buck.rules.RuleKeyBuilder.setReflectively(RuleKeyBuilder.java:204)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setReflectively(InputBasedRuleKeyBuilderFactory.java:184)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$Builder.setReflectively(InputBasedRuleKeyBuilderFactory.java:1)\n    at com.facebook.buck.jvm.java.JarBackedJavac.appendToRuleKey(JarBackedJavac.java:70)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$1.load(InputBasedRuleKeyBuilderFactory.java:83)\n    at com.facebook.buck.rules.keys.InputBasedRuleKeyBuilderFactory$1.load(InputBasedRuleKeyBuilderFactory.java:1)\n    at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3542)\n    at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2323)\n    at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2286)\n    at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2201)\n    ... 71 more\nIOW, it doesn't work.\nEven better, if Buck is going to ship error prone and is aware of it existence, i would expect to have a native integration, by say introducing: tools.user_error_prone = true, in which case buck own shipped buck/third-party/java/error-prone/error_prone_all_in_one.jar should be seamlessly activated and the tools.compiler_class_name is implicitly set to com.google.errorprone.ErrorProneJavaCompiler.\nNext step, when all are happy with having error prone activated by default, so that only projects would need to say:\ntools.user_error_prone = false\nthat would like to not use error prone.\nFWIW: I've uploaded the version of error_prone_2.13_all_in_one.jar.. OK, it turns out, it works as expected:\n```python\n  maven_jar(\n    name = 'errorprone',\n    id = 'com.google.errorprone:error_prone_ant:2.0.15',\n    sha1 = '607e3866e2ee25b74708c2898f84eac2f5452d2f',\n    license = 'Apache2.0',\n  )\njava_library(\n    name = 'compiler_lib',\n    srcs = ['java/BuckPrologCompiler.java'],\n    javac_jar = '//lib:errorprone',\n    compiler_class_name = 'com.google.errorprone.ErrorProneJavaCompiler',\n  )\n``\n. Actually, it only works when passing a//lib:errorpronerule tojavac_jarinjava_library. When I'm defining the same in.buckckonfig`, it's failing with:\n```\nThis is failing with: BUILD FAILED: Rule for target '//:errorprone' could not be resolved.\n\n[tools]\njavac_jar = //:errorprone\ncompiler_class_name = com.google.errorprone.ErrorProneJavaCompiler\n```\nI'v created a reproducer repository: https://github.com/davido/buck_error_prone_integration .\nAnyway, with monkey patching it just works. Note no pollution of javac_jar and compiler_class_name in java_library rule(s):\n```python\nremote_file(\n  name = 'errorprone',\n  sha1 = '607e3866e2ee25b74708c2898f84eac2f5452d2f',\n  url = 'mvn:com.google.errorprone:error_prone_ant:jar:2.0.15',\n  out = 'errorprone.jar',\n  visibility = ['PUBLIC'],\n)\njava_library(\n  name = 'util',\n  srcs = glob(['java/*/.java']),\n)\n```\nBut monkey patching through buildfile.includes config option in .buckconfig:\n```python\n_buck_java_library = java_library\ndef java_library(*args, kwargs):\n  _munge_args(kwargs)\n  _buck_java_library(*args, kwargs)\ndef _munge_args(kwargs):\n  _set_errot_prone(kwargs)\ndef _set_errot_prone(kwargs):\n  kwargs['javac_jar'] = '//:errorprone'\n  kwargs['compiler_class_name'] = 'com.google.errorprone.ErrorProneJavaCompiler'\n```\nRunning the build, is reporting Error Prone checks:\n```\n  $ buck build :util\n  /home/davido/projects/buck_error_prone_integration/java/org/ostrovsky/buck/Util.java:5: error: [DeadException] Exception created but not thrown\n    new Exception();\n    ^\n    (see http://errorprone.info/bugpattern/DeadException)\n  Did you mean to remove this line?\nErrors: 1. Warnings: 0.\nBUILD FAILED: //:util failed with exit code 1:\njavac\nstderr: /home/davido/projects/buck_error_prone_integration/java/org/ostrovsky/buck/Util.java:5: error: [DeadException] Exception created but not thrown\n    new Exception();\n    ^\n    (see http://errorprone.info/bugpattern/DeadException)\n  Did you mean to remove this line?\nErrors: 1. Warnings: 0.\n``. Build tool must not have any dependencies.Antis weird enough to depend on to bootstrap Buck. I wonder why #930 wasn't reverted yet?. Build tool must not have any dependencies.Ant` is weird enough to depend on to bootstrap Buck. I wonder why #930 wasn't reverted yet?. @Coneko Thanks.. @Coneko Thanks.. Indeed, thanks for the link. I also see that there was already some efforts to integrate Buck with error prone here: https://github.com/google/error-prone/issues/318.\n. Oh, thanks for pointing this out, I missed it.\n$ buck build --show-output headless\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83d\udc07  \n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...0.1s [0%] (0/561 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\n |=> //gerrit-server:server...  0.0s (checking local cache)\nThe outputs are:\n//:headless buck-out/gen/headless/headless.war\nI have three comments, though:\n\n\n\nThe targets command also accepts --show_output, while build command only supports --show-output spelling.\n\n\n\n\nFollowing the DRY principle, I wouldn't expect the output to be that verbose and dump the rule name, that I asked to build. I know that I asked to dump the output, and I know, what command i asked to execute. And there can be always at most one command outcome in Buck. So i would expect the --show-output to just tell me the output:\n\n\n\n$ buck build --show-output headless\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83d\udc07  \n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...0.1s [0%] (0/561 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\n |=> //gerrit-server:server...  0.0s (checking local cache)\n  buck-out/gen/headless/headless.war\n\n\n\nIt's annoying to always specify --show-output option, and i don't want to mess around with shell aliases. Please, consider to introduce some means to specify the defaut command options in user specific Buck configuration file, e.g.:\n\n\n\n$ cat ~/.buckrc\n[...]\n[commands]\n  build = --show-output\n[...]. Oh, thanks for pointing this out, I missed it.\n$ buck build --show-output headless\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83d\udc07  \n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...0.1s [0%] (0/561 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\n |=> //gerrit-server:server...  0.0s (checking local cache)\nThe outputs are:\n//:headless buck-out/gen/headless/headless.war\nI have three comments, though:\n\n\n\nThe targets command also accepts --show_output, while build command only supports --show-output spelling.\n\n\n\n\nFollowing the DRY principle, I wouldn't expect the output to be that verbose and dump the rule name, that I asked to build. I know that I asked to dump the output, and I know, what command i asked to execute. And there can be always at most one command outcome in Buck. So i would expect the --show-output to just tell me the output:\n\n\n\n$ buck build --show-output headless\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83d\udc07  \n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...0.1s [0%] (0/561 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\n |=> //gerrit-server:server...  0.0s (checking local cache)\n  buck-out/gen/headless/headless.war\n\n\n\nIt's annoying to always specify --show-output option, and i don't want to mess around with shell aliases. Please, consider to introduce some means to specify the defaut command options in user specific Buck configuration file, e.g.:\n\n\n\n$ cat ~/.buckrc\n[...]\n[commands]\n  build = --show-output\n[...]. Another alternative is to swap the logic to always show the output but offer \"--hide-output\" option to suppress it.. Another alternative is to swap the logic to always show the output but offer \"--hide-output\" option to suppress it.. I addressed all comments.. Right. That why i haven't uploaded a PR.. Looks like documentation is stale here, as target attribute not mentioned in the documentation of android_binary: [1]. Try to remove this line and try again.\n\n[1] https://buckbuild.com/rule/android_binary.html.  > Since we are already checking in these files, can we just provide an option to set a .buckconfig option to make the default javac the error prone compiler for end consumers of buck?\n\nThat's what #994 is all about. That's the plan and is the next change in this series..  > Since we are already checking in these files, can we just provide an option to set a .buckconfig option to make the default javac the error prone compiler for end consumers of buck?\nThat's what #994 is all about. That's the plan and is the next change in this series.. @kageiit \n\nSince we are already checking in these files, can we just provide an option to set a .buckconfig option to make the default javac the error prone compiler for end consumers of buck?\n\nDone. The option is: java.error_prone_javac. Add it to your .buckconfig or pass instantly with buck build --config java.error_prone_javac=true foo and enjoy error prone checks.. @kageiit \n\nSince we are already checking in these files, can we just provide an option to set a .buckconfig option to make the default javac the error prone compiler for end consumers of buck?\n\nDone. The option is: java.error_prone_javac. Add it to your .buckconfig or pass instantly with buck build --config java.error_prone_javac=true foo and enjoy error prone checks.. > Can we make this option be configurable per target as well similar to javac_jar for java and android rules?\nWorking on it right now. Should it be the same as in .buckconfig:\njava_library(\n    name = 'foo',\n    error_prone_javac = True,\n    [...]. > 2.0.16 has been released just now. This pr should be good to go after an update\nThanks for the confirmation. I will update the PR later today and bump to the EP 2.0.16.. @kageiit I have one found the time today to rebase the PR on top of master. EP upgrade to 2.0.16 will follow.... @kageiit Thanks, working on the upgrade right now.. Doesn't seem to work:\n```\n$ buck build buck\nFailed to calculate ABI for /home/davido/projects/davido_buck/third-party/java/errorprone/error_prone_ant-2.0.17.jar.\njava.lang.IllegalArgumentException\njava.lang.IllegalArgumentException\n    at org.objectweb.asm.ClassReader.(ClassReader.java:170)\n    at org.objectweb.asm.ClassReader.(ClassReader.java:153)\n    at org.objectweb.asm.ClassReader.(ClassReader.java:424)\n    at com.facebook.buck.jvm.java.abi.BytecodeStubber.createStub(BytecodeStubber.java:32)\n    at com.facebook.buck.jvm.java.abi.StubbingLibraryReader.openClass(StubbingLibraryReader.java:64)\n    at com.facebook.buck.jvm.java.abi.StubbingLibraryReader.openClass(StubbingLibraryReader.java:1)\n    at com.facebook.buck.jvm.java.abi.StubJar.writeTo(StubJar.java:74)\n    at com.facebook.buck.jvm.java.abi.StubJar.writeTo(StubJar.java:59)\n    at com.facebook.buck.jvm.java.CalculateAbiStep.execute(CalculateAbiStep.java:51)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:47)\n    at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:1400)\n    at com.facebook.buck.rules.CachingBuildEngine.lambda$13(CachingBuildEngine.java:332)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$0(WeightedListeningExecutorService.java:81)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:211)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:200)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:952)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nFailed to calculate ABI for /home/davido/projects/davido_buck/third-party/java/errorprone/error_prone_ant-2.0.17.jar.\njava.lang.IllegalArgumentException\njava.lang.IllegalArgumentException\n    at org.objectweb.asm.ClassReader.(ClassReader.java:170)\n    at org.objectweb.asm.ClassReader.(ClassReader.java:153)\n    at org.objectweb.asm.ClassReader.(ClassReader.java:424)\n    at com.facebook.buck.jvm.java.abi.BytecodeStubber.createStub(BytecodeStubber.java:32)\n    at com.facebook.buck.jvm.java.abi.StubbingLibraryReader.openClass(StubbingLibraryReader.java:64)\n    at com.facebook.buck.jvm.java.abi.StubbingLibraryReader.openClass(StubbingLibraryReader.java:1)\n    at com.facebook.buck.jvm.java.abi.StubJar.writeTo(StubJar.java:74)\n    at com.facebook.buck.jvm.java.abi.StubJar.writeTo(StubJar.java:59)\n    at com.facebook.buck.jvm.java.CalculateAbiStep.execute(CalculateAbiStep.java:51)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:47)\n    at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:1400)\n    at com.facebook.buck.rules.CachingBuildEngine.lambda$13(CachingBuildEngine.java:332)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$0(WeightedListeningExecutorService.java:81)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:211)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:200)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:952)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nBUILD FAILED: //third-party/java/errorprone:error_prone failed with exit code 1:\ncalculate_abi\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83c\udfd6  (Watchman reported no changes)\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 1.8s [100%] (305/637 JOBS, 41 UPDATED, 41 [6.4%] CACHE MISS)\n``. MyJVM` version is:\n$ java -version\nopenjdk version \"1.8.0_121\"\nOpenJDK Runtime Environment (IcedTea 3.3.0) (suse-21.4-x86_64)\nOpenJDK 64-Bit Server VM (build 25.121-b13, mixed mode).  > [...] Matchers.hasItem is the function you're looking for - Matchers.contains performs an equality rather than subset check.\nDone. PTAL.. Thanks for review. I will address your comments in next days.. > Thanks! Minor request: could we make adding the errorprone jar separate from this PR?\nI tried, and figured out that it fails to use newer Guava version. Note, that it's only annotation and not the whole error prone. I do not remember exactly the error message, but I can try to remove it and report back.. @marcinkosiba Sorry, was blocked with other urgent stuff, will fix the PR later this week.. @Coneko \n\nThis failed the lint:\nDaemonicParserState.java\n\nDone.\nIt seem that the lint in this case is failing to detect the disabling:\ntest/com/facebook/buck/testutil/MoreAssertsTest.java\nWarning (ANTPMDEmptyCatchBlock) Empty Code at line 33\nWhat I changed was:\n```\ndiff --git a/test/com/facebook/buck/testutil/MoreAssertsTest.java b/test/com/facebook/buck/testutil/MoreAssertsTest.java\nindex bb443c2..5a7880a 100644\n--- a/test/com/facebook/buck/testutil/MoreAssertsTest.java\n+++ b/test/com/facebook/buck/testutil/MoreAssertsTest.java\n@@ -24,7 +24,7 @@ import org.junit.Test;\npublic class MoreAssertsTest {\n\n@SuppressWarnings(\"PMD.EmptyCatchBlock\")\n@SuppressWarnings({\"PMD.EmptyCatchBlock, TryFailThrowable\"})\n   private void expectFail(Iterable<?> a, Iterable<?> b) {\n     try {\n       MoreAsserts.assertIterablesEquals(a, b);\nlines 1-19/19 (END)\n```\n\nWhat you are doing there is probably crazy, as you need to disable each and every checker tool, and because you now need to disable both, this combined annotation is not recognized now?. > Warning    (ANTPMDEmptyCatchBlock) Empty Code at line 33\nSeems that lint in this case doesn't detect disabling annotation?. @Coneko All comments addressed, PTAL.. My bad, will address it and update the PR.. @marcinkosiba Done. PTAL.. @marcinkosiba Fixed some issues. PTAL.. @marcinkosiba Fixed some issues. PTAL.. So, it appears, that my Linux provider OpenSuSE doesn't include JFX packages in its distro: [1]. Is it really justified to add dependency on that mess, only to abuse the usage of javafx.util.Pair?\n\n\n[1] https://forums.opensuse.org/showthread.php/517440-JavaFX-OpenJFX-installation. Closed in favor of: https://github.com/facebook/buck/issues/1219.. @Coneko Thx for confirming. Will upload a fix in a moment.. @ttsugriy I released a private version of auto-value with this PR included https://github.com/google/auto/pull/563 here: [1]. I needed it to build gerrit code review with bazel, with Java 9: [2].\n\n\n[1] https://github.com/davido/auto/releases/tag/auto-value-1.6\n\n[2] https://gerrit-review.googlesource.com/#/c/gerrit/+/147233/. @ttsugriy Right, but I was able to build Bazel with this version with Java 9, see https://github.com/bazelbuild/bazel/pull/4820.. @ttsugriy I filed this issue: https://github.com/bazelbuild/bazel/issues/4906. I'm on vacation now, and can only look into it later.. Actually, I can compile Buck with JDK11 without any issue. When I try to run Buck built on JDK11 it crashes: http://paste.openstack.org/show/744455.\n\nIs it a known issue?. Done\n. Done.\n. Done\n. Looks like a left over from the debugging session. Done.\n. Done\n. Done\n. @k21 Done. PTAL.. Why not to decrease the severity to WARN instead\nextra_args.extend(['-Xep:OptionalEquality:WARN']). Oh, I see, that the same issue was raised by @tbroyer on error prone issue tracker: [1], and the solution was to skip warnings in generated code by -XepDisableWarningsInGeneratedCode.\n\n[1] https://github.com/google/error-prone/issues/329. WTF?. The reason I did it was because there were errors in error prone checks for test/... . But I agree, let us do that and fix the breakage before submitting this.. Done.. Oh, nice, when i actually run the test (i only compiled the tests before pushing the PR), I'm seeing this breakage:\n\nRESULTS FOR //test/com/facebook/buck/artifact_cache:artifact_cache\nPASS    <100ms  3 Passed   0 Skipped   0 Failed   com.facebook.buck.artifact_cache.AbstractNetworkCacheTest\nPASS    <100ms 16 Passed   0 Skipped   0 Failed   com.facebook.buck.artifact_cache.ArtifactCacheBuckConfigTest\nPASS     179ms  4 Passed   0 Skipped   0 Failed   com.facebook.buck.artifact_cache.ArtifactCachesTest\nFAIL     307ms 14 Passed   0 Skipped   1 Failed   com.facebook.buck.artifact_cache.DirArtifactCacheTest\nFAILURE com.facebook.buck.artifact_cache.DirArtifactCacheTest testCacheStoresAndFetchHits: \nExpected: iterable containing [\"ec40f9121202be3508b4f5ab7b0a511d3bdcf9d9\"]\n     but: item 0: was \"8e2eabf8408715a938eaf41c6933ab0da79da6da\"\njava.lang.AssertionError: \nExpected: iterable containing [\"ec40f9121202be3508b4f5ab7b0a511d3bdcf9d9\"]\n     but: item 0: was \"8e2eabf8408715a938eaf41c6933ab0da79da6da\"\n    at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:18)\n    at org.junit.Assert.assertThat(Assert.java:956)\n    at org.junit.Assert.assertThat(Assert.java:923)\n    at com.facebook.buck.artifact_cache.DirArtifactCacheTest.testCacheStoresAndFetchHits(DirArtifactCacheTest.java:304)\nWs this the reason, why assert weren\u00c4t implemened?. @marcinkosiba \nIt was also unclear how to convince buck autodeps to add this dependency here? So i added it manually for now, and only here, ... Running buck autodeps would overwrite this file and remove it again, though.. Done. Done. Done. Done. Done. Done. Done. I think the problm is even more subtle here: There is no mentions of error-prone-annotations annotation in Buck code. It's the guava that indirectly depends on it, and crashing when it's not provided. So it would need to be investigated. Anyway, changing:\ndiff --git a/.buckconfig b/.buckconfig\nindex b47016f..05da64d 100644\n--- a/.buckconfig\n+++ b/.buckconfig\n@@ -14,7 +14,7 @@\n     maven-importer = //src/com/facebook/buck/maven:resolver\n [autodeps]\n    include_signature = false\n-   java-package-mappings = com.google.caliper => //third-party/java/caliper:caliper\n+   java-package-mappings = com.google.caliper => //third-party/java/caliper:caliper,com.google.errorprone.annotations => //third-party/java/errorprone:error-prone-annotations\n [buildfile]\n     includes = //DEFS\n [log]\nand running buck autodeps havn't added eror-prone to autodeps.. The base version doesn't compile for me, after adding the EP 2.0.17 on the classpath,\neven without using the EP itself:\n```\n$ java -version\nopenjdk version \"1.8.0_121\"\nOpenJDK Runtime Environment (IcedTea 3.3.0) (suse-21.4-x86_64)\nOpenJDK 64-Bit Server VM (build 25.121-b13, mixed mode)\n$ buck build buck\n/home/davido/projects/davido_buck/src/com/facebook/buck/android/SmartDexingStep.java:207: error: incompatible types: null\n    List> callables = Lists.transform(dxSteps,\n                                                    ^\nErrors: 1. Warnings: 0.\nBUILD FAILED: //src/com/facebook/buck/android:steps failed with exit code 1:\njavac_jar\nstderr: /home/davido/projects/davido_buck/src/com/facebook/buck/android/SmartDexingStep.java:207: error: incompatible types: null\n    List> callables = Lists.transform(dxSteps,\n                                                    ^\nErrors: 1. Warnings: 0.\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83c\udfd6  (Watchman reported no changes)\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 1.3s [100%] (522/566 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\n```. Yes. This is a workaround for JVM bug.. Done. Done. Ah, tabs. M-x untabify.\nThanks, Done.. Same here, tabs, Done.. Indeed, Thanks a lot.. Done.. ",
    "BYVoid": "Here is the example written in the doc:\n``` python\nprebuilt_jar(\n  name = 'junit',\n  binary_jar = 'junit-4.8.2.jar',\n  source_jar = 'junit-4.8.2-sources.jar',\n  javadoc_url = 'http://kentbeck.github.com/junit/javadoc/4.8/',\n)\njava_library(\n  name = 'tests',\n  srcs = glob(['tests/*/Test.java']),\n  deps = [\n    ':junit',\n  ],\n)\n```\nYou probably would like to see http://facebook.github.io/buck/rule/prebuilt_jar.html\n. ",
    "mallikarjunece": "Hi @BYVoid ,\nI tried this already, i want to include the jar from my local system.\nHave you tried the same from local path.\nI tried and got the following error.\n$ buck targets\njava.lang.RuntimeException: Not an ordinary file: src/com/test/common/libs/httpmime-4.1.1.jar\n    at com.facebook.buck.parser.BuildRuleFactoryParams.resolveFilePathRelativeToBuildFileDirectory(BuildRuleFactoryParams.java:146)\n    at com.facebook.buck.java.PrebuiltJarBuildRuleFactory.amendBuilder(PrebuiltJarBuildRuleFactory.java:36)\n    at com.facebook.buck.java.PrebuiltJarBuildRuleFactory.amendBuilder(PrebuiltJarBuildRuleFactory.java:25)\n    at com.facebook.buck.parser.AbstractBuildRuleFactory.newInstance(AbstractBuildRuleFactory.java:87)\n    at com.facebook.buck.parser.AbstractBuildRuleFactory.newInstance(AbstractBuildRuleFactory.java:32)\n    at com.facebook.buck.parser.Parser.parseRawRulesInternal(Parser.java:427)\n    at com.facebook.buck.parser.Parser.filterAllTargetsInProject(Parser.java:518)\n    at com.facebook.buck.parser.PartialGraph.createPartialGraph(PartialGraph.java:73)\n    at com.facebook.buck.parser.PartialGraph.createFullGraph(PartialGraph.java:57)\n    at com.facebook.buck.cli.TargetsCommand.runCommandWithOptionsInternal(TargetsCommand.java:99)\n    at com.facebook.buck.cli.TargetsCommand.runCommandWithOptionsInternal(TargetsCommand.java:56)\n    at com.facebook.buck.cli.AbstractCommandRunner.runCommandWithOptions(AbstractCommandRunner.java:120)\n    at com.facebook.buck.cli.AbstractCommandRunner.runCommand(AbstractCommandRunner.java:95)\n    at com.facebook.buck.cli.Command.execute(Command.java:95)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:271)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:362)\n    at com.facebook.buck.cli.Main.main(Main.java:380)\nPlease let me know at the earliest.......\nThanks,\nMallikarjuna\n. ",
    "iainmerrick": "I'd like to see this too. The whole behavior of \"target\" is really mysterious -- why should libraries behave differently depending on whether they're built directly or via another rule? If there are different build variants, should there be some kind of pseudo-rule for selecting them?\n. The more I think about it, the more genfile() seems like a bad idea. The docs imply it's needed to disambiguate between source files and generated files with the same name. But it seems needlessly confusing to set your build up that way in the first place -- what's the upside?\nIf all source and generated filenames were required to be unique, the build system would always be able to locate both types of file, and the bug described above would be much easier to fix.\n. Cool! I was able to work around my issue with $(location), but it's pretty nasty, especially in a macro. It would be awesome if $(SRCS) just magically did the right thing.\n. ",
    "georgepapas": "Hi, \nSigned agreement,  branch is up to date.\nThanks\n. ",
    "DominikDary": "Just running ant in the bukc folder was not enough - but http://facebook.github.io/buck/concept/troubleshooting.html and then the rebuilding instructions fixed it.\nThanks\n. ",
    "saper": "Oh, boy, it's not that simple, gee....\n. ",
    "tfarina": "Nope. I don't use Eclipse. It is plain from terminal. I'm on Linux x86_64 (Ubuntu 12.04).\njava version says:\njava version \"1.7.0_25\"\nOpenJDK Runtime Environment (IcedTea 2.3.10) (7u25-2.3.10-1ubuntu0.12.04.2)\nOpenJDK 64-Bit Server VM (build 23.7-b01, mixed mode)\n. Nope. I don't use Eclipse. It is plain from terminal. I'm on Linux x86_64 (Ubuntu 12.04).\njava version says:\njava version \"1.7.0_25\"\nOpenJDK Runtime Environment (IcedTea 2.3.10) (7u25-2.3.10-1ubuntu0.12.04.2)\nOpenJDK 64-Bit Server VM (build 23.7-b01, mixed mode)\n. @bolinfest any idea? \n. @bolinfest any idea? \n. Yeah, I think the problem was with OpenJDK.\nI have followed the instructions of www.printandweb.ca/2013/04/manually-install-oracle-jdk-7-for.html to install the Oracle Java and by installing it I was able to run 'ant' and './bin/buck build buck' successfully again.\n$ java -version\njava version \"1.7.0_45\"\nJava(TM) SE Runtime Environment (build 1.7.0_45-b18)\nJava HotSpot(TM) 64-Bit Server VM (build 24.45-b08, mixed mode)\nClosing this.\nThanks!\n. Yeah, I think the problem was with OpenJDK.\nI have followed the instructions of www.printandweb.ca/2013/04/manually-install-oracle-jdk-7-for.html to install the Oracle Java and by installing it I was able to run 'ant' and './bin/buck build buck' successfully again.\n$ java -version\njava version \"1.7.0_45\"\nJava(TM) SE Runtime Environment (build 1.7.0_45-b18)\nJava HotSpot(TM) 64-Bit Server VM (build 24.45-b08, mixed mode)\nClosing this.\nThanks!\n. Here is the backtrace:\nFAILURE testQuickstartCreatesProject: \njava.lang.NullPointerException\n    at com.facebook.buck.cli.QuickstartIntegrationTest.testQuickstartCreatesProject(QuickstartIntegrationTest.java:61)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at com.facebook.buck.junit.BuckBlockJUnit4ClassRunner$SameThreadFailOnTimeout$1.call(BuckBlockJUnit4ClassRunner.java:165)\n    at com.facebook.buck.junit.BuckBlockJUnit4ClassRunner$SameThreadFailOnTimeout$1.call(BuckBlockJUnit4ClassRunner.java:161)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\n. No, I don't have it installed. I'll look into installing it and see if it fixes this problem.\n. $ cd\n$ wget http://dl.google.com/android/android-sdk_r20-linux.tgz\n$ extract android-sdk_r20-linux.tgz\n$ ls ~/android-sdk-linux/\nSDK Readme.txt  add-ons  build-tools  docs  extras  platform-tools  platforms  samples  sources  system-images  temp  tools\nThen at my buck checkout:\n~/src/repos/buck\nI created a file named local.properties with the following content:\nsdk.dir=/home/tfarina/android-sdk-linux\nI reran the buck command line:\n$ ./bin/buck test --all\n...\nFAIL CACHED  0 Passed   1 Failed   com.facebook.buck.cli.QuickstartIntegrationTest\nFAILURE testQuickstartCreatesProject: \njava.lang.NullPointerException\n    at com.facebook.buck.cli.QuickstartIntegrationTest.testQuickstartCreatesProject(QuickstartIntegrationTest.java:61)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at com.facebook.buck.junit.BuckBlockJUnit4ClassRunner$SameThreadFailOnTimeout$1.call(BuckBlockJUnit4ClassRunner.java:165)\n    at com.facebook.buck.junit.BuckBlockJUnit4ClassRunner$SameThreadFailOnTimeout$1.call(BuckBlockJUnit4ClassRunner.java:161)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\n....\nTESTS FAILED: 1 Failures\nFailed target: //test/com/facebook/buck/cli:cli\nFAIL com.facebook.buck.cli.QuickstartIntegrationTest\nMaybe I'm missing something?\n. Yup, so I did:\n$ export ANDROID_SDK=/home/tfarina/android-sdk-linux/\n$ export ANDROID_HOME=/home/tfarina/android-sdk-linux/\nThe test itself requires Google APIs 16.\nFAILURE testQuickstartCreatesProject: Google APIs not found in /home/tfarina/android-sdk-linux/add-ons/addon-google_apis-google-16/libs.\nPlease run '/home/tfarina/android-sdk-linux/tools/android sdk' and select both 'SDK Platform' and 'Google APIs' under Android (API 16)\ncom.facebook.buck.util.HumanReadableException: Google APIs not found in /home/tfarina/android-sdk-linux/add-ons/addon-google_apis-google-16/libs.\nPlease run '/home/tfarina/android-sdk-linux/tools/android sdk' and select both 'SDK Platform' and 'Google APIs' under Android (API 16)\nI have this:\n$ ls /home/tfarina/android-sdk-linux/add-ons/addon-google_apis-google-16/libs\neffects.jar  maps.jar  usb.jar\n. Now worked. Yay!\nSurprisingly the trailing slash ended up making a difference:\n$ export ANDROID_SDK=/home/tfarina/android-sdk-linux\n$ export ANDROID_HOME=/home/tfarina/android-sdk-linux\n$ buck clean &&  buck test --all\n...\nTESTS PASSED\n. ",
    "oconnor663": "I'm not able to repro this myself (Arch Linux x86_64). Does it still repro for you? We tend to use Oracle Java, so I'm curious if the problem you're seeing might be specific to OpenJDK. Here's my java -version:\njava version \"1.7.0_45\"\nJava(TM) SE Runtime Environment (build 1.7.0_45-b18)\nJava HotSpot(TM) 64-Bit Server VM (build 24.45-b08, mixed mode)\n. I'm not able to repro this myself (Arch Linux x86_64). Does it still repro for you? We tend to use Oracle Java, so I'm curious if the problem you're seeing might be specific to OpenJDK. Here's my java -version:\njava version \"1.7.0_45\"\nJava(TM) SE Runtime Environment (build 1.7.0_45-b18)\nJava HotSpot(TM) 64-Bit Server VM (build 24.45-b08, mixed mode)\n. @bolinfest Do you know if there's anything fundamentally incompatible between the open and closed JDKs, or should we try to be compatible with both? The Oracle JDK is not in the default package database for any Linux distro I know of, so it might be worth a little ongoing work to maintain compatibility with OpenJDK, at least in Buck itself.\n. @bolinfest Do you know if there's anything fundamentally incompatible between the open and closed JDKs, or should we try to be compatible with both? The Oracle JDK is not in the default package database for any Linux distro I know of, so it might be worth a little ongoing work to maintain compatibility with OpenJDK, at least in Buck itself.\n. This might be the wrong place for this discussion, but would it be a better abstraction if the java_library was allowed to declare its own packaging deps, so that every android_binary that included it didn't need to duplicate the same ndk_library dep or whatever?\n. This might be the wrong place for this discussion, but would it be a better abstraction if the java_library was allowed to declare its own packaging deps, so that every android_binary that included it didn't need to duplicate the same ndk_library dep or whatever?\n. I should be clear that I don't fully understand the context of this pull request. I was just thinking in the abstract :)\n. I should be clear that I don't fully understand the context of this pull request. I was just thinking in the abstract :)\n. There aren't any tools for doing that automatically. I think the simplest thing to do would be to run buck quickstart to create a new stub project, and then move over your existing Java files and resources into the structure that creates.\n. There aren't any tools for doing that automatically. I think the simplest thing to do would be to run buck quickstart to create a new stub project, and then move over your existing Java files and resources into the structure that creates.\n. We should definitely show a helpful error, though, instead of an NPE.\n. Seems like this was opened by mistake?\n. Hey, sorry for the radio silence on this one. We're in the process of pulling it, and we'll post an update here when that's done. Thanks for the code! (And for making it a described rule, that really helps.)\n. Hey, sorry for the radio silence on this one. We're in the process of pulling it, and we'll post an update here when that's done. Thanks for the code! (And for making it a described rule, that really helps.)\n. Thanks! I will merge this.\n. One workaround is to create a .nobuckcheck at the root of your project. That causes buck to ignore the .buckversion that you're specifying. That won't help you if the different versions of Gerrit require different versions of buck that are incompatible, but if your revisions aren't too far apart hopefully it'll be ok. We usually use this when we're developing in the buck repo and need to test our changes in other repos.\nhttp://facebook.github.io/buck/concept/nobuckcheck.html\n. Normally what happens when your .buckversion changes is that we checkout the appropriate revision and then rebuild buck using ant. So enabling the buck cache actually wouldn't help us there. Buck is indeed able to build itself (buck build buck), but bootstrapping with ant means we don't have to distribute binaries, and we don't need to keep our current build compatible with old versions.\n. As you point out, Buck caches build rules based on their inputs only. We need to do it that way in general, because for the cache to be useful you've got to compute a rule's cache key before you build that rule, and you can't do that if the key depends on the rule's output. I think if we made an exception for genrules with no inputs, that would get confusing pretty quickly. For example, if you wrote the new_date rule like that, and then later (after forgetting about this problem) you added some srcs for some reason, you would break your rule without any warning or explanation.\nAn explicit force or dont_cache_me_i_know_what_im_doing field would avoid that particular problem, but it's still getting into dangerous territory. Buck is built around the assumption that build rules are idempotent. Apart from slowing down the build, a flag like this would be an invitation for developers to create genrules with side effects, which leads to dependencies that Buck doesn't know about and then to inconsistent builds. We're really serious about repeatable builds.\nOther folks should chime in here, but I think the Right Thing to do in your situation is to have some shell script that runs date > somefile before it calls buck build, and to have a genrule that reads that file (edit: or as @bolinfest mentioned, an export_file rule). That puts all your non-idempotency up front and lets Buck keep its usual assumptions. If you check in a reasonable default for that file, you can even keep using Buck directly for your own local builds, without always invalidating your cache.\n. We supported Windows in the past (take a look at bin/buck.cmd), but that code has bitrotted for lack of users.\nbin/buck (the unix version) doesn't currently work in Cygwin either, in part because we're invoking Java with a bunch of parameters parameters (including -classpath) with unix-style-forward-slash paths. We could fix that with some cygpath -w[p] calls, and it might not be much work beyond that to get things up and running. Would buck+cygwin be useful to you?\n. It's the contents of the build-tools dir that's important. You need to make sure you have build tools 19.x.x. I bet if you look in there, you will only see 17 or 18. Running android and updating your SDK should fix this.\nYou can see us fixing the same issue in our travis build in https://github.com/facebook/buck/commit/1ba4496a782b40dec33a42e69a74837afee06177.\n. @natthu can you remind me what the underlying cause of this was? Was it something like a switch from Java 6 to Java 7 in our default build settings?\n. You may need to delete the android-4.3 directory in there. (Or move it to a safe place in case this doesn't work?) I remember @natthu mentioning that it might take priority over the others for some reason, possible a bug in Buck. Sorry for this wild goose chase.\n. Good, because I was totally out of ideas :) I'm going to leave this open until I fix the underlying issue, or at least understand it better. I think the fix @natthu is working on is actually #105, which is similar but not quite the same.\n. I agree that something like this is important for usability. \"You must run buck from the root of your project\" isn't by design, it's just that we haven't gotten around to it yet. It could probably be made to work with something like buck build :test, to avoid the ambiguity that @sdwilsh mentioned. We already allow filepath-ish calls like buck build java/src/foo/bar:test, which is nice for shell autocompletion, so it's not a very big leap from root-relative paths to cwd-relative paths. Mostly what we're missing at this point is an official way to determine the root of your project, the way git looks for the nearest .git directory. Probably we would use .buckconfig for this?\n. .buckversion is optional, but I think .buckconfig is always mandatory, even if it's empty. In the past I've thought about relaxing that requirement to allow building with just a BUCK file. But if we ever want to support the relative paths we're talking about in this issue, we might want to keep the requirement, to know where to put buck-out etc. (Unless we want a semi-magical rule like \"put it next to the closest .buckversion in the parent hierarchy, unless there is no such file, in which case put it in the current directory.\" That makes me uncomfortable...)\n. Thanks for the fix, and sorry for the delay. I will merge it when I do a push this week.\n. @saleeh93 no, I don't think it is. That said, a couple of the very latest commits (a6f52f3a0e9e9e823e756b2a57b91f3bb565ff4b and 23ade750ff7f89cfe7066b57c44b39c10d205e3a) have added some more progress indication to the UI.\n. Right now I don't think there's a way to customize the location of buck-out. Even if there were, it wouldn't be a good idea to share it between two different builds. The paths under buck-out are determined by target names, and different projects could use the same target name to refer to totally different things. Plus things like logs would get mixed together. And probably other terrible consequences that I haven't thought of. If you want to experiment, though, you can tweak the constants in src/com/facebook/buck/util/BuckConstant.java.\nThat said, sharing your cache dir is totally fine and actually encouraged. If what you want is to build two copies of the same project without duplicating work, this should do it for you. Take a look at the [cache] section in http://facebook.github.io/buck/concept/buckconfig.html. We support expanding ~ for your home dir as well, if you want to use that.\n. ",
    "thkoch2001": "Maybe it'd make sense to use the same wording as used in maven: \"provided\"?\nMaven documentation: Introduction to the Dependency Mechanism\nThank you for working on an alternative to maven!!!\n. ",
    "bootstraponline": "Awesome. Thanks!\n. @davido Do you know if there's a way to pull the jar with dependencies? It seems like I have to hard code the dependencies as they're not read in from the pom.\n. ",
    "ghost": "Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for reporting this issue and appreciate your patience. We've  notified the core team for an update on this issue. We're looking for a response within the next 30 days or the issue may be closed.\n. Thank you for your pull request.  As you may know, we require contributors to sign our Contributor License Agreement, and we don't seem to have you on file and listed as active anymore.  In order for us to review and merge your code, please email cla@fb.com with your details so we can update your status.\n. Thank you for your pull request.  As you may know, we require contributors to sign our Contributor License Agreement, and we don't seem to have you on file and listed as active anymore.  In order for us to review and merge your code, please email cla@fb.com with your details so we can update your status.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thank you for your pull request.  As you may know, we require contributors to sign our Contributor License Agreement, and we don't seem to have you on file and listed as active anymore.  In order for us to review and merge your code, please email cla@fb.com with your details so we can update your status.\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thank you for your pull request.  As you may know, we require contributors to sign our Contributor License Agreement, and we don't seem to have you on file and listed as active anymore.  In order for us to review and merge your code, please email cla@fb.com with your details so we can update your status.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @asp2insp to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @michath and @ryu2 to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @sam-swarr, @andrewjcg and @sdwilsh to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @jkeljo, @davido and @grumpyjames to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @scrawlings to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @mzlee, @beefon and @marcinkosiba to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @yschimke, @dcolascione and @bhamiltoncx to be potential reviewers.\n. @Dominator008 updated the pull request.\n. @Dominator008 updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @marcinkosiba and @bhamiltoncx to be potential reviewers.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @mikekap updated the pull request.\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @kageiit updated the pull request.\n. By analyzing the blame information on this pull request, we identified @jkeljo, @andrewjcg and @Coneko to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @jkeljo, @andrewjcg and @Coneko to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @bhamiltoncx and @k21 to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @bhamiltoncx and @k21 to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. @zecke updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. By analyzing the blame information on this pull request, we identified @beefon, @andrewjcg and @bhamiltoncx to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @dreiss, @yiding and @andrewjcg to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @kageiit updated the pull request.\n. By analyzing the blame information on this pull request, we identified @asp2insp, @michath and @k21 to be potential reviewers.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request.\n. By analyzing the blame information on this pull request, we identified @ruibm, @sdwilsh and @andrewjcg to be potential reviewers.\n. @yschimke updated the pull request.\n. @yschimke updated the pull request.\n. By analyzing the blame information on this pull request, we identified @yiding, @ryu2 and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @k21 to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @mikekap to be a potential reviewer.\n. @Coneko updated the pull request.\n. @Coneko updated the pull request.\n. @Coneko updated the pull request.\n. @Coneko updated the pull request.\n. @Coneko updated the pull request.\n. @Coneko updated the pull request.\n. @Coneko updated the pull request.\n. By analyzing the blame information on this pull request, we identified @sam-swarr, @ryu2 and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @sam-swarr, @ryu2 and @andrewjcg to be potential reviewers.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. @mikekap updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @yiding, @ryu2 and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @yiding, @ryu2 and @andrewjcg to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. @robbertvanginkel updated the pull request.\n. By analyzing the blame information on this pull request, we identified @styurin to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @styurin to be a potential reviewer.\n. By analyzing the blame information on this pull request, we identified @Coneko, @beefon and @ryu2 to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @alsutton, @yiding and @Coneko to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @mikekap, @inglorion and @ryu2 to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @russellporter, @andrewjcg and @dreiss to be potential reviewers.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @Coneko to be a potential reviewer.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. @robbertvanginkel updated the pull request.\n. @robbertvanginkel updated the pull request.\n. @robbertvanginkel updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review.\n. By analyzing the blame information on this pull request, we identified @ryu2, @sdwilsh and @k21 to be potential reviewers.\n. @rmaz updated the pull request.\n. @rmaz updated the pull request.\n. By analyzing the blame information on this pull request, we identified @beefon, @yiding and @ruibm to be potential reviewers.\n. @dsyang updated the pull request.\n. @dsyang updated the pull request.\n. @dsyang updated the pull request - view changes\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. @dsyang updated the pull request - view changes - changes since last import\n. @dsyang updated the pull request - view changes - changes since last import\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @yiding to be a potential reviewer.\n. @tonycosentini updated the pull request.\n. @tonycosentini updated the pull request.\n. @tonycosentini updated the pull request.\n. @tonycosentini updated the pull request.\n. @tonycosentini updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review internal test results.\n. Thanks for importing. If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @jernejstrasner, @Coneko and @ryu2 to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @Coneko, @beefon and @yiding to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @Coneko, @beefon and @yiding to be potential reviewers.\n. @robbertvanginkel updated the pull request.\n. @robbertvanginkel updated the pull request.\n. Thanks for importing. If you are an FB employee go to Phabricator to review internal test results.\n. Thanks for importing. If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @dreiss to be a potential reviewer.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request - view changes - changes since last import\n. @kageiit updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @ryu2, @yiding and @bhamiltoncx to be potential reviewers.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. @nguyentruongtho updated the pull request.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @alsutton, @ilya-klyuchnikov and @andrewjcg to be potential reviewers.\n. @kageiit updated the pull request.\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. By analyzing the blame information on this pull request, we identified @Coneko, @tonycosentini and @mikekap to be potential reviewers.\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. @robbertvanginkel updated the pull request.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @ryu2 and @LegNeato to be potential reviewers.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @andrewjcg, @ryu2 and @LegNeato to be potential reviewers.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @yiding, @andrewjcg and @bhamiltoncx to be potential reviewers.\n. @kageiit updated the pull request - view changes\n. @kageiit updated the pull request - view changes\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @aiked, @k21 and @ryu2 to be potential reviewers.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. @shs96c updated the pull request - view changes - changes since last import\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. By analyzing the blame information on this pull request, we identified @bolinfest, @keelerh and @aiked to be potential reviewers.\n. Thanks for importing.If you are an FB employee go to Phabricator to review internal test results.\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. By analyzing the blame information on this pull request, we identified @michsien, @ruibm and @marcinkosiba to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @ryu2, @andrewjcg and @Coneko to be potential reviewers.\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @mikekap, @aiked and @yiding to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @ryu2, @Coneko and @yiding to be potential reviewers.\n. @nguyentruongtho updated the pull request - view changes\n. By analyzing the blame information on this pull request, we identified @yiding, @yschimke and @dcolascione to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @sdwilsh, @aiked and @yiding to be potential reviewers.\n. @shs96c updated the pull request - view changes\n. @shs96c updated the pull request - view changes\n. @shs96c updated the pull request - view changes\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. @shatlykuber updated the pull request - view changes\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. @shatlykuber updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @k21, @jernejstrasner and @kangzhang to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @k21, @jernejstrasner and @kangzhang to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @alisdair04 to be a potential reviewer.\n. @shs96c updated the pull request - view changes - changes since last import\n. Thank you for signing our Contributor License Agreement. We can now accept your code for this (and any) Facebook open source project. Thanks!\n. By analyzing the blame information on this pull request, we identified @mikekap and @andrewjcg to be potential reviewers.\n. @nguyentruongtho updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. @nguyentruongtho updated the pull request - view changes - changes since last import\n. By analyzing the blame information on this pull request, we identified @Coneko, @yiding and @ryu2 to be potential reviewers.\n. @nguyentruongtho updated the pull request - view changes\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @asp2insp, @dreiss and @andrewjcg to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @Coneko, @jernejstrasner and @ryu2 to be potential reviewers.\n. Thanks for importing. If you are a Facebook employee, you can view this diff on Phabricator.\n. By analyzing the blame information on this pull request, we identified @beefon, @yiding and @ryu2 to be potential reviewers.\n. By analyzing the blame information on this pull request, we identified @ryu2, @k21 and @beefon to be potential reviewers.\n. Thank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla - and if you have received this in error or have any questions, please drop us a line at cla@fb.com. Thanks!\n. By analyzing the blame information on this pull request, we identified @ryu2, @Coneko and @yiding to be potential reviewers.\n. Seconding @kageiit. Several developers on our side have separately seen this issue. Changes to test code are sometimes not reflected in the APKs that are built. We need to rm -rf buck-out in order to clear the cache and rebuild.. ",
    "ashu-22": "Is it necessary that we are only used the Eclipse for this kind o project!. Sir these are the errors I have got yesterday When I was trying to run that command there.\nIt is quite amazed me that I have not looked anything outside this error's.. ",
    "styurin": "We are not using Eclipse internally so the team is not going to work on that. We would be happy to review any PRs for that, but we would prefer to have a standalone script which is not a part of buck binary.. We are not using Eclipse internally so the team is not going to work on that. We would be happy to review any PRs for that, but we would prefer to have a standalone script which is not a part of buck binary.. It was implemented some time ago, check android_resource documentation: https://buckbuild.com/rule/android_resource.html. No one is working on it and we have an internal implementation that is based on code gen, so it's unlikely that we are going to add it to buck any time soon.. @rowillia this PR is pretty old. Please, rebase and resubmit it if you want to merge these changes in.. @rowillia this PR is pretty old. Please, rebase and resubmit it if you want to merge these changes in.. > If you have a genrule that creates a directory with several files, it's a bit of a pain to write another genrule rule for each (expected) output, just to be able to pass it to *_library (java, python, etc).\nYou can write a genrule that creates a zip file and pass it as an input in srcs: https://buckbuild.com/rule/java_library.html#srcs. Most of this code was removed. project_config is long dead. @andrewjcg Do we want to merge this in?. @andrewjcg Do we want to merge this in?. This was implemented in 3dddf893259dae0e4a492d29f4c5ecb575d96810. a271a23a24a63e88decba55e176d623717628719. quickstart was removed. @Piasy upstream means AOSP: https://android.googlesource.com/platform/sdk/+/a35f8af/manifmerger/src/com/android/manifmerger/ManifestMerger.java\nWe don't want to introduce fixes that change logic in code that is taken from other libraries. The main concern here is maintenance cost of such changes in cases when we need to update our copy of this library with a new version from upstream.\n. Thanks, let us know what you find, we may only need to update ManifestMerger from upstream.\n. Fixed in 3d611c94df024796d7aa0d7785b663006f9a604d. That was recently implemented, check .buckconfig docs: https://buckbuild.com/concept/buckconfig.html#intellij.\n. This is already implemented, can you check existing functionality and see if we are missing something?\n. > \nThis option in iml tells IntelliJ where to keep files generated inside IntelliJ.\n\nLooks like this can be disabled by unchecking Generate sources automatically in the Project Structure > Project Settings > Facets dialog and removing the files manually.\n\nThis folder still can be created if sources are generated manually.\n\nStill ideally this should be disabled when running buck project\n\nThis can be disabled by adding the following section to .buckconfig:\n[project]\n  disable_r_java_idea_generator = true\nWe should document this option in our docs though.\n. Do you still have this problem? Have you tried ant clean?. Please, address comment about BuckToGeneralTestEventsConverter constructor. Also, could you update plugin.xml with a brief description of this feature. You can put it under version 2.7.3 since it's not released yet.\n. I still see the old commit, did you push your rebased commit?\n. Not sure this would work correctly with the current logic in DefaultParser, it depends on the order of TargetNodeSpecs.. Thanks!. Fixed in 6bc1888f83660f2f8f7e81e895803891090faa79. @justinmuller is that possible to write a unit test for this situation?. Some things have probably changed since this PR was created. Do we still need it?. First of all, prebuilt_jar works as you described, the library xml contains a reference to a jar in repo, not in buck-out.\nprebuilt_aar needs to be built because IntelliJ doesn't support aar files (or I am not aware of the way to set it up in libraries / modules).\n. You can do that without introducing new functionality in buck project, just find prebuilt_aar targets in dependencies of the target and build them.. > Can IjProject not just generate the right project files based on the target type?\nI'm not sure I understand the question, but this issue doesn't affect how buck project works for IntelliJ. It only makes the choice of IDE explicit and removes the autodetection.. You should use ANT_OPTS like this:\nANT_OPTS=-Xmx512m ant. Thanks for reporting the issue!. > I think the icons are a lot more discoverable :)\nWhy not both? I'm not asking to remove icons from line markers, just add context actions the same way as the default test runner does.. you need to run ant lint. you need to run ant lint. Please reopen if you still have this problem.. Created https://github.com/fbsamples/bucksamples/pull/4 to remove these targets.. Fixed in 40fb511f5b3e27027175497940f3fda687fb30b4. Hey, here's the section from Getting Started guide:\n\nBefore building make sure you installed correct build tools and a target in Android SDK and correct version of Android NDK. You can find the required versions of these tools in .buckconfig:\nndk.ndk_version points to the version of Android NDK.\n\nYou need to check the version of ndk in the config and install the correct version.\nndk_version option in buck config (https://buckbuild.com/concept/buckconfig.html#ndk.ndk_version):\n\nThe version of the NDK that Buck should use to build native code. This is searched for in the subfolders defined by the folder found in the ANDROID_NDK_REPOSITORY environment variable.\n\nYou need to change ANDROID_NDK_REPOSITORY to point to a folder with ndks and then put the specific NDK into a subfolder. For example, if ANDROID_NDK_REPOSITORY points to /tmp/, Android NDK should be in /tmp/android-ndk-r10e.. Are you using the latest buck version? This was fixed in https://github.com/facebook/buck/issues/1176.. This is because NDK versions are stored differently depending on the version: https://github.com/facebook/buck/blob/93e2aafe9c8031f2b086a589e53bbc068dcf0bf1/src/com/facebook/buck/android/DefaultAndroidDirectoryResolver.java#L43-L46\nI'll update the docs.. updated docs in 6640d076ab97c4b1e4a906b6e2dca9ca7d7f2e35. Looks like it's working, do you want to merge it?. Answered in another issue, we don't have plans to support that.. Answered in another issue, we don't have plans to support that.. You need to reformat java files using google-java-format.. Please, reformat files with google-java-format: https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style. Please, reformat files with google-java-format: https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style. Please, add integration tests. I thought it would be faster for us if I show you my suggestions in code, here it is: https://github.com/styurin/buck/commit/c5c84de4e66275ea9a9b3f0d6d1c49d92744b0aa. Sorry for the delay. I was trying this fix and it seems it doesn't handle some situations, for example, where there is no resources_root. Here's my test: https://github.com/styurin/buck/commit/4f300dc3623327156f07f271e70a9d2eaf9febdc. Sorry for the delay. I was trying this fix and it seems it doesn't handle some situations, for example, where there is no resources_root. Here's my test: https://github.com/styurin/buck/commit/4f300dc3623327156f07f271e70a9d2eaf9febdc. Also, could update the description? This PR doesn't add support for creating configurations from current file, right?. Also, could update the description? This PR doesn't add support for creating configurations from current file, right?. By the way, travis is failing because of your change, you need to run ant lint. By the way, travis is failing because of your change, you need to run ant lint. Can you please rebase and format Java files using google-java-format? See https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style for instructions. 1. You need to update the title, it's not only java_test\n\nI was testing this locally and noticed that when a cursor is in a method name, Buck tab shows up every time there is an updated even if I opened a different tab. Also, I noticed that right-mouse clicking has a very long and noticeable delay (in order of 2-3 seconds). It's probably calling buck query when it's not needed. I don't notice such a delay when I use line actions.. Can you add more information about variant? What is it?. Can you add more information about variant? What is it?. Could you add a test with non-default variant?. why do you need this?. why do you need this?. I think you need to provide more information about what your are trying to do. What do you mean by plugin?. Plugin was updated: https://plugins.jetbrains.com/plugin/7826-buck-for-idea. Please, re-format java files using google-java-format: https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style. Could you rebase this PR on the latest stable, there were some backward-incompatible changes in our CI and builds are failing on old commits.. > this re-enables the extra \"Design\" tab when editing Android Layout XML files. as of IntelliJ 2017.2, XML layouts won't display the tab without this change. screenshots added to the description\n\nDo you use aggregation of modules with Android resources (option intellij.aggregate_android_resource_modules in .buckconfig)? This is the only reason I can think of why IntelliJ isn't showing that tab.\nIf you don't use this option, can you provide a sample project where this tab isn't shown?\n. @mkillianey can you please comment if we are ready to bump the minimum version for buck plugin to 2017.2?\n\ncan you please clarify the android.jar via ideabuck.iml comment?\n\nWhen building and testing plugin inside IntelliJ (using IntelliJ build-in functionality, not buck build), the plugin jar contains stripped version of android.jar and, since the content of the stripped jar is not working, the plugin is not working. If dependency type on android.jar is \"provided\" then android.jar is not included in the plugin jar and the plugin is using classes provided by InteliiJ.\n. Also, re-format files using google-java-format. > are developers intended to build/test/run code through IntelliJ, or should they be only using the Buck plugin?\nIt depends on your project complexity. Simple projects can be built using IntelliJ, but IntelliJ model is less flexible and it doesn't allow certain configurations (like when two targets are present in one directory). In such cases a project generated by buck project wouldn't be compileable by IntelliJ and the only way to build it is to use ideabuck plugin.\n\"new project generation\" still tries to convert buck dependency graph into a form that be understood by IntelliJ. Since IntelliJ has restrictions, the conversion cannot be exact. . Please, provide more details.. So you got this error when you run cd buck? Did you run git clone before that? How did you create that folder?. Could you add a stand-alone test to demonstrate the changes instead of modifying a test responsible for aggregation?. Buck has hard-coded logic to detect NDK version. We are working on a generic approach to allow toolchain configuration to live in the target graph.\nShort term solution would be extend parsing logic to support v16.. @kageiit Do you use buck project --view?. Here's the reason: https://github.com/facebook/buck/blob/07baa0198425c75af5b76ef841704dad9ed517c3/src/com/facebook/buck/jvm/groovy/DefaultGroovyLibraryBuilder.java#L43\nYou can try to fix it yourself with adding some tests :). Thanks for fixing, could you reformat the files, please?. Sorry for long delay.\nIn your example, could you also add information about which targets do you have, where and their type?. Oh, it was earlier in the post, my apologizes.\n\nIntelliJ then fails to compile the \"source\" file FooTest.java because it can't see the inner class of the \"test\" file FooBarTest.java.\n\nDo you have this problems when you try to build code in IntelliJ? Most developers at Facebook do not build code using IntelliJ native Java compilation. We either use buck in the command line or invoke Buck build using IntellIJ Buck plugin. Given that, majority of our developers do not have this problem.\nWe also do not aim to provide the capability to build Buck project using IntelliJ native builder and the main reason is that IntelliJ module model is based on directories while Buck model uses files as a minimal entity in inputs of a target. This means that fundamentally Buck dependency graph cannot be represented in IntelliJ and therefore built properly.\nWe've done some work to integrate Buck functionality into IntelliJ UI via Buck plugin, but it only provides basic capabilities like syntax highlight and building/testing targets.\n\nShould I not have any test_utils?\n\nIt's up to you, but we use test utils targets to separate test code and test utilities.\n\nShould we generally not have multiple targets containing files from the same directories / packages?\n\nThe general motivation behind this behavior is to mark production sources properly when prod and test targets are in the same directory.\nTo solve you case we can add an option to .buckconfig to control this behavior.\nIs this structure consistent across the whole repository? In other words, do you have places where you need different behavior or what you described is what you want to be applied to the whole project?. > What code is picking the project roots (ModuleBuildContext::addSourceFolder?)\nI'm not sure what you mean by picking project roots, but I think you're right about the place where the changes should happen. addSourceFolder calls mergePromotingToSourceIfDifferent and that's the place where folders are merged into a SourceFolder so you'll need to change that method.. not yet, let me follow up with the person who wanted to make that change. The person  who made a diff is on vacation right now. I'll try to push the change, but no guarantees at this point. In worse case we would have to wait around a week or so for him to return.. The main reason is that this project has internal tests which are not exposed to public and we rely on them to verify the correctness.. One of the issues in including javac-plugin.jar. I have a fix for that. This should solve the problem of using java compilers with different minor versions.\nI also plan to add a way to use the old behavior, probably without using the old logic when we collected all local changes to calculate the Buck version.. We actually use Eclipse compiler that is in the repository.. I tried to reproduce the problem with KotlinLibraryBuilder.class using the same JDKs, but was unable to do that. In my case these files were identical.\nAfter looking at the class files I found that local class has corrupted LineNumberTable in it. Since we build code using Eclipse compiler I suspect there might be some bug in it.\n@kageiit Could you double check that you still see a problem with this file, please?. I tried to reproduce the problem with KotlinLibraryBuilder.class using the same JDKs, but was unable to do that. In my case these files were identical.\nAfter looking at the class files I found that local class has corrupted LineNumberTable in it. Since we build code using Eclipse compiler I suspect there might be some bug in it.\n@kageiit Could you double check that you still see a problem with this file, please?. I'm going to put some changes to revert this logic and have a configuration option to control this behavior.. Committed 80e39a9f0952d3f960ce239779640063967bf826. It seems like this problem is specific to one project only and we don't really want to support cases like this.\nAs to your problem, you can rename all BUCK files to something else thought it might be too disruptive to do.\nMy recommendation is to pay one time cost of moving ./buck to something else rather dealing with workarounds. The more time use spend with that the more problems you'll have later.\n\nget the file to be syntactically correct in both bash and python.\n\nWe are moving to Skylark soon and it can break with that migration.. It seems like this problem is specific to one project only and we don't really want to support cases like this.\nAs to your problem, you can rename all BUCK files to something else thought it might be too disruptive to do.\nMy recommendation is to pay one time cost of moving ./buck to something else rather dealing with workarounds. The more time use spend with that the more problems you'll have later.\n\nget the file to be syntactically correct in both bash and python.\n\nWe are moving to Skylark soon and it can break with that migration.. 14f7eb4cc927eea4ab861b3bb88b52037149f783 adds an ability to change this behavior for the whole project or by target.. The diff was reverted because there is a bug in the procedure that creates symlinks. When multiple targets in the same package create files with the same name Buck creates one symlink. The current issue is on hold till I fix that bug.. Check this PR: https://github.com/facebook/buck/pull/1417\nbuck project doesn't have a good support for Kotlin files. To properly understand package information from Kotlink files we need to add parsing to buck project in the same way we do for Java files.. Removed in ab056c1e1d23bc24153e59866bdb947d4afbedb7. Removed in ab056c1e1d23bc24153e59866bdb947d4afbedb7. Have you thought about using an external runner for that? Check this config section to learn how to configure a test runner: https://buckbuild.com/concept/buckconfig.html#test.external_runner. Different projects have different strategies around flaky tests and don't want to force one way or another. An ability to use external testrunner looks ideal for such functionality and this is what we do internally. I don't think we are going to do any changes here.\nWhat would be useful for community is to create a test runner outside of buck repository which can be configured however you want.. We use an approach where a test runner controls which tests needs to be executed and skipped and how many times they need to be retried.\nAnother approach is to ask buck to run tests and then analyze test results to detect if some failures needs to be skipped, etc. In this approach adding re-trying logic to Buck seems reasonable.\nSince we don't use the second approach, we aren't going to do any improvements here. If you want to add support for that, we'd like to get better understanding of what you want to add and how that would affect test reporting.. We use an approach where a test runner controls which tests needs to be executed and skipped and how many times they need to be retried.\nAnother approach is to ask buck to run tests and then analyze test results to detect if some failures needs to be skipped, etc. In this approach adding re-trying logic to Buck seems reasonable.\nSince we don't use the second approach, we aren't going to do any improvements here. If you want to add support for that, we'd like to get better understanding of what you want to add and how that would affect test reporting.. ec3aee5f6d69ca4c50847de46b49dd2cfdef489e moved a module with zip rules into a stand-alone module.. > The original plans for extensions included allow each cell to define its own extensions.\nYeah, it's possible, but it's not on a plan right now. I'll take a look at lazy / per-cell loading of modules after the implementation in a better state.. > The original plans for extensions included allow each cell to define its own extensions.\nYeah, it's possible, but it's not on a plan right now. I'll take a look at lazy / per-cell loading of modules after the implementation in a better state.. > Can we make it possible to load custom modules via a plugin framework without needing to hack the bootclasspath of buck?\nIt's not a priority right now, but I see no reason why we can't do that. I'd wait for APIs to stabilize before doing that though, otherwise it'll be difficult to maintain.\n\nAnother question is if the hash of the cxx module changes, does that mean that java rules will be unaffected upon updating buck?\n\nIf java rules do not depend on cxx than yes, updating cxx rules will not affect java. Right now java rules depend on cxx, not sure if we can refactor them to remove this dependency. There are very few rules that do not depend on cxx so this is not the best example. For instance, changing Android code should not affect Java rules.\n\nIs there a public, stable API that I can use for my plugins?\n\nNot yet, this a step towards extracting core API for rules and decoupling non-related rules. There might be other injection points not related to rules and I think we can discuss adding them to solve your use cases.\n\nCan I redefine existing rules?\n\nThe way how it's implemented right now no, and I think we'd better keep it that way. I think a better approach here is to enhance existing rules using build defs and SkyLark.\n\nHow do I refer to functionality in other plugins from my own? For example, if I want to use the FIleBundler from the zip rules, how is this done?\n\nI'm working on adding support for dependencies between modules so you'll have to explicitly declare that your module depends on a module with zip rules.\n\nCan extensions be built and loaded as part of a single build?\n\nCould you explain this scenario, please?\n. > Can we make it possible to load custom modules via a plugin framework without needing to hack the bootclasspath of buck?\nIt's not a priority right now, but I see no reason why we can't do that. I'd wait for APIs to stabilize before doing that though, otherwise it'll be difficult to maintain.\n\nAnother question is if the hash of the cxx module changes, does that mean that java rules will be unaffected upon updating buck?\n\nIf java rules do not depend on cxx than yes, updating cxx rules will not affect java. Right now java rules depend on cxx, not sure if we can refactor them to remove this dependency. There are very few rules that do not depend on cxx so this is not the best example. For instance, changing Android code should not affect Java rules.\n\nIs there a public, stable API that I can use for my plugins?\n\nNot yet, this a step towards extracting core API for rules and decoupling non-related rules. There might be other injection points not related to rules and I think we can discuss adding them to solve your use cases.\n\nCan I redefine existing rules?\n\nThe way how it's implemented right now no, and I think we'd better keep it that way. I think a better approach here is to enhance existing rules using build defs and SkyLark.\n\nHow do I refer to functionality in other plugins from my own? For example, if I want to use the FIleBundler from the zip rules, how is this done?\n\nI'm working on adding support for dependencies between modules so you'll have to explicitly declare that your module depends on a module with zip rules.\n\nCan extensions be built and loaded as part of a single build?\n\nCould you explain this scenario, please?\n. @shs96c I just added an ability to use dependent modules (see 49cb16e9caa76830a66e30842a4204906fab7e93 for an example). You can also use DescriptionProvider to register new build rule types without touching KnownBuildRuleTypes. Note that at this point we cannot guarantee the stability of the API, it can be changed in future.\n\nSomething like this in the BUCK file would be splendid:\n\nWhat stops you right now to write custom build rules using Skylark?. > In addition, I need this to work on Windows, Linux, and OS X, which makes using genrules a Really Bad Idea.\nPython can give you system-independent functionality :)\nWhat exactly do you do with zip files? Should Buck support that?. > some of my Description instances need access to the BuckConfig.\nThis should be easy to add access to config. I'm going to migrate some descriptions that require BuckConfig so there should be support for that soon.\n\nAlso, it'd be nice if there was a PluginManager per Cell rather than globally....\n\nDo you mean loading external plugins per cell configuration? This means adding a way to load external plugins and we don't have plans to do that though I don't see a reason why we shouldn't do that if you want to add support for that.. @shs96c 2988b70363ef2ae556f37ab244e05c4baf35bce7 added an ability to access BuckConfig when creating descriptions.. The solution here is to use a genrule to place files in locations you need them to be. You can also use filegroup which should place these two files together.. export_file is going to be replaced by filegroup. The output of filegroup is placed in a directory so it wouldn't work for you. The solution is to use a genrule with output set to logback.xml, that genrule would copy the file from the original location.. @rmaz what kind of functionality do you want to remove?. It's possible to disable some modules right now though I don't know how much of a win you would get from that. I started moving some features to modules, but it's mostly some languages that do not add a lot to the binary size.\nHere's the list of modules: https://github.com/facebook/buck/blob/master/programs/BUCK#L87-L96 You can remove some of these modules if you don't use them and see how big is the difference.. It doesn't build. Please, submit working code :). It doesn't build. Please, submit working code :). cc @bolinfest . cc @bolinfest . Fixed in 4d08337821fa9b6dfadfb11d593fb2633e2df179. Fixed in 4d08337821fa9b6dfadfb11d593fb2633e2df179. > In general, is there a \"better\" way to structure integration test data to not need to duplicate these jars, especially the huge scala ones?\nI added buck cell with libraries used in testing exactly for that reason - to avoid duplication of libraries. We also have different versions of the same library and in most tests we can use a single version only so we should be able to remove duplicate libraries.\n\nCan we always refer to the buck//third-party jars?\n\nIn tests, yes.\n\nare there downsides to that?\n\nIt can be a little bit tricky if your library depends on other libraries mostly because buck in the main repository doesn't treat those dependencies differently. For example, if your library references //third-party/java/hamcrest:java-hamcrest it should exist in both the main repo and the test cell.. > In general, is there a \"better\" way to structure integration test data to not need to duplicate these jars, especially the huge scala ones?\nI added buck cell with libraries used in testing exactly for that reason - to avoid duplication of libraries. We also have different versions of the same library and in most tests we can use a single version only so we should be able to remove duplicate libraries.\n\nCan we always refer to the buck//third-party jars?\n\nIn tests, yes.\n\nare there downsides to that?\n\nIt can be a little bit tricky if your library depends on other libraries mostly because buck in the main repository doesn't treat those dependencies differently. For example, if your library references //third-party/java/hamcrest:java-hamcrest it should exist in both the main repo and the test cell.. 94f9d5c2ef61859584075e6fa5eaa8d0d10df905. 94f9d5c2ef61859584075e6fa5eaa8d0d10df905. Why skipped tests need to marked as failed?. Why skipped tests need to marked as failed?. Please, split changes into small independent modifications so that it's easier to understand what you are trying to do. This would speed up the review process.. Is that still relevant?. @epkugelmass have you tried to build Java 9 code with buck using out of the process compilation?. Try to update java to the latest 8 version, 31 is quite old.. Yeah, we haven't migrated to Java 9, please, use the latest java 8.. I think this is happening because buck tries to find all cxx platforms in all toolchains (which means it tries to discover Android and Apple toolchains).\n\nandroid-9 is no longer available as a platform\n\nCould you explain why it's not available? I can see android-9 in my NDK installation.. I was looking at ndk 15. This change should be ok. @Bill you need to sign CLA:\n\nThank you for your pull request and welcome to our community. We require contributors to sign our Contributor License Agreement, and we don't seem to have you on file. In order for us to review and merge your code, please sign up at https://code.facebook.com/cla. If you are contributing on behalf of someone else (eg your employer), the individual CLA may not be sufficient and your employer may need the corporate CLA signed.\n. @carljparker can you take a look, please?. We have the same problem in Buck where we add git information to the package. The problem with having this logic as part of Buck build is that we cannot express the state of the repository in the target graph. It seems that having this logic outside of a target graph is a better approach.. Looks like we don't test rust at all. Tests are not working at all.. Could you provide a description with an explanation?. Could you provide a description with an explanation?. Tests are still broken. Could you provide more details about your problem including IntelliJ version and what kind of issues you are having?\n\nI'm not really convinced that this is a right solution. The purpose of autogenerate_sources is to instruct IntelliJ to automatically generate R.java and other generated files vs. generate them manually. When these files are generated manually the folder with generated files should still be included as a content root. . Could you provide more details about your problem including IntelliJ version and what kind of issues you are having?\nI'm not really convinced that this is a right solution. The purpose of autogenerate_sources is to instruct IntelliJ to automatically generate R.java and other generated files vs. generate them manually. When these files are generated manually the folder with generated files should still be included as a content root. . I'm going to close this PR for now. Please, re-open when needed.. I'm going to close this PR for now. Please, re-open when needed.. Could you split these changes into individual PRs? This way we can revert specific commits if something is broken. Also, we can separate discussion about some of these changes without blocking other changes.. Could you split these changes into individual PRs? This way we can revert specific commits if something is broken. Also, we can separate discussion about some of these changes without blocking other changes.. There are some problems with formatting. Could you reformat the files? See https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style to find out how to do it.. There are some problems with formatting. Could you reformat the files? See https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style to find out how to do it.. Nope, it should be merged in later today. Nope, it should be merged in later today. could you reformat the source code?. could you reformat the source code?. Could reformat source using google-java-format? Here are the instructions: https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style. You can use UnzipStep to unzip an archive.. You can use UnzipStep to unzip an archive.. Fixed in 5eeab6d869057b37c958052fe6952f67ef3b2aad. Fixed in 5eeab6d869057b37c958052fe6952f67ef3b2aad. Could you explain why srcs=['.'] is preferred to using glob([\"*.go\"], exclude=[\"*_test.go\"]) and glob([\"*.go\"])?. I don't know why go rules support specifying directories as inputs, but this is definitely not a recommended way to declare inputs. Unless there is a good reason we shouldn't support that at all. Other rules use globs and we have no plans to specify directories as inputs.. > This branch has conflicts that must be resolved\nPlease, rebase these changes. > This branch has conflicts that must be resolved\nPlease, rebase these changes. I'm going to update this PR with a bit more logic that verifies that configuration makes sense with the current NDK version and adding some tests.. I'm going to update this PR with a bit more logic that verifies that configuration makes sense with the current NDK version and adding some tests.. Fixed in 6ac033ed30865239fecea4a8d06b4a87766f8a67. I got some windows-related failures in out production CI and didn't have time to take a closer look. I'll try to take a look next week.. Still investigating, I hope we'll find the root cause later this week. It looks like it's failing because of 505511d41647a04be21bbec00c8dc22fe87628c2. I'll follow up with the author of that commit. . https://github.com/brettwooldridge/NuProcess/commit/505511d41647a04be21bbec00c8dc22fe87628c2. @ilya-klyuchnikov . Yeah, but PR still doesn't contain that change for some reason.. Yeah, but PR still doesn't contain that change for some reason.. We're getting closer, I expect this to be merged sometime later this week.. Could you update the description and put the reason why you need this change first and then list the changes. Right now it's not clear what the phrase that starts with \"This is needed to prevent framework resources\" is related to.. Looks like we have some miscommunication here.\n\nConvert integer entries to hex decimal entries during RDotTxtEntry initialization\n\nWhy do we need this change at all?\nCould you use the following format in the description:\nState the problem. Describe the root cause. Describe the solution and provide any details about implementation which are not clear from the source code and which would help with the review.\nNo need to include source code in the description.. Looks like we have some miscommunication here.\n\nConvert integer entries to hex decimal entries during RDotTxtEntry initialization\n\nWhy do we need this change at all?\nCould you use the following format in the description:\nState the problem. Describe the root cause. Describe the solution and provide any details about implementation which are not clear from the source code and which would help with the review.\nNo need to include source code in the description.. thanks a lot! It's much better now. Do you mind adding integration tests for robolectric_test?. Cannot reproduce, it shows an error about SDK:\nBUILD FAILED: Android SDK could not be found. Make sure to set one of these environment variables: ANDROID_SDK, ANDROID_HOME, or android.sdk_path in your .buckconfig\nWe did a few changes around that logic and it probably fixed the problem.. e1dd89b810b91a727041a9d32ff9fdae3df59ef9 marked export_file as deprecated. It's recommended to use filegroup instead (added in 984e7903212c23d703f3dd2fa6a0c6f8543304de).. Try Python 2.7?. Try Python 2.7?. Fixed in 4ba983ea268d37a301123b6b8ad6e20f843d1aef. Can you run other java applications? Looks like something's wrong with JDK/JRE.. Can you run other java applications? Looks like something's wrong with JDK/JRE.. Have you tried to google \"/lib64/libc.so.6: version GLIBC_2.14' not found\"? :). Have you tried to google \"/lib64/libc.so.6: versionGLIBC_2.14' not found\"? :). We actually have a dependency on JNA library (https://github.com/java-native-access/jna), looks like it requires glibc 2.14.. We actually have a dependency on JNA library (https://github.com/java-native-access/jna), looks like it requires glibc 2.14.. This change looks reasonable, but I'm not sure about practical value of this approach:\n\nHow often developers add new main methods? In practice, not very often.\nWhat if there are multiple targets that own this file?\nWhat if the file is compiled in a java_library and there is no java_binary or there are multiple java_binary targets?\n\nAt the same time this feature modifies UI for all users of the Buck plugin and add some run time cost when a new file is opened (or even switched to, don't know how often IntelliJ would call it.) \nMy general recommendation would be to ask before spending time on writing a new feature.. We already have a way to add a configuration to run buck test. Can we re-use the same approach here and use buck run? From what I understand it does deep build and then IntelliJ executes the class, is that right?. Sorry I didn't get, why we cannot use buck run instead of deep build and running the application using IntelliJ capabilities?. > Not every main method has a binary. Some are purely contained in a Java or android library.\nThinking about that from the Buck plugin for IntelliJ perspective, it's questionable why we need some hacks that emulate buck run in this plugin. From Buck perspective the target graph contains all the necessary information (except command line args) that is required to run an application. There might be some options in java_binary which is crucial to running an application.\nAt the same time, IntelliJ provides a way to run an application and if you have a working project it should work by creating a configuration that runs buck build --deep before running the application.\nSo I'm not convinced that this is a right solution, but I'll let @mkillianey to take a look.. > Not every main method has a binary. Some are purely contained in a Java or android library.\nThinking about that from the Buck plugin for IntelliJ perspective, it's questionable why we need some hacks that emulate buck run in this plugin. From Buck perspective the target graph contains all the necessary information (except command line args) that is required to run an application. There might be some options in java_binary which is crucial to running an application.\nAt the same time, IntelliJ provides a way to run an application and if you have a working project it should work by creating a configuration that runs buck build --deep before running the application.\nSo I'm not convinced that this is a right solution, but I'll let @mkillianey to take a look.. Which version of Android SDK and Android NDK do you use?. We recently added support for unified headers and building with NDK 16 should work.. You probably can find it in the Intellij log file. On MacOS you can open it by clicking on \"Help -> Show log in Finder\". Agree that we should unify classpath creation in all mentioned cases.\nA few thoughts:\n\n\nWhy do we need to sort? The only reason I can think of is rule key computation, but, for example, java_binaries with different order of classes should have different rule keys because their runtime behavior can be different.\n\n\nWe should give people a way to control the order of dependencies. This is important in cases when stubs are used in tests. With lexicographical sorting the only way to control that is to rename the target names which is counter-intuitive.\n\n\nSince Java doesn't have notion of dependency graphs (classpath is a flat list), it doesn't enforce sorting or traversal order.\nI suggest we choose some stable ordering produced by traversing the graph of dependencies.\n. @jkeljo any specific reasons why we sort classpath entries?. appcompat is not provided by default, you need to copy all the necessary files to the repository and create rules for them. For example, you can use android_prebuilt_aar to declare appcompat-v7-*.aar library and then make individual targets to depend on it. This also gives you a better control over which version of appcompat is included in the app.. As I said in #1843 we shouldn't change the configuration and instead let user know that the configuration is incorrect.. Again, we are not going to have any kind of magic logic in Buck that would change the configuration from what's defined in .buckconfig. If this configuration is not flexible enough you can add additional options, for example, platform level by ABI.. @cjhopman . ok, let's keep it together. Yeah, some tests are failing, need to take a closer look.. Please, add assumptions if the tests require a specific version of Go.. Try to rebuild the project in IntelliJ.. Can you add tests, please?. Can you add a test for that?. I'm working on it, there is another issue with NDK 16 which should be resolved before allowing NDK 17.. I doubt we'll have time for that. Having changelog would mean everyone should be updating it, otherwise there is no point in keeping it. . > When --ide=GoLand, Buck will skip project file generator, and only run pre_process and post_process scripts.\nAre you saying you use Buck to run some scripts? Why not run those scripts directly instead of adding basically no-op logic to Buck?. They are designed for commands that do some work. The way you want to use them makes Buck a wrapper for your script. We really don't want to make Buck a proxy for all kind of custom scripts.. Could you add information about where you got kotlinx-metadata-jvm-0.0.2-sources.jar?. Thanks for taking a look. We generate website from definitions in docs folder in the master branch so to fix that problem you would need change that line: https://github.com/facebook/buck/blob/master/docs/__common.soy#L892. Yeah, looks like it.\nYou can also test your changes locally by running docs/soyweb-local.sh, it should start a webserver and you can check your changes by opening http://localhost:9811/. Could you share your target definitions?\nYou cannot reference the output by path, you need to use target name instead.. We would probably avoid including this functionality as part of main binary, but we can include it as separate scripts in buck repository. Internally we don't have needs for this feature so it's unlikely we're going to work on that, but we would definitely take a look at any PRs.. We would probably avoid including this functionality as part of main binary, but we can include it as separate scripts in buck repository. Internally we don't have needs for this feature so it's unlikely we're going to work on that, but we would definitely take a look at any PRs.. Let's add support for modules in project command. Moving Go back to core would be a regression.\nI think we can do that by adding a plugin extension point that would provide implementations of project command. No need to move existing project commands to this model. I can take a look at this, but it'll take me some time to do that.. Yeah, it was intentional. If you want to run targets for all targets in a repository you can use //.... af4694a7cfaedc957f56db6bd3822b56a618587e is the change.. Yeah, it was intentional. If you want to run targets for all targets in a repository you can use //.... af4694a7cfaedc957f56db6bd3822b56a618587e is the change.. Could you show the structure?. thanks, I'll fix it. thanks, I'll fix it. Thanks for reporting.. You can declare new arguments in the description arg: https://github.com/facebook/buck/blob/1d44f998263ceb7635bc17e3d2162b186cd7aad3/src/com/facebook/buck/features/dotnet/CsharpLibraryDescription.java#L72. In general you'd better not rely on the particular directory structure between targets. You should be able to use $(location) macro to pass the location of the resource file to the test binary. Here's my attempt: https://github.com/styurin/sh_test/commit/8b5ba754a11f0b7ce557e4602dc5bb1528a3935d. So I was able to make it working without changing buck: 53badfb8d735a3ac317646b7f7f5a424f5e81bda. This requires some knowledge about the layout of files in buck-out. Looks like we don't expose the information about resources in sh_binary.. It's failing on some tests, can you rebase it to trigger CI runs on master?. Some tests are failing in test/com/facebook/buck/apple. Travis CI doesn't run them because we don't run tests on OS X. Can you check them locally?. Sorry for the delay, our internal testing got an error in PrebuiltAppleFrameworkIntegrationTest#testPrebuiltAppleFrameworkCopiedToBundle. Could you take a look, please?. Here's the error:\nLooking for a provisioning profile for bundle ID com.example.TestApp\nNo provisioning profile matching the bundle ID com.example.TestApp was found\nBuild failed: No valid non-expired provisioning profiles match for *.com.example.TestApp\nLooking for a provisioning profile for bundle ID com.example.TestApp\nNo provisioning profile matching the bundle ID com.example.TestApp was found\n    When running <provisioning-profile-copy>.\n    When building rule //app:TestAppBundle#dwarf-and-dsym,include-frameworks,iphoneos-arm64,iphoneos-armv7.. Tests are failing. It's not building and files needs re-formatting.. We could, but we are in the process of changing it and publishing those note would mean we need to update them too.. You need to add a python_library target with main.py in srcs and then list it in deps of python_binary target:\n```\npython_binary(\n  name = 'main',\n  main_module = 'main',\n  deps = [\n    ':main-lib',\n  ]\n)\npython_library(\n  name = 'main-lib',\n  srcs = [\n    'main.py',\n  ]\n)\n```. Could you reformat files and make sure CI passes?. Could you add readme to indicate where that library was downloaded from?. Could you add readme to indicate where that library was downloaded from?. Could you provide in the description:\n\nwhy do we need this\nwhy existing publish functionality doesn't work\n\nbrief overview changes in the code.\n. Could you provide in the description:\n\n\nwhy do we need this\n\nwhy existing publish functionality doesn't work\nbrief overview changes in the code.\n. How did you configure Android NDK? Using NDK_HOME or ANDROID_NDK? Could you use ANDROID_NDK_REPOSITORY instead? Buck would then skip unsupported versions of NDK.. How did you configure Android NDK? Using NDK_HOME or ANDROID_NDK? Could you use ANDROID_NDK_REPOSITORY instead? Buck would then skip unsupported versions of NDK.. Because NDK evolves over time and we cannot provide updates at the same time.. Because NDK evolves over time and we cannot provide updates at the same time.. Well, you hit that issue. If you use ANDROID_NDK or NDK_HOME Buck will try to use NDK no matter which version it has. If you use ANDROID_NDK_REPOSITORY it will use the latest supported unless version provided by configuration. This behavior looks similar to what you described.. Well, you hit that issue. If you use ANDROID_NDK or NDK_HOME Buck will try to use NDK no matter which version it has. If you use ANDROID_NDK_REPOSITORY it will use the latest supported unless version provided by configuration. This behavior looks similar to what you described.. Could you update docs, please?. Could you update docs, please?. Could you rebase on latest master?. Can you add a test for that? Also, some example would be great too.. IIRC it was restricted to avoid dealing with buck-out. cc @bobyangyf . Can you add some tests, please? Also, it may not look pretty when it fails, you probably need to use HumanReadableExceptino.. It looks fine, but I'm just curios, is that something that blocks you in some way?. Could you re-format the source code? You can find instructions here: https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style. > btw, is tha AppVeyor check expected to fail? Seems like fails on some code unrelated to my changes.\n\nYeah, TravisCI should test your changes.. > btw, is tha AppVeyor check expected to fail? Seems like fails on some code unrelated to my changes.\nYeah, TravisCI should test your changes.. > Is there a keyword to restart checks scripts?\nYou can restart the job on the job's page in Travis CI. > Is there a keyword to restart checks scripts?\nYou can restart the job on the job's page in Travis CI. I've change the settings to allow @booking.com to sign-up directly. Can you try?. I've change the settings to allow @booking.com to sign-up directly. Can you try?. Could you fix typos in the description?. > Could you fix typos in the description?\n\nThis PR seems to break kotlin compilation for us, can't reference resources from other module even tho there is an explicit dependency on it\n\n. Added \"kolide.co\" domain.. Done. Can you use some simple file that contains small amount of binary data instead of a jpeg file?. Some internal feedback:\n\nThis is better than the jpeg and is fine, but really we don't even need a file do we? All they do with it is read it in the go test to get binary data that is unprintable. Is there no way to create that binary data in the test itself? Then you could make it clear what specific values are being tested (and if, like Java, there are actual invalid sequences you could test those too).\n\n. This change will add proguard target to the deps, but where is it used?. Can you provide an example how it should be used? We have integration tests for robolectric_test.\n. I recently updated robolectric integration tests to specify runtime dir in vm_args using a macro: 9a880c642cf20e25e5d36b7f0329ce4d6706c984. It looks the same except that you would need to use robolectric_runtime_dependency instead of vm_aergs.. Could you rebase? Looks like there a merge conflict.. Could you rebase? Looks like there a merge conflict.. Committed as 90d62021dd3af51e437ae28c4a06231dd252fa98. I tried to committed with a proper author, but looks like that information was lost somewhere.. Committed as 90d62021dd3af51e437ae28c4a06231dd252fa98. I tried to committed with a proper author, but looks like that information was lost somewhere.. Tests are failing to compile. Is that possible to split this PR?. Is that possible to split this PR?. Also, Travis CI builds are failing.. Also, Travis CI builds are failing.. Could you rebase PR so that includes only your changes?. Could you rebase PR so that includes only your changes?. This error is probably from the release branch, what is the error from the master? We moved ideabuck out of srcs to tools long time ago.. Merged in 1be3f2174800261794ad1cb53f76a90bf0323263. Could you rebase on the latest stable?. Could you rebase on the latest stable?. I'm asking because there is a merge conflict caused by internal changes. I tried to change those internal pieces, but it's still failing and I hope rebasing on master would solve that. Otherwise someone would need to apply this PR manually to the internal repository which means wasting precious cycles of internal developers.. I'm asking because there is a merge conflict caused by internal changes. I tried to change those internal pieces, but it's still failing and I hope rebasing on master would solve that. Otherwise someone would need to apply this PR manually to the internal repository which means wasting precious cycles of internal developers.. Could you update IntelliJ project to remove the old library and add a new ones?. Could you update IntelliJ project to remove the old library and add a new ones?. Yeah, it doesn't check for absolute paths when searching for build files. We don't have many reports of this error so it's not a high priority for us.. Could you rebase on the latest master?. Fixed in 04000d48656d4c498813942b454b9d13fb570665. Could you rebase on the latest master? There are some merge conflicts with internal versions of these files, I've fixed the internal version, but this PR needs to be rebased.. Sorry for slow response, we're interested in merging, but since kotlin is not our top priority it can take some time.. I have changes for this issue in the review already. Can you split the changes? Also, looks like TravisCI failing because formatting is wrong.. Can you split the changes? Also, looks like TravisCI failing because formatting is wrong.. Thanks, I'll take a look later.. Is that possible to add tests for kotlin use case?. Is that possible to add tests for kotlin use case?. ping @jbarr21 . Tests are broken. Tests are broken. Is that possible to add an integration test?. Just wanted to clarify, this change modifies an existing test that would fail if that change hadn't been introduced, right?. Done. Adding support for the next version NDK is not simply bumping the version, there are usually major changes which needs to reflected before enabling that support.. Build is broken. Build is broken. I tried to debug the failed test, it looks like this PR is not complete. I'd recommend going through the failed test and fix the PR.. I tried to debug the failed test, it looks like this PR is not complete. I'd recommend going through the failed test and fix the PR.. Does it fail in some other way if sources are empty? Many folks use libraries with empty sources to combine dependencies into one target, is that supported in go?. Compiling with Java 10 requires special flags, adding support is in the process right now.\ncc @jtorkkola . Compiling with Java 10 requires special flags, adding support is in the process right now.\ncc @jtorkkola . Please, rebase on master. Please, rebase on master. I'm not sure this is a reasonable approach to hard the list of entries. Why these entries are there and can they be stripped out before? What if there are more entries that needs to be removed?. I was thinking about having an argument on a rule that would list entries to remove, but these details may look very low level for top level rule.. > Maybe we can add documentation to the code to make it clearer why we choose these entries only?\nSounds good.. Sorry for late comments, I forgot to post them. jdk_name is a bad name here, it's an SDK name, not JDK name. It's better leave it as it was before (i.e. just SDK name) because it can point to an Android SDK or Intellij Plugin SDK.\n. the same, JDK is one type, there might be other types.\n. We already have java_library_sdk_names, can you follow the same logic and rename this option to android_library_sdk_type?\n. \"Default SDK type for android_library modules\" or something like that. In other words, please, indicate that this is applied to android_library only.\n. The same, android_library_sdk_name.\n. The same comment as in SDK type\n. Project means it's a project level setting. In this case methods should be getAndroidLibrarySdkName and getAndroidLibrarySdkType.\n. Can you replace the example with the default SDK name, for example, \"Android API 23 Platform\"\n. The same about sdk name, please, replace with the default name \"Android API 23 Platform\".\n. Do we really need real code here?\n. what kind of issues with generated code?\n. why it's not true by default? because of issues with generated code?\n. Not sure it's a good idea to connect and subscribe in the constructor. Isn't consumeTestRunStarted a better place for that?\n. timestamp doesn't look like valuable information here. Can you convert it to readable format?\n. can you rename s to something meaningful?\n. Better text would be: Leave empty to run all tests\n. This wouldn't work in general case. You need to use buck query owner(filename) to find the owner of this file.. Or you can inspect directories starting from the current directory up to the root of the repo to find first buck file and then inspect that file :). Please, remove the trailing comma from test and description. Also, can you put these actions together with other actions like Run and Debug?. Ideally it should be in preferences, but that's fine for now. split this line, please. Can you change the text to match the default actions to something like:\n\nRun 'TestName' with Buck\n\nAlso, break the line so it fits the screen. The same for this:\n\nDebug 'TestName' with Buck. Do not forget access modifiers, this can be made private. add new line after this method. this needs to be changed to actionPerformed if you decide to remove derived classes. Also, please, do not forget access modifiers (protected in this case). Why not add a boolean parameter to RunSelectedTestAction and it in SelectedTestRunLineMarkerContributor? Creating two classes just because of one boolean seems excessive.. if (is method)\nelse if (is class)\nelse return\n\njust to be safe and to avoid NPE in future. I'd prefer to be consistent with the style above:\nif (buckFile == null) {\n  return;\n}. testConfiguration.data.testSelectors = testSelectors.orElse(\"\");. BuckCommand.QUERY,\nnew Function<List<String>, Void>() {. What would happen if type.getConfigurationFactories() is empty? And if first element is not RunnerAndConfigurationSettingsImpl?. I'm a bit concerned about sharing runnerAndConfigurationSettingsResult as a instance variable. This means that two concurrent execution can overlap. It's much safer to keep it inside of createTestConfigurationFromContext method.\nYou can even try to keep it inside of BuckQueryCommandHandler by moving this code to afterCommand of BuckQueryCommandHandler.. Can you check the size of the array just to be safe. You can keep logic to determine an executor in this if and move ProgramRunnerUtil.executeConfiguration( after it to reduce the amount of duplicated code.. looks like method.getContext().getContainingFile() can return null. Can you check for that?. Looks like it duplicated code? It's called on the next line. Could you reformat if to make it easier to extend if we need to?\nprivate static final String[] TEST_ANNOTATIONS = {\n    \"org.junit.Test\",\n    \"org.testng.annotations.Test\",\n};. You don't need it if you move code to handler's afterCommand.. please, split the name to fit screen. could add a check for first element to be present? If case there are no owners of a file.. ```\nif (ExecutorRegistry.getInstance().getRegisteredExecutors().length == 0) {\n  return;\n}\nexecutor = ExecutorRegistry.getInstance().getRegisteredExecutors()[0];. split the lines, please. method.getContext().getContainingFile() can return null. you need to check for string.isEmpty(). and here for type.getConfigurationFactories() to have something. ?. As I asked before, can you change it to follow the standard IntelliJ format:\n\nRun 'TestName' with Buck. split the line, it's too long. the same, split the line. should be:\n\nif (strings == null || strings.isEmpty() || strings.get(0) == null || strings.get(0).isEmpty()) {\n  return null;\n}. Split the line. unused import. if (isTestMethod(method)) {\n...\n}\nand remove isTestClass.. Information from targets is collected in module rules. For android_library it would be here: https://github.com/facebook/buck/blob/master/src/com/facebook/buck/ide/intellij/lang/android/AndroidLibraryModuleRule.java\nThis class should not deal with particular target types.. target.getShortName().contains(\"aidl\") what is that?. Use this: https://github.com/facebook/buck/blob/44be031266fc118cb712802f1d67489291cde8d0/src/com/facebook/buck/jvm/java/DefaultJavaLibrary.java#L280-L282. looks like this change is unnecessary. the same, can you revert changes in this file?. all these lines can be replaced with moduleBasePath.relativize(compilerOutputPath.get()). This needs to be in JavaLibraryModuleRule. This should be Optional.of(). Revert these changes. Please, replace this wildcard with individual imports. Can you rename this option to be something like project_compiler_output_url instead? Right now it's too generic.. Why did you change it to filter out non-java_test targets? What if it's robolectric_test or something else?. Yeah, I think that should work. Ideally we need to have a way to indicate that we need only test targets, since there is no way right now, let's use *_test.. I suggest simplifying design and be consistent with java source folders and java test folders.\nYou can rename this method to getIsTesFolder and use it together with getIsResourceFolder to detect the folder type. You would need to add JavaTestResourceFolder class to be consistent with TestFolder and SourceFolder.. Is this method used anywhere? Looks like it's not.. This method is also not used.. Can you refactor this part so that if someone changes either UnzipAar or AndroidPrebuiltAarDescription, this code would be changed too? Right now the folder name is copied and there is no way detect these dependencies. I suppose you can use buildTarget.withFlavors(AndroidPrebuiltAarDescription.AAR_UNZIP_FLAVOR) and then refactor UnzipAar to provide access to unpack path.. As I understand AAR must contain \"res\". Can you add a comment about that to help with understanding where this constant is coming from. IntelliJ complains about this null check, it's safe to remote it.. This should be more efficient:\nboolean hasClasspathsWithoutRes = getClassPaths()\n        .stream()\n        .anyMatch(input -> !input.endsWith(\"res\"));. not used, please, remove. Do you really need a command line option? Isn't buck config enough?. where did you get that?. Why do you need to create a directory here?. This is not present in JavaLibraryDescription.CoreArg. Where did you get this jar? Is that from IntelliJ installation? It's pretty big, 32Mb. Do you need a jar from some specific IntelliJ version?\nCan you update get_jars.sh script to include this jar? Also, can you add it to LIBS_TO_STUB and test this change with stubbed jar? Could you do it in a separate PR so that I can re-run the script and commit jars from my installation.. oh, I missed that, probably not, may be add a comment?. > which piece of that do you want in a separate PR?\nUpdating get_jars.sh and adding a new jar.. Could you change it to (add a colon after \"executable\"):\nMake the script executable:  chmod +x .git/hooks/pre-commit. It looks like the arguments are wrong:\n\ncopy_or_stub_jars \"$ANDROID_SRC_DIR\" ${#ANDROID_LIBS_TO_COPY[@]} ${#ANDROID_LIBS_TO_STUB[@]} ${ANDROID_LIBS_TO_COPY[@]} ${ANDROID_LIBS_TO_STUB[@]}\n\nshould be\n\ncopy_or_stub_jars \"$ANDROID_SRC_DIR\" ${#ANDROID_LIBS_TO_COPY[@]} ${ANDROID_LIBS_TO_COPY[@]} ${#ANDROID_LIBS_TO_STUB[@]} ${ANDROID_LIBS_TO_STUB[@]}\n\nThe format is: number of libs, libs, number of stubs, stubs. But in your case it's: number of libs, number of stubs, libs, stubs.\nIdeally, to catch these kinds of errors you would need to have some kind of separators in the list of arguments, but it's up to you to use that.. Looks like you meant to use a list here, but autoformatting changed it. You should be able to use html to make a list, can you make it more readable?. What about a case with java test sources and java resource files? It should be merged into test sources, not regular sources.. Do we really need this relativeOutputPath? From https://www.jetbrains.com/help/idea/configuring-content-roots.html:\n\nDuring the build process, by default, the resources are copied into the root of the compilation output folder. If necessary, you can specify a different folder within that output folder.\n\nIt seems that this is only useful if we use IntelliJ build. buck project can generate a project that works with IntelliJ, but it doesn't guarantee such compatibility. Do you have a legitimate use case to provide this option?. Where this path is coming from?. looks like wrong place for this dep, can you run buildifier?. still the wrong place :). by the way, you are bringing more by using JavaTestDescription.CoreArg, it inherits JavaLibraryDescription.CoreArg. The proper way is to create an abstract JvmBasedTestArg where T is the type of library. You would be able to use it like this: \nextends KotlinLibraryDescription.CoreArg, JvmBasedTestArg<KotlinLibraryDescription.CoreArg> {}. I suppose you can move this location to a config parameter and change logic to enable with extra dependencies if path is not empty.. You can replace `enable_extra_compiler_output_modules` with a path and enable this logic when this path is not empty. No need to add two options.. The purpose of `IjModuleGraphFactory` is to create `IjModuleGraph`. Creating a directory has nothing to do with that. It's better either adjust `IjProjectTemplateDataPreparer` or create these directories before main logic of `buck project`.. please, remove. and this. Why this logic doesn't work for you? This should create a library with extra class path which should point to R.java.. what about this comment?. the same for this method.. The same for this method.. JavaResourceFolder. this is not used. no need for final, it's static. Also, this needs to have `@Nullable` because `resourcesRoot` can be a null.. This needs to have `@Nullable`.. this variable can be null, right?. Weird, I had different comment here.\n\nYou can declare an abstract method here and then override it in each enum object. This would remove the need of IllegalArgumentException. Why this needs to be created for every android module even if config option doesn't exist in buck config? addAndroidCompilerOutputPath is called later at the end of this method which means it would called twice. Is this by design?. Why do we need a set here? Looks like only one Path is used, can you replace it with Optional<Path>?. It looks a bit complex, how about this:\n```\n  private static IjModule createExtraModuleForCompilerOutput(\n      IjModule module,\n      ProjectFilesystem projectFilesystem,\n      Path extraCompileOutputRootPath) {\n    Path extraModuleRelativePath = extraCompileOutputRootPath.resolve(module.getModuleBasePath());\n    if (!projectFilesystem.exists(extraModuleRelativePath)) {\n      try {\n        projectFilesystem.mkdirs(extraModuleRelativePath);\n      } catch (IOException e) {\n        throw new AssertionError(\n            \"Could not make directories for extra module for compiler output module: \"\n                + extraModuleRelativePath.toString());\n      }\n    }\nreturn IjModule.builder()\n    .setModuleBasePath(extraModuleRelativePath)\n    .setTargets(ImmutableSet.of())\n    .addAllFolders(ImmutableSet.of())\n    .putAllDependencies(ImmutableMap.of())\n    .setLanguageLevel(module.getLanguageLevel())\n    .setModuleType(IjModuleType.ANDROID_MODULE)\n    .setCompilerOutputPath(module.getExtraModuleDependencies().asList().get(0))\n    .build();\n\n}\n. When I removed this logic, your test passes. What are the conditions for this logic to be not working?. This is not a flag, right? Also, it seems generic enough, not Android specific.\nHow about something like this:\n\nThis option specifies the location of additional modules for code generated outside of buck graph. For example, it can be used to specify the location of R.java classes generated for Android plugin to help Layout Preview with resolving references to resources.. Can you update the description with this information? I mean the fact that Layout Preview uses compiler output, not the module dependencies.. Either is fine, I suppose. > When generating a real project (I used uber/okbuck sample app), without this logic, I get the exception below. It looks like the FakeProjectFilesystem used in the test code does not throw the same exception since it's .exists() method only checks whether its a file or directory and not the presence of the actual file on disk\n\nLet's fix IjProjectTemplateDataPreparer.createExcludes instead of hacking in this class:\npublic ImmutableCollection<IjFolder> createExcludes(final IjModule module) throws IOException {\n    final Path moduleBasePath = module.getModuleBasePath();\n    if (!projectFilesystem.exists(moduleBasePath)) {\n      return ImmutableList.of();\n    }\n    final ImmutableList.Builder<IjFolder> excludesBuilder = ImmutableList.builder();\n    projectFilesystem.walkRelativeFileTree(\n. Note sure if you saw my comment, but I mean something like this:\n```\npublic interface HasResourceRoot {\n  public Path getResourcesRoot();\n}\npublic class JavaResourceFolder extends InclusiveFolder implements HasResourceRoot {\n  ..\n}\npublic class JavaTestResourceFolder extends InclusiveFolder implements HasResourceRoot {\n  ..\n}\npublic enum ResourceFolderType {\n  JAVA_RESOURCE(\"java-resource\", JavaResourceFolder.class) {\n    public IJFolderFactory getFactoryWithResourcesRoot(Path resourcesRoot) {\n      return JavaResourceFolder.getFactoryWithResourcesRoot(resourcesRoot);\n    }\n  },\n  JAVA_TEST_RESOURCE(\"java-test-resource\", JavaTestResourceFolder.class) {\n    public IJFolderFactory getFactoryWithResourcesRoot(Path resourcesRoot) {\n      return JavaTestResourceFolder.getFactoryWithResourcesRoot(resourcesRoot);\n    }\n  };\nprivate final String resourceType;\n  private final Class<? extends HasResourceRoot> folderClass;\nResourceFolderType(String resourceType, Class<? extends HasResourceRoot> folderClass) {\n    this.resourceType = resourceType;\n    this.folderType = folderClass;\n  }\n@Override\n  public String toString() {\n    return resourceType;\n  }\npublic abstract IJFolderFactory getFactoryWithResourcesRoot(Path resourcesRoot);\npublic abstact boolean isIjFolderInstance(IjFolder folder) {\n    return folderClass.isInstance(folder);\n  }\npublic Path getResourcesRootFromFolder(IjFolder folder) {\n    return folderClass.cast(folder).getResourcesRoot();\n  }\n}\n``\n. Please, re-format this file with google-java-format. Please, move this declaration afterif. final.@NullablePath resourcesRoot.@Nullable`. On the second thought it's worth moving common functionality that deals with resources root to this class:\n```\npublic class ResourceFolder {\n  @Nullable private Path resourcesRoot;\npublic Optional getRelativeOutputPath() {\n    ...\n  }\n}\n```\nThen you can just derive JavaResourceFolder and JavaTestResourceFolder from this class.. This is incorrect, it's adding resource folders, not source folders. I recommend adding a separate interface:\npublic interface ResourceFolderFactory {\n  IjFolder create(Path path, Path resourceRoot, ImmutableSortedSet<Path> inputs);\n}\nThen add addResourceFolders method:\naddResourceFolders(\n  resourceFolderType.getFactory(),\n  getSourceFoldersToInputsIndex(resourcePaths),\n  resourcesRoot,\n  context);\n. You can replace this with something like this:\nif (folder instanceof ResourceFolder) {\n  ResourceFolder resourceFolder = (ResourceFolder) folder;\n  relativeOutputPath = resourceFolder.getRelativeOutputPath().orElse(null);\n  resourceFolderType = resourceFolder.getResourceFolderType();\n}\nYou would need to add missing methods to ResourceFolder though.. This can be done by adding a new field to IjFolder (isResourceFolder) and overriding it in these three classes to return true.\n. These factories should never be called, right? Why not make this restriction explicit by setting them to null.. Better name would be addDepsAndFoldersWithFilteringIfNeeded or just addDepsAndFoldersWithFiltering. I don't see how this comment is related to the code, specifically the part about src_roots. How about instead of increasing complexity of the template move URL construction to java code and pass one parameter here:\n<output url=\"%androidFacet.compiler_output_path%\" />. Can you move this functionality to IjProjectPaths?. The proper fix would be to add \"//src/com/facebook/buck/model:simple_types\" to exported_deps of more-paths:\njava_library(\n    name = \"more-paths\",\n    ...\n    exported_deps = [\n        \"//src/com/facebook/buck/model:simple_types\",\n    ],\n    deps = [\n        \"//src/com/facebook/buck/util:exceptions\",\n        \"//src/com/facebook/buck/util:util\",\n        \"//src/com/facebook/buck/util/environment:platform\",\n        \"//third-party/java/guava:guava\",\n        \"//third-party/java/jsr:jsr305\",\n    ],\n). I doubt src_root is used to detect the relative location of resources in the final jar. That's the purpose of resources_root, right? If resources_root not present the resources are placed in the same location in a jar as they are relatively to target's base path. I think this logic should be reproduced here, otherwise IntelliJ and buck will have resources in different locations.. you need to update this comment if my assumption is valid. This name doesn't follow naming convention we usually use, it should be lower case and words separated by -.. why do you need two tests here?. Why not new DefaultPluginRepository(getPluginsRoot(), isDevelopment()?. Could you instead override createPluginsRoot() and use buck-plugins name instead? Then you can use new DefaultPluginRepository(getPluginsRoot(), isDevelopment()). why do we need this? Looks like we don't use h2 in other place. I'd just add these parameters without putting them into a separate category. why this change is part of this PR? Is that necessary?. Yes, please, move it to a separate change. In case it causes any problems we can revert this change only without touching logic around skipped tests. doesn't look like this change is related, can you revert it?. return String.valueOf(parameter);. Why do we need to catch it and not fail fast?. Improved is not a great term to use. Could you replace it with a name that explain the purpose of this class.. This method is already too big, could you move the logic responsible for collecting source files into a standalone method?. Please, use full work, f is not a well-known reduction. please, use full word. What would happen if Buck runs this tests with go that is lower than 1.7?. Should be getSourceFiles. The proper solution would be to detect the version of go and enable this test only when it's higher than 1.7. Check GoAssumptions.assumeGoCompilerAvailable(); that is called in the test to make sure go is available. You'll need to extend it to detect the version of go.. Could you remove it?. The method contains two tests, could you split it?. That wouldn't work for versions like '1.10.123'. Could you use regex instead? Something like ((\\d)+)\\.((\\d)+)\\.((\\d)+) ?. Any changes in this file? Why do you need to move this method?. Changes in this file look unrelated, could you revert them?. This needs to be annotated with @Nullable.. These tests are failing on Windows. Our CI doesn't run these tests for some reason (we're investigating), but it looks like it's failing because of the path separators.. This is not initialized, it should probably be set to Optional.empty(). this is usually called setUp. It also does more than creating macro expander.. test methods usually start with test so that the method name is a verb, right now it's a statement. Could you make this variable final and ImmutableMap?. instead of initializing filterSteps in initFilterSteps could you do the following?\nfilterSteps = createFilterSteps(buildTarget, goToolchain, platform, fileTypes);. Can you change it to static to avoid mixing srcs from the argument and the instance variable.. Could you rename importMap to something that reflects the purpose of this object? It's definitely not a map.. Why do you need to call echo?. This comment is out of place here. Why do we need to know about Travis CI in this file?\nI think it's totally reasonable to set these variables before running go command without explanation, so you can remove this comment or change it to state that the go commands rely on these variables and we set them to override external variables.. A better fix would be to allow specifying both variants so that you don't need to change this code in future.. It looks like this method is called right after the creation of FilteredSourceFiles. Why not pass it as a parameter in the constructor and make it immutable?. Why not throw an exception?. I think the more appropriate place for that is Kotlin package since this is where it's used.. A better place for this is com.facebook.io.filesystem.. We already have visitors in the filesystem, why not use it?. Why?. This change doesn't bring any value, does it?. Could you move it to a separate PR?. For the purpose of documentation it doesn't matter. What would happen if the command line has no source files? Would that produce something? Can we detect the lack of input files earlier?. Could you add a check to filterSteps.get to make sure it doesn't return a null? Something like this:\n Preconditions.checkNotNull(filterSteps.get())\n\nOur code analysis check is complaining about that. Then if srcs is empty we can skip this step, right?. This issue shows the problem with supporting the directories as inputs in general. Buck need to know about the inputs before creating these steps, we shouldn't skip steps based on the output from the previous steps.\nGoing to back to the original issue of supporting directories as inputs in go rules, Java, for example, supports using zip files as inputs. This gives you a way to pass multiple files as a single file. Is there a reason we cannot add support for that in go rules?. Is running this \"go list\" command a prerequisite for a build or it's just for the sake of convenience?\nThe issue as I see it is the steps generated in FilteredSourceFilesare accessing the whole directory and it's not clear whether the files in that directory are dependencies of the build rule that produced the steps or not.\nIt still feels to me that this logic is more complicated than necessary because of the support of directories.. How about overriding execute to check if srcs is empty, return StepExecutionResult.of(0) if it is and proceed with compilation if some source files are present?. How about backward compatibility? What's general practice around updating to latest go toolchain?. If this PR is going to be in review for some other fixes you may want to move change related to this class to a separate PR. Why?. why --deep?\nAlso, I'd recommend avoid writing to buck-out, in this case a temporary folder would just fine.. I'd add a sleep here. Could you split this method into smaller methods to show what's actually happening here. Right now it requires reading the whole method.. looks like duplicated logic.. buck query can output in json format, can you use it instead of parsing new lines?. Can you verify the actual exception message? Otherwise this test may continue to work when there is a different problem.. Could you split this class and move the tests to JavaTestIntegrationTest and JavaBinaryTest?. Please, add more information to the method name to indicate what exactly is testing in this method.. This should be in AuditClasspathCommandTest.. I'd rather throw an error rather than silently disable feature especially given that non-unified headers may be wrong and unified headers are generated from the Android platform.\nAlso, unified headers are supported from v14.. I wonder if we can make it default.. Where this option is set?. Can you rename it to createProjectWorkspaceForScenarioWithoutDefaultCell. Can you add tests for this case?. This needs to be updated to the latest version. the same. Please, update this too. This is still pointing to the old version. The same. if (summaryVerbosity.getIncludeStdOut()\n    && !Strings.isNullOrEmpty(testResult.getStdOut())) {. Can we have a map instead? Buck configuration supports keeping maps in a single option. For example:\napp_platform_per_abi = arm64 => android-21, armv7 => android-23\n. I'd call it getDefaultAppPlatform. We cannot remove this field right now. Some tests use resources and removing this filed would break situations when a resource has changed but the test's rule key hasn't changed.\nThe proper handling of these resources would be to provide access to them from test's current folder (by symlinking like in genrule), but right now we don't have this logic.. Ok, let's keep it. Could you remove this? It should be in the lists of modules by default. Yeah, could you change that to using a map?. Could you change \"Visiblity\" to lower case too?. So it will affect all the invocations of buck project even if it's not related to Go?. What's vendor?. Could you wait with that? I'll try to migrate project command to a plugin model, but it can take some time.. We do not have repository-specific details in Buck logic. You need to change it to smarter about detecting this location.. We don't really want to change Buck when there is a change in where these libs are located. You can put it in a configuration option and set it to whatever you need in your repository.. From the way it looks it should implemented as a separate command.\nFor which IDE this command is implemented? Is that just copying files?. > Go toolchain and IDEs don't take configurations like that\nBut what if they change location? You would need to change this code to make it working, then deal with support of the different versions of these tools.\nA configuration option makes it much easier to maintain. You can even use a configuration option with default value of src/vendor when it's not present.. Did you test this? There are two targets with the same name in this BUCK file. Please, run the tests before updating the PR. Also, formatting is still off.. You need to add .fixture extension to this file. Why sorting?. Can you replace it with ImmutableSortedSet.copyOf(toolchainStream) and remove the sorting?. Could you move the test case with the exception to a separate method? Other test cases are homogeneous and can stay in one method, but the the test case with an error stands out.. This is not compatible with Windows. What is this character?. Is that something that go test print? Why not use some ASCII character?. This needs to be annotated with @Nullable since it can return null when both groovyc and groovyBuckConfig is null.. this can trigger NPE. I'm not really following here, how it can be null?. Why not provide non-null instance in the test?. Oh, it was made before your change. I think we should refactor the test to provide non-null instance. No need to have logic in production that is only applied in tests. I think we should provide both test cases, can you create another test for robolectric_runtime_dependency?. You need to add a test in RobolectricTestRuleIntegrationTest that uses this target.. Why do we need this?. I mean the change in bazel only deal with OtherOperationType. Please, add a readme file indicating where that file was taken from as well as the license file. output can be a null here, addModule need to have @Nullable on the corresponding argument. Please, keep the readme file with information where this file was taken from as well as the license file.. s/APK/AAB/. Can you revert this?. So this is the only change in this PR that is actually fixing the logic, right? Is the rest of the changes for consistency with AndroidBinary?. What about the same when the list is empty, it still adds -Xfriend-paths= option?. You can use Files.getNameWithoutExtension() instead.. This needs to have \"tokens.length == 0\", the same as it was in the original change.. Why not compiler_args? Even extra_compiler_args. It's not what \"free\" means here and we use extra in some other rules.. Can you add a test to make sure duplicate arguments are handled properly?. It's not clear what should be the result of this method. It does some validation, but what exactly it returns? I'd recommend renaming it to emphasize what is the result.. The same here.. This list of names looks difficult to understand. Can we have a list of names listed which is then used to filter entries. It would be easier to maintain.\nAlso, the current logic would work for something like \"META-INF/directory/MANIFEST.MF\" which probably is not the intention.. ",
    "rowillia": "https://github.com/facebook/buck/commit/4326149b66eb43123f1d20916541bfde073980a4 fixed these.\n. 60efceb5239134d709be4087916e95e07542519a Switched us to 7 and added in a .buckconfig option to flip it to something else.\n. Hey @davido, thanks for the Pull.  We are actually already looking at something similar to this, but we want to generalize it a bit more.  For example, if a java_library depends on a ndk_library, the ndk_library doesn't actually need to finish building in order for the java_library to start building since the ndk_library is actually a packaging dep, not a compile time dep (e.g. any android_binary that has the java_library in it's deps needs to also have the ndk_library)\nAlso, I think that exported_deps does what you want in this case.\n. Yeah, that's definitely a bug on our part.  Thanks for the report!\nOn Dec 29, 2013 7:13 PM, \"Christian Legnitto\" notifications@github.com\nwrote:\n\nYuck, yeah this is super unfriendly. @rowilliahttps://github.com/rowilliawhat do you think, should we create an empty file or just make the message\nbetter?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/issues/72#issuecomment-31329101\n.\n. Thanks @mread.  Digging into this further to ensure it doesn't break anything else, but we should be able to take this.\n. @mread Can you take a look at https://github.com/rowillia/buck/commit/b7e70d0a58674642671dd2d69568acbe25de93a7 ?\n\nPatching in https://github.com/mread/buck/commit/b3eaf68609b339cdd745ff4cc5d9af22f509ccd6 , the unit test doesn't appear to produce the result you were expecting.\n. Thanks, this was pulled and will go out with our next push to github!\n. Thanks, this was pulled and will go out with our next push to github!\n. Pulled in 496e8d0\n. Pulled in 496e8d0\n. Pulled in 4c3b7f4\n. Pulled in 4c3b7f4\n. Thanks!  @oconnor663 pulled this and will land it in our next push.\n. Fixed in d0269d1\n. Fixed in d0269d1\n. I'm looking at adopting Buck now, but unfortunately I've hit a stopping point due to this issue.  @dreiss  had some ideas in irc as to how to solve it (have android_binary take in srcs which get graph enhanced to an android_library rules that has the final merged R.java.\nI've also considered forking ButterKnife to support generating the code as part of Buck's build process, but unfortunately I don't have time for either :/\n. I did, the problem is src/com/facebook/buck/file/MavenUrlDecoder.java expects there to always be 5 fields.\n. https://github.com/facebook/buck/pull/411 fixes this.\n. Fiiiiiiiiiiine....added a test\n. @sdwilsh fixed tests.\n. \n. \n. Added a test\n. Unfortunately this doesn't work :/\nSuperConsole does a dirty check before every render, and the fact that the build failed has already dirtied the console.  We need SuperConsole to keep printing ConsoleEvents even after stderr is dirty.\n. With a burning passion.\n. The reason I went down this path is JavaBinary followed a similar pattern of first copying the input jar to buck-out before doing anything with it.\n. Yeah, it does feel a little janky.  I guess we could graph enhance another step in there to copy the input first and then pass that to the prebuilt jar and aar?\n. ",
    "Zitrax": "\nMaybe a preference in .buckconfig to set what the default source and\ntarget is for a java_library() that doesn't specify it?\n\nI would love to have that.\n. ",
    "cakoose": "I think the term ABI should be avoided entirely.  Saying \"ABI\" sort of implies that the important thing here is binary compatibility instead of source compatibility, which is the exact opposite of what's really going on.  Overall, \nI think referencing the JLS's binary compatibility section is more of a distraction than a help.\nThe best term I can come up with right now is \"externally visible API\".  There may be subtle differences between a reader's idea of what \"externally visible API\" means and what Buck actually computes (for example, the \"public static final\" field inlining garbage that javac does) but I think it gets you most of the way there.\nMy attempt at a rewrite kills the footnote and replaces the term ABI with either \"externally visible API\" or \"API\":\nTitle: If a Java library's API doesn't change, code that uses the library doesn't need to be rebuilt.\nOftentimes, a developer will modify Java code in a way that does not affect its interface. For example, adding or removing private methods, as well as modifying the implementation of existing methods (regardless of their visibility), does not change the externally visible API of the code.\nWhen Buck builds a java_library rule, it also computes its externally visible API. Normally, modifying a private method in a java_library would cause it and all rules that depend on it to be rebuilt because the change in cache keys would propagate up the DAG. However, Buck has special logic for a java_library where, if the .java input files have not changed since the previous build, and the API for each of its Java dependencies has not changed since the previous build, then the java_library will not be recompiled. This is valid because we know that neither the input .java files nor the API against which they would be compiled has changed, so the result would be the same if the rule were rebuilt. This localizes how much Java code needs to be recompiled in response to a change, again reducing build times.\n. There's a script in the docs dir that you have to run to update the site.\nOn May 20, 2014 3:57 PM, \"Shawn Wilsher\" notifications@github.com wrote:\n\nWebsite didn't actually update with the push. I'm missing something, but\nI'm not sure what yet.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/facebook/buck/pull/115#issuecomment-43693992\n.\n. I don't think I updated the pull request.  facebook-github-bot might be malfunctioning: https://www.dropbox.com/s/derhi3j4l2d8vqf/Screenshot%202016-03-23%2017.01.30.png\n. \n",
    "simpleton": "https://github.com/simpleton/eclipse2buck\n. https://github.com/simpleton/eclipse2buck\n. May be android_library() will help you.\nhere is a simple script for generate BUCK files from eclipse project. I\nonly test it in our project, hope it work well for u.\nhttps://github.com/simpleton/eclipse2buck\nOn Mon, Jul 7, 2014 at 10:22 AM, zhangyulong882 notifications@github.com\nwrote:\n\nHi, could you please introduce how to write the corresponding buck files\nof a project with third-party lib project(not a jar file, it's an android\nlib project)?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/149.\n. @dreiss This feature is important for APPs which download some dex files from internet.\nIt could make some seperated features in seperated dex file, and then download it from internet when customer actually use it.\n. @dreiss This feature is important for APPs which download some dex files from internet.\nIt could make some seperated features in seperated dex file, and then download it from internet when customer actually use it.\n. @DzMonster \nQuestion 2:\nThe framework will extract resource.arsc, and use the shared memory to access it. Because of the 1M limitation some APP didn't compressed it. But this limitation only affect on the system below Android 2.3(or 2.2, I can't remember it clearly).And FB APP use API 14 as min api level.\n. R.java will generate by BUCK, do not use the R.java which generated by Ant.\n. \n",
    "djonesfp": "Alternatively a default settable by users in the buckconfig would be good too, but I'll settle for updating the default for now. :)\n. You make a good point for the no sources listed case and I thank you for your explanation as to why a force flag could be a bad thing. It seems though that having a script that gets run before buck is a clunky solution. This seems like it would not be an uncommon element for a build that buck should have some way to enable it. Having $DATETIME as something that can be referenced? Of course then something like revision of the source tree would be desired and that is not so straight forward. \nTime to think of another solution.\n. You make a good point for the no sources listed case and I thank you for your explanation as to why a force flag could be a bad thing. It seems though that having a script that gets run before buck is a clunky solution. This seems like it would not be an uncommon element for a build that buck should have some way to enable it. Having $DATETIME as something that can be referenced? Of course then something like revision of the source tree would be desired and that is not so straight forward. \nTime to think of another solution.\n. ",
    "andrewjcg": "Yeah, I tend to think of this as being similar to a corrupted JAR in the sense that it's something that buck can't and shouldn't know how to handle (e.g. which of the class files should we drop?).  What about using a genrule to run \"zip -d ...\" to remove the offending entries and then have the output plug into the prebuilt_jar rule?  Would something like this work for you?\n. Thanks for reporting this issue.  It appears there is a bug in the JarDirectoryStep that is causing invalid compressed sizes to be written to the central directory.  Fix coming.\n. Thanks for such a detailed bug report!  This undesirable behavior (and a few others) is caused by how we currently handle \"include_defs\" and python globals.  We're working on remodeling this around python modules, which should fix a number of issues (and I've confirmed it fixes this issue), and hope to have it pushed soon.\n. Heh, completely missed Simon's comment.\n. The $(platform) macro evaluates to one of android-arm, android-armv7, or android-x86, so that .so would need to be in a directory with the above names (not armeabi-v7a).\n. So sorry for taking this long to get to this, but it's definitely on my radar now.  Generally it looks good, I just have a few concerns and suggestions about separating out the PEX-specific stuff from the more general python stuff which I'll comment on inline.\n. So sorry for taking this long to get to this, but it's definitely on my radar now.  Generally it looks good, I just have a few concerns and suggestions about separating out the PEX-specific stuff from the more general python stuff which I'll comment on inline.\n. Looks good thanks!  Just a few minor questions/comments inline.\n. Looks good thanks!  Just a few minor questions/comments inline.\n. @facebook-github-bot import\n. I feel the current behavior is correct, since implicitly dropping all but one of the duplicates means we'll silently pick one which might lead to unexpected behavior (e.g. what if the contents of the two dupliates are different) and requiring input JARs to not have duplicate classes should be pretty straight forward.  In this case, something like https://gist.github.com/andrewjcg/9fa8bb8a1d94aa044a56 should be enough to explicitly sanitize the downloaded JAR before plugging it into the prebuilt_jar rule (I actually think zip_file should also probably error out here, but it should be straight forward to add a genrule which deletes one of the items).\nIs this happening a lot?  If not, I'm hoping adding a few extra rules to explicitly manage these JARs means we don't need to add handling of this into Buck.\n. Does wrapping the output in a sh_binary work?  That said, something like this does sound like a nice shorthand.\n. Yeah, the prebuilt_cxx_library UI is pretty bad.  Ideally we'd get rid of the lib_dir and lib_name parameters, which we currently use to construct the paths to static, static-pic, and shared libs, and replace them with explicit parameters for the these libraries (e.g. static_lib, static_pic_lib, shared_lib) which would be SourcePaths directly pointing to the library.\n. Yeah, the prebuilt_cxx_library UI is pretty bad.  Ideally we'd get rid of the lib_dir and lib_name parameters, which we currently use to construct the paths to static, static-pic, and shared libs, and replace them with explicit parameters for the these libraries (e.g. static_lib, static_pic_lib, shared_lib) which would be SourcePaths directly pointing to the library.\n. Sorry for the delay here.  The convention we've been using is that if both static_lib and static_pic_lib are specified, then the former is PDC and the latter is PIC.  If, however, only static_lib is specific it is assumed to be PIC.  It is a bit unintuitive, so I wouldn't be against changing this, but I think either way we need to end up using a PIC lib in a non-PIC link if it's the only one available, since this is a pretty common scenario.\nWe have the weird interface mostly for legacy reasons.  It's true that the linux and darwin linkers have present extensions they looks for when -l<name> is used, but I think it's actually linker dependent if it requires these extensions when the full lib path is specified on the link line, and in the case of binutils/linux I believe the actual extension doesn't matter.  That said, I think it's fine to leave the input names unchecked and just let the link through an error if it takes issue with the name.\n. Yeah, I'm not completely comfortable about baking this in to all libraries.  Since the library deployment strategy is really binary/rule specific, ideally the top-level binary would set the RPATH, as is done with C/C++ binaries.  However, this is obviously tricky since the Python interpreter is prebuilt.  We had a similar issue with Lua binaries, so we ended up embedding the interpreter into a super simple C/C++ program and setting -rpath on that.  I wonder if we can do similar here (e.g. https://docs.python.org/3/extending/embedding.html#very-high-level-embedding).. Yeah, the rel-libs macro is really only meant for libraries which don't contain SONAMEs and so need to be linked in a special way.  In those few cases I've seen, the libraries usually have the lib<name>.so, which the rel-lib support converts to -L<prefix> -l<name> which the link will then use to look for lib<name>.so.  I think this thing breaks down in the presence of version suffices, as even if we do strip the version suffix of correctly when forming the link line, the linker won't then know how to reconstruct the shared lib path.  However, it's common for devel installations to include a symlink from lib<name>.so to lib<name>.so.<version>, in which case I think the symlink can be used in place of the versioned name throughout (e.g. use libclang.so instead of libclang.so.4.0 in all locations in your BUCK file).\nAll that said, I think clang normally builds it's shared libs with a SONAME, so I would think you should be able to just use $(lib libclang.so.4.0) and have everything work correctly.  Was there something not working with that approach which made you start using $(rel-lib ...)?. Bleh, sorry for taking forever on this.  Changes look good to me.. Does setting provided=True help here?  This will signal to the prebuilt_cxx_library that the library is to be provided by the system/deployer at runtime, and so it's safe/appropriate to link dynamically.. Yeah, Buck doesn't setup host-specific build platforms (it's basically just \"default\" for the host platform, and Android and iOS specific platforms for everything else), which makes this kind of thing a pain.\nSome possible short-term ways forward, depending on what your trying to do:\n1) If you don't really care about cross-compilation, you can probably get using some logic in the BUCK file itself to detect the OS type (e.g. with import platform; platform.system()) and add flags to plain old linker_flags instead.\n2) Setup you're own linux and platform in .buckconfig.  Since Buck doesn't yet support configuring a host-dependent cxx.default_platform value, this would unfortunately require an explicit flavor being set for each build.. Yeah, Buck doesn't setup host-specific build platforms (it's basically just \"default\" for the host platform, and Android and iOS specific platforms for everything else), which makes this kind of thing a pain.\nSome possible short-term ways forward, depending on what your trying to do:\n1) If you don't really care about cross-compilation, you can probably get using some logic in the BUCK file itself to detect the OS type (e.g. with import platform; platform.system()) and add flags to plain old linker_flags instead.\n2) Setup you're own linux and platform in .buckconfig.  Since Buck doesn't yet support configuring a host-dependent cxx.default_platform value, this would unfortunately require an explicit flavor being set for each build.. We don't have a way to support this now, as Buck just generates native executable formats from a cxx_binary rule (e.g. ELF, MachO).  I think we'd either need to use a higher-level format (e.g. like python_binary rules) or do some trickery with embedding resources in the native executable format (e.g. in a manually added ELF section) and have some library code to access it.  Either way, it's likely not trivial.. Looks like the default ghc is 7.4, which might be too old.  Trying again with 7.6.. Used a PPA (https://launchpad.net/~hvr/+archive/ubuntu/ghc) which provides a new GHC (as per the pandoc example, https://github.com/jgm/pandoc/blob/master/.travis.yml, linked from https://docs.travis-ci.com/user/languages/haskell/).. If the tests pass, I'll update again to use GHC-8.. Ok, looks like the haskell tests run and pass now.. Sorry, I think I'm missing some additional context here.  From the original issue mentioned above, it sounds like the original libicuuc.a library is not PIC-enabled, yet you're specifying it via the static_pic_lib (this field is only meant for prebuilt static archives which are PIC enabled)?. Sorry, I think I'm missing some additional context here.  From the original issue mentioned above, it sounds like the original libicuuc.a library is not PIC-enabled, yet you're specifying it via the static_pic_lib (this field is only meant for prebuilt static archives which are PIC enabled)?. Ah yeah, that'd be great thanks.. Ah yeah, that'd be great thanks.. This isn't expected and Buck should fail the build when input sources do not exist.  Do you have a an example/repro you can paste/post?. Ah, that makes sense.  FWIW, there is a (apparently undocumented) [build] allow_empty_globs = false config setting which will fail when globs do not evaluate to any sources.. Ah, that makes sense.  FWIW, there is a (apparently undocumented) [build] allow_empty_globs = false config setting which will fail when globs do not evaluate to any sources.. Yeah, I think the fundamental thing is that *linker_flags isn't really a great way to model library dependencies (e.g. -lz) since, as you mentioned, Buck puts them on the link line before the object files, which seems like it causes issues with --as-needed on some backends (and probably correctly so).\nIt might be worth adding a class of post_*linker_flags parameters which get added after the object files for this use case.  For better or worse, we at least avoid this internally by using \"wrapper\" rules to abstract the packaged NDK libs, and depend on those rules instead of using linker flags:\n```\nthird-party/android-ndk/BUCK\nprebuilt_cxx_library(\n    name = \"z\",\n    exported_linker_flags = [\"-lz\"],\n    header_only = True,\n    visibility = [\"PUBLIC\"],\n)\n```\nThis at least guarantees and dependents add -lz onto the link after all their objects/libs.. Yeah, I think the fundamental thing is that *linker_flags isn't really a great way to model library dependencies (e.g. -lz) since, as you mentioned, Buck puts them on the link line before the object files, which seems like it causes issues with --as-needed on some backends (and probably correctly so).\nIt might be worth adding a class of post_*linker_flags parameters which get added after the object files for this use case.  For better or worse, we at least avoid this internally by using \"wrapper\" rules to abstract the packaged NDK libs, and depend on those rules instead of using linker flags:\n```\nthird-party/android-ndk/BUCK\nprebuilt_cxx_library(\n    name = \"z\",\n    exported_linker_flags = [\"-lz\"],\n    header_only = True,\n    visibility = [\"PUBLIC\"],\n)\n```\nThis at least guarantees and dependents add -lz onto the link after all their objects/libs.. Thanks for the patch!  However, the new way to report stdout/stderr is via the BuckEventBus object (so that it interacts properly with the super console):\nbuckEventBus.post(ConsoleEvent.warning(line));\nThe constructor already gets access to the event bus object, so this should be an easy change.  Also, it's probably worth batching all the output together into a single message, rather than sending each line individually.\n. It seems odd that we're listing essentially a copy of the input file as the output.  Shouldn't the output of UnzipAar be unpackDirectory?\n. It feels a bit round-about to use the UnzipAar rule to thread through the original AAR (but it's likely I'm missing something).  Can we just have the constructor of this rule take the orignal AAR SourcePath and list that as the output without touching UnzipAar (and also propagate the appropriate runtime dep on any rule that generates the original AAR)?\n. Obviously, a bit outside the scope of this diff, but why can't we just reuse SymlinkTree here?  The only different seems that we want to create the links via walking the deps, but this looks like it could easily be done in a method that does the walk to build up the link map, then just news up a SymlinkTree.\n. We already have this as MorePaths.TO_PATH.\n. We use the \"require\" method naming convention for methods which only create the build if it doesn't already exist.  Since this one (and others below) just unconditionally always creates a new build rules, use \"create\" instead.\n. So the only reason we need this is to set the GOROOT environment variable?  Env vars seem general enough that it feels we should support those in the Tool abstraction (via a getEnvironment() getter or something), and avoid adding this class to support it.\n. Why remove this dep?  I think the pex sources import pkg_resources, which means there should be a dep here.\n. But the pex builder uses it right?  So the pex-builder binary we build (to build the actual PEXs) should depend on this, no?\n. I might just be getting confused here, but does this mean we're pulling from a the system pkg_resources?  What if the system doesn't have this installed?\n. Yup, just tested this locally on a system without pkg_resources and it works when run from both the in-place and PEX buck.  In the former case, it's pulling from the sys.path above, in the latter it's using pkg_resources from the pex builder's own PEX.\n. I'll add a comment before committing this about this anti-dep, since it appears initially counter-intuitive.\n. It'd be nice if we didn't have more PEX-specific stuff in the core python support.  Can we just have PythonVersion support the interpreter-name and version (as you've added above) and have the make_pex.py script do the necessary PEX-specific formatting?\n. Long-term we'd like to move all the PEX-specific naming/code out of Buck, just supporting the general way to use arbitrary custom Python packagers via the python:path_to_pex config setting.\nIn this vein, it'd be nice to at least keep the zip-vs-directory choice separate from the inplace-vs-standalone choice. What do you think about having a separate PexStyle enum with ZIP and DIRECTORY choices (which would apply when STANDALONE is used with the default PEX builder)?\nAnother option might be to make the current in-place package style more general and provide a config option to choose between \"simple\" and \"PEX\" sub-styles, the latter of which implements the in-place PEX. The annoying thing about this is that the current code path for in-place assumes that the generated symlink trees with the modules will be used and that the in-place starter script won't do any of it's own packaging (even if it is just copying to a directory).\n. It seems a bit weird to test for this in the commandLineArgs test.  Maybe move this to a separate testOutput test where we check for a directory for the --directory case and files for the others?\n. Why was this necessary?\n. Was this to find the python binary in the path?\n. Sorry, not sure I follow this.  Why are we adding a static_pic_lib parameter to all C/C++ rules (via LinkableCxxConstructorArg)?  Shouldn't this change only affect prebuilt_cxx_library?. ",
    "rbraunstein": "In the case I was looking at, the two entries were exactly the same.\nOn Mon, Jun 9, 2014 at 6:00 PM, andrewjcg notifications@github.com wrote:\n\nYeah, I tend to think of this as being similar to a corrupted JAR in the\nsense that it's something that buck can't and shouldn't know how to handle\n(e.g. which of the class files should we drop?). What about using a genrule\nto run \"zip -d ...\" to remove the offending entries and then have the\noutput plug into the prebuilt_jar rule? Would something like this work for\nyou?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/84#issuecomment-45563017.\n. In the case I was looking at, the two entries were exactly the same.\n\nOn Mon, Jun 9, 2014 at 6:00 PM, andrewjcg notifications@github.com wrote:\n\nYeah, I tend to think of this as being similar to a corrupted JAR in the\nsense that it's something that buck can't and shouldn't know how to handle\n(e.g. which of the class files should we drop?). What about using a genrule\nto run \"zip -d ...\" to remove the offending entries and then have the\noutput plug into the prebuilt_jar rule? Would something like this work for\nyou?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/84#issuecomment-45563017.\n. Thanks, I would suggest that having to list the annotation processors is a pain for users.\n\nThere were actually 3 different ones in the problem I was trying to track down.\nIdeally there would be an option to do what javac does and just use the ones it finds on the classpath.\nIn general annotation processors are \"magic\" and people don't have to configure their build systems to know about them.\n. ",
    "brettwooldridge": "@sdwilsh I'd like to request that this issue be re-opened (and re-visited).  In our case, we do not check-in jars but instead resolve them from maven.  One of our dependencies, org.apache.xmlbeans:xmlbeans:2.6.0, is built with duplicate class entries.\nAs expected, the result is:\nBUILD FAILED: //ThirdParty:xmlbeans failed on step get_class_names with an exception:\nMultiple entries with same key:\n  org/apache/xmlbeans/xml/stream/Location=b010d46296931435514ab3d6237b17e03df64e5b\n  org/apache/xmlbeans/xml/stream/Location=b010d46296931435514ab3d6237b17e03df64e5b\nHowever, as in the case for @rbraunstein, the duplicate classes are identical, yielding the same hash.  As the zlib specification allows duplicate entries, it seems the correct handling would be to simply ignore one of the classes, provided that the hashes match.\nOf course, if the classes are truly different an error is warranted.\nGiven that xmlbeans hasn't updated since 2013 it seems unlikely that an upstream fix will be available in a timely fashion (though we will certainly open an issue there).  At that same time, we are loath to alter our build process to accommodate a single jar issue.  Again, it seems like buck can both easily and safely resolve the issue by simply ignoring classes with identical keys and identical hashes.\nADDENDUM: The recommendation of altering the jar breaks the auditing and security guarantees provided by the SHA1 lineage as published by the originator.\n. Thanks guys.  In the meantime I'm cooking up a pull request for review, looks like a one or two line change.\n. @ryandm Not that it matters so much, but the code in the pull request throws a nearly identical exception to the one previously being throw by guava.\n. @sdwilsh You're welcome.. @artemyarulin I know this is an old issue, but given the contents thought I would ask here.  You mention the sh_binary rule, but I do not see that rule documented.  Looking at some source I can see it is referenced.  I also notice that it is referenced in the documentation for worker_tool but no explanation is given for the possible parameters (other than those in the example).\nIs sh_binary an officially supported rule that is safe to use?\n. @artemyarulin I know this is an old issue, but given the contents thought I would ask here.  You mention the sh_binary rule, but I do not see that rule documented.  Looking at some source I can see it is referenced.  I also notice that it is referenced in the documentation for worker_tool but no explanation is given for the possible parameters (other than those in the example).\nIs sh_binary an officially supported rule that is safe to use?\n. Pull request #1054 addresses this issue.. @Coneko How can I run the lint task from my fork?  If I rebase and force push to my repo does it mess you up?\n. @Coneko I rebased and force pushed up to my repo.  It is building now.  Is line length on the two exception throws the only issue?  I turned on Checkstyle and that seems to be it (other than carping about import ordering, but I didn't change that, so...).\n. @kageiit @Coneko I'm running into something similar working on the improved Kotlin compiler support.  I really want to be able to reference a target in .buckconfig...\n[kotlin]\n  compiler_jar = //ThirdParty/deps:kotlin-compiler\nwhere there is a rule:\nprebuilt_jar(\n   name = 'kotlin-compiler',\n   binary_jar = 'kotlin-compiler-1.1.1.jar',\n   visibility = ['PUBLIC'],\n)\nBut for the life of me I cannot figure out how to get the resolve to work.  I get a similar error to that above:\nBUILD FAILED: Rule for target '//ThirdParty/deps:kotlin-compiler' could not be resolved.\nIt would be nice to be able to simply change the jar version in the rule.  If the .buckconfig must contain a path the user has to update multiple places.  Is there any workaround to inject kotlin-compiler into the target graph without having a rule explicitly depend on it?  SourcePathResolver clearly finds it, but BuildRuleResolver of course fails.\n. @kageiit @Coneko I'm running into something similar working on the improved Kotlin compiler support.  I really want to be able to reference a target in .buckconfig...\n[kotlin]\n  compiler_jar = //ThirdParty/deps:kotlin-compiler\nwhere there is a rule:\nprebuilt_jar(\n   name = 'kotlin-compiler',\n   binary_jar = 'kotlin-compiler-1.1.1.jar',\n   visibility = ['PUBLIC'],\n)\nBut for the life of me I cannot figure out how to get the resolve to work.  I get a similar error to that above:\nBUILD FAILED: Rule for target '//ThirdParty/deps:kotlin-compiler' could not be resolved.\nIt would be nice to be able to simply change the jar version in the rule.  If the .buckconfig must contain a path the user has to update multiple places.  Is there any workaround to inject kotlin-compiler into the target graph without having a rule explicitly depend on it?  SourcePathResolver clearly finds it, but BuildRuleResolver of course fails.\n. @kageiit The definition is in .buckconfig, but the resolution (by the kotlin build rule) is not needed until after the target graph is complete.  But at that point the target graph is immutable, and so nothing can be injected.  Basically, it seems like buck needs to include rule references defined in .buckconfig in the target graph.\nI mistyped before, basically we have a remote_file rule that downloads the kotlin-compiler.  But obviously the version changes, for example, from kotlin-compiler-1.0.jar to kotlin-compiler-1.1.1.jar.  It would be good if the user only has to change the version there, in that one place.  But if the reference is by path, then the .buckconfig must also change to reflect the new version.  However, if the reference in .buckconfig is to a rule target, that name is constant regardless of what the actual version is.\n. @kageiit The definition is in .buckconfig, but the resolution (by the kotlin build rule) is not needed until after the target graph is complete.  But at that point the target graph is immutable, and so nothing can be injected.  Basically, it seems like buck needs to include rule references defined in .buckconfig in the target graph.\nI mistyped before, basically we have a remote_file rule that downloads the kotlin-compiler.  But obviously the version changes, for example, from kotlin-compiler-1.0.jar to kotlin-compiler-1.1.1.jar.  It would be good if the user only has to change the version there, in that one place.  But if the reference is by path, then the .buckconfig must also change to reflect the new version.  However, if the reference in .buckconfig is to a rule target, that name is constant regardless of what the actual version is.\n. I'll re-run them and fix the affected ones.. I'll re-run them and fix the affected ones.. I rebased without any changes and I got no failures in the tests covering these components.. I rebased without any changes and I got no failures in the tests covering these components.. Yup.  I just realized that the build on my Mac is skipping all of those tests because of an Android SDK assumption.  So running buck test //.... was returning no failures.  I'm not an Android developer so the SDK is not installed.  Once that is done it should be quick work to fix the tests.. Yup.  I just realized that the build on my Mac is skipping all of those tests because of an Android SDK assumption.  So running buck test //.... was returning no failures.  I'm not an Android developer so the SDK is not installed.  Once that is done it should be quick work to fix the tests.. Done.. Done.. @dsyang @kageiit I have coincidentally started working on in-VM compilation of kotlin rather than shelling out, based on code hijacked from the kotlin ant task.  I can sweep up this issue at the same time.\n. @dsyang As I understand it, this is basically a sequential compilation currently, correct?  Meaning Kotlin and then Java.  So the following, in a single project would not be supported?\nA.kt extends B.java\nB.java references C.kt\n. @dsyang I've got big plans for the coming weeks. \ud83d\udc4d  Probably before this feature I will tackle autodeps support, which entails prying into kotlin-compiler.jar to get at the AST parser.. @kageiit Thanks.  I stumbled across that, and didn't realize what I was looking at, and moved on...\n. @kageiit If any one of you is adventurous, you can try my kotlin-compiler2 branch (in my fork).  It does not support mixed compilation yet but will soon.  It uses the kotlin compiler daemon under the covers (1.1 required).\nI am interested in any build performance metrics you can provide.\n. @kageiit I'll look into it, seems feasible.  Still interested in feedback on performance.. @kageiit If you are interested in testing the latest changes, I have updated my kotlin-compiler2 branch of my fork.  The Kotlin compile daemon is now started in-process with the buck daemon.\nIt seems to work on my current Kotlin project.  Successive runs, deleting buck-out between, saw decreasing compile times:\n```\n[-] PROCESSING BUCK FILES...FINISHED 0.2s [100%] \ud83c\udfd6  Watchman reported no changes\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 27.8s [100%] (453/453 JOBS, 453 UPDATED, 453 [100.0%] CACHE MISS)\n    Details: http://localhost:53857/trace/548a1968-c52b-4bfa-bb01-48894bd91c97\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83c\udfd6  (Watchman reported no changes)\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 19.6s [100%] (453/453 JOBS, 453 UPDATED, 453 [100.0%] CACHE MISS)\n    Details: http://localhost:53857/trace/570bf15f-ebe9-43de-ab20-39635dcb2179\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83c\udfd6  (Watchman reported no changes)\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 18.2s [100%] (453/453 JOBS, 453 UPDATED, 453 [100.0%] CACHE MISS)\n    Details: http://localhost:53857/trace/2a881c98-2db2-4bce-be67-b3f5d338c77c\n[-] PROCESSING BUCK FILES...FINISHED 0.0s \ud83c\udfd6  (Watchman reported no changes)\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 16.5s [100%] (453/453 JOBS, 453 UPDATED, 453 [100.0%] CACHE MISS)\n    Details: http://localhost:53857/trace/00e7dd26-81fb-41eb-bf96-d59959e61d6e\n. @kageiit I'm sure you know the drill, but just in case, I have been running:\ncd \nant clean ; ant ; bin/buck build buck\n`\nAnd then doingexport PATH=/bin:$PATHin the shell I build my Kotlin project in.\n. Good question.  I have nothing in my.buckconfig.  There is [code there](https://github.com/brettwooldridge/buck/blob/kotlin-compiler2/src/com/facebook/buck/jvm/kotlin/KotlinBuckConfig.java) to try to find the Kotlin jars, and you should be able to explicitly definedaemon_jar,compiler_jar, andruntime_jar`` locations.  Untested.\nEDIT: If it can't find the daemon jar, it should fallback to external execution (also untested).\nEDIT2: 2:30am here in Tokyo, I'm headed to bed.  I'll pick up the thread in the morning if you run into any issues.\n. @kageiit I'm not surprised.  I rebased a few weeks back onto a stable commit.  Once I get the code closer to where it needs to be I'll fight the rebase fight (unless someone wants to do it can give me a pull request).\nGreat to hear about the speed improvement!\nSomebody might try sending mixed sources into the target (.java and .kt), I haven't gotten around to trying it yet, but there is no code explicitly forbidding it.\n. @kageiit @dsyang @ilya-g Does anybody know what the specific purpose of the CompilerId Kotlin class is, for example, CompilerId compilerId = CompilerId.makeCompilerId(compilerIdPaths).\nMy current code has a hack to work around a strange issue I encountered...\nI thought it was sufficient to start one Kotlin compiler daemon instance, but if I do so, I get sporadic failures trying to connect.  The hack is, if I get a connection failure, I start another in-process daemon instance and try the connection again.\nI thought this might have something to do with the ComplierId, if for example, that is supposed to somehow be unique per client-invocation, but looking at it, that doesn't seem so...\nIt may be a simple race condition within the compiler daemon itself, as Buck probably tries to initiate several connections in extremely rapid succession (i.e.. simultananeously).\nAny ideas?\n. @ligee Thanks!  That leads to more questions.  We want the daemon to live for the life of the buckd process (i.e. possibly hours or days).  If I use the lease, what does the daemon do when the last lease is released?  Does it exit?  \nAnother question.  It seems we need multiple daemon instances running, is that expected?  I thought we could start one daemon instance, and then run compiles from N number of threads, but it seems to want multiple daemons, possibly one per thread.  Is that expected?\n. @kageiit I have rebased my changes onto master; what a pain in the a**.  I also implemented the daemon leasing scheme suggested by @ligee.  That means that Kotlin 1.1.1 is required.\nThe new branch is kotlin-compiler (not kotlin-compiler2).  It seems to be working, but I know the code still needs some work.\n3:45am here so I'm knocking off for tonight.  Let me know how it works for you.\n. @dsyang @kageiit I ditched the Kotlin daemon changes.  buckd is already a daemon, so now I directly instantiate a K2JVMCompiler that is kept alive for the lifetime of buckd. Performance seems to be identical to the previous incarnation but the code is substantially simpler.\nGive it a try if you have a chance.\n@dsyang I'll try to put together a pull request.\nEDIT: Because we no longer use the Kotlin daemon API, and that was part of Kotlin 1.1.1, the current changes should be backward compatible to Kotlin 1.0.\n. @dsyang @kageiit I ditched the Kotlin daemon changes.  buckd is already a daemon, so now I directly instantiate a K2JVMCompiler that is kept alive for the lifetime of buckd. Performance seems to be identical to the previous incarnation but the code is substantially simpler.\nGive it a try if you have a chance.\n@dsyang I'll try to put together a pull request.\nEDIT: Because we no longer use the Kotlin daemon API, and that was part of Kotlin 1.1.1, the current changes should be backward compatible to Kotlin 1.0.\n. Rebased again.  Gd help me buck moves too fast, that was painful.. Rebased again.  Gd help me buck moves too fast, that was painful.. @dsyang @kageiit Can either of you shed light on what this is about, and how it is used from an external .buckconfig or BUCK file perspective?\n. @dsyang @kageiit It seems my mental image of \"mixed source\" was off (I don't use mixed source).  Looking at the existing Kotlin build tasks (ant/maven), \"mixed source\" compilation seems to simply mean \"invoke kotlinc, then invoke javac\".\nSo, in summary, is this issue basically about being able to do the following?\nkotlin_library(\n    name = 'project',\n    srcs = glob(['**/*.kt', '**/*.java']),\n)\nWith the result being a .jar file of compiled Kotlin and Java classes?\n. @dsyang @kageiit It seems my mental image of \"mixed source\" was off (I don't use mixed source).  Looking at the existing Kotlin build tasks (ant/maven), \"mixed source\" compilation seems to simply mean \"invoke kotlinc, then invoke javac\".\nSo, in summary, is this issue basically about being able to do the following?\nkotlin_library(\n    name = 'project',\n    srcs = glob(['**/*.kt', '**/*.java']),\n)\nWith the result being a .jar file of compiled Kotlin and Java classes?\n. @kageiit Ok, thanks.  That's next on the agenda then.. @kageiit Ok, thanks.  That's next on the agenda then.. I did consider that.  But as far as I can tell, none of the tests are run anyway because of KotlinTestAssumptions.\nASSUME  <100ms  0 Passed   1 Skipped   0 Failed   com.facebook.buck.jvm.kotlin.KotlinBuckConfigTest\nASSUME   171ms  0 Passed   3 Skipped   0 Failed   com.facebook.buck.jvm.kotlin.KotlinLibraryIntegrationTest\nASSUME  <100ms  0 Passed   4 Skipped   0 Failed   com.facebook.buck.jvm.kotlin.KotlinTestIntegrationTest\nMy intention is to actually remove that assumption when I implement in-VM compilation (and include kotlin-compiler.jar in third-party).\nUPDATE: It goes without saying that the existing tests pass locally, where kotlin is present.. BTW, the build failure is unrelated to these changes.  Should I rebase against a commit that passes the build?\n. @kageiit I disagree.  While it is certainly valid to allow specifying a kotlin compiler and runtime jar in buckconfig, it should not be required.  Doing so makes a project non-portable unless the project also includes both the jars in its own repository.  It is the least desirable option.\nI have three versions of Java installed, and two versions of Scala, and I switch accordingly, without the need to edit anyone's project build files, by setting the appropriate environment variable and environment path.  The same is possible with Kotlin.. @sdwilsh Agreed, if the compiler/runtime is defined in the buckconfig that should override everything.. @kageiit I don't see Java or its runtime components in the repositories of projects I've encountered, maybe that is done \"at scale\", but the majority of ant, maven, gradle, and buck users probably don't expect that.\nAs far as I know, Kotlin has committed to binary compatibility, so I don't know under what conditions a shared cache wouldn't work in any case.. That I definitely agree with 100%.. Rebased w/changes.  Tests coming soon'ish.. @dsyang Just pushed a commit, didn't see your most recent comments, so it does not include those changes.  But it does include a set of new unit tests.\n. @dsyang I think this is ready for final review.. Removed synchronized.. @dsyang Thanks!  Massive work on in-process compiler support is under way.. @illicitonion I don't think this can work because of how buck invokes g++.  This is a long standing issue with travis-ci.  The only fix I've found that works is this.  \nBasically, we can't use lightweight containers if we want to switch g++ versions ... at least not unless/until buck honors CXX and CC environment variables.  We must use a sudo: true (heavy-weight container) in order to switch the symbolic link for /usr/bin/g++.  Unfortunately, this has a rather bad impact on the container performance (~44 minute build instead of ~24 minute builds).\n. @illicitonion This build demonstrates the \"fix\".  I think the actual fix is for buck to honor the CXX environment variable over the hard-coded default path.  If it does, the travis build can be made to run with a simple export CXX=... instead of sudo update-alternatives ....\n. b503b5a mimicked this fix, closing.. @illicitonion @Coneko Can you review this?  It removes the hard-coded paths for the C/C++ compilers (well, it does fall-back to them if they are not in the path), which allows the travis-ci build to return to running in container mode; cutting build times from ~45min to ~25min.\n. @illicitonion I appreciate the review.  Unfortuntely, I don't have any more time to invest in this side-trip.  My goal was to minimize the amount of change while making the code \"no worse\" than it already was.  Given the previous hardcoded values, I feel it is appreciably better.   My intention was re-enabling the containerized travis-ci build, which we in the community depend on quite heavily, to complete in a reasonable time.  I am more than happy if someone else wants to take up the challenge of the above refactors.\n. I feel like I've entered into a parallel universe where it is \"correct\" to hardcode tool paths.\nI'm on MacOS, why not change buck_tool.py from using that which(\"java\") function and just drop in the string \"/Library/Java/JavaVirtualMachines/jdk1.8.0_111.jdk/Contents/Home/bin/java\"?  I know, I know, maybe there are some users that doesn't work for, but we could allow specifying the location of Java in .buckconfig.  Like Lua, we could add a setting in the [java] section:\nini\n[java]\n  java = /usr/bin/java\nOr -- now just let me finish because I know how crazy it sounds -- maybe all external tool executables should be located by the equivalent of which() by default.. This refactor represents my final effort on this issue.. @illicitonion If you look at the latest commit, System.getenv() is no longer called.  The code uses the environment as it is passed up through CxxBuckConfig, which delegates to the BuckConfig that is passed up the chain.\nThe code always had an issue in that if gcc is updated buck may not rebuild.  Just because the compiler path was hardcoded to /usr/bin/gcc doesn't imply that gcc can't and hasn't changed.  Installation paths such as that are as much the environment as anything.\nCORRECTION: System.getenv() is called in the unit test, but I don't see any other option there.. @illicitonion While it is not a \"huge burden\", it has the feeling of busy work.  The existing tests never covered the case where /usr/bin/gcc might change, and it feels like I'm being asked to add a test to cover a quite frankly more obscure scenario.  I consider it highly more likely that a user might do a yum upgrade gcc than the likelihood that a file named gcc that was previously in the path but not executable suddenly becomes so.\nI don't mean to be a dick, but honestly I've spent a full day on this, and I'm not collecting a paycheck from Facebook.  My company doesn't even have any C/C++ code in a buck project; this honestly has nothing to do with our use of buck.  I've merely made this change because the process of submitting other contributions (namely improved kotlin support) became increasing painful when the continuous build jumped from 24 minutes to 45.  I understand that is not a pain that Facebook feels, as your continuous build servers are internal.\nI was trying to get this in before the holidays, but unfortunately in 16 hours from now I will be on an airplane (and it is 11pm here in Tokyo).\nI am sorry if you are not comfortable with the request as it stands, or if you yourself are not willing to pitch-in to add the unit test you'd like to see, but as I said above, the last commit was my final one on this pull request.  Thanks for you time.\n. @LegNeato Thanks for the test.  I fixed it.  Essentially an issue of needing to make the generated shell scripts executable.  I've merged into my  branch, and running a last local test before pushing it.\n. @illicitonion @sdwilsh Thanks to @LegNeato a test was added verifying that if the contents (hash) of the clang++/g++ binary change, that a build is re-triggered appropriately.  This pull request is ready for review.\n. @illicitonion Is there anything else needed for this pull request?\n. @Coneko I think the real solution is to break up some of the Android unit tests into multiple files.. @Coneko I think the real solution is to break up some of the Android unit tests into multiple files.. @Coneko Woohooo! Only one failure TESTS FAILED: 1 FAILURE, in the go tests.. @kageiit Nope.  Because this works:\npython\ngenrule (\n  name = 'dist-server',\n  bash = 'echo $(query_targets \"deps(//netld/provider.collection:com-dancer-provider-collection-kt)\") >$OUT',\n  out = 'dist-server.txt',\n)\nIf I replace //netld/provider.collection:com-dancer-provider-collection-kt with //... it fails the same way.  I.e. it only seems to work with a specific target (one with a :).\n. @asp2insp Thanks.  We sliced the cake in a different way to solve our use case.. @kageiit I should have been clear.  This contains changes toward support of kapt, i.e. it lays the foundation for completion of #956.  We now invoke the K2JVMCompiler.exec() method, which winds up here in the CLICompiler.  It is a short distance to go to thread the correct configuration through from buck.\n. @kageiit I should have been clear.  This contains changes toward support of kapt, i.e. it lays the foundation for completion of #956.  We now invoke the K2JVMCompiler.exec() method, which winds up here in the CLICompiler.  It is a short distance to go to thread the correct configuration through from buck.\n. @kageiit Just to be clear, this pull request was not made because the code is ready to merge, it was made due to @dsyang request:\n\nWould you be comfortable putting your changes in kotlin-compiler up in a PR so we could start reviewing it?\nI know there's still some work that you'd like to do but this could make it easier to merge later down the line.\n. @kageiit Just to be clear, this pull request was not made because the code is ready to merge, it was made due to @dsyang request:\nWould you be comfortable putting your changes in kotlin-compiler up in a PR so we could start reviewing it?\nI know there's still some work that you'd like to do but this could make it easier to merge later down the line.\n. @kageiit @dsyang I keep rebasing it once a week or so.  I've got a tiny bit of cleanup now that I realized that it was not possible for an entry in the .buckconfig to reference a prebuilt_jar rule.  Give me 'til Monday or so before doing any hasty merging.\n\nThe good news is that our development team has been using this branch as our primary buck and compiling lots of Kotlin code for well over a month.\n. @kageiit @dsyang I keep rebasing it once a week or so.  I've got a tiny bit of cleanup now that I realized that it was not possible for an entry in the .buckconfig to reference a prebuilt_jar rule.  Give me 'til Monday or so before doing any hasty merging.\nThe good news is that our development team has been using this branch as our primary buck and compiling lots of Kotlin code for well over a month.\n. I'll take a look.  I haven't gotten around to minimizing the diffs. Just working on the unit tests.  Once they're cleaned up and running I'll minimize the changes and the pull should be ready.\nI've already rebased on a local branch.  I may be able to push it tonight.. I'll take a look.  I haven't gotten around to minimizing the diffs. Just working on the unit tests.  Once they're cleaned up and running I'll minimize the changes and the pull should be ready.\nI've already rebased on a local branch.  I may be able to push it tonight.. @dsyang I've rebased my changes on to master, but I'm getting a difficult to trace exception from the Kotlin compiler.  Working forward in steps from my April 27 commit, if I rebased onto a May 1 commit then everthing is still working, but if I rebase the same changes onto a May 10 commit I get the same failure.\nIt's 3:30am here, so I'm going to knock off for tonight.  Tomorrow I'll see if I can use git bisect to narrow down the issue, or do a manual bisect.  Seems classloader related, but I wonly't know until I actually find the breaking commit.  If I can resolve the issue on that commit, I suspect the rebase from there to the head of master will go smoothly.\n. @dsyang I've rebased my changes on to master, but I'm getting a difficult to trace exception from the Kotlin compiler.  Working forward in steps from my April 27 commit, if I rebased onto a May 1 commit then everthing is still working, but if I rebase the same changes onto a May 10 commit I get the same failure.\nIt's 3:30am here, so I'm going to knock off for tonight.  Tomorrow I'll see if I can use git bisect to narrow down the issue, or do a manual bisect.  Seems classloader related, but I wonly't know until I actually find the breaking commit.  If I can resolve the issue on that commit, I suspect the rebase from there to the head of master will go smoothly.\n. @dsyang Yes, that is the error.\nI have been running my kotlin branch (literally that is the name) with Kotlin v1.1.1 for some time without that error.  That is the branch from April 27.  When I rebase/merge that into master at May 10th, it fails with that error.  If I merge a bit further back, May 1, it still succeeds.  I feel like it is classloader related (the JarBackedKotlinCompiler uses a distinct classloader).\nI have my rebased changes and cleanup on a branch called kotlin-merge -- failing with the same error.\n. @dsyang Yes, that is the error.\nI have been running my kotlin branch (literally that is the name) with Kotlin v1.1.1 for some time without that error.  That is the branch from April 27.  When I rebase/merge that into master at May 10th, it fails with that error.  If I merge a bit further back, May 1, it still succeeds.  I feel like it is classloader related (the JarBackedKotlinCompiler uses a distinct classloader).\nI have my rebased changes and cleanup on a branch called kotlin-merge -- failing with the same error.\n. @dsyang Here's a thought.  There are significant changes in kotlin-merge.  In Kotlin v1.1.1 it is no longer sufficient to specify a compiler jar and runtime jar, the kotlin compiler does it's own jar discovery based off of the location of the compiler jar, and pulls in other Kotlin jars.\nI am wondering if the mapdb thirdparty component is somehow pulling in the thirdparty/java/kotlin jars -- which may be incompatible with the compiler.  Those are no longer needed or used by the Kotlin integration.\nThe Kotlin compiler integration requires a true installation of Kotlin -- at least it needs all of the jars to be present.  The only .buckconfig variables are now kotlin_home and external (true for kotlinc shell out, false for in-process compilation).\n. @dsyang Here's a thought.  There are significant changes in kotlin-merge.  In Kotlin v1.1.1 it is no longer sufficient to specify a compiler jar and runtime jar, the kotlin compiler does it's own jar discovery based off of the location of the compiler jar, and pulls in other Kotlin jars.\nI am wondering if the mapdb thirdparty component is somehow pulling in the thirdparty/java/kotlin jars -- which may be incompatible with the compiler.  Those are no longer needed or used by the Kotlin integration.\nThe Kotlin compiler integration requires a true installation of Kotlin -- at least it needs all of the jars to be present.  The only .buckconfig variables are now kotlin_home and external (true for kotlinc shell out, false for in-process compilation).\n. The KotlinBuckConfig in the kotlin-merge branch only looks for kotlin_home and external.  I'm pretty sure that the mapdb dependency is the cause.. The KotlinBuckConfig in the kotlin-merge branch only looks for kotlin_home and external.  I'm pretty sure that the mapdb dependency is the cause.. I'm away from my computer now, but maybe it is shading some Kotlin classes?  Maybe I shouldn't speculate... I'll have a chance to look in a few hours.. I'm away from my computer now, but maybe it is shading some Kotlin classes?  Maybe I shouldn't speculate... I'll have a chance to look in a few hours.. @dsyang No clear explanation yet, but removing thirdparty/java/kotlin entirely, and deleting the dependency in thirdparty/java/mapdb/BUCK fixed the issue.  kotlin-merge now runs Kotlin builds against our production code without issue (unit tests may or may not all work, haven't checked them yet).\nOne possibility is, because there are two classloaders (at least), the main Java app classloader, and the one created by JarBackedReflectedKotlinc, that somehow Kotlin stdlib classes were getting loaded in two separate classloaders.  If that proves to be the cause, then in the future, we might need to create a custom classloader for the kotlin compile that is non-delegating -- or at least delegate last rather than delegate first.\n. @dsyang No clear explanation yet, but removing thirdparty/java/kotlin entirely, and deleting the dependency in thirdparty/java/mapdb/BUCK fixed the issue.  kotlin-merge now runs Kotlin builds against our production code without issue (unit tests may or may not all work, haven't checked them yet).\nOne possibility is, because there are two classloaders (at least), the main Java app classloader, and the one created by JarBackedReflectedKotlinc, that somehow Kotlin stdlib classes were getting loaded in two separate classloaders.  If that proves to be the cause, then in the future, we might need to create a custom classloader for the kotlin compile that is non-delegating -- or at least delegate last rather than delegate first.\n. I squashed and pushed kotlin-compiler2.\n. I squashed and pushed kotlin-compiler2.\n. @dsyang Thanks.  Fixed.  Also cleaned up code, minimized diffs, and fixed all unit tests.  Pending further review, I'm done on my end.\nEDIT: Sorry, missed some of the feedback above.  I'll address those and update.. @dsyang Thanks.  Fixed.  Also cleaned up code, minimized diffs, and fixed all unit tests.  Pending further review, I'm done on my end.\nEDIT: Sorry, missed some of the feedback above.  I'll address those and update.. A bunch?  The only missed ones I found was the change to getPathToCompilerBinary() and the comment on KotlincStep:117.  Both are pushed now.\n. I'm not sure what is particularly \"heavy\" about the testdata directory, given that it is merely a \"structure\" and the \"binaries\" and \"jars\" themselves are merely files of several dozen bytes.\nI have complained before about truly heavy testdata contents like that used by the scala tests, but it seems to fall on deaf ears.  Scala testdata has the scala compiler (15MB) and various other scala jars (~10MB) checked in multiple times -- totaling over 100MB.  By comparison, I'm not particularly concerned about three folders with fake binary files totaling a 100 bytes or so.\n. Done.  I left the kotlin_compiler_test unchanged as that code was not touched by this PR.\n. I see you started the merge, does that mean you are going to address the \"nits\", or do you still want me to change and squash them?  I'm out of the office right now but I could do it when I get in.. @dsyang That push should fix the warning.\n. Rebased onto master.\n. @kageiit @dsyang Anything else waiting on me here?\n. @kageiit Jesus, do we really need all these refactors that apparently touch almost every class in the tree?\n. @dsyang @kageiit Just checking on this.  It is closed, but not merged?  A little concerned, because pull #1358 seems based off of the existing mainline but will surely create conficts if merged before this.\n. @sdwilsh Sorry, I missed the facebook-github-bot closed this in 800d5a9 9 days ago message.  I guess the next question is, when might we see this is a release?\n. Maybe run dbuck and breakpoint in the catch block.  Is kotlin-stdlib in the classpath?. I've been thinking about that.  I'll take a look.. On a possibility related note, I occasionally encounter cross module compilation issues (application runtime errors actually) when Kotlin code has been changed, which indicate that the Kotlin ABI changed but buck did not realize it and therefore did not recompile a dependent class.  I suspect that, even though Kotlin generates valid bytecode, there are some nuances that are missed by bucks ABI hashing.. Unfortunately, metalava is not yet released (according to the commit history).... Considerably DRYer.. @kageiit LGTM. @dsyang Is this pull request dead? . @ttsugriy @jkeljo Found it.  Java 9 issue.  Pull request coming...\n. @jkeljo Two issues...\nFirst, asm v5.0.3 cannot grok any Java 9 class files, which blows up the ABI calculation code in buck -- in my case when log4j2 v2.9.0 is used.\nSecond, apparently the module-info.class itself that is contained within the log4j2 maven artifact contains invalid class information even when asm v6-Beta is used.  Unclear whether this is an asm issue or log4j2 issue.  Excluding module-info.class across the board allows the ABI calculation code to succeed for all of the other Java 9 classes in the log4j2 jar.\n. @jkeljo Two issues...\nFirst, asm v5.0.3 cannot grok any Java 9 class files, which blows up the ABI calculation code in buck -- in my case when log4j2 v2.9.0 is used.\nSecond, apparently the module-info.class itself that is contained within the log4j2 maven artifact contains invalid class information even when asm v6-Beta is used.  Unclear whether this is an asm issue or log4j2 issue.  Excluding module-info.class across the board allows the ABI calculation code to succeed for all of the other Java 9 classes in the log4j2 jar.\n. @ttsugriy It is absolutely not safe to ignore module-info.class with respect to computing the ABI. \ud83d\ude01  Having said that, because of either a bug in asm v6-Beta, or more likely an invalid module-info.class in the log4j2 artifact, the log4j2 jar is not grok'able by asm (and therefore buck) unless that class is excluded.\nPresumably, by the time Java 9 goes GA, either asm or log4j will have gotten their act together, at which point the exclusion can be removed.  Also presumably, additional buck changes are likely to be required to support Java 9.\n. @ttsugriy It is absolutely not safe to ignore module-info.class with respect to computing the ABI. \ud83d\ude01  Having said that, because of either a bug in asm v6-Beta, or more likely an invalid module-info.class in the log4j2 artifact, the log4j2 jar is not grok'able by asm (and therefore buck) unless that class is excluded.\nPresumably, by the time Java 9 goes GA, either asm or log4j will have gotten their act together, at which point the exclusion can be removed.  Also presumably, additional buck changes are likely to be required to support Java 9.\n. It should be noted, we couldn't care less about Java 9 support (we use Java 8).  We just wanted to use log4j2 v2.9.0, which apparently contains both Java 7/8 as well as Java 9 classes that end up choking asm 5.0.3.\n. It should be noted, we couldn't care less about Java 9 support (we use Java 8).  We just wanted to use log4j2 v2.9.0, which apparently contains both Java 7/8 as well as Java 9 classes that end up choking asm 5.0.3.\n. @jkeljo @ttsugriy I'm on board with those suggestions.  I'll make the changes and update the pull request in the next 24h.  Thanks for your feedback.. @jkeljo @ttsugriy Sorry for the delay.  Pull request updated with exclusion of module-info.class removed.. @jkeljo BTW, what is the blacklist in java_library that you speak of, I do not find it in the documentation?\nNot to be too critical, but I can now count a handful of times when I've come across undocumented build rule properties mentioned in answers to issues etc.  In my opinion, a property should either be supported and documented, or supported and documented as experimental -- or it shouldn't exist.\nIf it exists in the documentation, even if flagged as experimental, the community has an opportunity to provide feedback on its usefulness or behavior.  Otherwise, users end up baking undocumented properties into their BUCK files, laying landmines for future developers maintaining those files should the property disappear or the behavior be altered.\n. @ttsugriy This smells like the same error I got when I was not excluding module-info.class, and indicates to me that it may well be a bug in ASM.  I will investigate further this week.\n. @ttsugriy Awaiting the outcome of the automated builds, but I think I've addressed the issue.. @ttsugriy Cool.  My local test run passed without error (er, at least without related errors).. @ttsugriy I reproduced the test failure on my Mac as well.  I am assuming it is not transient.  However, it may also be the case that the testcase needs to be updated for ASM 6.0/Java 9 behavior.  It's 4am here in Tokyo, so I'll take a look over the weekend.  If you nail it down or find anything interesting, let me know.\n. @ttsugriy Yeah, I didn't do that.  I always run ant clean ; ant, then bin/buck build buck.  (Really going to bed now) \ud83d\ude29  Thanks for chasing that down.\n... it does look like an additional semicolon is emitted (by ASM6?) and is causing that particular test to fail a literal text match.  I suspect that it is safe to simply update the expected text.. @Sayary I\u2019m late to the party here, but I just wanted to note that the current kotlin_library rule does support out of process execution.. @kageiit Done.. @kageiit Done.. I\u2019m hoping that is an unrelated failure; as far as I know, the Windows code path was completely untouched.. @styurin @kageiit Any update on this pull request status?\n. @styurin Bump.\n. @styurin Bump.\n. @styurin Ok, seeking some advice here.  Here is what I found.  Buck's Windows tasks seem to have been working primarily by luck.\n1/ Buck has code in ListeningProcessExecutor that clears the environment  set in NuProcessBuilder when the ProcessExecutorParams has its own environment defined.  Then, sets the environment from ProcessExecutorParams.\n2/ Prior to the referenced change, NuProcess always injected the environment into the launch of the spawned task (on Windows) -- even if the environment had been cleared.  This was not by design, and did not match either the documented behavior nor the behavior on Linux or MacOS -- basically a bug.\n3/ Separately, and by default, on all platforms, NuProcess always seeds the environment when the NuProcessBuilder is constructed.  This behavior remains unchanged, and mirrors that of Java's ProcessBuilder.\nSo, after the fix to NuProcess, removing the (re-)injection of the environment, the Buck Windows build started to fail.\nThis implies to me that some, or possibly all, Windows tasks are not capable of executing based solely on the environment specified in their ProcessExecutorParams objects.  They were succeeding because NuProcess was re-injecting the environment after it was cleared by Buck.\nThe question is, what should be done?  NuProcess's behavior is now correct.  So either ListeningProcessExecutor needs to not clear the environment in the case of Windows -- basically preserving exactly the previous behavior, or somehow (someone?) needs to determine what the correct environment for Windows is and ensure that the ProcessExecutorParams instances passed in contain that environment.\nThe later feels more \"correct\", but I'm not sure I'd know where to start, since I have no familarity with any of the Windows tasks in Buck.  The former, again, preserves existing behavior exactly, but without correcting what appears to be a larger issue.\nOr is it a larger issue?  Maybe \"merging\" the environment is the correct behavior in the end.  But that's not my call.\n. Updated pull request to NuProcess v1.2.0.  No change with respect to Windows tasks environments.. @ilya-klyuchnikov Do you want me to stub-in a Windows-compatible change to this request that you can remove when your Windows changes are finished?  Something in ListeningProcessExecutor. launchProcess() like:\nJava\n...\n240  if (params.getEnvironment().isPresent()) {\n241     if (Platform.detect().getType() != Platform.WINDOWS) {  // TODO: remove conditional\n242        processBuilder.environment().clear();\n243     }\n244     processBuilder.environment().putAll(params.getEnvironment().get());\n245  }\n. Opps, that was part of the original pull request, I must have rolled it back when I rebased onto the head.. Opps, that was part of the original pull request, I must have rolled it back when I rebased onto the head.. Wait, what?  My master branch shows this as updated to v4.5.1. Wait, what?  My master branch shows this as updated to v4.5.1. @styurin Must have been some kind of delay on github, it now shows correctly.. @cjhopman @ttsugriy I am curious as well.  Is it related to the Windows issues that were uncovered?  If this pull request was merged without those being resolved, I can understand.  But if not, again, I am curious as to any issue encountered (and why NuProcess wasn't notified or this pull request annotated).. @cjhopman @ttsugriy I am curious as well.  Is it related to the Windows issues that were uncovered?  If this pull request was merged without those being resolved, I can understand.  But if not, again, I am curious as to any issue encountered (and why NuProcess wasn't notified or this pull request annotated).. @styurin Do you know what the \"alignment\" issues that @cjhopman refers to were?  Possibly this commit?\n@cjhopman When you say, \"I think it was an easy fix\", what are you referring to?  An easy fix to NuProcess?  An easy fix to Buck?. Commit 267719c5 seems to have broken the AppVeyor build roughly two months ago.\n\nThis build has not succeeded since this commit.. Commit 267719c5 seems to have broken the AppVeyor build roughly two months ago.\n\nThis build has not succeeded since this commit.. Is there any workaround for this?  For example, running buck under Java 8 but compiling under Java 11?\n. @jtorkkola What are the blocking items here?\n. @jtorkkola  Bump.  I am willing to take a look at some of the Java 11 issues, but it would be useful to know what the known items are.\n. @jtorkkola Thanks for the info.  Yeah, I had already run into the annotation issue when trying to compile (source files had been generated, but not compiled), and was investigating whether the newest version of ECJ fixes the issue.  I was curious about switching back to javac, but your reply tells me there are still issues even so.\nBut if ECJ/javac is the main blocking issue, I feel like I can make some progress by diving deeper.\n. @jtorkkola \nStatus update:\nStill pulling the thread ... it looks like an issue/bug in the Immutables library.  Adding the -XprintProcessorInfo and -XprintRounds options to the ecj compiler is now showing this error generated by the immutables library:\nERROR: Generated source file name colission. Attempt to overwrite already generated file: com.facebook.buck.query.TargetLiteral, javax.annotation.processing.FilerException: Source file already exists : com.facebook.buck.query.TargetLiteral. If this happens when using @Value.Immutable on same-named nested classes in the same package, use can use @Value.Enclosing annotation to provide some sort of namespacing\nThis error occurs for roughly 100+ classes, one of them being:\nERROR: Generated source file name colission. ... com.facebook.buck.step.ExecutionContext, javax.annotation.processing.FilerException: Source file already exists : com.facebook.buck.step.ExecutionContext. If this happens when using @Value.Immutable on same-named nested classes in the same package, use can use @Value.Enclosing annotation to provide some sort of namespacing\nWhere ExecutionContext just happens to be the first error reported by the compiler:\n[javac] ----------\n[javac] 1. ERROR in /Users/brettw/Documents/dev/buck/src/com/facebook/buck/android/AabBuilderStep.java (at line 27)\n[javac]     import com.facebook.buck.step.ExecutionContext;\n[javac]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[javac] The import com.facebook.buck.step.ExecutionContext cannot be resolved\nSo, I am now going to debug into the immutables library.  Luckily, the misspelling of \"colission\" in the error message makes it relatively easy to find where the error is being generated as a starting point.\n. @jtorkkola Tracking bug on immutables is here.\n. The latest buck build works for me.  That is to say, buck itself is built with JDK 8, but at runtime JDK 11 is used to build our project.\n. The latest buck build works for me.  That is to say, buck itself is built with JDK 8, but at runtime JDK 11 is used to build our project.\n. @kageiit It sounds from the issue comments that due to being implemented currently as a compiler plugin, it is not yet possible to process external (prebuilt) kotlin jars.  Even so, there could still be some compile time benefits to performing the abi generation when the source is present, to short-circuit unnecessary local module compiles.\n. @kageiit It sounds from the issue comments that due to being implemented currently as a compiler plugin, it is not yet possible to process external (prebuilt) kotlin jars.  Even so, there could still be some compile time benefits to performing the abi generation when the source is present, to short-circuit unnecessary local module compiles.\n. They weren't consistently present for all parameters, and were not present in the JavaLibraryDescription.  We can add them back in; though if we do, they should probably appear after the parameters rather than before to make the code \"prettier\".. @dsyang I did reintroduce these.  I actually to find them useful, where there might be a series of:\njava\nOptional.empty(),\nImmutableList.of(),\nImmutableSortedSet.of(),\nImmutableSortedSet.of(),\nIt actually is useful to read:\nOptional.empty(),        /* proguardConfig */\nImmutableList.of(),      /* postprocessClassesCommands */\nImmutableSortedSet.of(), /* exportedDeps */\nImmutableSortedSet.of(), /* providedDeps */\n. Probably coding too late at night ... because of the check below my brain switched into \"what if two threads are accessing this instance\" mode.  But actually that does not seem possible.  If that is true, and you know better than I, then I can take the synchronized out.. done.. Added @Nullable.\n. @kageiit This can be removed, because everything is done via reflection now.. Java reflection already performs caching, a subsequent call to loadClass() is basically a hash lookup.\n. I just basically mimicked what JarBackedJavac was using.\n. Done.. @dsyang I added additional tests to verify correct behavior.  The supported structures are...\nFor external compilation (external = true defined in .buckconfig):\n * kotlin_home pointing directly at directory containing kotlinc\n * kotlin_home pointing at directory containing a bin directory that contains kotlinc\n * KOTLIN_HOME environment variable the same as the above two\n * No kotlin_home defined nor KOTLIN_HOME environment variable, kotlinc in environment PATH\nFor in-process compilation:\n * kotlin_home pointing directly at directory containing kotlin-* JARs 1\n * kotlin_home pointing at directory containing a lib directory that contains kotlin-* JARs\n * kotlin_home pointing at directory containing a libexec directory, that contains a lib directory, that contains kotlin-* JARs\n * KOTLIN_HOME environment variable the same as the above three\n * No kotlin_home defined nor KOTLIN_HOME environment variable, kotlinc in environment PATH, assume kotlinc is in a bin directory, and the true \"kotlin home\" is one directory above that.\n1 This supports the case, actually my company's case, where Kotlin jars are present in the absence of an installation structure.  In our case, outside of buck, we essentially download the jars using maven:\nxml\n<dependency>\n    <groupId>org.jetbrains.kotlin</groupId>\n    <artifactId>kotlin-*</artifactId>\n    <version>${kotlin-version}</version>\n</dependency>. Removed.. Addressed.. All tests passing now.. Done.. When I take these out, I get this error:\nbuck/src/com/facebook/buck/jvm/kotlin/KotlinTestDescription.java:93: error: cannot access com.facebook.buck.android.AndroidPackageable\n    DefaultJavaLibrary testsLibrary = resolver.addToIndex(defaultJavaLibraryBuilder.build());\n                                              ^\n  class file for com.facebook.buck.android.AndroidPackageable not found\nErrors: 1. Warnings: 0.\n. The Kotlin compiler closes the stream and breaks the buck daemon.. I was just following what was present in the java_test documentation.. Yes, Kotlin does use prebuilt_jars, how else could it compile against Java libraries?. This renders correctly.  $binary is actually a parameter.  In the case of kotlin it renders as kotlin_library and in the case of java as java_library.. Done.\n. My preference would be that doc change be part of the mixed-source change.\nIn-memory Kotlin compiler support has been a long time coming. I don't want the publication of the documentation to be gated or delayed by completion and testing on another feature.  . I didn\u2019t realize pull requests needed to update IDE files.  I\u2019ll be happy to update it though.. ",
    "leiyangyou": "Could we not expose a mean to add additional processorpath entries?\n. ",
    "tageorgiou": "Are we not ready to expose annotation_processors, etc?\n. ",
    "dreiss": "We do use code review.  We do frequently leave options undocumented if we think they aren't ready for public consumption.  You're right that it would probably be a good idea to state that explicitly in the commit messages.. For the people seeing this externally, do you know if it started as soon as buckd was enabled, or were you using buckd successfully for a while and an update broke it?\n. Hold off on that for a bit.  We have found one issue and have a fix coming in, so I'd rather you try to get a repro after that.\n. There should be an update coming in a few minutes.  Before trying to repro, please add a .bucklogging.properties or .bucklogging.local.properties to your project with the following contents\ncom.facebook.buck.util.WatchmanWatcher.level=FINER\ncom.facebook.buck.util.DefaultFileHashCache.level=FINER\nAfter your first build, make sure that buck-out/log/buck-0.log contains a \"Full JSON\" line, which will include the full response we got from watchman.\n. @dborowitz , thanks for that range.  The bug we've found was introduced by f528a763af46839f98dedf23d974a4694988bb26, which is in that range.  It's a Buck issue, so at this point we suspect that watchman is working fine.  @wez informs us that the Watchman behavior that triggers this bug is most likely to happen on Linux, so I'd be very interested to know if anyone is seeing this on non-Linux systems.\n. I think IntelliJ has a very elegant solution to this (for max_watches being too low, not necessarily max_queued_events): it just warns you once the limit is hit and points you to a doc with an explanation.  I filed https://github.com/facebook/buck/issues/172 for watchman/buckd to do the same thing.\n. Can you explain why you want to do this?\n. @byronwind, I think I understand.  You want classes to be forced into the primary dex by default, and have patterns to specify what is allowed to go into the secondary dex?\nI think that is possible, but I would not recommend it.  Our only supported use case for secondary dex files right now is exopackage (see http://facebook.github.io/buck/article/exopackage.html).  In exopackae builds, only the bare minimum of bootstrap code should be in the primary dex, and the vast bulk of your application should be in secondary dex files.\n. @simpleton, in that case, you are probably better off using the techniques described in http://android-developers.blogspot.com/2011/07/custom-class-loading-in-dalvik.html\n. @simpleton, in that case, you are probably better off using the techniques described in http://android-developers.blogspot.com/2011/07/custom-class-loading-in-dalvik.html\n. > I tried decompiling the two apks and diffing the AndroidManifest.xml files and there isn't anything different other than a few  tags (which are different on purpose).\nDid you use apktool or aapt dump xmltree?  IIRC, apktool doesn't show the target-sdk, which could cause hardware acceleration to be disabled.\nP.S.: What's up, Brandon?\n. We had another user complain of poor performance, and it turned out to be an improper targetSdk, which was disabling hardware acceleration.  \"decompiling\" suggested apktool, which I know from (painful) experience leaves out targetSdk.\nThings are going well here.  I don't really work on Buck anymore, but I'm doing more NDK stuff, which means I'm always tuned in to Buck's NDK support.\n. Also, you should always use \"diff -u\".  The output is much easier to read, IMO.\n. This looks fine to me, though the default flags should be updated to match https://android.googlesource.com/platform/ndk.git/+/nougat-release/build/core/toolchains/aarch64-linux-android-4.9/setup.mk .\n. This looks fine to me, though the default flags should be updated to match https://android.googlesource.com/platform/ndk.git/+/nougat-release/build/core/toolchains/aarch64-linux-android-4.9/setup.mk .\n. @LegNeato , can you PR it just so we can use our normal import/CLA machinery?  We can probably get someone else to handle the rebase, cleanup, and test.\n. @LegNeato , can you PR it just so we can use our normal import/CLA machinery?  We can probably get someone else to handle the rebase, cleanup, and test.\n. Using exopackage (https://buckbuild.com/article/exopackage.html) will allow you to skip apk_builder for most incremental builds.\n. Using exopackage (https://buckbuild.com/article/exopackage.html) will allow you to skip apk_builder for most incremental builds.\n. Can you paste the full error message?  Does your AppShell depend on the android_build_config?\n. Can you paste the full error message?  Does your AppShell depend on the android_build_config?\n. Oh, yeah.  I think this is a known issue.  The BuildConfig that IntelliJ sees will be different from what's actually used by Buck to compile.\n. Oh, yeah.  I think this is a known issue.  The BuildConfig that IntelliJ sees will be different from what's actually used by Buck to compile.\n. Can you paste the error message?\n. The way we've done this in Facebook for Android is to define the real jar as rule like \"hadoop-client-private\" that has restricted visibility, then a wrapper java_library (\"hadoop-client\") that lists hadoop-client-private as a provided_dep and exported_dep.\nI agree that this is a bit cumbersome and it would be convenient to just specify it on the jar.\n. Hrm.  I'm sure it works for building Android apps, but it's possible that java_binary works differently.\n. Does this work?  It seems like there's no way to guarantee that the resource ids we generate in dummy_r_dot_java will be the same as what goes into the uber R.java and the resource bundle.  (In fact, it's practically guaranteed that they won't.)\n. Does this work?  It seems like there's no way to guarantee that the resource ids we generate in dummy_r_dot_java will be the same as what goes into the uber R.java and the resource bundle.  (In fact, it's practically guaranteed that they won't.)\n. > It would be nice if butterknife could run in a mode where it doesn't inline the constants\nI don't think this is possible.  Values in annotations need to be inlined constant values, not field references.\n\nCan you expand on what do you mean by it being slow?\n\nIt scales non-linearly and is extremely slow for large apps.\n\nIt still has to run atleast once during compilation.\n\nNot necessarily for incremental compilation.  But even when it is necessary, we want to compile java code while it's running.\n\nIf we were to enable running aapt before only for the binary I think we can still share the result of compiling individual java/android libraries\n\nI don't understand.  For normal android_library rules, we need to use non-final resource ids so the results can be shared between different apps.\nI think the solution in Shawn's comment is the right one.\n. > It would be nice if butterknife could run in a mode where it doesn't inline the constants\nI don't think this is possible.  Values in annotations need to be inlined constant values, not field references.\n\nCan you expand on what do you mean by it being slow?\n\nIt scales non-linearly and is extremely slow for large apps.\n\nIt still has to run atleast once during compilation.\n\nNot necessarily for incremental compilation.  But even when it is necessary, we want to compile java code while it's running.\n\nIf we were to enable running aapt before only for the binary I think we can still share the result of compiling individual java/android libraries\n\nI don't understand.  For normal android_library rules, we need to use non-final resource ids so the results can be shared between different apps.\nI think the solution in Shawn's comment is the right one.\n. > Obviously this means that if you need to use butterknife, it needs to be a src of the binary, and not part of a library.\nNote that this is the case with Gradle as well.\n. > Google announced a new aapt at Google I/O yesterday that is not supposed to rewrite the IDs when packaging\nDo you have a link for this?  I'll check it out and see if it might be able to solve this in a different way.\n. I think I found the reference.  It looks like they just improved its ability to produce compatible output from run to run.  That wouldn't help us with library projects, though.\n. > If you got butterknife to refer to fields\nThis is non-trivial.  See https://github.com/JakeWharton/butterknife/issues/100 .  I look forward to seeing  your PR, @kageiit .\n. Ignoring warnings seems kind of bad.  Maybe we can find a way to pipe this through Buck's console abstraction to avoid stalling the console.\nDo you know where the source for that class is?  I don't see it in the haha repository.\n. Do you know if this is handled upstream by the manifest merger?  We've been talking about upgrading it for a while now.\n. Okay, I guess this is fine.  I see a few issues with the diff.\n1. Doing this work in getShellCommandInternal is super confusing.  That method should have no side effects.  This should run in a separate step that happens before AaptStep.\n2. Overwriting the same file can be confusing for debugging, especially if it is actually the output of another rule.  This new step should create a new AndroidManifest.xml file that is the result of the substitutions.  It can replace the symlink currently generated at the beginning of AaptPackageResources.getBuildSteps.\n3. Make sure to call recordArtifact on the file you generate.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Added a bunch of inline comments.  Looks good overall.  I notice that you're not explicitly specifying the package of FinalR.  That's fine as long as it's intentional.\n. @facebook-github-bot import\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. For context, this affects debug builds and exopackage.\n. For context, this affects debug builds and exopackage.\n. I have a feeling that undoing 4cf0eb7 could open up edge cases that would be a pain to deal with.  I'm now thinking that doing the fully-qualified name tracking is the best way to go.  Want to give it a shot and see whether the perf impact is measurable?\n. Wait, wall duration went from 15 seconds to 26 seconds?  That doesn't seem possible...\n. What about the time in computeReferencedResources in dexer/Main?\n. Looks like AndroidBinaryIntegrationTest and TrimUberRDotJavaTest are failing.  Want to take a look?\n. Otherwise, the change looks fine.\n. We originally added receive-file so we could use run-as to put the files into the app's private data directory.  Now that we put them into /data/local/tmp, this might work fine.  I need to think about it a bit.\n. Oh, I think I remember the other problem.  This creates files with mode 777 (or 666), so there's a window where a malicious process could tamper with them.  The agent's umask forces the file to be created with the correct permissions, if I recall correctly.\n. Yeah, but I still consider it unsafe to allow any app on the phone to inject code into your development app.\n. Sorry for the delay.  It looks like the patch failed to apply.  Can you rebase and update?. Sorry for the delay.  It looks like the patch failed to apply.  Can you rebase and update?. This had to be reverted due to a test failure. :(  I'll revive it and get more details.. Yeah, this is definitely breaking some of our tests.  Some people who understand resources better than I do are trying to figure out exactly why.  It looks something like \"now that the styleables are reporting proper resource ids, we're trying to load the resources (fonts) and failing because our resource path is not properly set.\"  I'll ping them.. Hrm.  Is this for android_library or java_library?  For android_library, you should be building against android.jar instead of rt.jar.  Does android.jar not have the classes you need for lambdas?\n. Discussed this in chat.  Okay to close?\n. Discussed this in chat.  Okay to close?\n. I'd like to see a profile that shows a non-trivial fraction of build time being spent in this code on some real build.  If we can produce that, I'd be in favor of this.\n. Gautam and I discussed this on Slack.  For context, we considered implementing this a while back, but decided not to because we (Facebook) don't want to use it.  That said, I think we'd be open to a PR for this, as long as it's possible to disable.\nI foresee two likely sticking points:\n- The test running phase is currently pretty different from the building phase, but this is a fairly superficial problem.\n- It's not clear how the cache should work in the presence of test filters.  This is probably mostly a user-expectation problem.\n. Can you rebase this?  I fixed some of the annotations that should not have been referencing the Android versions.\nCan you also update the readme with enough detail for me to ensure that the steps can be reproduced?\nI'll also need to check that this doesn't break any of our existing manifest merging at FB.\n. Okay, I'm going to start sorting through the errors now.  The first one is really annoying: when there's a duplicate element conflict, it shows you the full path to the second occurrence, but only the basename of the first.  But all of our basenames are the same!. Okay, I'm going to start sorting through the errors now.  The first one is really annoying: when there's a duplicate element conflict, it shows you the full path to the second occurrence, but only the basename of the first.  But all of our basenames are the same!. Yeah, it breaks some stuff in our builds.  So far, it's all been valid errors in our code, but it's taking my a while to slog through them all.. Yeah, it breaks some stuff in our builds.  So far, it's all been valid errors in our code, but it's taking my a while to slog through them all.. Okay, I found one thing that I think is a legit bug.  If you have a WRITE_EXTERNAL_STORAGE, even if you have a READ_EXTERNAL_STORAGE elsewhere, it adds a READ_EXTERNAL_STORAGE permission, but with an \"android:\" prefix on the element name, which seems incorrect.  Want to check it out?. Okay, I found one thing that I think is a legit bug.  If you have a WRITE_EXTERNAL_STORAGE, even if you have a READ_EXTERNAL_STORAGE elsewhere, it adds a READ_EXTERNAL_STORAGE permission, but with an \"android:\" prefix on the element name, which seems incorrect.  Want to check it out?. There's no failure that I know of.  I'm just worried that something is going to go wrong at runtime.\n. There's no failure that I know of.  I'm just worried that something is going to go wrong at runtime.\n. There's an internal diff now to upgrade our sdklib to android/sdk-common-25.2.0.jar.  Does that make this easier or harder?. I think so.  Not sure about sdklib, but definitely the others.  I'll let you know when it lands.. Okay, I've narrowed down the problem to addImplicitElements.  Because it thinks that all of our library manifests are targeting sdk 1, it's adding a bunch of (unwanted) stuff to our manifest.  I commented out the call to that method and it seems to be working.  Can you comment it out in the PR, then we can see if we can find a cleaner way to disable these?. I think the next block (if (hasWriteToExternalStoragePermission) {) is also potentially problematic, though we could work around that.  I'm not sure about the last one.\nI think what I'd really like (upstream) is that if the library doesn't specify a target, instead of assuming that it is \"1\" (because, really, what are the odds of that), assume that it doesn't care and set it to the target of the main manifest.. I think the next block (if (hasWriteToExternalStoragePermission) {) is also potentially problematic, though we could work around that.  I'm not sure about the last one.\nI think what I'd really like (upstream) is that if the library doesn't specify a target, instead of assuming that it is \"1\" (because, really, what are the odds of that), assume that it doesn't care and set it to the target of the main manifest.. It looks like this removed both \"*Test.java\" files.  Was that intentional?  It was messing up our CI with a very confusing error message (which is one reason this has taken so long).. Looks like another failure has been introduced on our side: https://gist.github.com/dreiss/f22391e27e0c65c53c8684781d6591f4\nCode looks pretty reasonable to me.  Suggestions?  Maybe create a subclass to use as the second receiver?. This had to be reverted.  I'm looking into it.. This had to be reverted.  I'm looking into it.. Looks like the old version was (somehow) ensuring that all activity-alias elements came after the activities they referenced, but the new one does not, resulting in some <activity-alias> target activity [...] not found in manifest.  I guess I'm going to have to track down cases where this happens in our codebase and reorder them manually.  I'm not sure what will happen if the activity and the alias appear in separate files.\nI'm open to other suggestions if people have them.. Looks like the old version was (somehow) ensuring that all activity-alias elements came after the activities they referenced, but the new one does not, resulting in some <activity-alias> target activity [...] not found in manifest.  I guess I'm going to have to track down cases where this happens in our codebase and reorder them manually.  I'm not sure what will happen if the activity and the alias appear in separate files.\nI'm open to other suggestions if people have them.. idk, this seems like a bug in the merger.  Why would you require the user to run a separate postprocessing step?. idk, this seems like a bug in the merger.  Why would you require the user to run a separate postprocessing step?. Yep, I found a case in our codebase where the activity and the alias are in separate files, so there's no way to fix this short of postprocessing.  I can do it for Facebook, but this doesn't seem like a reasonable thing for us to ask every Buck user to do.  I'd much prefer it if the merger could just use a safe ordering.. Is there any urgency to this?. Is there any urgency to this?. Are you able to separate this into two commits?  One that's the unmodified code, and one that's your local changes?  It's pretty much impossible to review as-is.. Are you able to separate this into two commits?  One that's the unmodified code, and one that's your local changes?  It's pretty much impossible to review as-is.. This looks fine.  I want to take some time to make sure that changes in dx aren't going to interfere with any of our runtime optimizations (at FB).  If anyone's in a hurry to get this landed, let me know and I'll get it moving along faster.. This looks fine.  I want to take some time to make sure that changes in dx aren't going to interfere with any of our runtime optimizations (at FB).  If anyone's in a hurry to get this landed, let me know and I'll get it moving along faster.. Okay, this is working fine with redex on our apps as well.  I'm going to land it.\nThis will be the first non-squashed stack I've imported from GitHub, so bear with me.. Okay, this is working fine with redex on our apps as well.  I'm going to land it.\nThis will be the first non-squashed stack I've imported from GitHub, so bear with me.. Oh, I found a problem: this spews the merge report onto the console.  Any idea why that wasn't happening before?. Oh, I found a problem: this spews the merge report onto the console.  Any idea why that wasn't happening before?. I pulled these in, tweaked them a bit, and landed.  Maybe we should leave this PR open for a few days so we can make sure that we don't need to revert it.. Looking good on our end.. Sorry, we had some internal bugs that were making it tough for me to test this.  Giving it another shot.. Sorry, we had some internal bugs that were making it tough for me to test this.  Giving it another shot.. Andrew, you wrote the ndk linking stuff, right?  Thoughts on this?. I can't reproduce this in our sample repo (https://github.com/fbsamples/bucksamples).  What version of build-tools are you using?  Do you have any hidden characters in your .xml file?\n```\ndreiss@dr-mbp:master:bucksamples/cross-platform-scale-2015-demo:0$ git rev-parse HEAD\n13f7afc49e7658ef6bb040e6922592bc6246d83d\ndreiss@dr-mbp:master:bucksamples/cross-platform-scale-2015-demo:0$ git diff\ndiff --git i/cross-platform-scale-2015-demo/.buckconfig w/cross-platform-scale-2015-demo/.buckconfig\nindex 98bba03..83122bb 100644\n--- i/cross-platform-scale-2015-demo/.buckconfig\n+++ w/cross-platform-scale-2015-demo/.buckconfig\n@@ -21,6 +21,7 @@\n[android]\n   target = Google Inc.:Google APIs:23\n+  build_tools_version = 25.0.2\n[java]\n   src_roots = /android/java/\ndiff --git i/cross-platform-scale-2015-demo/android/resources/res/values/strings.xml w/cross-platform-scale-2015-demo/android/resources/res/values/strings.xml\nindex a40f5a6..b6dae89 100644\n--- i/cross-platform-scale-2015-demo/android/resources/res/values/strings.xml\n+++ w/cross-platform-scale-2015-demo/android/resources/res/values/strings.xml\n@@ -1,4 +1,5 @@\n <?xml version='1.0' encoding='utf-8' ?>\n \nBuck Demo App\n+  https://google.com\n\ndreiss@dr-mbp:master:bucksamples/cross-platform-scale-2015-demo:0$ buck build --out the_apk.apk demo_app_android\n[-] PROCESSING BUCK FILES...FINISHED 0.2s [100%] \ud83c\udfd6  Watchman reported no changes\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 1.3s [100%] (1/1 JOBS, 1 UPDATED, 0 [0.0%] CACHE MISS)\ndreiss@dr-mbp:master:bucksamples/cross-platform-scale-2015-demo:0$ ~/opt/asdk/build-tools/23.0.1/aapt dump strings the_apk.apk\nString pool of 4 unique UTF-16 non-sorted strings, 4 entries and 0 styles using 224 bytes:\nString #0: res/layout/hello.xml\nString #1: res/drawable-xxhdpi-v4/buck.png\nString #2: Buck Demo App\nString #3: https://google.com\n```. I can't reproduce this in our sample repo (https://github.com/fbsamples/bucksamples).  What version of build-tools are you using?  Do you have any hidden characters in your .xml file?\n```\ndreiss@dr-mbp:master:bucksamples/cross-platform-scale-2015-demo:0$ git rev-parse HEAD\n13f7afc49e7658ef6bb040e6922592bc6246d83d\ndreiss@dr-mbp:master:bucksamples/cross-platform-scale-2015-demo:0$ git diff\ndiff --git i/cross-platform-scale-2015-demo/.buckconfig w/cross-platform-scale-2015-demo/.buckconfig\nindex 98bba03..83122bb 100644\n--- i/cross-platform-scale-2015-demo/.buckconfig\n+++ w/cross-platform-scale-2015-demo/.buckconfig\n@@ -21,6 +21,7 @@\n[android]\n   target = Google Inc.:Google APIs:23\n+  build_tools_version = 25.0.2\n[java]\n   src_roots = /android/java/\ndiff --git i/cross-platform-scale-2015-demo/android/resources/res/values/strings.xml w/cross-platform-scale-2015-demo/android/resources/res/values/strings.xml\nindex a40f5a6..b6dae89 100644\n--- i/cross-platform-scale-2015-demo/android/resources/res/values/strings.xml\n+++ w/cross-platform-scale-2015-demo/android/resources/res/values/strings.xml\n@@ -1,4 +1,5 @@\n <?xml version='1.0' encoding='utf-8' ?>\n \nBuck Demo App\n+  https://google.com\n\ndreiss@dr-mbp:master:bucksamples/cross-platform-scale-2015-demo:0$ buck build --out the_apk.apk demo_app_android\n[-] PROCESSING BUCK FILES...FINISHED 0.2s [100%] \ud83c\udfd6  Watchman reported no changes\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 1.3s [100%] (1/1 JOBS, 1 UPDATED, 0 [0.0%] CACHE MISS)\ndreiss@dr-mbp:master:bucksamples/cross-platform-scale-2015-demo:0$ ~/opt/asdk/build-tools/23.0.1/aapt dump strings the_apk.apk\nString pool of 4 unique UTF-16 non-sorted strings, 4 entries and 0 styles using 224 bytes:\nString #0: res/layout/hello.xml\nString #1: res/drawable-xxhdpi-v4/buck.png\nString #2: Buck Demo App\nString #3: https://google.com\n```. You have hidden characters at the end of the line.  See below.\nGradle must be stripping these out when it merges resources, but we pass your resources directly to aapt, which complains.\n```\ndreiss@dr-mbp:url:okbuck-playground:0$ git rev-parse HEAD\nd7fe0e6c0f88221a62bed580a5f40c5feb85b61e\ndreiss@dr-mbp:url:okbuck-playground:0$ sha1sum app/src/main/res/values/strings.xml\n7e01ed67c6253d24d7c6afa589ea71e717590d4f  app/src/main/res/values/strings.xml\ndreiss@dr-mbp:url:okbuck-playground:0$ sed --version\nsed (GNU sed) 4.2.2\nCopyright (C) 2012 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\nWritten by Jay Fenlason, Tom Lord, Ken Pizzini,\nand Paolo Bonzini.\nGNU sed home page: http://www.gnu.org/software/sed/.\nGeneral help using GNU software: http://www.gnu.org/gethelp/.\nE-mail bug reports to: bug-sed@gnu.org.\nBe sure to include the word sed'' somewhere in theSubject:'' field.\ndreiss@dr-mbp:url:okbuck-playground:0$ sed -nel app/src/main/res/values/strings.xml\n$\n    okbuck$\n$\n    https://google.com\\342\\200\\250$\n    \"https://google.com\"\\342\\200\\250$\n    <![CDATA[https://google.com]]>\\342\\\n\\200\\250$\n    <![CDATA[\"https://google.com\"]]>\\342\\\n\\200\\250$\n$\ndreiss@dr-mbp:url:okbuck-playground:0$ xxd app/src/main/res/values/strings.xml\n0000000: 3c72 6573 6f75 7263 6573 3e0a 2020 2020  .  \n0000010: 3c73 7472 696e 6720 6e61 6d65 3d22 6170  okbuck\n0000030: 7374 7269 6e67 3e0a 0a20 2020 203c 7374  string..    \n0000050: 6874 7470 733a 2f2f 676f 6f67 6c65 2e63  https://google.c\n0000060: 6f6d 3c2f 7374 7269 6e67 3ee2 80a8 0a20  om.... \n0000070: 2020 203c 7374 7269 6e67 206e 616d 653d     \"https://g\n0000090: 6f6f 676c 652e 636f 6d22 3c2f 7374 7269  oogle.com\"....    <!\n00000c0: 5b43 4441 5441 5b68 7474 7073 3a2f 2f67  [CDATA[https://g\n00000d0: 6f6f 676c 652e 636f 6d5d 5d3e 3c2f 7374  oogle.com]]>....    \n0000100: 3c21 5b43 4441 5441 5b22 6874 7470 733a  <![CDATA[\"https:\n0000110: 2f2f 676f 6f67 6c65 2e63 6f6d 225d 5d3e  //google.com\"]]>\n0000120: 3c2f 7374 7269 6e67 3ee2 80a8 0a3c 2f72  .....\n```. You have hidden characters at the end of the line.  See below.\nGradle must be stripping these out when it merges resources, but we pass your resources directly to aapt, which complains.\n```\ndreiss@dr-mbp:url:okbuck-playground:0$ git rev-parse HEAD\nd7fe0e6c0f88221a62bed580a5f40c5feb85b61e\ndreiss@dr-mbp:url:okbuck-playground:0$ sha1sum app/src/main/res/values/strings.xml\n7e01ed67c6253d24d7c6afa589ea71e717590d4f  app/src/main/res/values/strings.xml\ndreiss@dr-mbp:url:okbuck-playground:0$ sed --version\nsed (GNU sed) 4.2.2\nCopyright (C) 2012 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later http://gnu.org/licenses/gpl.html.\nThis is free software: you are free to change and redistribute it.\nThere is NO WARRANTY, to the extent permitted by law.\nWritten by Jay Fenlason, Tom Lord, Ken Pizzini,\nand Paolo Bonzini.\nGNU sed home page: http://www.gnu.org/software/sed/.\nGeneral help using GNU software: http://www.gnu.org/gethelp/.\nE-mail bug reports to: bug-sed@gnu.org.\nBe sure to include the word sed'' somewhere in theSubject:'' field.\ndreiss@dr-mbp:url:okbuck-playground:0$ sed -nel app/src/main/res/values/strings.xml\n$\n    okbuck$\n$\n    https://google.com\\342\\200\\250$\n    \"https://google.com\"\\342\\200\\250$\n    <![CDATA[https://google.com]]>\\342\\\n\\200\\250$\n    <![CDATA[\"https://google.com\"]]>\\342\\\n\\200\\250$\n$\ndreiss@dr-mbp:url:okbuck-playground:0$ xxd app/src/main/res/values/strings.xml\n0000000: 3c72 6573 6f75 7263 6573 3e0a 2020 2020  .  \n0000010: 3c73 7472 696e 6720 6e61 6d65 3d22 6170  okbuck\n0000030: 7374 7269 6e67 3e0a 0a20 2020 203c 7374  string..    \n0000050: 6874 7470 733a 2f2f 676f 6f67 6c65 2e63  https://google.c\n0000060: 6f6d 3c2f 7374 7269 6e67 3ee2 80a8 0a20  om.... \n0000070: 2020 203c 7374 7269 6e67 206e 616d 653d     \"https://g\n0000090: 6f6f 676c 652e 636f 6d22 3c2f 7374 7269  oogle.com\"....    <!\n00000c0: 5b43 4441 5441 5b68 7474 7073 3a2f 2f67  [CDATA[https://g\n00000d0: 6f6f 676c 652e 636f 6d5d 5d3e 3c2f 7374  oogle.com]]>....    \n0000100: 3c21 5b43 4441 5441 5b22 6874 7470 733a  <![CDATA[\"https:\n0000110: 2f2f 676f 6f67 6c65 2e63 6f6d 225d 5d3e  //google.com\"]]>\n0000120: 3c2f 7374 7269 6e67 3ee2 80a8 0a3c 2f72  .....\n```. This message is straight from aapt, unfortunately.. This looks good to me.  I need to get the proper config values added to our .buckconfig before I can import it.. I'm trying to land this.  I did notice two non-critical issues that you might want to address.\n1/ This isn't being added to rule keys, which means that if you set the limit differently on CI and laptops, you might have engineers getting OOMs on rules that are building cleanly in CI, or vice-versa.  I kind of think that is okay because lots of things can already affect whether you get an OOM.\n2/ You're not passing this down to DexProducedFromJavaLibrary, which is the rule for dexing a single java library in a debug build.. I'm trying to land this.  I did notice two non-critical issues that you might want to address.\n1/ This isn't being added to rule keys, which means that if you set the limit differently on CI and laptops, you might have engineers getting OOMs on rules that are building cleanly in CI, or vice-versa.  I kind of think that is okay because lots of things can already affect whether you get an OOM.\n2/ You're not passing this down to DexProducedFromJavaLibrary, which is the rule for dexing a single java library in a debug build.. [Thu, 02 Mar 2017 08:40:01] ant lint\ncheckstyle:\n[checkstyle] Running Checkstyle 6.16.1 on 3281 files\n[checkstyle] [ERROR] src/com/facebook/buck/android/AndroidBinaryGraphEnhancer.java:457: Line is longer than 100 characters (found 115). [LineLength]\n:(. [Thu, 02 Mar 2017 08:40:01] ant lint\ncheckstyle:\n[checkstyle] Running Checkstyle 6.16.1 on 3281 files\n[checkstyle] [ERROR] src/com/facebook/buck/android/AndroidBinaryGraphEnhancer.java:457: Line is longer than 100 characters (found 115). [LineLength]\n:(. BufferedOutputStream inherits close from FilterOutputStream, which says \" The close method of FilterOutputStream calls its flush method, and then calls the close method of its underlying output stream.\"  It seems like this should work fine (unless BufferedOutputStream's constructor throws).. BufferedOutputStream inherits close from FilterOutputStream, which says \" The close method of FilterOutputStream calls its flush method, and then calls the close method of its underlying output stream.\"  It seems like this should work fine (unless BufferedOutputStream's constructor throws).. I think this has been resolved.  Please re-open if you have trouble.. I think this has been resolved.  Please re-open if you have trouble.. How common is this pattern?  If it's something particular to your app, I'd rather not push this all the way into ExopackageApplication.\nI think the alternative would be for you to define a HasSystemService interface that goes into the primary dex and is implemented by your delegate, then you can move the getSystemService definition that you currently have in ExopackageApplication into your AppShell. Would this change let you simplify your code?  If so, I'm okay with importing it.. Are you setting -proc:only explicitly or with annotation_processor_only=True?. e1da197cf45cd6846585289767e67989fd31ab8e fixed this in the latter case.. annotation_processor_only is the structured way to pass -proc:only, so we can automatically remove it when passing flags to the step that compiles dummy R.java.\nWe should be ready to finalize and document the arguments supporting APs soon.. Can you try this?  After you build, edit, build (with buckd), and see that the changes were not picked up, can you run \"buck verify-caches\" and see if it reports any issues?. Can you try this?  After you build, edit, build (with buckd), and see that the changes were not picked up, can you run \"buck verify-caches\" and see if it reports any issues?. If that were the problem, buck verify-caches should have caught it.. If that were the problem, buck verify-caches should have caught it.. This was done intentionally to match the behavior of the official Android build system at the time (ant).  What do you think is the proper behavior, and why?. This was done intentionally to match the behavior of the official Android build system at the time (ant).  What do you think is the proper behavior, and why?. I think it just inherits them from java_library, and they aren't totally ignored.  They would be included in a java_binary. :). I think it just inherits them from java_library, and they aren't totally ignored.  They would be included in a java_binary. :). We could probably add support for merging these resources in.  I'm not sure what the unintended consequences would be, though.\nBTW, why do you need this?  IIRC, getResourceAsStream allocates a ton of heap memory on Android, and using the AssetManager works much better.. We could probably add support for merging these resources in.  I'm not sure what the unintended consequences would be, though.\nBTW, why do you need this?  IIRC, getResourceAsStream allocates a ton of heap memory on Android, and using the AssetManager works much better.. Discussed this with @kageiit and @runningcode .  Here's a summary:\n\nDoing this is generally a bad idea because it's bad for build perf and runtime perf.\nGradle does this by default, so we should probably support it.\n\nThe way to do it is add an option to android_binary to add itself to com.facebook.buck.android.AndroidPackageableCollection#pathsToThirdPartyJars (probably after renaming it).. Discussed this with @kageiit and @runningcode .  Here's a summary:\n\n\nDoing this is generally a bad idea because it's bad for build perf and runtime perf.\n\nGradle does this by default, so we should probably support it.\nThe way to do it is add an option to android_binary to add itself to com.facebook.buck.android.AndroidPackageableCollection#pathsToThirdPartyJars (probably after renaming it).. I don't think it's related.  File hash cache and rule key cache are independent.  Are you able to get the list of open files?. Does this app use pre-dexing or no?  If not, I wonder if this is the same issue you were looking at with mbolin.  Does disabling the action graph cache fix it?. Does this app use pre-dexing or no?  If not, I wonder if this is the same issue you were looking at with mbolin.  Does disabling the action graph cache fix it?. Probably the same issue.  I discussed a possible solution with @raviagarwal7 on Slack.. Probably the same issue.  I discussed a possible solution with @raviagarwal7 on Slack.. Thanks for the repro.\n\nI looked into this a bit further.  It looks like the resource merging code in gradle takes care of this before the resources are ever shown to aapt.  I tested out the resource merger that we're using in Buck for android_aar, but it didn't do the same, so we need to find the code in gradle that has this logic.\nIf you can find it, that'd be awesome.  Otherwise, if you could send the most simple gradle project possible that exhibits this behavior (ideally with two values files that each override strings in the other), that would help me get started with the search.  Otherwise, I'll narrow down a small repro from the branch you posted above.. I fixed the installer.  We're still having some trouble with our internal version of the runtime, but I think the open-source version is working.  Please re-open if you have trouble.. Discussed on Slack.  This should already be working.. https://gist.github.com/dreiss/4ab8b4a4e45e07a5b8e3346460fe588d  Is the fix for this.. Trying to get this landed internally.  Sorry for the breakage.. Yeah, I thought so too, which is why I felt confident landing the broken version.\nThe subexpression\njava\narg.getManifestSkeleton()\n    .orElseThrow(\n        () ->\n            new IllegalArgumentException(\n                \"android_binary \"\n                    + targetNode.getBuildTarget()\n                    + \" did not specify manifest or manifest_skeleton\"));\nis not a lambda. It's evaluated unconditionally, so we throw if manifest_skeleton is not specified.. Merging now.. Yeah, this should be fixed.  We have no idea why this bug wasn't being triggered before now.. Sorry, looks like the patch doesn't apply anymore?. Hrm.  Might be a conflict with our internal tree.  Sorry.  I'm going to attempt to land manually.. The way we do this at Facebook is to use different .buckconfig files, or use Buck's @ argument syntax to easily pass options on the command-line.  For example, you could check in a file called mode/arduino that contains\n--config\ncxx.cxxflags=\"-std=gnu++14 -Os\"\nthen compile with buck build @mode/arduino //my:target to get that configuration option set on the command-line.\nWhat flags need to be different per-platform?  The include path locations?  For Android, we have native support for relocating the NDK, but another option is to just require the header files to be installed in a fixed location.. Let's wait to hear back on that Google task to see where the fix was.. The convention in buck is to document \"empty\" parameters, like \n/* finalRName */ Optional.<String>absent()\n. Same with boolean parameters.\n. Combine this into the previous conditional?  And maybe then invert the condition so the shorter case ends up on top?\n. Convention is to put .build(); on a new line.\n. this.rName = rName.or(\"R\");\n. Comment.\n. Comment.  I wonder if you blame the line below, if it would be from me.  How embarrassing.  I blame automated refactoring.\n. I would suggest adding a second value and testing that both symbols appear in the output and are properly initialized to distinct ids.\n. Teeny tiny nit: put a ; at the end of these strings to make sure there are no trailing digits.\n. Ugh, sorry.  This is over 100 chars, so it failed our lint check, so the automatic land failed.  Are you able to reformat?  If not, I can figure out how to import this to my laptop and do it manually.\n. Can you make this look like a shell command with input and output?  like \"shortCommand SOURCE_PATH > OUTPUT_PATH\"\n. This should always be present.  @marcinkosiba , do you know the best way to read this file with ProjectFilesystem?\n. What is \\\\[\\\\] for?\n. doesn't need \\\\ inside []\n. Make this start as null instead of \"\"?\n. Wait a sec.  This is for something totally different.  @Coneko , do you know what's going on here?\n. Why did this change?. Renaming SDKConstants is gross.  What libraries does this conflict with?  Should we update them?  This hack is fine for now, but you should file a task to clean it up.. Why is buck-lib in here?\n. Can you use ProjectFileSystem.writeContentsToPath here?. I'd like to avoid having this Java code relying on anything Android-specific.  Can the required information be passed from above in some generic way?  (\"extraEnvironmentForPostprocessing\" or something like that?). Doesn't the \"CLASSPATH\" variable get special treatment by java?  Can this be renamed to something more specific like COMPILATION_CLASSPATH?. Maybe just check this at the top and return an empty list?. This feels like it should be abstract and return a non-optional String.  Do kotlin/groovy/scala not have this concept?  Can you document when and how a subclass should be overriding this?. I don't think this needs to be final in Java 8.. Is it possible to use this method where we're actually generating the command line to ensure that they stay in sync?. This is still showing up with no indication of what the actual error is.  I think we need to display all available diagnostic info in the console to make it easier for engineers (and me) to debug their build failures.. It looks like this is not guaranteed to consume the entire string.  What if the longer one has a double-underscore in it?  Couldn't that give a false \"equal\" comparison with a different string?  What about comparing the two array lengths instead of this block.  Would that work?. Expected value should be the first argument, and actual value the second.. Unclear whether this is necessary, because merging is much less memory intensive, and we usually run it in-process, but okay.. Why does this start with \"dx-\"?  I think it had the \"dx\" prefix before because it was in the java section, but now it probably makes more sense to just call it \"threads\" or \"max_threads\".\nI guess anyone using the old directive will need to update their .buckconfig?  Should it fall back to checking the old value, with a warning?. I think the convention is underscore separators, rather than dashes, right?. Oh, interesting.  Yeah, almost everything uses underscores, though.. That I'm not sure.  It looks like KnownBuildRuleTypes has instances of LOG.warn and LOG.error.  Maybe try those?. Nope.  I just had a few speedbumps on the import.  No other changes required IMO.. FYI, this broke the windows test because it's using hard-coded \"/\" instead of EXPECTED_DX_PREFIX.  I'm fixing it locally.. This should also be checked in the Description (or the rule constructor) to ensure that we catch this early.. Looks like this comment is no longer relevant?. Not sure this comment makes sense anymore.  Maybe comment why this has to be created before you reassign rDotJavaPackageToResources below?. Why \"prebuilt\"?. I still don't understand what \"prebuilt\" means in this context.  That's the term we generally use for binaries that are checked into the repository.  Maybe just name this isSkipNonUnionRDotJava?  I don't know of any other name for these packages.  isSkipRDotJavaForThePackageThatDefinesEachResource doesn't seem quite right. :)\nAlso, can you document this parameter in the docs subdir?. ",
    "rahul-a": "Any update around annotation processing feature being available in open source version? Can't get this to work. I am working on trying to add support for databinding to Buck but I noticed some weird behavior. \nSo right now I'm plugging in the annotation processor into my android_library which is dependent on an android_resource (I've added a step to write intermediate layout info to project's gen path) and processing works fine but due to my library files being DummyRDotJava files their declarations are non final and that breaks the output of DataBinding Processor (since it uses the R declarations in a switch case) whereas if I explicitly make them final it gives me a Resource not found exception when running the app. \nAlso I noticed that sometimes when my BUCK build file changes for a project and I try to build a lib which has resources, the resources rule is not rebuilt and it's last generated artifacts disappear from buck-out, the problem I face is one of the databinding steps has to depend on the artifacts generated by android_resource rule.\nIdeas on how to tackle these issues would help a lot.. I am working on trying to add support for databinding to Buck but I noticed some weird behavior. \nSo right now I'm plugging in the annotation processor into my android_library which is dependent on an android_resource (I've added a step to write intermediate layout info to project's gen path) and processing works fine but due to my library files being DummyRDotJava files their declarations are non final and that breaks the output of DataBinding Processor (since it uses the R declarations in a switch case) whereas if I explicitly make them final it gives me a Resource not found exception when running the app. \nAlso I noticed that sometimes when my BUCK build file changes for a project and I try to build a lib which has resources, the resources rule is not rebuilt and it's last generated artifacts disappear from buck-out, the problem I face is one of the databinding steps has to depend on the artifacts generated by android_resource rule.\nIdeas on how to tackle these issues would help a lot.. ",
    "mread": "I've made some changes here mread@ab6fe896e72e5dc95b021fe3ae4974de26e8d1cc, I hope that's clearer.\n. This appears to have regressed - pull-request on the way\n. Ignore previous comment, my mistake, I didn't understand how new resources_root would work with resources in the root directory.\n. Sorry, I never got round to cleaning up my change and creating the pull request. Here's the commits that do most of the work. I hope it's helpful.\nmread@eecd3285d612f348bce332e2d3c5f41e6079d42c\nmread@3f9d01be0462e7aa0178218d9ae354561dfa9e46\n. Unfortunately the commit above doesn't resolve this issue. If a jar is created via a genrule then buck project now reports:\njava.lang.IllegalStateException: project_config() does not know how to process a src_target of type genrule.\n. I have now - that works fine. That was the original issue that I reported wasn't it? So closing this one. Thanks!\n. I think most of our issues have now been fixed and performance is far more predictable. So thanks very much for that. The one remaining issue is #6, package renames or other file moves often seem to break things until buckd is killed. I can try to tighten up the steps to reproduce that and raise a separate issue so that this one can be closed if it's useful?\n. Thanks for the info, < 20 ms would definitely be ok for us if we could get there. Are you able to tell me how many files you have in your workspace?\n. A higher, lower or about the same would probably give me enough to think about for now - we're at about 40,000 here, or perhaps 90,000 if the ignore paths aren't working.\nWe're linux (fc20). I've checked the inotify watch limit to make sure it's ok and we don't seem to have problems there - it fails very explicitly when that's set too low.\n. Thanks very much for that suggestion Jim, I had increased max_user_watches but hadn't looked at the other two settings. I've bumped those up a few notches and we'll run with that for a while to see how we get on.\n. Thanks for giving this some attention!\nWith the latest commits I am seeing a tree recrawl for each change I make to a single source file:\nIn the watchman log\n1407407030: tid=571143936 watch descriptor for /path/to/project/buck-out/bin/path/to/module/lib__mymodule-test__classes should have been 16951, is 16996\n1407407030: tid=571143936 /path/to/project: stale watch descriptor found: scheduling a tree recrawl\n. Thanks for giving this some attention!\nWith the latest commits I am seeing a tree recrawl for each change I make to a single source file:\nIn the watchman log\n1407407030: tid=571143936 watch descriptor for /path/to/project/buck-out/bin/path/to/module/lib__mymodule-test__classes should have been 16951, is 16996\n1407407030: tid=571143936 /path/to/project: stale watch descriptor found: scheduling a tree recrawl\n. Wrt to the stale watch descriptor messages my guess is:\n1. buck queries watchman for changes without filtering out the ignore paths specified in .buckconfig\n2. watchman returns changes to all files including buck-out/\n3. watchman notices some of the directories in buck-out/ have been deleted and recreated so reports \"stale watch descriptor\" and triggers a recrawl of the entire tree\n. Wrt to the stale watch descriptor messages my guess is:\n1. buck queries watchman for changes without filtering out the ignore paths specified in .buckconfig\n2. watchman returns changes to all files including buck-out/\n3. watchman notices some of the directories in buck-out/ have been deleted and recreated so reports \"stale watch descriptor\" and triggers a recrawl of the entire tree\n. I had just found that part of the watchman docs when I saw your reply. I included .git in that list, which triggers a different error as something is writing a file to .git/.watchman-cookie-my.host-5158-1-1 and when watchman can't find the file it logs sync_to_now: /path/to/project/.git/.watchman-cookie-my.host-5158-1-1 timedwait failed: Connection timed out and buck hangs.\nSo, I remove .git and go with the list you suggested and things have got a whole lot faster - spectacularly fast in fact, back to what I remember from the pre-watchman days. And this, which is nice too - [com.facebook.buck.util.WatchmanWatcher] Posted 0 Watchman events. Waiting for subprocess to exit...\nAnyone running without that config is going to get no benefit from watchman at all are they? Might be a good one for the docs, particularly the .buckconfig project.ignore docs. That would certainly have saved me a few weeks/months of head-scratching.\n. I had just found that part of the watchman docs when I saw your reply. I included .git in that list, which triggers a different error as something is writing a file to .git/.watchman-cookie-my.host-5158-1-1 and when watchman can't find the file it logs sync_to_now: /path/to/project/.git/.watchman-cookie-my.host-5158-1-1 timedwait failed: Connection timed out and buck hangs.\nSo, I remove .git and go with the list you suggested and things have got a whole lot faster - spectacularly fast in fact, back to what I remember from the pre-watchman days. And this, which is nice too - [com.facebook.buck.util.WatchmanWatcher] Posted 0 Watchman events. Waiting for subprocess to exit...\nAnyone running without that config is going to get no benefit from watchman at all are they? Might be a good one for the docs, particularly the .buckconfig project.ignore docs. That would certainly have saved me a few weeks/months of head-scratching.\n. Thanks. It would be great if that work could allow us to exclude .svn and .git directories from the watchman query too - our subversion users are getting recrawls due to changes in the .svn/ directories that appear to be caused by IntelliJ interaction of some kind.\n. Thanks. It would be great if that work could allow us to exclude .svn and .git directories from the watchman query too - our subversion users are getting recrawls due to changes in the .svn/ directories that appear to be caused by IntelliJ interaction of some kind.\n. Thanks Wes, we'll try a few permutations of that - we are using both .git and .svn and those using .svn have a single dir at the root.\n. Thanks Wes, we'll try a few permutations of that - we are using both .git and .svn and those using .svn have a single dir at the root.\n. Awesome work on the log output by the way - I can now see why and where we're triggering cache invalidations and reparses.\n. Awesome work on the log output by the way - I can now see why and where we're triggering cache invalidations and reparses.\n. We're getting much better performance now but have run into another issue - perhaps you guys have a work around for this one?\nIntelliJ has a \"safe write\" feature which writes files to disk then renames them into place as a kind of atomic write. From time to time watchman detects jb_bak and jb_old files which is treats as new and therefore cause reparsing of the related module. Vim causes the same thing with ~ and .bak files. I can't see a file_ignore capability in watchman and the .buckconfig ignore_paths don't work for this - can you suggest any other way of ignoring these?\nThanks,\nMatt\n. We're getting much better performance now but have run into another issue - perhaps you guys have a work around for this one?\nIntelliJ has a \"safe write\" feature which writes files to disk then renames them into place as a kind of atomic write. From time to time watchman detects jb_bak and jb_old files which is treats as new and therefore cause reparsing of the related module. Vim causes the same thing with ~ and .bak files. I can't see a file_ignore capability in watchman and the .buckconfig ignore_paths don't work for this - can you suggest any other way of ignoring these?\nThanks,\nMatt\n. Yep, I tried both jbbak and _/jb_bak and they're still picked up by watchman. Although I was looking at the \"Full JSON\" line - I didn't double check that they caused reparses, I'll check that for sure tomorrow if you think it's worthwhile?\n. Yep, I tried both jbbak and _/jb_bak and they're still picked up by watchman. Although I was looking at the \"Full JSON\" line - I didn't double check that they caused reparses, I'll check that for sure tomorrow if you think it's worthwhile?\n. No luck, unfortunately buck detects the original saved file (saved and moved by safe write) as WatchEvent ENTRY_CREATE instead of WatchEvent ENTRY_MODIFY as it does with IntelliJ's Safe Write switched off.\n. No luck, unfortunately buck detects the original saved file (saved and moved by safe write) as WatchEvent ENTRY_CREATE instead of WatchEvent ENTRY_MODIFY as it does with IntelliJ's Safe Write switched off.\n. I don't think that will work - watchman reports the save (move) of the original file as {\"name\":\"src/SomeClass.java\",\"exists\":true,\"new\":true} so even if the temp files are ignored, that new:true still causes Parser invalidating my_module/BUCK cache\n. I don't think that will work - watchman reports the save (move) of the original file as {\"name\":\"src/SomeClass.java\",\"exists\":true,\"new\":true} so even if the temp files are ignored, that new:true still causes Parser invalidating my_module/BUCK cache\n. No, but it shouldn't exclude directories just because they contain a BUCK file - it should only exclude directories if that BUCK file defines a project_config for that directory/module.\nAn example would be a module containing a lib/ directory which in turn contained both .jar files and a BUCK file with a load of prebuild_jar entries. Since the commit referenced above, that lib/ directory is being excluded from its parent module and is therefore hidden in IntelliJ. It wouldn't make sense to put a project_config() in lib/BUCK because there are no appropriate src_roots... there are no sources.\n. No, but it shouldn't exclude directories just because they contain a BUCK file - it should only exclude directories if that BUCK file defines a project_config for that directory/module.\nAn example would be a module containing a lib/ directory which in turn contained both .jar files and a BUCK file with a load of prebuild_jar entries. Since the commit referenced above, that lib/ directory is being excluded from its parent module and is therefore hidden in IntelliJ. It wouldn't make sense to put a project_config() in lib/BUCK because there are no appropriate src_roots... there are no sources.\n. Of your two options, it's the former - the workspace still compiles but (using my previous example) you can't actually edit the BUCK file to add new dependencies or copy in new jar files because the whole directory is excluded. You can't even edit the BUCK file to add a project_config() rule.\nI've tried adding lib to the parent module src_roots but it's still excluded.\nFor us this is slightly more than annoying - we can't have a workspace for which source files are not editable. The previous behaviour, while a little unpredictable, did at least allow us to see our source files.\n. Of your two options, it's the former - the workspace still compiles but (using my previous example) you can't actually edit the BUCK file to add new dependencies or copy in new jar files because the whole directory is excluded. You can't even edit the BUCK file to add a project_config() rule.\nI've tried adding lib to the parent module src_roots but it's still excluded.\nFor us this is slightly more than annoying - we can't have a workspace for which source files are not editable. The previous behaviour, while a little unpredictable, did at least allow us to see our source files.\n. I think understand what you're getting at.\nI think the simplest logic would be that any subfolder of a BUCK module with a project_config should NOT be excluded unless it contains a BUCK file with a project_config. \nI don't think traversing the dependencies would get us anywhere because it would be valid to have a BUCK module that was not explicitly depended on by anything and still want to be able to edit it in IntelliJ.\n. I'm not sure I understand what you're suggesting - something like this? (/lib is still excluded)\n/BUCK\n```\njava_library(\n    name = 'buck_project_workaround',\n    deps = [ '//lib:buck_project_workaround' ]\n)\nproject_config(\n    src_target = ':buck_project_workaround',\n    src_roots = [ ]\n)\n```\n/lib/BUCK\njava_library(name = 'buck_project_workaround', visibility = [ '//:' ])\n. So just this?\n/BUCK\nproject_config(\n    src_target = '//lib:buck_project_workaround'\n)\n/lib/BUCK\njava_library(name = 'buck_project_workaround', visibility = [ '//:' ])\nWhat used to be the top-level parent module is now just a module called module_lib at the same level as all the others. I can see the sources though. I think this just shows that I don't understand what the intentions of buck project are. I think I need to dig into the source - next week.\n. Actually, I think it may be even simpler - in IntelliJ no folders should be excluded unless they're ignored in .buckconfig. IntelliJ handles submodules fine as far as I can see.\n. Our workaround for this has been to use a post_process script to go and remove all the excludeDir entries that buck added to the .iml files apart from the ones we want.\n. Our workaround for this has been to use a post_process script to go and remove all the excludeDir entries that buck added to the .iml files apart from the ones we want.\n. Not sure how far along the IntelliJ work is but there are still issues that stop us using it without post-processing. Let me know if it would be useful to list them.\n. Sorry, it took a while to get round to this. Our first run through failed an assertion here:\n[2015-06-03 17:12:55.626][error][command:ad781157-5a50-4026-a02c-0f190866c629][tid:15][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.lang.IllegalStateException\n    at com.google.common.base.Preconditions.checkState(Preconditions.java:158)\n    at com.facebook.buck.java.intellij.IjModuleGraph.from(IjModuleGraph.java:181)\n    at com.facebook.buck.java.intellij.IjProject.write(IjProject.java:107)\n    at com.facebook.buck.cli.ProjectCommand.runExperimentalIntellijProjectGenerator(ProjectCommand.java:431)\n. No, I can't share the project that produces that error. I will try to step through at some point as try to work out what the issue is.\nThere may be another project that I could share, I'll get back to you on that.\n. If you were to do the following:\ngit clone https://github.com/mread/spark-redis-bootstrap-buck.git\ncd spark-redis-bootstrap-buck\nrm -rf .idea\nbuck project --experimental-ij-generation\nFirst issue is that it seems to attempt to build the project, not just configure it so you get a failure due to missing nodejs deps. To fix that\nnpm install\nbuck project --experimental-ij-generation\n1. Every package under src/main/java appears to get an entry in the sources, this is unnecessary and for very large projects a bit confusing\n2. Exclude folders include lib/, build/ and node_modules/, I'm not sure where this list is coming from but I don't think I want to exclude those. Is it just excluding everything that isn't explicitly part of a rule?\n3. If misc.xml doesn't exist then it doesn't create one. If it does then it defaults the JDK to\n<component name=\"ProjectRootManager\" version=\"2\" languageLevel=\"JDK_1_6\" assert-keyword=\"true\" jdk-15=\"true\" />\neven though we have specified the following in .buckconfig\n[java]\n    source_level = 8\n    target_level = 8\n1. Likewise project language level is 6, not 8\n2. No output directory set.\nThat's it for now. Hope it's helpful.\n. I think it's any JavaLibrary that has resources with a glob that could match .svn.\n. Yes I am, only older versions of subversion that dump .svn directories everywhere. If a resource pattern matches .svn then it will get included in the jar.\n. No, this was happening without any include_dotfiles.\nA quick hack of com.facebook.buck.java.ResourcesRootIntegrationTest where I add a directory called .dotdir and then ensure that it's not in the resulting jar file fails whether i set include_dotfiles = False or not so it looks like that parameter is being ignored completely.\nLet me know if you want a patch to show that.\n. How about this?\nhttps://github.com/LMAX-Exchange/buck/commit/cd6975def0e7805ce0c03a59b6fe9f612e209c14\n. Not in a position to check anymore I'm afraid. If the test in the commit I linked to above passes then we're all good. @grumpyjames may need to help make that repo visible again though as it seems to have gone dark.\n. Not in a position to check anymore I'm afraid. If the test in the commit I linked to above passes then we're all good. @grumpyjames may need to help make that repo visible again though as it seems to have gone dark.\n. Thanks. Any news or can any pointers on where to look? I reached a dead-end but could spend some time on this later.\n. The issues seems to be with the calculation of com.facebook.buck.step.fs.SymlinkFileStep#getDesiredLinkPath.\nIn old working code existing and desired were this:\n.../java/com/example/data/looping.data\n.../java/com/example/lib__resources__classes/data/looping.data\nin the new code we seem to trim the filename from the desired link name:\n.../java/com/example/data/looping.data\n.../java/com/example/lib__resources__classes/data\nInvestigation continues...\n. The hack that works for me is to add a slash at the end of the javaPackageAsPath when we use it as a String in CopyResourceStep line 123.\nint lastIndex = resource.lastIndexOf(MorePaths.pathWithUnixSeparators(javaPackageAsPath) + \"/\");\nPerhaps that should be the responsbility of a method in MorePaths though?\n. Has behaviour changed here in last month or so? We are also seeing all sorts of other rules match when we specify a filter, e.g.:\nbuck test --dry-run --filter com.package.tests.SomeTest\nOutput:\nMATCHING TEST RULES (715):\n...\nAt first glance it looks like every sh_binary rule in our project, possibly some others too. Shouldn't this only apply to java_test rules?\nIn fact, if I type this:\n./bebuck targets --type java_test\nI get sh_binary rules matching too. That didn't used to happen did it? I might raise a separate issue for that.\n. My mistake, we define a load of rules as java _test that having nothing to do with java tests so that we can run them using labels. Sorry for hijacking this issue.\n. Thanks for the detailed responses. \n\nbuck project --experimental-ij-generation will attempt to build the code. This is because both buck project --experimental-ij-generation and buck project reference stuff from buck-out. The difference is that plain buck project implicitly relies on the developer running the appropriate buck build command, so you can get into a state where IntelliJ doesn't index stuff/has even more errors because you haven't built yet. Having the build be part of the project generation is an attempt to address that scenario.\n\nThis is a tricky one - what if the project isn't in a buildable state and I want to configure my IDE as best as I can to work out why? I think your example is the stronger and more common use case though. In most cases once you've built the project once, it's more useful to give IntelliJ the best chance we can of configuring itself properly. Happy to go with whatever you decide.\n\nI'm aware of the fact that every folder ends up getting a package. I'd assumed it's more of a cosmetic problem (and so fixing it is low-pri). Is it really jarring or is it more of a \"huh? that's weird..\" sort of thing?\n\nFirst impression was \"that's weird, all the folders are the wrong colour\". I haven't worked out whether there's a genuine issue hidden in there but I wouldn't enjoy rolling it out to our team in this form - too many WTFs. I'm wondering whether for very large modules (we have a few because we migrated to Buck from a more monolithic structure) that we might break a limit of some kind but I can't be sure.\n\nYes, the new buck project will end up building a set of folders from the inputs of rules responsible for compiling source code and exclude everything else. This makes IntelliJ a lot faster if you have a lot of source files in your repo but are only working on a small subset. In your case would it be more appealing to take over control of the excludes set (define a list of folders and have those and only those be excluded) or would you prefer to turn excludes off entirely?\n\nIn our case, not everything is a BUCK module, perhaps it should be. But if it's not, then that doesn't mean we want to exclude it. A configurable exclude set would probably be more useful to us. That's how we do it now.\n\nbuck project --experimental-ij-generation currently doesn't emit neither misc.xml nor compiler.xml. This will be addressed in the future :)\n\nAwesome\n. Thanks for the detailed responses. \n\nbuck project --experimental-ij-generation will attempt to build the code. This is because both buck project --experimental-ij-generation and buck project reference stuff from buck-out. The difference is that plain buck project implicitly relies on the developer running the appropriate buck build command, so you can get into a state where IntelliJ doesn't index stuff/has even more errors because you haven't built yet. Having the build be part of the project generation is an attempt to address that scenario.\n\nThis is a tricky one - what if the project isn't in a buildable state and I want to configure my IDE as best as I can to work out why? I think your example is the stronger and more common use case though. In most cases once you've built the project once, it's more useful to give IntelliJ the best chance we can of configuring itself properly. Happy to go with whatever you decide.\n\nI'm aware of the fact that every folder ends up getting a package. I'd assumed it's more of a cosmetic problem (and so fixing it is low-pri). Is it really jarring or is it more of a \"huh? that's weird..\" sort of thing?\n\nFirst impression was \"that's weird, all the folders are the wrong colour\". I haven't worked out whether there's a genuine issue hidden in there but I wouldn't enjoy rolling it out to our team in this form - too many WTFs. I'm wondering whether for very large modules (we have a few because we migrated to Buck from a more monolithic structure) that we might break a limit of some kind but I can't be sure.\n\nYes, the new buck project will end up building a set of folders from the inputs of rules responsible for compiling source code and exclude everything else. This makes IntelliJ a lot faster if you have a lot of source files in your repo but are only working on a small subset. In your case would it be more appealing to take over control of the excludes set (define a list of folders and have those and only those be excluded) or would you prefer to turn excludes off entirely?\n\nIn our case, not everything is a BUCK module, perhaps it should be. But if it's not, then that doesn't mean we want to exclude it. A configurable exclude set would probably be more useful to us. That's how we do it now.\n\nbuck project --experimental-ij-generation currently doesn't emit neither misc.xml nor compiler.xml. This will be addressed in the future :)\n\nAwesome\n. Yes, your decription matches exactly what we see. I might try a standalone test to see what happens when you access a variable that references a class that has been unloaded via classloader.close().\n. We've tried a few simple tests and as the Javadoc for URLClassLoader.close() states \"any classes or resources that are already loaded, are still accessible.\" We can't reproduce a situation where closing the classloader of a loaded class causes a NPE, including when the parent classloaders are closed.\n. > What revision of checkerframework are you using? \nv1.9.4\n\nHow frequent is this NPE?\n\nPretty much guaranteed to happen as soon as we get a reasonable degree of parallel javac's happening. I can explore this in more detail if you think it would be helpful?\n\nI'd be curious to see exactly what is NPEing\n\nSee stacktrace at the top of this issue (v1.9.4)\n. Awesome. Looks like we missed that commit by a few hours, I'll pull the latest tomorrow and let you know how it goes.\n. @sdwilsh buckd also massively leaks memory for us - is there way of getting watchman without buckd/nailgun? We'd probably go for that.\n. It appears to be outside the JVM's heap so I'm guessing somewhere in nailgun it's leaking - i.e. buckd Xmx is at about 1000m from memory but we often see 11GB+ for the buckd process via top.\n. Here's a load of stats from various tools for a ./buckd process that appears to be using too much memory, i.e. after startup and running a build we see RSS of less than 1 GB and now, a few hours later it is 5 GB. Other members of the team have seen this go as far as 16GB on a machine with 24GB total - they tend to kill it at that point.\n```\n% smem -t\nPID User     Command                         Swap      USS      PSS      RSS \n14584 hancockd buckd -Xmx1000m -Djava.awt.        0  5085732  5088802  5096328\n% top\nKiB Mem:  24682644 total, 14207416 used, 10475228 free,   196088 buffers\nKiB Swap:        0 total,        0 used,        0 free,  2658684 cached\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                        \n14584 hancockd  20   0 14.439g 4.852g   5392 S  78.9 20.6  57:15.99 java  \n...\n% cat /proc/14584/status \nName:        java\nState:        S (sleeping)\nTgid:        14584\nNgid:        0\nPid:        14584\nPPid:        1\nTracerPid:        0\nUid:        1178        1178        1178        1178\nGid:        100        100        100        100\nFDSize:        1024\nGroups:        100 1000 1003 4000 4001 4002 4003 4004 4005 4006 4007 4008 4009 11005 11011 \nVmPeak:        16936660 kB\nVmSize:        15140088 kB\nVmLck:               0 kB\nVmPin:               0 kB\nVmHWM:         6418484 kB\nVmRSS:         5087212 kB \nVmData:        14976884 kB\nVmStk:             148 kB\nVmExe:               4 kB\nVmLib:           16772 kB\nVmPTE:           14160 kB\nVmSwap:               0 kB\nThreads:        45\nSigQ:        2/193123\nSigPnd:        0000000000000000\nShdPnd:        0000000000000000\nSigBlk:        0000000000000000\nSigIgn:        0000000000000000\nSigCgt:        2000000181005ccf\nCapInh:        0000000000000000\nCapPrm:        0000000000000000\nCapEff:        0000000000000000\nCapBnd:        0000003fffffffff\nSeccomp:        0\nCpus_allowed:        ffffffff,ffffffff\nCpus_allowed_list:        0-63\nMems_allowed:        00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001\nMems_allowed_list:        0\nvoluntary_ctxt_switches:        1\nnonvoluntary_ctxt_switches:        2\n```\n. Can confirm that the latest code fixes the shutdown issue. We still have awful memory usage, it seems to creap up even without any activity build activity. I ran a handful of builds before leaving last night, came in this morning and buckd is using 13GB of memory - a jmap heapdump  dumps only 1GB as expected so this is off-heap - we suspect NGUnixDomainSocketLibrary.java in nailgun-server but only because it appears to allocateMemory off-heap.\nAny ideas or suggestions for lines of investigation would be gratefully received.\ncat /proc/27459/status\nName:   java\nState:  S (sleeping)\nTgid:   27459\nNgid:   0\nPid:    27459\nPPid:   1\nTracerPid:  0\nUid:    1265    1265    1265    1265\nGid:    100 100 100 100\nFDSize: 256\nGroups: 100 209 1000 1003 4000 4001 4002 4003 4004 4005 4006 4007 4008 4009 11005 11011 \nVmPeak: 26420152 kB\nVmSize: 26368724 kB\nVmLck:         0 kB\nVmPin:         0 kB\nVmHWM:  14334604 kB\nVmRSS:  14328668 kB\nVmData: 26204240 kB\nVmStk:       148 kB\nVmExe:         4 kB\nVmLib:     16864 kB\nVmPTE:     35736 kB\nVmSwap:        0 kB\nThreads:    45\nSigQ:   4/193123\nSigPnd: 0000000000000000\nShdPnd: 0000000000000000\nSigBlk: 0000000000000000\nSigIgn: 0000000000000000\nSigCgt: 2000000181005ccf\nCapInh: 0000000000000000\nCapPrm: 0000000000000000\nCapEff: 0000000000000000\nCapBnd: 0000003fffffffff\nSeccomp:    0\nCpus_allowed:   ffffffff\nCpus_allowed_list:  0-31\nMems_allowed:   00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001\nMems_allowed_list:  0\nvoluntary_ctxt_switches:    1\nnonvoluntary_ctxt_switches: 4\n. With a little bit of profiling we see quite a few instances of com.martiansoftware.nailgun.NGUnixDomainSocketLibrary.SockaddrUn being created within the buckd process. However there's no code in this class to free up the memory that it allocates using Structure.allocateMemory(). While this isn't necessarily the source of our large leak it probably needs some attention.\n. Thanks for all the feedback - I think you're probably right, even if there is a small leak  it doesn't explain the massive memory usage we're seeing.\nI'm wondering also about ZipDeflater usage, this ancient issue http://bugs.java.com/view_bug.do?bug_id=4797189 and this comments on 1415c3f09343b1426bf11e84f4241de6c738b873 by @dreiss. Seems like it better matches our symptoms.\n. > Are you using an HTTP cache or HTTP fetching in your build process?\nNo.\n\nwhat version of the JVM are you running?\n\nJava(TM) SE Runtime Environment (build 1.8.0_60-b27)\n\nI pushed a potential fix for some leaks\n\nBrilliant - we're seeing a steady 2GB total memory usage (as reported by top) when I run our benchmarks. I'm going to push this out to our team and see how we get on but this is really good - thank you!\nMatt.\n. It's recent for us because we rebased from facebook/buck on 1st Sept for the first time since June. Not sure how I'd go about bisecting for this problem - except very slowly. Anything else I could look at?\n. No log produced, only a launch.trace which doesn't reveal anything useful, the tail of it is pasted below. \nRolling back to the version you suggested is quite tricky for us as we have a number of patches that we apply over the top of buck which tend to require a lot of merging. However, if this problem occurs for buckd running against the buck project itself then I could test that quite easily. I'll try it and let you know.\n{\n        \"args\": {},\n        \"cat\": \"buck-launcher\",\n        \"name\": \"BuckRepo._is_buckd_running\",\n        \"ph\": \"B\",\n        \"pid\": 23403,\n        \"tid\": 1,\n        \"ts\": 1297151216002\n    },\n    {\n        \"args\": {},\n        \"cat\": \"buck-launcher\",\n        \"name\": \"BuckRepo._is_buckd_running\",\n        \"ph\": \"E\",\n        \"pid\": 23403,\n        \"tid\": 1,\n        \"ts\": 1297152119090\n    },\n    {\n        \"args\": {},\n        \"cat\": \"buck-launcher\",\n        \"name\": \"BuckRepo.launch_buck\",\n        \"ph\": \"E\",\n        \"pid\": 23403,\n        \"tid\": 1,\n        \"ts\": 1297152119125\n    },\n    {\n        \"args\": {},\n        \"cat\": \"buck-launcher\",\n        \"name\": \"BuckProject.__exit__\",\n        \"ph\": \"B\",\n        \"pid\": 23403,\n        \"tid\": 1,\n        \"ts\": 1297152119160\n    },\n    {\n        \"args\": {},\n        \"cat\": \"buck-launcher\",\n        \"name\": \"BuckProject.__exit__\",\n        \"ph\": \"E\",\n        \"pid\": 23403,\n        \"tid\": 1,\n        \"ts\": 1297152119375\n    },\n    {\n        \"args\": {},\n        \"cat\": \"buck-launcher\",\n        \"name\": \"main\",\n        \"ph\": \"E\",\n        \"pid\": 23403,\n        \"tid\": 1,\n        \"ts\": 1297152119398\n    }\n. Appears to be fixed with the latest code, perhaps it was related to the race condition in nailgun shutdown. Thanks for your help.\n. Yes, something like this below. I would expect a change to findbugs.sh to trigger a rebuild of my-findbugs-rule - but it doesn't.\n```\nsh_binary(\n    name = 'run-findbugs',\n    main = 'findbugs.sh',\n    resources = glob( [ '*' ], excludes = [ 'findbugs.sh' ] ),\n    visibility = [ 'PUBLIC' ]\n)\ngenrule(\n    name = 'my-findbugs-rule',\n    srcs = glob( ['src/main/java/*/']),\n    cmd = '$(exe :run-findbugs) $SRCDIR etc etc',\n    out = '%s_result' % name,\n    deps = [ ':run-findbugs' ],\n    visibility = [ 'PUBLIC' ]\n)\n```\nEdited to fix typo and reference rule locally\n. Great explanation, I understand now and looking forward to seeing the effect on some of our long-running genrules.\n. I'm still getting issue in this area - let me know if I need to raise a new issue in github.\nI've got a genrule like this:\nexport_file(name = 'file1.txt')\nexport_file(name = 'file2.txt')\ngenrule(\n    name = 'check-file-test1',\n    srcs = glob( [ 'srcs/SomeSrc.java' ] ),\n    cmd = 'cat $(location :file1.txt) > $OUT && cat $(location :file2.txt) >> $OUT && cat $OUT 1>&2',\n    out = 'targ-file.txt',\n    deps = [\n        ':file1.txt',\n        ':file2.txt'\n    ]\n)\nThis gets triggered whenever file1.txt or file2.txt are modified. As expected.\nHowever if I modify the rule to look like this:\ngenrule(\n    name = 'check-file-test2',\n    srcs = glob( [ 'srcs/SomeSrc.java' ] ),\n    cmd = 'cat $(location :file2.txt) > $OUT && cat $OUT 1>&2',\n    out = 'targ-file.txt',\n    deps = [\n        ':file1.txt',\n        ':file2.txt'\n    ]\n)\nThen the rule is only triggered for changes to file2.txt and doesn't get run for changes to file1.txt. \nIs this expected/correct behaviour? Previously any material change to a dependency would cause a rule to be re-run.\n. Our use case is that we have certain jobs which we want to run every commit, even if the results would normally be cached. E.g. an integration test job that has some occasionally intermittent tests so we want to re-run the job every time there's a commit so we can record the level of intermittency.\nWe do this by writing the current svn revision number to a file and then exposing that file via export_file() and depending on it in rules that we want to run every commit.\nI know this is quite hacky however it's worked well for us so far.\nI actually prefer the behaviour you're working towards so I guess we'll have to find another hack. Simply using the dependency in the cmd works fine and we can probably wrap the whole of that in a custom macro.\n. Here's our .buckconfig.local. The key part is /buckcache/ this worked before that commit but not after. I haven't confirmed this myself but I'm told we're seeing cache requests going to the root URL instead.\n[cache]\n  mode = http\n  http_url = http://our.cache.server.lmax.com:9090/buckcache/\n  http_mode = readonly\n  http_timeout_seconds = 5\n. @bhamiltoncx Could this also be the cause of the slow response times you mentioned in 3d44018978210721a8a8dc5326972bebb1ada78d? I've never seen watchman version or watchman watch-project take long enough to warrant a 10s timeout.\n. The command-line exits quickly but NuProcess is checking open file handles or something equally magic (according to its docs), try this with a watchman process running:\nNuProcessBuilder processBuilder = new NuProcessBuilder(this, \"/path/to/watchman\", \"version\");\nfinal NuProcess process = processBuilder.start();\nprocess.waitFor(10L, TimeUnit.SECONDS);\nthen killall watchman and run it again.\nFor me, on the 2nd run it takes 10 seconds then timesout.\n. Yes, Fedora 20 kernel 3.19.\n. Our latest is:\ncommit b8fa3fa7c03a8df28deaa53ece5078d66024d1e4\nDate:   Thu Sep 24 14:05:36 2015 -0700\n. Have upgraded and tested - unfortunately it doesn't fix the issue. The test code I pasted in https://github.com/facebook/buck/issues/438#issuecomment-144429486 was run on the HEAD of master in NuProcess project itself. As far as I can see this is intended behaviour by NuProcess on both Windows and Linux - from the readme.md:\n\nOn Linux and Windows there is no method by which you can be notified in an asynchronous manner that a child process has exited.  Rather than polling all child processes constantly NuProcess uses what we call \"Soft Exit Detection\".  When a child process exits, the OS automatically closes all of it's open file handles; which is something about we can be notified.  So, on Linux and Windows when NuProcess determines that both the STDOUT and STDERR streams have been closed in the child process, that child process is put into a \"dead pool\".  The processes in the dead pool are polled to determine when they have truly exited and what their exit status was.  See com.zaxxer.nuprocess.deadPoolPollMs\n\nI can see by breakpointing my pasted code that the deadPool is empty until watchman is killed.\n. Yep, fixes - thanks!\n. I'm working on pulling some of the functionality up to base class. What did you mean by concrete base class? As in not abstract? I don't quite understand when you'd actually want to use it rather than one of its implementations?\n. @sdwilsh, I keep hitting deadends trying to break out some common \"jvm-language\" functionality so that Java, Groovy, Kotlin etc can be supported with minimal code duplication. I think the code needs a bit of re-organisation first. There's a few issues that I keep on butting up against. E.g. JavaLibrary...\n\nThings like HasClasspathEntries and HasSources don't really seem to fit. HasClasspathEntries is used indirectly by almost everything. When I make its methods return something more abstract it ends badly deep within AndroidBinaryGraphEnhancer.\nI'm happy to have a go at this but only if you're sure a pull-request is the right way to go about it. Changes would probably cause major merge headaches. A small price to pay for the merge hell I go through keeping this Groovy support working in a fork though.\n. > If there is some substantial cleanup to do create smaller pull request we can merge in early in the process so you don't have to keep remerging the changes.\nHere's a structure which breaks up the com.facebook.buck.java package to make it easier to add support for additional JVM languages\n- c.f.b.java - perhaps renamed to jvmlang\n  - lang-specific, e.g. java, groovy, scala, kotlin\n    - lang-specific build rule code, e.g. java_library, java_binary\n    - lang-specific shared implementation, e.g. javac related code\n  - supporting rules relevant for several languages, e.g. jar packaging, source jars\n  - supporting shared implementation relevant for several languages, e.g. classpath and dependency wrangling\nIf you think this is ok then we could do this as a single pull request although our preference would be several smaller increments to ensure that we don't cause merge problems.\nWhat do you think?\n. IRC sounds like a good idea. Sorry if I'm missing the obvious - which server/channel?\n. Agreed. Closing.\n. Agreed. Closing.\n. I can't (yet) reliably reproduce but I'm not running buckd.\n. Eventually reproduced this by running two versions of buck against the same project. Apologies, hope I didn't waste too much of anyone's time. Closing.\n. Eventually reproduced this by running two versions of buck against the same project. Apologies, hope I didn't waste too much of anyone's time. Closing.\n. Yeah, I'd tried that. It's not that the test results are cached - they do get re-run. It's just that the tests are not being recompiled first.\nI'm guessing that buck finds a copy of the previously built artifact in the directory cache and decides to use it, hence the FETCHED_FROM_CACHE. But then it doesn't use it to run the tests against - not sure how that goes astray.\n. Additionally, if I turn off directory caching with the following in .buckconfig then the problem goes away:\n[cache]\n    mode =\n. Appears to be fixed by the same change as #827.. I've just noticed there's a boolean param for wantsPackagePrefix, I'll have look to see if that solves problem 3 above.\n. Setting package prefix to false removes the package prefix and it turns out the exclude was there because of an unnecessary folder. So 3 above is fully resolved.\n. Awesome, let me know if I can help test your patch.\n. @marcinkosiba Hi, you've no doubt got your own priorities but if I could possible help with getting this fix in the please let me know. We're doing a massive migration to Buck and rebuilding classpaths by hand and this issue is really slowing us down. It also gets a lot of wtfs from people when they encounter it for the first time which isn't helping me sell Buck :) \n. Looks like this commit introduces the problem 550bbe1de1e4c263056425b57b372eef5df09f86\n. Thanks, that appears to fix it.\nIt's also fixed in master somewhere in early Sept, I think between these 2 commits - 090ecd66530504e9e7346dc040ffe1b65319c1a9 and d08ca157b4489cfe7f3f19f0a9319aff45ff83b8.\n. I was mistaken in my previous comment - this commit fixes the issue in master d08ca157b4489cfe7f3f19f0a9319aff45ff83b8\n. As far as I know it's greedy but must still match the .trace a the end so it'll work. I think this is superceded by @bgertzfield's comment below but let me know if you still want an additional file added to the test.\n. Done.\n. ",
    "gonzojive": "Directory handling is also an issue for glob()s and srcs() that I'd expect to include directories, not just source files.\nHere's my original post on the mailing list:\nHow should buck handle (empty) directories in srcs and globs?  It seems to me they should be copied into the srcs directory as if by \"cp -R\".\nI'm attempting to create a genrule that's similar to issuing the command \"zip -r -FS release-0.1.1.zip \" from the project root.  It seems glob([\"__/\"]) matches pretty much everything except empty directories and files that start with a dot.\nI also noticed that specifying a directory in srcs results in an error:\n[+] BUILDING...0.0s^[[?7h\njava.lang.RuntimeException: Not an ordinary file: tmp/tmp2\nHere's the zipfile rule:\ngenrule(\n  name = 'zipfile',\n  out = 'release.zip',\n  srcs = glob(['/']),\n  bash = 'cd \"$SRCDIR\" && zip --filesync -r \"$OUT\" ',\n)\n. ",
    "sschuberth": "In addition to that, I had the impression that Buck required the Android SDK even when building a pure Java project, in my case a Gerrit plugin. Also see my post on the mailing list. But maybe it just looked like that as Buck was somehow updating itself when building the Gerrit plugin, thus building itself before it built the plugin, and so it was not building the Gerrit plugin but building Buck that required the Android SDK.\n. If Cygwin is good enough, this more or less is a dupe of issue #195 (which has some nice progress, it seems).\n. > I'm not sure if the support library handles this now, or if it just works with Lollipop and newer devices.\nThe multidex-support library transparently handles loading multiple dex files on pre-Lollipop devices, you just need to derive from MultiDexApplication to use the custom class loader. On Lollipop, where the VM natively supports multiple dex files, using the multidex-support library is a no-op.\nThat said, adding support for creating multiple dex files by making Buck call dx with the --multi-dex option would be nice! Also, just like Gradle, Buck should be able to automatically determine the list of classes to pass to the --main-dex-list option, see the Android SDKs mainDexClasses script.\n. @llj098 Like I said, this is not sufficient. You also need to determine the list of classes that need to go to the main dex file. Otherwise it's just a matter of luck if all classes that you app needs at startup end up in the main dex file.\n. Done, I've split out the typo fixes to PRs #323 and #324.\n. As long as the daemon is inheriting the client's environment that should not be a problem, or?\nOther than that, any hints on how to explicitly get the client's environment?\n. Done.\n. Done.\n. ",
    "scrivener": "Any news on this? I also have the need to use genrule() outputs as assets.\n. ",
    "k21": "It is now possible to have genrules that output directories. android_resource unfortunately still does not accept outputs of other targets in its res and assets parameters, but that should not be too hard to change.\n. This should now work as expected.\n. Cross repo (or cross cell, as we are going to call it) is currently under development and although preliminary support has landed in the master branch, most build rules do not support it properly yet.\n. This has been merged in https://github.com/facebook/buck/commit/f2dfafa638415c26e0c73ea059a68be74be8eedb.\n. From IRC discussion it looks like no metadata directory is created in buck-out/bin/tools/.hello, which is where the old rule keys should be stored. Without it, Buck doesn't have anything to compare the new rule key against.\n. Thanks for your contribution! Can you please share your use-case for this feature? I would like to understand in what context it will be used.\n. I have found a slight issue with your tests. We would like to be able to run Buck's tests with older Python versions (2.6). Your test code uses argparse and with on a zipfile, which are not supported in that Python version. Can you please fix the new test to work with Python 2.6?\n. > added a description that should give you an idea of where I'm going with this.\nI might be looking in the wrong places, but where did you add the description? I don't see it anywhere.\n. One issue I see is if people tried to build something in two different projects that share their buck-out at the same time, that would almost definitely break unless we check for that case in Buck and only allow one of those builds at a time.\n. You can specify max heap size for proguard by putting this into your .buckconfig:\n[tools]\nproguard-max-heap-size = 2G\nI am going to update the issue to add this to the documentation as well.\n. Hm, the heap size for the external dx is currently not customizable. To unblock yourself, you can override it in DxStep by putting e.g. \"-JXmx1g\" there. We might make it configurable or at least increase the default in the future, but sending a pull request would be the fastest way to get the change in.\n. One of Buck's goals is to ensure that the builds are reproducible, e.g. that you can check out an old revision of your repository and build it and get the same result you got when you just created that revision. remote_file is a convenience rule that goes against that goal by making the build dependent on external services. If the hash of the downloaded file was not checked, there would be three possible outcomes:\n1. The external service works and it gives you the same file as you expect. You get the correct build.\n2. The external service is offline or broken and the download fails. The build fails.\n3. The external service is broken or malicious and it serves you a different file than you expect. Your build might succeed, but the output will be different than what you would expect.\nWhile it is difficult to address the 2nd point while still keeping the convenience of remote_file, the 3rd point can be prevented fairly simply by checking the hash of the downloaded file.\nYour approach that downloads the hash from the maven server will not be protected against the silent failure which can happen in the 3rd case. Also, if you are making a network connection every time the BUCK files are parsed, your build times will suffer. If you want to make use of all of Buck's advantages, I would recommend specifying the hash in your BUCK files.\n. I guess it might make Buck slightly easier to use but repeatable builds are higher priority for us than this convenience. Even making the field optional means that you can no longer trust a Buck project to have repeatable builds unless you are the only developer working on it or you review all of its commits, which is impossible for any bigger project.\n. > Maybe the quickstart (or any other project skeleton builder) would take the list of dependencies and if no SHA1 is provided - fetch it from maven and generate remote_file() rules with the fetched SHA1?\nI think that sounds like a pretty good approach.\n. @shs96c I have created #327 to add documentation for the maven importer.\n@zserge I hope your questions have been answered or will be answered soon in the new documentation. If not, please reopen the task.\n. Unfortunately we don't have this functionality in Buck (yet). There were some talks about allowing custom extensions, but it is currently not our top priority. But I think if you wrap the compiler in a nailgun server yourself, Buck will work with it just fine (as long as the compiler itself works with nailgun - it will need to know to use the environment of the client process instead of the server process and so on).\n. I don't think it is possible to reuse Buck's nailgun. Buck can sometimes be distributed as a Python pex package and then there is no Buck repository with the third-party jars. You can just check-in the nailgun prebuilt jar and c sources into your repo, that is what Buck does.\n. Having a prebuilt binary and calling it from a genrule is also possible, although then you lose portability. But that is a compromise you will need to make yourself. I hope I have answered your questions. I am closing the task, please reopen if you need more information.\n. Thanks for your contribution! Can you please create separate pull requests for each commit? It will work better with our internal systems and we can review the commits independently. For example the typo fixes can be merged fairly quickly, but the Android SDK directory discovery might require some discussion.\n. I have merged your changes internally. I think @sdwilsh is going to export them to the Github repo later today. Thanks again!\n. Yes, I think it usually makes more sense to make the android_resource a dependency of the android_library that uses it. It is likely that buck quickstart is outdated. By the way, I saw your https://github.com/zserge/buckbone script. If you would like to get some of that functionality into Buck, pull requests are welcome :)\n. The android_binary no longer accepts the target parameter, you should instead specify it in .buckconfig. Can you please tell us where you found the walkthrough you are following so we can update it as appropriate?\n. The android_binary no longer accepts the target parameter, you should instead specify it in .buckconfig. Can you please tell us where you found the walkthrough you are following so we can update it as appropriate?\n. Thanks @Stoff81, you are right, I have filed #681 for that.\n. The headers parameter is supposed to contain the individual files, not folders (see cxx_library documentation). You can use the glob function if you want to use all files from a certain directory. We should  add checks to enforce that those paths are not directories.\n. The headers parameter is supposed to contain the individual files, not folders (see cxx_library documentation). You can use the glob function if you want to use all files from a certain directory. We should  add checks to enforce that those paths are not directories.\n. This might be related to #363, which seems to be caused by a bug that broke the logic responsible for stopping the SuperConsole when there is extra output. We have a fix ready and we will publish it either tomorrow or early next week, hopefully it will fix this issue.\n. This might be related to #363, which seems to be caused by a bug that broke the logic responsible for stopping the SuperConsole when there is extra output. We have a fix ready and we will publish it either tomorrow or early next week, hopefully it will fix this issue.\n. Some of Buck's classes are autogenerated by the Immutables library. In IntelliJ you can use \"Build -> Make Project\" to generate those classes and get rid of the missing symbol errors.\n. From the traces it looks like almost all of the time in the no-op build is spent computing the rule keys, which usually means hashing the source files. If you are using buckd, then hashes of files in the repo should be cached, so the reason of the slow build is either that you are not using buckd or that the rules refer to files outside of the repository.\n. Also also, running ant -v might output more information about which Java compiler and what options are used.\n. Both the original error messages and the invalid target release: 7 message suggest that ant is for some reason trying to use Java compiler older than 1.7. Unfortunately I don't see anything in ant's output that would suggest why. All I can find online is http://stackoverflow.com/questions/16029668/ant-is-using-the-wrong-java-compiler-but-thinks-its-right, which seems to describe the same issue, but does not have an accepted answer.\nI am not sure how to proceed. It might help to uninstall any older version of Java if there is any on your system.\n. @mikekap, I am trying to enable Travis builds for the Buck repo and there seem to be issues with the Go tests. The compilation is failing with messenger/messenger.go:3: can't find import: \"fmt\". See https://travis-ci.org/k21/buck/builds/85138691 for the whole build or the log below for the relevant lines from the log. I don't have experience with Go so I have no idea if there is anything misconfigured or if any packages are missing. Do you know what could be the issue?\n[2015-10-13 15:09:26.914][debug][tid:77][com.facebook.buck.step.DefaultStepRunner] StepStarted(go compile)\n[2015-10-13 15:09:27.047][debug][tid:77][com.facebook.buck.shell.ShellStep] [/home/travis/.gimme/versions/go1.5.1.linux.amd64/pkg/tool/linux_amd64/compile, -p, messenger, -pack, -trimpath, /tmp/buck-85bebb76-db65-440c-8601-7aa8bbf9f4f0/test/com/facebook/buck/go/__java_test_integration_tmp__/junit2727049556196031897, -nolocalimports, -o, buck-out/gen/messenger/messenger/messenger.a, -I, buck-out/bin/messenger/__messenger#symlink-tree__tree, messenger/messenger.go]: exit code: 2. os load (before, after): (35.800000, 35.800000). CPU count: 16.\nstdout:\nmessenger/messenger.go:3: can't find import: \"fmt\"\nstderr:\n[2015-10-13 15:09:27.047][debug][tid:77][com.facebook.buck.step.DefaultStepRunner] StepFinished(go compile)\n. It looks like the directory entry contains the directory of the file instead of the working directory from which the command should be executed. That should be fixed. The extra args key is not mentioned in the specification, but it is also not forbidden, so I don't think it makes the database invalid. The command entry that you have pasted is a valid command if you do JSON unescaping, I don't see an issue there.\nPlease also let us know how you are using the compilation database output and what errors you are seeing, having a way to test if our changes work will make fixing the issue easier.\nAlso, can you please try replacing bucksamples/cross-platform-scale-2015-demo/common in the directory entry with bucksamples/cross-platform-scale-2015-demo and try using the modified file? I suspect it might resolve the issues you are seeing.\n. @dreiss has actually just made the exact same change internally, it will go out in the next open-source push. Sorry we did not get that information to you earlier. :(\n. Closed by https://github.com/facebook/buck/commit/9d50192185ae23d300a718018910c7988e28405f.\n. No, you don't it is a part of a standard Python installation.\nThe error message says that the file apps/DEFS in your copy of the AntennaPod repo does not exist, but it should not be used at all. Can you please check if you have .buckconfig file or .buckconfig.d directory in your home folder? It looks like some configuration file somewhere is setting\n[buildfile]\n    includes = //apps/DEFS\nwhich breaks the AntennaPod repository.\n. No, you don't it is a part of a standard Python installation.\nThe error message says that the file apps/DEFS in your copy of the AntennaPod repo does not exist, but it should not be used at all. Can you please check if you have .buckconfig file or .buckconfig.d directory in your home folder? It looks like some configuration file somewhere is setting\n[buildfile]\n    includes = //apps/DEFS\nwhich breaks the AntennaPod repository.\n. In that case please upload the logs from buck-out/log/buck-0.log somewhere, they should tell us where that setting is coming from.\n. In that case please upload the logs from buck-out/log/buck-0.log somewhere, they should tell us where that setting is coming from.\n. Here is the issue:\nLoaded a configuration file /home/ai/.buckconfig: {alias={app=//apps/com.example.build:app}, java={src_roots=/java/}, project={default_android_manifest=//res/AndroidManifest.xml}, android={target=Google Inc.:Google APIs:21}, buildfile={includes=//apps/DEFS}, download={maven_repo=http://repo1.maven.org/maven2, in_build=true}}\nLooks like there is a file at /home/ai/.buckconfig that defines this setting. You should probably remove it.\n. Here is the issue:\nLoaded a configuration file /home/ai/.buckconfig: {alias={app=//apps/com.example.build:app}, java={src_roots=/java/}, project={default_android_manifest=//res/AndroidManifest.xml}, android={target=Google Inc.:Google APIs:21}, buildfile={includes=//apps/DEFS}, download={maven_repo=http://repo1.maven.org/maven2, in_build=true}}\nLooks like there is a file at /home/ai/.buckconfig that defines this setting. You should probably remove it.\n. Did that fix the issue?\n. Did that fix the issue?\n. Can you please also share the actual logs that you ran the diff script on? Unfortunately the diff script is not perfect and there seems to be some information missing from its output. I would also like to investigate why it is reporting conflicts for rule names, that should not be happening.\n. Can you please also share the actual logs that you ran the diff script on? Unfortunately the diff script is not perfect and there seems to be some information missing from its output. I would also like to investigate why it is reporting conflicts for rule names, that should not be happening.\n. Based on the logs, this seems to be the root of the difference:\nRuleKey deadd8c67d89bd1c7df2a438f92906d232968736=string(\"\"):key(metadata_path):string(\"\"):key(resources_path):string(\"\"):key(executables_path):string(\"\"):key(frameworks_path):string(\"\"):key(plugins_path):\nRuleKey 819206430cccf02442865351c574e74e8d33a39d=string(\"\"):key(metadata_path):string(\"\"):key(resources_path):string(\"\"):key(executables_path):string(\"\"):key(frameworks_path):string(\"PlugIns\"):key(plugins_path):string(\"Watch\"):key(watch_app_path):\nThe second log has correct paths for plugins and watch apps, the first one uses empty path for plugins and is missing the watch app path entirely. I am fairly sure that can never happen on builds using the same Buck version. Are you sure the Buck versions you are the same on both machines? (BTW, if you are using Buck from a repo, make sure to run ant clean in its repo to make sure Buck is rebuilt to the version that you have checked-out, otherwise it reports different version than the one that is actually running).\n. Based on the logs, this seems to be the root of the difference:\nRuleKey deadd8c67d89bd1c7df2a438f92906d232968736=string(\"\"):key(metadata_path):string(\"\"):key(resources_path):string(\"\"):key(executables_path):string(\"\"):key(frameworks_path):string(\"\"):key(plugins_path):\nRuleKey 819206430cccf02442865351c574e74e8d33a39d=string(\"\"):key(metadata_path):string(\"\"):key(resources_path):string(\"\"):key(executables_path):string(\"\"):key(frameworks_path):string(\"PlugIns\"):key(plugins_path):string(\"Watch\"):key(watch_app_path):\nThe second log has correct paths for plugins and watch apps, the first one uses empty path for plugins and is missing the watch app path entirely. I am fairly sure that can never happen on builds using the same Buck version. Are you sure the Buck versions you are the same on both machines? (BTW, if you are using Buck from a repo, make sure to run ant clean in its repo to make sure Buck is rebuilt to the version that you have checked-out, otherwise it reports different version than the one that is actually running).\n. No, it is hardcoded in the code, that is why I believe that your two machines are running different versions of Buck. In particular it looks like only one of your machines has https://github.com/facebook/buck/commit/085eef778ca3e0ed244b0ddbe1bba97065eea9fd. Are you sure you didn't add another Buck installation or checkout on your PATH on one of the machines?\n. No, it is hardcoded in the code, that is why I believe that your two machines are running different versions of Buck. In particular it looks like only one of your machines has https://github.com/facebook/buck/commit/085eef778ca3e0ed244b0ddbe1bba97065eea9fd. Are you sure you didn't add another Buck installation or checkout on your PATH on one of the machines?\n. We have resolved this on IRC, it turned out to be caused by different Buck versions between the machines, plus incorrect configuration of the client.\n. We have resolved this on IRC, it turned out to be caused by different Buck versions between the machines, plus incorrect configuration of the client.\n. It looks like your shell did not expand ~ to the absolute path to your home directory when the variable was assigned. Buck does not do this expansion, so you will have to change the contents of ANDROID_HOME to contain the absolute path. Use either export ANDROID_HOME=\"${HOME}/Library/Android/sdk\" or export ANDROID_HOME=~/Library/Android/sdk to do that (in the second case note that there cannot be quotes around ~, otherwise the shell won't expand it).\n. It looks like your shell did not expand ~ to the absolute path to your home directory when the variable was assigned. Buck does not do this expansion, so you will have to change the contents of ANDROID_HOME to contain the absolute path. Use either export ANDROID_HOME=\"${HOME}/Library/Android/sdk\" or export ANDROID_HOME=~/Library/Android/sdk to do that (in the second case note that there cannot be quotes around ~, otherwise the shell won't expand it).\n. The *ThreadStateRendererTest failures are my fault, I have just added them before the @bhamiltoncx's fix and they are using the system default locale. I will make sure to fix them soon.\n. The *ThreadStateRendererTest failures are my fault, I have just added them before the @bhamiltoncx's fix and they are using the system default locale. I will make sure to fix them soon.\n. I think I have a fix for the failing Android tests in #572.\n. @mogers, are you interested in rebasing and updating this pull request or should I close it?\n. The first case you have mentioned does not guarantee that the dependencies will be rebuilt when they change (they won't be if Buck determines that the genrule's output does not depend on the outputs of the rules) and having the parameter available made it likely that people using the rule will reach the wrong conclusion and rely on broken functionality.\nThe second use case you mention does not currently have a better workaround, but I think it would be preferable to have a dedicated mechanism to specify meta-rules like this over relying on fake genrules that do nothing.\n. Travis is failing in GroovyTestIntegrationTest which is unrelated to this change.\n@facebook-github-bot shipit\n. It is not recommended to import external Python modules because Buck is not aware that they are used and does not re-run the BUCK files when the external modules change. The recommended way is to use the include_defs function in your BUCK file which lets you execute another file in the same repo.\n. It is not recommended to import external Python modules because Buck is not aware that they are used and does not re-run the BUCK files when the external modules change. The recommended way is to use the include_defs function in your BUCK file which lets you execute another file in the same repo.\n. I hope that answered your question. Please let me know if you need any clarification.\n. I hope that answered your question. Please let me know if you need any clarification.\n. We were thinking about standardizing the rules' output directories which would let us move all this set up / clean up code into a single common place and we could stop doing it ad-hoc in each rule (cc @Coneko). It would help make code like this more succinct and less error prone. Unfortunately we did not get to it yet. Unless there is a good reason to remove the step right now, I would prefer keeping it for now and cleaning it up together with everything else once we unify the logic in a single place.\n. We were thinking about standardizing the rules' output directories which would let us move all this set up / clean up code into a single common place and we could stop doing it ad-hoc in each rule (cc @Coneko). It would help make code like this more succinct and less error prone. Unfortunately we did not get to it yet. Unless there is a good reason to remove the step right now, I would prefer keeping it for now and cleaning it up together with everything else once we unify the logic in a single place.\n. A similar bug was fixed in 435cbc057866b0aa9e9537c4656330199f72a9b5. Can you please try if you can reproduce the issue with the latest release?\n. Unfortunately I had to revert this PR because it breaks some of our internal infrastructure that uses an external test runner. I will try to get it fixed an re-land it when it is ready.\n. Yes, the issue was that the format in which tests were passed to the external test runner has changed. If the pull request either avoids changing the format or puts it behind a buckconfig option, I can reimport it without changing anything on our side, which would probably be easier and faster.\n. @facebook-github-bot import\n. Did you wrap some configuration value in double quotes? The values in .buckconfig usually shouldn't be using quotes. Send us your .buckconfig if this does not resolve your issue.\n. Did you wrap some configuration value in double quotes? The values in .buckconfig usually shouldn't be using quotes. Send us your .buckconfig if this does not resolve your issue.\n. The manual quick start guide was removed.. Thanks for the report, I have checked that the issue reproduces on the master branch as well. It looks like we are not getting modification events from Watchman. I will try to find the commit that broke this.\n. Bisect points to 10942e9e65ce4905bbc7a276e4a18d1d40a2807d as the breaking commit. The problem seems to be caused by this line in your .buckconfig:\nignore = .git, **/.svn,\nDue to the trailing comma, the newer version of Buck parses this value as a list of 3 elements where the third element is an empty string representing the root of the repository. Removing the trailing comma fixes the issue:\n```\n--- a/.buckconfig\n+++ b/.buckconfig\n@@ -7,4 +7,4 @@\n        target = android-23\n[project]\n-       ignore = .git, /.svn,\n+       ignore = .git, /.svn\n```\nThere is a work in progress to abort the build when someone tries to build a target in an ignored directory, which would make problems like this easier to debug.\n. Looks like the new check in 9f45799db1cd25b02dadc7cc982f2264c1c13153 revealed an existing issue. buck test is equivalent to buck test //..., so it recursively finds all test targets, including targets under lib/jgit. This way you should get a graph that contains both //lib/jgit:something and @jgit//:something. However the parser cache uses only the absolute path of the BUCK file as the key, so it only parses that file once, although they should be treated as two different files.\nAs a workaround, you can add lib/jgit to project.ignore in .buckconfig, which will stop Buck from trying to parse //lib/jgit:something and only use the @jgit//:something targets if other targets depend on them.\n. @Dominator008 the buck audit problems seem to be caused by a different issue, however I am unable to reproduce them on Buck's master branch (673c14330b16b9e86ea425ad3d369dc28f8ae83a) and Gerrit revision 8a867d6414b55a3a6edb6f0b12725f4477301618. Can you please check if getting the latest Buck version fixes the problem? If not, please let me know which Gerrit commit you are using.\n. @Dominator008 the buck audit problems seem to be caused by a different issue, however I am unable to reproduce them on Buck's master branch (673c14330b16b9e86ea425ad3d369dc28f8ae83a) and Gerrit revision 8a867d6414b55a3a6edb6f0b12725f4477301618. Can you please check if getting the latest Buck version fixes the problem? If not, please let me know which Gerrit commit you are using.\n. @davido I think Buck should handle building the target both locally and as a cross-cell target, so I do consider this a bug. Only using one of the options in all invocations and dependencies fixes this, but it's just a workaround.\nWe decided to completely drop the cross-cell prefix in the latest Buck revision (the + would introduce ambiguities in buck query syntax). The motivation is to make it possible to run for example buck build jgit//org.eclipse.jgit.archive:jgit-archive__download_src and have it build the cross-cell target, unfortunately this functionality is not implemented yet.\nRight now the only way to build a target from another cell is to cd into that repository and build the target there. If that is not feasible for your build, then hopefully we can either get this problem fixed or get the cross-cell building from CLI implemented soon.\n. @davido I think Buck should handle building the target both locally and as a cross-cell target, so I do consider this a bug. Only using one of the options in all invocations and dependencies fixes this, but it's just a workaround.\nWe decided to completely drop the cross-cell prefix in the latest Buck revision (the + would introduce ambiguities in buck query syntax). The motivation is to make it possible to run for example buck build jgit//org.eclipse.jgit.archive:jgit-archive__download_src and have it build the cross-cell target, unfortunately this functionality is not implemented yet.\nRight now the only way to build a target from another cell is to cd into that repository and build the target there. If that is not feasible for your build, then hopefully we can either get this problem fixed or get the cross-cell building from CLI implemented soon.\n. Yeah, that's the goal.\n. Yeah, that's the goal.\n. That looks like a recent regression in the open-source sync logic. We do rebase all commits to keep a linear history which is why facebook-github-bot shows up as the committer, but the author should be the original contributor. This was the case for pull requests until recently, e.g. 20639e0674d5c1d601386f700e0282770aa7d382, f302d65c8aa67da5a47eff7349424050eb8adbc8 or 2f8f2739bd469aa4eb7ed4b1e018ed1f5635fcf1. Sorry for the inconvenience, I will make sure people maintaining the open-source sync are aware of the issue. Thanks for reporting!\n. ExecutionContext is generated by the Immutables library from AbstractExecutionContext. Using Build -> Make Project in IntelliJ should generate those sources and fix the issues you are seeing. Does that work for you?\n. ExecutionContext is generated by the Immutables library from AbstractExecutionContext. Using Build -> Make Project in IntelliJ should generate those sources and fix the issues you are seeing. Does that work for you?\n. Since Buck does not need the NDK to build itself, unsetting ANDROID_NDK before installing Buck should fix this. After that, you can override the compiler version by putting this in the .buckconfig file in your project:\n[ndk]\n  gcc_version = 4.9\n. You need to use the name of the target that generates the source file, so in your case it would be either '//:test-peg' or ':test-peg'. What is the output when you try one of those?\n. Just by itself, without the $(location ) part.\n. This is most likely because the second time the target you built was already present in the cache and so its dependencies did not need to be built. If you want to pass the symlink tree to another rule, then explicitly reference the symlink tree target (e.g. with :res_release#assets-symlink-tree), not something that depends on it. Buck does not guarantee to build all dependencies of the target that you have requested.. Both resource and asset symlink trees are created in AndroidResourceDescription. It is possible that robolectric_test uses one of the two symlink trees directly and only depends on the other one transitively. In particular, AndroidLibraryGraphEnhancer seems to collect all transitive resource dependencies and maybe they get used as direct dependencies later, which would explain why the symlink tree is always created. Assets, on the other hand, probably get aggregated into another rule first so the test rule does not depend on the symlink trees directly. Those are all implementation details though, adding an explicit dependency on the symlink tree you need should solve the problem without having to rely on Buck's internals.\nFeel free to reopen the issue if you are planning to work on this, although note that always building all asset symlink trees when a test is built is probably not the right answer as they should not be required in most cases.. I see. In that case you will still want to make sure that both of the symlink tree rules are not only direct dependencies of the robolectric test rule, but also runtime dependencies.. Please annotate this field with @Nullable.\n. I am afraid that when we run with the daemon, System.getenv() will give you the environment of the daemon process. We should make this use the client's environment.\n. No, the daemon's System.getenv() will stay the same even if the client's environment changes. In this case I think you can use params.getRepository().getAndroidDirectoryResolver() to get the resolver and avoid creating a new instance.\n. I think that flavor is used to distinguish between targets belonging to the test library from the ones from the test bundle. The headers usually belong to apple_library, so they have that flavor here. It should be fine to remove that flavor but it might require changing createBuildRule for the test description and probably some other code that looks up this rule by the build target.\n. Why does the worker tool need to read its rule key from the disk? Cannot it use a RuleKeyBuilderFactory? I would prefer that over relying on mutable external state.\n. The key should probably include the target's cell in some form to avoid false sharing of workers between rules in different cells.\n. Unfortunately I think outside of the parser the cell prefix is not present in the build targets because it would have to change based on which cell references the target (two cells can be using a different names for another cell or the same name for different cells). Explicitly adding the cellPath from the build target should work well though.\n. The RuleKeyBuilderFactory classes have a cache of all computed rule keys on them, so it should be cheap. The part I worry about when using OnDiskBuildInfo is that it can only be safely called after the rule has been built and the call to it is buried in the call stack of a method that doesn't communicate this requirement in any way (WorkerMacroArg#getWorkerHash). But since violating that would result in an exception which should be caught by the tests, it is probably not such a big deal.\n. In Python code we generally don't use parentheses around the condition in if statements, please remove those here and on the line above.\n. If you want to use exceptions here, change this block to only handle the exact error type that gets raised when the process exits with a nonzero code. Although I would prefer using subprocess.run instead and checking the returncode manually.\n. This and the next change don't look right, I think the format should be changed to something like %1$s=%2$s and %1$s=%3$s (or the positional arguments can be removed and we can just pass key, value, key, existing).. This looks like it will work correctly, but I would prefer to keep digit as an int instead.. This seems very similar to the sources for the doc jar, maybe extract the common parts in a single place outside of the conditional.. Shouldn't this depend on the mavenPomTemplate as well? From how it is used, it looks like it might even need to be a runtime dependency.. Add some more information about where the problem happened, e.g. which file. I am also not convinced this should be an IllegalStateException since it is essentially a user error.. Not sure if this shouldn't be an error condition instead, we probably shouldn't assume default package for broken source files or if there are bugs in the parser.. Why is whitespace at EOF UNKNOWN instead of WHITE_SPACE?. Again, it feels like this should be a comment, not unknown.. Same.. I am not sure why the value is needed here, but since it is passed, it looks like this will contain the last *, but not the /.. It looks like resourcesRoot can be null, which would make this throw a NullPointerException, please address.. ",
    "benkc": "I got it (kind of) working.  Below is a stripped-down, commented version of what I ended up doing.  I don't know when the plan is for deprecating the gen_aidl rule, but in the meantime, putting something like this in the documentation would be good.\n```\nandroid_library(\n  name = 'foo_service_debug',\n  visibility = ['PUBLIC'],\n  srcs = glob(['Android/src/*/.java'])  + \\\n  # Also include the generated .java files as sources.\n  [genfile(f) for f in [\n      'Android/src/com/blah/blah/blah/ipc/IFoo.java',\n      'Android/src/com/blah/blah/blah/ipc/IBar.java',\n      'Android/src/com/blah/blah/blah/ipc/IBaz.java',\n      # ...and so on...\n  ]],\ndeps = [\n          ':aidl_1',\n          ':aidl_2',\n          ':aidl_3',\n          # ...and so on...\n         ],\n)\nAIDL stuff is tricky in BUCK.\n1) Each gen_aidl rule can seemingly only process one .aidl file\n2) The import_path is relative to where you run buck from (ie,\ntrunk, where the .buckconfig file is) not relative to the BUCK\nfile like all other buck paths\n3) The import_path must point to the root of the src dir that the\n.aidl files are somewhere under.  ie, Android/src, not\nAndroid/src/com/blah/blah/blah/ipc\nHandy reference links:\nhttps://github.com/facebook/buck/issues/29\nhttps://github.com/facebook/buck/issues/103\nhttp://stackoverflow.com/questions/2179453/how-do-i-use-aidl-tool-from-command-line-using-sdk-sample-code\ngen_aidl(\n    name = 'aidl_1',\n    aidl = 'Android/src/com/blah/blah/blah/ipc/IFoo.aidl',\n    import_path = 'libs/foo_service/Android/src/',\n)\ngen_aidl(\n    name = 'aidl_2',\n    aidl = 'Android/src/com/blah/blah/blah/ipc/IBar.aidl',\n    import_path = 'libs/foo_service/Android/src/',\n)\ngen_aidl(\n    name = 'aidl_3',\n    aidl = 'Android/src/com/blah/blah/blah/ipc/IBaz.aidl',\n    import_path = 'libs/foo_service/Android/src/',\n)\n...and so on...\n```\nEdit: updated example to include the genfile part, that I was missing.\n. I got it (kind of) working.  Below is a stripped-down, commented version of what I ended up doing.  I don't know when the plan is for deprecating the gen_aidl rule, but in the meantime, putting something like this in the documentation would be good.\n```\nandroid_library(\n  name = 'foo_service_debug',\n  visibility = ['PUBLIC'],\n  srcs = glob(['Android/src/*/.java'])  + \\\n  # Also include the generated .java files as sources.\n  [genfile(f) for f in [\n      'Android/src/com/blah/blah/blah/ipc/IFoo.java',\n      'Android/src/com/blah/blah/blah/ipc/IBar.java',\n      'Android/src/com/blah/blah/blah/ipc/IBaz.java',\n      # ...and so on...\n  ]],\ndeps = [\n          ':aidl_1',\n          ':aidl_2',\n          ':aidl_3',\n          # ...and so on...\n         ],\n)\nAIDL stuff is tricky in BUCK.\n1) Each gen_aidl rule can seemingly only process one .aidl file\n2) The import_path is relative to where you run buck from (ie,\ntrunk, where the .buckconfig file is) not relative to the BUCK\nfile like all other buck paths\n3) The import_path must point to the root of the src dir that the\n.aidl files are somewhere under.  ie, Android/src, not\nAndroid/src/com/blah/blah/blah/ipc\nHandy reference links:\nhttps://github.com/facebook/buck/issues/29\nhttps://github.com/facebook/buck/issues/103\nhttp://stackoverflow.com/questions/2179453/how-do-i-use-aidl-tool-from-command-line-using-sdk-sample-code\ngen_aidl(\n    name = 'aidl_1',\n    aidl = 'Android/src/com/blah/blah/blah/ipc/IFoo.aidl',\n    import_path = 'libs/foo_service/Android/src/',\n)\ngen_aidl(\n    name = 'aidl_2',\n    aidl = 'Android/src/com/blah/blah/blah/ipc/IBar.aidl',\n    import_path = 'libs/foo_service/Android/src/',\n)\ngen_aidl(\n    name = 'aidl_3',\n    aidl = 'Android/src/com/blah/blah/blah/ipc/IBaz.aidl',\n    import_path = 'libs/foo_service/Android/src/',\n)\n...and so on...\n```\nEdit: updated example to include the genfile part, that I was missing.\n. ",
    "winterDroid": "So the genfile command does not exist anymore. Can you update the example? I try to import the OpenCV4Android SDK and am stuck on the aidl stuff.\nHere is my configuration:\n```\nandroid_library(\n  name = 'lib',\n  srcs = glob(['*/.java']),\n  manifest = '//res/org/opencv:manifest',\n  deps = [\n    '//res/org/opencv:res',\n    ':aidl',\n  ],\n  visibility = [ 'PUBLIC' ],\n)\ngen_aidl(\n    name = 'aidl',\n    aidl = 'engine/OpenCVEngineInterface.aidl',\n    import_path = 'java/org/opencv/',\n)\nproject_config(\n  src_target = ':lib',\n)\n```\nIn IntelliJ everything gets displayed correctly, but I am not able to build with buck because OpenCVEngineInterface can't be found.\n. I just found a way to get it working:\n```\nandroid_library(\n  name = 'lib',\n  srcs = glob(['*/.java']),\n  manifest = '//res/org/opencv:manifest',\n  deps = [\n    '//res/org/opencv:res',\n    ':opencv_aidl',\n  ],\n  visibility = [ 'PUBLIC' ],\n)\nandroid_library(\n  name = 'opencv_aidl',\n  srcs = [':aidl'],\n)\ngen_aidl(\n    name = 'aidl',\n    aidl = 'engine/OpenCVEngineInterface.aidl',\n    import_path = 'java/',\n)\nproject_config(\n  src_target = ':lib',\n)\n```\nIs that the intended way to do it?\nEDIT: Unfortunately I'm now not able to install the app because of INSTALL_FAILED_DEXOPT\n. @marcinkosiba Thanks! Yeah I figured out that the INSTALL_FAILED_DEXOPT is just happening on Genymotion but not on my real device. Not sure why. Thanks!\n. :+1: \n. :+1: \n. Same issue here\n. Yes I know. But it seems Buck is not compatible with r11c because of another issue:\n[2016-04-03 10:06:28.936][error][command:5a902683-ccfe-4dc2-98d1-37038c4e9c7c][tid:94][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.lang.IllegalStateException: /Users/marcprengemann/android-ndk-r11c/toolchains/arm-linux-androideabi-4.8/prebuilt/darwin-x86_64/bin/arm-linux-androideabi-gcc\n    at com.google.common.base.Preconditions.checkState(Preconditions.java:174)\n    at com.facebook.buck.android.NdkCxxPlatforms.getToolPath(NdkCxxPlatforms.java:580)\n    at com.facebook.buck.android.NdkCxxPlatforms.getCTool(NdkCxxPlatforms.java:629)\n    at com.facebook.buck.android.NdkCxxPlatforms.build(NdkCxxPlatforms.java:373)\n    at com.facebook.buck.android.NdkCxxPlatforms.getPlatforms(NdkCxxPlatforms.java:138)\n    at com.facebook.buck.android.NdkCxxPlatforms.getPlatforms(NdkCxxPlatforms.java:105)\n    at com.facebook.buck.rules.KnownBuildRuleTypes.createBuilder(KnownBuildRuleTypes.java:351)\n    at com.facebook.buck.rules.KnownBuildRuleTypes.createInstance(KnownBuildRuleTypes.java:226)\n    at com.facebook.buck.rules.KnownBuildRuleTypesFactory.create(KnownBuildRuleTypesFactory.java:49)\n    at com.facebook.buck.rules.Cell.<init>(Cell.java:120)\n    at com.facebook.buck.rules.Cell.createCell(Cell.java:182)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:779)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:1467)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1552)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1665)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:338)\nReason for it is that the path does not exist. It is version 4.9 and not 4.8\n. ",
    "marcinkosiba": "That looks about right. I don't think you need the intermediate android_library : \nandroid_library(\n  name = 'lib',\n  srcs = glob(['**/*.java']) + [':aidl'],\n  manifest = '//res/org/opencv:manifest',\n  deps = [\n    '//res/org/opencv:res',\n  ],\n  visibility = [ 'PUBLIC' ],\n)\ngen_aidl(\n    name = 'aidl',\n    aidl = 'engine/OpenCVEngineInterface.aidl',\n    import_path = 'java/',\n)\nNot sure about the INSTALL_FAILED_DEXOPT error, adb logcat should have some details about why it's happening.\n. So the new thing is buck project --experimental-ij-generation and I'd be interested to hear your opinions. It may not solve your problem though - if a particular directory doesn't contain source code necessary to compile the targets it will be excluded from the project (the logic is based on the actual targets, not on project_config, so results will be different).\nIntelliJ still lets you edit excluded files, is the issue that they will not get syntax highlighting?\nWe could generate excludes for sources only if you explicitly pass a target to buck project, would that work for you guys?\n. I don't suppose you're working on an open-source project or can share the BUCK files that cause this? \n. Thanks Matt! I created issue #350 for discussing your second comment. I'm assuming the project you linked there doesn't actually reproduce the IllegalStateException.\n. Thanks Matt! I created issue #350 for discussing your second comment. I'm assuming the project you linked there doesn't actually reproduce the IllegalStateException.\n. This should be fixed now. Are you still seeing this?\n. FYI for anyone watching: we're not going to look at this any time soon (we'll take pull requests, obviously).\n. FYI for anyone watching: we're not going to look at this any time soon (we'll take pull requests, obviously).\n. Actually, buck project recently started generating a misc.xml file.\nThe experimental flag is '--experimental-ij-generation' and that's what I'm concentrating on right now. I'd appreciate it if you could check it out. Depending on the input the generated project may heavily rely on buck-out being up to date, so it may not be too great for you if 'buck build' is not part of your usual workflow.\n. Actually, buck project recently started generating a misc.xml file.\nThe experimental flag is '--experimental-ij-generation' and that's what I'm concentrating on right now. I'd appreciate it if you could check it out. Depending on the input the generated project may heavily rely on buck-out being up to date, so it may not be too great for you if 'buck build' is not part of your usual workflow.\n. This was opened for the plugin, plugin doesn't need this, so closing (re-open if needed).\n. This was opened for the plugin, plugin doesn't need this, so closing (re-open if needed).\n. Hey! The manifest merger wasn't intended for rewriting parts of the manifest like that and I don't think there is a way to make it do what you want. I'm guessing the problematic bit is the fact that you're merging a bunch of manifests and so you need to reference the same application name everywhere? In that case would using a genrule to replace the name be an acceptable solution?\n. From that link it sounds like gradle upgraded to a newer version of the Manifest merger which has the nice features you're looking for. It's something we might look at in the future but is not a high priority at the moment. If you'd like to speed that along pull requests are always welcome - the instructions under third-party/java/aosp would be a good starting point.\n. Looks like you have a syntax error in '/Users/terryyhl/Documents/CompanySource/115office/BUCK' line 1. NameError: name 'va_library' is not defined. Did you accidentally delete some characters? Should line 1 be java_library instead?\nCan't really help you other than that as your bug report doesn't contain any way to reproduce your issue/\n. Looks like you have a syntax error in '/Users/terryyhl/Documents/CompanySource/115office/BUCK' line 1. NameError: name 'va_library' is not defined. Did you accidentally delete some characters? Should line 1 be java_library instead?\nCan't really help you other than that as your bug report doesn't contain any way to reproduce your issue/\n. assuming this is solved. If not please provide repro steps.\n. It's possible to generate an IntelliJ project using buck project, Android Studio should be able to load the resulting project. You'll still need to run buck build from the command line to get a build though.\nOr is this about being able to compile with buck from within Android Studio?\n. http://stackoverflow.com/questions/27758084/how-do-i-use-the-facebook-buck-building-tool-with-android-studio\nIf that's not what you're looking for please open a new issue and explain your request in more detail.\n. Hey!\n We've been concentrating efforts behind the experimental IntelliJ project generator which doesn't use project_config at all. Regardless of that I don't think forcing the user to specify this as a parameter on project_config is the right approach - we should be able to extract the information from the java_library targets, right?\n The other two patches (5a7da9f and 2e49735) look good so I'll merge those in.\n. Hey!\n We've been concentrating efforts behind the experimental IntelliJ project generator which doesn't use project_config at all. Regardless of that I don't think forcing the user to specify this as a parameter on project_config is the right approach - we should be able to extract the information from the java_library targets, right?\n The other two patches (5a7da9f and 2e49735) look good so I'll merge those in.\n. The long-term goal is to remove project_config entirely. The idea is to use IntelliJ to index the code, but build with Buck.\nYou can take a look at IjModuleFactory on how I plan to handle multiple targets in the same file. I actually have a diff to add resources support to it, but haven't had the time to push on it lately.\n. The long-term goal is to remove project_config entirely. The idea is to use IntelliJ to index the code, but build with Buck.\nYou can take a look at IjModuleFactory on how I plan to handle multiple targets in the same file. I actually have a diff to add resources support to it, but haven't had the time to push on it lately.\n. >  It would be great if we'd be able to still allow users to build the same repo via Intellij and command line at the same time though.\nThe current plan for that is to have an IntelliJ plugin that will delegate building the project to Buck. Is there some other benefit to building with IntelliJ other than the convenience of being able to do this from the UI? If not then I don't think there is any reason for us to burn time on trying to support that.\n. >  It would be great if we'd be able to still allow users to build the same repo via Intellij and command line at the same time though.\nThe current plan for that is to have an IntelliJ plugin that will delegate building the project to Buck. Is there some other benefit to building with IntelliJ other than the convenience of being able to do this from the UI? If not then I don't think there is any reason for us to burn time on trying to support that.\n. OK, we've merged in 5a7da9f and 2e49735, the plan for the IntelliJ plugin is unchanged. I don't think there is anything left to do here, so closing.\n. @mread was kind enough to provide this piece of feedback in issue 188:\nIf you were to do the following:\ngit clone https://github.com/mread/spark-redis-bootstrap-buck.git\ncd spark-redis-bootstrap-buck\nrm -rf .idea\nbuck project --experimental-ij-generation\nFirst issue is that it seems to attempt to build the project, not just configure it so you get a failure due to missing nodejs deps. To fix that\nnpm install\nbuck project --experimental-ij-generation\n1. Every package under src/main/java appears to get an entry in the sources, this is unnecessary and for very large projects a bit confusing\n2. Exclude folders include lib/, build/ and node_modules/, I'm not sure where this list is coming from but I don't think I want to exclude those. Is it just excluding everything that isn't explicitly part of a rule?\n3. If misc.xml doesn't exist then it doesn't create one. If it does then it defaults the JDK to\n<component name=\"ProjectRootManager\" version=\"2\" languageLevel=\"JDK_1_6\" assert-keyword=\"true\" jdk-15=\"true\" />\neven though we have specified the following in .buckconfig\n[java]\n    source_level = 8\n    target_level = 8\n1. Likewise project language level is 6, not 8\n2. No output directory set.\nThat's it for now. Hope it's helpful.\n. @mread was kind enough to provide this piece of feedback in issue 188:\nIf you were to do the following:\ngit clone https://github.com/mread/spark-redis-bootstrap-buck.git\ncd spark-redis-bootstrap-buck\nrm -rf .idea\nbuck project --experimental-ij-generation\nFirst issue is that it seems to attempt to build the project, not just configure it so you get a failure due to missing nodejs deps. To fix that\nnpm install\nbuck project --experimental-ij-generation\n1. Every package under src/main/java appears to get an entry in the sources, this is unnecessary and for very large projects a bit confusing\n2. Exclude folders include lib/, build/ and node_modules/, I'm not sure where this list is coming from but I don't think I want to exclude those. Is it just excluding everything that isn't explicitly part of a rule?\n3. If misc.xml doesn't exist then it doesn't create one. If it does then it defaults the JDK to\n<component name=\"ProjectRootManager\" version=\"2\" languageLevel=\"JDK_1_6\" assert-keyword=\"true\" jdk-15=\"true\" />\neven though we have specified the following in .buckconfig\n[java]\n    source_level = 8\n    target_level = 8\n1. Likewise project language level is 6, not 8\n2. No output directory set.\nThat's it for now. Hope it's helpful.\n. Thanks for the feedback @mread!  Some answers/followup questions:\n1. buck project --experimental-ij-generation will attempt to build the code. This is because both buck project --experimental-ij-generation and buck project reference stuff from buck-out. The difference is that plain buck project implicitly relies on the developer running the appropriate buck build command, so you can get into a state where IntelliJ doesn't index stuff/has even more errors because you haven't built yet. Having the build be part of the project generation is an attempt to address that scenario.\n2. I'm aware of the fact that every folder ends up getting a package. I'd assumed it's more of a cosmetic problem (and so fixing it is low-pri). Is it really jarring or is it more of a \"huh? that's weird..\" sort of thing?\n3. Yes, the new buck project will end up building a set of folders from the inputs of rules responsible for compiling source code and exclude everything else. This makes IntelliJ a lot faster if you have a lot of source files in your repo but are only working on a small subset. In your case would it be more appealing to take over control of the excludes set (define a list of folders and have those and only those be excluded) or would you prefer to turn excludes off entirely?\n4. buck project --experimental-ij-generation currently doesn't emit neither misc.xml nor compiler.xml. This will be addressed in the future :)\n. Thanks for the feedback @mread!  Some answers/followup questions:\n1. buck project --experimental-ij-generation will attempt to build the code. This is because both buck project --experimental-ij-generation and buck project reference stuff from buck-out. The difference is that plain buck project implicitly relies on the developer running the appropriate buck build command, so you can get into a state where IntelliJ doesn't index stuff/has even more errors because you haven't built yet. Having the build be part of the project generation is an attempt to address that scenario.\n2. I'm aware of the fact that every folder ends up getting a package. I'd assumed it's more of a cosmetic problem (and so fixing it is low-pri). Is it really jarring or is it more of a \"huh? that's weird..\" sort of thing?\n3. Yes, the new buck project will end up building a set of folders from the inputs of rules responsible for compiling source code and exclude everything else. This makes IntelliJ a lot faster if you have a lot of source files in your repo but are only working on a small subset. In your case would it be more appealing to take over control of the excludes set (define a list of folders and have those and only those be excluded) or would you prefer to turn excludes off entirely?\n4. buck project --experimental-ij-generation currently doesn't emit neither misc.xml nor compiler.xml. This will be addressed in the future :)\n. Because buck supports a features that can't be expressed in terms of IntelliJ's build it generally no longer makes sense to build through IntelliJ. We should probably make this clearer, but the main reason we have buck project is so that you can edit the code, not as an export strategy. We're working on having a plugin which will allow you to conveniently invoke buck build and buck test from IntelliJ in the future.\n\nBut the --experimental-ij-generation flag still does not work. You still can't rebuild the project\nCould you elaborate? Is the generated project incorrect or does the build initiated from within buck project --experimental not work?\nseems the src-roots in project_config does not work with this flag?\nThe --experimental-ij-generation intentionally ignores project_config - we should be able to infer all of that information from the target description itself. If you're seeing problems with the package prefix in the generated project then 1f2fb48498 should fix this.\n. I think this is sorted? Please reopen if you have further questions.\n. Are tests the only reason you're making the bus and console optional? I know making it optional was a lot of work but if the only reason for the change are tests then could I ask you to try using a nice easymock mock instead (http://easymock.org/user-guide.html#mocking-nice) instead? Adding the bus/console optional makes the code a bit harder to read and suggests that missing values are OK in production code.\n. Are tests the only reason you're making the bus and console optional? I know making it optional was a lot of work but if the only reason for the change are tests then could I ask you to try using a nice easymock mock instead (http://easymock.org/user-guide.html#mocking-nice) instead? Adding the bus/console optional makes the code a bit harder to read and suggests that missing values are OK in production code.\n. Looks good, just a couple of questions.\n. Looks good, just a couple of questions.\n. Could you provide repro steps? I've seen an aar-related change that Shawn landed recently (88aee076dc) that could help.\n. I don't think the change is entirely correct - will it not cause us to not restart ADB in the case that the user has 2 devices but neither of them are online?\nFrom a quick look it seems the code is awkward because filterDevices is doing too much (it's both filtering and trying to decide how to react to various scenarios). How about if we moved the logic around printing errors into getDevices (and updated AdbHelperTest accordingly) and just had filterDevices do the filtering?\n. Umm, could you try updating to the latest Java 7 and 8? I've got 1.7.0_75 and I've seen weird type errors like this in some older 1.7 javac versions.\n. This happens if you target java 1.8. I have a fix for it internally - it's super-trvial - just add a 1.8 entry to the map in JavaFileParser.\n. Hi there! I see the problem you're trying to address, but just adding the classes to the exported deps makes them also available in the auto-completion index (so you end up auto-completing classes that are missing from your deps and you get a compile error when you build with buck). Luckily IJ has the concept of 'add this to classpath but don't add it to the autocomplete index' (Runtime dep type in the 'Dependencies' tab). Currently the project generator doesn't use this type, but it shouldn't be hard to add (it would be a new IjModuleGraph.DependencyType)\n\nAn alternative would be to use the buck plugin (the one under src/com/facebook/buck/intellij/plugin/) to run tests via buck.\n. no updates for over a year, closing. I haven't looked at the diff yet, but it looks like you're trying to get the generated projects to work with IntelliJ so I wanted to set expectations: getting the generated project to compile and run in IntelliJ is not a goal at the moment. The reason for the buck project command is to enable you to edit the code in IntelliJ and we plan to delegate build+run functionality to buck via the IntelliJ plugin.\nYour description makes sense and I'll look over the diff when I have a moment, however I don't think it's worthwhile to invest much effort into fixing the generated project.\n. I haven't looked at the diff yet, but it looks like you're trying to get the generated projects to work with IntelliJ so I wanted to set expectations: getting the generated project to compile and run in IntelliJ is not a goal at the moment. The reason for the buck project command is to enable you to edit the code in IntelliJ and we plan to delegate build+run functionality to buck via the IntelliJ plugin.\nYour description makes sense and I'll look over the diff when I have a moment, however I don't think it's worthwhile to invest much effort into fixing the generated project.\n. got some feedback that this sounds differently to what I intended to say, so let me rephrase: I think the approach is correct and we will most likely take the diff, it's just that making the IntelliJ project build with IntelliJ is not the best thing to focus on.\n. got some feedback that this sounds differently to what I intended to say, so let me rephrase: I think the approach is correct and we will most likely take the diff, it's just that making the IntelliJ project build with IntelliJ is not the best thing to focus on.\n. > 1) we unconditionally add the lib as 'exported', this should depend on whether the compiled\n\nshadow lib was included in 'deps' or 'exported_deps'\n\nthe compiled_shadow is a hack to work around issues around annotation processors (for big projects you don't want to have to \"build\" with IJ to be able to reference classes created by annotation processors) and sourcejars (buck magically supports zip files containing .java files as inputs, IntelliJ doesn't). The compiled_shadow jar contains all of the classes in the original module plus any code-gen and sourcejar-related stuff. Because the generated project already has exported deps resolved (any exported deps appear as regular deps in the project) it's fine to 'cheat' and mark the compiled-shadow as exported (which has the effect that anything that depends on the target also depends on its shadow, so you get to access the classes coming from code-gen without adding an explicit dependency on this library in the other module). Ultimately this is just a trick to get IntelliJ's indexing to pick up code-gen'd classes.\n\n2) We should properly handle 'provided_deps' for both COMPILED_SHADOW and PROD/TEST types\nas well. This patch breaks the first but the later dep types are always included as 'compile'.\n\nI believe IJ just has either provided (for prod) or test deps, no provided_for_test, so you'd probably need to promote any provided deps coming from tests to prod. But yes, it would be nice to support that properly as well.\nIf you get all of your compiled_shadow deps as scope=compile the only thing that's making sure the duplicated classes are resolved correctly is classpath order. The result is a bit of a franken-build that will break in weird ways if you forget to buck build after changing anything that affects code-gen. I think the real issue here is that buck project is not handling either annotation processors or src.zip genrule inputs (or both) in your project and I don't know of a good way to make that happen:\n- I've found that our internal annotation processors work with Buck, but don't want to work with IntelliJ, so I never invested a lot of effort in making the generated project expose annotation processors to IJ, you're welcome to try though,\n- I don't have a good idea for src.zip - using an intermediate folder means this breaks with caching, un-zipping the file as part of buck project means it doesn't get updated when you buck build.\n. > 1) we unconditionally add the lib as 'exported', this should depend on whether the compiled\n\nshadow lib was included in 'deps' or 'exported_deps'\n\nthe compiled_shadow is a hack to work around issues around annotation processors (for big projects you don't want to have to \"build\" with IJ to be able to reference classes created by annotation processors) and sourcejars (buck magically supports zip files containing .java files as inputs, IntelliJ doesn't). The compiled_shadow jar contains all of the classes in the original module plus any code-gen and sourcejar-related stuff. Because the generated project already has exported deps resolved (any exported deps appear as regular deps in the project) it's fine to 'cheat' and mark the compiled-shadow as exported (which has the effect that anything that depends on the target also depends on its shadow, so you get to access the classes coming from code-gen without adding an explicit dependency on this library in the other module). Ultimately this is just a trick to get IntelliJ's indexing to pick up code-gen'd classes.\n\n2) We should properly handle 'provided_deps' for both COMPILED_SHADOW and PROD/TEST types\nas well. This patch breaks the first but the later dep types are always included as 'compile'.\n\nI believe IJ just has either provided (for prod) or test deps, no provided_for_test, so you'd probably need to promote any provided deps coming from tests to prod. But yes, it would be nice to support that properly as well.\nIf you get all of your compiled_shadow deps as scope=compile the only thing that's making sure the duplicated classes are resolved correctly is classpath order. The result is a bit of a franken-build that will break in weird ways if you forget to buck build after changing anything that affects code-gen. I think the real issue here is that buck project is not handling either annotation processors or src.zip genrule inputs (or both) in your project and I don't know of a good way to make that happen:\n- I've found that our internal annotation processors work with Buck, but don't want to work with IntelliJ, so I never invested a lot of effort in making the generated project expose annotation processors to IJ, you're welcome to try though,\n- I don't have a good idea for src.zip - using an intermediate folder means this breaks with caching, un-zipping the file as part of buck project means it doesn't get updated when you buck build.\n. no activity for over a year, closing. Thanks @tgummerer !\n. Thanks @tgummerer !\n. I'll own up to DiffRuleKeysScriptIntegrationTest. Apologies for the rubbish debugging session you had to endure because of this! Ideally we'd output the rulekey information to a separate file (like buck audit rulekey <target> --json path/to/file) in a sane format that the script (and anyone else) could use, but in the meantime I'll look into not truncating the log file.\nThanks for the feedback! \n. I'll own up to DiffRuleKeysScriptIntegrationTest. Apologies for the rubbish debugging session you had to endure because of this! Ideally we'd output the rulekey information to a separate file (like buck audit rulekey <target> --json path/to/file) in a sane format that the script (and anyone else) could use, but in the meantime I'll look into not truncating the log file.\nThanks for the feedback! \n. I just un-zipped the .aar file and:\n- material_blue_500 is not present in the R.txt file,\n- design_navigation_item_separator is not in the R.txt file\n  I can't seem to find them in the .xml files either, so this seems to be a case of referencing non-existent symbols. For the material_blue_500 issue this might be helpful: http://stackoverflow.com/questions/26460389/android-5-0-intellij-gradle-cannot-resolve-symbol-colormaterial-blue-500\nThemeOverlay_AppCompat_Dark_ActionBar is present in the R.txt file and I can see .xml resources for it. I wonder if it's a case of the tooling being confused by previous errors, but it also may be a legit bug. Could you send me the snippet that's trying to reference that style?\n. Thanks for the great writeup! \nI think the Java rules support this as a workaround for the fact that genrules didn't support directories at the time this was added. I don't think it is important to have source .zip support baked in for all jvm-based languages and it's fine for this to stay a java-only feature.\nIf you wanted to support this later on then we could inject the unzip step based on whether the compiler supports reading directly from .zip files (we could do it by having the compilestepfactory return this information along with the step, for example). We could even pull that into a separate rule (the benefit there is that you could potentially run that 'unzip' rule earlier in the build), though I don't think it's worth it unless we somehow find ourselves flinging a lot of code around in .zip files.\n. Hey!\n  Thanks for the pull request and apologies for not getting back to you sooner!\n  I don't think it's necessary for resource roots to be manually specified: we already have that information on android_res() rules, so we don't need to force the user to type that in a second time.\n  Al recently landed support for the Android plugin to the --experimental-ij-generation project mode in c2691f3c5ccdc162884c70ee39cddfe317ce551b, which should do what I just described.\n. Hey!\n  Thanks for the pull request and apologies for not getting back to you sooner!\n  I don't think it's necessary for resource roots to be manually specified: we already have that information on android_res() rules, so we don't need to force the user to type that in a second time.\n  Al recently landed support for the Android plugin to the --experimental-ij-generation project mode in c2691f3c5ccdc162884c70ee39cddfe317ce551b, which should do what I just described.\n. > I don't think java_library's resources section can help us achieve this - targets, bespoke entries for particular libs... it wouldn't give us what we need.\nI don't think I understand this bit. From the pull request it seems like you need to add a \n<sourceFolder type=\"java-resource\" /> line to the .iml file. You could start off simple and only handle resources that are SourcePaths (that way you side-step the issue of genrules, etc..). We already have most of the plumbing you'd need in place for android resources (look for AndroidResourceFolder), it looks like it should work out of the box if you have the JavaLibraryModuleRule add AndroidResourceFolder that correspond to its resources (might make sense to rename AndroidResourceFolder->ResourceFolder).\n. > I don't think java_library's resources section can help us achieve this - targets, bespoke entries for particular libs... it wouldn't give us what we need.\nI don't think I understand this bit. From the pull request it seems like you need to add a \n<sourceFolder type=\"java-resource\" /> line to the .iml file. You could start off simple and only handle resources that are SourcePaths (that way you side-step the issue of genrules, etc..). We already have most of the plumbing you'd need in place for android resources (look for AndroidResourceFolder), it looks like it should work out of the box if you have the JavaLibraryModuleRule add AndroidResourceFolder that correspond to its resources (might make sense to rename AndroidResourceFolder->ResourceFolder).\n. FYI the default for buck project changed (it took a while), so, unless you run with the --deprecated-ij-generation option, project_config entries aren't used.\nMarking as needs revision because I imagine the diff doesn't apply cleanly anymore.\n. Please provide a more detailed description of your issue.\n. > ic_launcher is in safetykeyboardnew/res/drawable-xxhdpi.\nhowever you android_resource entry in safetykeyboardnew/BUCK says res = 'src/main/res', which means that, for that target, buck is looking for resources under safetykeyboardnew/src/main/res and not under safetykeyboardnew/res. Looks like you're missing an android_resource( ... res ='res' ... ) rule in your safetykeyboardnew/BUCK file.\n. Just had a look over this. Just to make sure I understand - if you have liba->libb->libc then the R.java file for liba should contain the union of resources in libb and libc or just libb?\nI can see how you'd have problems with resource_union_package as it only allows for one union package for the entire app (it's intended for migrating from the single res folder approach). \n. Just had a look over this. Just to make sure I understand - if you have liba->libb->libc then the R.java file for liba should contain the union of resources in libb and libc or just libb?\nI can see how you'd have problems with resource_union_package as it only allows for one union package for the entire app (it's intended for migrating from the single res folder approach). \n. @polycoder, understood. I assume that's different than gradle?. I'm asking because we have a MergeResourcesSources rule which uses the same code as gradle does to merge resources. The downside to using it is that it actually does a resource merge (sucks in a bunch of folders and spits out a new folder) so it's not as cheap as the thing \n. > We were seeing with libraries built with buck that they were never including merged resources txt so for the case of liba->libb liba would not contain the resources of libb in it's R.txt file, and this would lead to a runtime exception since the R.class generated for liba did not contain the proper resource entry to a resource in libb\nThat's in the case of the resource_union_package, right? It's kinda fiddly as you need to set the same package on both the android_library and android_binary.\nAnyhow. The MergeAndroidResourcesSources thing probably doesn't give you that much win here (it would have been simpler to code up, but whatevs), so stick to the thing you've got.\n. @polycoder copyWithNewIdValue should be OK. Take a look at the comment in MergeAndroidResourceStep.sortSymbols.\n. Also, docs for the new option and a test would be nice :)\n. Thanks for persisting @polycoder!\n. Thanks for persisting @polycoder!\n. Sweet! I'm going to start the import flow on this.\n. @facebook-github-bot shipit\n. internal tests are failing because RDotTxtEntryTest.java and AaptResourceCollectorTest.java doesn't have the correct license header. Could you please update the PR to have those? (I'd do it but I'm not sure if it's OK from a legal perspective).\n. @facebook-github-bot shipit\n. Had a quick look. ApkBuilderStep, line 189-ish. If you add a null check on the key returned from keystore.getKey (Preconditions.checkNotNull or just call key.getFormat() or something) will it blow up?\n. Thanks for the detailed report!\nThe output of the --dot command is intended to be used by the graphviz tool or humans, not fed back into buck. Also, \"surprise!\" the --dot option does something different than the --json option (look at AuditClasspathCommand, if you pass in --dot it actually inspects the TargetGraph, not the ActionGraph).\nThe way we handle cells in the two graphs slightly differs but that does look a bit bogus. I don't think anyone will look at this any time soon though.\n. Wow, an individual component of the build is too big to dex.. ok. Try disabling pre-dex (disable_pre_dex = true on the android_binary target).\n. I'm going to assume that worked, re-open if it didn't\n. Sorry but I don't understand your bug report. Please at least write a full sentence. Which pex? Buck-as-a pex or a pex you built with buck, which revision, repro steps, etc? \nhttp://www.chiark.greenend.org.uk/~sgtatham/bugs.html\n. Args being concrete classes with fields (rather than following the immutables abstract method pattern) and Java not allowing fields on interfaces (or mixins) make this hard to express in the type system. \nI'd love be able to say:\n```\ninterface CanHaveLicense {\n  Optional> getLicenses()\n}\nclass Arg implements CanHaveLicense {\n}\n```\n(so essentially same thing as @yiding said above).\nMaking this stuff magical in the parser is a bit gross, though we don't really have enough of these special magic things to make a strong case for putting in the work to do the immutables-like approach.\n. Args being concrete classes with fields (rather than following the immutables abstract method pattern) and Java not allowing fields on interfaces (or mixins) make this hard to express in the type system. \nI'd love be able to say:\n```\ninterface CanHaveLicense {\n  Optional> getLicenses()\n}\nclass Arg implements CanHaveLicense {\n}\n```\n(so essentially same thing as @yiding said above).\nMaking this stuff magical in the parser is a bit gross, though we don't really have enough of these special magic things to make a strong case for putting in the work to do the immutables-like approach.\n. Seems like a reasonable way to go about this. An integration test would be nice if it's not too much trouble to write one.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. It's possible you have a repro of the parser being stuck. It would be cool if you could help us debug:\n 1) look at the buck-out/log/buck-.log coresponding to the build, see if it has any exceptions or anything interesting. Or just upload it somewhere and share it with us,\n 2) take a look at cpu usage (top, atop, htop, whatever), is everything idle or is one process stuck in 100% cpu?\n 3) run buck connected to the debugger and see what it's stuck in :)\n. other than the docs nit this seems fine. Sorry for the long review cycle, needed to fish out aidl sources to figure out what the -b option does.\n. @facebook-github-bot shipit\n. The diff still has the same problem, you need to update the GenAidlTest to not have the -b flag\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. > Ping... it's been a few weeks; just wanted to see what the status is on this pull request.\n\nHey! The diff hit an issue that only happened on internal CI. I'll have another go at debugging+landing this in ~12h\n. While you could argue it makes sense for sh_test to be runable, it won't be the case for other tests (cxx, java). I would prefer to not introduce this kind of inconsistency. You then start getting into scenarios where you $(execute) a test as part of a genrule to build some production code..\nIf you want to use the same code in a binary and test why not create sh_test that runs the sh_binary?\n. It's mostly java/robolectric tests that get the special treatment, the invocation results get spat out into an .xml file that is interpreted by buck. If you were to just run those you'd not get any useful output, which is why I said it would not make sense (I did not consider the debugging hangs case).\n\nFrom a quick look it does seem like ShBinary should also return its resources from getRuntimeDeps (rather than just the dep for main).\n. @facebook-github-bot shipit\n. > Running aapt before source code generation is how gradle behaves. Is there some reason why this is not the case in buck?\nif we were to run appt beforehand and have the java code see the R.id values it would be impossible to share the results of compiling an individual java/android_library across >1 android_binary. Also, aapt is slow, so sticking it on the critical path is not a good idea\n. > Running aapt before source code generation is how gradle behaves. Is there some reason why this is not the case in buck?\nif we were to run appt beforehand and have the java code see the R.id values it would be impossible to share the results of compiling an individual java/android_library across >1 android_binary. Also, aapt is slow, so sticking it on the critical path is not a good idea\n. It would be nice if butterknife could run in a mode where it doesn't inline the constants (you can still reclaim the perf benefits by running proguard on the final .jar and have it do the inlining).\n. It would be nice if butterknife could run in a mode where it doesn't inline the constants (you can still reclaim the perf benefits by running proguard on the final .jar and have it do the inlining).\n. > I made a version of butterknife that outputs R.id.identifier in the generated code instead of inlining the integers. But then I realized that it does not matter even if the dummy R dot Java files are final, the resource will not be found at runtime since the final R dot Java has entirely different values. aapt seems to be still rewriting resource ids on the latest sdk tools version available.\nI don't understand how appt changing the value defeats the butterknife changes.\nBuck deals with aapt changing the values by using non-final fields in the generated R class (this way the java compiler doesn't inline R.id constants). This allows us to 'swap in' the correct final R.class right before creating the apk.\nIf you got butterknife to refer to fields then it should \"just work\" as the code generated by butterknife will continue to refer to the non-inlined fields (rather than their values), so when buck swaps in the R.class with the correct resource IDs the code generated by your version of butterknife should pick those up.\n. @kageiit - really glad to hear that you got it working that way! I'm assuming it's OK to close this PR. If there is any extra work needed for buck to work with the code you landed in ButterKnife, could you please open a separate PR?\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. > Separately, why do both prebuilt_jar & export_file copy the contents? Should they be using HasRuntimeDeps instead?\nI believe they were written before we had runtime deps\n. > Separately, why do both prebuilt_jar & export_file copy the contents? Should they be using HasRuntimeDeps instead?\nI believe they were written before we had runtime deps\n. Seems like there is a legitimate test failure here\nFailed target: //test/com/facebook/buck/jvm/java:java\nFAIL com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest\n[Tue, 17 May 2016 06:39:23 -0700] Step \"Testing with Buck\" failed with: Summary (beta): \nFAILURE com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest testPrebuiltJarGenruleDirectory: Expected exit code 0 but was 1.\n[CONTEXT] java.lang.AssertionError: Expected exit code 0 but was 1.\n[CONTEXT]   at org.junit.Assert.fail(Assert.java:88)\n[CONTEXT]   at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertExitCode(ProjectWorkspace.java:643)\n[CONTEXT]   at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertSuccess(ProjectWorkspace.java:604)\n[CONTEXT]   at com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest.testPrebuiltJarGenruleDirectory(PrebuiltJarIntegrationTest.java:101)\n[CONTEXT]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n[CONTEXT]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n[CONTEXT]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n[CONTEXT]   at java.lang.reflect.Method.invoke(Method.java:606)\n[CONTEXT]   at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n[CONTEXT]   at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n[CONTEXT]   at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n[CONTEXT]   at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n[CONTEXT]   at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n[CONTEXT]   at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n[CONTEXT]   at com.facebook.buck.testrunner.SameThreadFailOnTimeout$1.call(SameThreadFailOnTimeout.java:45)\n[CONTEXT]   at com.facebook.buck.testrunner.SameThreadFailOnTimeout$1.call(SameThreadFailOnTimeout.java:41)\n[CONTEXT]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[CONTEXT]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[CONTEXT]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[CONTEXT]   at java.lang.Thread.run(Thread.java:744)\n[2016-05-17 06:37:03.992][warn ][tid:5186][com.facebook.buck.event.listener.LoggingBuildListener] BUILD FAILED: //:genjardir failed with exit code 255:\ngenrule\nstderr: Traceback (most recent call last):\n  File \"/usr/lib64/python2.6/runpy.py\", line 122, in _run_module_as_main\n    \"main\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"/usr/lib64/python2.6/zipfile.py\", line 1409, in \n    main()\n  File \"/usr/lib64/python2.6/zipfile.py\", line 1383, in main\n    fp = open(tgt, 'wb')\nIOError: [Errno 21] Is a directory: u'/tmp/buck-f7e8b563-8ae4-4512-b262-c8c24da606ae/test/com/facebook/buck/jvm/java/java_test_java_tmp/junit4013778068020185065/buck-out/gen/genjardir/junit2/META-INF/'\n. Seems like there is a legitimate test failure here\nFailed target: //test/com/facebook/buck/jvm/java:java\nFAIL com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest\n[Tue, 17 May 2016 06:39:23 -0700] Step \"Testing with Buck\" failed with: Summary (beta): \nFAILURE com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest testPrebuiltJarGenruleDirectory: Expected exit code 0 but was 1.\n[CONTEXT] java.lang.AssertionError: Expected exit code 0 but was 1.\n[CONTEXT]   at org.junit.Assert.fail(Assert.java:88)\n[CONTEXT]   at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertExitCode(ProjectWorkspace.java:643)\n[CONTEXT]   at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertSuccess(ProjectWorkspace.java:604)\n[CONTEXT]   at com.facebook.buck.jvm.java.PrebuiltJarIntegrationTest.testPrebuiltJarGenruleDirectory(PrebuiltJarIntegrationTest.java:101)\n[CONTEXT]   at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n[CONTEXT]   at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n[CONTEXT]   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n[CONTEXT]   at java.lang.reflect.Method.invoke(Method.java:606)\n[CONTEXT]   at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n[CONTEXT]   at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n[CONTEXT]   at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n[CONTEXT]   at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n[CONTEXT]   at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n[CONTEXT]   at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n[CONTEXT]   at com.facebook.buck.testrunner.SameThreadFailOnTimeout$1.call(SameThreadFailOnTimeout.java:45)\n[CONTEXT]   at com.facebook.buck.testrunner.SameThreadFailOnTimeout$1.call(SameThreadFailOnTimeout.java:41)\n[CONTEXT]   at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n[CONTEXT]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n[CONTEXT]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n[CONTEXT]   at java.lang.Thread.run(Thread.java:744)\n[2016-05-17 06:37:03.992][warn ][tid:5186][com.facebook.buck.event.listener.LoggingBuildListener] BUILD FAILED: //:genjardir failed with exit code 255:\ngenrule\nstderr: Traceback (most recent call last):\n  File \"/usr/lib64/python2.6/runpy.py\", line 122, in _run_module_as_main\n    \"main\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.6/runpy.py\", line 34, in _run_code\n    exec code in run_globals\n  File \"/usr/lib64/python2.6/zipfile.py\", line 1409, in \n    main()\n  File \"/usr/lib64/python2.6/zipfile.py\", line 1383, in main\n    fp = open(tgt, 'wb')\nIOError: [Errno 21] Is a directory: u'/tmp/buck-f7e8b563-8ae4-4512-b262-c8c24da606ae/test/com/facebook/buck/jvm/java/java_test_java_tmp/junit4013778068020185065/buck-out/gen/genjardir/junit2/META-INF/'\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. sorry for the delay. Turns we use python 2.7 on travis when running tests but our internal CI uses 2.6, so this was choking on land. Fixed the test, should be in soon\n. I'll take you up on that then :) Our Windows CI is failing with:\nFile \"unzip.py\", line 36, in <module>\n  File \"unzip.py\", line 29, in main\n  File \"C:\\Python27\\lib\\zipfile.py\", line 1053, in extractall\n    self.extract(zipinfo, path, pwd)\n  File \"C:\\Python27\\lib\\zipfile.py\", line 1041, in extract\n    return self._extract_member(member, path, pwd)\n  File \"C:\\Python27\\lib\\zipfile.py\", line 1096, in _extract_member\n    file(targetpath, \"wb\") as target:\nIOError: [Errno 2] No such file or directory: u'C:\\\\cygwin\\\\data\\\\temp\\\\buck-e827d919-22bd-4490-a98a-39648d155ade\\\\test\\\\com\\\\facebook\\\\buck\\\\jvm\\\\java\\\\__java_test_java_tmp__\\\\junit1759102774629287037\\\\buck-out\\\\gen\\\\genjardir\\\\junit2\\\\org\\\\junit\\\\experimental\\\\theories\\\\PotentialAssignment$CouldNotGenerateValueException.class'\nI tried playing around with the Python code (making sure the directory is created, touching the file first, etc..) but couldn't get it to work.\nI'll be on vacation till middle of next week, @Coneko will be able to re-import any changes you've made to the PR, otherwise I'll pick the PR back up after I return.\n. Agree with @dreiss, the correct way to fix this is to post a ConsoleEvent to the BuckMessageBus, doing that causes the warning to print without breaking the rendering\n. @kageiit take a look at DxStep instead. We give the dexer direct access to stdout/stderr, we would need to buffer the output and re-post as a consoleevent\n. use the right slashes: .\\bin\\buck --help. The error you're seeing is windows thinking you want to run command . with options /bin and /buck\n. Can you elaborate on doesn't build x86_64 compatible library.? \n. Thanks for the PR!\n\nwhat additional unit or integration tests do you want to see?\n\nThe code looks straightforward, I don't think we need any extra testing.\n\nI'm not sure what addCompiledShadowIfNeeded() does but I'm not calling it, should I?\n\nIt will add a .jar file containing the compiled version of the target to your dependencies list if the target uses annotation processors or has inputs from other buildrules. It's used to make the project support annotation processors (turns out not all APs that run with Javac work with IntelliJ) and generated code (sources coming from genrules/src.zip files that are not available before running the build).\n\nthere's an unnecessary  and a packagePrefix being created in the .iml, any suggestions on the best place to look for a fix?\n\nLooks like you figured out the packagePrefix. Not sure about the exclude. An <exclude-output> tag is hardcoded. The excludes are calculated by looking at all the files included into the project and marking any folders on disk that weren't included as excluded.\n. @facebook-github-bot  shipit\n. Thanks! It looks like the new project generator has problems with AARs. For now you can use the old code by running buck project --deprecated-ij-generation\n. Thanks! It looks like the new project generator has problems with AARs. For now you can use the old code by running buck project --deprecated-ij-generation\n. the problem is that you have either set an android sdk version in your .buckconfig or have one of the ANDROID_* environment variables set.\n. the problem is that you have either set an android sdk version in your .buckconfig or have one of the ANDROID_* environment variables set.\n. @kageiit not really, that string doesn't come out of the buck codebase, so it's either libddm or adb itself that's doing the restart. Going by the error message maybe an adb version conflict due to which adb being different than the adb buck fishes out of $ANDROID_SDK?\n. @kageiit not really, that string doesn't come out of the buck codebase, so it's either libddm or adb itself that's doing the restart. Going by the error message maybe an adb version conflict due to which adb being different than the adb buck fishes out of $ANDROID_SDK?\n. please make the timeout a setting on .buckconfig\n. yeath, so it looks like exported_deps are broken in this case. I think it's because AndroidLibraryGraphEnhancer.getBuildableForAndroidResources filters directly on first-order deps instead of filtering on an expanded set.\nIf you change the code to be this:\nandroid_library(\n   name = 'main-lib',\n   srcs = glob(['src/main/java/**/*.java']),\n   deps = [\n     ':build-config',\n     ':jars__buck-android-support',\n     ':all-jars',\n     ':all-aars', # <-- This is partially broken, sorry.\n     ':res',\n   ]  + aar_deps,  # <-- Depend on the prebuilt aar targets *directly*\n)\nit compiles fine.\n. this approach isn't going to be reliable as the files may not be on disk at the point where your code runs. The UnzipAar rule already does this. What you need to do instead is find the AndroidPrebuiltAar BuildRule associated with the AAR, getPrebuiltJar() method to figure out where the .jar files are coming from and add the BuildRule to the set of things that need to be built (see getPathIfJavaLibrary in IjProject.java).\nEssentially replace the call to libraryFactoryResolver.getPath with a new API that does the right thing for AAR files.\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Just to be clear (since you mentioned R.txt): for robolectric, we don't have an R.txt as that file is created by running aapt. The values in the R.java file are dummy placeholders. Using aapt for robolectric_test is not acceptable as it would introduce too much overhead.\nIt's been a long time since I looked at that code. Last I looked robolectric 2 resource loader didn't support styleable correctly, not sure if that changed with robolectric 3. I'm not sure whether it's just the MergeAndroidResources that's broken or whether MiniAapt also needs to be fixed to correctly emit the right styleable entries, but fixing either (or both) of those to correctly support the case would be the preferred approach.\n. yea, the buck run command is broken: it runs the command as a background process and forwards stout/stderr but not stdin. It really should work by calling exec in the 'client' process instead.\nThat being said your use of genrule is incorrect. genrules are for running arbitrary commands to create artifacts that are consumed at later stages of the build. The inputs of those commands must be completely exposed to the build system, otherwise you get incorrect caching behavior.\nIn your example the result of read is not captured at all.\nI'm going to re-purpose this issue to address the fact that 'buck run ignores stdin`. For the time being I suggest you build a standalone repl thing and invoke it from outside of the buck process:\nbuck targets --show-output <name of target> | cut -f2 -d\" \"\n. Sorry, this isn't very actionable. I don't think remote-debugging a perf issue in a codebase I don't have access to is a good use of our time. Please re-open this once you've narrowed down the root cause.\nHere are some questions to get you started: have you confirmed your app is running hw-accelerated? Maybe the resources for the needed dpi are not included?\n. @facebook-github-bot shipit\n. @kageiit looks like facebook-github-bot doesn't like me, not sure why. I'll look into it.\n. @facebook-github-bot shipit\n. @raviagarwal7, the comment from our bot points to a commit that doesn't seem to exist. Could you please confirm whether you updated this pull request and maybe try re-pushing the branch or something if you did?\n. Thanks! It doesn't look like this bit about getStyleableResources was addressed:\n\nI think this is brittle - the code in the Merge step relies on the sorting behavior. We could add tests to make sure these don't get broken (yea, btw, add tests), but it seems to me a simpler approach would be to take all int styleable, split on the first _ and stick them in a multimap.\n. travis found a bunch of pmd errors, please address those.. travis found a bunch of pmd errors, please address those.. For some reason the patch for the diff doesn't apply cleanly. I finally had time to look into it today, unfortunately my work was rewarded with a ton of failures around line length and checkstyle.\nPlease fix your IntelliJ line length/style settings. We have a correct project config checked into buck, not sure why your editor is not picking that up.\n\ntl;dr; ant lint is failing on the diff.. For some reason the patch for the diff doesn't apply cleanly. I finally had time to look into it today, unfortunately my work was rewarded with a ton of failures around line length and checkstyle.\nPlease fix your IntelliJ line length/style settings. We have a correct project config checked into buck, not sure why your editor is not picking that up.\ntl;dr; ant lint is failing on the diff.. this breaks a ton of our robolectric tests with errors similar to the one below:\njava.lang.ArrayIndexOutOfBoundsException: 799060974\nat android.content.res.TypedArray.getResourceId(TypedArray.java:570). > do you have a sample test case where it fails, that I can try out?\nNot one easily available. I'll try and make time for this, but no promises. cc @dreiss in case he or his team can help out.. > do you have a sample test case where it fails, that I can try out?\nNot one easily available. I'll try and make time for this, but no promises. cc @dreiss in case he or his team can help out.. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @kageiit, actually - there seem to be legit test failures on travis, could you take a look please?\n. I can't determine what's wrong based on the information you provided. Could you please create a minimal repro and share it as a .zip or github repository?\n. @GunNan \nunfortunately that still doesn't allow me to reproduce the issue. If you can't share all of the code then perhaps you could create a small sample app that demonstrates the problem?\nAlso, the internets say that you might need to add an option to AAPT: --no-version-vectors. Buck does not do this by default, so on you android_binary target, try setting includes_vector_drawables = True, and see if it helps.\n. 26 days without activity, closing.\n. Peter,\n  I believe the reason this is undocumented is that it's essentially a hack from a time before genrules:\ngenrule(\n name = 'post-process',\n cmd = \"$(exe //my/processor:target) $(location //my/java_library:jar)\",\n)\nCheers!\n  Martin\nFrom: Peter van Zetten notifications@github.com<mailto:notifications@github.com>\nReply-To: facebook/buck reply@reply.github.com<mailto:reply@reply.github.com>\nDate: Friday, September 30, 2016 at 1:22 PM\nTo: facebook/buck buck@noreply.github.com<mailto:buck@noreply.github.com>\nSubject: [facebook/buck] Support macro expansion in java_library's postprocess_classes_commands (#910)\nThe (undocumented...) parameter {{postprocess_classes_commands}} for java_library targets allows the definition of an array of strings which are executed as {{BashStep}}s on the classes directory before packaging.\nAllowing these strings to make use of the macro expansion from genrules would be really useful, for example to define a binary target in the project which can be used for class processing:\njava_library(\n  name = 'foo',\n  postprocess_classes_commands = [\n    '$(exe //my/processor:target) arg1 arg2'\n  ],\n  ...\n)\nIn particular this would allow the easy creation of postprocessing helpers for tasks supplied in jars -- like AspectJ's ajc (aspectj-tools.jar) or JiBX binding (jibx-bind.jar) -- which could be trivially defined as java_binary targets, sidestepping $PATH issues.\n\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHubhttps://github.com/facebook/buck/issues/910, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ADqo1QIFsQBmQY5Vs4mQ1Ekz4_K_L-hfks5qvP8MgaJpZM4KLB6H.\n. Hi Peter,\n  I assumed you'd do this processing on the final java_binary. Using the output as a dep is a bit of a pain as it requires wrapping the output of the genrule in a prebuilt_jar:\njava_library(name = 'vanilla', srcs = glob(['*.java]))\ngenrule(name = 'vanilla_g', cmd=\"$(exe :processor) $(location :vanilla)\", out=\"vanilla.jar\")\nprebuilt_jar(name='lib', binary_jar=':vanilla_g') # <-- have other java/android_libraries depend on this, depending on the genrule won't work.\nThe ABI stuff works fine with this sort of setup, there will be 2 #abi rules: vanilla#abi and lib#abi. This works because you wouldn't be updating classes in place, you'd be creating an updated copy. Also you'd be getting the .jar file as input, but all you need to do is unzip it to get at the .class files. The output of the genrule should either be a .jar file or a folder with class files which you'd need to convert back into a .jar file.\n  Making sure the .class files are jar'd up correctly does seem pretty tedious and I don't see a reason why we couldn't extend the com.facebook.buck.zip.Zip rule to use JarDirectoryStep if the output extension is .jar.\nIf you want to add macro support to postprocess_classes instead of going the genrule route, I don't think anyone will stop you, but remember that we make no guarantees as to how long we'll keep this around for and whether .\nYou're correct in thinking that this won't work with autodeps. Autodeps is alpha-quality and currently it's not being worked on, but if you want to add a feature to make it understand this kind of post-processing then that would be cool :)\nCheers!\n  Martin\nFrom: Peter van Zetten notifications@github.com<mailto:notifications@github.com>\nReply-To: facebook/buck reply@reply.github.com<mailto:reply@reply.github.com>\nDate: Friday, September 30, 2016 at 4:55 PM\nTo: facebook/buck buck@noreply.github.com<mailto:buck@noreply.github.com>\nCc: Martin Kosiba mkosiba@fb.com<mailto:mkosiba@fb.com>, Comment comment@noreply.github.com<mailto:comment@noreply.github.com>\nSubject: Re: [facebook/buck] Support macro expansion in java_library's postprocess_classes_commands (#910)\nThat would certainly explain the documentation!\nI did think about doing it as a genrule but the exact process wasn't exactly clear - for example the genrule contract states it should be producing a single file/folder as output, and indeed out is mandatory. I also couldn't see how a target of this type could be used as a java_library-type for deps/autodeps purposes.\nAlso, assuming it's possible to update the .classes in-place with another target, how would this work with the java_library's ABI definition? For example if the post-processing changes/adds public stuff it'd be nice to have it available for autodeps.\nI couldn't see any easy way to keep the intuitiveness of a single java_library target representing the collection of .java -> .class files (including post-processing), until I started looking at the code and found the java_library parameter. Plus the postprocess_classes_command stuff is executed before the ABI calculation in DefaultJavaLibrary so this kind of naturally fits in.\nI might be missing something really easy here - I'm still very much learning the ropes, so any hints in the right direction would be great.\n\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHubhttps://github.com/facebook/buck/issues/910#issuecomment-250781860, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ADqo1YO8leYPWGQUYpEC3yCuoPhhpKW-ks5qvTDqgaJpZM4KLB6H.\n. @mikekap - could you please update the docs to mention this new option?\n. @mikekap - could you please update the docs to mention this new option?\n. I'm a bit anxious about having no test coverage for this. Would it be possible to have an entry for this in https://github.com/facebook/buck/blob/1a5992e4592746c8bc5fdc8d7f82afcfc966c719/test/com/facebook/buck/cxx/CxxBinaryIntegrationTest.java#L1847\n?\nI think not having arm64 in the default set is OK for now.\n. I'm a bit anxious about having no test coverage for this. Would it be possible to have an entry for this in https://github.com/facebook/buck/blob/1a5992e4592746c8bc5fdc8d7f82afcfc966c719/test/com/facebook/buck/cxx/CxxBinaryIntegrationTest.java#L1847\n?\nI think not having arm64 in the default set is OK for now.\n. > Travis resists to approve my PR, even it is not my fault this time. Well played, Travis.\nI just fixed it. It was a jdk version problem. Try rebasing and it should be fine (well, or at least fail on something else)\n. @dsyang, to handle generated sources you could check whether all SourcePaths are instances of PathSourcePath and require an explicit language setting if they're not.\nWhile I support auto-detect in obvious cases I don't agree with removing the possibility to specify the language, should the user want to.\n. @dsyang, to handle generated sources you could check whether all SourcePaths are instances of PathSourcePath and require an explicit language setting if they're not.\nWhile I support auto-detect in obvious cases I don't agree with removing the possibility to specify the language, should the user want to.\n. fix ant build and checkstyle (see travis failures). fix ant build and checkstyle (see travis failures). Could you please fix checkstyle errors? Internal CI will not let me land otherwise:\ncheckstyle:\n[checkstyle] Running Checkstyle 6.16.1 on 2926 files\n[checkstyle] [ERROR] test/com/facebook/buck/cxx/CxxBinaryIntegrationTest.java:1859: Line is longer than 100 characters (found 115). [LineLength]\n[checkstyle] [WARN] test/com/facebook/buck/cxx/CxxBinaryIntegrationTest.java:1871:32: Name 'TEST_CPU_ABIS' must match pattern '^[a-z][a-zA-Z0-9]*$'. [LocalFinalVariableName]\n. Could you please fix checkstyle errors? Internal CI will not let me land otherwise:\ncheckstyle:\n[checkstyle] Running Checkstyle 6.16.1 on 2926 files\n[checkstyle] [ERROR] test/com/facebook/buck/cxx/CxxBinaryIntegrationTest.java:1859: Line is longer than 100 characters (found 115). [LineLength]\n[checkstyle] [WARN] test/com/facebook/buck/cxx/CxxBinaryIntegrationTest.java:1871:32: Name 'TEST_CPU_ABIS' must match pattern '^[a-z][a-zA-Z0-9]*$'. [LocalFinalVariableName]\n. Travis and our internal CI are saying:\n/home/travis/build/facebook/buck/test/com/facebook/buck/cxx/CxxBinaryIntegrationTest.java:1859: error: incompatible types: no instance(s) of type variable(s) E exist so that com.google.common.collect.Sets.SetView conforms to com.google.common.collect.ImmutableSet\n    final ImmutableSet nonDefaultABIs = Sets.difference(\n                                                               ^\nErrors: 1. Warnings: 0.\n. sorry, still seeing failures (both internally and on Travis):\nFAILURE com.facebook.buck.cxx.CxxBinaryIntegrationTest customNdkCxxPlatforms: Unrecognized flavor in target foo:simple#android-arm while parsing foo/BUCK\nFAILURE com.facebook.buck.cxx.CxxBinaryIntegrationTest defaultNdkCxxPlatforms: Unrecognized flavor in target foo:simple#android-arm64 while parsing foo/BUCK\n. sorry, still seeing failures (both internally and on Travis):\nFAILURE com.facebook.buck.cxx.CxxBinaryIntegrationTest customNdkCxxPlatforms: Unrecognized flavor in target foo:simple#android-arm while parsing foo/BUCK\nFAILURE com.facebook.buck.cxx.CxxBinaryIntegrationTest defaultNdkCxxPlatforms: Unrecognized flavor in target foo:simple#android-arm64 while parsing foo/BUCK\n. Thanks! It would be awesome if we could also warn the user if the app might not be debuggable. Because of the fantastic stuff we do to manifests it might be a bit hard to check, but for AndroidBinary we know the packageType, so there's at least that..\n. The code that does this is pretty old, I think it was an attempt to match the ignore pattern that AAPT applies internally.\nInstead of exposing the property, the android_resource rules should take the result of running glob, just like (almost) all the other rules, rather than taking in a directory as a string and then doing their own special thing. Then the global ignore patterns you can set for the entire project would just work.\nTo handle aapt having its own ignore logic, I think buck should error out with a descriptive message if the user has globbed anything that aapt would otherwise reject instead of silently ignoring that too.\n. > I'm not convinced we want to bundle error prone with Buck for consumers.\nI'll elaborate as Coneko is passing on a point I originally made. We don't want to bundle this by default as it's 9MB extra to our binary size, which also affects startup time. I'm not saying \"it should be hard to use\", just \"if you don't use it you shouldn't need pay for it\". It seems like we're all agreeing that having it be a remote_file is a good way out.. Thanks for the report. The 'cell' feature is still a work in progress.\nIt looks like the parser doesn't \"stop\" at cell boundaries when doing recursive traversals (I think the issue isn't specific to buck test, probably buck targets //... would fail in a similar way).\nJust to set expectations: we don't nest cells like this internally, so fixing this is not high priority for us.. Take a look at Parser.resolveTargetSpecs. In the first loop we try and get all of the BUCK files by calling AbstractBuildFileSpec.forEachBuildFile, but that method doesn't have any code to stop at cell boundaries, so it might recurse into any cells that may be nested in the current cell.\nThen, in the second for loop, that iterates over the build files, we have this line:\nCell cell = rootCell.getCell(firstSpec.getBuildFileSpec().getCellPath());\nThat just 'trusts' the BuildFileSpec to always be constrained to a single cell, but, like I mentioned, there doesn't seem to be any code that would ensure that is the case.\nIdeally we'd change the code in the second loop to get the 'right' cell, instead of trusting the spec. We could also make the forEachBuildFile not recurse into child cells, however that would make //... less useful as it would mean \"everything in the current cell\" instead of \"everything\". I remember fixing a bug that would cause similar symptoms. Sometimes the bser codec becomes unusable for some reason after an exception happens and re-using a Python parser process would cause these kinds of errors. The fix was to implement python process 'retiring' in the parser pipeline.\n@joewalnes could you check your buck-out/log/buck-0.log for any useful details when this happens?. I remember fixing a bug that would cause similar symptoms. Sometimes the bser codec becomes unusable for some reason after an exception happens and re-using a Python parser process would cause these kinds of errors. The fix was to implement python process 'retiring' in the parser pipeline.\n@joewalnes could you check your buck-out/log/buck-0.log for any useful details when this happens?. Assuming this is resolved, please re-open if not.. Could one of you provide repro steps?. I think it's cleaner to use .buckconfig' + https://buckbuild.com/function/read_config.html to change the behavior of the build. I suggest you put the information in theuser` section of buckconfig. You can override configuration on the command line (--config) or using a .buckconfig.local\nIf you have a strong reason to use the environment, then you can get at the variables from your BUCK fike using os.environ['NAME'] (don't forget to import os at the top of the file).. It looks like the BgProcessKiller thought the buckd process was going down. Were there any prior build/test failures?. So yea, some of those seem to be a HumanReadableException wrapped in a RuntimeException, most likely because HumanReadableException extends RuntimeException, so propagate would just re-throw it, whereas your changes make it so that the HumanReadableException gets wrapped in a RuntimeException. @davido  the stack trace looks like we were waiting for 'python -version'. If you're not getting this locally then I'd chalk it up to the CI machine being overloaded.\nat java.lang.Object.wait(Object.java:502)\n         at java.lang.UNIXProcess.waitFor(UNIXProcess.java:395)\n         at com.facebook.buck.util.DefaultProcessExecutor.execute(DefaultProcessExecutor.java:321)\n         at com.facebook.buck.util.DefaultProcessExecutor.launchAndExecute(DefaultProcessExecutor.java:129)\n         at com.facebook.buck.util.DefaultProcessExecutor.launchAndExecute(DefaultProcessExecutor.java:117)\n         at com.facebook.buck.python.PythonBuckConfig.getPythonVersion(PythonBuckConfig.java:268)\n         at com.facebook.buck.python.PythonBuckConfig.getPythonEnvironment(PythonBuckConfig.java:194)\n         at com.facebook.buck.python.PythonBuckConfig.getPythonPlatform(PythonBuckConfig.java:138)\n         at com.facebook.buck.python.PythonBuckConfig.getDefaultPythonPlatform(PythonBuckConfig.java:96)\n         at com.facebook.buck.python.PythonBuckConfig.getPythonPlatforms(PythonBuckConfig.java:113)\n         at com.facebook.buck.rules.KnownBuildRuleTypes.createBuilder(KnownBuildRuleTypes.java:501)\n         at com.facebook.buck.rules.KnownBuildRuleTypes.createInstance(KnownBuildRuleTypes.java:247)\n         at com.facebook.buck.rules.KnownBuildRuleTypesFactory.create(KnownBuildRuleTypesFactory.java:46)\n         at com.facebook.buck.rules.Cell.lambda$new$0(Cell.java:88)\n         at com.facebook.buck.rules.Cell$$Lambda$38/576210526.get(Unknown Source)\n         at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:120)\n         at com.facebook.buck.rules.Cell.getKnownBuildRuleTypes(Cell.java:113)\n         at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:1148)\n         at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(ProjectWorkspace.java:502)\n         at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(ProjectWorkspace.java:444)\n         at com.facebook.buck.testutil.integration.TestDataHelper$CacheClearingProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(TestDataHelper.java:134)\n         at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommand(ProjectWorkspace.java:387)\n         at com.facebook.buck.android.BadAndroidConfigIntegrationTest.testBadAndroidConfigDoesNotInterfereNonAndroidBuild(BadAndroidConfigIntegrationTest.java:60). @davido\nfor me GH still shows the previous version of your diff (clicking the 'view changes' link leads me to  a We went looking everywhere, but couldn\u2019t find those commits. error page). Did you force push an old commit from another machine or something? Also GH is complaining about conflicts.\nre: # Native memory allocation (mmap) failed to map 13982760960 bytes for committing reserved memory.\nDo you have an env variable set (or a javaargs file) that has a massive -Xmx arg? By default buck uses a small heap, and I can't think of any other reason it would want to mmap that much memory... The other option is this: http://stackoverflow.com/questions/27262629/jvm-cant-map-reserved-memory-when-running-in-docker-container\n. Hi @davido, sorry for the long wait: our opensource import is having issues with binary files.\nIt looks like you didn't update the Throwables.propagate code under //test, so when I  ant compile-tests I get a bunch of errors about deprecated methods... Thanks! Minor request: could we make adding the errorprone jar separate from this PR?. Thanks! Minor request: could we make adding the errorprone jar separate from this PR?. > Note, that it's only annotation and not the whole error prone.\nThat's OK. I thought that the addition was accidental. Thanks!. This usually means that the test crashed before the test runner started running. have you looked into the log file? Is there something like a class loading exception?. getting a bunch of arc lint failures about unused imports.. > Does any guy have ideas on this problem?\nIt's not a known problem. Could you please provide us with a way to reproduce this? Ideally a .zip file or github repository that contains a minimum working example.. I was looking at that yesterday. Multiple things going on:\n - android-integration getting killed (most likely by OOM killer)\n - timeouts\n - not sure what the deal with cxx failures is. I was looking at that yesterday. Multiple things going on:\n - android-integration getting killed (most likely by OOM killer)\n - timeouts\n - not sure what the deal with cxx failures is. thanks for the help @samjoch!\n@fkorotkov, you can check if your config is correct by using the buck audit config cache command\nFWIW if you set both dircaches to readwrite buck will write to both.. @ldjhust I think that error means that you're either using application_module_targets or you somehow convinced buck to put that class into the primary and secondary dex. What does your android_binary rule look like?. > Has there a solution to merge the attributes in different aar module?\nno, buck doesn't have a feature like that.\n\nAs I can't modify the aar module,\n\nCan you ask the authors of the .aar modules to use unique names for the attributes? otherwise you can write a genrule that unzips the .aar, removes the attributes that are conflicting and re-zips it.\n```\ngenrule(\n  name='fix_aar',\n  cmd='', # you need to figure this out\n)\nandroid_prebuilt_aar(\n  name='aar',\n  aar=':fix_aar'\n)\n```. > Has there a solution to merge the attributes in different aar module?\nno, buck doesn't have a feature like that.\n\nAs I can't modify the aar module,\n\nCan you ask the authors of the .aar modules to use unique names for the attributes? otherwise you can write a genrule that unzips the .aar, removes the attributes that are conflicting and re-zips it.\n```\ngenrule(\n  name='fix_aar',\n  cmd='', # you need to figure this out\n)\nandroid_prebuilt_aar(\n  name='aar',\n  aar=':fix_aar'\n)\n```. a while being a long time ago. I don't recall intentionally changing test suite behavior, but given how magical test running is's possible this changed unintentionally. . a while being a long time ago. I don't recall intentionally changing test suite behavior, but given how magical test running is's possible this changed unintentionally. . > Can the trace files be split up somehow if they are larger than the limit in buck? Or is there another viewers buck recommends to use?\nA while back I wrote scripts/slice_trace.py. It's not perfect as events that span slices are not duplicated, but at least you can view the trace file.. > Can the trace files be split up somehow if they are larger than the limit in buck? Or is there another viewers buck recommends to use?\nA while back I wrote scripts/slice_trace.py. It's not perfect as events that span slices are not duplicated, but at least you can view the trace file.. I'm trying a bigger number in https://github.com/facebook/buck/pull/1364\nmaybe @ilya-klyuchnikov has some insight into the failing test. 60sec timeout doesn't help :(. Paths.get(\"\") is a no-no, use the ProjectFileSystem (from params.getProjectFileSystem()) to resolve paths.\n. won't this make all C++ libraries (even those built, say, for Android) reference that directory at runtime?\n. This really depends on your code structure, right? You can say that \"For many apps it will be the base dir...\" but avoid saying \"it should be\" as that implies that either buck or the aidl tool care/enforce this, which I don't think is true.\n. to make it easier to debug we tend to use the MoreExecutors wrappers which give the threads in the pool useful names. Any chance you could update this to name the threads something like \"MavenArtifactDownload\"?\n. why do you need to do this?\n. multiple TargetNodes in the same module could have different language levels. The way you've written it means \"last one wins\", at minimum keep them as a ImmutableSortedSet and get the first/last one.\n. IjProjectWriter should cary as little logic and behavior as possible as it's only covered by integration tests. Move this to IjProjectTemplateDataPreparer and add tests.\nAlso, passing in the entire BuckConfig is overkill as, again, it makes things harder to test (I know the IJProjectCleaner does it, however, you will notice that that class has no tests :/). We have two patterns:\n 1) create a IjProjectBuckConfig and have it wrap BuckConfig (see ArtifactCacheBuckConfig for an example), this has the benefit of keeping the config-ish logic in one place, but to test you still need to new up a BuckConfig,\n 2) create a data object for the config and have separate code that extracts it from BuckConfig (see AbstractRageConfig, and RageBuckConfig).\nI'd prefer using 2), as it makes testing simpler, but if you go 1) I won't block the review.\n. I had a bunch of code that would attempt to read IntelliJ's config and determine whether these SDKs are actually defined (with the intent to figure out if the .jar files they include would be the ones buck would use during the build). IIRC that was like 80% complete, would you be interested in taking that over?\nAssuming that the developers will have the correct SDK set up has not worked well for us internally. Any changes to the default are painful and it takes a long time for everyone to update their IJ setup.\n. > This is purely scoped to java_sdk. If someone wants to use groovysdk, they would need to be a separate config key groovy_sdk in the intellij block of buckconfig and it could be used here.\nI think one of my comments wasn't clear. I didn't mean you should add support for more kind of language SDKs, I meant that you have no guarantee that these SDKs are defined in IntelliJ's config nor that they are correctly set up. To put it another way - you're effectively hardcoding strings and expecting those to be correctly set up on every machine you run buck project on.\n\nThe auto detection change should not be part of this change imo\n\nAgreed, that was not what I was asking for. My question was \"do you want the code?\", not \"merge it into this PR\". The real question behind it is: are you planning more changes to this feature (project generation)?\n. just like with IjProjectWriter, the templates are only tested through integration tests, so it's more convenient to have any logic live at higher abstraction levels. Here I suggest adding a Jdk type on the module, if it's null, print 'inheritedJdk', otherwise print it's .name and .type:\n%if(jdk)%\n  <orderEntry type=\"jdk\" jdkName=\"%jdk.name%\" jdkType=\"%jdk.type%\" />\n%else%\n <orderEntry type=\"inheritedJdk\" />\n%endif%\n. when is this true?\n. return manifestPath.transform(sourcePathResolver.getAbsolutePathFunction()).or( intellijConfig.getAndroidManifest());\n. robolectricRuntimeDependency\n. robolectricManifest\n. Why do you to convert this to a map? ST handles Java objects just fine.\n. double space before throws\n. this is confusing, put it in an else clause of the if statement above\n. We already have a global language and target level configured in buck: https://buckbuild.com/rule/java_library.html (source/target) and https://buckbuild.com/concept/buckconfig.html#java.source_level\nCan we not use those instead?\n. Might be more robust to check if it starts with resource name followed by _, otherwise you'll get false matches if you have names like ActionBar and ActionBarz\nstyleableResource.name.startsWith(resource.name + \"_\")\n. why did you drop resource.idValue.startsWith(\"0x7f\") ?\n. not thrilled at the O(N^2) behavior here. I would prefer we run a single scan (you could just split on the first _ and stick the results in a MultiMap)\n. why remove static?\n. your reuse of the index as the offset of the next resource later in the code is a bit confusing. Use a regular for loop and assign index +1 to an appropriately named variable.\n. It would be great if the logic for the styleables lived in a separate method.\n. why can't we integrate this into the condition of the previous if statement?\n. newline after comma\n. oh, sorry, it looked like the comma was outside of the string (part of the Java code)\n. if (m.find()) {\n        final String resource = m.group(1);\n        if (!allReferencedResources.contains(packageName + \".\" + resource) &&\n            (!pattern.isPresent() || !pattern.get().matcher(resource).find())) {\n          continue;\n        }\n      }\nthough I personally find inverting it is clearer:\nboolean shouldWriteLine = allReferencedResources.contains(packageName + \".\" + resource)\n            || (keepPattern.isPresent() && keepPattern.get().matcher(resource).find());\n        if (!shouldWriteLine) {\n          continue;\n        }\n\n. why did you remove this?\n. uber-nit. This makes it sound like switching it to 'true' is something everyone would want always on. I think it matters, especially that the worker could leak resources or just not give back memory to the system (like the JVM does without G1GC) which could impact the overall performance of the system.\nCould this be something more like \"The default is false. Take care when enabling as a poorly behaved worker process can consume resources (such as memory, cpu, file handles) outside of the scope of a build\".\n. How about something that doesn't result in the user ducking for cover?\n. should we error out for things that don't have a classpath?\n. this, combined with the traversal, is O(n^2). How hard would it be to make it more efficient?\n. marginally better than \"Boom!\" but equally helpful :)\n. please express the control flow such that there is only one call to new ZipStep\n. atFilePath -> sourcesListFilePath ?\n. This is not even used yet, right? Could we add it in the commit that actually needs it?\n. you call this twice, maybe extract to a variable?. does it make sense to check that the key is not already present? I believe ImmutableSortedMap.Builder does this \"for free\". could we get rid of one level of if nesting here by merging this into the else clause above?. since you're already here, please kill the project_config entries :) They were needed for the now-deprecated Intellij project generator.. we already have a ParsingJavaPackageFinder, why re-invent the wheel?. this is not actionable for the user, make it a Precondition check.. mm... repeated identical conditions in nested if statements.. It looks like the only thing you're sharing is ImmutableSortedSet<SourcePath> sources, maybe move that into a static method and compute everything else unconditionally?. @davido autodeps should understand dependencies on 3rd party JARs, but if it isn't picking up a checked-in jar for some reason you can force an explicit import->dep mapping through .buckconfig. We already do this for caliper:\n[autodeps]\n   java-package-mappings = com.google.caliper => //third-party/java/caliper:caliper. this is no-op, IOException is checked.. NoSuchBuildTargetException is checked. makes no sense, ExecutionException is checked. UncheckedExecutionException is a RuntimeException, throw it directly. NumberFormatException is RuntimeException. IOException is checked. same as above. you're missing Throwables.throwIfUnchecked(e.getCause());. this option is there mostly because fb source layout is weird and doesn't match Intellij convention. At the same time, given the similarity between kotlin and java, it might not be a bad idea to have it. Give it a shot, if it works with this set to true maybe just leave it in?. ",
    "jacobjennings": "I also encountered this. addon-google_apis-google-19-1 instead of addon-google_apis-google-19\n. I also encountered this. addon-google_apis-google-19-1 instead of addon-google_apis-google-19\n. From build: \n[junit] Tests run: 6, Failures: 0, Errors: 0, Time elapsed: 0.02 sec\n[junit] ------------- Standard Error -----------------\n[junit] Attempting to overwrite an existing zip: zipstep\n[junit] ------------- ---------------- ---------------\n. From build: \n[junit] Tests run: 6, Failures: 0, Errors: 0, Time elapsed: 0.02 sec\n[junit] ------------- Standard Error -----------------\n[junit] Attempting to overwrite an existing zip: zipstep\n[junit] ------------- ---------------- ---------------\n. ",
    "skybrian": "I don't think JSNI is too much of an issue since it's designed so you can compile it as Java. It will be a native method with no implementation.\nIn the build tool's implementation, you probably want to have separate, mostly-parallel DAG's of build actions to perform for Java and GWT, so that the GWT output doesn't have to be rebuilt when you only want Java. However, it's annoying to have to maintain separate rules for GWT and non-GWT library variants in build files. So I think java_library should handle both, but you will need special attributes for GWT. For example, there may be gwt-only dependencies, Java-only dependencies, and shared dependencies. It might also be good to distinguish GWT generator source code (typically in a \"rebind\" directory) and dependencies needed only by the generator.\nDev Mode is slowly going away so I wouldn't worry about that too much. For the GWT compiler and Super Dev Mode, you need to construct a Java classpath containing all the dependencies and use that to start the GWT tool. (We are also working on incremental compilation for GWT, but that's not far enough along to worry about quite yet.)\nAnother issue for (Super)DevMode is that you want to put the original source files into the classpath, so that when the user edits a file, the GWT compiler sees the changes without having to run buck. However, the GWT compiler doesn't recompile code used by generators, so the bytecode for generators has to be in the classpath. (In addition, some GWT generators assume Java bytecode exists so they can use Class.forName() and reflection.)\n. I don't think JSNI is too much of an issue since it's designed so you can compile it as Java. It will be a native method with no implementation.\nIn the build tool's implementation, you probably want to have separate, mostly-parallel DAG's of build actions to perform for Java and GWT, so that the GWT output doesn't have to be rebuilt when you only want Java. However, it's annoying to have to maintain separate rules for GWT and non-GWT library variants in build files. So I think java_library should handle both, but you will need special attributes for GWT. For example, there may be gwt-only dependencies, Java-only dependencies, and shared dependencies. It might also be good to distinguish GWT generator source code (typically in a \"rebind\" directory) and dependencies needed only by the generator.\nDev Mode is slowly going away so I wouldn't worry about that too much. For the GWT compiler and Super Dev Mode, you need to construct a Java classpath containing all the dependencies and use that to start the GWT tool. (We are also working on incremental compilation for GWT, but that's not far enough along to worry about quite yet.)\nAnother issue for (Super)DevMode is that you want to put the original source files into the classpath, so that when the user edits a file, the GWT compiler sees the changes without having to run buck. However, the GWT compiler doesn't recompile code used by generators, so the bytecode for generators has to be in the classpath. (In addition, some GWT generators assume Java bytecode exists so they can use Class.forName() and reflection.)\n. Sure, adding support for a sourcefile manifest wouldn't be too hard. However, in a way, the gwt.xml files are already a manifest if you don't use globs. Would Buck be generating them?\nAlso, you probably want to build using the GWT compiler's -strict flag (also known as -failOnErrors) by default; this will help ensure you get compile errors if your gwt.xml files include too much.\n. Sure, adding support for a sourcefile manifest wouldn't be too hard. However, in a way, the gwt.xml files are already a manifest if you don't use globs. Would Buck be generating them?\nAlso, you probably want to build using the GWT compiler's -strict flag (also known as -failOnErrors) by default; this will help ensure you get compile errors if your gwt.xml files include too much.\n. On Wed, Apr 30, 2014 at 4:50 PM, bolinfest notifications@github.com wrote:\n\nI'm learning as I go with all things GWT right now, so please bear with me.\n@tbroyer https://github.com/tbroyer \"Also, if a GWT library (client or\nshared) has a single gwt.xml, it's possible to generate/merge from the rule\ndependencies.\"\nIs it possible for a GWT library (or \"module\" in your parlance?) to have\nmore than one gwt.xml file?\nWhat we call a \"GWT module\" is by definition one gwt.xml file and whatever\nsource code it includes. However, any given jar file can have multiple GWT\nmodules within it. For example, gwt-user.jar in the SDK has many GWT\nmodules.\n\nFor prebuilt jar files, you might want to have a gwt_import rule that takes\na jar file and the name of the module to use.\n\nFrom a build perspective, it appears that they are just resources in a\nJAR file, so I guess there is no reason why there cannot be more than one.\nIs there ever a case where additional metadata about the gwt.xml files\nneeds to be written to the JAR's manifest or anywhere else?\nNormally nothing special is needed in the jar's manifest. When you start up\nthe GWT compiler, you give it the name of the top-level module you want and\nit looks for that gwt.xml file in the classpath (looks it up as a\nresource), and finds the transitive dependencies from there. Once it finds\nall the modules, it compiles all their source code together (ignoring\nmodule boundaries).\n\nAs a result, if you just compile using the GWT compiler, you won't catch\nerrors where one library depends on another one but doesn't declare the\ndependency. Also, GWT modules can have circular dependencies, which is\nprobably a bad idea.\nFor incremental compilation, we will need to clean this up. In Buck, it's\nprobably a good idea to be stricter about dependencies from the beginning.\n\nThe answer to this question determines whether a java_library() should\n(1) take a single gwt_xml argument as a string, (2) take a single gwt_xmlargument as a list of strings, or (3) not special-case\ngwt_xml as its own argument and require developers to use the existing\nresources argument.\nIf you use gwt.xml files as-is, there's nothing to keep their dependencies\nin sync with the declared dependencies in Buck. So our usual approach isn't\nto check in the entire gwt.xml file. Instead we check in a fragment\n(everything but the dependencies) , and generate the part of the gwt.xml\nfile containing the deps. But you could also write automatic checks to\nverify they're in sync, or generate the entire gwt.xml file from\nGWT-specific attributes.\n@skybrian https://github.com/skybrian \"However, the GWT compiler\ndoesn't recompile code used by generators, so the bytecode for generators\nhas to be in the classpath. (In addition, some GWT generators assume Java\nbytecode exists so they can use Class.forName() and reflection.)\"\nDoes the GWT compiler normally need the .class files for the .java files\nfor which it is generating JavaScript? Or is that only for the special\ngenerator case?\nThe two cases I know of are generators using reflection and the GWT\ncompiler itself needs to load annotation classes. It's rare enough that in\nSuper Dev Mode, we can get away with adding source code without adding it\nto the classpath (using the -src flag), but unfortunately doesn't work in\nall cases.\nWhen the .class files are not needed, it would be nice if Buck could\navoid running javac (assuming it doesn't add any value). (@spearcehttps://github.com/spearceI believe this is what you are doing in\nhttps://gerrit.googlesource.com/gerrit/+/master/tools/default.defs by\nhaving gwt_module() generate a java_library() that treats all of its srcsas\nresources.)\nIt does add a fair bit of value since javac will report better compiler\nerrors than the GWT compiler.\nWe have been able to avoid the \"look upwards\" thing using a technique we\ncall graph_enhancement, which I won't get into here (it probably\ndeserves its own write-up on http://facebook.github.io/buck/). Under the\nhood, for a java_library named //foo:bar, we could generate a rule whose\nname was //foo:bar#srcs_plus_resources that would be a node in the build\ngraph with no edges. Its output would be a JAR containing the srcs and\nresources of the java_library() rule.\nYes, something like graph enhancement is similar to what I was thinking\nabout. You need parallel build graphs in the implementation but the user\nshouldn't have to have near-duplicate rules in the build file.\n\nHowever, incremental compiles will be a problem; there's currently no way\nto do it without a \"look upwards\". This is because any GWT module can\ncontribute configuration properties (last one wins in a post-order\ntraversal) and these properties are global. You need a separate pass over\nthe dependency tree to collect the properties and then to compile each\nlibrary. We're still figuring that out ourselves, so perhaps punt on that\nfor now.\n- Brian\n. On Wed, Apr 30, 2014 at 4:50 PM, bolinfest notifications@github.com wrote:\n\nI'm learning as I go with all things GWT right now, so please bear with me.\n@tbroyer https://github.com/tbroyer \"Also, if a GWT library (client or\nshared) has a single gwt.xml, it's possible to generate/merge from the rule\ndependencies.\"\nIs it possible for a GWT library (or \"module\" in your parlance?) to have\nmore than one gwt.xml file?\nWhat we call a \"GWT module\" is by definition one gwt.xml file and whatever\nsource code it includes. However, any given jar file can have multiple GWT\nmodules within it. For example, gwt-user.jar in the SDK has many GWT\nmodules.\n\nFor prebuilt jar files, you might want to have a gwt_import rule that takes\na jar file and the name of the module to use.\n\nFrom a build perspective, it appears that they are just resources in a\nJAR file, so I guess there is no reason why there cannot be more than one.\nIs there ever a case where additional metadata about the gwt.xml files\nneeds to be written to the JAR's manifest or anywhere else?\nNormally nothing special is needed in the jar's manifest. When you start up\nthe GWT compiler, you give it the name of the top-level module you want and\nit looks for that gwt.xml file in the classpath (looks it up as a\nresource), and finds the transitive dependencies from there. Once it finds\nall the modules, it compiles all their source code together (ignoring\nmodule boundaries).\n\nAs a result, if you just compile using the GWT compiler, you won't catch\nerrors where one library depends on another one but doesn't declare the\ndependency. Also, GWT modules can have circular dependencies, which is\nprobably a bad idea.\nFor incremental compilation, we will need to clean this up. In Buck, it's\nprobably a good idea to be stricter about dependencies from the beginning.\n\nThe answer to this question determines whether a java_library() should\n(1) take a single gwt_xml argument as a string, (2) take a single gwt_xmlargument as a list of strings, or (3) not special-case\ngwt_xml as its own argument and require developers to use the existing\nresources argument.\nIf you use gwt.xml files as-is, there's nothing to keep their dependencies\nin sync with the declared dependencies in Buck. So our usual approach isn't\nto check in the entire gwt.xml file. Instead we check in a fragment\n(everything but the dependencies) , and generate the part of the gwt.xml\nfile containing the deps. But you could also write automatic checks to\nverify they're in sync, or generate the entire gwt.xml file from\nGWT-specific attributes.\n@skybrian https://github.com/skybrian \"However, the GWT compiler\ndoesn't recompile code used by generators, so the bytecode for generators\nhas to be in the classpath. (In addition, some GWT generators assume Java\nbytecode exists so they can use Class.forName() and reflection.)\"\nDoes the GWT compiler normally need the .class files for the .java files\nfor which it is generating JavaScript? Or is that only for the special\ngenerator case?\nThe two cases I know of are generators using reflection and the GWT\ncompiler itself needs to load annotation classes. It's rare enough that in\nSuper Dev Mode, we can get away with adding source code without adding it\nto the classpath (using the -src flag), but unfortunately doesn't work in\nall cases.\nWhen the .class files are not needed, it would be nice if Buck could\navoid running javac (assuming it doesn't add any value). (@spearcehttps://github.com/spearceI believe this is what you are doing in\nhttps://gerrit.googlesource.com/gerrit/+/master/tools/default.defs by\nhaving gwt_module() generate a java_library() that treats all of its srcsas\nresources.)\nIt does add a fair bit of value since javac will report better compiler\nerrors than the GWT compiler.\nWe have been able to avoid the \"look upwards\" thing using a technique we\ncall graph_enhancement, which I won't get into here (it probably\ndeserves its own write-up on http://facebook.github.io/buck/). Under the\nhood, for a java_library named //foo:bar, we could generate a rule whose\nname was //foo:bar#srcs_plus_resources that would be a node in the build\ngraph with no edges. Its output would be a JAR containing the srcs and\nresources of the java_library() rule.\nYes, something like graph enhancement is similar to what I was thinking\nabout. You need parallel build graphs in the implementation but the user\nshouldn't have to have near-duplicate rules in the build file.\n\nHowever, incremental compiles will be a problem; there's currently no way\nto do it without a \"look upwards\". This is because any GWT module can\ncontribute configuration properties (last one wins in a post-order\ntraversal) and these properties are global. You need a separate pass over\nthe dependency tree to collect the properties and then to compile each\nlibrary. We're still figuring that out ourselves, so perhaps punt on that\nfor now.\n- Brian\n. Super Dev Mode as it exists today is basically a wrapper around draft mode. (Note that -draft is not quite the same as -optimize 0; it sets some additional flags). It gets a bit of speed on subsequent compiles because it's running the compiler in the same JVM, so some things get cached. But it's fundamentally not that different from -draft.\nThe compiler improvements you describe are basically what we call \"incremental compilation\". John Stalcup has been working on this for many months and is now adding it to Super Dev Mode; it's available on trunk behind the \"-incremental\" flag.  However, many modules (including within the GWT SDK itself) don't work with it yet. Also, it's not always faster yet; we're currently focused on making the migration smoother.\nWe did Super Dev Mode first because we control the entire build process that way, but it's definitely a goal to make incremental compilation work with other build systems. It would be great if we could support it in Buck. But it's a little early to get started, unless you want to jump into working on GWT's internals. (It might be worth looking into it and giving us feedback on the design.)\nThere will be some significant improvements to Super Dev Mode in GWT 2.7 which we're planning on releasing around June. Also, we're currently releasing GWT 2.6.1 but that's just a bugfix release. (The main change for Super Dev Mode in 2.6.1 is getting it to work on Windows.)\n. Super Dev Mode as it exists today is basically a wrapper around draft mode. (Note that -draft is not quite the same as -optimize 0; it sets some additional flags). It gets a bit of speed on subsequent compiles because it's running the compiler in the same JVM, so some things get cached. But it's fundamentally not that different from -draft.\nThe compiler improvements you describe are basically what we call \"incremental compilation\". John Stalcup has been working on this for many months and is now adding it to Super Dev Mode; it's available on trunk behind the \"-incremental\" flag.  However, many modules (including within the GWT SDK itself) don't work with it yet. Also, it's not always faster yet; we're currently focused on making the migration smoother.\nWe did Super Dev Mode first because we control the entire build process that way, but it's definitely a goal to make incremental compilation work with other build systems. It would be great if we could support it in Buck. But it's a little early to get started, unless you want to jump into working on GWT's internals. (It might be worth looking into it and giving us feedback on the design.)\nThere will be some significant improvements to Super Dev Mode in GWT 2.7 which we're planning on releasing around June. Also, we're currently releasing GWT 2.6.1 but that's just a bugfix release. (The main change for Super Dev Mode in 2.6.1 is getting it to work on Windows.)\n. Also, this isn't going to help get you from 20s to 1s, but it's an important speedup for larger GWT projects: it's possible to optimize each permutation in a separate JVM, in parallel.\nThe entry points for that are com.google.gwt.dev.Precompile for the first phase, com.google.gwt.dev.CompileOnePerm to compile a permutation (this can be run in parallel), and com.google.gwt.dev.Link to assemble the permutations into a single output directory.\nIn Google's build system, we use this to compile each permutation on a different machine.\n. Also, this isn't going to help get you from 20s to 1s, but it's an important speedup for larger GWT projects: it's possible to optimize each permutation in a separate JVM, in parallel.\nThe entry points for that are com.google.gwt.dev.Precompile for the first phase, com.google.gwt.dev.CompileOnePerm to compile a permutation (this can be run in parallel), and com.google.gwt.dev.Link to assemble the permutations into a single output directory.\nIn Google's build system, we use this to compile each permutation on a different machine.\n. I think we do need a catch-all for various GWT compiler arguments, which should be appended at the end. (In the GWT compiler, flags that come later in the list override flags that come earlier.) There are lots of flags, some are experimental, and we do change them in new GWT releases (while trying to remain backward compatible). You shouldn't have to update Buck (and its documentation) every time we do a GWT release; instead link to the GWT compiler's docs. [1] Also, Buck users should be able to use nightly builds of GWT if they like and try out experimental compiler flags without having to change Buck, so they can give the GWT team feedback on release candidates.\nOf course there are some compiler options that Buck needs to know about, so I suggest just adding attributes for those. (In particular, controlling the compiler's inputs and outputs.)\nRegarding JVM flags: we do have a compiler_jvm_flags attribute in blaze. It seems to be used solely for tinkering with JVM performance to make GWT compiles go faster, so I don't have a strong opinion; it could start out as a global flag for now.\n[1] http://www.gwtproject.org/doc/latest/DevGuideCompilingAndDebugging.html at the bottom.\n(This page is out of date and we should probably have a separate \"man page\" for the GWT compiler that everyone can link to.)\n. ",
    "tbroyer": "There are three kind of GWT artifacts: shared libraries (shared between JVM -e.g. server, or Android client- that is), client-only libraries, and applications.\nThe difference between client and shared libs is about where the classes go. Shared libs have most classes in a non-GWT jar, and another GWT-specific jar with GWT-specific files and classes and the gwt.xml. Client-only libs on the other hand do not need that separation.\nApplications are the result of compiling a GWT module to JS.\nShared libraries are the toughest ones to deal with, for the reasons you gave. My mind has been corrupted by Maven and the like, but I think a parallel tree is what works best: shared1-gwt depends on shared1, shared2 depends on shared1, shared2-gwt depends on shared2 and shared1-gwt.\nIdeally, a build rule would have 2 outputs, and the gwt one would depend on the gwt variants of the rule dependencies.\nAlso, if a GWT library (client or shared) has a single gwt.xml, it's possible to generate/merge  from the rule dependencies.\nI started doing something along these lines for Maven (where separation is strict), an was thinking of doing the same for Gradle (where you could generate both jars if a shared lib from the same project).\n. As for dev mode, first you'll want to use superdevmode nowadays.\nSize of the classpath can have a big impact on performance, so you don't want to put your source tree there. Following Buck's strategy for other things, you'll rather symlink files. For a better edit-refresh-cycle (including when adding files), maybe you'd rather symlink directories instead.\nAnd you'll of course need to use the gwt.xml too.\n. I think we should change GWT to load from a dedicated class loader ultimately.\nIt could be set to the system class loader by default for backwards compatibility, but if it's swappable then it becomes possible to pass a classpath as argument to the GWT compiler/superdevmode/etc. and have it construct a URLClassLoader; and you could then also swap in a specialized class loader that would respect Buck's srcs and resources (and in Maven and Gradle plugins, we could then do something similar too, without the need to fork a new JVM to trim the classpath).\nThat said, for that to happen, we'd probably first have to remove classpath scanning from GWT (the custom class loader for Buck would then be about ensuring some file that isn't in the srcs or resources won't ever be loaded by GWT; rather than limiting the size of the classpath to be scanned)\n. On Thu, May 1, 2014 at 6:22 PM, Brian Slesinsky notifications@github.comwrote:\n\nOn Wed, Apr 30, 2014 at 4:50 PM, bolinfest notifications@github.com\nwrote:\n\nI'm learning as I go with all things GWT right now, so please bear with\nme.\n@tbroyer https://github.com/tbroyer \"Also, if a GWT library (client or\nshared) has a single gwt.xml, it's possible to generate/merge from the\nrule\ndependencies.\"\nIs it possible for a GWT library (or \"module\" in your parlance?) to have\nmore than one gwt.xml file?\nWhat we call a \"GWT module\" is by definition one gwt.xml file and whatever\nsource code it includes. However, any given jar file can have multiple GWT\nmodules within it. For example, gwt-user.jar in the SDK has many GWT\nmodules.\n\nFor prebuilt jar files, you might want to have a gwt_import rule that takes\na jar file and the name of the module to use.\n\nFrom a build perspective, it appears that they are just resources in a\nJAR file, so I guess there is no reason why there cannot be more than\none.\nIs there ever a case where additional metadata about the gwt.xml files\nneeds to be written to the JAR's manifest or anywhere else?\nNormally nothing special is needed in the jar's manifest. When you start up\nthe GWT compiler, you give it the name of the top-level module you want and\nit looks for that gwt.xml file in the classpath (looks it up as a\nresource), and finds the transitive dependencies from there. Once it finds\nall the modules, it compiles all their source code together (ignoring\nmodule boundaries).\n\nAs a result, if you just compile using the GWT compiler, you won't catch\nerrors where one library depends on another one but doesn't declare the\ndependency. Also, GWT modules can have circular dependencies, which is\nprobably a bad idea.\nFor incremental compilation, we will need to clean this up. In Buck, it's\nprobably a good idea to be stricter about dependencies from the beginning.\n\nThis is why I said earlier that you'd want to symlink files like you do for\njavac, to make sure you don't cross boundaries (launching GWT \u2013compiler or\n(super)devmode\u2013 using the sources would be different from launching it\nusing the packaged files).\nFor example, you could have:\n- src/lib1/BUCK defines a lib1 library with Lib1.gwt.xml and client/\n- src/lib1/Lib1.gwt.xml\n- src/lib1/client/\u2026\n- src/lib2/BUCK defines lib2 library with Lib2.gwt.xml and client/, but\n  missing the //lib1:lib1 dependency\n- src/lib2/Lib2.gwt.xml contains  (i.e; depends\n  on lib1/Lib1.gwt.xml)\n- src/lib2/client/\u2026\nIf you put src/ on the classpath, then GWT will find lib1/* despite the\nmissing dependency.\nIf you package things in JARs (or symlink files into buck-out/) then\nlib1/* won't be in the classpath and you'll have an error. Add the missing\ndependency from //lib2:lib2 to //lib1:lib1 to fix it.\nComputing the GWT dependencies from Buck dependencies (see below) frees you\nfrom having to keep GWT and Buck deps synchronized.\n\nThe answer to this question determines whether a java_library() should\n\n(1) take a single gwt_xml argument as a string, (2) take a single\ngwt_xmlargument as a list of strings, or (3) not special-case\ngwt_xml as its own argument and require developers to use the existing\nresources argument.\nIf you use gwt.xml files as-is, there's nothing to keep their dependencies\nin sync with the declared dependencies in Buck. So our usual approach isn't\nto check in the entire gwt.xml file. Instead we check in a fragment\n(everything but the dependencies) , and generate the part of the gwt.xml\nfile containing the deps. But you could also write automatic checks to\nverify they're in sync, or generate the entire gwt.xml file from\nGWT-specific attributes.\n\n\nI tried to do something similar for Maven, but it has to look at a file\nwithin the JAR to determine the module contained within (assuming there's\nonly one; otherwise the dependency cannot be determined).\nThe file is META-INF/gwt/mainModule and contains the name of the \"main\nmodule\" of the dependency. Adding the dependency to your pom.xml is enough\nfor the GWT maven plugin (net.ltgt.gwt.maven:gwt-maven-plugin, not\norg.codehaus.mojo:gwt-maven-plugin) to generate the .\nContrary to Google, the plugin uses a complete XML document as base\n(defaults to src/main/module.gwt.xml) rather than a fragment, and merges in\n rules.\n\n@skybrian https://github.com/skybrian \"However, the GWT compiler\n\ndoesn't recompile code used by generators, so the bytecode for generators\nhas to be in the classpath. (In addition, some GWT generators assume Java\nbytecode exists so they can use Class.forName() and reflection.)\"\nDoes the GWT compiler normally need the .class files for the .java files\nfor which it is generating JavaScript? Or is that only for the special\ngenerator case?\nThe two cases I know of are generators using reflection and the GWT\ncompiler itself needs to load annotation classes. It's rare enough that in\nSuper Dev Mode, we can get away with adding source code without adding it\nto the classpath (using the -src flag), but unfortunately doesn't work in\nall cases.\n\n\nThere's also the case of classes referenced by annotations (e.g.\n@MyAnnotation(someProperty=SomeClass.class) )\n\n\nWhen the .class files are not needed, it would be nice if Buck could\navoid running javac (assuming it doesn't add any value). (@spearce<\nhttps://github.com/spearce>I believe this is what you are doing in\nhttps://gerrit.googlesource.com/gerrit/+/master/tools/default.defs by\nhaving gwt_module() generate a java_library() that treats all of its\nsrcsas\nresources.)\nIt does add a fair bit of value since javac will report better compiler\nerrors than the GWT compiler.\n\n\nYou'll also need to javac the classes if you test them.\n\nThomas Broyer\n/t\u0254.ma.b\u0281wa.je/ http://xn--nna.ma.xn--bwa-xxb.je/\n. FYI, I copied from Buck how you configure GWT for my gwt-maven-plugin (very few properties exposed, and compilerArgs, jvmArgs and systemProperties for further customization needs).\nPlease note however that strict has been renamed to failOnError in GWT, with strict still being recognized as an alias. Maybe you'd want to use the new naming before documenting it.\nAlso, GWT 2.8 will add --setProperty (gwtproject/gwt@d4f4f4229accfdc29b79cce924ad26cc91e8057a) that you might want to eventually expose on the build rule.\n. Isn't that line missing a trailing comma?. ",
    "MichaelTamm": "buck+cygwin would be good enough.\n. buck+cygwin would be good enough.\n. ",
    "Macarse": "I had SDK tools 22.3 and I am updating to 22.6 still the same issue.\nI downloaded Android SDK Build-tools 19.0.3. I already had 19.0.2, 19.0.1, 19 still the same issue.\n@bolinfest: Any idea what else I can try?\n. I had SDK tools 22.3 and I am updating to 22.6 still the same issue.\nI downloaded Android SDK Build-tools 19.0.3. I already had 19.0.2, 19.0.1, 19 still the same issue.\n@bolinfest: Any idea what else I can try?\n. java version:\njava version \"1.7.0_51\"\nJava(TM) SE Runtime Environment (build 1.7.0_51-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 24.51-b03, mixed mode)\nBuild tools dir:\n/Users/csessa/Documents/adt-bundle-mac-x86_64/sdk/build-tools\n. java version:\njava version \"1.7.0_51\"\nJava(TM) SE Runtime Environment (build 1.7.0_51-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 24.51-b03, mixed mode)\nBuild tools dir:\n/Users/csessa/Documents/adt-bundle-mac-x86_64/sdk/build-tools\n. @oconnor663:\n$ ls ~/Documents/adt-bundle-mac-x86_64/sdk/build-tools/\n19.0.0      19.0.1      19.0.2      19.0.3      android-4.3\n. @oconnor663:\n$ ls ~/Documents/adt-bundle-mac-x86_64/sdk/build-tools/\n19.0.0      19.0.1      19.0.2      19.0.3      android-4.3\n. @oconnor663: Ok, I removed the folder and everything worked correctly.\n. @oconnor663: Ok, I removed the folder and everything worked correctly.\n. @aiked I will try increasing the heap memory. What I don't understand is why gradle doesn't need it.. @aiked I will try increasing the heap memory. What I don't understand is why gradle doesn't need it.. I fixed the problem by adding -Xmx4g to my .buckjavaargs. I guess somehow buck uses more ram than gradle. Would it be worth documenting? . I fixed the problem by adding -Xmx4g to my .buckjavaargs. I guess somehow buck uses more ram than gradle. Would it be worth documenting? . ",
    "sk-": "Note that the error also happens when you simply list the targets.\nI would expect that buck targets still list the targets and only an error is raised when trying to build such target,\nIt seems to me that validating that the target can be built when parsing the configuration is an artifact of the implementation and should be done just at build time.\n. Note that the error also happens when you simply list the targets.\nI would expect that buck targets still list the targets and only an error is raised when trying to build such target,\nIt seems to me that validating that the target can be built when parsing the configuration is an artifact of the implementation and should be done just at build time.\n. Yes, that seems like an appropriate fix. But what about subdirectories\nbuilds? Let's say we are in src/foo/bar, which has the subdirectory\nbaz, would it also be possible to build something in baz using something\nlike buck build baz:foo.\nOn Fri, Jun 6, 2014 at 11:50 PM, Shawn Wilsher notifications@github.com\nwrote:\n\nI think we'd be OK supporting buck build :test in this case, but not buck\nbuild test. Does that seem OK @sk- https://github.com/sk-?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/130#issuecomment-45387973.\n\n\nSebastian Kreft\n. Yes, that seems like an appropriate fix. But what about subdirectories\nbuilds? Let's say we are in src/foo/bar, which has the subdirectory\nbaz, would it also be possible to build something in baz using something\nlike buck build baz:foo.\nOn Fri, Jun 6, 2014 at 11:50 PM, Shawn Wilsher notifications@github.com\nwrote:\n\nI think we'd be OK supporting buck build :test in this case, but not buck\nbuild test. Does that seem OK @sk- https://github.com/sk-?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/130#issuecomment-45387973.\n\n\nSebastian Kreft\n. Thanks, that actually fixes the issue. However, I think that using exported_deps is probably a better solution.\n. Thanks, that actually fixes the issue. However, I think that using exported_deps is probably a better solution.\n. That's correct.\nI have at least two use cases for such a pattern:\n1) Generate a jar file with a resource in a specific location (not the same as the package)\n2) Generate a non-shaded jar file with dependencies. This is important for some frameworks like Spring, as they have a custom class-loader.\nProbably for case number 1) there's a better way to do it.\nI forgot to mention that the build succeeds and no error is raised, which makes it a hard to debug issue.\n. @natthu I tried what you suggested, but as expected, that only add the jar as a resource. Which is not what is I was looking for.\n. Yes. Would it be possible to add that info somewhere in the docs.\nOn Aug 7, 2014 10:23 PM, \"Natthu Bharambe\" notifications@github.com wrote:\n\nSorry, I did not understand the issue correctly before. A java_library\nonly includes resources from its transitive dependencies of type\njava_library/android_library/prebuilt_jar, so you must wrap that jar in a\nprebuilt_jar rule.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/135#issuecomment-51526441.\n. Yes. Would it be possible to add that info somewhere in the docs.\nOn Aug 7, 2014 10:23 PM, \"Natthu Bharambe\" notifications@github.com wrote:\nSorry, I did not understand the issue correctly before. A java_library\nonly includes resources from its transitive dependencies of type\njava_library/android_library/prebuilt_jar, so you must wrap that jar in a\nprebuilt_jar rule.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/135#issuecomment-51526441.\n. Agree. However I think it's confusing to have the term build target and build target pattern when the latter only applies to visibility. Maybe the latter could be changed in the documentation to something like Visibility build target pattern, or Build target pattern (visibility).\n\nI created issue #139, asking for this feature.\nps: the build target docs, have a slight error. It reads:\nA build target that ends with /... matches any build target pattern that ...\nBut it should read\nA build target pattern that ends with /... matches any build target that ...\n. Thanks @bolinfest for the reference to the sh_test build rule. However, I still think that a proper gentestrule will be much useful, as mnay things that java test can do are not possible with a sh_test.\nCurrently the sh test only allows you to run an executable with no arguments, so its very limited when compared to the sh option of a genrule. In addition there's no way to pass the arguments of buck test to the underlying executable. The options that are very important to be able to pass to the tests, are: --code-coverage, --filter, --test-selectors and --dry-run.\nFor the boolean options, a possible solution would be something like $(if-code-coverage --with-coverage), where that string will translate to --with-coverage only if the --code-coverage option was specified. That method could also work for non boolean options. In addtion non boolean options values could be accessed with something like $(filter).\nThen one could write the sh option like:\nsh = 'test_exe $(if-coverage --with-coverage) $(if-filter --test-filter=$(filter))'\nAnd finally the output of a sh test in case of failure is quite different to the one of a java test. It just prints the stdout and stderr with a separator. Instead it would be much nicer if one could generate the output of the test in a specific way that BUCK understands so the output is normalized across all tests.\n. Thanks, for pointing that out. However, I still think that having a gettestrule as detailed above will certainly make BUCK much more powerful.\nThe problem with python_test is that it does not understand test filters or provide code coverage. additionally it is  bound to the unittest runner. But what if I would like to allow pytest tests?\nAlso, what if I want to support test for an unsupported language like Javascript, or even D as flint requires?\n. Thanks, for pointing that out. However, I still think that having a gettestrule as detailed above will certainly make BUCK much more powerful.\nThe problem with python_test is that it does not understand test filters or provide code coverage. additionally it is  bound to the unittest runner. But what if I would like to allow pytest tests?\nAlso, what if I want to support test for an unsupported language like Javascript, or even D as flint requires?\n. Thanks for pointing that out. However, building the library in that way does not really allow me to use it, as a soname is being set. In my case, the soname includes the path to the library (libthird_party_cld2_cld2_full.so). Is there a way to disable that behavior?\nBelow is an excerpt of the command executed by BUCK:\n/usr/bin/g++ -o buck-out/bin/third_party/cld2/cld2_full#default,shared/libcld2_full.so -shared -Xlinker -soname -Xlinker libthird_party_cld2_cld2_full.so ...\nAlso could you explain what flavors are and list them, so we could propose a PR to the documentation.\n. Thanks for pointing that out. However, building the library in that way does not really allow me to use it, as a soname is being set. In my case, the soname includes the path to the library (libthird_party_cld2_cld2_full.so). Is there a way to disable that behavior?\nBelow is an excerpt of the command executed by BUCK:\n/usr/bin/g++ -o buck-out/bin/third_party/cld2/cld2_full#default,shared/libcld2_full.so -shared -Xlinker -soname -Xlinker libthird_party_cld2_cld2_full.so ...\nAlso could you explain what flavors are and list them, so we could propose a PR to the documentation.\n. That was the trick, to manually set the soname. Which I didn't in the first place as there is not specified in the documentation. \n. That was the trick, to manually set the soname. Which I didn't in the first place as there is not specified in the documentation. \n. ",
    "evancox10": "I know this issue has been closed for a while, but I wanted to double check that this is in fact how Buck determines the project root:\n\"Mostly what we're missing at this point is an official way to determine the root of your project, the way git looks for the nearest .git directory. Probably we would use .buckconfig for this?\"\nI couldn't find anything that documents this, guess it was never made official?\nAlso, I think I could make a case for a need to use CWD-relative and/or current-BUCK-file-relative paths in my (admittedly very niche) use case. Should I raise a new issue?\n. I'm hitting inotify limits but only getting a generic watchman timed out message, had to hunt down the failure cause manually. Possible regression? Details below\n[x@y some_folder]$ buck clean\nShutting down nailgun server...\nUsing watchman.\nWaiting for Watchman query [[watch-project, /some_folder/.]]...\nTimed out after 10000 ms waiting for Watchman command [[watch-project, /some_folder/.]]. Disabling Watchman.\nChecking ~/var/run/watchman/evancox-state/log\n```\n2016-07-10T22:19:39,803: [client=0x1866720:stm=0x1866120] send_error_response: [\"get-pid\"] failed: A non-recoverable condition has triggered.  Watchman needs your help!\nThe triggering condition was at timestamp=1468214319: inotify-add-watch(/some_folder/another_folder) -> The user limit on the total number of inotify watches was reached; increase the fs.inotify.max_user_watches sysctl\nAll requests will continue to fail with this message until you resolve\nthe underlying problem.  You will find more information on fixing this at\nhttps://facebook.github.io/watchman/docs/troubleshooting.html#poison-inotify-add-watch\n2016-07-10T22:19:39,803: [sockcheck] Failed to extract pid from get-pid response: Object item not found: pid\n2016-07-10T22:19:39,805: [sockcheck] Fatal error detected at:\n2016-07-10T22:19:39,805: [sockcheck] /home/evancox/bin/watchman() [0x4067f5]\n2016-07-10T22:19:39,805: [sockcheck] /home/evancox/bin/watchman() [0x406365]\n2016-07-10T22:19:39,805: [sockcheck] /lib64/libpthread.so.0() [0x38d46079d1]\n2016-07-10T22:19:39,805: [sockcheck] /lib64/libc.so.6(clone+0x6d) [0x38d3ee88fd]\n```\nwatchman is version 4.6.0\nBuck is version 8ba44608c8829cfadf18efadd41b064cbc768536\n. Sorry to continue my run of commenting on closed issues, but I'm also seeing what looks like a regression of this ticket. Here's my .buckconfig:\n[buildfile]\n  includes = //support/etc/verilog.def\n[project]\n  ignore = INCA_libs, cds6\n  temp_files = .*~$\n  watchman_query_timeout_ms = 30000\n  allow_symlinks = forbid\nRunning buck clean, I get this:\n[evancox@machine evancox_sjc]$ buck clean\nShutting down nailgun server...\nUsing watchman.\nWaiting for Watchman query [[watch-project, /my_folder/.]]...\nTimed out after 10000 ms waiting for Watchman command [[watch-project, /my_folder/.]]. Disabling Watchman.\nWhen watchman hits the inotify limit, it's on a file inside //cds6. From ~/var/run/watchman/evancox-state/log:\n```\n2016-07-11T13:01:02,640: [client=0x139b720:stm=0x139b120] send_error_response: [\"get-pid\"] failed: A non-recoverable condition has triggered.  Watchman needs your help!\nThe triggering condition was at timestamp=1468267202: inotify-add-watch(/my_folder/cds6/something1/something2) -> The user limit on the total number of inotify wat\nAll requests will continue to fail with this message until you resolve\nthe underlying problem.  You will find more information on fixing this at\nhttps://facebook.github.io/watchman/docs/troubleshooting.html#poison-inotify-add-watch\n2016-07-11T13:01:02,640: [sockcheck] Failed to extract pid from get-pid response: Object item not found: pid\n2016-07-11T13:01:02,642: [sockcheck] Fatal error detected at:\n2016-07-11T13:01:02,642: [sockcheck] /home/evancox/bin/watchman() [0x4067f5]\n2016-07-11T13:01:02,642: [sockcheck] /home/evancox/bin/watchman() [0x406365]\n2016-07-11T13:01:02,642: [sockcheck] /lib64/libpthread.so.0() [0x38d46079d1]\n2016-07-11T13:01:02,642: [sockcheck] /lib64/libc.so.6(clone+0x6d) [0x38d3ee88fd]\n```\nCan confirm that the problem is in buck telling watchman what to do, as if I add the following in a .watchmanconfig file:\n{ \"ignore_dirs\": [ \"buck-out\", \"buch-cache\", \".buckd\", \"cds6\", \"INCA_libs\" ] }\nthen I still hit the inotify limit, but it's not in cds6 or one of the other ignore_dirs.\nYou'll notice that Buck also doesn't seem to be obeying the watchman_query_timeout_ms setting. Have I just PEBCAK'ed the .buckconfig file? I triple-checked the documentation and compared it to the .buckconfig in facebook/buck, seem's like I'm doing it right. I noticed that the project still has a .watchmanconfig, however, so if there were any issues with this I'm not sure it would surface in your environment.\n(Can't just increase inotify limits as this server is managed by IT and I don't have root. Until the gears turn on a support ticket, I'd like to still move ahead with buck development.)\n. You've hit the nail on the head. I looked at using Buck or Bazel for managing HDL environments (Verilog, SystemVerilog, VHDL, etc.), but lack of support for nesting projects was a show stopper.\nIn Verilog, the basic unit of \"code\" is actually called a module, so one would think it would be easy to adapt Buck to it. Not so! I'm unable to reuse a module from another Buck project if that modules also happened to reuse sub-modules \nThanks for the write-up here.\n. ",
    "Qix-": "I've written a pretty thorough explanation of the problem along with two proposed solutions at #939 as some of your here have suggested. I couldn't find anything else in the tracker regarding this other than this ticket.\n. Still confused as to how to use genrule()'s output.\n``` python\ngenrule(\n    name = 'test-peg',\n    srcs = ['src/test.peg'],\n    out = 'test-peg.c',\n    cmd = 'peg src/test.peg -o $OUT')\ncxx_binary(\n    name = 'test-project',\n    srcs = [\n        'src/cli.c',\n        '$(location //:test-peg.c)'],  # //:test-peg by itself didn't work either...\n    compiler_flags = [\n        '-Wall', '-Wextra',\n        '-Werror', '-pedantic',\n        '-std=c99'],\n    licenses = [\n        'LICENSE'],\n    visibility = [\n        'PUBLIC'])\n```\nbuck targets gets me\nconsole\n$ buck targets\n[+] PARSING BUCK FILES...0.1s [100%]\nBUILD FAILED: Unable to find repository '$(location ' in cell rooted at: /src/test-project-grammar\n. Still confused as to how to use genrule()'s output.\n``` python\ngenrule(\n    name = 'test-peg',\n    srcs = ['src/test.peg'],\n    out = 'test-peg.c',\n    cmd = 'peg src/test.peg -o $OUT')\ncxx_binary(\n    name = 'test-project',\n    srcs = [\n        'src/cli.c',\n        '$(location //:test-peg.c)'],  # //:test-peg by itself didn't work either...\n    compiler_flags = [\n        '-Wall', '-Wextra',\n        '-Werror', '-pedantic',\n        '-std=c99'],\n    licenses = [\n        'LICENSE'],\n    visibility = [\n        'PUBLIC'])\n```\nbuck targets gets me\nconsole\n$ buck targets\n[+] PARSING BUCK FILES...0.1s [100%]\nBUILD FAILED: Unable to find repository '$(location ' in cell rooted at: /src/test-project-grammar\n. Do you mean $(location //:test-peg)? or just //:test-peg as a source path by itself?\n. Do you mean $(location //:test-peg)? or just //:test-peg as a source path by itself?\n. Ahh okay. I'll try that again.\nEDIT: worked, thanks!\n. Ahh okay. I'll try that again.\nEDIT: worked, thanks!\n. I can't even fix this using the workaround of re-creating the rules in the higher directories right now.\n[+] PARSING BUCK FILES...0.2s\nBUILD FAILED: 'ext/arua-bootstrap-grammar/src/arua.leg' in '//:arua-leg' crosses a buck package boundary.  This file is owned by 'ext/arua-bootstrap-grammar'.  Find the owning rule that references 'ext/arua-bootstrap-grammar/src/arua.leg', and use a reference to that rule instead of referencing the desired file directly.\nI'm going to have to use an os.unlink() call in the main BUCK file to remove the nested BUCK files in order to get passed the boundary and tell Git to ignore those submodules being dirty. :/\nEDIT: the workaround:\n``` python\nXXX temporary - see facebook/buck#939\nimport os\nimport os.path as path\ndef punlink(*args, kwargs):\n    try:\n        os.unlink(*args, kwargs)\n    except:\n        pass\npunlink('ext/arua-bootstrap-grammar/BUCK')\npunlink('ext/arua-bootstrap-grammar/.buckconfig')\npunlink('ext/arua-bootstrap-grammar/ext/BUCK')\nXXX end temporary\n```\n. @sdwilsh I'm not sure I'm following. What are cells? Where can I read about them?\n. From what I can gather about cells, no, this is not what I'm addressing. From what I can tell (since there is no documentation) cells are just sibling directories with Buck projects inside that allow you to reference another sibling. This doesn't solve this problem.\n. If Buck is to remain a monorepo-biased build system then yes, that does work. Thank you for the followup @coneko :)\n. ",
    "kageiit": "@mread can you post the xslt stylesheets for the conversion here?\nedit: nvm, I used a slightly modified version of https://gerrit-review.googlesource.com/69762 (to produce only one junit report xml). Thanks @davido \n. @yiding and update on this?. Who would be the right poc for this? For a large codebase migration, this seems like a useful feature. I added support for this in https://github.com/facebook/buck/pull/1435. This error is thrown by dx (only when building with buck, gradle builds just fine). I had a similar error with other core classes like DocumentBuilder and QName.class. You may have to repackage the jar after removing the classes dx complains about and try again. Rinse and repeat till dx is happy.\n. @sdwilsh can this be reviewed please?\n. @dreiss You are right. The R.java entries from the dummy and the uber ones differ, so the generated classes from butterknife have the wrong integer constant specified which crashes the app at runtime. One solution I can think of is to run the aapt step before javac/apt when force_final_resource_ids is true to ensure the ids do not mismatch. Let me know if that sounds ok, I will investigate how to do so\n. @dreiss You are right. The R.java entries from the dummy and the uber ones differ, so the generated classes from butterknife have the wrong integer constant specified which crashes the app at runtime. One solution I can think of is to run the aapt step before javac/apt when force_final_resource_ids is true to ensure the ids do not mismatch. Let me know if that sounds ok, I will investigate how to do so\n. Running aapt before source code generation is how gradle behaves. Is there some reason why this is not the case in buck?\n. Running aapt before source code generation is how gradle behaves. Is there some reason why this is not the case in buck?\n. @marcinkosiba this is only for the android library rule that corresponds to the android binary code. This will not be run on every android library rule. Only the R.java generated using the code of the app will be done this way. That code is not shared across binaries.\nButterknife is not the only tool to rely on resource IDs this way there are plenty of other libraries that do so like android-annotations, android-data-binding etc. We would be excluding an entire class of apps from being able to take advantage of buck without this.\nGradle runs resource processing before code gen already. Can you expand on what do you mean by it being slow? It still has to run atleast once during compilation. If we were to enable running aapt before only for the binary I think we can still share the result of compiling individual java/android libraries\n. @marcinkosiba this is only for the android library rule that corresponds to the android binary code. This will not be run on every android library rule. Only the R.java generated using the code of the app will be done this way. That code is not shared across binaries.\nButterknife is not the only tool to rely on resource IDs this way there are plenty of other libraries that do so like android-annotations, android-data-binding etc. We would be excluding an entire class of apps from being able to take advantage of buck without this.\nGradle runs resource processing before code gen already. Can you expand on what do you mean by it being slow? It still has to run atleast once during compilation. If we were to enable running aapt before only for the binary I think we can still share the result of compiling individual java/android libraries\n. > However, we can take the srcs from an android_binary and graph\n\nenhance it to produce an android_library with forceFinalResourceIds\nset to true.  It's a bigger change, but it's the safer one and I think\n@marcinkosiba would be okay with that.  I'm pretty sure I've talked with\nhim or @dreiss about that very solution (but never had time to code it up).\n\nThe issue is that aapt step rewrites the resource ids that get put into the resource bundle/apk. So it does not matter if we generate R.java with final values by setting forceFinalResourceIds=true , if it will get overwritten anyway.\n. > However, we can take the srcs from an android_binary and graph\n\nenhance it to produce an android_library with forceFinalResourceIds\nset to true.  It's a bigger change, but it's the safer one and I think\n@marcinkosiba would be okay with that.  I'm pretty sure I've talked with\nhim or @dreiss about that very solution (but never had time to code it up).\n\nThe issue is that aapt step rewrites the resource ids that get put into the resource bundle/apk. So it does not matter if we generate R.java with final values by setting forceFinalResourceIds=true , if it will get overwritten anyway.\n. @sdwilsh thats the same idea I had in mind as well. We can of course do this without exposing the forceFinalResourceIds as well. But it would still be nice to have this as an option since if an app does not use this, there is no need for it to suffer he burden of having aapt run on the critical path.\n. > If an app doesn't specify any srcs, I don't think we'd have to do this. Am I misunderstanding you?\nthe android_binary rule does not expose anyway to set a srcs in buck. Are you talking about the sources that come from the various dependencies?\n. Sounds like a pretty major change :(\nGoogle announced a new aapt at Google I/O yesterday that is not supposed to rewrite the IDs when packaging. Combined with the original PR and having resourceUnion = True I believe it might be able to solve the problem without this change (although it would be the right thing to do for the long term). I will try that out and update on what the result is.\n. I made a version of butterknife that outputs R.id.identifier in the generated code instead of inlining the integers. But then I realized that it does not matter even if the dummy R dot Java files are final, the resource will not be found at runtime since the final R dot Java has entirely different values. aapt seems to be still rewriting resource ids on the latest sdk tools version available.\nSeems like the solution proposed by @sdwilsh is the proper one in the long term that will work for all cases.\n. @marcinkosiba sorry, I forgot to mention that javac optimizations inline the constants so the class files will just have the integers (since R.id values are final and we cannot use non final values in annotations). I have however been able to come up with a system that will support libraries to work with butterknife and put the non final R values in the generated code. This has a side effect of making buck work with butterknife without any changes to buck. I plan to open a PR on butterknife soon.\n. @dreiss @sdwilsh @marcinkosiba I made this work in butterknife instead. https://github.com/JakeWharton/butterknife/pull/613\n. @dreiss @marcinkosiba \n. > Agree with @dreiss, the correct way to fix this is to post a ConsoleEvent to the BuckMessageBus, doing that causes the warning to print without breaking the rendering\nI can just replace the warning call to instead post a ConsoleEvent to the BuckMessageBus. That sounds fine by me.\n\nDo you know where the source for that class is? I don't see it in the haha repository.\n\nMaybe an older version of haha. This also happens on a lot of other sdks provided by baidu for example\n. @marcinkosiba @dreiss this code is in the third party dx code dump. Is there a way to get access to the BuckEventBus there?\n. @marcinkosiba @dreiss this code is in the third party dx code dump. Is there a way to get access to the BuckEventBus there?\n. @marcinkosiba updated with your suggestion\n. @marcinkosiba tagging you since you wrote the original manifest_entries logic\n. @dreiss would you be able to take a look at this please?\n. > Do you know if this is handled upstream by the manifest merger? We've been talking about upgrading it for a while now.\n@dreiss \nActually digging deeper, it does in com.android.manifmerger.ManifestMerger2 . But I am not sure how I would be able to upgrade/use it in buck.\n. > Do you know if this is handled upstream by the manifest merger? We've been talking about upgrading it for a while now.\n@dreiss \nActually digging deeper, it does in com.android.manifmerger.ManifestMerger2 . But I am not sure how I would be able to upgrade/use it in buck.\n. upgrading the manifest merger is out of scope of this PR. It is a much larger change which I do not have the time to do right now unfortunately :(\n. upgrading the manifest merger is out of scope of this PR. It is a much larger change which I do not have the time to do right now unfortunately :(\n. Might be the same as #784 \n. @marcinkosiba could also please help take a look?\n. > I notice that you're not explicitly specifying the package of FinalR. That's fine as long as it's intentional.\nYes its intentional. finalR will just be created alongside R. There did not seem to have a compelling reason to have an option to put it anywhere else\n. updated\n. @cosmin1123 you may be interested in this\n. @cosmin1123 you may be interested in this\n. @marcinkosiba can you provide any insight on this?\n. @marcinkosiba can you provide any insight on this?\n. We have also observed even with the correct adb version, buck is not able to install to devices since it thinks adb connection does not exists/devices do not exist.\nadb devices says otherwise. The problem seemed to go away after deleting the .buckd folder and rerunning the same command. Ill provide concrete repro steps next time this happens.\n. We have also observed even with the correct adb version, buck is not able to install to devices since it thinks adb connection does not exists/devices do not exist.\nadb devices says otherwise. The problem seemed to go away after deleting the .buckd folder and rerunning the same command. Ill provide concrete repro steps next time this happens.\n. We are seeing this when trying to run instrumentation tests as well\n```\ninstrumentation test\nstderr: Unable to set up adb.\n    at com.facebook.buck.step.StepFailedException.createForFailingStepWithExitCode(StepFailedException.java:62)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:71)\n    at com.facebook.buck.step.DefaultStepRunner$1.call(DefaultStepRunner.java:92)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService$1.apply(WeightedListeningExecutorService.java:80)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService$1.apply(WeightedListeningExecutorService.java:76)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n    at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n    at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n\n====STANDARD OUT====\n====STANDARD ERR====\n```\nAfter deleting the .buckd folder and running again the error message changes to\nBUILD FAILED: Failed to create adb connection.\nBUILD FAILED: Expecting one android device/emulator to be attached.\n. The adb path is correct. I verified it by looking at the returned adbExecutablePath in InstrumentationTestRunner\nThis seems to be mitigated by changing ADB_CONNECT_TIMEOUT_MS in com.facebook.buck.testrunner.InstrumentationTestRunner to a much higer value like 50 seconds instead of 5.\nA few possible options to look at\n- We are using latest adb from platform tools 24.4.1_1\n- Buck is using an older version of ddmlib\n- Providing a way to increase the timeout in buckconfig\n@marcinkosiba please advice\n. The adb path is correct. I verified it by looking at the returned adbExecutablePath in InstrumentationTestRunner\nThis seems to be mitigated by changing ADB_CONNECT_TIMEOUT_MS in com.facebook.buck.testrunner.InstrumentationTestRunner to a much higer value like 50 seconds instead of 5.\nA few possible options to look at\n- We are using latest adb from platform tools 24.4.1_1\n- Buck is using an older version of ddmlib\n- Providing a way to increase the timeout in buckconfig\n@marcinkosiba please advice\n. We have noticed that there is a delay of atleast 25 seconds before AdbHelper can return true for isAdbInitialized\nHere are the repro steps for this bug\n- Install latest platform tools -> 24.4.1_1 (Android Debug Bridge version 1.0.36 Revision e02fe72a18c3-android )\n- Checkout https://github.com/uber/okbuck\n- Run ./gradlew okbuck to generate buck files for the project\n- Run buck test //app:instrumentation_demoDebug_test against HEAD of buck\n- Test fails with cannot create adb/ cannot setup adb\n- Change ADB_CONNECT_TIMEOUT_MS to something like 60000 instead of 5000 in both src/com/facebook/buck/testrunner/InstrumentationTestRunner.java and src/com/facebook/buck/android/AdbHelper.java\n- Run the instrumentation test command again. It will succeed\n. We have noticed that there is a delay of atleast 25 seconds before AdbHelper can return true for isAdbInitialized\nHere are the repro steps for this bug\n- Install latest platform tools -> 24.4.1_1 (Android Debug Bridge version 1.0.36 Revision e02fe72a18c3-android )\n- Checkout https://github.com/uber/okbuck\n- Run ./gradlew okbuck to generate buck files for the project\n- Run buck test //app:instrumentation_demoDebug_test against HEAD of buck\n- Test fails with cannot create adb/ cannot setup adb\n- Change ADB_CONNECT_TIMEOUT_MS to something like 60000 instead of 5000 in both src/com/facebook/buck/testrunner/InstrumentationTestRunner.java and src/com/facebook/buck/android/AdbHelper.java\n- Run the instrumentation test command again. It will succeed\n. @marcinkosiba the error strings are definitely coming from the buck codebase and it thinks that adb is not initialized yet. I have suggested some approaches to mitigate this issue previously. let us know what the best course of action would be\n. @marcinkosiba the error strings are definitely coming from the buck codebase and it thinks that adb is not initialized yet. I have suggested some approaches to mitigate this issue previously. let us know what the best course of action would be\n. @k21 @cosmin1123 any updates on this?\n. The same issue occurs with use_linear_alloc_split_dex set to true and false\n. The same issue occurs with use_linear_alloc_split_dex set to true and false\n. This is how the debug variant looks like and is able to build successfully\nandroid_binary(\n    name = 'bin_debug',\n    manifest = ':manifest_debug',\n    keystore = '//.okbuck/keystore/app-apk:key_store_debug.keystore',\n    use_split_dex = True,\n    linear_alloc_hard_limit = 16777216,\n    manifest_entries = {\n        'placeholders': {\n            'applicationId': 'com.example.app.development',\n        },\n    },\n    deps = [\n        ':src_debug',\n        ':res_debug_ed72d21a643fcb598330f892147f5f0b',\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n)\n. This is how the debug variant looks like and is able to build successfully\nandroid_binary(\n    name = 'bin_debug',\n    manifest = ':manifest_debug',\n    keystore = '//.okbuck/keystore/app-apk:key_store_debug.keystore',\n    use_split_dex = True,\n    linear_alloc_hard_limit = 16777216,\n    manifest_entries = {\n        'placeholders': {\n            'applicationId': 'com.example.app.development',\n        },\n    },\n    deps = [\n        ':src_debug',\n        ':res_debug_ed72d21a643fcb598330f892147f5f0b',\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n)\n. Here is the full stack trace\n```\nThere was an error in smart dexing step.\ncom.facebook.buck.step.StepFailedException: Failed on step dx_&&_write_file with an exception:\nfield ID not in [0, 0xffff]: 65536\ncom.android.dex.DexIndexOverflowException: field ID not in [0, 0xffff]: 65536\n    at com.android.dx.merge.DexMerger$5.updateIndex(DexMerger.java:482)\n    at com.android.dx.merge.DexMerger$IdMerger.mergeSorted(DexMerger.java:302)\n    at com.android.dx.merge.DexMerger.mergeFieldIds(DexMerger.java:490)\n    at com.android.dx.merge.DexMerger.mergeDexes(DexMerger.java:173)\n    at com.android.dx.merge.DexMerger.merge(DexMerger.java:195)\n    at com.android.dx.command.dexer.Main.mergeLibraryDexBuffers(Main.java:488)\n    at com.android.dx.command.dexer.Main.runMonoDex(Main.java:334)\n    at com.android.dx.command.dexer.Main.run(Main.java:268)\n    at com.android.dx.command.dexer.Main.run(Main.java:238)\n    at com.facebook.buck.android.DxStep.executeInProcess(DxStep.java:206)\n    at com.facebook.buck.android.DxStep.execute(DxStep.java:186)\n    at com.facebook.buck.step.CompositeStep.execute(CompositeStep.java:43)\n    at com.facebook.buck.step.CompositeStep.execute(CompositeStep.java:43)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:63)\n    at com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:124)\n    at com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:1)\n    at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108)\n    at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41)\n    at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\ncom.facebook.buck.step.StepFailedException: Failed on step dx_&&_write_file with an exception:\nfield ID not in [0, 0xffff]: 65536\ncom.android.dex.DexIndexOverflowException: field ID not in [0, 0xffff]: 65536\n    at com.android.dx.merge.DexMerger$5.updateIndex(DexMerger.java:482)\n    at com.android.dx.merge.DexMerger$IdMerger.mergeSorted(DexMerger.java:302)\n    at com.android.dx.merge.DexMerger.mergeFieldIds(DexMerger.java:490)\n    at com.android.dx.merge.DexMerger.mergeDexes(DexMerger.java:173)\n    at com.android.dx.merge.DexMerger.merge(DexMerger.java:195)\n    at com.android.dx.command.dexer.Main.mergeLibraryDexBuffers(Main.java:488)\n    at com.android.dx.command.dexer.Main.runMonoDex(Main.java:334)\n    at com.android.dx.command.dexer.Main.run(Main.java:268)\n    at com.android.dx.command.dexer.Main.run(Main.java:238)\n    at com.facebook.buck.android.DxStep.executeInProcess(DxStep.java:206)\n    at com.facebook.buck.android.DxStep.execute(DxStep.java:186)\n    at com.facebook.buck.step.CompositeStep.execute(CompositeStep.java:43)\n    at com.facebook.buck.step.CompositeStep.execute(CompositeStep.java:43)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:63)\n    at com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:124)\n    at com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:1)\n    at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108)\n    at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41)\n    at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nat com.facebook.buck.step.StepFailedException.createForFailingStepWithException(StepFailedException.java:85)\nat com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:65)\nat com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:124)\nat com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:1)\nat com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108)\nat com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41)\nat com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n\nBUILD FAILED: //app-apk:bin_exo#dex_merge failed with exit code 1:\nsmart_dex\n[-] PROCESSING BUCK FILES...FINISHED 0.2s \ud83d\udc07\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 0.6s [100%] (381/383 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS) Details: http://localhost:61950/trace/e0c90467-d4ab-4d86-863a-781a43cfafa0\n```\n. Here is the full stack trace\n```\nThere was an error in smart dexing step.\ncom.facebook.buck.step.StepFailedException: Failed on step dx_&&_write_file with an exception:\nfield ID not in [0, 0xffff]: 65536\ncom.android.dex.DexIndexOverflowException: field ID not in [0, 0xffff]: 65536\n    at com.android.dx.merge.DexMerger$5.updateIndex(DexMerger.java:482)\n    at com.android.dx.merge.DexMerger$IdMerger.mergeSorted(DexMerger.java:302)\n    at com.android.dx.merge.DexMerger.mergeFieldIds(DexMerger.java:490)\n    at com.android.dx.merge.DexMerger.mergeDexes(DexMerger.java:173)\n    at com.android.dx.merge.DexMerger.merge(DexMerger.java:195)\n    at com.android.dx.command.dexer.Main.mergeLibraryDexBuffers(Main.java:488)\n    at com.android.dx.command.dexer.Main.runMonoDex(Main.java:334)\n    at com.android.dx.command.dexer.Main.run(Main.java:268)\n    at com.android.dx.command.dexer.Main.run(Main.java:238)\n    at com.facebook.buck.android.DxStep.executeInProcess(DxStep.java:206)\n    at com.facebook.buck.android.DxStep.execute(DxStep.java:186)\n    at com.facebook.buck.step.CompositeStep.execute(CompositeStep.java:43)\n    at com.facebook.buck.step.CompositeStep.execute(CompositeStep.java:43)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:63)\n    at com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:124)\n    at com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:1)\n    at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108)\n    at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41)\n    at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\ncom.facebook.buck.step.StepFailedException: Failed on step dx_&&_write_file with an exception:\nfield ID not in [0, 0xffff]: 65536\ncom.android.dex.DexIndexOverflowException: field ID not in [0, 0xffff]: 65536\n    at com.android.dx.merge.DexMerger$5.updateIndex(DexMerger.java:482)\n    at com.android.dx.merge.DexMerger$IdMerger.mergeSorted(DexMerger.java:302)\n    at com.android.dx.merge.DexMerger.mergeFieldIds(DexMerger.java:490)\n    at com.android.dx.merge.DexMerger.mergeDexes(DexMerger.java:173)\n    at com.android.dx.merge.DexMerger.merge(DexMerger.java:195)\n    at com.android.dx.command.dexer.Main.mergeLibraryDexBuffers(Main.java:488)\n    at com.android.dx.command.dexer.Main.runMonoDex(Main.java:334)\n    at com.android.dx.command.dexer.Main.run(Main.java:268)\n    at com.android.dx.command.dexer.Main.run(Main.java:238)\n    at com.facebook.buck.android.DxStep.executeInProcess(DxStep.java:206)\n    at com.facebook.buck.android.DxStep.execute(DxStep.java:186)\n    at com.facebook.buck.step.CompositeStep.execute(CompositeStep.java:43)\n    at com.facebook.buck.step.CompositeStep.execute(CompositeStep.java:43)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:63)\n    at com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:124)\n    at com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:1)\n    at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108)\n    at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41)\n    at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nat com.facebook.buck.step.StepFailedException.createForFailingStepWithException(StepFailedException.java:85)\nat com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:65)\nat com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:124)\nat com.facebook.buck.step.DefaultStepRunner$2$1.call(DefaultStepRunner.java:1)\nat com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:108)\nat com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:41)\nat com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:77)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n\nBUILD FAILED: //app-apk:bin_exo#dex_merge failed with exit code 1:\nsmart_dex\n[-] PROCESSING BUCK FILES...FINISHED 0.2s \ud83d\udc07\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 0.6s [100%] (381/383 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS) Details: http://localhost:61950/trace/e0c90467-d4ab-4d86-863a-781a43cfafa0\n```\n. Followup for #814 \n. Followup for #814 \n. cc @cosmin1123 \n. cc @cosmin1123 \n. The listing confirms it too https://plugins.jetbrains.com/plugin/7826?pr=idea\nIt is listed as compatible with 139-147. But the current plugin.xml on master is compatible with 162.*\n. The listing confirms it too https://plugins.jetbrains.com/plugin/7826?pr=idea\nIt is listed as compatible with 139-147. But the current plugin.xml on master is compatible with 162.*\n. Looks good!\n. Looks good!\n. > so the choice is to either have a hardcoded value, which may or may not work (deprecated project), to have none (current project implementation)\nHow about writing only if values are explicitly specified instead? I was also thinking of doing an sdk option per language like\nandroid_sdk\njava_sdk\nThis can then be set on the module xml of the corresponding targets. This way more jvm based languages can add their own sdk parameters as needed and st them in their module xml.The language level can be inferred from the source and target options set on the java/android targets, to be set on the module xml instead of misc.xml as well.\n. @marcinkosiba I put up a PR #832 that sets up the jdk and language level in every module.iml file instead. This achieves what @tonycosentini mentioned in the previous comment.\n. #832 makes it possible to configure multiple default sdks per project based on the type of module\n. Where is the report located? I am only seeing buck-out/gen/jacoco/jacoco.exec even after i passed the --code-coverage-format=xml option like\nbuck test --code-coverage-format=xml --code-coverage\nRunning with the buck built from HEAD\n. Where is the report located? I am only seeing buck-out/gen/jacoco/jacoco.exec even after i passed the --code-coverage-format=xml option like\nbuck test --code-coverage-format=xml --code-coverage\nRunning with the buck built from HEAD\n. I opened a PR for the fully-qualified name approach. Ran a clean build on our codebase\n```\nHEAD - 88.7s [100%] (1086/1086 JOBS, 1086 UPDATED, 1086 [100.0%] CACHE MISS)\nWith fully qualified names - 91.8s [100%] (1086/1086 JOBS, 1086 UPDATED, 1086 [100.0%] CACHE MISS)\n```\nI also profiled the two most expensive dx steps from our build trace\nHEAD:\n```\nTitle   dx\nCategory    buck\nStart \n13,572.447 ms\nWall Duration \n15,425.481 ms\nTitle   dx\nCategory    buck\nStart \n9,368.561 ms\nWall Duration \n5,632.914 ms\n```\nWith fully qualified names:\n```\nTitle   dx\nCategory    buck\nStart \n13,767.272 ms\nWall Duration \n26,444.564 ms\nTitle   dx\nCategory    buck\nStart \n11,440.091 ms\nWall Duration \n7,884.260 ms\n```\nI think the overall performance impact during build is not significant using this approach.\n. As a comparison, the number of fields in the uber R.java jar dex went down from 60570 to 2091\n. > Wait, wall duration went from 15 seconds to 26 seconds? That doesn't seem possible...\nIt is probably because we do some extra work for supporting robolectric tests in the MergeResourcesStep. I will profile the time taken to compute the referenced fields by getting the time in Millis before and after the computation for the change to see the impact more isolated\n. I got the time before and after https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/TrimUberRDotJava.java#L119\nand here are the results\n```\nCurrent\nTime to compute referenced resources : 290.765277 ms\nWith FQ name\nTime to compute referenced resources : 193.802684 ms\n```\nI think it is because the time gained back by not writing back more entries to the file is more than the time lost comparing with the FQ names\n. > What about the time in computeReferencedResources in dexer/Main?\nThe time was 1~3 ms for that operation across most dexes in both cases\n. > Looks like AndroidBinaryIntegrationTest and TrimUberRDotJavaTest are failing. Want to take a look?\nSure I will update the tests. Thanks!\n. @dreiss tests updated and pass\n. @dreiss tests updated and pass\n. > Have you considered what happens when aggregation is enabled?\nI dont know what aggregation means. Could you please clarify?\n\nhow are multiple language versions resolved if 2 targets in the same path have different settings\n\nI am not sure if intellij supports this? Is this a common enough scenario to support?\nI want to keep this change as small as possible to support the most common case. More features etc. can be added in later\n. Seems like part of this was addressed in 60058a4f32681808ce5776d9f8bbb348282b5633\nI will rebase this pr and include only the android sdk changes\n. Seems like part of this was addressed in 60058a4f32681808ce5776d9f8bbb348282b5633\nI will rebase this pr and include only the android sdk changes\n. @marcinkosiba I have rewritten this with your suggestions and isolated all logic to IjModuleFactory. Let me know if this approach looks ok and I will add tests to check all the scenarios.\n. @marcinkosiba I have rewritten this with your suggestions and isolated all logic to IjModuleFactory. Let me know if this approach looks ok and I will add tests to check all the scenarios.\n. Seems like the approach looks fine. So i will address comments from @marcinkosiba and add tests\n. Just did a quick rebase. will be adding tests tomorrow\n. Just did a quick rebase. will be adding tests tomorrow\n. I have not added tests yet. See my previous comment. I just did a quick rebase to resolve some merge conflicts. I will fix the line limit and test scenarios\n. @styurin please take a look\n. cc @marcinkosiba \n. @marcinkosiba added tests\n. @marcinkosiba added tests\n. @marcinkosiba the travis failure seems to be due to integration tests which this PR does not touch\n. @sdwilsh Can you please help merge this?\n. @sdwilsh the unit test is pretty much an integration test by itself, as the code path is fairly trivial.\nI updated the documentation as suggested. Will wait for @marcinkosiba to take a look\nThanks!\n. @marcinkosiba seems like this is not closed still\n. @marcinkosiba seems like this is not closed still\n. > @kageiit - travis correctly failed on line length limits. I'll fix it up for you this time, but please pay attention to the travis build in the future.\nAh sorry about that. The log was huge, I did not see it correctly. Thanks for fixing the line lengths\n. #892 will adresses this\n. Trying to fix travis build still. ant build works fine. buck build cannot find some imports\n. @Coneko any suggestion on the right buck file updates to keep the buck build happy?\n. e3c0eab - broken\nd5491b2969418c2ef3922318a60cf25ba8135682 - works\n. Git bisect points to 2910f2ecf78ca93d660114e7af90ab4639b7e067 as the first bad commit\n. @marcinkosiba can you see anything obvious from the bad commit?\n. I see. But nowhere in the documentation of buck it ever states that it is case sensitive/insensitive when it comes to configuration files. Maybe we can make that clear as well?\n. ah gotcha. That makes sense. This is probably a rare quirk. I would be ok if this was not fixed too. Because we have moved away from using ./buck and are using ./buckw instead as the wrapper script.\nBut I'll leave it up to you. I think we can mention this somewhere in the docs still especially for case sensitive file systems. All the docs talk about BUCK files and if someone is not aware of this behavior, it can lead to unpleasant surprises\n. Does this account for kapt support as well?\n. what version will be included? can that be configured via the kotlin library rule description?\n. The later :)\n. cc @marcinkosiba \n. This is happening rarely on our ci servers on a very large internal project. Its hard to reproduce on a small project\nThis is an example definition of the src_release rule\nandroid_library(\n    name = 'src_release',\n    srcs = glob([\n        'src/**/*.java',\n    ]),\n    manifest = 'build/okbuck/release/AndroidManifest.xml',\n    source = '7',\n    target = '7',\n    deps = [\n        '//.okbuck/cache:com.android.support.animated-vector-drawable-24.1.1.aar',\n        '//.okbuck/cache:com.android.support.appcompat-v7-24.1.1.aar',\n        '//.okbuck/cache:com.android.support.support-annotations-24.1.1.jar',\n        '//.okbuck/cache:com.android.support.support-v4-24.1.1.aar',\n        '//.okbuck/cache:com.android.support.support-vector-drawable-24.1.1.aar',\n        '//.okbuck/cache:com.google.code.gson.gson-2.6.2.jar',\n        '//.okbuck/cache:com.google.dagger.dagger-2.5.jar',\n        '//.okbuck/cache:javax.inject.javax.inject-1.jar',\n        '//libraries/common:res_main',\n        '//libraries/common:res_paidRelease',\n        '//libraries/common:src_paidRelease',\n        '//libraries/emptylibrary:res_release',\n        '//libraries/emptylibrary:src_release',\n        '//libraries/javalibrary:src_main',\n        '//libraries/parcelable:res_main',\n        '//libraries/parcelable:src_release',\n        ':build_config_release',\n        ':prebuilt_native_library_release_jniLibs',\n        ':res_another-app',\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n)\n. @aiked The issue is coming from a prebuilt jar. I don't see a similar option in prebuilt_jar\n. @aiked that's what we ended up doing, but it would be great to have an option in buck android binary rule for this so things can be excluded before they are packaged, similar to gradle.\n. @felipecsl you may want to keep trim_resource_ids = True to keep your primary dex minimal and so that you can lower your linear_alloc_hard_limit values. To do so, you need atleast a sha that includes #830 or higher in your .buckversion\n. @marcinkosiba There are no existing public facing docs for robolectric_test. Do you want us to add completely new ones?\n. @dreiss any update on this?. @dreiss any update on this?. @dreiss any update on the revert?. Sounds good. I will address your comment and add integration tests\n. @marcinkosiba the android_project_with_gradle_conventions integration test fixture covers this case already\n. @marcinkosiba the android_project_with_gradle_conventions integration test fixture covers this case already\n. @marcinkosiba I added a test for the default manifest path by deleting the manifest path from one of the test fixtures and letting it fallback to the value specified in buckconfig\n. @marcinkosiba I added a test for the default manifest path by deleting the manifest path from one of the test fixtures and letting it fallback to the value specified in buckconfig\n. @marcinkosiba @dreiss ping\n. keep.xmlis a larger change and could be done separately.\n. @marcinkosiba thanks for the heads up. The integration test did indeed catch a real error. I updated the code to make the test pass\n. Hmm I don't remember touching the unit tests in the last commit. Didn't look because they were green on travis\n. Hmm I don't remember touching the unit tests in the last commit. Didn't look because they were green on travis\n. Thanks for tagging @Coneko \n@ryandm @mikekap We have built a dependency resolution/importing mechanism and mapping to Buck build model using gradle in https://github.com/OkBuilds/OkBuck\nAs @mikekap mentioned, we chose this approach because the gradle dependency model declaration has all the features listed in the requirements. It also has resolution strategy hooks to do advanced dependency conflict management etc. And in general, this is already a solved problem by other systems for several years and we wanted to take advantage of whats already built rather than reinventing the wheel.\nThis was natural for us because the OkBuck gradle plugin converts java and android based projects to buck projects. The workflow with the Gradle Dependency Management and how it is mapped to Buck's model is as follows:\n- Dependencies are defined in build.gradle files in the dependencies block\n```\ndependencies {\n    compile fileTree(dir: 'libs', include: ['*.jar'])\n    compile(name:'rxscreenshotdetector-release', ext:'aar')\n    compile 'io.reactivex:rxjava:1.1.0'\n    compile ('io.reactivex:rxandroid:1.1.0') {\n        exclude module: 'rxjava'\n    }\n    compile 'com.tbruyelle.rxpermissions:rxpermissions:0.5.2@aar'\ncompile 'com.android.support:multidex:1.0.1'\ncompile 'com.jakewharton:butterknife:8.4.0'\napt 'com.jakewharton:butterknife-compiler:8.4.0'\n\n}\n```\nThe representation is very succinct and highly usable/readable.\n- A gradle task is run that resolves the various configurations and forces gradle do do its dependency resolution and downloading/caching the jars/aars and source jars to its local cache.\n- The final resolved versions of the dependencies are copied over into a project local dependency cache directory. The gradle task generates a BUCK file in the cache directory that maps all the artifacts and gives meaningful rule names of the prebuilt_jar and prebuilt_android_aar kind.\n  \n- These rules can now be used in other BUCK files as usual\ndeps = [\n        '//.okbuck/cache:com.android.support.animated-vector-drawable-24.1.1.aar',\n        '//.okbuck/cache:com.android.support.appcompat-v7-24.1.1.aar',\n        '//.okbuck/cache:com.android.support.support-annotations-24.1.1.jar',\n        '//.okbuck/cache:com.android.support.support-v4-24.1.1.aar',\n        '//.okbuck/cache:com.android.support.support-vector-drawable-24.1.1.aar',\n    ]\nWe have gone a step further and created a wrapper script around buck that detects when changes to build.gradle files are made and automatically invokes the dependency fetch and resolution mechanism before delegating the build/test commands back to buck again i.e something like\n```\nChange a dependency in build.gradle\n./buckw build target\nbuckw invokes the gradle task, then proceeds with buck\n```\nWe are able to do the wrapper script because OkBuck also automatically generates the BUCK files for all java/android gradle projects.\nBut I think for the purpose of dependency management itself, it would be very easy to utilize what we have built already in OkBuck using gradle and tweak it to serve additional needs if any.\n. All the features you listed like dependency jar caching are currently available in the gradle system (and probably also in maven). Gradle itself is wrapped in the wrapper which will download and install gradle if its not available, so its not really a hard dependency for the end user. It would all be behind the scenes\nWhats your rationale for not wanting to interact with third party build tool chains? I dont see any solid arguments against it, just that you want to reimplement it again in buck. This has greater chance of adding more risk for a small part of the system just used for dependency management.\nBuck relies on several third party tools already to power itself. How would this be any different?\n. All the features you listed like dependency jar caching are currently available in the gradle system (and probably also in maven). Gradle itself is wrapped in the wrapper which will download and install gradle if its not available, so its not really a hard dependency for the end user. It would all be behind the scenes\nWhats your rationale for not wanting to interact with third party build tool chains? I dont see any solid arguments against it, just that you want to reimplement it again in buck. This has greater chance of adding more risk for a small part of the system just used for dependency management.\nBuck relies on several third party tools already to power itself. How would this be any different?\n. Not handling transitive dependencies is a huge downside for any decent dependency management system. Gradle built their integrations on top of maven (all of these were written in java and are well maintained and have been stable for many years).\n\nFor other needs, like transitively download non Java artifacts, like say bower_components you would need yet another toolchain (Node, bower, ...).\n\nI do not see this as a downside at all. I would argue it is better that way because developers in any ecosystem using the tools would be most familiar with those tools already and would find it easy to adopt buck without having to learn/migrate to a new model for their dependency management. Also, this issue is purely dealing with java dependency management.\n\nmaven_jar(\n    name = 'foo',\n    artifact = 'bar:baz:qux-1.0',\n    sha1_bin = '42',\n    sha1_src = '43',\n    transitive = True # per default False, obviously\n  )\n\nThere is no need to actually define a build.gradle file to take advantage of gradle for this. The artifact rule you described above can be translated internally to a model gradle/maven understand and use their core logic to do the rest.\n\nOnce downloaded on my local machine (of course this should respect proxies to work in enterprise environment) the artifact should survive Buck upgrade, rm -rf buck-out and downloaded artifact should be re-used when the same projects is cloned multiple times on the same machine.\n\nThese are already well solved problems under all the constraints you just described and buck can benefit a lot by taking advantage of them.\n\nIs this too much to expect, that for the requirements above i would like not need to install, configure, not to mention interact (by that I mean edit) with any other build toolchains, like build.xml, pom.xml and build.gradle.\n\nAs I mentioned before, you do not need to. The mapping can be done internally, but then again you would need to learn about whatever way is supported at least once anyway. To drive adoption of buck in the real world among more developers, it is great to adhere to existing standards (unless they are completely broken), otherwise it just ends up being a closed system with a high cost to learn about and buy into to use buck.\n\n\nexcept handling transitive dependencies\n\nI think this makes it not very useful as it is almost similar to a vanilla buck fetch with some scripting to figure out where the jar/aar lives on maven central. Not to mention, it has no real logic to handle complex cases like excluding selective artifacts from transitive dependencies etc. the likes of maven/gradle support. When working in a non monorepo situation, these sort of features are absolutely necessary for projects that use dependency management\n. Not handling transitive dependencies is a huge downside for any decent dependency management system. Gradle built their integrations on top of maven (all of these were written in java and are well maintained and have been stable for many years).\n\nFor other needs, like transitively download non Java artifacts, like say bower_components you would need yet another toolchain (Node, bower, ...).\n\nI do not see this as a downside at all. I would argue it is better that way because developers in any ecosystem using the tools would be most familiar with those tools already and would find it easy to adopt buck without having to learn/migrate to a new model for their dependency management. Also, this issue is purely dealing with java dependency management.\n\nmaven_jar(\n    name = 'foo',\n    artifact = 'bar:baz:qux-1.0',\n    sha1_bin = '42',\n    sha1_src = '43',\n    transitive = True # per default False, obviously\n  )\n\nThere is no need to actually define a build.gradle file to take advantage of gradle for this. The artifact rule you described above can be translated internally to a model gradle/maven understand and use their core logic to do the rest.\n\nOnce downloaded on my local machine (of course this should respect proxies to work in enterprise environment) the artifact should survive Buck upgrade, rm -rf buck-out and downloaded artifact should be re-used when the same projects is cloned multiple times on the same machine.\n\nThese are already well solved problems under all the constraints you just described and buck can benefit a lot by taking advantage of them.\n\nIs this too much to expect, that for the requirements above i would like not need to install, configure, not to mention interact (by that I mean edit) with any other build toolchains, like build.xml, pom.xml and build.gradle.\n\nAs I mentioned before, you do not need to. The mapping can be done internally, but then again you would need to learn about whatever way is supported at least once anyway. To drive adoption of buck in the real world among more developers, it is great to adhere to existing standards (unless they are completely broken), otherwise it just ends up being a closed system with a high cost to learn about and buy into to use buck.\n\n\nexcept handling transitive dependencies\n\nI think this makes it not very useful as it is almost similar to a vanilla buck fetch with some scripting to figure out where the jar/aar lives on maven central. Not to mention, it has no real logic to handle complex cases like excluding selective artifacts from transitive dependencies etc. the likes of maven/gradle support. When working in a non monorepo situation, these sort of features are absolutely necessary for projects that use dependency management\n. Is the reason for this to retry flaky tests?\n. What if a flaky test passed on the first run? There would never be a way to detect a real failure in that case right?\n. So it only reruns the failing tests in a whole set of tests defined by a test rule?\nThat seems like a good option to have in general as well\n. Got it. so it only preserves results cache if all tests in the target passed. But would definitely be good to have a filter to run the failed tests from previous run without running every other test as well\n. @dsyang has some plans for android kotlin support in #857\nAdding them to ensure this is compatible\n. Try setting\ntrim_resource_ids = True in your binary rule. Try setting\ntrim_resource_ids = True in your binary rule. cc @JonShemitz @dreiss \n. cc @JonShemitz @dreiss \n. @Coneko why does this need revision? Can you please elaborate. The travis failure is not related to this change it is being addressed in #934 \n. We saw the same problem and had to turn the option off because it was causing flaky CI builds due to bad cache\n. Any update on this? the feature seems very useful to have\n. builds work fine, but we are seeing code coverage completely gone with track_class_usage set to true. We are going to disable it again. @justinmuller will post back repro steps and findings about this issue\n. builds work fine, but we are seeing code coverage completely gone with track_class_usage set to true. We are going to disable it again. @justinmuller will post back repro steps and findings about this issue\n. Source\n. Source\n. Git clone buck\nBuild with ant and run\nI'm not sure what pex is\n. This is buck running from source @Coneko \n. Have not tried this in a while. Nowadays I just run tests from intellij. Closing this for now. will reopen if needed. Have not tried this in a while. Nowadays I just run tests from intellij. Closing this for now. will reopen if needed. cc @dsyang \n. It seems like kapt3 in 1.0.6-eap77 ships with an APT_ONLY mode\nhttps://github.com/JetBrains/kotlin/blob/8afac55a908c80feb7dd7bf7105e0557d34cacce/plugins/kapt3/src/org/jetbrains/kotlin/kapt3/Kapt3Plugin.kt#L88\nhttps://github.com/JetBrains/kotlin/commit/95d12103171315bc2cb71d1a51a564234f0b5477\nThis means any build system can call kotlinc with this option and pass in kotlin source files to generate the java stubs required for the javac annoation processor round and compilation. It seems like kapt3 in 1.0.6-eap77 ships with an APT_ONLY mode\nhttps://github.com/JetBrains/kotlin/blob/8afac55a908c80feb7dd7bf7105e0557d34cacce/plugins/kapt3/src/org/jetbrains/kotlin/kapt3/Kapt3Plugin.kt#L88\nhttps://github.com/JetBrains/kotlin/commit/95d12103171315bc2cb71d1a51a564234f0b5477\nThis means any build system can call kotlinc with this option and pass in kotlin source files to generate the java stubs required for the javac annoation processor round and compilation. @davido #1019 might be useful in this regard\n. Yes. We have been using it internally. Just set the javac jar to the error prone javac jar (I used the one that ships with bazel) and set the compiler class name to the error prone compiler and it's good to go. Yes. We have been using it internally. Just set the javac jar to the error prone javac jar (I used the one that ships with bazel) and set the compiler class name to the error prone compiler and it's good to go. We compiled error prone from source ourselves. It's better that way because buck cannot anticipate what versions of javac and error prone can be shipped with it. But for out of box Integration of error prone into buck, I am not the right person to ask :). We compiled error prone from source ourselves. It's better that way because buck cannot anticipate what versions of javac and error prone can be shipped with it. But for out of box Integration of error prone into buck, I am not the right person to ask :). You have to use a project relative path. You cannot use an absolute path for the javac jar. You have to use a project relative path. You cannot use an absolute path for the javac jar. I would recommend checking in all jars into a module and make a java_binary out of it and make all rules that need error prone depend on it in the rules. I would recommend checking in all jars into a module and make a java_binary out of it and make all rules that need error prone depend on it in the rules. You can also use remote_file and make that a dependency of a Java binary and depend on it that way. Even if buck shipped with error prone, we would probably use our own built version for greater control. You can also use remote_file and make that a dependency of a Java binary and depend on it that way. Even if buck shipped with error prone, we would probably use our own built version for greater control. Building error prone from source let's us wrote our own error prone rules as well, which can be lot more than what the standard checks are. I won't mind if buck supported error prone out of the box, but given the custom compiler options, you can write your own bucklets as well to tie it all together nicely.. Building error prone from source let's us wrote our own error prone rules as well, which can be lot more than what the standard checks are. I won't mind if buck supported error prone out of the box, but given the custom compiler options, you can write your own bucklets as well to tie it all together nicely.. I think javac_jar only supports source paths in buckconfig, but the individual rules can support java build targets. using DEFS file might be a way to achieve that. I think if the usage is in .buckconfig, SourcePath is the only way to go as the target graph is not ready yet.\nAlso, why would the user need to update the path in multiple places?. I think if the usage is in .buckconfig, SourcePath is the only way to go as the target graph is not ready yet.\nAlso, why would the user need to update the path in multiple places?. R.txt is not mandatory if there are no resources\n. cc @yiding @sdwilsh \n. cc @yiding @sdwilsh \n. I took some macros with a lot of dependencies out and put in several hundred macros with no dependencies and the genrule ran fine. I was also able to make it run fine by adding several hundred lines with no location macros to the genrule. Very perplexing\n. I took some macros with a lot of dependencies out and put in several hundred macros with no dependencies and the genrule ran fine. I was also able to make it run fine by adding several hundred lines with no location macros to the genrule. Very perplexing\n. Seems like this was fixed. Thanks a lot @yiding \n. Can we add tools.jar to the bootclasspath as well @dreiss \n. android.jar is already in the boot class path, but it does not have the required classes.\nThe retrolambda gradle plugin also adds rt.jar to compile class path for it to work correctly.\nhttps://github.com/evant/gradle-retrolambda/blob/37b4418274553022b540084f139d1983454ac556/gradle-retrolambda/src/main/groovy/me/tatarka/RetrolambdaPluginAndroid.groovy#L78\n. Will revisit this some other time then. Thanks!\n. Will revisit this some other time then. Thanks!\n. @dreiss where should we start looking to make changes for this option? Any pointers would be helpful\n. Looks good. But please be aware that a lot of users of buck now use the okbuck gradle plugin for their builds. When they hook into buckw which wraps running the gradle okbuck task before running buck (only if needed), the output from the buck binary set in the ide preferences will have output different from vanilla buck.\nAs long as the plugin looks for key text on all output lines, it should be okay.\n. New bus event would be the best solution and won't break the ide if the message changes in future buck updates.\nThere are still a few points in the plugin that seem to rely on text out put like progress printing etc. If we make bus events, we will have the best customizability and can make new ide plugin features do the same to talk to buck.\n. Needing a dependency that is not documented in the docs can be confusing, especially when there are alternatives available with already required dependencies\n. ManifestMerger2 also has a lot of improvements we contributed to aosp, most notably the fix to remove duplication of library manifest loading https://code.google.com/p/android/issues/detail?id=222034#c7\nExcited to see this change in buck finally\n. ManifestMerger2 also has a lot of improvements we contributed to aosp, most notably the fix to remove duplication of library manifest loading https://code.google.com/p/android/issues/detail?id=222034#c7\nExcited to see this change in buck finally\n. Any update on this?. Any update on this?. > What's the failure?\nI think the issue here is that even if READ_EXTERNAL_STORAGE is already present elsewhere, it is being re-added as android: READ_EXTERNAL_STORAGE from @dreiss 's comment. > What's the failure?\nI think the issue here is that even if READ_EXTERNAL_STORAGE is already present elsewhere, it is being re-added as android: READ_EXTERNAL_STORAGE from @dreiss 's comment. All the apps in the wild using gradle have been on manifest merger 2 for many months now. If there was indeed something to worry about at runtime, it would have been quite obvious :)\nYou could also sanity test the apk produced by the new merger if needed. All the apps in the wild using gradle have been on manifest merger 2 for many months now. If there was indeed something to worry about at runtime, it would have been quite obvious :)\nYou could also sanity test the apk produced by the new merger if needed. Subclass should work fine. Happy to add tests, if I can be pointed to where to add them\n. Happy to add tests, if I can be pointed to where to add them\n. Added tests and docs\n. @Coneko fixed the templates. Also tested locally by running ./docs/soy2html.sh and checking the output docs\nPlease take a look. Thanks. @Coneko fixed the templates. Also tested locally by running ./docs/soy2html.sh and checking the output docs\nPlease take a look. Thanks. @zhihuawensc I think for your purpose, it should be done as a postprocess_classes_command instead. Similar to how retrolambda works right now in okbuck. @zhihuawensc I think for your purpose, it should be done as a postprocess_classes_command instead. Similar to how retrolambda works right now in okbuck. @Coneko aspectj is more of a postprocess_classes_command similar to retrolambda. @Coneko aspectj is more of a postprocess_classes_command similar to retrolambda. cc @dreiss . cc @dreiss . > Is there any urgency to this?\nno urgency. Just wanted to put it up so we can build and test on fb's and external users' projects.. > Is there any urgency to this?\nno urgency. Just wanted to put it up so we can build and test on fb's and external users' projects.. > This looks fine. I want to take some time to make sure that changes in dx aren't going to interfere with any of our runtime optimizations (at FB)\nredex is used outside of fb already on apks (and their dex files) that are produced by this version of dx out in the wild already. I would be surprised if this regressed anything majorly :). > This looks fine. I want to take some time to make sure that changes in dx aren't going to interfere with any of our runtime optimizations (at FB)\nredex is used outside of fb already on apks (and their dex files) that are produced by this version of dx out in the wild already. I would be surprised if this regressed anything majorly :). Any update on this?. Any update on this?. > Oh, I found a problem: this spews the merge report onto the console. Any idea why that wasn't happening before?\nShould be fixed now. @dreiss if everything looks stable, can we please close this PR?. cc @dreiss . cc @dreiss . This is kinda related to how kapt works as well. kapt in the gradle plugin generates an abi jar of all the kotlin sources so javac annotation processing can run with that on the classpath.\nIt then runs kotlinc with the generated sources on the classpath so that kotlin code can actually refer to generated code from the javac annotation processor step.. This is kinda related to how kapt works as well. kapt in the gradle plugin generates an abi jar of all the kotlin sources so javac annotation processing can run with that on the classpath.\nIt then runs kotlinc with the generated sources on the classpath so that kotlin code can actually refer to generated code from the javac annotation processor step.. @brettwooldridge the use case you mentioned should be supported. Kotlin adds all java sources to the class path when compiling and then the kotlin classes are added to the javac class path. So cross cutting dependencies between java and kotlin source should be fully supported. This is already possible in gradle and you can verify the same. It is still sequential.\nWith the availability of kapt3 in kotlin compiler, there are additional steps before where kotlin generates the java stubs from kotlin classes required for javac annotation processing to work.. > Probably before this feature I will tackle autodeps support, which entails prying into kotlin-compiler.jar to get at the AST parser.\n@brettwooldridge https://github.com/JetBrains/uast might be useful for this task. It can provide a universal AST for both java and kotlin code. This parser is going to be used to migrate all the standard android lint checks into it very soon as well, so definitely worth considering.. @brettwooldridge can the daemon client not be run as part of the buck daemon? It seems weird to have a daemon separate from the one in buck which buck kill may still leave intact and can lead to weird non reproducible build artifacts.. Nice. I will test it out on our codebase. we have one big kotlin module right now that we can try this on.. Should i be changing anything in .buckconfig? like kotlin_home etc? Currently, kotlin jars etc. are checked in and buck is pointing to those. Sure. ill update with results. @brettwooldridge Compared the performance with external kotlinc vs the in memory one with the daemon. Its a big improvement ~3x even after removing buck-out. The kotlin daemon seems to be no longer active when i kill the buck daemon as expected.. @brettwooldridge Sorry forgot to report back. The latest changes look good. sounds great. Ill give it a try. Yep. Since we are already checking in these files, can we just provide an option to set a .buckconfig option to make the default javac the error prone compiler for end consumers of buck? This way they dont need to obtain an error prone javac jar themselves. > Done. The option is: java.error_prone_javac. Add it to your .buckconfig or pass instantly with buck build --config java.error_prone_javac=true foo and enjoy error prone checks.\nCan we make this option be configurable per target as well similar to javac_jar for java and android rules? Also needs docs. We found another performance regression on 2.0.16 in https://github.com/google/error-prone/issues/529\nBut there is a fix and its verified to bring compile times back to normal levels. We can still go ahead with 2.0.16 as the inbuilt version unless we hear back from error prone maintainers about the release date for the fix. Ok 2.0.17 is now released and we should be good to update to it\nhttps://search.maven.org/#artifactdetails%7Ccom.google.errorprone%7Cerror_prone_ant%7C2.0.17%7Cjar. the ant build works fine. Seems like the buck based build is broken. @jkeljo has been working on the abi generation part of code a lot lately. Might be related. Seems like asm supports v53 class files in later versions\nhttps://bugs.openjdk.java.net/browse/JDK-8151858\nMaybe needs an update to asm along with this change?. @tdrhq any updates?. Going to pull this in by tomorrow. Will report back. @tdrhq We are seeing an exception with the latest buck version\nTESTS PASSED\nFailed on step emma_report with an exception:\nbuck-out/bin/freight/freight-authentication/lib__src_release__classes does not exist\njava.lang.IllegalStateException: buck-out/bin/freight/freight-authentication/lib__src_release__classes does not exist\n    at com.google.common.base.Preconditions.checkState(Preconditions.java:444)\n    at com.facebook.buck.jvm.java.GenerateCodeCoverageReportStep.populateClassesDir(GenerateCodeCoverageReportStep.java:189)\n    at com.facebook.buck.jvm.java.GenerateCodeCoverageReportStep.execute(GenerateCodeCoverageReportStep.java:98)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:47)\n    at com.facebook.buck.cli.TestRunning.runTests(TestRunning.java:437)\n    at com.facebook.buck.cli.TestCommand.runTestsInternal(TestCommand.java:316)\n    at com.facebook.buck.cli.TestCommand.runWithoutHelp(TestCommand.java:580)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:205)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:91)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:1287)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:706)\n    at com.facebook.buck.cli.Main.main(Main.java:1884)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.facebook.buck.cli.bootstrapper.ClassLoaderBootstrapper.main(ClassLoaderBootstrapper.java:62). We have been seeing the same issue for a few months with instrumentation test apks. Changes to source never seem to be picked up.. cc @styurin @dreiss . cc @marcinkosiba @sdwilsh this is blocking us from updating to a newer version of buck. Can someone please comment or let us know where we can help?. cc @marcinkosiba @sdwilsh this is blocking us from updating to a newer version of buck. Can someone please comment or let us know where we can help?. Sure. I can run a bisect and report back. Sure. I can run a bisect and report back. Ok, I ran a git bisect and it pointed out to 4da74e2747c730fd9269709d8be4df6333503faa as the problematic commit. cc @illicitonion . This is still broken with a new error message\njava.lang.IllegalStateException://.okbuck/cache:com.android.support.support-core-ui-25.1.0.aar#aar_prebuilt_jar is flavored.\n    at com.google.common.base.Preconditions.checkState(Preconditions.java:518)\n    at com.facebook.buck.model.AbstractBuildTarget.checkUnflavored(AbstractBuildTarget.java:131)\n    at com.facebook.buck.model.BuildTarget.checkUnflavored(BuildTarget.java:1)\n    at com.facebook.buck.android.AndroidPrebuiltAarDescription.createPrebuiltJar(AndroidPrebuiltAarDescription.java:170)\n    at com.facebook.buck.android.AndroidPrebuiltAarDescription.createBuildRule(AndroidPrebuiltAarDescription.java:136)\n    at com.facebook.buck.android.AndroidPrebuiltAarDescription.createBuildRule(AndroidPrebuiltAarDescription.java:1)\n    at com.facebook.buck.rules.DefaultTargetNodeToBuildRuleTransformer.transform(DefaultTargetNodeToBuildRuleTransformer.java:50)\n    at com.facebook.buck.rules.BuildRuleResolver.requireRule(BuildRuleResolver.java:136)\n    at com.facebook.buck.rules.ActionGraphCache$1.visit(ActionGraphCache.java:166)\n    at com.facebook.buck.rules.ActionGraphCache$1.visit(ActionGraphCache.java:1)\n    at com.facebook.buck.graph.AbstractBottomUpTraversal.traverse(AbstractBottomUpTraversal.java:36)\n    at com.facebook.buck.rules.ActionGraphCache.createActionGraph(ActionGraphCache.java:172)\n    at com.facebook.buck.rules.ActionGraphCache.getActionGraph(ActionGraphCache.java:107)\n    at com.facebook.buck.cli.BuildCommand.createActionGraphAndResolver(BuildCommand.java:723)\n    at com.facebook.buck.cli.BuildCommand.createGraphs(BuildCommand.java:432)\n    at com.facebook.buck.cli.BuildCommand.run(BuildCommand.java:384)\n    at com.facebook.buck.cli.BuildCommand.runWithoutHelp(BuildCommand.java:353)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:210)\n    at com.facebook.buck.cli.ProjectCommand.runBuild(ProjectCommand.java:703)\n    at com.facebook.buck.cli.ProjectCommand.runBuild(ProjectCommand.java:690)\n    at com.facebook.buck.cli.ProjectCommand.runIntellijProjectGenerator(ProjectCommand.java:620)\n    at com.facebook.buck.cli.ProjectCommand.runIntellijProjectGenerator(ProjectCommand.java:789)\n    at com.facebook.buck.cli.ProjectCommand.runWithoutHelp(ProjectCommand.java:508)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:210)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:91)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:1319)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:729)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:2105)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:338). cc @illicitonion . Tagging @marcinkosiba as well since he seems to be knowledgeable about this part of the buck's codebase.. @marcinkosiba @dreiss or @Coneko can any of you please update on the status of this?. cc @dreiss @malbano. I will look into fixing the second part. The first as you explained can already happen in many other cases. I will look into fixing the second part. The first as you explained can already happen in many other cases. @dreiss I addressed your comments and rebased onto latest. @dreiss I addressed your comments and rebased onto latest. ah i forgot to run lint. lemme fix that :(. ah i forgot to run lint. lemme fix that :(. ok fixed and pushed. sry abt that. ok fixed and pushed. sry abt that. @dreiss Any issues with import I can help resolve?. @dreiss this file seems to get more conflicts the longer its not merged. Any update on whats holding back the merge?. it maybe worthwhile to ignore the failing tests and follow up with a fix so that it can unblock contributions to buck and remove false negatives on PRs. cc @dsyang . cc @dsyang . Ill fix the tests and re-upload. ant tests passed for me. Need to look at the buck build path. Ill fix the tests and re-upload. ant tests passed for me. Need to look at the buck build path. @dsyang rebased on latest and force pushed. @dsyang rebased on latest and force pushed. @dsyang any update on the import?. @dsyang any update on the import?. cc @dreiss . cc @dreiss . @dreiss thanks for the info. Going to close this. Seems like the problem is something else. @dreiss thanks for the info. Going to close this. Seems like the problem is something else. Can cxx_library be used with cmake?. Thanks for clarifying!. We currently use a tool after the tests are run to perform the conversion - https://github.com/uber/okbuck/tree/master/tools/junit\nBut im planning to open a change to buck to enable outputting junit xml directly. cc @dreiss @dsyang . cc @dreiss @coneko @davido @cushon. cc @dreiss @coneko @davido @cushon. @jkeljo \nIt works if everything is documented and visible. Currently I had no idea anything of that sorts existed. Can you point me at more documentation around this so we can explore the approach you suggested?. @jkeljo \nIt works if everything is documented and visible. Currently I had no idea anything of that sorts existed. Can you point me at more documentation around this so we can explore the approach you suggested?. @jkeljo taking a cusrory look at the code, the existing java_annotation_processor rule will not work for this use case as it requires the processorClass argument as non optional. https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/JavaAnnotationProcessorDescription.java#L81\nError prone checkers do not have an annotation processor class but still need to show up on the processor path. @jkeljo taking a cusrory look at the code, the existing java_annotation_processor rule will not work for this use case as it requires the processorClass argument as non optional. https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/JavaAnnotationProcessorDescription.java#L81\nError prone checkers do not have an annotation processor class but still need to show up on the processor path. This happens even after git clean -fdx; ant inside the buck codebase.\nRunning killall java; watchman watch-del-all seem to make it work sometimes (i.e killing off any old buck daemons). cc @dreiss . These are actually on linux. We increased the limit to more than the default i.e 8192 to a much higher value. We are able to get by, but have not had time to look into whats causing the issue yet. We are planning to profile this soon and will respond back with info. cc @msridhar. @jkeljo any update on this? We are getting around this by removing the assertion and only logging non null events.. cc @styurin @dreiss . Its rebased. Maybe @dreiss ? :). @guhan121 Another solution would be to use the same aar for both places as well. cc @dreiss . There is actually only a single location for the class being added and that is a prebuilt_jar . We do not have support library in source. cc @styurin . @styurin reran everything through google java format and added an integration test. Rebased to remove conflict. cc @dreiss @styurin . cc @styurin without the executable flag, the commit would exit silently and not format anything. Any update on this? This still is causing instability on our CI builds. Any idea what else we can do to debug this?. Need to tweak one more place to decouple NO_LOCALS from the package type in dexing. Ok fixed the last place around dexing as well. @bertmaher This should be good to go for import now :). @bertmaher any update on this? :). @bertmaher any update on this? :). @bertmaher Fixed the unused field usage. Ran ant lint to confirm no more issues. @bertmaher Fixed the unused field usage. Ran ant lint to confirm no more issues. I could have sworn ant worked for me locally. I'll try to build clean this time :|. I could have sworn ant worked for me locally. I'll try to build clean this time :|. Ok ant clean default works now. @bertmaher . Ok ant clean default works now. @bertmaher . @bertmaher any update on this?. > Hey @kageiit, as I was fixing up some of our targets I noticed that this diff makes android_sdk_proguard_config default to \"none\" instead of \"default\". I hadn't thought through the implications until I got bit by it, and I'm worried about other OSS users suddenly getting sub-optimal or wrong results by not using the default PG options. What do you think? Would it be reasonable to leave \"default\" alone, but allow a target to disable PG by explicitly setting it to \"none?\nHmm that seems fine, but the current checks for shouldProguard will not work then. If the default is always going to be the standard android sdk rules, how do we know if the binary needs to be proguarded or not? It would require another flag like proguard = True which makes it a weirder api. > Hey @kageiit, as I was fixing up some of our targets I noticed that this diff makes android_sdk_proguard_config default to \"none\" instead of \"default\". I hadn't thought through the implications until I got bit by it, and I'm worried about other OSS users suddenly getting sub-optimal or wrong results by not using the default PG options. What do you think? Would it be reasonable to leave \"default\" alone, but allow a target to disable PG by explicitly setting it to \"none?\nHmm that seems fine, but the current checks for shouldProguard will not work then. If the default is always going to be the standard android sdk rules, how do we know if the binary needs to be proguarded or not? It would require another flag like proguard = True which makes it a weirder api. Im going to take a look at adding D8 support into buck this weekend and report back.. Yep. cc @jkeljo @styurin . Can we not do the same thing as we do with merging duplicates in the transitive classpath i.e post order traversal?. Can we not do the same thing as we do with merging duplicates in the transitive classpath i.e post order traversal?. I am not sure the order matters or not however. I am not sure the order matters or not however. @dreiss rebased with all your offline comments and added integration tests. Please take a look. @dreiss rebased with all your offline comments and added integration tests. Please take a look. @alonlevih There already exists a keep_resource_pattern option in android binary for this.\nI would recommend looking at the source code AndroidBinaryDescription directly next time since all options are not documented. In fact, we use the same approach to keep resources we load using reflection to get around this issue and enable resource trimming.. @alonlevih There already exists a keep_resource_pattern option in android binary for this.\nI would recommend looking at the source code AndroidBinaryDescription directly next time since all options are not documented. In fact, we use the same approach to keep resources we load using reflection to get around this issue and enable resource trimming.. cc @jkeljo . @jkeljo I addressed your comments and added more test cases. @cwoodwar6 you have access to buckw so you can intercept the args and add in extra ones like the config file transparently under the hood.\nThis is what we do for folks invoking ./buckw project. We intercept the args and ensure they are not projecting on the entire workspace and we also add some extra flags to speed it up for example. buck allows you to set arbitrary labels on any build rules\nYou can use custom DEFS to add a android-26 label onto the targets that require the new sdk, then use buck query to filter out those targets\nThen on ci, you can run two test commands with different arguments. One for 26 and one for the rest. @jkeljo scala/groovy rules might need the same treatment. > should this be a configuration option in .buckconfig instead of an attribute of the java_library?\nI am open to making it an option in .buckconfig. I felt doing it per target was more flexible. Let me know if you feel otherwise and I can change it. @ttsugriy I added tests and rebased. We have fec4a62 in our version and do not see this issue. strange\nCan you check the buck log to see why the test apk build failed?. We have fec4a62 in our version and do not see this issue. strange\nCan you check the buck log to see why the test apk build failed?. we build all apk targets in the travis config before the ui test command is run. It is strange that buck errors out like that.\nWe do not rely on buck to run ui test commands, but have our own wrapper, that is probably why we did not see this particular error.. we build all apk targets in the travis config before the ui test command is run. It is strange that buck errors out like that.\nWe do not rely on buck to run ui test commands, but have our own wrapper, that is probably why we did not see this particular error.. @cjhopman Does https://github.com/facebook/buck/commit/cfdefd2185c9e2a84b75953ee965e8d9e4123d70 fix this?. Thanks @yiding we will stage this change for a week and report back. Yep we enabled it as well without any issues. Thanks!. Yep we enabled it as well without any issues. Thanks!. cc @jkeljo seems like kotlin has the similar issues to kotlin. > ok, I gave up and reverted to using plain for loop instead of parameterized tests :( With JUnit5 it would be so much nicer... Sigh...\nouch. sorry to hear. Thanks for working around it though. We encountered a similar issue when trying to add support for thrift in go. We would like to have a genrule generate a sources zip that a go library can then depend on. This is supported by the java and python library rules today already. cc @mkaczanowski. 552c0b0b98ff9bf2d7c8753dc91ec3ec8eb48910 fixes this and made it possible to use stock aapt2 from the sdk build tools folder seamlessly.. We are not using it. We wanted to at some point but the implementation seemed very fb specific so we didn't end up pursuing it. Thanks for the heads up!. cc @jkeljo . @jkeljo have you had a chance to look at this?. We have integration tests already for groovy rules. Fix is up in https://github.com/facebook/buck/pull/1571\nNot sure what the test was missing exactly. Fixed formatting. Ill try to repro on the okbuck codebase. I have a feeling it could be a flaky issue though. Ill update soon. Does the stack trace help in any way in the meantime?. Got a repro\nClone\nhttps://github.com/uber/okbuck\nRun\n./gradlew :okbuck -Dokbuck.wrapper=true; buck build //libraries/groovylibrary:test_main\nSee the error\n[2017-10-10 11:37:23.306][error][command:null][tid:16][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.lang.IllegalStateException: Multiple rules created for target '//libraries/groovylibrary:test_main':\nnew rule '//libraries/groovylibrary:test_main' does not match existing rule '//libraries/groovylibrary:test_main'.\n    at com.google.common.base.Preconditions.checkState(Preconditions.java:738)\n    at com.facebook.buck.rules.SingleThreadedBuildRuleResolver.computeIfAbsent(SingleThreadedBuildRuleResolver.java:92)\n    at com.facebook.buck.rules.SingleThreadedBuildRuleResolver.requireRule(SingleThreadedBuildRuleResolver.java:107)\n    at com.facebook.buck.rules.ActionGraphCache$2.visit(ActionGraphCache.java:291)\n    at com.facebook.buck.rules.ActionGraphCache$2.visit(ActionGraphCache.java:1)\n    at com.facebook.buck.graph.AbstractBottomUpTraversal.traverse(AbstractBottomUpTraversal.java:36)\n    at com.facebook.buck.rules.ActionGraphCache.createActionGraphSerially(ActionGraphCache.java:293)\n    at com.facebook.buck.rules.ActionGraphCache.createActionGraph(ActionGraphCache.java:226)\n    at com.facebook.buck.rules.ActionGraphCache.getActionGraph(ActionGraphCache.java:129)\n    at com.facebook.buck.rules.ActionGraphCache.getActionGraph(ActionGraphCache.java:66)\n    at com.facebook.buck.cli.BuildCommand.createActionGraphAndResolver(BuildCommand.java:920)\n    at com.facebook.buck.cli.BuildCommand.createGraphs(BuildCommand.java:453)\n    at com.facebook.buck.cli.BuildCommand.executeBuildAndProcessResult(BuildCommand.java:521)\n    at com.facebook.buck.cli.BuildCommand.run(BuildCommand.java:412)\n    at com.facebook.buck.cli.BuildCommand.runWithoutHelp(BuildCommand.java:379)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:232)\n    at com.facebook.buck.cli.AbstractContainerCommand.run(AbstractContainerCommand.java:79)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:79)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:1065)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:386)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1825)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:329). cc @yiding . > There's a known issue about running ButterKnife with kotlinc in-process config\n@thalescm I dont think we should make kapt run out of process because of some issue with a thrid party library. That issue should be fixed by the library maintainers. Running out of process incurs significant overhead for process creation and not being able to take advantage of JIT.. Is it not possible to fix butter knife to deal with this? It seems like a problem with the library than the tool and it should be solved in the right place.. I wrote the original logic in butterknife that uses the sun trees api to make it support library projects. It should be possible to fix the issue in butterknife to use the available trees class that is. I think the fix should reside in butterknife as an out of process compiler does not make sense and can complicate the implementation of kept in buck more.. I will try on a few other machines and report back. Local file was using oracle jdk on a mac and ci was using openjdk on linux just to make sure you were testing with the same environment. You can use javac arguments to pass in apt options like -Aobjectbox.modelPath=... to javac so its already supported. I would advise not to pass in absolute paths, but use project root relative paths instead as it keeps your cache keys the same across multiple machines. cc @msridhar to check if it affects any of our genrules. Alternatively, one can apply this patch to buck to have buck project respect source roots correctly without having to post process. Its a similar approach, but happens inside the project command itself\nhttps://gist.github.com/kageiit/4e48964cb6d9382737b96c21e1adf730. cc @cdeange @cwoodwar6 ^. cc @hzsweers @cwoodwar6 @artem-zinnatullin . > Did you not need to handle the annotation processing jar?\nIts not required for compilation. kapt support is being handled separately by @cwoodwar6 's kapt PR that will attach the jar as a compiler argument instead. > The reason I ask is because our internal build failed due to okbuck trying\n\nto download it, so I wasn't sure where in the pipeline that was happening\n\nThats handled separately in https://github.com/uber/okbuck/commit/00b96385c4879cace766894d20820866cc74d182. cc @styurin @dreiss . will confirm and close this if its already working. @dreiss is right. They proguard files from aars do get included in the final obfuscation step.. cc @styurin @cjhopman . Seems like this change broke the original behavior - https://github.com/facebook/buck/commit/b1f3f9fbee92e90cf62293d13e2a4bd3ade7f874#diff-0eac0fc574859fa0c2ad0c8e59b9c1da. We were able to workaround this by always using export_file in reference mode. But this behavior is still a change and should probably be documented/fixed for other use cases. Having some tests should be good to ensure future behavior changes are not done uncaught.. cc @edsilfer. cc @dreiss . cc @styurin . @jkeljo @dreiss Ping :). @dreiss hoping to get another fix in - https://issuetracker.google.com/issues/70348575\nif we can wait a bit. Seems like this merged. Will open another PR for the fix from  https://issuetracker.google.com/issues/70348575. cc @styurin . @Nickersoft the remote file url seems incorrect\naccording to https://buckbuild.com/rule/remote_file.html , you need a mvn: prefix before your maven coordinates. cc @styurin @jkeljo @dreiss @robbertvanginkel @rmaz. Sure. @michaeleiselsc if its important for your team to synchronize buckversions, you should consider moving to prebuilt buck binaries instead. Buck publishes releases on github now, you can also fetch buck built at any git sha from jitpack like https://jitpack.io/com/github/facebook/buck/<buck-repo-git-sha>/buck-<buck-repo-git-sha>.pex\nThe logic to download buck should be administered via a wrapper script ( example ). The logic was removed from buck originially as it adds overhead to always check the buck version against the git in the source copy.. cc @dreiss @styurin . Done. Ping! is this blocked on something? :). @styurin Ping :). @styurin updated. Time to run proguard on buck? :). Need to also update build.xml. Any reason why this was reverted in https://github.com/facebook/buck/commit/3364a82d144a8e48a136747a717b8c7ee7eb61d1 ?. cc @jkeljo @ttsugriy @msridhar . This happens with the jdk 9 javac as well (which seems to be the root cause since error prone relies on it). If track_class_usage is set to false, the error message becomes\n2018-03-16 12:44:18,054 [WARNING][buck_tool.py:391] Not using buckd because NO_BUCKD is set.\nBuck encountered an internal error\njava.nio.file.NoSuchFileException: /Users/kage/Desktop/repro/buck-out/gen/lib__bar_legacy_ap#source-abi__output/bar_legacy_ap-abi.jar. Finally got to the bottom of this. The trace file is inundated with javac phase events (parse/enter/analyze) etc. This is causing the exponential blow up of the trace file size. We have 2.5k java files in a single android_library target and compiling it alone (all dependencies available in cache) causes a 4.07 Gb trace file.\nI commented out method bodies of\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/JavacEventSinkToBuckEventBusBridge.java#L97\nand \nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/JavacEventSinkToBuckEventBusBridge.java#L110\nRan the build again, and the size of the trace file is 4.7 Mb. Seems like javac phase event reporting is causing a 3 orders of magnitude size increase in the amount of logs written to disk. I think it would be best to disable this behavior by default and let users configure turning it on if needed.\nI tried this with both the errorprone javac and the vanilla jdk 8 javac with same results, so the choice of compiler does not seem to matter.\ncc @jkeljo @styurin @ttsugriy . The hang does not seem to be because of nailgun. I traced the buck daemon with truss and it seems to be stat'ing tons of files in the dir artifact cache. Looking at the config, the machine seemed to have reached the limit at which it tries to cleanup\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/artifact_cache/DirArtifactCache.java#L62\nbut it is unable to do so since the cleanup has a very short timeout and the operation never completes\nThis seems to be related to #803\n. Running the build command with ./buckw build foo --config cache.mode=\"\" got rid of the problem, but this should be handled more gracefully by buck. It should atleast print some log that disk log cleanup is happening. After attaching the debugger, the buck jvm goes to https://github.com/facebook/buck/blob/3730801723060665c4cb766bc24aa206251949fc/src/com/facebook/buck/util/DirectoryCleaner.java#L52\nBut never enters the loop. @sbalabanov do folks at FB not use the disk cache?\n\"A quickfix solution may be to totally purge dir cache folder and limit it's size.\" Is not something that can be easily rolled out across all dev laptops without friction.\nCan someone point us in the right direction where we can add the post-command workflows? We would be happy to make a PR\ncc @styurin . I was thinking of making a new executor service that buck does not have to wait on. Can we have this be a short term solution? The long term solution being on the buck team's plan does not look like something that can be easily PR'ed given what other constraints it might satisfy. We should be able to not let consumers of buck bear this slowdown till the longterm solution is in place.\nGiven its just one additional thread, it seems like a good short term solution that can be cleaned up later. Thoughts?. @styurin any update on this?. @styurin Ping :). @styurin any updates on landing this PR?. cc @sbalabanov . @sbalabanov Can you suggest a good place to close the service? We do not want to wait/block on it either. @sbalabanov Updated. Please take a look. @sbalabanov Ping\ncc @styurin . This gives a clue - https://github.com/facebook/buck/blob/master/src/com/facebook/buck/step/AbstractTestStep.java#L71\nSeems like the output is redirected to a file. This gives a clue - https://github.com/facebook/buck/blob/master/src/com/facebook/buck/step/AbstractTestStep.java#L71\nSeems like the output is redirected to a file. Does this also fix #1890 potentially?. https://github.com/facebook/buck/pull/1889#discussion_r190300732 should fix the issue. @styurin any update on the import?. @styurin any update on the import?. cc @thalescm will make a pr to fix this issue. cc @thalescm to make sure its still on his radar :). cc @thalescm to make sure its still on his radar :). Sure. Let me add a readme. @styurin any update on merging this pr?. @styurin I have updated the pr. kotlin-metadata-jvm is no longer required. Can you please re-import?. This is a problem in okbuck. Fixed by https://github.com/uber/okbuck/pull/684 . Feel free to close this. cc @styurin @ttsugriy . cc @styurin @ttsugriy . Thanks for confirming!. Thanks for confirming!. cc @styurin . What would happen to\n[buildfile]\n  includes = //foo/DEFS\nin .buckconfig\nHopefully that will still continue to function. cc @romanoid @raviagarwal7 . I understand about skylark. But if a project is still using polyglot parsing and is in the process of migration, its important that the functionality of buildfile.includes still works. You can add stuff to rulekey dynamically like so\nhttps://github.com/facebook/buck/blob/419c18025998e57d3a1e89c7ff19d90d29d1f00c/src/com/facebook/buck/rules/coercer/AbstractManifestEntries.java#L53. cc @styurin . @ttsugriy tests added :). also cc @asp2insp . The regression was due to this line https://github.com/facebook/buck/commit/8c331339d4484f90c8888db175af805887a01015#diff-86807c89dcffcbdf9fd7f5307183325aR204\nPrimary dex scenario file we specified was being added to by additional implicit patterns in buck. We had 900 more R classes added to the primary dex than before which ended up overflowing the main dex. Fixed in 6bb508bd20e494cd3173dc6d968ffe9e90381803. cc @styurin @asp2insp @dreiss . Fixed in interal PR. Thanks @asp2insp !. cc @styurin . > please add a test to verify that this functionality actually works :)\n@ttsugriy There are no existing tests for doctor that check the validity of args/headers/request format. Whats the best way to test this, given its mostly looking like a smoke test?. @ttsugriy added integration tests. cc @styurin @asp2insp . cc @styurin @asp2insp . @styurin done. @styurin done. cc @raviagarwal7 @romanoid . cc @raviagarwal7 @romanoid . cc @linzhp. cc @styurin @raviagarwal7 . cc @styurin @raviagarwal7 . There are no docs for this in prebuilt_jar either. Didn't know if this is supposed to be made publicly available with docs yet.. There are no docs for this in prebuilt_jar either. Didn't know if this is supposed to be made publicly available with docs yet.. cc @cwoodwar6 @thalescm . cc @cwoodwar6 @thalescm . Yep. going to fix builds and add tests. @styurin added tests and rebased. Test failures seem unrelated. @styurin rebased and resolved conflicts. Thanks!. @styurin rebased and resolved conflicts. Thanks!. @styurin rebased once more. Can we please merge? :). @styurin rebased once more. Can we please merge? :). upgrade asm in buck @zmanji ?. Seems like the upgrade merged - https://github.com/facebook/buck/commit/aad4ab401838290cea29b123eb237ef144ef0c4e\nThanks @jtorkkola !. cc @styurin . @styurin ping :). cc @ttsugriy @styurin . We would actually like to commit that file to source control for things like project specific buck binary aliases (we typically have a buck wrapper at project root that we would like to configure). cc @styurin . cc @styurin ping! :). This is completely broken by https://github.com/facebook/buck/commit/afdf9be370c9cae6fa94c1231395de10c8d77696\ncc @styurin @jtorkkola Can you please suggest an alternative?. > Can you prune the jars before passing them into ApkBuilder, i.e. do essentially what SignedJarBuilder::writeZip does? I understand there'd be a performance hit with that approach, but we'd really like to remove as much of our AOSP fork as possible.\n@jtorkkola That is not an option. That will require things like buck project to build all the pruned jar rules for IDE to work correctly. We also need to rewrite aar files which is more complex than jars. This seems like something buck should support tbh since the android gradle plugin already does. Im ok with not forking AOSP and open to suggestions of doing it in buck earlier than calling into  ApkBuilder. There are also several bits that buck forks from aosp - dx, d8 etc. I am not sure moving them to aosp forks will be easy due to how buck is architected. This kind of pruning is mostly useful for release builds only. I think another option would be to do this as a post_process step after proguard etc. have run. I was going to hook in the android resource shrinker there to remove unused resources from the .ap_ file (similar to what redex does, but those bits are not opensource). I will try to see if this can be hooked in there instead . @asp2insp this does not seem correct. prebuilt_jar does not have this behavior and it supports correctly packaging transitive deps and creating poms when running buck publish. android_aar should do the same (so its not WAI). I believe there is some work to make android_aar behave the same as prebuilt_jar for publishing. Ideally for fb's needs, there should be a separate option/rule to make the aar fat. I think only FB builds fat aars by default :)\nBut a flag would be the best option and we can force it to false for anyone using okbuck so that becomes the default. cc @thalescm. @sbalabanov @ttsugriy I intend to upstream a pr for this. Let me know if this looks ok\ncc @msridhar @romanoid  FYI. This is still happening as of https://github.com/facebook/buck/commit/ea8add2016df57ff22cfc4c79647e63a6d7806a9\ncc @mkillianey . @styurin @sbalabanov any update on this?. > looks like you forgot to update paths to source jars which is why travisci is broken\ngood catch! updated @ttsugriy . @jtorkkola are the abi issues specific to source-only abi mode?. @dulmandakh you can also use https://github.com/facebook/buck#prebuilt-buck-binaries. cc @mkillianey. cc @christolliday Could you please import this as well? This is required for android layout preview support. cc @styurin @msridhar. Can you please also change the title to explicitly state \"Enable static and interface method desugaring with D8\" ? Lambda desugaring is already supported and it is much clearer to avoid confusion.. In our codebase, we have every single target building with java 8 currently. We would be happy to test this PR out once you have made the changes. What we need to ensure is that whatever changes are made here work not only for FB but also for OSS users of buck. I would advise some caution and let users configure via a .buckconfig and java_library/android_library flag to turn off interface method desugaring if they face any problems regardless of if they are using Java 8 or not. > AndroidPlatformTarget\nAndroidPlatformTarget may not apply to pure java libraries right? It would be a weird import to have in such cases. Im running this on our ci now and will report back on how it goes. Seeing an error in running d8 on a library\ncom.android.tools.r8.CompilationFailedException: Compilation failed to complete\n    at com.android.tools.r8.utils.ExceptionUtils.withCompilationHandler(ExceptionUtils.java:72)\n    at com.android.tools.r8.utils.ExceptionUtils.withD8CompilationHandler(ExceptionUtils.java:43)\n    at com.android.tools.r8.D8.run(D8.java:73)\n    at com.facebook.buck.android.DxStep.executeInProcess(DxStep.java:350)\n    at com.facebook.buck.android.DxStep.execute(DxStep.java:303)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:45)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.executeCommands(CachingBuildRuleBuilder.java:1362)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.executeCommandsNowThatDepsAreBuilt(CachingBuildRuleBuilder.java:1330)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.runWithExecutor(CachingBuildRuleBuilder.java:1289)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.run(CachingBuildRuleBuilder.java:1278)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$2.runWithDefaultExecutor(CachingBuildRuleBuilder.java:811)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submit$2(WeightedListeningExecutorService.java:100)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submitWithSemaphore$0(WeightedListeningExecutorService.java:74)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:206)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:195)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:115)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:999)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\nCaused by: com.android.tools.r8.utils.AbortException: Error: Classpath type already present: com.squareup.leakcanary.AndroidExcludedRefs\n    at com.android.tools.r8.utils.Reporter.failIfPendingErrors(Reporter.java:101)\n    at com.android.tools.r8.utils.Reporter.fatalError(Reporter.java:72)\n    at com.android.tools.r8.utils.ExceptionUtils.withCompilationHandler(ExceptionUtils.java:64)\n    ... 19 more\ncom.android.tools.r8.CompilationFailedException: Compilation failed to complete\n    at com.android.tools.r8.utils.ExceptionUtils.withCompilationHandler(ExceptionUtils.java:72)\n    at com.android.tools.r8.utils.ExceptionUtils.withD8CompilationHandler(ExceptionUtils.java:43)\n    at com.android.tools.r8.D8.run(D8.java:73)\n    at com.facebook.buck.android.DxStep.executeInProcess(DxStep.java:350)\n    at com.facebook.buck.android.DxStep.execute(DxStep.java:303)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:45)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.executeCommands(CachingBuildRuleBuilder.java:1362)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.executeCommandsNowThatDepsAreBuilt(CachingBuildRuleBuilder.java:1330)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.runWithExecutor(CachingBuildRuleBuilder.java:1289)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.run(CachingBuildRuleBuilder.java:1278)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$2.runWithDefaultExecutor(CachingBuildRuleBuilder.java:811)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submit$2(WeightedListeningExecutorService.java:100)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submitWithSemaphore$0(WeightedListeningExecutorService.java:74)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:206)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:195)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:115)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:999)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\nCaused by: com.android.tools.r8.utils.AbortException: Error: Classpath type already present: android.support.v4.view.animation.PathInterpolatorCompat\n    at com.android.tools.r8.utils.Reporter.failIfPendingErrors(Reporter.java:101)\n    at com.android.tools.r8.utils.Reporter.fatalError(Reporter.java:72)\n    at com.android.tools.r8.utils.ExceptionUtils.withCompilationHandler(ExceptionUtils.java:64)\n    ... 19 more\ncom.android.tools.r8.CompilationFailedException: Compilation failed to complete\n    at com.android.tools.r8.utils.ExceptionUtils.withCompilationHandler(ExceptionUtils.java:72)\n    at com.android.tools.r8.utils.ExceptionUtils.withD8CompilationHandler(ExceptionUtils.java:43)\n    at com.android.tools.r8.D8.run(D8.java:73)\n    at com.facebook.buck.android.DxStep.executeInProcess(DxStep.java:350)\n    at com.facebook.buck.android.DxStep.execute(DxStep.java:303)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:45)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.executeCommands(CachingBuildRuleBuilder.java:1362)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.executeCommandsNowThatDepsAreBuilt(CachingBuildRuleBuilder.java:1330)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.runWithExecutor(CachingBuildRuleBuilder.java:1289)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$BuildRuleSteps.run(CachingBuildRuleBuilder.java:1278)\n    at com.facebook.buck.core.build.engine.impl.CachingBuildRuleBuilder$2.runWithDefaultExecutor(CachingBuildRuleBuilder.java:811)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submit$2(WeightedListeningExecutorService.java:100)\n    at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submitWithSemaphore$0(WeightedListeningExecutorService.java:74)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:206)\n    at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:195)\n    at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:115)\n    at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:999)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\nCaused by: com.android.tools.r8.utils.AbortException: Error: Classpath type already present: android.support.v4.util.Pair\n    at com.android.tools.r8.utils.Reporter.failIfPendingErrors(Reporter.java:101)\n    at com.android.tools.r8.utils.Reporter.fatalError(Reporter.java:72)\n    at com.android.tools.r8.utils.ExceptionUtils.withCompilationHandler(ExceptionUtils.java:64)\n    ... 19 more\nSeems like types are being included twice on the classpath? Will dig to see where the duplication is coming from. > Looks like your error is a bit different case because it complains about android.support.v4 classes. Is it possible that you are including multiple copies of support library? DxStep uses set function so the jar paths should be unique.\nWe only have a single aar. I verified by checking that there was only one instance of that class inside buck-out's processed classes.txt files for every aar. Testing the latest changes again. Builds of all our apps succeeded. Going to run automated ui tests to ensure they still work as expected :P . > Don't forget to include java.desugar_interface_methods=true. Just double checking.\nYes ofcourse :). All our automated ui tests have passed as well. Seems like this change is good. Any updates on the merge? :). @christolliday any update on this?. @christolliday Fixed the tests. @christolliday any update on this?. @christolliday Updated integration tests. @christolliday fixed one more test that travis spotted. Sry for the trouble. Should be good now. > Can you rebase and make this build? There's a method missing.\nWill do!. > Can you rebase and make this build? There's a method missing.\nWill do!. @christolliday Fixed the missing method and rebased. @christolliday Fixed the tests. @styurin @mkillianey @bobyangyf Can we stop creating this symlink?. cc @styurin . @styurin any update on the import?. cc @styurin Can we please import this?. @styurin any update on this?. cc @mkillianey @christolliday . After discussing offline with @mkillianey , we decided not to change this and let users customize the facet excludes using buck's post process ability after the project command runs. @styurin any update on the import?. @styurin any update on the import?. cc @thalescm @artem-zinnatullin @brettwooldridge . Not sure yet how this would work with prebuilt jars/aars that were compiled with kotlin. cc @joelmccall @styurin . > Could you rebase on the latest stable?\nHey @styurin is there any reason why this cannot be done internally? It seems to waste precious cycles for external contributors to do this when there are no conflicts. > I'm asking because there is a merge conflict caused by internal changes. I tried to change those internal pieces, but it's still failing and I hope rebasing on master would solve that. Otherwise someone would need to apply this PR manually to the internal repository which means wasting precious cycles of internal developers.\nGot it. It was not clear where the conflict was. Thanks for clarifying!. @styurin any update on the import?. @styurin can we please import this?. @ZacSweers can you please rebase this?. Lets make sure to run gjf as well upon rebase so we can shorten review cycles. Lets make sure to run gjf as well upon rebase so we can shorten review cycles. Seems like build started failing after rebase (compilation, not tests). Seems like build started failing after rebase (compilation, not tests). cc @styurin . cc @styurin . cc @styurin . cc @styurin . It seems this was fixed by something @thalescm did recently. We have a fixture for this already https://github.com/facebook/buck/blob/master/test/com/facebook/buck/jvm/kotlin/testdata/kotlin_library_description/com/example/zip/BUCK.fixture and we no longer need this change. It would be helpful if someone can open a PR with an update to the integration test to showcase the problem. We are not able to see any issues with this change enabled on our apps.\ncc @raviagarwal7 . It would be helpful if someone can open a PR with an update to the integration test to showcase the problem. We are not able to see any issues with this change enabled on our apps.\ncc @raviagarwal7 . cc @raviagarwal7 Can you please look into this ^ ?. cc @styurin can we import this simple change?. cc @styurin can we import this simple change?. cc @styurin . cc @styurin . cc @styurin @awelc. cc @styurin @awelc. > Build is broken\nhuh it was working before recent change iirc. let me take a look!. > Build is broken\nhuh it was working before recent change iirc. let me take a look!. @styurin fixed the build and rebased again. Sorry about that! Feel free to merge once build passes. @styurin fixed the build and rebased again. Sorry about that! Feel free to merge once build passes. Seems like the new logic using files api is broken in integration tests. Will fix and push up. Seems like the new logic using files api is broken in integration tests. Will fix and push up. Fixed the bug and pushed. Please re-import :). Fixed the bug and pushed. Please re-import :). Hmm seems like travis has surfaced new failures. Im unable to run these integration tests locally. Ill continue to iterate and ping again once travis is fully green. Sorry for the trouble @styurin . Hmm seems like travis has surfaced new failures. Im unable to run these integration tests locally. Ill continue to iterate and ping again once travis is fully green. Sorry for the trouble @styurin . Seems like 2 tests failed. lot better than before, Are you planning to fix these internally @styurin ?. Seems like 2 tests failed. lot better than before, Are you planning to fix these internally @styurin ?. @styurin I cant seem to run this test locally. Complaints about missing ndk platform toolchains. Whats the best way to set this up on a mac so i can reproduce. Its not clear why the build fails with proguard on and exit code 10. @styurin I cant seem to run this test locally. Complaints about missing ndk platform toolchains. Whats the best way to set this up on a mac so i can reproduce. Its not clear why the build fails with proguard on and exit code 10. @styurin CI is now green. The only failure is from BuildEndToEndTest which seems to be flaky. @styurin CI is now green. The only failure is from BuildEndToEndTest which seems to be flaky. cc @styurin @demon-xxi. cc @styurin @demon-xxi. @styurin Rebased and fixed conflicts. cc @styurin . cc @styurin . I think the ApkBuilder from aosp does this implicitly today for apks in buck. What alternative approach would you suggest @styurin \nCan we follow something like https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/ApkBuilderStep.java#L178 ?. > I was thinking about having an argument on a rule that would list entries to remove, but these details may look very low level for top level rule.\nI think such a list would be very hard to maintain. I think what we wanted here is an include list rather than an exclude list. But having a list would be too low level as you noticed. This current change mirrors what the apk builder does in buck. Maybe we can add documentation to the code to make it clearer why we choose these entries only?. cc @styurin . The version of BK that has this support is not released yet, but I will add docs with a note\n. I can reformat\n. what about the packaging type?\nif you hardcode jars, android aar poms will not be resolved correctly\n. I think this can be generic to include both the classifier and packaging type as well\n. The ?:\\\\[\\\\])? part I took from the regex above. I dont think it is needed. I can remove it for simplicity\n. will do\n. This is purely scoped to java_sdk. If someone wants to use groovysdk, they would need to be a separate config key groovy_sdk in the intellij block of buckconfig and it could be used here.\nI would like to get this in to atleast mirror the legacy support and make it module level granularity. The auto detection change should not be part of this change imo\n. > I had a bunch of code that would attempt to read IntelliJ's config\nWhat if there are multiple installations of intellij/android studio or its variants? There is a lot of complexity involved in that calculation and it should be kept separate from this change\n. This utility provides most of the logic to include/exclude files via wildcard patterns. Reimplementing it will be a lot more work than using a standard utility that has been well tested already.\n. ah I was not aware. I will clean it up :)\n. Sure I will make the changes. Thanks for the feedback\n. Done\n. Done\n. It was before, but that caused the integration test to fail. This is because the continue needs to happen for both conditionals, but the write only needs to happen if the inner conditional is satisfied\n. Does that work with the replaceFileContents method? It seems to be just generating throw away files during testing. Do we care about the formatting of one such auto generated test scaffold file?\n. What people are used to seeing is based on who is seeing it :)\nintellij, gradle and other build systems typically report \"x minutes and y seconds\"\nThis change only makes it slightly more readable instead of totally changing it :)\n. this assumes git is on the path. it may not be a valid assumption to make\n. nevermind. I see you are checking it above :)\n. This seems limiting. Why can the sourcepaths not be compiled separately and combined together later? Gradle supports this already for example\n. nevermind, this is fine since there can be multiple android library targets with different jvm languages that can still be combined later\n. This applies to all android rules. I think the original argument should instead be renamed to java_sdk_names instead because it would apply to all java rules as well\n. Same comment as above. I think this should be named android_sdk_name as it applies to all android rules\n. If we replace with the default, how would we ever confirm that the override is actually working?\n. We dont. I will remove\n. Done. @dreiss any luck checking this PR out on FB's codebase?. I dont think that is possible in this case. This will run the build twice. Can we just do this by default?. should make the list of extensions configurable as other jvm based libraries can have scala/groovy/kotlin files etc and can easily override this. Same with file extension here. Why do you need a parser to create source jars?. If you just need to extract the package, a full blown java source code parser might be overkill. Java/Scala/Groovy/Kotlin do not differ in how they declare their package names except for maybe the omission of a semi colon at the end. The package can be extracted via a simpler means (regex?) and the logic can then be applied to all jvm based language source files. Thoughts?. I mentioned other languages because source jars are traditionally just zips of folders with pretty well defined structure. But in the event the code is not well structured according to the package names, parsing makes sense. But it also makes creating source jars more complicated than necessary. Most source jar tasks for all jvm based languages can be simple zip rules if they arleady adhere to a given structure. Maybe we can provide it as an option so buck does not force parsing of the files just to put them back in the same folder structure inside the source jar (i.e useless work). In that case, well defined structures can be used quickly to create source jars for any language, but in case the structure is not defined, parsing can be enabled and in this case, just support for java is fine. do we need to add error prone version to the rule key here?. sounds good. https://www.youtube.com/watch?v=j6CiHlapado\nhttp://fragmentedpodcast.com/episodes/68/\nhttp://fragmentedpodcast.com/episodes/69/\nhttps://speakerdeck.com/kageiit/lightning-fast-android-builds-with-gradle-plus-buck\nWe also have  blogpost for ios buck usage that I will need to check with alan about. We have pretty different adoption stories for android and ios. Might still be fine to have atleast two links here for that purpose. If the links show up short enough in the final output html, it might be ok. If you strictly want just one link for android, I would suggest to hold off until we have a real blogpost out.. proguard config was using dashes. I can use _ if thats the convention, but was unsure. I can remove the dx prefix. I can also add the fallback. Whats the best way to show a warning?. I just copied it from the groovy rule :). More info here: https://github.com/facebook/buck/blob/336cafaf458effabd78bf7281f5e6f9658899e3c/src/com/facebook/buck/jvm/java/intellij/IjFolder.java#L95. @dreiss Do you want want me to change this or is there any other change you requested?. change to 2.0.18. do you want to check if name is not null here? given that we may not be adding the annotation?. ah ok :). Can we clean up these comments?. Considering kotlin versions evolve rapidly, it may not make sense to bundle kotlin jars with buck for every release. Maybe its best if we let consumers point to the kotlin jars they want as remote_files or jars etc.?. I think autodeps was mostly removed by @Coneko recently. cleanup comments. move this to a constant. We can also cache the class obtained this way to avoid needing to load the class for every compile invocation. constat. cleanup comments. cleanup comments. The usecase mentioned by @brettwooldridge in 1 will be what we would be using for okbuck as well. Thanks!. Do we want to mention about the fallback for kotlin-runtime for older versions? If not, it might make sense to remove that fallback in a followup change. If most of the arguments are the same as java_library, it might make sense to DRY this up and use a template that is commonly used for other jvm based rule docs. Lets create tow actions\n\"Run Test(s) with Buck\"\n\"Debug Test(s) with Buck\"\nand add the buck icon to the left side. Lets place it after the default test actions group. Do we really need a wildcard import here?. how is this action different? It needs to know to set the debug flag right?. Can we easily extend this for packages and modules too?. Can we make this a bit generic. we should be able to also consume any java_library rules here so best to avoid specifying that kotlin_library rules are used as deps typically.. This is not fully accurate. After @runningcode 's changes to support mixed sources compilation, the sources can include both java and kt files at once. Can we update it to reflect the same?. Same comment abouth allowing both kt and java files. Mixed-sources already merged. So maybe @runningcode can look at it as a follow up along with the kapt work he is tackling right now?\nThis should not be blocking at the moment. Can we make the copyright consistent here? It seems to be always at the top of the file elsewhere, but not in this file. Same here with copyright. it should be 2017 here as the inception year is 2017 in this case. Make the non abstract action classes final unless you plan to mock them. Can you expand on this?\nWhat is this running/debugging? Please be explicit if possible. inline isTestMethod(method) directly and avoid the variable as you dont reuse it. Dry this up into a utility method and pass in true or false. lets just call this variable debug. lets just call runInDebug as debug. lets just call runInDebug as debug. You should try to use Java Optional instead of empty strings everywhere where there is an optional parameter.. What about TestNg ? If it is not supported yet (buck supports test ng), please make a note in the documentation of this class. Rename variable to isTestMethod. You should break early when you find the first Test method. Its wasteful to keep iterating. why are we hardcoding debug?. Can you add a comment about this so we know why it is defaulted to \"debug\". We need to add a comment that this may not work if buck spools directly to jar. I do not think we should have a default. There can be resource only modules that have no sources which will not have a compiler output path and they will be fine inheriting from the root project compiler output path. Can we just do this for any JvmLibrary. That way it will work for android,java,kotlin,groovy rules etc without any extra configuration. Can you please add this one line change to kotlin and groovy module rules as well. when can this be null?. We should add this to kotlin library description as well. ah cool. Good catch. Let me add it. Can we make this Optional instead?. Updated. Done. oops. Updated now! :). KotlinLibraryDescription.CoreArg already inherits from JavaLibraryDescription.CoreArg. So this change does not bring in anything more . Maybe opportunistically fix this as well to not make a copy?. ah gotcha. @cwoodwar6 not sure if you saw this comment but we should make this optional. @styurin any updates on this?. Use File separator instead of /. We need a preconditions check to ensure there is only one resource rule labelled preferred_res_folder per BUCK file/iml. Can you also add a test that we throw an error in this case please?. Just noticed this. It might be possible, but the logic is fairly trivial and not sure if its worth DRY'ing up. Added a comment to point to https://github.com/facebook/buck/issues/1386. Sure. I can make the change. Rename to  \"Generate Buck Project\". Rename to  \"Generate Buck Project\". if its done on a file, we can use buck query to see which targets own the file as well. This is no longer present in jdk 9. Can we not need this or atleast let users specify a location for this jar?. Instead of \"selected file\", we can show what file and target got invoked. lot of common code between this and the above that can be DRY'ed. getPluginsRoot() is what returns plugins path by default which is exactly what we do not want.\nAlso its strange to run it in development mode as we do not know what other weirdness that will turn on. Im ok with that approach :). @thalescm The clue is in https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/kotlin/JarBackedReflectedKotlinc.java#L160\nThis is where the Kotlinc is loaded by creating a new classloader with the kotlin jars passed in via buckconfig. you should change the parent classloader from null to ToolProvider.getSystemToolClassLoader\nThis way, classloader hierarchy will set setup such that you dont have to add the tools jar again when running the KotlincStep. Sure. ant complains if I remove this though :(. cc @jkeljo . in .buckconfig\n[java]\n  track_javac_phase_events = true. you can do a single\nbrew install ant watchman. Github is not letting me comment on the actual code line in this file, but can we change\npublic static final ImmutableSet<String> DEFAULT_CPU_ABIS =\n      ImmutableSet.of(\"arm\", \"armv7\", \"x86\");\nto \npublic static final ImmutableSet<String> DEFAULT_CPU_ABIS =\n      ImmutableSet.of(\"armv7\", \"x86\");\nThat will make buck work by default with the latest ndk. Cant use getExecutorWrapper() as it does a blocking await. Thats exactly the situation we are trying to avoid. Bumping timeout just makes the buck process hang longer before giving control back to the user on the terminal. I can add this back and keep it adding to the rulekey. This is only required for d8 runtime so I did not add it to idea project files. Why do we need this change?. Sure let me add a test. kapt_apoptions -> kapt_ap_options. Can we return the abi jars here? Desugaring does not require full jars. Using abi jars ensures we do not run d8 unless the abi surface has changed and should give a good build speedup. D8 can generate multiple dex files in a single step. Can we fix the assumption that buck makes currently which is always expecting a single dex as output from D8?. Does this need to be done for aars as well?. That makes sense. Can be done separately, but it will be a big win to do so later since buck currently computes the method and field counts via an asm pass after compilation so it can play with the rules of the old dexer. Since that is not needed anymore, we can avoid all that overhead with D8. god catch. I think I ran google java format on this and didnt need the changes after. ill remove. @jtorkkola can you please add this requirement to the contributing doc? https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style\nThis is the first time in reviews this was made a concern. I think its best we set the same standard for everyone to avoid loss of review cycle time. This enables d8 to have a unique identifier per dex bucket i.e classes2.dex, classes3.dex etc. so that the synthetic classnames are not duplicated and end up conflicting in redex.\nThe change to buck to actually pass in this id will be opened in a separate PR.\ncc @awelc. Done. interesting. ok will make the change to see if the tests pass finally :). Done and pushed. Lets wait for CI :). Its been renamed to make the purpose clear. We use it below. ",
    "Zetten": "I've added an approach in https://gist.github.com/Zetten/1e2f26cd48d144c972ba687c27dc25f5, also adapted from the bucklets xsl, with a python lxml wrapper (unlike bucklets which does the processing with a downloaded jar).\nThis approach is more script-y and produces one converted file per input. So if the end goal is to get reports into SonarQube, it's up to the caller to make sure that the transformed files are named \"TEST-foo.xml\" for compatibility with the Sonar-Java Surefire report sensor.\n. That would certainly explain the documentation!\nI did think about doing it as a genrule but the exact process wasn't exactly clear - for example the genrule contract states it should be producing a single file/folder as output, and indeed out is mandatory. I also couldn't see how a target of this type could be used as a java_library-type for deps/autodeps purposes.\nAlso, assuming it's possible to update the .classes in-place with another target, how would this work with the java_library's ABI definition? For example if the post-processing changes/adds public stuff it'd be nice to have it available for autodeps.\nI couldn't see any easy way to keep the intuitiveness of a single java_library target representing the collection of .java -> .class files (including post-processing), until I started looking at the code and found the java_library parameter. Plus the postprocess_classes_command stuff is executed before the ABI calculation in DefaultJavaLibrary so this kind of naturally fits in.\nI might be missing something really easy here - I'm still very much learning the ropes, so any hints in the right direction would be great.\n. Hi Martin,\nThanks for clearing the genrule stuff up - that's put me on the right track now. It's a bit cumbersome, but it definitely makes sense. I'm defining a few target macros to simplify stuff at the module level, but it all makes sense.\nI'm wrapping the final prebuilt_jar in a(nother) java_library, so that it can define the tests and exported_deps it needs. This means a bit of wrestling with autodeps, but I guess defining the deps manually is more correct for this sort of tangled situation.\nIn any case, thanks again. No need for postprocess_classes_commands after all!\n. ",
    "zhangyulong882": "Thanks for your comment. I have solved this problem. I have an invalid string in the string.xml file. So the R.java cannot be generated and this results in the problem. But when I solved this, it came cross a new problem:\nI have  two projects: one main project and one android library project. The lib project can be built successfully. But the main project cannot. The java files in main project still cannot find the classes in the lib project. it prompts: Cannot find symbol ....\nI wrote the BUCK file in main project like this:\nandroid_library(\nname = 'activity',\nsrcs = glob(['src/*/.java']),\ndeps= [\n'//third_party/safewidget/sqlite3sec:app3',\n'//libs:zxing',\n'//res/com/paic/zhifu/wallet/activity:res',\n'//third_party/pamap:app2',\n],\nvisibility = [ 'PUBLIC' ],\n)\nthe deps string \"//third_party/safewidget/sqlite3sec:app3\" is the build rule of the lib project and seems useless. \n. I defined like this:\nprebuilt_native_library(\n  name = 'nativelibs',\n  native_libs = 'libs',\n)\nandroid_library(\n  name = 'app3',\n  manifest = 'AndroidManifest.xml',\n  deps = [\n    ':nativelibs',\n    '//third_party/pamap/res:res',\n    '//third_party/pamap/java/com/map/sdk/map:paactivity',\n  ],\n  visibility = ['PUBLIC'],\n)\nproject_config(\n  src_target = ':app3',\n)\n2014-07-11 9:34 GMT+08:00 bolinfest notifications@github.com:\n\nHow is app3 defined?\nOn Jul 10, 2014 5:37 PM, \"zhangyulong882\" notifications@github.com\nwrote:\n\nThanks for your comment. I have solved this problem. I have an invalid\nstring in the string.xml file. So the R.java cannot be generated and\nthis\nresults in the problem. But when I solved this, it came cross a new\nproblem:\nI have two projects: one main project and one android library project.\nThe\nlib project can be built successfully. But the main project cannot. The\njava files in main project still cannot find the classes in the lib\nproject. it prompts: Cannot find symbol ....\nI wrote the BUCK file in main project like this:\nandroid_library(\nname = 'activity',\nsrcs = glob(['src/*/.java']),\ndeps= [\n'//third_party/safewidget/sqlite3sec:app3',\n'//libs:zxing',\n'//res/com/paic/zhifu/wallet/activity:res',\n'//third_party/pamap:app2',\n],\nvisibility = [ 'PUBLIC' ],\n)\nthe deps string \"//third_party/safewidget/sqlite3sec:app3\" is the build\nrule of the lib project and seems useless.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/151#issuecomment-48682254.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/151#issuecomment-48685426.\n. I have tried to put the file in asset directory and succeed. But if I prefer to put it in src directory, how can I write the BUCK file. I use this way to read the file:\n\nProperties props = new Properties();\n        try {\n            InputStream in = Thread.currentThread().getContextClassLoader()\n                    .getResourceAsStream(filename);\n            props.load(in);\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n. I have tried to put the file in asset directory and succeed. But if I prefer to put it in src directory, how can I write the BUCK file. I use this way to read the file:\nProperties props = new Properties();\n        try {\n            InputStream in = Thread.currentThread().getContextClassLoader()\n                    .getResourceAsStream(filename);\n            props.load(in);\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n. Hi\uff0c I have another question\uff1a\nI have a property file (like local.properties) in src directory. And I would read this file in my java file. When I successfully built the project and run the apk, the application cannot find the property file. How can I write the BUCK file and make the property file included in my app.\n. ",
    "posto": "I had the same issue. Switching JAVA_HOME from Java 7 to 8 had no effect on buck and it took a while to understand why.\nPerhaps buckd can write our somewhere JAVA_HOME path (and/or other env variables) along with the pid, and this would be checked later by buck before passing the command to buckd.\n. ",
    "edwardspeyer": "My comment appears to have disappeared.  Huzzah!\nIn brief, agree completely that assumptions aren't errors.  However, when you're in the mood to see what the actual assumption-violations are, it's nice to put buck into a mode (permanently in fact for some of us, hence this being a .buckconfig option) where it treats assumption-violations as errors for the purposes of output, even though in the event-bus and Buck's internal model they are still distinct from errors.\nThanks for flagging, and I hope that clears up the confusion!\n. The test-plan on my original commit shows the difference in output when this option is turned on.  With the \"assumptions-are-errors\" option, the assumption-violation's exception is printed, whereas it is usually not printed.\n. ",
    "anotherchrissmith": "Sorry for the delay, I was away last week.  I no longer notice the problem although I have disabled buckd because of this issue https://github.com/facebook/buck/issues/170.\n. Now that https://github.com/facebook/buck/issues/170 appears to have been fixed (brilliant work, thanks), this issue also appears to have been fixed.  I can run buck multiple times, over and over, and it now gives me consistent output without aborting half way through.  Closing.  Thanks.\n. We have had to turn off buckd.  We're putting considerable effort into switching to buck, but we need correct and reproducible results.  This is especially so for our continuous integration system if we're not doing a clean in between each build.\n. ",
    "dborowitz": "Ah, didn't know about buck/bin/buckd; I started using buck before buckd existed, and it's not mentioned in the installation instructions. Thanks.\nIt would still be nice if buck could do a better job of detecting when buckd is wedged and kill it on its own, so my vote is to leave this issue open to track that.\n. Maybe \"buck d\" as an alias for \"buckd\"? ;)\n. I believe it started happening after updating buck from 0fe4569e871fd6588f7cbfb4b1d4a14baa791a9f to 620fdf494f66c2876cfc7cae6f6feb9d36e45df4.\nAt the time of the upgrade my watchman was at 5161cb6eeca4405bcaea820f377cd6d2f51ce1f4 and I then upgraded to 35466dc6e8cca28b0eedcdc4c67474fee806c3e8 to see if it would help (which it did not).\nIf I find some time today I will try to produce a reliable reproduction and grab a watchman log.\n. I believe it started happening after updating buck from 0fe4569e871fd6588f7cbfb4b1d4a14baa791a9f to 620fdf494f66c2876cfc7cae6f6feb9d36e45df4.\nAt the time of the upgrade my watchman was at 5161cb6eeca4405bcaea820f377cd6d2f51ce1f4 and I then upgraded to 35466dc6e8cca28b0eedcdc4c67474fee806c3e8 to see if it would help (which it did not).\nIf I find some time today I will try to produce a reliable reproduction and grab a watchman log.\n. I've been unable to reproduce since upgrading. (Full disclosure, I've also been unable to reproduce after downgrading again...)\n. I've been unable to reproduce since upgrading. (Full disclosure, I've also been unable to reproduce after downgrading again...)\n. I do see those lines, thanks. (Though the unix timestamps in the log threw me off for a sec :)\n. I do see those lines, thanks. (Though the unix timestamps in the log threw me off for a sec :)\n. Though that document is not very helpful as far as advice on choosing an appropriate value. My max_queued_events is 16384 which is 6x the number of files in my repo. Why would that not be sufficient? What is a good value? What happens if I set it too high? Is 2^20 good? 102^20? 2^30?\n. Though that document is not very helpful as far as advice on choosing an appropriate value. My max_queued_events is 16384 which is 6x the number of files in my repo. Why would that not be sufficient? What is a good value? What happens if I set it too high? Is 2^20 good? 102^20? 2^30?\n. Also, if this should be some roughly constant multiple of the number of files in my repo (maybe also times max_user_instances?), ISTM buck should be able to set/suggest a value for me.\n. Also, if this should be some roughly constant multiple of the number of files in my repo (maybe also times max_user_instances?), ISTM buck should be able to set/suggest a value for me.\n. Ok, I buy that there is no magic bullet. But given the default of 16k is almost certainly too small for a decent-size repo, maybe the documentation should suggest something pretty-big-but-reasonable like 1M as a first resort.\n. Ok, I buy that there is no magic bullet. But given the default of 16k is almost certainly too small for a decent-size repo, maybe the documentation should suggest something pretty-big-but-reasonable like 1M as a first resort.\n. https://gist.github.com/dborowitz/d2c83924066c067dbf5f\n. https://gist.github.com/dborowitz/d2c83924066c067dbf5f\n. The zip file is in the same gist as the console output.\n. The zip file is in the same gist as the console output.\n. Aside...\n\nI didn't realize you could attach binary files to gists\n\nNot the simplest thing in the world, you have to actually clone the gist repo and add the file manually. And directories aren't supported. shrug\n. Aside...\n\nI didn't realize you could attach binary files to gists\n\nNot the simplest thing in the world, you have to actually clone the gist repo and add the file manually. And directories aren't supported. shrug\n. Oops. I was trying to be helpful by not polluting the directory with logs from other runs.\nDone: https://gist.github.com/dborowitz/d2c83924066c067dbf5f/3dd0ea6d7694544dae10024a0518c27a565575a4\n. Oops. I was trying to be helpful by not polluting the directory with logs from other runs.\nDone: https://gist.github.com/dborowitz/d2c83924066c067dbf5f/3dd0ea6d7694544dae10024a0518c27a565575a4\n. Python 2.7.6.\n. Python 2.7.6.\n. Unable to reproduce this with\n$ for i in {1..20}; do buck clean && buck build gerrit-common:server; done\nso I think we're good. Thanks!\n. Unable to reproduce this with\n$ for i in {1..20}; do buck clean && buck build gerrit-common:server; done\nso I think we're good. Thanks!\n. ",
    "kchodorow": "~80% laziness (installing two things is more work than installing one thing) and ~20% paranoia (tracking files on my work machine? no thanks).\n. @bolinfest yes, it looks like 5298eac fixes the same problem I ran into, thanks!\n. @bolinfest yes, it looks like 5298eac fixes the same problem I ran into, thanks!\n. ",
    "tom-smalls": "We've been having issues with buckd+watchman failing to detect file changes, and like anotherchrissmith, have turned them off. This has exposed us to issue #165, which isn't ideal either.\n. We've been having issues with buckd+watchman failing to detect file changes, and like anotherchrissmith, have turned them off. This has exposed us to issue #165, which isn't ideal either.\n. ",
    "wez": "From the watchman side, to rule out anything funky, can you pull the log file?\nIt will typically be at $TMPDIR/.watchman.$USER.log, or if you configured using --enable-statedir, it will be STATEDIR/$USER.log.\nSince this seems to affect multiple people, can you also chime in with the OS, watchman and buck versions you're all using?\nWe could do with more details on what buck is seeing so that we can tell where things are going awry; I don't know how to coax this information out of Buck, so defer to those that do.\n. From the watchman side, to rule out anything funky, can you pull the log file?\nIt will typically be at $TMPDIR/.watchman.$USER.log, or if you configured using --enable-statedir, it will be STATEDIR/$USER.log.\nSince this seems to affect multiple people, can you also chime in with the OS, watchman and buck versions you're all using?\nWe could do with more details on what buck is seeing so that we can tell where things are going awry; I don't know how to coax this information out of Buck, so defer to those that do.\n. if the updates resolve the issue and you saw watchman log lines similar to IN_Q_OVERFLOW: scheduling a tree recrawl then it is an indicator that you need to tune your inotify limits per https://facebook.github.io/watchman/docs/install.html#linux-inotify-limits.\nThe changes in buck allow a more graceful recovery but they do mean that buck has to perform a full tree crawl itself to recover.  Tuning inotify appropriately for your repo size and workload should keep things humming along more efficiently.\n. if the updates resolve the issue and you saw watchman log lines similar to IN_Q_OVERFLOW: scheduling a tree recrawl then it is an indicator that you need to tune your inotify limits per https://facebook.github.io/watchman/docs/install.html#linux-inotify-limits.\nThe changes in buck allow a more graceful recovery but they do mean that buck has to perform a full tree crawl itself to recover.  Tuning inotify appropriately for your repo size and workload should keep things humming along more efficiently.\n. A problem with auto-suggesting is that buck doesn't know how many users and repos you have overall.  watchman doesn't know that either, and neither of them runs as root and thus can't set it in your behalf in any case.\nmax_queued_events sizing depends on how fast your system is able to process those events as well as the size of the repo and the number of temporary files and file updates, moves, deletes that occur within your tree as a side effect of running your build.  I don't know if there is a magic formula for sizing it, but bigger is better.\nSizing it larger means that more memory will be allocated by the kernel to maintain the inotify buffers.  If you generally have a lot of RAM available, you should be able to crank it up with impunity.\n. A problem with auto-suggesting is that buck doesn't know how many users and repos you have overall.  watchman doesn't know that either, and neither of them runs as root and thus can't set it in your behalf in any case.\nmax_queued_events sizing depends on how fast your system is able to process those events as well as the size of the repo and the number of temporary files and file updates, moves, deletes that occur within your tree as a side effect of running your build.  I don't know if there is a magic formula for sizing it, but bigger is better.\nSizing it larger means that more memory will be allocated by the kernel to maintain the inotify buffers.  If you generally have a lot of RAM available, you should be able to crank it up with impunity.\n. Re: ignoring vcs dirs, you've run into https://github.com/facebook/watchman/issues/17.  The TL;DR is that we perform a shallow watch on .git, .svn and .hg by default.  We do this for two reasons: we need a place to create cookie files for synchronization purposes that won't show up as new files if you happen to git status while a query is in progress, and also because we want to notice repo lock activity to detect when the tree is settled and at a good point to launch a trigger process.  By listing the vcs dir in the ignores list, the cookie portion of this gets broken.  I'll push a diff to avoid breaking down in this case in the next day or so, ideally sooner.\nIn the meantime, if you want to completely ignore .svn you need to set your .watchmanconfig up like this:\n{\n   \"ignore_vcs\": [\".git\", \".hg\"],\n   \"ignore_dirs\": [\".svn\", \"buck-out\", \"buck-cache\", \".buckd\"]\n}\nThe main thing is moving .svn from ignore_vcs and into ignore_dirs\n. Re: ignoring vcs dirs, you've run into https://github.com/facebook/watchman/issues/17.  The TL;DR is that we perform a shallow watch on .git, .svn and .hg by default.  We do this for two reasons: we need a place to create cookie files for synchronization purposes that won't show up as new files if you happen to git status while a query is in progress, and also because we want to notice repo lock activity to detect when the tree is settled and at a good point to launch a trigger process.  By listing the vcs dir in the ignores list, the cookie portion of this gets broken.  I'll push a diff to avoid breaking down in this case in the next day or so, ideally sooner.\nIn the meantime, if you want to completely ignore .svn you need to set your .watchmanconfig up like this:\n{\n   \"ignore_vcs\": [\".git\", \".hg\"],\n   \"ignore_dirs\": [\".svn\", \"buck-out\", \"buck-cache\", \".buckd\"]\n}\nThe main thing is moving .svn from ignore_vcs and into ignore_dirs\n. worth asking while I'm here: @mread are your .svn dirs only in the root of the tree, or are you using an older version that puts a .svn in every dir?  We don't have a great answer for the latter case, having been focused more on .git and .hg so far.\n. worth asking while I'm here: @mread are your .svn dirs only in the root of the tree, or are you using an older version that puts a .svn in every dir?  We don't have a great answer for the latter case, having been focused more on .git and .hg so far.\n. I understand your frustration, but we do need some information from you to help clarify what is going on; I think there are a couple of issues here:\n1. your .watchmanconfig doesn't list buck-out in its ignore_dirs list.  This should be the standard deployment for buck and we do need to make setting and discovering this easier and more automated\n2. Something is creating dirs under buck-out that you don't have access to.  Either the permissions are completely screwed up or perhaps you sudo ran something and left something behind.  We'd like to understand which of these it is so that we can figure out if this is a bug that we need to fix, or a general problem with surfacing unexpected conditions\n3. due to an oversight, watchman is treating this condition (I'm assuming EACCES) as a poison state when it shouldn't, leaving you with a stuck watchman process.  I've pushed https://github.com/facebook/watchman/commit/2a528373c54f4ca585dcbd8f10c066d8ec8dab2d as a speculative fix for this.\n. For 1), this is on our radar; there are pieces available for buck to interrogate watchman to surface this, it just hasn't been done yet.\nFor 2), I suspect that either the access mode was broken (I've seen stuff get chmod'd to random bits in the past) or that the dir went away.  The man page isn't clear on the error code reported in this case; we already had code to handle ENOENT because we've seen this in the wild, but this code isn't listed on my current man page. :-/\nFor 3), the intent of poison states is only to enter them if there is nothing that watchman can do itself to remedy things such that it can give you a sane outcome.  It refuses all requests across all watches to ensure that you notice the issue.  A dir that is not watchable doesn't warrant this level of response, but perhaps could be surfaced better in any case.\n. @davido you should only need to specify ignore_dirs; the default ignore_vcs has the usual suspects\n. Watchman does not follow symlinks.  https://github.com/facebook/watchman/issues/105 has some context.  We have no plans to magically and generally make symlinks \"work\" because it seems way too complex to make it work as you might expect.  We may be able to work something out that will make it easier for tools to deal with this situation though.\nIn the absence of any helpers, it sounds like buck should resolve symlink(s) and watch-project on the target path(s) and feed those subscriptions into its watcher implementation.\nWe'll need to brainstorm on this.\n. The link at the bottom of your error paste has instructions on how to remediate this situation (increase your system limits so that you don't run out of watch resources).\nIf you can't or don't want to do that for some reason, you can manually cancel out watches using the watchman watch-del command.\nWith that addressed, I think @davido's question is, how can he ask buck not to use watchman for builds in the projects that he doesn't want to commit watch resources against?\n. The link at the bottom of your error paste has instructions on how to remediate this situation (increase your system limits so that you don't run out of watch resources).\nIf you can't or don't want to do that for some reason, you can manually cancel out watches using the watchman watch-del command.\nWith that addressed, I think @davido's question is, how can he ask buck not to use watchman for builds in the projects that he doesn't want to commit watch resources against?\n. @davido take a look at this watchman configuration option:\nhttps://facebook.github.io/watchman/docs/config.html#root_files\n. @davido take a look at this watchman configuration option:\nhttps://facebook.github.io/watchman/docs/config.html#root_files\n. Regarding that error, my suspicion is that the root_files configuration you pasted was working against you.\nYou can use watchman watch-list to enumerate the watches.\nI'm sorry for not elaborating on this earlier; If the only thing you want to put in root_files is .watchmanconfig, then I don't think you need or want an /etc/watchman.json file, as that is a subset of the default configuration.\nRather, you want to focus on how you can tell watchman where the root of your projects are.  If we didn't find a .watchmanconfig, then the defaults will stop walking up the tree until we find a source control directory (.hg, .git, .svn), so if those projects are in separate repos, they'll be watched as separate roots.\nIf that is not the case, then you can create a .watchmanconfig file at the location that you consider to be the root of your project; it can just be an empty json object {} as the content.\nDoes that make sense?\nCan you share the output from ls -l /home/davido/projects/proj1 /home/davido/projects/proj2 /home/davido/projects/proj3 /home/davido/projects to help me understand which of these control files are present on your system?\n. Regarding that error, my suspicion is that the root_files configuration you pasted was working against you.\nYou can use watchman watch-list to enumerate the watches.\nI'm sorry for not elaborating on this earlier; If the only thing you want to put in root_files is .watchmanconfig, then I don't think you need or want an /etc/watchman.json file, as that is a subset of the default configuration.\nRather, you want to focus on how you can tell watchman where the root of your projects are.  If we didn't find a .watchmanconfig, then the defaults will stop walking up the tree until we find a source control directory (.hg, .git, .svn), so if those projects are in separate repos, they'll be watched as separate roots.\nIf that is not the case, then you can create a .watchmanconfig file at the location that you consider to be the root of your project; it can just be an empty json object {} as the content.\nDoes that make sense?\nCan you share the output from ls -l /home/davido/projects/proj1 /home/davido/projects/proj2 /home/davido/projects/proj3 /home/davido/projects to help me understand which of these control files are present on your system?\n. I think we should probably add these options to both buck and watchman.\nA couple of reasons why below; maybe not the best reasons in the world :-)\n- If watchman isn't yet started and buck spawns it, that will cause watchman to crawl any saved watches.  If it turns out that the project dir of interest to buck is disabled through watchman configuration, buck will then be competing for I/O to run the build.\n- The error reporting interface from watchman is textual in nature, so if buck would like to react to the situation where watchman is configured to be disabled for a path (perhaps to show a less scary notice to the user than the default unavailable-watchman messaging), buck would be at the mercy of matching text strings\n. I think we should probably add these options to both buck and watchman.\nA couple of reasons why below; maybe not the best reasons in the world :-)\n- If watchman isn't yet started and buck spawns it, that will cause watchman to crawl any saved watches.  If it turns out that the project dir of interest to buck is disabled through watchman configuration, buck will then be competing for I/O to run the build.\n- The error reporting interface from watchman is textual in nature, so if buck would like to react to the situation where watchman is configured to be disabled for a path (perhaps to show a less scary notice to the user than the default unavailable-watchman messaging), buck would be at the mercy of matching text strings\n. Can we get a copy of whatever that blob is that is trying to be decoded? the subject of the f.read() call\n. Can we get a copy of whatever that blob is that is trying to be decoded? the subject of the f.read() call\n. I honestly don't know the answer to that; I wrote the bser stuff but for a different project.  Buck folks, is there a way to get a hold of that data?\n. I honestly don't know the answer to that; I wrote the bser stuff but for a different project.  Buck folks, is there a way to get a hold of that data?\n. Can you get that in hex?\nhttp://stackoverflow.com/a/12214957/149111 may help\n. Can you get that in hex?\nhttp://stackoverflow.com/a/12214957/149111 may help\n. ",
    "st-f": ":+1: Seconding\n. :+1: Seconding\n. ",
    "tyzero": "how can I use it ?\n. how can I use it ?\n. ",
    "Piasy": "Maybe this gradle plugin? OkBuck.\nOkBuck is a gradle plugin, aiming to help developers utilize the super fast build system: BUCK, based on the existing project with Android Studio + gradle, and keep both build systems work, with less to only 10 lines of configuration.\n. Maybe this gradle plugin? OkBuck.\nOkBuck is a gradle plugin, aiming to help developers utilize the super fast build system: BUCK, based on the existing project with Android Studio + gradle, and keep both build systems work, with less to only 10 lines of configuration.\n. @sdwilsh Hi, I think the problem is that in @amitkot 's ControlService.aidl file, it imports a self defined data type, BackendServiceState I guess, while in BUCK build process, the aidl program complains that it won't generate for parcelables or flattenables, so BUCK fails.\nAnd I also tried change src into src/, it makes no difference.\n. @sdwilsh And I find that inside BUCK source code, when executing the aidl program, it adds -b option, which will fail when trying to compile a parcelable, I think that's the root cause of this problem. Besides, the import_path should point to where .aidl files locate, not where .java file locate, although they could be the same.\n. @sdwilsh I create a reproduce project that could reproduce the AIDL support problem.\nInside the project root dir, execute buck build app/:src_debug, it fails with:\nbash\n/Users/piasy/src/BuckAidlDemo/app/src/main/aidl/com/github/piasy/buckaidldemo/Person.aidl:3 aidl can only generate code for interfaces, not parcelables or flattenables,\n/Users/piasy/src/BuckAidlDemo/app/src/main/aidl/com/github/piasy/buckaidldemo/Person.aidl:3 .aidl files that only declare parcelables or flattenablesmay not go in the Makefile.\nWhen I use my self built BUCK with the modification of removing the -b option passing to aidl executable, to execute ../buck/bin/buck build app/:src_debug, it fails with:\nbash\n/com/github/piasy/buckaidldemo/IMyAidlInterface.java:152: error: can't find symbol\npublic void sayHello(com.github.piasy.buckaidldemo.Person person) throws android.os.RemoteException;                                                  \n                                                   ^\nObviously the javac execution didn't find my self implemented Person class, but gradle works perfectly. I haven't dig into BUCK source code deeply so I can't figure out how to fix the problem myself, hope you guys could fix it soon. :)\n. Sounds cool, I'll try it.\n. @loveguag I have a better solution based on yours, see my demo project for full example:\n0 . modify AidlStep.java, comment off line 69:args.add(\"-b\") then build buck;\n1 . Put all self implemented parcelable class inside a directory under app/src/main/parcelable;\n2 . Add this rule into app/BUCK:\npython\nandroid_library(\n    name = 'parcelables',\n    srcs = glob([\n        'src/main/parcelable/**/*.java',\n    ]),\n)\n3 . Change the app_aidls rule to this:\npython\nandroid_library(\n    name = 'app_aidls',\n    srcs = gen_app_aidls,\n    deps = [':parcelables'], // add dependency to :parcelables\n)\n4 . (To enable gradle works well at the same time) Add this line into app/build.gradle's android closure:\ngradle\nandroid {\n    ...\n    sourceSets {\n        main.java.srcDirs += 'src/main/parcelable'\n    }\n}\n5 . Enjoy!\nBesides, I submitted a pr #708, hope @sdwilsh can process it soon.\nAfter BUCK could compile aidl correctly, I'll update OkBuck to get fully aidl support too.\n. In deed Android data binding has already been stable, when could BUCK support them?\n. @sdwilsh Thanks! But there is still a big problem on RetroLambda support...\n. @symphony2512 Do you set android_resource rule and set the right package value in your BUCK file? It seems that the generated R class doesn't locate in the same package with MainActivity.java.\n. @symphony2512 Do you set android_resource rule and set the right package value in your BUCK file? It seems that the generated R class doesn't locate in the same package with MainActivity.java.\n. @symphony2512 Yes, your BUCK file in same package with MainActivity.java defined a android_library rule, while it didn't depend on android_resource rule in BUCK file in apps/com/android/example, so the generated R class isn't visible in your MainActivity.java.\nYou should change your android_resource rule into this:\npython\nandroid_resource(\nname = 'res',\nres = 'res',\nassets = 'assets',\npackage = 'com.androi.example',\nvisibility = [\n'PUBLIC',\n],\n)\nand change your BUCK file in same package with MainActivity.java into this\n``` python\nandroid_library(\nname = 'app',\nsrcs = glob(['*.java']),\nvisibility = [ 'PUBLIC' ],\ndeps = [\nUncomment this if you want to include otto as a maven dependency\n':otto',\nimport resources\n'//res/com/androi/example:res',\n],\n)\n```\nB.T.W. if your project has gradle build files, and the gradle build system works well, you can try this OkBuck gradle plugin, which can generate the magic BUCK file for you, based on your gradle build system.\n. @symphony2512 Yes, your BUCK file in same package with MainActivity.java defined a android_library rule, while it didn't depend on android_resource rule in BUCK file in apps/com/android/example, so the generated R class isn't visible in your MainActivity.java.\nYou should change your android_resource rule into this:\npython\nandroid_resource(\nname = 'res',\nres = 'res',\nassets = 'assets',\npackage = 'com.androi.example',\nvisibility = [\n'PUBLIC',\n],\n)\nand change your BUCK file in same package with MainActivity.java into this\n``` python\nandroid_library(\nname = 'app',\nsrcs = glob(['*.java']),\nvisibility = [ 'PUBLIC' ],\ndeps = [\nUncomment this if you want to include otto as a maven dependency\n':otto',\nimport resources\n'//res/com/androi/example:res',\n],\n)\n```\nB.T.W. if your project has gradle build files, and the gradle build system works well, you can try this OkBuck gradle plugin, which can generate the magic BUCK file for you, based on your gradle build system.\n. @sdwilsh Before I report this issue, first time I didn't set android_sdk_proguard_config parameter, buck build app failed with the same error message above, then I tried to set android_sdk_proguard_config = 'none', nothing changed.\nBut the really strange things is, today when I remove android_sdk_proguard_config parameter, it works! and setting to 'optimized', it works too, but take more time to finish build, and setting to 'none' will fail with the error message above. Really strange...\n. @sdwilsh Before I report this issue, first time I didn't set android_sdk_proguard_config parameter, buck build app failed with the same error message above, then I tried to set android_sdk_proguard_config = 'none', nothing changed.\nBut the really strange things is, today when I remove android_sdk_proguard_config parameter, it works! and setting to 'optimized', it works too, but take more time to finish build, and setting to 'none' will fail with the error message above. Really strange...\n. @sdwilsh Yes I understand that, what bothered me was before I open this issue, it didn't work even when I didn't set android_sdk_proguard_config parameter, but after a week, it just works. Maybe I missed something, anyway, it works fine, that's good.\n. @sdwilsh Yes I understand that, what bothered me was before I open this issue, it didn't work even when I didn't set android_sdk_proguard_config parameter, but after a week, it just works. Maybe I missed something, anyway, it works fine, that's good.\n. Could it be the tab character problem? The BUCK file is a python script.\n. @symphony2512 How do your refer to examplesdk_aar ?\n. @symphony2512 Can you paste your full BUCK file?\n. @sdwilsh Thanks! I tried the cpu_filters parameter  and fix this problem. The only difference is the values should be one of [ARM, ARMV7, X86, X86_64, MIPS]\n. When I roll back to v2016.02.08.01, it works fine.\n. When I roll back to v2016.02.08.01, it works fine.\n. @marcinkosiba Updated!\n. I'll try it.\n. @marcinkosiba Updated!\n. @sdwilsh I just found the manifest_entries parameter of android_binary rule today, but I find out that we still need add minSdkVersion and targetSdkVersion into our android_manifest rule's skeleton, otherwise the android_manifest rule will fail. This is still not convenient :(  \nBut indeed manifest_entries add the flexibility of change the final apk we can build.\n. @sdwilsh I just found the manifest_entries parameter of android_binary rule today, but I find out that we still need add minSdkVersion and targetSdkVersion into our android_manifest rule's skeleton, otherwise the android_manifest rule will fail. This is still not convenient :(  \nBut indeed manifest_entries add the flexibility of change the final apk we can build.\n. @sdwilsh Updated! But inside this doc file, no indent inside <p> tag.\n. @sdwilsh Updated again, I use force push to avoid redundant commit.\n. Without rt.jar in classpath, the compiler fails with:\njava\ncom.sun.tools.javac.code.Symbol$CompletionFailure: class file for java.lang.invoke.MethodType not found.\nSee https://github.com/Piasy/OkBuck/issues/32 and https://github.com/Piasy/BuckJava8RetroLambdaDemo\nBesides, there are lots of test cases related to the changes, hope you fb guys could update related test cases (I'm not quite familiar with BUCK code base) :)\n. ping?\n. Since we could add rt.jar into -bootclasspath option via extra_arguments parameter, there is no need  for BUCK to do so.\n. @styurin Could this pr be merged?\n. @styurin Could this pr be merged?\n. @Coneko \n\nsince it comes from upstream\n\nI don't understand what does the upstream mean.\nGradle build could handle this problem automatically. Hope BUCK could work well on this too.\n. @Coneko \n\nsince it comes from upstream\n\nI don't understand what does the upstream mean.\nGradle build could handle this problem automatically. Hope BUCK could work well on this too.\n. Got it. But android gradle plugin works well in this case, I'll figure out how does it works.\n. Updated!\n. Yes right, I'll make a update, should I update another new commit?\n. ",
    "aneesv": "@Coneko I was trying to get buck's output from a script (php) , but as buck prints real time output one 1-3 lines i am unable to get the output\nAlso i would like to know how can i print some custom messages to bucks output (For some logging purpose) \n. @BruceZu @oconnor663 @Coneko \nThanks a lot , was really helpful \n. ",
    "saleehk": "@oconnor663 \n Is it possible to have a callback after every process is done,.?\nI want to get progress of total Process,\n. @oconnor663 \n Is it possible to have a callback after every process is done,.?\nI want to get progress of total Process,\n. You can use this simple hack,I am pretty sure there will be better ways,\nFor now you can try this\nshell\nimport os;\noutput_file = open(\"out\", \"a\") # note \"a\" for append mode\noutput_file.write(\"some stuff\\n\")\noutput_file.write(os.popen('echo $PATH').read())\n. @nickdai In my experience,It support print but we can't see output,\nWell said by @oconnor663 \n\nWhen buck executes the Python code in a BUCK file, that code prints JSON to stdout, which buck reads as build rules. So if you print inside of a BUCK file, you won't see the output, and you will probably confuse the JSON parser and cause errors. Printing to stderr should work though. You could also create a temporary file, have your Python code append to that, and tail -f it from another terminal. Bear in mind that your Python code will run when the build files are parsed, not when the build is actually happening.\n. @oconnor663  Thanks a Lot,\nthat is what i am looking for,In my case i building same project many times with some changes in some java files and some xml files of app source,\nBut libraries are always same,There is a bunch of libraries i am using(BTW Thanks for buck for amazing work, I tested all other available build system out there,Buck is many times faster than others),\nSo i want to make fast as possible to do this,Is there is any other tips that you can give me ..?\nRegards \nSaLi\n. @oconnor663  Thanks a Lot,\nthat is what i am looking for,In my case i building same project many times with some changes in some java files and some xml files of app source,\nBut libraries are always same,There is a bunch of libraries i am using(BTW Thanks for buck for amazing work, I tested all other available build system out there,Buck is many times faster than others),\nSo i want to make fast as possible to do this,Is there is any other tips that you can give me ..?\nRegards \nSaLi\n. I tried the [cache],\nI set cache dir as ~/buck-cache\nbut there is a problem arsing some time when i change the package name in Androidmanifest.xml\n\nError creating all assets directory in //:Wooapp_debug#aapt_package.\nbuck-out/bin/__unpack_PagingListView#aar_unzip__/assets\nBUILD FAILED: //:Wooapp_debug#aapt_package failed with exit code 1:\nsymlink_assets\nSome times it works \n. I tried the [cache],\nI set cache dir as ~/buck-cache\nbut there is a problem arsing some time when i change the package name in Androidmanifest.xml\nError creating all assets directory in //:Wooapp_debug#aapt_package.\nbuck-out/bin/__unpack_PagingListView#aar_unzip__/assets\nBUILD FAILED: //:Wooapp_debug#aapt_package failed with exit code 1:\nsymlink_assets\nSome times it works \n. @sdwilsh i added another pull request without formating code\nhttps://github.com/facebook/buck/pull/191\n. ",
    "dcposch": "Fixed a bug. Tests pass locally, hopefully Travis will be green now\n. Fixed a bug. Tests pass locally, hopefully Travis will be green now\n. Updated the documentation and added some basic tests\nThose tests use JUnit on Ant to verify that Buck can run TestNG and JUnit\n\n. Updated the documentation and added some basic tests\nThose tests use JUnit on Ant to verify that Buck can run TestNG and JUnit\n\n. ant travis passes locally\nThe build failure looks like some CI flakyness: https://travis-ci.org/facebook/buck/builds/34358860\n. ant travis passes locally\nThe build failure looks like some CI flakyness: https://travis-ci.org/facebook/buck/builds/34358860\n. Yeah looks like it failed because the Travis CI server it ran on was OOM:\n[junit] === STDOUT ===\n    [junit] Error occurred during initialization of VM\n    [junit] Could not reserve enough space for object heap\n. Yeah looks like it failed because the Travis CI server it ran on was OOM:\n[junit] === STDOUT ===\n    [junit] Error occurred during initialization of VM\n    [junit] Could not reserve enough space for object heap\n. Normally when you hit the JVM limit (-Xmx) it dies with either a \"GC Overhead Limit Exceeded\" or some other kind of OutOfMemoryError\nIt looks like what's happening here is that it's trying to launch a JVM (likely for a test runner) and can't--so the forked JVM isn't even starting\n. Normally when you hit the JVM limit (-Xmx) it dies with either a \"GC Overhead Limit Exceeded\" or some other kind of OutOfMemoryError\nIt looks like what's happening here is that it's trying to launch a JVM (likely for a test runner) and can't--so the forked JVM isn't even starting\n. Rebased on latest master. Squashed into three logical commits (one adds testng support, one adds docs, one adds unit tests). Build is green now!\n. Also addressed the comments--the extra logging is gone. Thanks for taking a look @LegNeato @sdwilsh !\n. Let me know if there's anything else I should change.\n. Thanks!\n. sweet\n. Cool thanks!\n. Cool thanks!\n. ",
    "bhamiltoncx": "Thanks for noticing this! I hit this as well when further tweaking the file format to include the date and time as well as the command ID. We're going to push a slightly different version of the fix soon.\n. I'll fix the 0 PASS/0 FAIL issue. Can you give a specific example of the output, in a github gist? If you could attach buck-out/log/buck-0.log it'd be nice as well.\n. Understood, I was just trying to get a bit more information so I could reproduce locally.\nI think I might have figured out one way this could happen, but I wanted to confirm in your logs. Can you check in your buck-out/log/buck-0.log to see if you have a line containing the string [error]?\nIf you see a line with [error] in the logs (say, like the following):\n[2015-06-24 13:24:07.430][error][command:7c93f5b0-b149-4917-beb6-7e9308b4ccfa][tid:27][com.google.common.eventbus.EventBus.buck-build-events] Could not dispatch event: com.facebook.buck.event.listener.ChromeTraceBuildListener@2ce8eb00 to public void com.facebook.buck.event.listener.ChromeTraceBuildListener.testStartedEvent(com.facebook.buck.rules.TestSummaryEvent$Started)\nit means we tried (and failed, due to a bug I'm fixing) to log an error to the console. Any time this happened, you'd see a visual glitch like the one you're describing.\n. Interesting. That's not quite the one I would have expected (that's only logged at the very end), but it might be related. I have a few fixes out for review now that I hope will help with this.\n. I just pushed a few fixes which should greatly improve the junit test console output. Please update to 899fcfe50805ecdff15a0a3165ba93effaca3352 or later and let me know if that helps.\n. @jiangty-addepar, any luck?\n. OK. We don't have any tests using testng, so it's unlikely we'll get to this very soon. I've been hammering on the test runner and I haven't seen this.\n. So the very basics have landed. You can build apple_binary() rules and apple_bundle() rules with one or more swift_library() dependencies. OS X, iOS simulator, and iOS device are all working.\nswift_library() rules currently cannot have any dependencies, and there isn't any Obj-C/Swift interop. But it's a start.\n. Good feedback, thanks. I think it makes sense to change the default level\nto info.\n2015\u5e7411\u670813\u65e5(\u91d1) 9:06 David Ostrovsky notifications@github.com:\n\nWell, that's sensible and i believe that the default value is wrong. I\nwould expect it to be at least info, if not even warn. I also think\ndeveloper shouldn't configure anything in .buckconfig to get sane default\nbehaviour, not to mention passing additional parameter(s) to hundreds of\njava_rule() invocations across the code base. So the only way to make it\nwork on latest master and restore the old behaviour is to monkey patch\njava_test rule:\n_buck_java_test = java_test\n  def java_test(_args, _kwargs):\n    _do_not_spam_std_out(kwargs)\n    _buck_java_test(_args, _kwargs)\ndef _do_not_spam_std_out(kwargs):\n  level = 'std_out_log_level'\n  if level not in kwargs:\n    kwargs[level] = 'INFO'\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/505#issuecomment-156489437.\n. Fix is coming shortly. Thanks for reporting, and sorry for the pain.\n. Looks OK to me, but @andrewjcg is the PEX master, I'll defer to him.\n. Thanks for reporting, and sorry for the problem.\n\nCan you just zip up the buck-out/log/ directory and include a link to that?\n. Thanks, @dborowitz. That error is helpful. It's not quite the same as the one I fixed; your error is a failure to shut down the Nailgun server.\nCould you possibly provide a zip of the buck-out/log/ directory as I mentioned?\n@davido, I have been trying and I've been unable to reproduce the problem. There's something about the build environment that triggers this issue. Here's the steps I tried; it worked fine.\nhttps://gist.github.com/bhamiltoncx/8d0469f46a59c6e935b4\n. I also tried a second time and induced the client to kill the server like @dborowitz's gist, but it didn't reproduce the error:\nhttps://gist.github.com/bhamiltoncx/20727de5cdc5c4b02ace\n. > The zip file is in the same gist as the console output.\nAh ha, thanks! I didn't realize you could attach binary files to gists, so my eyes just glanced over that. Reading through now.\n. Ah, there's no buck logs in there at all, since you did rm -f buck-out/log/buck*.log at the start of the command. :( Those logs are the ones I needed, since they were for the previously-running server.\nIt'd be great if you could reproduce this without the rm -f buck-out/log/buck*.log..\n. Ah hah. I bet this is a Linux vs. OS X issue. Let me test some more on Linux.\nBy the way, what version of Python are you running on this system?\n. OK, now I know what the problem is. Can you try this patch to Buck?\nhttps://github.com/facebook/buck/commit/ffaebc04f4108d4ff0ccf16fa41d6b9f495aeadf\nHere's my analysis.\nIn https://github.com/facebook/buck/commit/3c872ec36eba9847283e9270938882a6b94e246b , I changed the behavior of the Buck wrapper for the Nailgun client.\nPreviously, it would exec() the nailgun C client passing the command ng-stop when running buck kill. If the C client exited with an error code of 230, 229, or 227, it would silently swallow the error.\nThe C client would exit with error code 227 if the server ever closed the socket without sending an exit code\u2014and this is \"expected\" behavior whenever running the ng-stop command (it just kills the server and doesn't send an exit code to the client).\nWith the new Python client, I updated the check to look for a NailgunException with one of those error codes inside. However, the Python client currently raises socket.error with errno 104 (ECONNRESET), not NailgunException, when this happens.\n. Great! Fix should land today. Thanks again for the detailed report.\n. The last of the fixes for this issue are out for review internally. I hope to land them today.\n. Apologies for the delay. The fixes were reviewed last night and are landing now.\n. Thanks @k21. I should have re-run all the tests in German (I forgot to do it after your diff).\n@davido, the PythonBinaryIntegrationTest failure appears to be a separate problem.\n. Awesome stuff, great job! I left you some comments.\n. Eek. I suspect an LP64 vs. LLP64 issue in pybser. Summoning @wez..\n. I think the actual swift Xcode integration assumes a file named main.swift\nalways has the main method, and no other file does.\n2016\u5e748\u670811\u65e5(\u6728) 18:50 Nguyen Truong Tho notifications@github.com:\n\nI think you are talking about this flag: -parse-as-library\nhttps://github.com/nguyentruongtho/buck/blob/tho/objectivec_mix_swift/src/com/facebook/buck/swift/SwiftLibrary.java#L238-L241.\nI completely forgot about it when I used the new approach. The question is:\nhow do you know whether there is a main in objc source so that we can\nignore the implicitly one generated by swift.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/831#issuecomment-239342829, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AApAU4VNHhcLOwHAlw3iV7jjVWjw7vMcks5qe9FKgaJpZM4Jc_lA\n.\n. Nope, pretty sure this was working at one point in time.\nOn Wed, Feb 15, 2017 at 8:18 AM Shawn Wilsher notifications@github.com\nwrote:\n@bhamiltoncx https://github.com/bhamiltoncx, was this a known\nlimitation of the watchman glob?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1187#issuecomment-280056869, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AApAUzKBEYuCxlQOLyG69V5HzEgN79m3ks5rcyU2gaJpZM4MB4r0\n.\n. Maybe testsToRunPatternComponents?\n. I think it's what you want.\n. Hmm. Why doesn't this fail on the last line of the output? Shouldn't strTestCase be empty on the last line? Or is there no newline on the last line of the output?\n. This argument could get really long really fast (especially with dynamically-generated tests). That might send it over the kernel's command-line length limit (which differs by OS).\n\nRight now, __test_main__.py is using optparse. If you convert it to argparse (which should basically be a drop-in replacement), you can set fromfile_prefix_chars='@' and pass in the arguments via a temp file on disk.\nYou don't have to do that in this diff, but if you don't, please file a follow-up issue here and mention it in a comment.\n. A test to filter a test class in a module would be nice.\n. True. Anyway, we can leave that for another time.\nOn Fri, Feb 5, 2016 at 2:20 PM Shawn Wilsher notifications@github.com\nwrote:\n\nIn src/com/facebook/buck/python/PythonRunTestsStep.java\nhttps://github.com/facebook/buck/pull/646#discussion_r52080644:\n\n\nString[] testCase = strTestCase.split(\"#\", 2);\nif (testCase.length != 2) {\nthrow new RuntimeException(String.format(\n\"Bad test case name from python runner: '%s'\", strTestCase));\n}\n  +\nTestDescription testDescription = new TestDescription(testCase[0], testCase[1]);\nif (testSelectorList.isIncluded(testDescription)) {\ntestsToRunRe.add(Pattern.quote(testDescription.toString()));\n}\n}\n  +\nString testsToRunRegex = \"^\" + Joiner.on('|').join(testsToRunRe.build()) + \"$\";\n  +\nreturn getShellStepWithArgs(\n\"-o\", resultsOutputPath.toString(), \"-r\", testsToRunRegex).execute(context);\n\n\nNote that argparse is python2.7+, and Buck supports python2.6+. If we did\nthis, we'd have to import the package for 2.6.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/pull/646/files#r52080644.\n. Descriptions can use Arg classes which extend other Arg classes to get all their fields:\n\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/apple/AppleLibraryDescription.java#L454\n. ",
    "eboudrant": "Thanks, I don't really know where to modify, do you have an example ?\nI modified to this and still the same error :\n```\nandroid_resource(\n  name = 'res_android',\n  res = 'res',\n  package = 'android.support.v7.appcompat',\n  visibility = [\n    'PUBLIC',\n  ]\n)\nandroid_library(\n  name = 'android-support-v7-appcompat',\n  deps = [\n    ':res_android',\n    ':libs_android-support-v7-appcompat.r19.1.0.jar',\n    ':libs_android-support-v4',\n  ],\n  visibility = [\n    'PUBLIC',\n  ]\n)\nprebuilt_jar(\n  name = 'libs_android-support-v7-appcompat.r19.1.0.jar',\n  binary_jar = 'libs/android-support-v7-appcompat.r19.1.0.jar'\n)\nprebuilt_jar(\n  name = 'libs_android-support-v4',\n  binary_jar = 'libs/android-support-v4.r19.1.0.jar'\n)\n```\n```\nandroid_resource(\n  name = 'res',\n  res = 'res',\n  package = 'com.testpackage.app',\n)\nandroid_binary(\n  name = 'app',\n  manifest = 'AndroidManifest.xml',\n  target = 'android-17',\n  keystore = ':debug_keystore',\n  deps = [\n    ':res'\n    '//libraries/android-support-v7-appcompat/r19.1.0:android-support-v7-appcompat'\n    '//libraries/android-support-v7-appcompat/r19.1.0:res_android-support-v7-appcompat'\n  ],\n)\nkeystore(\n  name = 'debug_keystore',\n  store = 'debug.keystore',\n  properties = 'debug.keystore.properties',\n)\n```\n. Thanks, I don't really know where to modify, do you have an example ?\nI modified to this and still the same error :\n```\nandroid_resource(\n  name = 'res_android',\n  res = 'res',\n  package = 'android.support.v7.appcompat',\n  visibility = [\n    'PUBLIC',\n  ]\n)\nandroid_library(\n  name = 'android-support-v7-appcompat',\n  deps = [\n    ':res_android',\n    ':libs_android-support-v7-appcompat.r19.1.0.jar',\n    ':libs_android-support-v4',\n  ],\n  visibility = [\n    'PUBLIC',\n  ]\n)\nprebuilt_jar(\n  name = 'libs_android-support-v7-appcompat.r19.1.0.jar',\n  binary_jar = 'libs/android-support-v7-appcompat.r19.1.0.jar'\n)\nprebuilt_jar(\n  name = 'libs_android-support-v4',\n  binary_jar = 'libs/android-support-v4.r19.1.0.jar'\n)\n```\n```\nandroid_resource(\n  name = 'res',\n  res = 'res',\n  package = 'com.testpackage.app',\n)\nandroid_binary(\n  name = 'app',\n  manifest = 'AndroidManifest.xml',\n  target = 'android-17',\n  keystore = ':debug_keystore',\n  deps = [\n    ':res'\n    '//libraries/android-support-v7-appcompat/r19.1.0:android-support-v7-appcompat'\n    '//libraries/android-support-v7-appcompat/r19.1.0:res_android-support-v7-appcompat'\n  ],\n)\nkeystore(\n  name = 'debug_keystore',\n  store = 'debug.keystore',\n  properties = 'debug.keystore.properties',\n)\n```\n. Thanks for the help. fixed.\n. Thanks for the help. fixed.\n. ",
    "saadfarooq": "Cool. Thanks.\n. Cool. Thanks.\n. That works. Thanks.\nOne comment though. The while not keeps looping forever if there is no .buckversion' file.\n. That works. Thanks.\nOne comment though. Thewhile notkeeps looping forever if there is no.buckversion' file.\n. ",
    "byronwind": "Thanks your reply @dreiss.\nWe have a very large project. At present, we build the whole project with ant. In the build.xml,we hacked the dex-helper macro for generating secondary dex file. \nNow I am try build the project with Buck. We have many packages and classes,and also third-part libraries. So I want to define  secondary dex patterns, because in the secondary dex file, there is less classes than primary dex file.\n. Thanks your reply @dreiss.\nWe have a very large project. At present, we build the whole project with ant. In the build.xml,we hacked the dex-helper macro for generating secondary dex file. \nNow I am try build the project with Buck. We have many packages and classes,and also third-part libraries. So I want to define  secondary dex patterns, because in the secondary dex file, there is less classes than primary dex file.\n. @dreiss, I got it. I think I can customize it on my own. Thanks again.\n. @dreiss, I got it. I think I can customize it on my own. Thanks again.\n. ",
    "ficusk": "Did a little more digging this morning. Appears that \"android_empty\" is a sanitized version of \"android:empty\" but Buck doesn't know how to resolve this reference to the SDK. The only refs I see like this in the AntennaPod source are to android:empty, but this must have worked at some point, so maybe my environment is misconfigured somehow? Yak shaving continues.\n. Realized that these refs looked wrong to me, so I changed the two references in AntennaPod from \"@id/android:empty\" to \"@android:id/empty\" and everything builds now.\nIs \"@id/android:empty\" a legit way to refer to this? Not sure if this is a problem with Buck or AntennaPod. Happy to send a PR for the AntennaPod change, but it's a pretty trivial diff if that's the right fix.\n. ",
    "jhansche": "CLA has been signed.\n. @bolinfest, it is required, and the res dir does exist in the source aar file.  The problem is that the buck-out/bin/__unpack_$NAME$#aar_unzip__/res directory does not exist.  One popular example is the support-v4 library (r21):\n$ unzip -l buck-libs/support-v4-21.0.0-rc1.aar\nArchive:  buck-libs/support-v4-21.0.0-rc1.aar\n  Length     Date   Time    Name\n --------    ----   ----    ----\n      897  06-20-14 22:25   AndroidManifest.xml\n   656626  06-20-14 22:25   classes.jar\n        0  06-20-14 22:25   libs/\n   149188  06-20-14 22:25   libs/internal_impl-21.0.0-rc1.jar\n        0  06-20-14 22:25   assets/\n        0  06-20-14 22:25   aidl/\n        0  06-20-14 22:25   res/\n --------                   -------\n   806711                   7 files\nBut, the unpacked directory does not include the empty directories:\n$ ls -l buck-out/bin/__unpack_aars__support-v4-21.0.0-rc1#aar_unzip__/\ntotal 1296\n-rw-r--r--+ 1 jhansche  staff     897 Oct 14 18:21 AndroidManifest.xml\n-rw-r--r--+ 1 jhansche  staff  656626 Oct 14 18:21 classes.jar\ndrwxr-xr-x+ 3 jhansche  staff     102 Oct 14 18:21 libs\n-rw-r--r--+ 1 jhansche  staff       0 Oct 14 18:21 proguard.txt\nAnd that causes aapt to fail because the \"#aar_unzip__/res/\" directory is assumed to exist, even if it was empty in the source aar file.\nThat said, my patch only works some of the time...  Other times, it appears to have the same problem.  There must be some issue somewhere that causes the unzip process (or something that reuses the cache) to ignore empty directories.\nI admit I've only been playing with Buck for a couple days so far, so I'm still trying to wrap my head around some of the processes.\n. Investigating this further, it appears that the issue is not specific to unpacking, but using the cache mode.\nFor example, I added this to libs/BUCK of the quickstart project (and used it with deps=['//libs/support-v4']):\npython\nandroid_prebuilt_aar(\n    name='support-v4',\n    aar='support-v4-21.0.0-rc1.aar',\n    visibility=['PUBLIC']\n)\nI then used this command line repeatedly, and it works every time:\n$ buck clean && buck build //libs:support-v4 && ls -d buck-out/bin/libs/__unpack_support-v4#aar_unzip__/res/\nShutting down nailgun server...\nUsing watchman.\nUsing buckd.\nUsing buckd.\n[-] PROCESSING BUCK FILES...FINISHED 0.2s\n[-] BUILDING...FINISHED 0.4s (5/5 JOBS)\nLog:\nNo Android platform target specified. Using default: Google Inc.:Google APIs:19\nbuck-out/bin/libs/__unpack_support-v4#aar_unzip__/res/\nI then add the cache.mode=dir entry to .buckconfig, and on the second (and subsequent) builds, the res/ directory is absent:\n[cache]\n    mode = dir\n```\n$ buck clean && buck build //libs:support-v4 && ls -d buck-out/bin/libs/unpack_support-v4#aar_unzip/res/\nShutting down nailgun server...\nUsing watchman.\nUsing buckd.\nUsing buckd.\n[-] PROCESSING BUCK FILES...FINISHED 0.2s\n[-] BUILDING...FINISHED 0.4s (5/5 JOBS)\nLog:\nNo Android platform target specified. Using default: Google Inc.:Google APIs:19\nbuck-out/bin/libs/unpack_support-v4#aar_unzip/res/\n$ buck clean && buck build //libs:support-v4 && ls -d buck-out/bin/libs/unpack_support-v4#aar_unzip/res/\nShutting down nailgun server...\nUsing watchman.\nUsing buckd.\nUsing buckd.\n[-] PROCESSING BUCK FILES...FINISHED 0.2s\n[-] BUILDING...FINISHED 0.2s (5/5 JOBS)\nLog:\nNo Android platform target specified. Using default: Google Inc.:Google APIs:19\nls: buck-out/bin/libs/unpack_support-v4#aar_unzip/res/: No such file or directory\n```\nSo it seems that the problem is when unpacking the files from the buck cache.  This patch does not resolve the issue.\n. @sdwilsh: buck version e96d2402b219294aa9a5c13d786f51d088ff86b5 was doing it.  I ended up setting the NO_BUCKD env var, because I wanted to be sure that these hanging processes weren't impacting clean builds while trying to get my project up and running with Buck.\n. It looks like this is done intentionally in MergeAndroidResourcesStep#writeEmptyRDotJavaForPackages().  It seems the only reason this is done, however, is because the JavacStep has already been created (expecting the R.java paths to exist for each package that ultimately has no resources), before MergeAndroidResourcesStep can conclude that R.txt was empty to begin with:\njava\n    for (String rDotJavaPackage : rDotJavaPackages) {\n      Path outputFile = getPathToRDotJava(rDotJavaPackage);\n      filesystem.mkdirs(outputFile.getParent());\n      filesystem.writeContentsToPath(\n          String.format(\"package %s;\\n\\npublic class R {}\\n\", rDotJavaPackage),\n          outputFile);\n    }\nIf, however, that bogus R.java file is simply an empty file, everything works fine;  the cache does not collide, the bogus/empty R.class is not created, and proguard and dex do not complain about duplicate classes:\njava\n    for (String rDotJavaPackage : rDotJavaPackages) {\n      Path outputFile = getPathToRDotJava(rDotJavaPackage);\n      filesystem.mkdirs(outputFile.getParent());\n      filesystem.writeContentsToPath(\n          String.format(\"\"),\n          outputFile);\n    }\n. ",
    "joshzana": "Bringing this up again - this is currently breaking my code.  I want a single codebase that is buildable by both gradle and buck users.\nMy code depends on appCompat-v7 and consumes the following resource:\nandroid.support.v7.appcompat.R.attr.colorPrimary\nIf I fully specify it like that, buck is happy, but gradle is not:\nError:(38, 55) error: package android.support.v7.appcompat.R does not exist\nFor the gradle build, I have to have:\ncom.mypackagename.R.attr.colorPrimary\nBut then buck is unhappy:\nerror: cannot find symbol\n        int[] attrs = { com.mypackagename.R.attr.colorPrimary, android.R.attr.actionBarSize };\n                              ^\nWhich I suspect is because in gradle land this resource actually gets merged into my own project's package.  \nThis issue has been open for a while.  Can we get an update?  Any plans to address this?\n. I would much prefer for that logic to live in the manifest with the \"tools:*\" directives.  In gradle these are called \"markers\" and they instruct the merger how to deal with conflicts:  http://tools.android.com/tech-docs/new-build-system/user-guide/manifest-merger#TOC-Markers    These are useful for more than just name (eg. icon, label, etc on your debug variant) so duplicating all of that in a general seems duplicative.\nDo you think this is something buck could support?\n. Thanks!  Does .buckjavaargs get used for proguard invocations?  It looks like it does not:\nwrite_proguard_command_line_parameters\njava -Xmx1024M -jar /Users/joshzana/Library/Android/sdk/tools/proguard/lib/proguard.jar ...\nWith the .buckjavaargs I get past dx, but then crash in proguard.\n. Nice!  That got me past proguard, but not dx: \nUNEXPECTED TOP-LEVEL ERROR:\njava.lang.OutOfMemoryError: GC overhead limit exceeded\n    at com.android.dx.dex.code.RopTranslator$TranslationVisitor.visitPlainInsn(RopTranslator.java:551)\n    at com.android.dx.dex.code.RopTranslator$LocalVariableAwareTranslationVisitor.visitPlainInsn(RopTranslator.java:835)\n    at com.android.dx.rop.code.PlainInsn.accept(PlainInsn.java:80)\n    at com.android.dx.rop.code.InsnList.forEach(InsnList.java:76)\n    at com.android.dx.dex.code.RopTranslator.outputBlock(RopTranslator.java:262)\n    at com.android.dx.dex.code.RopTranslator.outputInstructions(RopTranslator.java:233)\n    at com.android.dx.dex.code.RopTranslator.translateAndGetResult(RopTranslator.java:212)\n    at com.android.dx.dex.code.RopTranslator.translate(RopTranslator.java:105)\n    at com.android.dx.dex.cf.CfTranslator.processMethods(CfTranslator.java:317)\n    at com.android.dx.dex.cf.CfTranslator.translate0(CfTranslator.java:137)\n    at com.android.dx.dex.cf.CfTranslator.translate(CfTranslator.java:93)\n    at com.android.dx.command.dexer.Main.processClass(Main.java:729)\n    at com.android.dx.command.dexer.Main.processFileBytes(Main.java:673)\n    at com.android.dx.command.dexer.Main.access$300(Main.java:83)\n    at com.android.dx.command.dexer.Main$1.processFileBytes(Main.java:602)\n    at com.android.dx.cf.direct.ClassPathOpener.processArchive(ClassPathOpener.java:284)\n    at com.android.dx.cf.direct.ClassPathOpener.processOne(ClassPathOpener.java:166)\n    at com.android.dx.cf.direct.ClassPathOpener.process(ClassPathOpener.java:144)\n    at com.android.dx.command.dexer.Main.processOne(Main.java:632)\n    at com.android.dx.command.dexer.Main.processAllFiles(Main.java:510)\n    at com.android.dx.command.dexer.Main.runMonoDex(Main.java:280)\n    at com.android.dx.command.dexer.Main.run(Main.java:246)\n    at com.android.dx.command.dexer.Main.main(Main.java:215)\n    at com.android.dx.command.Main.main(Main.java:106)\nSeems to me there should be one config on .buckconfig that controls all of these, instead of a setting per tool.\n. ",
    "sean-kenny": "@joshzana you may want to take a look at https://github.com/facebook/buck/issues/643, we also had the same requirement of getting something to work in buck and bazel and were having a terrible time with letting go of resource conventions from gradle, specifically the simplicity of the resource merging it provides. So, we made a change that allowed an options for merging R.txt contents for android resources and deps. Using this approach we were able to build a very large app (with many many related android aar/project libraries), and still support both buck and gradle simultaneously with the same R naming conventions. \n. @prince-gill I took a quick shot at a fix in pr #680. This seems to work for me and allows building a project even if the aar does not contain a classes.jar file. @sdwilsh let me know if you think this is an alright approach...I tried adding a TouchStep to create the classes.jar file as well, but that resulted in other problems during the AccumulateClassNamesStep where the file is expected to be a zip... If we want to move ahead I can back fill an integration test :smile: \n. Yes @sdwilsh you are entirely correct - changing R.string.lib_two_value to com.buckbuild.scenario.lib2.R.string.lib_two_value will allow buck build //libs/lib1:lib to run successfully.\nIt sounds like this is expected behavior that is a known deviation from how Gradle packages lib resources. It's a bit of a hindrance for us since our libraries currently heavily utilize the 'convenience' of the resource merging into the library's R file...so we would need to do additional code changes to reference the full paths to get things up and running.\nDo you think there is room for a feature to enable 'gradle-like' merging of resources. It could possibly help other developers with ease of adoption when converting from gradle to buck.\nI was hoping the resource_union_package would do the trick and couldn't quite figure out why the lib1 library builds but the app can't find the resource at runtime...@dreiss would you be able to shed any light on why the unioned resources of lib1 can't be found when running the app after using the resource_union_package and adding it to the //app:app android_binary target? It ends up yielding this exception when the app starts:\nE/AndroidRuntime( 2011): FATAL EXCEPTION: main\nE/AndroidRuntime( 2011): Process: com.buckbuild.scenario.buckscenariolibraryresourcemerging, PID: 2011\nE/AndroidRuntime( 2011): java.lang.NoSuchFieldError: No static field lib_two_value of type I in class Lcom/buckbuild/scenario/lib1/R$string; or its superclasses (declaration of 'com.buckbuild.scenario.lib1.R$string' appears in /data/app/com.buckbuild.scenario.buckscenariolibraryresourcemerging-1/base.apk)\nE/AndroidRuntime( 2011):    at com.buckbuild.scenario.lib1.subpackage1.LibOneHelper.getLibTwoString(LibOneHelper.java:10)\nE/AndroidRuntime( 2011):    at com.buckbuild.scenario.buckscenariolibraryresourcemerging.MainActivity.onCreate(MainActivity.java:18)\nE/AndroidRuntime( 2011):    at android.app.Activity.performCreate(Activity.java:5990)\nE/AndroidRuntime( 2011):    at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1106)\nE/AndroidRuntime( 2011):    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2278)\nE/AndroidRuntime( 2011):    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2387)\nE/AndroidRuntime( 2011):    at android.app.ActivityThread.access$800(ActivityThread.java:151)\nE/AndroidRuntime( 2011):    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1303)\nE/AndroidRuntime( 2011):    at android.os.Handler.dispatchMessage(Handler.java:102)\nE/AndroidRuntime( 2011):    at android.os.Looper.loop(Looper.java:135)\nE/AndroidRuntime( 2011):    at android.app.ActivityThread.main(ActivityThread.java:5254)\nE/AndroidRuntime( 2011):    at java.lang.reflect.Method.invoke(Native Method)\nE/AndroidRuntime( 2011):    at java.lang.reflect.Method.invoke(Method.java:372)\nE/AndroidRuntime( 2011):    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:903)\nE/AndroidRuntime( 2011):    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:698)\n. Thanks @sdwilsh, the plot thickens around this hidden flag! Let me try it out, and see where I can get with this. \n. Hi @sdwilsh I tried for a long to get our app to build with the hidden resource_union flags, but couldn't find a combination that would allow us to build with buck and gradle at the same time. Basically when using the resource_union for a library the dummyrdotjava contained the resource identifier, but the R.txt did not and this caused issues when using the library as a dep of an android_binary. To resolve this I created a commit that selectively allows resource_union for an android_resource deps, creating a merged R.txt. With this in place I am able to build the sample project, as well as a much more complicated project we have here with minimal code changes. Love to know what you think about this.\n. Hi @sdwilsh I tried for a long to get our app to build with the hidden resource_union flags, but couldn't find a combination that would allow us to build with buck and gradle at the same time. Basically when using the resource_union for a library the dummyrdotjava contained the resource identifier, but the R.txt did not and this caused issues when using the library as a dep of an android_binary. To resolve this I created a commit that selectively allows resource_union for an android_resource deps, creating a merged R.txt. With this in place I am able to build the sample project, as well as a much more complicated project we have here with minimal code changes. Love to know what you think about this.\n. right now we aren't affected by the need to include a transitive dependency to libc, rather we have a series of libraries (mostly theming related - so lots of resources) that rely on dependent library resources (liba->libb, liba->libc) being available from liba.\n. right now we aren't affected by the need to include a transitive dependency to libc, rather we have a series of libraries (mostly theming related - so lots of resources) that rely on dependent library resources (liba->libb, liba->libc) being available from liba.\n. it's actually meant to be very gradleesque. We were seeing with libraries built with buck that they were never including merged resources txt so for the case of liba->libb liba would not contain the resources of libb in it's R.txt file, and this would lead to a runtime exception since the R.class generated for liba did not contain the proper resource entry to a resource in libb. Gradle however can build and run the same liba->libb project just fine. Is there perhaps another issue going on here where MergeResourcesSources step is not included as part of liba->libb android library build scenarios? Although the full resource merging wouldn't be as cheap -  if the functionality exists, we will use it. \n. Yes @marcinkosiba that is true, it did work appropriately for this sample if we fiddled with the union packages for both android_library and android_binary. This approach didn't work for our main app though because we still had resources in the main app (not in library), that needed to exist as well, so we couldn't resource_union_package in android_binary to a single dependent library package (our.app.R was missing resources in this case). \nI've been playing around a lot with MergeAndroidResourceSources and trying to implement something within AndroidResourceDescription to gather resource deps of an AndroidResource and perform a merge. I thought this approach would be nice because then we are basically just adding another optional step to creating an AndroidResource as opposed to changing underlying details of MIniAppt...\nI have something working, but when the aapt package command is run from android_binary, it results in the creation of duplicate attributes errors. This is due to the aapt package -S entries (aapt package -S /app/res, -S /lib1/res, -S .lib2/res) for each res dep of android_binary having a merged copy of all the resources leading to attribute collisions...I could def see this approach working if there was a way to exclude libraries from being included in aapt package -S entries.  We would still however need each library to have an R.class file generated...I've been able to exclude res with provided_deps which removes them from having -S entries added during the aapt package process, but this also results in the final R.class files never being generated for each library that is excluded via provided_deps, so runtime exceptions eventually occur when the app is launched (cant find some.library.R$layout for example). I could share some code around this approach if you think it might be more promising.\nAnyways, for now, I think I'll try to revisit the first approach again and add tests as you requested.\n. The unioned resources should receive a new id since the id could be taken in the current set, so I opted to use the IfNotPresent methods which generate them.\n. The unioned resources should receive a new id since the id could be taken in the current set, so I opted to use the IfNotPresent methods which generate them.\n. ok - will do @marcinkosiba.\n. @marcinkosiba I've been experimenting a bit with alternative approaches via MergeAndroidResourceSources, but can't seem to find something that works as easily as replacing the R.txt values like what is done here. I'll clean this up a bit and add tests. More details added to #643 \n@sdwilsh I can see you not wanting to add docs for this, it worked really nicely for use to be able to build our app, but it's because we rely very much on the gradle library/binary resource merging techniques.\n. @marcinkosiba I changed the approach a bit based on your suggestions, and added unit tests. \n. @marcinkosiba I changed the approach a bit based on your suggestions, and added unit tests. \n. Thank for the feedback @marcinkosiba I made some additional changes and pushed a new commit!\n. Great, let me know if you need anything else with this!\n. @marcinkosiba, I forgot to make sure this was linted properly, so I just pushed a change to make sure all the lint issues are fixed.\n. @marcinkosiba :+1: on adding the license headers\n. @marcinkosiba :+1: on adding the license headers\n. @DanielGrech @marcinkosiba I verified that the values for Key and Certificate could be null if an invalid alias is provided, and added null pointer checks. When the checks are in place and in invalid alias is provided I see (instead of silent failure):\nBUILD FAILED: //app:app failed on step apk_builder with an exception:\nThe keystore [/Users/seank/repo/spotify/buck-tests/BuckScenarioLibraryResourceMerging/app/debug.keystore] key.alias [androiddebugkeyasdfadsfs] does not exist or does not identify a key-related entry\njava.lang.NullPointerException: The keystore [/Users/seank/repo/spotify/buck-tests/BuckScenarioLibraryResourceMerging/app/debug.keystore] key.alias [androiddebugkeyasdfadsfs] does not exist or does not identify a key-related entry\n    at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:251)\n    at com.facebook.buck.android.ApkBuilderStep.createKeystoreProperties(ApkBuilderStep.java:191)\n    at com.facebook.buck.android.ApkBuilderStep.execute(ApkBuilderStep.java:122)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:63)\n    at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:1069)\n    at com.facebook.buck.rules.CachingBuildEngine.access$10(CachingBuildEngine.java:1052)\n    at com.facebook.buck.rules.CachingBuildEngine$4.apply(CachingBuildEngine.java:460)\n    at com.facebook.buck.rules.CachingBuildEngine$4.apply(CachingBuildEngine.java:1)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n    at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n    at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n. @DanielGrech @marcinkosiba I verified that the values for Key and Certificate could be null if an invalid alias is provided, and added null pointer checks. When the checks are in place and in invalid alias is provided I see (instead of silent failure):\nBUILD FAILED: //app:app failed on step apk_builder with an exception:\nThe keystore [/Users/seank/repo/spotify/buck-tests/BuckScenarioLibraryResourceMerging/app/debug.keystore] key.alias [androiddebugkeyasdfadsfs] does not exist or does not identify a key-related entry\njava.lang.NullPointerException: The keystore [/Users/seank/repo/spotify/buck-tests/BuckScenarioLibraryResourceMerging/app/debug.keystore] key.alias [androiddebugkeyasdfadsfs] does not exist or does not identify a key-related entry\n    at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:251)\n    at com.facebook.buck.android.ApkBuilderStep.createKeystoreProperties(ApkBuilderStep.java:191)\n    at com.facebook.buck.android.ApkBuilderStep.execute(ApkBuilderStep.java:122)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:63)\n    at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:1069)\n    at com.facebook.buck.rules.CachingBuildEngine.access$10(CachingBuildEngine.java:1052)\n    at com.facebook.buck.rules.CachingBuildEngine$4.apply(CachingBuildEngine.java:460)\n    at com.facebook.buck.rules.CachingBuildEngine$4.apply(CachingBuildEngine.java:1)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\n    at com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\n    at com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\n    at com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n. Right, HumanReadableException sounds better. Will also place a test in.\n. @sdwilsh changed to an HumanReadableException and added an integration test to make sure this is handled.\n. @sdwilsh I modified a line to pass the linter\n. @sdwilsh I believe I have resolved the buck dep issue.\n. @sdwilsh I believe I have resolved the buck dep issue.\n. @marcinkosiba I'll see about moving the functionality to JarDirectoryStepHelper, and will def add an integration test.\n. @marcinkosiba I'll see about moving the functionality to JarDirectoryStepHelper, and will def add an integration test.\n. @marcinkosiba I moved some of the code to JarDirectoryStepHelper and added an integration test so this doesn't regress in the future.\n. @marcinkosiba I moved some of the code to JarDirectoryStepHelper and added an integration test so this doesn't regress in the future.\n. ah, i was running/building the test with ant. should be fixed now!\n. ",
    "grumpyjames": "Who is this @mread guy that keeps referencing me? I have a faint memory of someone of that name, but it's starting to fade. Joking aside, it looks like we deleted LMAX-Exchange/buck in a fit of excitement at being close enough to stock buck to not need our own fork.\n@marcinkosiba : Please feel free to close this, we haven't seen this problem recently, to the best of my knowledge\n. Continuing on the #439 theme (probably safe to assume anything else from me will be along such lines; will make any exceptions explicit).\nIf this looks OK, will move on to JavaLibrary and friends. Once that's out, the way forward will hopefully be a little clearer. \n. I think this is broken in travis because of the current state of upstream.\n. Regarding travis: could it be oomkiller?\n. One thing we are not sure about is the implementations of RuleKeyAppendable in JavacStepFactory and the two JavacOptionsAmender implementations. If what we've done there is wrong or unusual, some further guidance would be much appreciated :-)\n. You are quite right. That's interesting, because I remember changing that test having seen it fail (the test also acts as a detector for any part of the key changing because of how it's written), and ./bin/buck test passes for me locally (indeed, that test passes for me in intellij). I will take a closer look to see what is missing here.\nEDIT: the test in question actually looks at the diff, I'm thinking about the dependencyAdded test, which looks at the whole SHA.\n. So, it's good that this failed, as it made me wonder why it wasn't failing anyway, and it's because we are incorrectly implementing RuleKeyAppendable in JavacStepFactory (we omit the call to JavacOptionsAmender's impl). Further changes to follow.\nI am still somewhat puzzled as to why it fails in travis and not locally, investigations continue.\n. Thanks for the speedy review. Will* have to level up my github fu to 'understand how to create dependent pull requests', but that sounds like a worthy quest if it creates a cleaner commit log in the real master.\nRegarding travis: if I perform the same steps as it does (from a fresh checkout) on this machine, the build passes.\nThe diff it finds (//:java_lib_1#abi versus //:java_lib_1) is hard for me to explain, particularly given that the previous version (before my change) also contains the \"#abi\" in the expectations, and the key changes ought to be below that level. I will continue to add print statements to diff_rulekeys.py locally in the hope of understanding, but any more specific hints would be greatly appreciated.\n* EDIT: Well, maybe not, actually. The changes you mention actually look pleasantly orthogonal, so expect separate PRs for those shortly.\n. Understood. Closing this, will reconstruct the agnostification (definitely a word) changes in a separate PR later.\n. Understood. Closing this, will reconstruct the agnostification (definitely a word) changes in a separate PR later.\n. Good spot; will split those out and resubmit.\n. Is there anything we can do to help get this reviewed? We don't want to move too far from tip, at the same time though, we're really keen to make some progress. Let me know where to send the cake ;-)\n. That sounds great, thanks again.\n. I think we're probably conflicting with some of the work in DiffRuleKeysIntegrationTest here; will close this/reopen once we've rebased.\n. This isn't a candidate to be merged, more an opportunity for a discussion. This change doesn't even pass all the tests (it breaks DefaultJavaLibraryTest).\nSo, some context. We are adding groovy_library support, and we find that java libraries have the ability to have source files that are in fact zips full of sources (there's a meme in there somewhere). We would want the code that does that to be common between groovy and java code if we were to support it in groovy_library; this change starts to pull up that code to somewhere where it can be shared.\nProblems with this change\nWe corrupt CompileStepFactory, splitting it into two methods that both have the same if. Given the behaviour of the optionsAmender is unbounded, not invoking it before registering artifacts is a cause for concern. \nWe potentially break FatJar if it requires the same 'sources might be in zips' constraint (although if this is supported, it isn't tested).\nWe shift from having a nice series of small steps into a place where we have one giant (monster, in fact) step.\nWe potentially make Jsr199Javac based builds slower, as we do a real filesystem unzip rather than unzipping into a memory based file representation\nAlternative Options\n\nWe could unzip/move all source files to the working directory, then just get the compile steps to compile any .java file it finds in there. This way we can maintain the separate steps and just add a 'get all my source files into this folder with no subfolders please' step. We worry though that half the point of the Jsr199Javac is that it doesn't require any filesystem fiddling.\nOn the assumption we're going to start with ExternalGroovyc, we could share only the code from ExternalJavac; this preserves pretty much all the existing behaviour and we just pull up getExpandedSourcePaths to somewhere common.\n\nConclusions\n\nWe're probably not going to give our initial groovy_library this feature. \nIf we were to add it later, we'd probably lean towards option 2. \n\nRegarding conclusion 2: This PR exists to provide a place for someone to say \"actually, using option 1 is better because...\" or \"have you consider far superior option (...)\".\nAny feedback would be lovely, but it isn't at all urgent unless there is disagreement over conclusion 1.\nThanks,\nJames.\n. Thanks for taking the time to read it - we'll get on with our first go at groovy_library.\n. This is on Fedora 20.\n. One area of potential controversy is how we locate the groovy compiler, and the fact that it implicitly picks up its java from the environment's JAVA_HOME. We intend to revisit this as we add cross compilation, but if you feel it ought to go in with this change (or have a different view), let us know!\n. We will definitely add documentation, but we'd prefer not to yet. The next step (to introduce cross compilation with javac) makes a breaking change to how groovy_library is configured. We'd rather get that change in and document afterward rather than expose things now only to break them in the next release.\nWe can try to backport the config change to the initial version and document earlier if you want - let us know if that's your preferred route and we'll get to it ASAP.\n. Starting to worry that these somewhat abstract changes are a bit meaningless without the context; so I've been pushing the next pieces of work (quite spiky, not well tested, naming not well considered) to https://github.com/grumpyjames/buck/tree/spike/lmax-beta-2 .\nTip there at the moment shows one possible vision of a world where there is JvmLibraryDescription with Java/Groovy policies used to configure it. Groovy also gains java cross-compilation.\n(It also has groovy tests, and a horrible hack that stops us hitting a classloader bug that we don't understand yet, but there you go)\n. Thanks for reviewing. I'll take another look at the sourcepath option handling and add further commit(s) here.\n. So, I think I addressed everything, apart from switching from ProcessBuilder to ProcessExecutor, which I'll look at in a separate commit.\nI had a further look at sourcepath option; it's only ever set from within AbstractJavacOptions, and the setting it provides is incompatible with how cross compilation works. Quietly ignoring it sounds like the right thing to do, so I've updated the comment to explain.\n. A few caveats here:\n- I have absolutely no idea what I'm doing, so most of the structure has been heavily borrowed from the existing doc.\n- I've not tried too hard to share the content of the documentation between groovy_library and java_library yet.\n. Ta for the review! Expect an improved version early next week.\n. I think I got all of them this time. Thanks for the continuing scrutiny; it's clearly necessary :-)\n. I think I got all of them this time. Thanks for the continuing scrutiny; it's clearly necessary :-)\n. Unintended consequence of moving between machines at work, I think; bit annoying to have left the inconsistency in the history though, sorry! Both addresses are relatively public so not a big deal; will prod the config of the checkout I'm using now back to the gmail account. Thanks for the heads up.\n. I'm only semi-serious about this being a PR; there's quite a lot wrong with it that I'd probably want to address before expecting it to ship:\n- the change feels big; it could perhaps be split into extracting JvmLibraryDescription and then porting GroovyLibraryDescription into it. This feels a little artificial though, as it's the existence of GroovyLibraryDescription that really drives the change.\n- it doesn't feel that well tested on the groovy side; but then I'm not sure the features we gain from this change are that well tested for JavaLibraryDescription either\n- some of the names are terrible (confession: I have an irrational hatred for concrete inheritance and avoid it at all costs, aspects of this change might be improved by using it, but I couldn't bring myself to do it yet)\n- it might be too soon to do this change ; it's not clear how Kotlin/Scala library descriptions will want to vary, so this might be the wrong abstraction for them. That said, it shouldn't be too difficult to make more aspects of JvmLibraryDescription configurable (one only needs to move the behaviours to JvmLibraryConfigurable)\nThere's probably other stuff wrong with it that I haven't thought of, too.\nLet me know what you think and we can discuss how we want to move forward!\n. I'm only semi-serious about this being a PR; there's quite a lot wrong with it that I'd probably want to address before expecting it to ship:\n- the change feels big; it could perhaps be split into extracting JvmLibraryDescription and then porting GroovyLibraryDescription into it. This feels a little artificial though, as it's the existence of GroovyLibraryDescription that really drives the change.\n- it doesn't feel that well tested on the groovy side; but then I'm not sure the features we gain from this change are that well tested for JavaLibraryDescription either\n- some of the names are terrible (confession: I have an irrational hatred for concrete inheritance and avoid it at all costs, aspects of this change might be improved by using it, but I couldn't bring myself to do it yet)\n- it might be too soon to do this change ; it's not clear how Kotlin/Scala library descriptions will want to vary, so this might be the wrong abstraction for them. That said, it shouldn't be too difficult to make more aspects of JvmLibraryDescription configurable (one only needs to move the behaviours to JvmLibraryConfigurable)\nThere's probably other stuff wrong with it that I haven't thought of, too.\nLet me know what you think and we can discuss how we want to move forward!\n. Well, that's jolly exciting; not least because scala_test related changes mirror what I have locally to get groovy_test to work :-). \nIt looks like this duplicates as much as groovy library does, but has a few differences around the deps related keys contained in the Arg. It still has to call the giant DefaultJavaLibrary constructor though, and that's what I want to have happen in only a single place.\nI'll wait for that to land and then rejig this.\n. Thanks for the writeup; glad the work we've been doing was a help :-)\nI'm hoping we can share even more code between java/groovy/scala. I worry that will preclude the scala side from being able to grow into something that approaches the usefulness of sbt/zinc, though. My temptation is to tie attempt to tie the three together for the time being despite that. It would make the job of Kotlin folks (who I don't think suffer the same compiler woes as scala folk, afaik) even easier, and I suspect that if we wanted to add friendlier scala support to buck, it would probably end up looking completely different to DefaultJavaLibrary anyway.\nI'll see how things look when your change lands in master (which it did between me starting this comment and actually posting it, woot.)\n. Thanks for the writeup; glad the work we've been doing was a help :-)\nI'm hoping we can share even more code between java/groovy/scala. I worry that will preclude the scala side from being able to grow into something that approaches the usefulness of sbt/zinc, though. My temptation is to tie attempt to tie the three together for the time being despite that. It would make the job of Kotlin folks (who I don't think suffer the same compiler woes as scala folk, afaik) even easier, and I suspect that if we wanted to add friendlier scala support to buck, it would probably end up looking completely different to DefaultJavaLibrary anyway.\nI'll see how things look when your change lands in master (which it did between me starting this comment and actually posting it, woot.)\n. Further commits to dedupe between (Java/Groovy/Scala)TestDescription and add documentation to follow\n. Further commits to dedupe between (Java/Groovy/Scala)TestDescription and add documentation to follow\n. Hey, it's still January, it takes me a while to get these things straight :P\n. Hey, it's still January, it takes me a while to get these things straight :P\n. I can definitely give it a go :-)\nThe implementation of groovy_test is so embarrassingly similar to java_test that I don't think it is likely to be to blame. Therefore, my first guess is that I've done something unidiomatic in the tests that's causing some sort of corruption when we create the project workspace (those prebuilt jars definitely aren't checked in empty, or the build would always fail).\nI can spot one unnecessary thing immediately: the verify calls are completely pointless; I'll remove them.\nOther than that, the test looks reasonable; certainly it appears very similar to other integration tests (some of the Aapt tests create and setup the workspace in a @Before, for example)\nThis makes me think that, however unlikely, there might actually be something wrong with the implementation. I'll take a closer look to see if there's any differences between Groovy Test/Java Test that I've missed. It's possible this might be uncovering a bug somewhere in the groovy library implementation too, I suppose.\nSide note: looks like I have something else to fix in GroovycToJarStepFactory\n\n[2016-01-20 11:09:06.173][warn ][tid:143][com.facebook.buck.rules.RuleKeyBuilder] Attempting to add absolute path to rule key. Only using file name: /usr/share/groovy/bin/groovyc\n\n. Looking a bit at how those jars are supposed to get into:\n\n/tmp/buck-64555de1-6bb7-43bf-a9a6-aa22c4472bed/test/com/facebook/buck/jvm/groovy/__java_test_groovy_tmp__/junit7935749327569884613/buck-out/gen/com/example/spock/spock-core.jar.\n\nIt looks like prebuilt_jar is supposed to do this here (PrebuiltJar:235):\n\nsteps.add(CopyStep.forFile(getProjectFilesystem(), resolvedBinaryJar, copiedBinaryJar));\n\nThat really does suggest that we've managed to end up with empty jar files in our temporary project folder. I'll go and check a few of the other test rules to see if I've done anything exceptional with regards to adding those jars or configuring the prebuilt_jar rules in addition.\n. Odd: we never see the exception for the junit jar\n. I didn't realise that by flaky, you actually meant \"it hasn't passed since landing in master\".\nIn more oddness, it did pass in the PR run...\n. OK; this fails reliably for me locally as well on master\n@ruibm Please feel free to revert the introducing change. Something's gone awry in the integration process - I'll investigate locally and send a new PR.\n. @ruibm Scratch that. I blame @facebook-github-bot\nAll five of those jar files are empty on master (and have always been), but they are there on the PR ref (checking out the PR yields success).\n. Heh; I didn't know this was possible; neither the groovy documentation (www.groovy-lang.org/groovyc.html) or groovyc's usage documents it.\nI'll look at adding it: GroovycToJarStepFactory already has the information to make the decision, it just deliberately ignores it right now :-)\n. Some notes in case @trevorriles (or indeed anyone else) fancies a bash at this:\n- Code with very similar behaviour lives in ExternalJavac at the moment.\n- We deliberately decided to not give groovy the behaviour java has right now where it can read sources out of zips (so the big else if in getExpandedSourcePaths is probably irrelevant)\nIf someone else did want to pick this up, please yell and I'll hold off putting together the PR myself :-)\n. In other amusing news, it looks like that Optional<Path> isn't really that optional; we only ever call createCompileToJarStep with Optional.of(pathToSrcsList) in DefaultJavaLibrary or delegate the call, so a secondary change would be to get rid of the Optional and the associated branching code below it. Woot.\nEDIT: gwaargh, turns out this isn't true because of some indirection and JarFattener. Perhaps that could be cajoled into creating the file as well, hmm.\n. Possibly even three changes, as I reckon \n\nsteps.add(new MkdirStep(getProjectFilesystem(), pathToSrcsList.getParent()));\n\nin DefaultJavaLibrary is redundant as well. That unlocks the removal of that Optional, and that makes fixing the issue a little easier. Unless I hear otherwise, I'll start work on these tomorrow.\n. I'm not actually convinced that it is redundant (this pattern turns up a lot elsewhere); I'd really like to understand the scenario in which it becomes necessary, though; advice welcome\n. I'm not actually convinced that it is redundant (this pattern turns up a lot elsewhere); I'd really like to understand the scenario in which it becomes necessary, though; advice welcome\n. Weak regex fu suggests there are ~95 other places that do roughly the same thing. If it isn't redundant, it perhaps ought to be made so.\n. Weak regex fu suggests there are ~95 other places that do roughly the same thing. If it isn't redundant, it perhaps ought to be made so.\n. Ok, took a closer look.\nIn fact, every MkdirStep does a mkdir -p, so anyone creating a folder in the gen area is going to end up creating it for us. That sort of leaves things in a working by coincidence state, so this PR probably shouldn't be merged.\nWe could remove lots of tedious step code by always having buck-out/(gen|bin|res|annotation)/${buildTarget}/ already exist\nThoughts?\n. Ok, took a closer look.\nIn fact, every MkdirStep does a mkdir -p, so anyone creating a folder in the gen area is going to end up creating it for us. That sort of leaves things in a working by coincidence state, so this PR probably shouldn't be merged.\nWe could remove lots of tedious step code by always having buck-out/(gen|bin|res|annotation)/${buildTarget}/ already exist\nThoughts?\n. Historical context: https://github.com/facebook/buck/pull/546\nIt would be great if we could find a single place for this behaviour to live such that it supports each jvmlang implementation appropriately. That PR was a spike towards that; you might, if you were feeling particularly enthusiastic, feel like reviving it, or on the other hand perhaps not :-)\nHaving getExpandedSourcePaths be static and somewhere other than ExternalJavac doesn't sound like too bad a place to move to for the time being, in any case :-)\n. Disclaimer: I haven't looked at this code for a fair old while\nBut: A quick look yields no obvious problems (that one piece of alignment pedantry aside (sorry)): nice work :-)\nMore general comments about this area:\nIt would be good to revisit the various LibraryDescription classes to see if there is something common to be extracted there. We've always deferred this in the past to see what other implementations turned up - perhaps now might be a time to reassess. I suppose it depends if we expect any more jvm langs to turn up, and whether they will be similar. Similar motivation might be found if desirable features from JavaLibraryDescription were not being hooked into by groovy, scala, kotlin &c without manual effort (i.e someone copies them across).\nThere are probably plenty of things in the java package that could probably be pushed into somewhere agnostic, too (DefaultJavaLibrary caught my eye in this commit - that's really DefaultJvmLibrary now, right?); that's something I meant to get to but never did.\n. Will do.\n. Sounds good to me!\n. Agreed on both counts!\n. So, by default in AbstractJavacOptions, we have this:\n// Set the sourcepath to stop us reading source files out of jars by mistake.\noptionsConsumer.addOptionValue(\"sourcepath\", \"\");\nIt turns out that this doesn't play well with cross compilation, to the point where passing empty sourcepath to the 'inner' javac means it cannot find the groovyc compiled classes.\nWe found two potential paths to avoiding this problem; the simpler one (just ignore the source path option) is presented here. The more complicated solution involves making every path we pass to the compile step absolute; we liked this less.\nI'm not particularly happy with either solution and would welcome any further input. I'll go and think about the possible values of source path to see if we always want to drop it, whether we want to log a warning if it's set, etc...\n. Understood!\n. I'm going to undo the spurious part in this PR, but I think switching to ProcessExecutor or equivalent should probably be a separate commit.\n. Will fix this.\n. I'll fix the others in return for leaving this one ;-)\n. both of them in this case, I guess (from context that looks like the rule; will see if I can persuade intellij to do this for me in future)\n. In retrospect, that is well named enough that it should have actually triggered a response in my brain. Good catch, thanks.\n. I'm translating this as: \n- remove the part of the Arg that refers to it.\n- destroy validateAndGetSourcesUnderTest\n- pass an empty set to JavaTest's constructor arg.\nIs there a plan to remove it from the java side as well?\n. I get \ncom.facebook.buck.util.HumanReadableException: Rule for target '//com/example/spock:passing' could not be resolved.\nThe stack trace holds the answer:\n\ncom.facebook.buck.util.HumanReadableException: Rule for target '//com/example/spock:passing' could not be resolved.\n\n    at com.facebook.buck.rules.BuildRuleResolver.getRule(BuildRuleResolver.java:93)\n    at com.facebook.buck.rules.SourcePathResolver$5.apply(SourcePathResolver.java:294)\n    at com.facebook.buck.rules.SourcePathResolver$5.apply(SourcePathResolver.java:291)\n    at com.google.common.collect.Iterators$8.transform(Iterators.java:799)\n    at com.google.common.collect.TransformedIterator.next(TransformedIterator.java:48)\n    at com.google.common.collect.ImmutableList.copyOf(ImmutableList.java:271)\n    at com.google.common.collect.ImmutableList.copyOf(ImmutableList.java:226)\n    at com.google.common.collect.FluentIterable.toList(FluentIterable.java:373)\n    at com.facebook.buck.rules.SourcePathResolver.filterBuildRuleInputs(SourcePathResolver.java:297)\n    at com.facebook.buck.rules.SourcePathResolver.filterBuildRuleInputs(SourcePathResolver.java:301)\n    at com.facebook.buck.jvm.java.CalculateAbi.of(CalculateAbi.java:65)\n    at com.facebook.buck.jvm.groovy.GroovyTestDescription.createBuildRule(GroovyTestDescription.java:139)\n    at com.facebook.buck.jvm.groovy.GroovyTestDescription.createBuildRule(GroovyTestDescription.java:49)\n\nSo we need it to be in the resolver by the time we call CalculateAbi.of. I'll see if there's a clever way around this that could perhaps be applied to JavaTestDescription also, but I might save it for a separate commit.\n. Looked at this further - there is a better way. We should port every caller of CalculateAbi.of over though (and there are 13 of them), so definitely a separate commit.\nWe can always avoid the resolver, because:\n1. SourcePathResolver::filterBuildRuleInputs(SourcePath... sourcePaths) is actually only ever called with a singlesourcePath(still compiles when I remove the ellipsis)\n2. All we're doing is seeing if thatsourcePathis aBuildTargetSourcePath, and if it is, returning the build rule that builds it. We already know what the rule is from the context we are in, so we can probably either avoidfilterBuildRuleInputs` altogether or appropriately 'can' the BuildRule to return\ntl;dr the only thing that resolver will be returning will be [the rule we're currently building], or maybe [] in the prebuilt_jar case.\n. This was inspired by ExternalJavac which needs the filtering to cope with the potential of expanding zipped sources. We totally don't need it here, I'll remove it.\n. would be nice to keep the alignment tidy here :-)\n. ",
    "FrancisToth": "Hi ! I'm gonna make a clean rebase and ask for merging.\n. Hi ! I'm gonna make a clean rebase and ask for merging.\n. I've just pushed everything and made some fixes. An integration test is still required, and I'll do that tomorrow. Regarding the build, do you have any idea why it is not passing ? All tests are green locally, and Travis does not specify any clear reason explaining why it has failed.\n. I've just pushed everything and made some fixes. An integration test is still required, and I'll do that tomorrow. Regarding the build, do you have any idea why it is not passing ? All tests are green locally, and Travis does not specify any clear reason explaining why it has failed.\n. Thank for those informations, next time I'll check those aspects before pushing. Now the build is ok but unfortunately, one test is still failing, and as far as I know, this happens only on Travis : ExternalJavacIntegrationTest : \nFAILURE whenBuckdUsesExternalJavacThenClientEnvironmentUsed: java.io.IOException: Cannot run program \"watchman\": error=2, No such file or directory\njava.lang.RuntimeException: java.io.IOException: Cannot run program \"watchman\": error=2, No such file or directory\n    at com.google.common.base.Throwables.propagate(Throwables.java:160)\n    at com.facebook.buck.util.WatchmanWatcher$1.get(WatchmanWatcher.java:192)\n    at com.facebook.buck.util.WatchmanWatcher$1.get(WatchmanWatcher.java:185)\n    at com.facebook.buck.util.WatchmanWatcher.postEvents(WatchmanWatcher.java:207)\n    at com.facebook.buck.cli.Main$Daemon.watchFileSystem(Main.java:284)\n    at com.facebook.buck.cli.Main$Daemon.access$1000(Main.java:160)\n    at com.facebook.buck.cli.Main.getParserFromDaemon(Main.java:781)\n    at com.facebook.buck.cli.Main.executeCommand(Main.java:603)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:452)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentAndContext(ProjectWorkspace.java:315)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckdCommand(ProjectWorkspace.java:248)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckdCommand(ProjectWorkspace.java:242)\n    at com.facebook.buck.java.ExternalJavacIntegrationTest.whenBuckdUsesExternalJavacThenClientEnvironmentUsed(ExternalJavacIntegrationTest.java:110)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at com.facebook.buck.junit.BuckBlockJUnit4ClassRunner$SameThreadFailOnTimeout$1.call(BuckBlockJUnit4ClassRunner.java:122)\n    at com.facebook.buck.junit.BuckBlockJUnit4ClassRunner$SameThreadFailOnTimeout$1.call(BuckBlockJUnit4ClassRunner.java:118)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.io.IOException: Cannot run program \"watchman\": error=2, No such file or directory\n    at java.lang.ProcessBuilder.start(ProcessBuilder.java:1047)\n    at com.facebook.buck.util.WatchmanWatcher$1.get(WatchmanWatcher.java:190)\n    ... 27 more\nCaused by: java.io.IOException: error=2, No such file or directory\n    at java.lang.UNIXProcess.forkAndExec(Native Method)\n    at java.lang.UNIXProcess.(UNIXProcess.java:186)\n    at java.lang.ProcessImpl.start(ProcessImpl.java:130)\n    at java.lang.ProcessBuilder.start(ProcessBuilder.java:1028)\n    ... 28 more\n\nI've noticed this problem some days ago, and managed to fix it by installing a fresh version of watchman, as suggested here : \n$ git clone https://github.com/facebook/watchman.git\n$ cd watchman\n$ ./autogen.sh\n$ ./configure\n$ make\n$ sudo make install\n. No problem :) I'm happy to contribute !\n. Actually, I've put this in another pull request regarding Buck android project integration in Intellij : https://github.com/facebook/buck/pull/209\n. Is this still an issue ? I thought this was resolved considering the e-mails we've exchanged. Would it be possible to get the example back ?\n. I think this is fixed. However, the generated IDEA's files are pretty bad. If we take the example of .idea/misc.xml : \nbefore buck project :\nxml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"ProjectModuleManager\">\n    <modules>\n      <module fileurl=\"file://$PROJECT_DIR$/third-party/java/aosp/aosp.iml\" filepath=\"$PROJECT_DIR$/third-party/java/aosp/aosp.iml\" />\n      <module fileurl=\"file://$PROJECT_DIR$/buck.iml\" filepath=\"$PROJECT_DIR$/buck.iml\" />\n      <module fileurl=\"file://$PROJECT_DIR$/src/com/facebook/buck/maven/maven.iml\" filepath=\"$PROJECT_DIR$/src/com/facebook/buck/maven/maven.iml\" />\n      <module fileurl=\"file://$PROJECT_DIR$/scripts/scripts.iml\" filepath=\"$PROJECT_DIR$/scripts/scripts.iml\" />\n      <module fileurl=\"file://$PROJECT_DIR$/src/com/facebook/buck/junit/testrunner.iml\" filepath=\"$PROJECT_DIR$/src/com/facebook/buck/junit/testrunner.iml\" />\n    </modules>\n  </component>\n</project>\nafter buck project  : \nxml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"EntryPointsManager\">\n    <entry_points version=\"2.0\" />\n  </component>\n  <component name=\"FrameworkDetectionExcludesConfiguration\">\n    <type id=\"android\" />\n  </component>\n  <component name=\"IdProvider\" IDEtalkID=\"0DE2DAD55CCA0E8D48163E3F370D8939\" />\n  <component name=\"ProjectResources\">\n    <default-html-doctype>http://www.w3.org/1999/xhtml</default-html-doctype>\n  </component>\n  <component name=\"ProjectRootManager\" version=\"2\" languageLevel=\"JDK_1_7\" assert-keyword=\"true\" jdk-15=\"true\" project-jdk-name=\"1.7\" project-jdk-type=\"JavaSDK\">\n    <output url=\"file://$PROJECT_DIR$/build-ij/classes\" />\n  </component>\n</project>\n. Sorry my bad, I looked at the wrong file (this is what happens when you work too late :)). However, there is a clear difference (just try to open IDEA before and after). I'll try to look into that this week.\nSorry again . \n. ",
    "ncalexan": "I'm evaluating buck as a candidate build system for Firefox for Android; we don't have a huge number of resource directories but this would certainly make life easier.\n. Could you associate the project with a subdirectory of buck-out, so that even asking to share buck-out across projects builds into a sandbox?  Perhaps you could hash some portion of the project state and use that to index into buck-out?\nPersonally I think this is not worth it.  At some point folks will abuse the tool.  Yes, we try to prevent footguns; but users can do things with symlinks and hard links that no program should be trying to avoid.\n. ",
    "csandeep": "We face the same problem as the resources are spread over gradle build variants and there is a bit of shared resources (colors etc). Would be great to have workaround / fix for this issue.\n. ",
    "edisonw": "Signed, not sure if I need to redo this..going to make a new one. \n. Looks like CI failed because \"https://junit-team.github.io/junit/javadoc/latest/package-list\" 404s. \n. I see, thanks for the clarification. time to change all R references. \n. Turns out after making this work for gradle, some of the plugins that I use assumes and look for the standard R file (it also won't work in AS/gradle setup). Is it possible to make \"transitive\" an option?  Thanks again @natthu \n. Say you have the following structure:\nandroid_resource(\n  name = 'shared_res',\n  package = 'com.example.shared',\n  res = 'shared/src/main/res',\n  deps = [\n    ':app_compact',\n    ':play_services',\n  ],\n)\nandroid_resource(\n  name = 'res',\n  package = 'com.example.app',\n  res = 'app/src/main/res',\n  deps = [\n    ':shared_res',\n  ]\n)\nWhat It used to be: (before that commit) \n1. com.example.app.R will have all the constants from com.example.shared.R, mimic the way gradle handles it, \n2. You can safely use com.example.R for resources defined in shared.R. \nWhat current HEAD does: \nUsing com.example.shared.R is now required, using com.example.app.R will give symbol not found. \n. Revert that commit and add back the R txt Util classes almost works, but I think there's other parts of the system that may have changed since 5ae51de. \nI guess what I am asking is when \nandroid_resource(\nname = 'res',\npackage = 'com.example.app',\nres = 'app/src/main/res',\ndeps = [\n':shared_res',\n]\nhappens, since shared_res IS a dependency that's included in res, other modules that use res should have direct access to shared_res through res, but right now a user of res would need to have both shared_res and res as dependencies. \n. um, that could work, there's still one issue with this not working, not sure if you guys have better way for: how to use resource ids from pre built aars such as AppCompact v7's \"R.drawable.abc_ic_ab_back_holo_dark\" as pacakge name can't be changed there. \nOf course, the reflection way works: \npublic static int getBackIcon(String appPackageName, boolean dark) {\n        String fieldName = dark ? \"abc_ic_ab_back_holo_dark\" : \"abc_ic_ab_back_holo_light\";\n        Field field = null;\n        try {\n            Class classR = Class.forName(appPackageName + \".R$drawable\");\n            try {\n                field = classR.getField(fieldName);\n            } catch (NoSuchFieldException e) {\n                //It's ok.\n            }\n        } catch (ClassNotFoundException e) {\n            throw new IllegalArgumentException(\"Invalid pacakge name.\");\n        }\n        if (field == null) {\n            try {\n                Class classR = Class.forName(\"android.support.v7.appcompat.R$drawable\");\n                try {\n                    field = classR.getField(fieldName);\n                } catch (NoSuchFieldException e) {\n                    throw new RuntimeException(e);\n                }\n            } catch (ClassNotFoundException e) {\n                throw new RuntimeException(e);\n            }\n        }\n        try {\n            return field.getInt(null);\n        } catch (IllegalAccessException e) {\n            throw new RuntimeException(e);\n        }\n    }\n. it was complaining about R resources not found.\n. I'm using a buck from few weeks ago, let me update to latest and give it another try. \n. Yea, with master I'm still getting BUILD FAILED: //:depdendant#aar_android_resource failed with exit code 1:\ngenerate_resource_ids \nSetup: \nandroid_prebuilt_aar(\n    name = 'depdendant',\n    aar = 'depdendant/depdendant.aar',\n    deps = [\n      ':depdendant-core'\n    ]\n)\nWhen I unzip depdendant-core I can see the ids that buck complains to exist inside R.txt. \n. ^yea, correct, there are other libraries that need :dependent-core as well. \n. Thanks for getting back so quickly! Really appreciate it. \nUmm...it won't get through the process stage now:\nBUILD FAILED: //:dependent: exported dep //:dependent#aar_android_resource (android_resource) must be a type of java library.\n(I didn't change the BUCK file yet, it has no exported_deps for //:dependent)\n. @sdwilsh thanks! I applied the diff from latest master (e96bb81d675d2517aee5e5fcc36c4833ca85a346) This did make the aar pass it's own build stage, but now prebuilt_jar are not found in android_lib projects (as if the prebuilt jars were not included). Any ideas? \nAs for twitter-core, you can find it here: \nhttp://twittersdk.artifactoryonline.com/twittersdk/repo/com/twitter/sdk/android/twitter-core/1.3.4/\nWhich in turn depends on:\nhttps://twittersdk.artifactoryonline.com/twittersdk/repo/io/fabric/sdk/android/fabric/1.3.3/\nhttps://s3.amazonaws.com/uploads.hipchat.com/27122/262519/dhRxa3UHEUpavqs/gson-2.2.4.jar\nhttps://s3.amazonaws.com/uploads.hipchat.com/27122/262519/2kMXmvNMEAmyfLu/retrofit-1.6.0.jar\n. \"a android_prebuilt_aar that has prebuilt_jars in its dependency chain\"\n^Yea, tho the diff broke other android_libs that have prebuilt_jars in them for some reason. :| \nI'll see if I can use digits to make a clean example. We do have pretty complicated setup right now with other jars as well. \n. Sounds good. Thanks! \n. Thanks!\n. Thank @sdwilsh, but I can just make C also a dep of A, correct? \n. I see, sounds good. \n. Yea, this happens only when I use a re-zipped aar file. :D aar the correct way will not confuse BUCK. \n. Yea, this happens only when I use a re-zipped aar file. :D aar the correct way will not confuse BUCK. \n. @sdwilsh btw, the transitive aar stuff works now perfectly, thanks again. : ) \n. @sdwilsh btw, the transitive aar stuff works now perfectly, thanks again. : ) \n. ",
    "cgrushko": "Given that android_library only look at first-order dependencies, what is the purpose of the android_library.deps attribute?. ",
    "nicks": "Why is it that \"R constants in Android library projects cannot be assumed to be final\"? \nThe gradle/android stuff seems to be OK using final R constants, and I'm curious how Buck's compilation model is different.\n. thanks!!\nOn Sat, Oct 17, 2015 at 3:29 AM, Coneko notifications@github.com wrote:\n\nFixed in ef5cafc\nhttps://github.com/facebook/buck/commit/ef5cafc5cec1f9d96081b4a36e3ef61fff24892d\n.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/466#issuecomment-148905503.\n. thanks!!\n\nOn Sat, Oct 17, 2015 at 3:29 AM, Coneko notifications@github.com wrote:\n\nFixed in ef5cafc\nhttps://github.com/facebook/buck/commit/ef5cafc5cec1f9d96081b4a36e3ef61fff24892d\n.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/466#issuecomment-148905503.\n. \n",
    "bmihai": "Ok, a reboot seems to have mostly fixed it. That error message now only shows up if --help is run in the root of the Buck repository. In an actual project directory all commands seem to work fine after the reboot (the build was failing before).\nStill, the --help command should work in the Buck dir too, and there should be an easy way to clean up daemons. Using buckd --kill was not sufficient apparently.\n. Seems fixed as of 000aca10393d9a0fc133715650b9baa84fd5457a.\n. Thank you for looking into this sdwilsh!\nI'm using ndk_library(), and buck clean does not change things. I'm using the latest buck from the repository.\nI've tried keeping all the changes that should have (but did not) work with r10e, and replacing the files of the r10e folder with the ones of r10d: with this 'faked' r10e it worked. So, something in android-ndk-r10e is breaking buck (or at least my buck).\nI'll try to reproduce it in a modified buck quickstart project, and will write back.\n. Well, with a modified buck quickstart I'm getting SLES/OpenSLES.h: No such file or directory with both r10d and r10e. It looks like it might be a configuration problem on my end, and the fact that r10d worked is the odd thing. Will look into this again tomorrow.\n. I've had a bit more time to look into this. (I'm writing this here because I feel it's a bit too specific for stackoverflow.com, and it looks like a bug in either buck or android-ndk.)\nI was able to reproduce the problem in a minimal buck quickstart project. The reason I wasn't before was that I'd forgotten to create an Application.mk file. Interestingly enough, it seems the problem with r10e+buck is that it doesn't find Application.mk, so the failure mode was the same. I've uploaded a minimal test project to github.\nI've narrowed the cause of the problem down to one of the arguments buck passes to ndk-build: 'APP_PROJECT_PATH=/home/mihai/tmp/delme/buck-out/bin/jni/__libbugtest/'. Manually calling the ndk-build with this argument removed completes the compilation, and if buck build is re-run, it happily declares the build complete.\nWhen this arg is passed to the r10e ndk-build, it calls gcc with a -I [...]/android-ndk-r10e/platforms/android-3/arch-arm/usr/include. If r10d is used or the APP_PROJECT_PATH argument is removed, it uses -I [...]/android-ndk-r10e/platforms/android-9/arch-arm/usr/include. (So, android-3 for the bad case, and android-9 for the good).\nUsing flags = ['NDK_LOG=1'], shows how ndk-build behaves differently with r10d:\nAndroid NDK: Looking for jni/Android.mk in /home/mihai/tmp/delme/jni\nAndroid NDK: Looking for jni/Android.mk in /home/mihai/tmp/delme\nAndroid NDK:     Found it !\nAndroid NDK: Found project path: /home/mihai/tmp/delme\nAndroid NDK: Ouput path for intermediate files: /home/mihai/tmp/delme/buck-out/bin/jni/__libbugtest/\nAndroid NDK: Ouput path for generated library files: /home/mihai/tmp/delme/buck-out/bin/jni/__libbugtest/libs\nAndroid NDK: Parsing /home/mihai/tmp/delme/jni/Application.mk\nAndroid NDK:   Adjusting APP_PLATFORM android-11 to android-9\nversus r10e:\nAndroid NDK: Use APP_PROJECT_PATH for NDK_PROJECT_PATH: /home/mihai/tmp/delme/buck-out/bin/jni/__libbugtest/\nAndroid NDK: Found project path: /home/mihai/tmp/delme/buck-out/bin/jni/__libbugtest/\nAndroid NDK: Ouput path for intermediate files: /home/mihai/tmp/delme/buck-out/bin/jni/__libbugtest/\nAndroid NDK: Ouput path for generated library files: /home/mihai/tmp/delme/buck-out/bin/jni/__libbugtest/libs\nAndroid NDK: Parsing /home/mihai/bin/android-ndk-r10e/build/core/default-application.mk\nAndroid NDK:   Defaulted to APP_PLATFORM=android-3\nSo, with r10e, APP_PROJECT_PATH is causing ndk-build to not see Application.mk anymore and use default values for APP_PLATFORM. I believe the behaviour is due to a 17-line segment of code added by the Android devs at line 93 in android-ndk-r10e/build/core/build-local.mk. But buck should be handling this somehow, I believe?\n. Yup, there's the apps/myapp/AndroidManifest.xml that buck quickstart creates (you can see it in the minimal project I uploaded here).\n. Shawn, would it be worth reopening this? I believe it's a genuine bug, and seems like a significant one.\n. No problem, as long as it's on the radar somewhere! :)\nThank you.\n. Yup, that works! Thank you.\n(I'll let you close the bug report when you wish, in case you want the report to stay up until the fix is made public).\n. Yup, that works! Thank you.\n(I'll let you close the bug report when you wish, in case you want the report to stay up until the fix is made public).\n. Just wanted to add that this is still happening with the Android NDK r11c, released just recently.\n. For some reason the original bug is still up for me. I now get this error message when running a buck clean:\nBUILD FAILED: could not extract version from NDK repository at com.facebook.buck.io.ProjectFilesystem@470a90de (projectRoot=/home/mihai/bin/android-ndk-r11c, whiteListedPaths=Optional.absent(), blackListedPaths=[]: /home/mihai/bin/android-ndk-r11c/RELEASE.TXT\nI'm on buck commit 1d1d4a4. The source.properties file exists and is readable. It contains the text\nPkg.Desc = Android NDK\nPkg.Revision = 11.2.2725575\n. @Coneko, I've tried doing a buck kill first and no changes, same error message. I've tried it with the lastest commit, 797cdf6.\n. It also gives the same error message:\nBUILD FAILED: could not extract version from NDK repository at com.facebook.buck.io.ProjectFilesystem@470a90de (projectRoot=/home/mihai/bin/android-ndk-r11c, whiteListedPaths=Optional.absent(), blackListedPaths=[]: /home/mihai/bin/android-ndk-r11c/RELEASE.TXT\nIf I change the project's local.properties to use android-ndk-r10d (the last fully working version) it says:\nbuck version 797cdf60b1f26acd59bbe2b34340089107785532\n. ",
    "liuxyc": "hi simpleton,\nI didn't use R.java which generated by Ant, i just compare then after i got the error above.\nThe reason i compare them is trying to find out where the issue came from.(Why Ant build can pass but BUCK can not)\n. ",
    "liufsd": "My project folder list:\nfr --- my  fr dict module project\nen --- my en dict  module project\nes --- my  es  dict  module project\n.\n.\nReciteLibrary -- main library\nlibprojects{\nabs -- abs library\n   MPChartLib -- chart library\n   library--  ui library\n}\n### ### ### ### ### ### ###\nReciteLibrary has three libs project\n( android.library.reference.1=../libprojects/abs\n  android.library.reference.2=../libprojects/library\n  android.library.reference.3=../libprojects/MPChartLib\n)\nAnd then fr's library is ReciteLibrary.(android.library.reference.1=../ReciteLibrary)\nand how to build it ?\nThanks!\n. i have update my buck here: \nThe files and modifications provided by Facebook are for testing and evaluation purposes only.  Facebook reserves all rights not expressly granted.\nimport re\nall jar build\njar_deps = []\nfor jarfile in glob(['ReciteLibrary/libs/.jar']):\n  name = 'jars__' + re.sub(r'^./([^/]+).jar$', r'\\1', jarfile)\n  jar_deps.append(':' + name)\n  prebuilt_jar(\n    name = name,\n    binary_jar = jarfile,\n  )\nandroid_library(\n  name = 'all-jars',\n  exported_deps = jar_deps,\n)\nandroid_build_config(\n  name = 'build-config',\n  package = 'com.eusoft.recite',\n)\nmain library project build\nAPP_CLASS_SOURCE = 'ReciteLibrary/src/com/eusoft/recite/AppShell.java'\nandroid_library(\n  name = 'application-lib',\n  srcs = [APP_CLASS_SOURCE],\n  deps = [\n    ':build-config',\n    ':jars__buck-android-support',\n  ],\n)\nandroid_library(\n  name = 'main-lib',\n  srcs = glob(['ReciteLibrary/src/////*.java'], excludes = [APP_CLASS_SOURCE]),\n  deps = [\n    ':all-jars',\n    ':abs-lib',\n    ':uiLib-lib',\n    ':MPChartLib-lib',\n    ':build-config',\n    ':mainLib_res',\n  ],\n)\nandroid_resource(\n  name = 'mainLib_res',\n  package = 'com.eusoft.recite',\n  res = 'ReciteLibrary/res',\n  deps = [\n    ':abs-res',\n    ':uiLib-res',\n    ':MPChartLib-res',\n  ]\n)\nui library project build\nandroid_library(\n  name = 'uiLib-lib',\n  srcs = glob(['libprojects/library/src/*/.java']),\n  deps = [\n    ':all-jars',\n     ':abs-lib',\n    ':uiLib-res',\n  ],\n)\nandroid_resource(\n  name = 'uiLib-res',\n  package = 'com.manuelpeinado.refreshactionitem',\n  res = 'libprojects/library/res',\n  deps = [\n    ':abs-res',\n  ]\n)\nabs library project build\nandroid_library(\n  name = 'abs-lib',\n  srcs = glob(['libprojects/abs/src/*/.java']),\n  deps = [\n    ':all-jars',\n    ':abs-res',\n  ],\n)\nandroid_resource(\n  name = 'abs-res',\n  package = 'com.actionbarsherlock',\n  res = 'libprojects/abs/res',\n  deps = [\n  ]\n)\nMPChartLib library project build\nandroid_library(\n  name = 'MPChartLib-lib',\n  srcs = glob(['libprojects/MPChartLib/src/*/.java']),\n  deps = [\n    ':all-jars',\n    ':MPChartLib-res',\n  ],\n)\nandroid_resource(\n  name = 'MPChartLib-res',\n  package = 'com.github.mikephil.charting',\n  res = 'libprojects/MPChartLib/res',\n  deps = [\n  ]\n)\nfr module project build\nandroid_library(\n  name = 'fr-src',\n  srcs = glob(['fr/src/*/.java']),\n  deps = [\n    ':main-lib',\n    ':fr-res',\n  ],\n)\nandroid_resource(\n  name = 'fr-res',\n  package = 'com.eusoft.recite.fr',\n  res = 'fr/res',\n  assets = 'fr/assets',\n  deps = [\n  ]\n)\nandroid_manifest(\n  name = 'manifest',\n  skeleton = 'fr/AndroidManifest.xml',\n  deps = [\n    ':fr-src',\n  ],\n)\nkeystore(\n  name = 'debug_keystore',\n  store = 'keystore/debug.keystore',\n  properties = 'keystore/debug.keystore.properties',\n)\nbuild apk\nandroid_binary(\n  name = 'demo',\n  manifest = ':manifest',\n  target = 'android-19',\n  keystore = ':debug_keystore',\n  use_split_dex = True,\n  exopackage = True,\n  primary_dex_patterns = [\n    '^com/eusoft/recite/AppShell^',\n    '^com/facebook/buck/android/support/exopackage/'\n  ],\n  deps = [\n    ':fr-src',\n    ':application-lib',\n  ],\n)\nBUILD FAILED log here:\nlius-MacBook-Pro:ReviewProject liupeng$ buck build demo\nUsing buckd.\n[+] PROCESSING BUCK FILES...0.5s\nNo library manifests found. Aborting manifest merge step.\nBUILD FAILED: //:manifest failed with exit code 1:\ngenerate_manifest\n. @sdwilsh I have put my project here : https://github.com/79144876/FacebookBuckExample\nYou can clone it ,and then run buck build.it will error again.\nMay be you will find some error.\nThanks.\n. Oh.i fix it at last night .(https://github.com/facebook/buck/issues/231#issuecomment-68563018)\nthanks @natthu and @sdwilsh !\n. @shs96c I have put my project here : https://github.com/79144876/FacebookBuckExample\nYou can clone it ,and then run buck build.it will error again.\nMay be you will find some error.\nThanks.\n. Sorry.I have fix it.\nThanks.\n. yes . it got work.Thanks.\nBut i have trouble question:\nI have a cbl_collator_so-1.0.3.1.jar\nThis jar include three so file in the jar ( it just like 'libs' folder jar). so ,in Idea , i just import this jar by 'classes'.\nBut in the buck , how to config this jar file ?\nJust config jar file like normal libs?\n. By the way. why can not set package_type ??\nandroid_binary(\n  name = 'fr_release',\n  manifest = ':manifest',\n  target = 'android-19',\n  keystore = ':release_keystore',\n  use_split_dex = True,\n  exopackage = True,\n  package_type = 'release',\n  proguard_config = 'fr/proguard.cfg',\n  primary_dex_patterns = [\n    '^com/eusoft/recite/AppShell^',\n    '^com/facebook/buck/android/support/exopackage/'\n  ],\n  deps = [\n    ':fr-src',\n  ],\n)\nlog:\nlius-MacBook-Pro:ReviewProject liupeng$ buck build fr_release                  \nUsing buckd.                                                       \n[+] PROCESSING BUCK FILES...0.5s                    \n[2015-01-03 03:57:25.270][error][command:a007ab6c-5c8f-4cbe-a247-50d90b1f0ec3][tid:428][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.lang.IllegalArgumentException: //:fr_release specified exopackage without pre-dexing, which is invalid.\n. 'You cannot use exopackage with package_type set to release. It only works with debug.'???\nThat mean 'exopackage = True' should be delete in release action ? ''exopackage = True' ' and only works with debug. \nBy the way, if i use the 'application'  class, i should use your 'AppShell' ?\n@sdwilsh \nThanks.\n. @natthu I have change 'MyApplication' to 'AppShell' .(http://facebook.github.io/buck/article/exopackage.html).\nI mean,it must be to change or may be not? i worry about this in release.Because i have deleted the 'exopackage = True' in release config.\nSorry, i cannot understand clear @sdwilsh .\n. # proguard fail\nI found another  question:\nI use this library jar file :https://github.com/baoyongzhang/ParcelableGenerator/issues/8\nAnd i have use ant build success.\nBut why can not fail by buck build ?\nproguard.cfg\n```\n-optimizationpasses 5\n-dontusemixedcaseclassnames\n-dontskipnonpubliclibraryclasses\n-dontpreverify\n-verbose\n-optimizations !code/simplification/arithmetic,!field/,!class/merging/\n-dontshrink\n-keep class com.crashlytics. { *; }\n-keep class com.actionbarsherlock. { ; }\n-keep interface com.actionbarsherlock. { *; }\n-keep class net.sqlcipher. {;}\n-keep class com.aocate. { *; }\n-keep class com.blahti.drag. {;}\n-keep class com.haarman. { *; }\n-keep class cn.pedant. { ; }\n-keep class com.manuelpeinado.refreshactionitem. { *; }\n-keep class com.haarman.listviewanimations. { ; }\n-keep class com.handmark.pulltorefresh.library. { *; }\n-keep class com.baoyz.swipemenulistview. { ; }\n-keep class com.bossturban.webviewmarker. {*;}\n-keep interface com.bossturban. { ; }\n-keep class com.sina.{*;}\n-keep class cn.sharesdk.{;}\n-keep class m.framework.*{;}\n-keepnames class org.codehaus.jackson. { *; }\n-dontwarn org.codehaus.jackson.map.ext.\n-dontwarn com.baoyz.pg.PGProcessor.\n-dontwarn com.couchbase.lite.listener.\n-dontwarn com.google.common.\n-dontwarn javax.annotation.processing.\n-dontwarn  javax.lang.\n-dontwarn  javax.tools.\n-keep class javax. { *; }\n-keep class org. { ; }\n-keep class com.google.code.  { *; }\n-keep class java.lang.management.  { ; }\n-keep class com.github.{*;}\n-keep class org.apache.http.{;}\n-keep class com.couchbase.{;}\n-keep class com.couchbase.touchdb.TDCollateJSON { ; }\n-keep class com.couchbase.lite.android.AndroidLogger { ; }\n-keep class com.couchbase.lite.android.AndroidSQLiteStorageEngine { ; }\n-keep class org.apache.commons.{;}\nOrmLite uses reflection\n-keep class com.j256.\n-keepclassmembers class com.j256. { ; }\n-keep enum com.j256.\n-keepclassmembers enum com.j256. { ; }\n-keep interface com.j256.\n-keep class com.eusoft.dict.util.localhttpcache.entities.{*;}\n-keepattributes Annotation\n-dontwarn android.support.\n-dontwarn android.net.http.\n-keep class android.webkit. { *;}\n-keep public class * extends android.webkit.WebView\n-keepattributes SourceFile,LineNumberTable\n-keep public class * extends android.support.v4.\n-keep public class * extends android.app.Fragment\n-keep public class * extends android.app.FragmentActivity\n-keep public class * extends android.app.Activity\n-keep public class * extends android.app.Application\n-keep public class * extends android.app.Service\n-keep public class * extends android.content.BroadcastReceiver\n-keep public class * extends android.content.ContentProvider\n-keep public class * extends android.app.backup.BackupAgentHelper\n-keep public class * extends android.preference.Preference\n-keep public class com.android.vending.licensing.ILicensingService\n-dontwarn CompatHoneycomb \n-dontwarn CompatCreatorHoneycombMR2\n-dontwarn ActivityCompatHoneycomb\n-dontwarn MenuCompatHoneycomb \n-dontwarn org.apache.commons.httpclient\nremove all logs\n-assumenosideeffects class android.util.Log { public * ; }\nsearch and deobfuscate addJavascriptInterface\n-dontwarn javax.annotation.**\n-dontwarn android.app.\n-dontwarn android.support.\n-dontwarn android.view.\n-dontwarn android.widget.\n-dontwarn com.google.common.primitives.**\n-dontwarn CompatHoneycomb\n-dontwarn CompatHoneycombMR2\n-dontwarn **CompatCreatorHoneycombMR2\n-keepclassmembers class * {\n   public void *(android.view.View);\n}\n-keepclassmembers class * {\n public void myClickHandler(android.view.View);\n}\n-keepclasseswithmembernames class * {\n     native ;\n}\n-keepclasseswithmembers class * {\n     public (android.content.Context, android.util.AttributeSet);\n}\n-keepclasseswithmembers class * {\n     public (android.content.Context, android.util.AttributeSet, int);\n }\n-keepclassmembers class *.R$ {\n     public static ;\n }\n-keep class com.eusoft.recite.support.entities. {\n;\n}\n-keep class * extends *.JavascriptClassHelper {\n;\n}\n-keep class com.eusoft.dict.util.JniApi {\n*;\n}\n-keep class .SpeechUtil {\n*;\n}\n-keep class .TranslationUtil {\n;\n}\n-keep class * extends .TranslationUtil {\n*;\n}\n-keep class .HtmlPageUtil {\n;\n}\n-keep class * extends .JavascriptClassHelper {\n;\n} \n-keep class com.eusoft.dict.model. {\n;\n}\n-keep class com.eusoft.recite.io.model. {\n;\n}\n-keep class com.eusoft.dict.LocalStorage {\n;\n}\n-keep class com.eusoft.dict.DBIndex {\n;\n}\n-keep class com.eusoft.dict.OnlineDicData {\n;\n}\n-keep class com.eusoft.dict.CategoryItem {\n;\n}\n-keep class com.eusoft.dict.DicInfo {\n;\n}\n-keep class com.eusoft.dict.ReciteDBInfo {\n;\n}\n-keep class com.eusoft.dict.CustomizeListItem {\n;\n}\n-keep class com.eusoft.dict.WikiInfo {\n;\n}\n-keep class com.eusoft.dict.util.JniApi {\n;\n}\n-keep class com.google.b {\n*;\n}\n-keepclasseswithmembernames class * {\n    native ;\n}\n-keepclasseswithmembers class * {\n    public (android.content.Context, android.util.AttributeSet);\n}\n-keepclasseswithmembers class * {\n    public (android.content.Context, android.util.AttributeSet, int);\n}\n-keepclassmembers class * extends android.app.Activity {\n   public void *(android.view.View);\n}\n-keepclassmembers enum * {\n    public static [] values();\n    public static  valueOf(java.lang.String);\n}\n-keep class * implements android.os.Parcelable {\n  public static final android.os.Parcelable$Creator *;\n}\n```\n. So,i found here:http://stackoverflow.com/questions/5884287/how-to-keep-class-file-package-info-class-generated-by-jaxb-during-proguard-ob\nbut error again:\nInvalid line in proguard mapping: com.google.common.base.package-info -> com.google.common.base.package-info:\n. The jar name:guava-r09.jar\nAnd then i have try to remove \"  use_split_dex = True,\" in BUCK android_binary.\nThe 'package-info' error have not happened.\nBut error this:\nBUILD FAILED: //:fr_release failed on step collect_smart_dex_inputs_hash with an exception:\nMultiple entries with same key: com/google/common/a/a=b734e325e40ecc1ba981172b4fadcbb20cad0845 and com/google/common/a/a=b734e325e40ecc1ba981172b4fadcbb20cad0845\njava.lang.IllegalArgumentException: Multiple entries with same key: com/google/common/a/a=b734e325e40ecc1ba981172b4fadcbb20cad0845 and com/google/common/a/a=b734e325e40ecc1ba981172b4fadcbb20cad0845\n        at com.google.common.collect.ImmutableMap.checkNoConflict(ImmutableMap.java:150)\n        at com.google.common.collect.RegularImmutableMap.checkNoConflictInBucket(RegularImmutableMap.java:104)\n        at com.google.common.collect.RegularImmutableMap.<init>(RegularImmutableMap.java:70)\n        at com.google.common.collect.ImmutableMap$Builder.build(ImmutableMap.java:254)\n        at com.facebook.buck.android.AndroidBinary$4.get(AndroidBinary.java:619)\n        at com.facebook.buck.android.AndroidBinary$4.get(AndroidBinary.java:1)\n        at com.google.common.base.Suppliers$MemoizingSupplier.get(Suppliers.java:125)\n        at com.facebook.buck.android.HashInputJarsToDexStep.execute(HashInputJarsToDexStep.java:77)\n        at com.facebook.buck.step.DefaultStepRunner.runStepInternal(DefaultStepRunner.java:97)\n        at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:83)\n        at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:501)\n        at com.facebook.buck.rules.CachingBuildEngine.buildOnceDepsAreBuilt(CachingBuildEngine.java:380)\n        at com.facebook.buck.rules.CachingBuildEngine.access$3(CachingBuildEngine.java:304)\n        at com.facebook.buck.rules.CachingBuildEngine$1.onSuccess(CachingBuildEngine.java:181)\n        at com.facebook.buck.rules.CachingBuildEngine$1.onSuccess(CachingBuildEngine.java:1)\n        at com.google.common.util.concurrent.Futures$6.run(Futures.java:1319)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nThanks.\n. any idea about this?\n. OK. i have push my project here:https://github.com/79144876/ParcelableGeneratorFacebookBuck.\n(and a question here:https://github.com/facebook/buck/issues/233#issuecomment-70037521)\nThanks for your help.\n. Oh,sorry, it's a empty folder.you can create it .Now, i have push it. you can pull and then test it.(https://github.com/79144876/ParcelableGeneratorFacebookBuck/commit/9e43c1497e728b48fcab1683d0c39d8bd8bea4c1)\nThanks for your help!\n. Hi!\nDo you have any idea about this ??? If you have got it,you can push request.\nThanks.\n. ",
    "jart": "This feature would be extremely useful for anyone working on a large existing project using a Python build system, except their build files are named BUILD and they don't want to have to rename them in order to use Buck.\n. It's close enough that I can write polyfills in Python that get loaded by buildfile.includes.\n. I took a look into implementing this already and it appears to be nontrivial. Right now \"BUCK\" is defined as BuckConstants#BUILD_RULES_FILE_NAME which is referenced by a whole bunch of places. I'm guessing we'd want to move this to a method on BuckConfig like:\n```\nprivate static final String DEFAULT_BUILD_RULES_FILE_NAME = \"BUCK\";\npublic String getBuildRulesFileName() {\n  ImmutableMap entries = getEntriesForSection(\"buildfile\");\n  return MoreObjects.firstNonNull(entries.get(\"name\"), DEFAULT_BUILD_RULES_FILE_NAME);\n}\n```\nThe problem is that nearly all the places that reference this constant don't have access to the BuckConfig instance. So it then becomes a question of whether or not we want to:\n1. Kludge it by making BuckConstants#BUILD_RULES_FILE_NAME mutable.\n2. Refactor a whole bunch of classes to have access to BuckConfig.\nThese are decisions better left to the project owners. I can still do the PR if you want, but I'd appreciate guidance on the best way to proceed. Also I'm not sure what your conventions are for import statements. I noticed when I made some changes, my editor completely rearranged them :\\ Perhaps there's some Eclipse settings I could import?\nAlso what's your process for assignment of copyright? Since I'd need to get the patched cleared with mine employer.\n. Hmm, unfortunately the Facebook CLA is rejected by my employer because they couldn't agree on the terms. I wish I could write the PR for you guys, but I guess now that's out of the question :cry: \n. You're amazing; thank you! :dancer: \n. I've confirmed it works. Kudos @Coneko.\n. ",
    "xasima": "That needs to be used near the all-jars dependency include\n```\nimport re\njar_deps = []\n  for jarfile in glob(['libs/.jar']):\n    name = 'jars__' + re.sub(r'^./([^/]+).jar$', r'\\1', jarfile)\n    jar_deps.append(':' + name)\n    prebuilt_jar(\n      name = name,\n      binary_jar = jarfile,\n    )\nandroid_library(\n    name = 'all-jars',\n    exported_deps = jar_deps,\n  )\n```\n. That needs to be used near the all-jars dependency include\n```\nimport re\njar_deps = []\n  for jarfile in glob(['libs/.jar']):\n    name = 'jars__' + re.sub(r'^./([^/]+).jar$', r'\\1', jarfile)\n    jar_deps.append(':' + name)\n    prebuilt_jar(\n      name = name,\n      binary_jar = jarfile,\n    )\nandroid_library(\n    name = 'all-jars',\n    exported_deps = jar_deps,\n  )\n```\n. ",
    "strangemonad": "@sdwilsh @marcinkosiba I've just recently ported a large-ish project from maven to buck. Everything is now working (mostly) except for project generation. The experimental flag didn't seem to fix it but I was sure how to debug further\n. @sdwilsh @marcinkosiba I'm assuming https://github.com/facebook/buck/issues/350 is the relevant meta-task describing the experimental flag?\n. @marcinkosiba thanks for the pointer, I'll try that out. Any idea when the actual fix will land for proper java 8 support?\n. @sdwilsh cool, that looks like it fixes that issue. There are still several other issues I'm running into with the project generation but I'll track those separately \n. @sdwilsh cool, that looks like it fixes that issue. There are still several other issues I'm running into with the project generation but I'll track those separately \n. @marcinkosiba yup, I think we agree mostly. I only want the transitive lib to be included in the IjModule's runtime classpath, this patch doesn't do that but I'm wondering how hard it would be to do that? I'm basically trying to get the IJ classpath when running a target to match the 'buck run' classpath.\nThanks for pointing out the the intellij plugin in the sources. I only knew about this 3rd party library: https://github.com/wangyanxing/buck_idea_plugin. I spent about 30 mintues trying to get src/com/facebook/buck/intellij/plugin/ working but the state of the plugin's build seems to be questionable?\n. @petrumarius. thanks. I'll take a look at that approach for the plugin\n. @petrumarius. thanks. I'll take a look at that approach for the plugin\n. ",
    "nsharma-git": "I'm a beginner trying to import the gerrit project in intelliJ. I tried both \"--ide intellij\" and \"--experimental-ij-generation\"\ngerrit/gerrit-acceptance-framework/BUCK\", line 54, in \n    java_sources(\nNameError: name 'java_sources' is not defined\nBuck Version - v2016.03.28.01\nGerrit - stable-2.12\nPython - Python 2.7.10\nOS - Mac OS 10.10\n. ",
    "mkillianey": "Should be fixed at dabe44eac57c296cdf87ede3f210935f8ae8debb.\n. Now available as 2.7.1, see here: https://plugins.jetbrains.com/plugin/7826?pr=idea\n. In test/com/facebook/buck/swift/BUCK, this commit removed the swift:swift target and replaces it with unit and swift_integration_test, so this no longer points to a valid target.\n. Q:  Does using this mean that you need to update the since-build on line 144?. Observation of a potential edge case:  if you're using a build server, then building --deep may not be sufficient to make your code runnable.  IIUC, asking buck to build --deep doesn't require it to build all of your dependencies --\u00a0it is permitted to fetch ABIs from the build server, instead, if that is sufficient to build the target you've selected.. As per my other comment, I think that some of these elements won't be generated by --deep.\nIf that thinking is correct, then I'm not sure if there are one or two error conditions:\n\nIf the dependency is missing, that's because --deep only fetched the ABI from the build server.  This seems easy to detect, and could probably be remedied by repeating a more thorough version of the previous build, like buck build $(buck query 'deps(original-target)')?\nI'm unclear...is it possible for the dependency to exist, but be stale?  This would happen if buck only rebuilt the ABI and not the actual jar.  (I'm not totally sure what buck's guarantee is for --deep builds of java_library targets.)\n. Should this query also restrict the buck.type to one of the java_* targets, so that it doesn't apply to arbitrary targets like python_library or even genrule?. \n",
    "minid33": "This can also be because we're using guava which defines many many methods.\n. ",
    "dakkad": "That would make a lot of sense. For now I am bye-passing the requirement for the import flow.\n. ",
    "perezd": "Thats fine. but it should assume the default name, if I don't specify it. Both what you've said and what I've said are supported in the model I am proposing. \n. Thats fine. but it should assume the default name, if I don't specify it. Both what you've said and what I've said are supported in the model I am proposing. \n. Did a bit of analysis tonight, I think it'd be a pretty minor change around this area of the code:\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/parser/BuildTargetParser.java#L120\n. Did a bit of analysis tonight, I think it'd be a pretty minor change around this area of the code:\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/parser/BuildTargetParser.java#L120\n. Honestly, it doesn't seem less readable. If there is a target that matches the name of the folder its in, its a clear convention. If anything, being repetitive is less readable in my opinion. I guess its all subjective, however.\n. I thought those were on their way out...\n. oooh ok, I think genrule might be an option here then!\n. So, I think the issue here would be that, protoc command generates raw java files, and what we really need is java class files...so I'm not sure a pure genrule will satisfy this. Ideally we'd be able to have this auto generate effectively java_library directives and point to the generate source code as the srcs of that generated java_library. Does that make any sense?\n. From this excerpt:\nsrcs (defaults to []) The set of .java files to compile for this rule. If any of the files in this list end in .src.zip, then the entries in the ZIP file that end in .java will be included as ordinary inputs to compilation. This is common when using a genrule to auto-generate some Java source code that needs to be compiled with some hand-written Java code.\nI have a macro with 2 things, a genrule and a java_library, Is it possible for me to reference the zip file produced by the genrule within the java_library? \n. You're right, that did work. Took some finagling but its WAI now.\nOn Wed, May 20, 2015 at 12:53 PM, Shawn Wilsher notifications@github.com\nwrote:\n\nYou should just be able to specify '//path/to/genrule:rulename' in your\nsrcs, and I think it'll work.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/254#issuecomment-104014737.\n. Yeah, SGTM.\n\nOn Wed, May 20, 2015 at 12:55 PM, Shawn Wilsher notifications@github.com\nwrote:\n\nCool, should we close this then? I'm not sure we want to add explicit\nsupport (although at some point we'll add an extension API and you could\nadd the rule to do this via that if you wanted).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/254#issuecomment-104015843.\n. That should work nicely, actually. Good tip!\n. That should work nicely, actually. Good tip!\n. This is great! I think I actually do care about Flavors. Do flavors allow me to run different build rules depending on what type of build rule may depend on me? \n. This is great! I think I actually do care about Flavors. Do flavors allow me to run different build rules depending on what type of build rule may depend on me? \n. Also, for posterity, this git commit looks like a good atomic example of adding a new build rule:\nhttps://github.com/LMAX-Exchange/buck/commit/3617f4a5fc3ef8d516fec41e5a0c80937b52bdf5\n. Also, for posterity, this git commit looks like a good atomic example of adding a new build rule:\nhttps://github.com/LMAX-Exchange/buck/commit/3617f4a5fc3ef8d516fec41e5a0c80937b52bdf5\n. Yes, I'm thinking about protocol buffers, specifically. They have a cxx,\njava, and go flavor.\n\nOn Thu, Feb 19, 2015 at 10:35 AM, Shawn Wilsher notifications@github.com\nwrote:\n\nIt also sounds like you might want flavours - we use this for thrift when\na cxx_library depends on a thrift_library - we use the {rule}#cxx (or\nsomething like that) version of the rule.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/256#issuecomment-75109048.\n. Yes, I'm thinking about protocol buffers, specifically. They have a cxx,\njava, and go flavor.\n\nOn Thu, Feb 19, 2015 at 10:35 AM, Shawn Wilsher notifications@github.com\nwrote:\n\nIt also sounds like you might want flavours - we use this for thrift when\na cxx_library depends on a thrift_library - we use the {rule}#cxx (or\nsomething like that) version of the rule.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/256#issuecomment-75109048.\n. \n",
    "amitkot": "With the stable version I'm getting this error:\nbash\n$ buck build app\nUsing watchman.\n/Users/amit/Library/LaunchAgents/com.github.facebook.watchman.plist:\nOperation already in progress\n1425199381: tid=2072961792 unable to talk to your watchman!\nTraceback (most recent call last):\n  File \"/opt/buck/bin/../programs/buck.py\", line 52, in <module>\n    sys.exit(main(sys.argv))\n  File \"/opt/buck/bin/../programs/buck.py\", line 45, in main\n    return buck_repo.launch_buck(build_id)\n  File \"/opt/buck/programs/buck_tool.py\", line 122, in launch_buck\n    self.launch_buckd(buck_version_uid=buck_version_uid)\n  File \"/opt/buck/programs/buck_tool.py\", line 169, in launch_buckd\n    self._setup_watchman_watch()\n  File \"/opt/buck/programs/buck_tool.py\", line 303, in _setup_watchman_watch\n    stderr=subprocess.STDOUT)\n  File \"/opt/buck/programs/buck_tool.py\", line 476, in check_output\n    raise CalledProcessError(retcode, cmd, output=output)\nbuck_tool.CalledProcessError: Command '['watchman', 'watch',\n'/private/tmp/ddd/trial']' returned non-zero exit status 1\n. Any idea why this doesn't work, or what workaround can I use?\n. Any idea why this doesn't work, or what workaround can I use?\n. @Coneko After reboot it works using stable version. Thanks!\n. @Coneko After reboot it works using stable version. Thanks!\n. I have some more insights. Out of the four AIDL files, it seems 3 only contain parcelable objects (as the error describes), which leaves us with only one AIDL file to be handled - ControlService.aidl .\nI made the minimal changes to the BUCK file so that it will handle only that AIDL file:\npython\nproj_gen_aidls = []\nfor aidlfile in glob(['src/main/java/**/ControlService.aidl']):\n    name = 'proj_aidls__' + re.sub(r'^.*/([^/]+)\\.aidl$', r'\\1', aidlfile)\n    proj_gen_aidls.append(':' + name)\n    gen_aidl(\n        name = name,\n        aidl = aidlfile,\n        import_path = 'src',\n)\nNow I am getting the following errors:\nsrc/main/java/com/mobile/proj/be/api/ControlService.aidl:3: couldn't find import for class\ncom.mobile.proj.domain.TripState\nsrc/main/java/com/mobile/proj/be/api/ControlService.aidl:4: couldn't find import for class\ncom.mobile.proj.domain.BackendServiceState\nsrc/main/java/com/mobile/proj/be/api/ControlService.aidl:5: couldn't find import for class com.mobile.proj.domain.VehicleState\nIt looks as though the import_path doesn't reach those Java files, however, they are indeed located in the src directory:\nsh\n$ ls -a .buckconfig\n.buckconfig\n$ find . | egrep 'BackendServiceState.java|TripState.java|VehicleState.java'\n./src/main/java/com/mobile/proj/domain/BackendServiceState.java\n./src/main/java/com/mobile/proj/domain/TripState.java\n./src/main/java/com/mobile/proj/domain/VehicleState.java\nSo why isn't the gen_aidl() task able to import those java files?\n. I have some more insights. Out of the four AIDL files, it seems 3 only contain parcelable objects (as the error describes), which leaves us with only one AIDL file to be handled - ControlService.aidl .\nI made the minimal changes to the BUCK file so that it will handle only that AIDL file:\npython\nproj_gen_aidls = []\nfor aidlfile in glob(['src/main/java/**/ControlService.aidl']):\n    name = 'proj_aidls__' + re.sub(r'^.*/([^/]+)\\.aidl$', r'\\1', aidlfile)\n    proj_gen_aidls.append(':' + name)\n    gen_aidl(\n        name = name,\n        aidl = aidlfile,\n        import_path = 'src',\n)\nNow I am getting the following errors:\nsrc/main/java/com/mobile/proj/be/api/ControlService.aidl:3: couldn't find import for class\ncom.mobile.proj.domain.TripState\nsrc/main/java/com/mobile/proj/be/api/ControlService.aidl:4: couldn't find import for class\ncom.mobile.proj.domain.BackendServiceState\nsrc/main/java/com/mobile/proj/be/api/ControlService.aidl:5: couldn't find import for class com.mobile.proj.domain.VehicleState\nIt looks as though the import_path doesn't reach those Java files, however, they are indeed located in the src directory:\nsh\n$ ls -a .buckconfig\n.buckconfig\n$ find . | egrep 'BackendServiceState.java|TripState.java|VehicleState.java'\n./src/main/java/com/mobile/proj/domain/BackendServiceState.java\n./src/main/java/com/mobile/proj/domain/TripState.java\n./src/main/java/com/mobile/proj/domain/VehicleState.java\nSo why isn't the gen_aidl() task able to import those java files?\n. ",
    "benhyland": "Different team members seem to have somewhat different experiences, but in my case I can repro fairly reliably by \na) first running 'buck test --no-results-cache' with a filter that selects our usual complement of 'fast' unit tests, and then \nb) running 'buck test' repeatedly with no changes will repro for at least the first few builds.\nIf instead in b) I run 'strace -f -e connect,sendto,execve buck test' I can reliably see buck get an EPIPE in response to a sendto which was sending \"\\0\\0\\0\\0H\" - a heartbeat. Because (I think) the signal handler and socket are not configured from the default, we also get a SIGPIPE raised.\n. Since pulling in changes from the upstream nailgun client, natthu's changes (e.g. https://github.com/facebook/buck/commit/371f502640527492eda2046f0dcc4afb2d5216bf#diff-56a419ae8baaa423da656f7379077866) have been lost, and the above-referenced patch no longer applies cleanly (by the way, we have had this change on our fork for a couple weeks and it does fix the issue I described above).\nYou should probably decide how you wish to manage buck-local changes to the nailgun client to avoid losing work in future - perhaps make it clear that patches should be applied upstream and stop accepting pull requests in this area, or else maintain the ability to merge local changes with upstream changes when you choose to resync.\n. I don't think this is fixed until https://github.com/martylamb/nailgun/pull/57 is merged upstream and buck's copy of the client updated.\n. Sorry, I don't know enough of nailgun to say, but I would guess not. Assuming nailgun server usually sends a message to the client indicating the end of its output and that https://github.com/martylamb/nailgun/pull/49 ensures this is message always seen by the client, I think the client will still have a race where it might not have processed that message and stopped heartbeating before the server closes the socket. In which case, you will still need https://github.com/martylamb/nailgun/pull/57 to avoid the SIGPIPE in the client.\n. Sorry, I don't know enough of nailgun to say, but I would guess not. Assuming nailgun server usually sends a message to the client indicating the end of its output and that https://github.com/martylamb/nailgun/pull/49 ensures this is message always seen by the client, I think the client will still have a race where it might not have processed that message and stopped heartbeating before the server closes the socket. In which case, you will still need https://github.com/martylamb/nailgun/pull/57 to avoid the SIGPIPE in the client.\n. Sorry for the noise, didn't notice the merge conflicts\n. ",
    "martylamb": "Just merged it.  Thanks much.\n. ",
    "denji": "@sdwilsh @benhyland e6ed02c\n. ",
    "plinehan": "Thanks, yeah I found out about \"exopackage_modes\" about 20 minutes after submitting this :)\n. Ha, a good guess!  I also suspected that I bisected wrong, so I went back and double-checked that the problem appears right at this commit.\nThe icon is missing in this scenario:\n/uninstall app from phone/\n$ buck kill & rm -fr buck-out/ buck-cache/\n$ echo 6ac44db66e0209dc7ea5b5cebe5396ab2611f33c > .buckversion\n$ buck build, install, etc\nAnd present in this scenario:\n/uninstall app from phone/\n$ buck kill & rm -fr buck-out/ buck-cache/\n$ echo 4c071483996bf84450438ccf20723a845086be85 > .buckversion\n$ buck build, install, etc\nThe first two steps of each process (uninstalling the app, buck kill-ing, and clearing caches) are just me being extremely paranoid about making the process as hermetic as possible.\n. So it turns out that the app isn't missing the icon, it is just picking up a default-looking icon from one of our external dependencies, specifically the Dropbox Chooser SDK.  They include ic_launcher.png images for a few display densities, and as a result of this change they are now being used instead of our ic_launcher.png files.\nIf I just delete the images from the Dropbox Chooser SDK, the problem goes away.  I'm assuming this commit now considers the resources equivalent, so it is arbitrarily picking the Dropbox resources?\nI'm totally fine to delete the Dropbox images and just move forward, but this does seem like a bug.  The Dropbox resources are in their own package, as evidenced by our dropbox-chooser/BUCK file:\nandroid_resource(\n  name = \"res\",\n  res = \"res\",\n  package = \"com.dropbox.chooser.android\",\n)\nIs the package name not considered when merging or comparing resources?  I'm just confused as to why this is happening, even if it was odd for us to have the duplicate resources.\nAlso, thanks for building Buck.  It is a fantastic piece of software.\n. If anyone knows of a comparable commit I could steal/borrow from I could take a swing at a PR for this.. Done!. ",
    "zuolongxiang": "I hope this bug could fix it soon.\n. ",
    "8enet": "I cannot build,always receive same problem.\n. ",
    "jamesgpearce": "Isn't the point that buck is always quick so doesn't need a qualifying adjective?\n. ",
    "nanaze": "@jamesgpearce It's more of a marketing thing. Fast cars look fast, right? \nSay hi to @bolinfest for me.\n. @jamesgpearce It's more of a marketing thing. Fast cars look fast, right? \nSay hi to @bolinfest for me.\n. ",
    "MartinRogalla": "Thank you so much for your contributions. How stable is Buck currently for iOS? Do you have an ETA for when it will be fully supported and documented?\n. ",
    "grp": "Interesting. Maybe you could add a target that depends on all of them, and add an alias in .buckconfig called all pointing to it? Then it'd be as simple as buck build all, at the cost of one extra target to maintain.\n. ",
    "csdigi": "It would be nice to support the same syntax for target visibility at the command line\nBuild all targets under this BUCK file\nbuck build //package1/package2/...\nBuild all targets referenced  by this BUCK file\nbuck build //package1:all \nThe same for test would be nice. IMO this much better than messing up your target structure by introducing functionless targets.\n. ",
    "luser": "For comparison Bazel has :all:\nhttp://bazel.io/docs/bazel-user-manual.html#target-patterns\n. Yes, I'd like to indicate that I want an actual shared library. rr has a shared library that it needs to use with LD_PRELOAD, so it really needs a shared library there. AFAIK there's no way for buck to automatically select anything because nothing else depends on it (rr doesn't actually link to the library).\n. buck audit rules already exists, so maybe buck audit known-build-rules.\n. (The test failures in the Travis build are because I didn't update the unit tests that check the usage output.)\n. Probably not right now, although I haven't forgotten about it. If you would like to do it yourself I won't be offended.\n. No. If you look at the log you can see that it's both preprocessing and compiling every source file.\n. This is basically a deal-breaker for using buck for C++ projects, FWIW.\n. Finally got around to updating and trying this out again and this works as expected now. Thanks!\n. Finally got around to updating and trying this out again and this works as expected now. Thanks!\n. ",
    "nayrmi": "If folks hit this in the future, we'd always welcome a pull request. Otherwise, this isn't needed for the time being.\n. Closing issue since it was a copy error. Thanks!\n. Thanks for the report, Josh! We've committed a fix and will have it out in the next push.\n. Closing since there's no repro now. However, feel free to reactivate if you are able to generate a consistent repro!\n. Closing for now. Feel free to reopen if you want to take a stab at it!\n. Closing because we haven't heard back from @spierce7. But we'll be here if you want to reactivate!\n. Closing out since we haven't heard back from @zlwen - but we'll be here if you want to reactivate!\n. Closing because we haven't heard back from @avnerbarr. However, we'll be here if you want to reactivate!\n. Hey @davido - this should be resolved now. Let us know if you're still hitting this.\n. We're completely unable to repro now - @ASCE1885, are you still seeing this at all? I know, it's been a bit...\n. @ASCE1885 - I'm guessing that this resolved your issue. If not, please reactivate!\n. Indeed a dupe of #371.\n. Closing out since we have heard from folks in a few months. However, @mremick - feel free to reactivate if you have more info to provide!\n. @cbrauchli / @dflems - I'm closing this out with @andrewjcg's response, but please reactivate if you're still hitting this!\n. ",
    "tdrhq": "It's still possible to create an instrumentation test, just that you need to add some boilerplate. I'll explain the easier version where you're creating an instrumentation test for a library, which means it's mostly just an android_binary() that includes all your sources and your test code.\nThe difference is you need to specify the  tag in your AndroidManifest for this binary, make the instrumented package to point to the itself. (i.e. if the AndroidManifest's package is com.foo.bar, the android:targetPackage in the  should point to com.foo.bar):\n\n  <instrumentation\n      android:name=\"android.test.InstrumentationTestRunner\"\n      android:targetPackage=\"com.foo.bar\" />\n\nYou can then install it using buck-install, and run it manually using:\n\n  adb shell am instrument -w com.foo.bar/android.test.InstrumentationRunner\n\nObviously, this isn't ideal, and we should definitely make this flow better.\n. Also, can you add an example target? I think all the examples are in test/com/facebook/buck/android/testdata (@sdwilsh would know better). That way I can apply your patch and play around with running the tests locally.\nThe example target would also help us iron out issues with how the API looks like.\n. Also, can you add an example target? I think all the examples are in test/com/facebook/buck/android/testdata (@sdwilsh would know better). That way I can apply your patch and play around with running the tests locally.\nThe example target would also help us iron out issues with how the API looks like.\n. @kageiit  This should be easy to do, but how much of a regression are we talking about? The code coverage logic has broken a few times in the past, so having fewer variations on the code path would prevent this from breaking again. If the regression is really significant, then I can put in a few if-elses. To be clear, it shouldn't be every single jar file, it should only be the ones that have the given test in their tests = [] argument. (So, ideally just 2-3 at most even in a big repository). @kageiit I see, so your concern is with CI runs where you run all the tests, correct? Local runs probably don't get affected as much because people probably run a few targets at a time. Just understanding the situation right now.. will be doing this soon, I would still love some kind of number to get a sense of what percentage increase we're talking about, an approximation would do. woops sorry, I'll work on this today. woops sorry, I'll work on this today. Fixed in https://github.com/facebook/buck/commit/a4cd1b0561cbd56a2ab2fa1e4ac3be37ce986d9a\nLet me know if it works. it's a little bit of work but this can be detected from the apk without having to manually specify it. Here's for example some python code that does the same (this might not be the best way of doing it, but it does the job):\n```\ndef get_instrumentation_runner(apk):\n    output = subprocess.check_output(['aapt', 'dump', 'xmltree', apk, 'AndroidManifest.xml'], stderr=os.devnull)\n    name_regex = re.compile('E: instrumentation.?A: android:name.?=\"(.?)\".?Raw', flags=re.DOTALL)\nm = name_regex.search(output)\nif m:\n    return m.group(1)\nraise RuntimeError(\"Could not find instrumentation\")\n\n```\n. does this also work with the manifest points to an android_manifest rule?\n. this should a failure, right?\n. I would also love to support the case where the APK is instrumenting itself. (that is the case for most \"library\" tests, you only have to install the APK which bundles both the library and the tests together)\nIt doesn't look like that would be too much more work to support, correct?\n. @sdwilsh please look at this file\nI don't know the caching semantics of Steps, so I don't know if this is a reasonable thing to do in buck steps.\nAlso, should this be renamed to something specific for instrumentation tests? I know there's nothing instrumentation tests specific in this, but it could be confusing for n00b looking through buck's code.\n. just to verify, this works will work with exopackage, right?\n. thanks for the sample buck files!\n. I feel like it makes more semantic sense to make baseApk optional and instrumentation_apk as required.\nThe reason is that the instrumentation_apk is the one that defines  in the manifest, and then in the self-instrumenting case it somehow feels more right to still call that an instrumentation_apk.\n. hmm, why is this? I don't see any obvious reason why this should be the case\n. suggestion for another version (we don't have to do this in this pull request):\nwe should be able to update the AndroidManifest to automatically generate the instrumentation/targetPackage field based on the properties here so we can remove that piece of redundancy. I think gradle does something like this, but let's leave this to another change.\n. this is redundant.. if you're supporting using android_instrumentation_apk() in the instrumentation_apk() target, you can automatically figure this out. So let's remove this altogether:\na. for apks instrumenting itself, we just need to point to an android_binary()\nb. for apks instrumenting another apk, we point to an android_instrumentation_apk(). \nIs this easy to do?\n. Yep that's what I meant. Shouldn't need changes to android_instrumentation_apk, right?\n. perhaps we can just call this 'apk' now. Aside from that the API looks great\n. ",
    "tgummerer": "Yes, unfortunately.  But I have to admit I didn't really have time to look into it more deeply over the last few days.\n. Yes, unfortunately.  But I have to admit I didn't really have time to look into it more deeply over the last few days.\n. @sdwilsh I took another stab at it, and finally figured out where the issue was.  I needed to add the library to JAVA_CLASSPATHS in programs/buck_repo.py.\n. @sdwilsh I took another stab at it, and finally figured out where the issue was.  I needed to add the library to JAVA_CLASSPATHS in programs/buck_repo.py.\n. Heh yeah, my grep skills left me down for a while there.  No worries, I'll be moving at the end of the next week, so I probably won't have too much time to spend on buck anyway.  Thanks a lot for your help so far :smiley: \n. Heh yeah, my grep skills left me down for a while there.  No worries, I'll be moving at the end of the next week, so I probably won't have too much time to spend on buck anyway.  Thanks a lot for your help so far :smiley: \n. Thanks, that looks much nicer!\n. Yeah, sorry I didn't notice.  I tried, but GitHub doesn't seem to let me just add one commit to the pull request, as the second one depends on the first one.  I could make it a separate commit, not depending on the first one, but that will result in a merge conflict, so I guess it's still simpler for you this way?\n. Yeah, sorry I didn't notice.  I tried, but GitHub doesn't seem to let me just add one commit to the pull request, as the second one depends on the first one.  I could make it a separate commit, not depending on the first one, but that will result in a merge conflict, so I guess it's still simpler for you this way?\n. Thanks, I saw you merged the other pull request now, so I updated this one to just include the right commit.\n. Thanks, I saw you merged the other pull request now, so I updated this one to just include the right commit.\n. Thanks a lot for your review.  I updated the pull request :) \n. Thanks a lot for your review.  I updated the pull request :) \n. No worries, there is no rush :) I updated the pull request.\n. No worries, there is no rush :) I updated the pull request.\n. Sorry about that.  Is there any way to catch those issues automatically? I rebased the second commit now.\n. Sorry about that.  Is there any way to catch those issues automatically? I rebased the second commit now.\n. Thanks, will do for my future commits.\n. Thanks, will do for my future commits.\n. Thanks, will do for my future commits.\n. Hi, \nI took a look at your project.  An android_resource cannot depend on a prebuilt_jar.  Instead you have to use a android_prebuilt_aar rule for the appcompat library (you probably want to use that rule for the other android libraries as well).\nThere is another error after fixing this one (missing icon in drawable), but that should be easier to fix.\n. Hi, \nI took a look at your project.  An android_resource cannot depend on a prebuilt_jar.  Instead you have to use a android_prebuilt_aar rule for the appcompat library (you probably want to use that rule for the other android libraries as well).\nThere is another error after fixing this one (missing icon in drawable), but that should be easier to fix.\n. I think the problem are the System.out.println() statements in TestNGRunner.  I experienced similar things when I added such statements for debugging purposes.\nI think the following might fix it, but I don't have any TestNG tests around with which I could test it, so I'm not submitting a pull request.\n```\ndiff --git a/src/com/facebook/buck/junit/TestNGRunner.java b/src/com/facebook/buck/junit/TestNGRunner.java\nindex b9f149e..3ede20e 100644\n--- a/src/com/facebook/buck/junit/TestNGRunner.java\n+++ b/src/com/facebook/buck/junit/TestNGRunner.java\n@@ -44,9 +44,7 @@ import java.util.List;\n public final class TestNGRunner extends BaseRunner {\n   @Override\n   public void run() throws Throwable {\n-    System.out.println(\"TestNGRunner started!\");\n     for (String className : testClassNames) {\n-      System.out.println(\"TestNGRunner handling \" + className);\n       final Class<?> testClass = Class.forName(className);\n   List<TestResult> results;\n\n@@ -60,7 +58,6 @@ public final class TestNGRunner extends BaseRunner {\n         TestListener listener = new TestListener(results);\n         tester.addListener(new TestListener(results));\n         try {\n-          System.out.println(\"TestNGRunner running \" + className);\n           tester.initializeSuitesAndJarFile();\n           tester.runSuitesLocally();\n         } catch (Throwable e) {\n@@ -79,12 +76,10 @@ public final class TestNGRunner extends BaseRunner {\n               ResultType.FAILURE, e,\n               \"\", \"\"));\n         }\n-        System.out.println(\"TestNGRunner tested \" + className + \", got \" + results.size());\n       }\n   writeResult(className, results);\n }\n\n\nSystem.out.println(\"TestNGRunner done!\");\n   }\n\nprivate XmlSuite createXmlSuite(Class<?> c) {\n``\n. I think the problem are theSystem.out.println()statements inTestNGRunner`.  I experienced similar things when I added such statements for debugging purposes.\nI think the following might fix it, but I don't have any TestNG tests around with which I could test it, so I'm not submitting a pull request.\n```\ndiff --git a/src/com/facebook/buck/junit/TestNGRunner.java b/src/com/facebook/buck/junit/TestNGRunner.java\nindex b9f149e..3ede20e 100644\n--- a/src/com/facebook/buck/junit/TestNGRunner.java\n+++ b/src/com/facebook/buck/junit/TestNGRunner.java\n@@ -44,9 +44,7 @@ import java.util.List;\n public final class TestNGRunner extends BaseRunner {\n   @Override\n   public void run() throws Throwable {\n-    System.out.println(\"TestNGRunner started!\");\n     for (String className : testClassNames) {\n-      System.out.println(\"TestNGRunner handling \" + className);\n       final Class<?> testClass = Class.forName(className);\n   List<TestResult> results;\n\n@@ -60,7 +58,6 @@ public final class TestNGRunner extends BaseRunner {\n         TestListener listener = new TestListener(results);\n         tester.addListener(new TestListener(results));\n         try {\n-          System.out.println(\"TestNGRunner running \" + className);\n           tester.initializeSuitesAndJarFile();\n           tester.runSuitesLocally();\n         } catch (Throwable e) {\n@@ -79,12 +76,10 @@ public final class TestNGRunner extends BaseRunner {\n               ResultType.FAILURE, e,\n               \"\", \"\"));\n         }\n-        System.out.println(\"TestNGRunner tested \" + className + \", got \" + results.size());\n       }\n   writeResult(className, results);\n }\n\n\nSystem.out.println(\"TestNGRunner done!\");\n   }\n\nprivate XmlSuite createXmlSuite(Class<?> c) {\n``\n. @jiangty-addepar ah sorry I didn't see that.  I also can't reproduce this easily myself with the sample @sdwilsh pointed out, so I won't be looking into this further, as I don't have use for testng myself.\n. @reondz your issue in the demo project is somewhat different.  Because buck doesn't include transitive dependencies for the resources,R.attr.colorPrimarywill not be available in thereon.me.helloworldpackage, but only in theandroid.support.v7.appcompatpackage.  So the following diff fixesbuck build app:lib` in your project.\n``` diff\ndiff --git a/app/src/main/java/reon/me/helloworld/MainActivity.java b/app/src/main/java/reon/me/helloworld/MainActivity.java\nindex 4cd64ca..7301885 100644\n--- a/app/src/main/java/reon/me/helloworld/MainActivity.java\n+++ b/app/src/main/java/reon/me/helloworld/MainActivity.java\n@@ -11,7 +11,7 @@ public class MainActivity extends AppCompatActivity {\n     protected void onCreate(Bundle savedInstanceState) {\n         super.onCreate(savedInstanceState);\n         setContentView(R.layout.activity_main);\n-        int a = R.attr.colorPrimary;\n+        int a = android.support.v7.appcompat.R.attr.colorPrimary;\n     }\n @Override\n\n```\n. @tdrhq thanks for the review, I updated the pull request according to your suggestions.  The example is very basic, as it includes no actual tests, I can expand that if needed.\nThere's still no documentation, I'll add that once we agree how the API will look like.\n. @tdrhq thanks for the review, I updated the pull request according to your suggestions.  The example is very basic, as it includes no actual tests, I can expand that if needed.\nThere's still no documentation, I'll add that once we agree how the API will look like.\n. Thanks @sdwilsh and @tdrhq for your reviews.  I addressed the comments and updated the pull request.  Here's an overview of the changes since the last version:\n- Add support for apk instrumenting itself\n- Changed the test code in the testdata directory.  It now actually executes some tests and has an android_instrumentation_test that tests an exopackage (exopackages can't instrument test themselves.  If the user tries that a HumanReadableException is raised).\n- Removed the extra constructor in ApkInstallStep\n- Added documentation (It is in a separate commit, but I can squash it if that's preferred)\n- Removed deps parameter.  I don't think it's needed, as all dependencies are needed in the apks.\n- Fix a couple of infer eradicate errors (They were false positives, but simple to fix)\n- Rebased on the latest master\n. Thanks @sdwilsh and @tdrhq for your reviews.  I addressed the comments and updated the pull request.  Here's an overview of the changes since the last version:\n- Add support for apk instrumenting itself\n- Changed the test code in the testdata directory.  It now actually executes some tests and has an android_instrumentation_test that tests an exopackage (exopackages can't instrument test themselves.  If the user tries that a HumanReadableException is raised).\n- Removed the extra constructor in ApkInstallStep\n- Added documentation (It is in a separate commit, but I can squash it if that's preferred)\n- Removed deps parameter.  I don't think it's needed, as all dependencies are needed in the apks.\n- Fix a couple of infer eradicate errors (They were false positives, but simple to fix)\n- Rebased on the latest master\n. @tdrhq thank you very much for the new review.  I addressed your comments in the new version.\n. @tdrhq thank you very much for the new review.  I addressed your comments in the new version.\n. I somehow messed up the tests, and they failed to build the android_instrumentation_apk.  I've updated the pull request, and also rebased it onto the latest master branch.  This is the diff without the rebase:\ndiff --git a/test/com/facebook/buck/android/testdata/android_instrumentation_test_integration_test/apps/myapp/BUCK b/test/com/facebook/buck/android/testdata/android_instrumentation_test_integration_test/apps/myapp/BUCK\nindex 7fbfdc0..3c29cdb 100644\n--- a/test/com/facebook/buck/android/testdata/android_instrumentation_test_integration_test/apps/myapp/BUCK\n+++ b/test/com/facebook/buck/android/testdata/android_instrumentation_test_integration_test/apps/myapp/BUCK\n@@ -28,7 +28,6 @@ android_binary(\n     '//java/com/example/app:app',\n     '//java/com/example/activity:activity',\n     '//res/com/example/activity:res',\n-    '//test/com/example/activity:activity_test',\n   ],\n   visibility = ['PUBLIC'],\n )\n. I updated the pull request according to the latest comments.  The end result looks much nicer and is simpler to use with the apk target removed. Thanks!\nA diff between the two versions is available at https://gist.github.com/tgummerer/71bd19b2f142b149071c.\n. @marcinkosiba yes, they were the only reason.  I didn't particularly like these changes in the first place, I just didn't know of a better alternative to avoid the output.  Using easymock does indeed look much nicer, I'll try to change it to that. Thanks for the suggestion!\n. @marcinkosiba yes, they were the only reason.  I didn't particularly like these changes in the first place, I just didn't know of a better alternative to avoid the output.  Using easymock does indeed look much nicer, I'll try to change it to that. Thanks for the suggestion!\n. I updated the pull request to use easymock.  Using createNiceMock() doesn't work, because it returns null, but using createMock() works well.\n. I updated the pull request to use easymock.  Using createNiceMock() doesn't work, because it returns null, but using createMock() works well.\n. @marcinkosiba oh wait, I think I might have misread the message.  The Console and BuckEventBus are optional, so that there is no unnecessary output when running buck test in a project with an android_instrumentation_apk, not when running it on buck itself.  I still think this is nicer, but I'm not sure easymock should be used in the production code.  I uploaded the version with Console and BuckEventBus as Optional to https://github.com/tgummerer/buck/tree/instrumentation-test-optional for comparison.\n. @marcinkosiba oh wait, I think I might have misread the message.  The Console and BuckEventBus are optional, so that there is no unnecessary output when running buck test in a project with an android_instrumentation_apk, not when running it on buck itself.  I still think this is nicer, but I'm not sure easymock should be used in the production code.  I uploaded the version with Console and BuckEventBus as Optional to https://github.com/tgummerer/buck/tree/instrumentation-test-optional for comparison.\n. Thanks :) Is there anything like a Helped-by: line or something similar for buck, as especially @tdrhq helped a lot getting this code in shape.\n. Thanks :) Is there anything like a Helped-by: line or something similar for buck, as especially @tdrhq helped a lot getting this code in shape.\n. Thanks, I updated the pull request (just the commit message in the Add android_instrumentation_test commit).\n. Thanks, I updated the pull request (just the commit message in the Add android_instrumentation_test commit).\n. I updated the pull request, with most of @marcinkosiba's comments addressed.  The only one's that are still not addressed are adding the AdbHelper to the ExecutionContext (see comment https://github.com/tgummerer/buck/commit/e52918311db8be5ef940ef2a08c895a19be51e03#commitcomment-12375376), and moving the code to AndroidInstrumentationApk, see comment (https://github.com/tgummerer/buck/commit/e52918311db8be5ef940ef2a08c895a19be51e03#commitcomment-12374549)\n. I updated the pull request, with most of @marcinkosiba's comments addressed.  The only one's that are still not addressed are adding the AdbHelper to the ExecutionContext (see comment https://github.com/tgummerer/buck/commit/e52918311db8be5ef940ef2a08c895a19be51e03#commitcomment-12375376), and moving the code to AndroidInstrumentationApk, see comment (https://github.com/tgummerer/buck/commit/e52918311db8be5ef940ef2a08c895a19be51e03#commitcomment-12374549)\n. @marcinkosiba thanks for your latest comments, I updated the pull request accordingly.\n. @marcinkosiba thanks for your latest comments, I updated the pull request accordingly.\n. @marcinkosiba Thanks a lot for the help! I addressed the questions in the update.  Interdiff:\ndiff\ndiff --git a/build.xml b/build.xml\nindex 5effe72..74d147f 100644\n--- a/build.xml\n+++ b/build.xml\n@@ -104,7 +104,6 @@\n     <include name=\"jetty/jetty-all-9.2.10.v20150310.jar\" />\n     <include name=\"jimfs/jimfs-1.0.jar\" />\n     <include name=\"jsr/javax.inject-1.jar\" />\n-    <include name=\"kxml2/kxml2-2.3.0.jar\" />\n     <include name=\"okhttp/okhttp-2.2.0.jar\" />\n     <include name=\"okio/okio-1.2.0.jar\" />\n     <include name=\"servlet-api/javax.servlet-api-3.1.0.jar\" />\ndiff --git a/programs/buck_repo.py b/programs/buck_repo.py\nindex 05ae450..c72391c 100644\n--- a/programs/buck_repo.py\n+++ b/programs/buck_repo.py\n@@ -21,7 +21,6 @@ JAVA_CLASSPATHS = [\n     \"third-party/java/aopalliance/aopalliance.jar\",\n     \"third-party/java/args4j/args4j-2.0.30.jar\",\n     \"third-party/java/asm/asm-debug-all-5.0.3.jar\",\n-    \"third-party/java/cglib/cglib-nodep-2.2.jar\",\n     \"third-party/java/closure-templates/soy-excluding-deps.jar\",\n     \"third-party/java/commons-compress/commons-compress-1.8.1.jar\",\n     \"third-party/java/dd-plist/dd-plist.jar\",\n@@ -52,7 +51,6 @@ JAVA_CLASSPATHS = [\n     \"third-party/java/jsr/jsr305.jar\",\n     \"third-party/java/kxml2/kxml2-2.3.0.jar\",\n     \"third-party/java/nailgun/nailgun-server-0.9.2-SNAPSHOT.jar\",\n-    \"third-party/java/objenesis/objenesis-1.2.jar\",\n     \"third-party/java/okhttp/okhttp-2.2.0.jar\",\n     \"third-party/java/okio/okio-1.2.0.jar\",\n     \"third-party/java/servlet-api/javax.servlet-api-3.1.0.jar\",\n. @marcinkosiba Thanks a lot for the help! I addressed the questions in the update.  Interdiff:\ndiff\ndiff --git a/build.xml b/build.xml\nindex 5effe72..74d147f 100644\n--- a/build.xml\n+++ b/build.xml\n@@ -104,7 +104,6 @@\n     <include name=\"jetty/jetty-all-9.2.10.v20150310.jar\" />\n     <include name=\"jimfs/jimfs-1.0.jar\" />\n     <include name=\"jsr/javax.inject-1.jar\" />\n-    <include name=\"kxml2/kxml2-2.3.0.jar\" />\n     <include name=\"okhttp/okhttp-2.2.0.jar\" />\n     <include name=\"okio/okio-1.2.0.jar\" />\n     <include name=\"servlet-api/javax.servlet-api-3.1.0.jar\" />\ndiff --git a/programs/buck_repo.py b/programs/buck_repo.py\nindex 05ae450..c72391c 100644\n--- a/programs/buck_repo.py\n+++ b/programs/buck_repo.py\n@@ -21,7 +21,6 @@ JAVA_CLASSPATHS = [\n     \"third-party/java/aopalliance/aopalliance.jar\",\n     \"third-party/java/args4j/args4j-2.0.30.jar\",\n     \"third-party/java/asm/asm-debug-all-5.0.3.jar\",\n-    \"third-party/java/cglib/cglib-nodep-2.2.jar\",\n     \"third-party/java/closure-templates/soy-excluding-deps.jar\",\n     \"third-party/java/commons-compress/commons-compress-1.8.1.jar\",\n     \"third-party/java/dd-plist/dd-plist.jar\",\n@@ -52,7 +51,6 @@ JAVA_CLASSPATHS = [\n     \"third-party/java/jsr/jsr305.jar\",\n     \"third-party/java/kxml2/kxml2-2.3.0.jar\",\n     \"third-party/java/nailgun/nailgun-server-0.9.2-SNAPSHOT.jar\",\n-    \"third-party/java/objenesis/objenesis-1.2.jar\",\n     \"third-party/java/okhttp/okhttp-2.2.0.jar\",\n     \"third-party/java/okio/okio-1.2.0.jar\",\n     \"third-party/java/servlet-api/javax.servlet-api-3.1.0.jar\",\n. Thanks for all the help getting this in, especially @tdrhq and @marcinkosiba for the reviews :)\n. Thanks for all the help getting this in, especially @tdrhq and @marcinkosiba for the reviews :)\n. Hi,\nthe preferred way is to check in jars or aars in the repository, and use the prebuilt_jar and the android_prebuilt_aar rules to make them available for the other rules.\nIf you don't want to check the dependencies into the repository you can use remote_file rules, but then you have to remember to use buck fetch before running buck build.\n. Hi,\nthe preferred way is to check in jars or aars in the repository, and use the prebuilt_jar and the android_prebuilt_aar rules to make them available for the other rules.\nIf you don't want to check the dependencies into the repository you can use remote_file rules, but then you have to remember to use buck fetch before running buck build.\n. Using prebuilt_native_library. (http://buckbuild.com/rule/prebuilt_native_library.html)\n. Using prebuilt_native_library. (http://buckbuild.com/rule/prebuilt_native_library.html)\n. I now tried to update the design library to version 22.2.1, but that seems to make things even worse.  That version fails at the compilation step with:\n```\n$ buck build lib:design-library\nNot using buckd because watchman isn't installed.\n[-] PROCESSING BUCK FILES...FINISHED 0.0s\n[+] BUILDING...0.6s (4/8 JOBS, 2 UPDATED, 0.0% CACHE HITS)\n |=> IDLE\n |=> //lib:design-library#aar_android_resource...  0.1s (running generate_resource_ids[0.0s])\n |=> IDLE\n |=> IDLE\n |=> IDLE\n |=> IDLE\n |=> IDLE\n |=> IDLE\n |=> IDLE\n |=> IDLE\n[2015-07-23 16:19:54.586][error][command:30dace5d-e02a-4b63-aa4c-e4b4946f3d91][tid:15][com.facebook.buck.event.listener.LoggingBuildListener] The following resources were not found when processing buck-out/bin/lib/unpack_design-library#aar_unzip/res: \nRDotTxtEntry{idType=int, type=style, name=TextAppearance_AppCompat_Body2, idValue=0x00000000}\njava.lang.RuntimeException\njava.lang.RuntimeException\n    at com.facebook.buck.android.aapt.MiniAapt.execute(MiniAapt.java:151)\n    at com.facebook.buck.step.DefaultStepRunner.runStepForBuildTarget(DefaultStepRunner.java:62)\n    at com.facebook.buck.rules.CachingBuildEngine.executeCommandsNowThatDepsAreBuilt(CachingBuildEngine.java:730)\n    at com.facebook.buck.rules.CachingBuildEngine.access$4(CachingBuildEngine.java:705)\n    at com.facebook.buck.rules.CachingBuildEngine$1.apply(CachingBuildEngine.java:272)\n    at com.facebook.buck.rules.CachingBuildEngine$1.apply(CachingBuildEngine.java:1)\n    at com.google.common.util.concurrent.Futures$ChainingListenableFuture.run(Futures.java:906)\n    at com.google.common.util.concurrent.Futures$1$1.run(Futures.java:635)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nBUILD FAILED: //lib:design-library#aar_android_resource failed with exit code 1:\ngenerate_resource_ids\n```\n. The code deciding how to react in the various scenarios is more closely tied to the filtering code than I thought.  I don't think it's worth to factor out all code for deciding what to do, as that will just add unnecessary complexity.\nI decided to just take out the code for deciding whether there are more than two devices, when multi install mode is not enabled.\nThe pull request is updated with the changes.\n. @natthu thanks for the review!  I updated the pull request.\n. @sdwilsh Ah ok thanks, I suspected it was something about my system.\n. Ah ok, thanks for the explanation.\n. Hrm not sure I follow, I'd have to update once @ttsugriy's change lands, or do you mean your comment about deleting the build-successful file before starting the build from above?\n. Thanks for the explanation!\nIn the meantime I updated the pull request, according to the comments.\n. Thanks, totally forgot that.\n. This happens because GitHub doesn't include the contents of submodules in the zip file you can download.  The easiest way to solve this would be to just use git to download the repository (git clone --recursive git@github.com:facebookarchive/AntennaPod.git) as described in the Exopackage documentation\n. I think you should exclude AppShell.java in the main lib, using something like srcs = glob(['src/**/*.java'], excludes = [APP_CLASS_SOURCE]),.\nOtherwise it is defined in two libraries when doing the dex merge in android_binary, so buck won't know which one to use.\n. Hi,\nI think the issue is a missing comma after name = 'native_library'.\nSo what you should have is:\nprebuilt_native_library (\n  name = 'native_library',\n  native_libs= 'lib_android/3rdpartyso/src/com/libs',\n)\n. Thank you very much for fixing this up and getting it in :)\n. @tdrhq Thanks for the suggestion, that makes sense.  I modeled it after tryToExtractPackageName that is already in the AdbHelper.\n. Good point, I didn't think about it first, but it still works, I just tested it.\n. No I don't think so.  If this is a failure, we get a test failure, we can have the test in the ASSUME state otherwise, which I think is more appropriate when no devices are attached.  I think that's in line with the other tests which return the assume state when some prerequisite is missing. Or would you prefer to fail outright when no devices are attached?\n. That's a good idea, thanks!  I'll try to do that for the next version.\n. Yeah, this should work with exopackages since 806e7ccaa09c1ea5928bccdcdf993f299caef8e1.  I'm not sure how exopackages interact with instrumentation tests however.  I'll test it and modify it/add a test as appropriate.\n. Heh yes, I think just removing the second constructor would work.  Not sure what I was thinking there.  I think I still prefer InstallableApk over AndroidBinary, as that will cover an apk_genrule() as well.\n. I'm not 100% sure why, but when I tried to run the tests with just the exopackage as apk and no instrumentation_apk, no tests were run.  (Done by commenting out the instrumentation_apk line in apps/myapp_test/BUCK and adding '//test/com/example/activity:activity_test', in the exopackage android_binary rule in apps/myapp/BUCK.  Maybe I'm missing something here (I have very little experience with exopackages), but otherwise I'd prefer to just not allow it instead of having some users confused.\n. Yeah, I agree, will change for the next version, thanks!\n. No wait, scratch that, I messed up my testing before, sorry.  I'll remove this block.\n. That definitely sounds like a nice to have.  But I do agree that's kind of unrelated to this pull request.  I'll try to do it if I find some time.\n. hmm I'm not sure I follow.  You mean just removing the apk target here and finding the main apk from the android_instrumentation_apk() target if necessary?\nIf that's what you mean it shouldn't be too hard, we could just store the apkUnderTest in the AndroidInstrumentationApk class, and then get it if we have an android_instrumentation_apk() as instrumentation_apk.\nOr did you mean something else?\n. Great! No, only a small change in the internal implementation is needed.\n. Sounds good.  I updated the pull request.  Thanks a lot for your help!\n. Thanks for the advice.  I'll have a look at AndroidLibraryGraphEnhancer.getBuildableForAndroidResources and see if I can cook something up over the next few days!\n. Thanks, I'll have a look!\n. Oops, sorry.  I really need to find a way to remember to run ant lint :(\n. That would be neat! In the meantime I set up a pre-push hook for myself, so this shouldn't happen anymore in the future.\n. We don't need to remove it to match current behaviour.  After running buck in any project, the build-successful file is there, and when buck is rebuilt with ant, it stays there even if the build fails.  It is only removed when buck is updated to a new revision from git.\nHowever I think it would make sense to remove it unconditionally before trying to build buck with ant anyway, so when the build fails a more sensible error message is shown when running buck.\n. ",
    "powderluv": "Im hitting the same problem with r10e. \nUpdated (1/15/16): Still seen on top of master 3c42b08e8440cc6899891ec4d650126988138973\n. ",
    "vovkab": "Can you please move your answer there, so we can continue conversation in #309?\n. ",
    "llj098": "@sschuberth @sdwilsh \nSo, It seems that only pass the --multi-dex paramter to dx will be OK. But how can I set this parameter in a buck build rule?\n. Oh right , I mised the mainDexClasses.\nIs it able to pass these parameter to dx in buck build rule?\nThanks.\n2015\u5e748\u670821\u65e5 \u4e0a\u534812:51\u4e8e \"Sebastian Schuberth\" notifications@github.com\u5199\u9053\uff1a\n\n@llj098 https://github.com/llj098 Like I said, this is not sufficient.\nYou also need to determine the list of classes that need to go to the main\ndex file. Otherwise it's just a matter of luck if all classes that you app\nneeds at startup end up in the main dex file.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/309#issuecomment-133073517.\n. Just a stupid typo, fixed\n. Just a stupid typo, fixed\n. @sdwilsh Got it.\n\nBut the --experimental-ij-generation flag still does not work. You still can't rebuild the project. BTW, seems the src-roots in project_config does not work with this flag?\n. @sdwilsh Got it.\nBut the --experimental-ij-generation flag still does not work. You still can't rebuild the project. BTW, seems the src-roots in project_config does not work with this flag?\n. Thanks @sdwilsh , I have tried the BUCK_EXTRA_JAVA_ARGS I will try  .buckjavaargs.\n. I found the problem, I failed in the smart_dex step, it runs the android sdk's dx, the default Mmx of it is 1024M. \n. buck version *390487558bc1d333c7146bb4e03a7661119012f3\n. Hi @sdwilsh Thanks for your support!\nIt works with your change, but after I rename the layout main.xml to m.xml, I run buck build a:app, it shows:\nUsing buckd.\nAdding watchman root: .\n[-] PROCESSING BUCK FILES...FINISHED 0.1s\n[+] BUILDING...0.0s (0/13 JOBS, 0 UPDATED)\n |=> //a:debug_keystore...  0.0s (checking local cache)\n |=> //b:res...  0.0s (checking local cache)\n |=> IDLE\nb/res/layout/m.xml:15: error: No resource identifier found for attribute 'start' in package 'com.example.b'\nSo, it seems that only main.xml works,, is it a bug or I missed something?\nThanks.\n\nPS: I have update my example project, you can pull it, try to reproduce this error.\n. Yes it works. Thank you very much for your excellent work!\n. ",
    "zserge": "But won't making SHA parameter optional solve it?\nIf one needs reproducible builds - provide the SHA and ensure the dependencies are identical.\nIf one needs just convenient fast builds - provide no SHA and hope the maven server was not hacked.\n. I agree that it is useful to have hashes. But most developers are too relaxed to worry about it - in Go they simply fetch sources from git's tip, in js they get whatever is in the npm etc etc.\nHow user is supposed to get the initial hash value? My current way is super-dumb, I just open the URL at maven central and copy *.jar.sha1 contents from there.\nMaybe the quickstart (or any other project skeleton builder) would take the list of dependencies and if no SHA1 is provided - fetch it from maven and generate remote_file() rules with the fetched SHA1?\n. Great! I'm now still struggling with Buck+Kotlin, but once I see how that can be done (or can't be done) - I will have a look at buck sources to see if I can fix quickstart.\nBtw, is there any reason why Buck doesn't contain a standard macro for Maven? Writing (and reading) manually remote_file + java_library can quickly become messy.\n. I see. As I understand in this case Buck file will have to download and build nailgun server/client? There is no way to reuse the nailgun from the Buck, right (at least know where it's nailgun server JAR and ng app are located)?\n. I see. The C side worries me, since that would require a C compiler to be present. Static builds are also not possible. Maybe I will build it dynamically once and download the binaries from inside Buck.\n. Moreover, the structure in $ANDROID_HOME/build-tools/23.0.0_rc1 has been changed, too.\nFor example they have moved aapt into bin subdirectory.\n. ",
    "dcolascione": "@zserge, I never understood how people could be comfortable with hashless Maven-style dependencies. They scare me. Without a hash, the actual contents of your program can change at any time, without notice, depending on the actions taken by some external server administrator. With a hash, your program changes only when you change it. \n. ",
    "Naveg": "@Coneko is creation of remote_file targets existing or planned functionality? I'm trying to use the maven importer with some success, but I'm not all the way there. When I do:\njava -jar resolver.jar . lib lib https://repo1.maven.org/maven2cat deps.txt | xargs``\nthe jars get pulled in, and the BUCK files under /lib contain the prebuilt_jar rules, but I don't see any remote_file rules. Furthermore, the prebuilt_jar rules aren't visible to the other buck targets.\nLooking forward to that documentation!\n. ",
    "kar": "I've just tried the quickstart and I experienced the same issue, but the version string is latest instead. Seems like it's a symlink in my SDK:\n\u279c  buck-quickstart  ls -la $ANDROID_HOME/build-tools/\ntotal 8\ndrwxr-xr-x   5 kargs  staff  170 May 13 17:25 .\ndrwxr-xr-x  12 kargs  staff  408 Jun 24 09:00 ..\ndrwxr-xr-x  20 kargs  staff  680 Feb  9 16:09 20.0.0\ndrwxr-xr-x  26 kargs  staff  884 Feb  3 14:24 21.1.2\nlrwxr-xr-x   1 kargs  staff    6 May 13 17:25 latest -> 21.1.2\n. I've just tried the quickstart and I experienced the same issue, but the version string is latest instead. Seems like it's a symlink in my SDK:\n\u279c  buck-quickstart  ls -la $ANDROID_HOME/build-tools/\ntotal 8\ndrwxr-xr-x   5 kargs  staff  170 May 13 17:25 .\ndrwxr-xr-x  12 kargs  staff  408 Jun 24 09:00 ..\ndrwxr-xr-x  20 kargs  staff  680 Feb  9 16:09 20.0.0\ndrwxr-xr-x  26 kargs  staff  884 Feb  3 14:24 21.1.2\nlrwxr-xr-x   1 kargs  staff    6 May 13 17:25 latest -> 21.1.2\n. @sdwilsh I just followed the quickstart instructions at http://buckbuild.com/setup/quick_start.html, so I assume today's master.\n. @sdwilsh I just followed the quickstart instructions at http://buckbuild.com/setup/quick_start.html, so I assume today's master.\n. Yep. I investigated what happens in buck-out, and R.java is never really included in jars from what I can tell. There's something going on with so called 'dummy r dot java' and then, from what I can tell, the actual R.java is generated only in android_binary. But I might be wrong.\n. Yep. I investigated what happens in buck-out, and R.java is never really included in jars from what I can tell. There's something going on with so called 'dummy r dot java' and then, from what I can tell, the actual R.java is generated only in android_binary. But I might be wrong.\n. Or I might be misusing something as I'm very fresh to Buck. Any pointers / help appreciated :)\n. Or I might be misusing something as I'm very fresh to Buck. Any pointers / help appreciated :)\n. In my scenario, I have to use a different compiler. I'm trying to compile Kotlin code and make sure it can refer to Android resources. So the above advice won't work (at least I couldn't make it work trying any configuration I could come up with). The only way I made it 'working', is to have an android_library which basically mimics / wraps constants from the R.java, and then make my Kotlin prebuilt_jar (which in turn is based on the genrule) be dependent on this library. But this is pretty cumbersome of course, so I wonder if any proper solution is possible.\n. In my scenario, I have to use a different compiler. I'm trying to compile Kotlin code and make sure it can refer to Android resources. So the above advice won't work (at least I couldn't make it work trying any configuration I could come up with). The only way I made it 'working', is to have an android_library which basically mimics / wraps constants from the R.java, and then make my Kotlin prebuilt_jar (which in turn is based on the genrule) be dependent on this library. But this is pretty cumbersome of course, so I wonder if any proper solution is possible.\n. Hmm I think we're getting closer. I hooked up kotlinc as the target compiler, however it doesn't like the arguments provided by buck. Invalid argument: -source. Is there any way to modify them?\n. Hmm I think we're getting closer. I hooked up kotlinc as the target compiler, however it doesn't like the arguments provided by buck. Invalid argument: -source. Is there any way to modify them?\n. Ok I got a bit hooked and made it working. You can see my simple project here (in particular this directory). I've made detailed comments in source, but the ugliest hack I had to do was to rename all .kt files to .java on the fly, so that android_library will fetch them in srcs - otherwise they seem to be ignored and never reach the compiler. Another thing is that my argument list adaptations for kotlinc may not make too much sense, but at least I was able to refer to R.java from Kotlin code and have it run on my device.\n. Ok I got a bit hooked and made it working. You can see my simple project here (in particular this directory). I've made detailed comments in source, but the ugliest hack I had to do was to rename all .kt files to .java on the fly, so that android_library will fetch them in srcs - otherwise they seem to be ignored and never reach the compiler. Another thing is that my argument list adaptations for kotlinc may not make too much sense, but at least I was able to refer to R.java from Kotlin code and have it run on my device.\n. Yeah it does for now, just wanted to report back. I might come up with a PR once I find time and get myself a bit more familiar with the docs / codebase. Thanks for help!\n. Yeah it does for now, just wanted to report back. I might come up with a PR once I find time and get myself a bit more familiar with the docs / codebase. Thanks for help!\n. Sure, it wasn't a bug per se I suppose. :)\n. Sure, it wasn't a bug per se I suppose. :)\n. ",
    "rallat": "This aar has transitive dependencies on another aars \n. here is twitter core: https://twittersdk.artifactoryonline.com/twittersdk/public/com/twitter/sdk/android/twitter-core/\nthe issue is that we are using R from the transitive dependency and buck isn't finding them.\nbtw, Digits is open source so you can check the dependencies: https://github.com/twitter/digits-android\n. Thanks!\n. ",
    "AnthonyUccello": "Ok so I fixed the issue, I had set the wrong path to my SDK. But whether the android SDK is right or wrong you still get the 'sucess' message blurb, you only get the error when you got to build. When I deleted it and set my path the right directory /Applications/android-sdk-macosx instead of ~/android-sdk-macosx it worked. Thanks\n. Gotcha I did get that setup but now I've run into soo many error outputs I don't know where to begin haha.\nIs there a bigger example I could look at somewhere (other than the quickstart)? Preferably one which has a fully project\n. Gotcha I did get that setup but now I've run into soo many error outputs I don't know where to begin haha.\nIs there a bigger example I could look at somewhere (other than the quickstart)? Preferably one which has a fully project\n. Gotcha thanks!\n. Gotcha thanks!\n. WOW!\nThanks for the indepth answer.\nI am going to spend the next 3 days learning this haha!\n. WOW!\nThanks for the indepth answer.\nI am going to spend the next 3 days learning this haha!\n. One area I'm most stuck is this\nbash\n$ ./gradlew :WordPress:dependencies --configuration compile \\\n  | grep -Eo '([^ ]+:[^ ]+)' | cut -d : -f2 | sort | uniq > deps.txt\nCould you flesh out what you are doing here a little more? On a simple level I understand you are trying to get unique ids (not group id's) but I can't quite follow what's going on in the piped commands.\n. One area I'm most stuck is this\nbash\n$ ./gradlew :WordPress:dependencies --configuration compile \\\n  | grep -Eo '([^ ]+:[^ ]+)' | cut -d : -f2 | sort | uniq > deps.txt\nCould you flesh out what you are doing here a little more? On a simple level I understand you are trying to get unique ids (not group id's) but I can't quite follow what's going on in the piped commands.\n. Incredible answer. Thank you immensely. \n. Incredible answer. Thank you immensely. \n. Its also missing the localproperties file to point to the Android SDK.\nEven after removing target from the binary, setting the Android SDK path I get this error output when I run buck install --run antennapod\n```\nbuck install --run antennapod\nNot using buckd because watchman isn't installed.\n[-] PROCESSING BUCK FILES...FINISHED 0.2s\n[-] BUILDING...FINISHED 8.3s (52/54 JOBS, 40 UPDATED, 0.0% CACHE HITS)\n[+] INSTALLING...1.0s\nLog:\nbuilt APK for //:antennapod at buck-out/gen/antennapod.apk\nBUILD FAILED: Failed: install exopackage\njava.util.concurrent.ExecutionException: java.lang.RuntimeException: Failed to install exopackage on ZX1G22HW4P\n    at com.google.common.util.concurrent.AbstractFuture$Sync.getValue(AbstractFuture.java:299)\n    at com.google.common.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:286)\n    at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:116)\n    at com.facebook.buck.cli.AdbHelper.adbCall(AdbHelper.java:294)\n    at com.facebook.buck.cli.ExopackageInstaller.install(ExopackageInstaller.java:154)\n    at com.facebook.buck.cli.InstallCommand.installApk(InstallCommand.java:213)\n    at com.facebook.buck.cli.InstallCommand.runWithoutHelp(InstallCommand.java:164)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:133)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:80)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:654)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:989)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1046)\n    at com.facebook.buck.cli.Main.main(Main.java:1064)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at com.facebook.buck.cli.bootstrapper.ClassLoaderBootstrapper.main(ClassLoaderBootstrapper.java:48)\nCaused by: java.lang.RuntimeException: Failed to install exopackage on ZX1G22HW4P\n    at com.facebook.buck.cli.ExopackageInstaller$1.call(ExopackageInstaller.java:161)\n    at com.facebook.buck.cli.AdbHelper$AdbCallable$1.call(AdbHelper.java:360)\n    at com.facebook.buck.cli.AdbHelper$AdbCallable$1.call(AdbHelper.java:1)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: com.facebook.buck.cli.AdbHelper$CommandFailedException: Command 'pm path com.facebook.buck.android.agent && dumpsys package com.facebook.buck.android.agent' failed with code 1.  Output:\nat com.facebook.buck.cli.AdbHelper.checkReceiverOutput(AdbHelper.java:477)\nat com.facebook.buck.cli.AdbHelper.executeCommandWithErrorChecking(AdbHelper.java:460)\nat com.facebook.buck.cli.ExopackageInstaller$SingleDeviceInstaller.getPackageInfo(ExopackageInstaller.java:389)\nat com.facebook.buck.cli.ExopackageInstaller$SingleDeviceInstaller.installAgentIfNecessary(ExopackageInstaller.java:401)\nat com.facebook.buck.cli.ExopackageInstaller$SingleDeviceInstaller.doInstall(ExopackageInstaller.java:207)\nat com.facebook.buck.cli.ExopackageInstaller$1.call(ExopackageInstaller.java:159)\n... 6 more\n\n```\n. Its also missing the localproperties file to point to the Android SDK.\nEven after removing target from the binary, setting the Android SDK path I get this error output when I run buck install --run antennapod\n```\nbuck install --run antennapod\nNot using buckd because watchman isn't installed.\n[-] PROCESSING BUCK FILES...FINISHED 0.2s\n[-] BUILDING...FINISHED 8.3s (52/54 JOBS, 40 UPDATED, 0.0% CACHE HITS)\n[+] INSTALLING...1.0s\nLog:\nbuilt APK for //:antennapod at buck-out/gen/antennapod.apk\nBUILD FAILED: Failed: install exopackage\njava.util.concurrent.ExecutionException: java.lang.RuntimeException: Failed to install exopackage on ZX1G22HW4P\n    at com.google.common.util.concurrent.AbstractFuture$Sync.getValue(AbstractFuture.java:299)\n    at com.google.common.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:286)\n    at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:116)\n    at com.facebook.buck.cli.AdbHelper.adbCall(AdbHelper.java:294)\n    at com.facebook.buck.cli.ExopackageInstaller.install(ExopackageInstaller.java:154)\n    at com.facebook.buck.cli.InstallCommand.installApk(InstallCommand.java:213)\n    at com.facebook.buck.cli.InstallCommand.runWithoutHelp(InstallCommand.java:164)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:133)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:80)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:654)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:989)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1046)\n    at com.facebook.buck.cli.Main.main(Main.java:1064)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at com.facebook.buck.cli.bootstrapper.ClassLoaderBootstrapper.main(ClassLoaderBootstrapper.java:48)\nCaused by: java.lang.RuntimeException: Failed to install exopackage on ZX1G22HW4P\n    at com.facebook.buck.cli.ExopackageInstaller$1.call(ExopackageInstaller.java:161)\n    at com.facebook.buck.cli.AdbHelper$AdbCallable$1.call(AdbHelper.java:360)\n    at com.facebook.buck.cli.AdbHelper$AdbCallable$1.call(AdbHelper.java:1)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: com.facebook.buck.cli.AdbHelper$CommandFailedException: Command 'pm path com.facebook.buck.android.agent && dumpsys package com.facebook.buck.android.agent' failed with code 1.  Output:\nat com.facebook.buck.cli.AdbHelper.checkReceiverOutput(AdbHelper.java:477)\nat com.facebook.buck.cli.AdbHelper.executeCommandWithErrorChecking(AdbHelper.java:460)\nat com.facebook.buck.cli.ExopackageInstaller$SingleDeviceInstaller.getPackageInfo(ExopackageInstaller.java:389)\nat com.facebook.buck.cli.ExopackageInstaller$SingleDeviceInstaller.installAgentIfNecessary(ExopackageInstaller.java:401)\nat com.facebook.buck.cli.ExopackageInstaller$SingleDeviceInstaller.doInstall(ExopackageInstaller.java:207)\nat com.facebook.buck.cli.ExopackageInstaller$1.call(ExopackageInstaller.java:159)\n... 6 more\n\n```\n. While Samsung has always been a thorn in my side, this one is a Nexus 6.\n. While Samsung has always been a thorn in my side, this one is a Nexus 6.\n. Let me set one up\n. Let me set one up\n. Ok here you go\nhttps://github.com/AnthonyUccello/bucktest\njust run buck build pumpup\n(I removed the png warning with the meta data issue)\n. Ok here you go\nhttps://github.com/AnthonyUccello/bucktest\njust run buck build pumpup\n(I removed the png warning with the meta data issue)\n. Any progress here? :)\n. Any progress here? :)\n. Ah ok cool. Thanks. Its only a fragment of the project so it only had the files for that error only. All the other files are missing haha\n. Ah ok cool. Thanks. Its only a fragment of the project so it only had the files for that error only. All the other files are missing haha\n. I haven't had time to jump back on to Buck yet but I will close this for now, if I run into problems again I will create a new issue or re-open!\n. I did not. I checked out antenna pod with Tower.\nI will now try to do a recursive clone (will need to fix my SSH first). \nWas missing the sub-module. Thanks. Closing.\n. I did not. I checked out antenna pod with Tower.\nI will now try to do a recursive clone (will need to fix my SSH first). \nWas missing the sub-module. Thanks. Closing.\n. http://developer.android.com/intl/es/tools/building/building-cmdline.html \nIn their docs they use 1.7. I have 1.8.\n. Yes that fixed this issue. Its cropping still up but for different files. But as you've said the core is this duplication issue. Will close this for now. Thank you.\n. Yes that fixed this issue. Its cropping still up but for different files. But as you've said the core is this duplication issue. Will close this for now. Thank you.\n. Thats what I figured.\n. Thats what I figured.\n. ``` python\nANDROID_BUILD_CONFIG_PARAMS = {'name' : 'build-config', 'package' : 'co.pumpup.app'}\nBuilds the build config file for the main .apk.\nandroid_build_config(**ANDROID_BUILD_CONFIG_PARAMS)\n```\nThis is included in the main-lib\n``` python\nANDROID_MAIN_LIBRARY_PARAMS = {\n  'name' : 'main-lib',\n  'srcs' : ['src/*/.java'],\n  'deps' : [\n    ':all-jars',\n    ':all-libs',\n    ':native_libs',\n    ':res',\n    ':build-config',\n  ]\n}\n. python\nANDROID_BUILD_CONFIG_PARAMS = {'name' : 'build-config', 'package' : 'co.pumpup.app'}\nBuilds the build config file for the main .apk.\nandroid_build_config(**ANDROID_BUILD_CONFIG_PARAMS)\n```\nThis is included in the main-lib\n``` python\nANDROID_MAIN_LIBRARY_PARAMS = {\n  'name' : 'main-lib',\n  'srcs' : ['src/*/.java'],\n  'deps' : [\n    ':all-jars',\n    ':all-libs',\n    ':native_libs',\n    ':res',\n    ':build-config',\n  ]\n}\n```\n. Its not an error message. \nIts that even after many successful Buck builds and installs my BuildConfig file doesn't have the flag:\n\nAlso the main binary depends on ':build-config',\n. Its not an error message. \nIts that even after many successful Buck builds and installs my BuildConfig file doesn't have the flag:\n\nAlso the main binary depends on ':build-config',\n. > Oh, yeah. I think this is a known issue. The BuildConfig that IntelliJ sees will be different from what's actually used by Buck to compile.\nI suspected this, and I tried hardcoding it and ignoring the error and running buck but it crashes still.\n. I stand corrected. I had the spelling wrong. Hardcoding DOES work.\n. Well the issue is, if its hard-coded, the Android Studio IDE will not compile, its a manual step between being able to compile with Buck and having an ever-present-compile error in Android-Studio. For example, the web team here doesn't need to use Buck, and when they compile (because they are testing a release build) they just use the IDE. Having this error in the IDE adds a manual step.\n. \nWhen I added Buck files it added this to Android Studio. It apparently does run buck install but it doesnt work. Is this the plugin you are referring to (if so can confirm it doesn't work, but perhaps there is something I need to configure somewhere?)\n. @sdwilsh Thanks for the heads up, I'm no longer at PumpUp though. All the best!. ",
    "zivkov": "I also hit this issue a couple of times when building Gerrit with plugins. Sometimes I want to just symlink a plugin from Gerrit's plugin folder instead of having to clone it inside the plugins folder. Unfortunately, this bug prevents me from doing that.\n. ",
    "somehibs": "I suppose the suggested workaround at present is to uninstall watchman when working on symblinked dependencies.\n. Can't confirm, ended up splitting jar apart.\n. ",
    "jaimeagudo": "Docs arent' fixed yet guys https://github.com/facebook/buck/pull/1189 Anyway it would be nice to solve this\n. ",
    "liuyang-li": "@sdwilsh, separate pull-requests have been submitted for each of the logical changes.\n. @sdwilsh, separate pull-requests have been submitted for each of the logical changes.\n. I agree. Let me try and add SKIPPED ResultType.\n. I agree. Let me try and add SKIPPED ResultType.\n. @sdwilsh , a SKIPPED result type already exists, which I was able to use.\nI realized that: We need to pass the timeout value from .buckconfig to testng, so that it will terminate for tests that run indefinitely. Let me separate out my changes for the test time out into another PR, and update this one.\n. @sdwilsh , I just updated the change set to set the default time out value correctly. Let us do the changes for testng in phases.\nI will submit another PR to update the default behavor for skipped tests in TestNGRunner. After that, I will refactor things a bit to move TestNG to its own package (it is under junit now, which is not correct). There are a couple of other fixes that I plan to do after that, e.g., correctly pass the filters to testng to select test classes.\nIn all, let us push this small change first.\n. Great. Thanks for the feedback.\nTaking things directly from the java_library might be problematic, especially when there are multiple java_library s defined in the same module: we actually do this to build thin/fat jars in different ways. We might be able to specify which java_library to use in the project_config. Is the long term goal to remove project_config entirely? Please let us know what's the preferred way of adding the source/resource roots, and we'll try to update the changeset.\n. Great. Thanks for the feedback.\nTaking things directly from the java_library might be problematic, especially when there are multiple java_library s defined in the same module: we actually do this to build thin/fat jars in different ways. We might be able to specify which java_library to use in the project_config. Is the long term goal to remove project_config entirely? Please let us know what's the preferred way of adding the source/resource roots, and we'll try to update the changeset.\n. That sounds good. That could also solve some dependency management issues, e.g., Intellij doesn't know about jars genereated/downloaded via genrule, and users have to run the command line build before being able to build in Intellij. I was considering adding dependencies to project_config, but agree that having Intellij build through buck is cleaner. It would be great if we'd be able to still allow users to build the same repo via Intellij and command line at the same time though.\n. That sounds good. That could also solve some dependency management issues, e.g., Intellij doesn't know about jars genereated/downloaded via genrule, and users have to run the command line build before being able to build in Intellij. I was considering adding dependencies to project_config, but agree that having Intellij build through buck is cleaner. It would be great if we'd be able to still allow users to build the same repo via Intellij and command line at the same time though.\n. I agree with the plan. My comment was a bit confusing.\nIt's great to have Intellij build via Buck. By \"It would be great if we'd be able to still allow users to build the same repo via Intellij and command line at the same time though.\", I meant that when Intellij builds through Buck, hopefully, we don't have some kind of lock such that building on the command line with buck build is not possible until the Intelilj build is finished. Maybe detaching from the nailgun server would be sufficient here.\n. I agree with the plan. My comment was a bit confusing.\nIt's great to have Intellij build via Buck. By \"It would be great if we'd be able to still allow users to build the same repo via Intellij and command line at the same time though.\", I meant that when Intellij builds through Buck, hopefully, we don't have some kind of lock such that building on the command line with buck build is not possible until the Intelilj build is finished. Maybe detaching from the nailgun server would be sufficient here.\n. @jiangty-addepar \n. @marcinkosiba , would you please take a look? This should be a quick one.\n. That's great. Thanks, @sdwilsh \n. Nice. Thanks for letting me know.\n. @jiangty-addepar \n. Thanks for the feedback, @marcinkosiba.\nI have removed the event posts.\n. Thanks for the feedback, @marcinkosiba.\nI have removed the event posts.\n. @marcinkosiba , shall we push this while we work on the long term goal to remove project_config, as this is pretty much just a bug fix?\n. @marcinkosiba , shall we push this while we work on the long term goal to remove project_config, as this is pretty much just a bug fix?\n. @Coneko it looks like we won't be able to reuse the TargetGraph here for the project generation. The target graph here contains only the root targets as we do not traverse the tree recursively when parsing the root level targets. To generate the project, we need the root targets and (potentially) their siblings, together with root targets children.\nPlease let me know how we can avoid the extra traversal, and I'd be happy to give it a try.\n. @Coneko it looks like we won't be able to reuse the TargetGraph here for the project generation. The target graph here contains only the root targets as we do not traverse the tree recursively when parsing the root level targets. To generate the project, we need the root targets and (potentially) their siblings, together with root targets children.\nPlease let me know how we can avoid the extra traversal, and I'd be happy to give it a try.\n. @Coneko , I gave that a try, and was not able to make it work. I feel that we need to do two traversals here: 1st one to get all the targets in the module when : is used, and 2nd one to get all the dependencies of the targets. I rebased my original change set. Please let me know if you have other suggestions.\n. Yes. I think PMD went into infinite recursion trying to deal with the varargs. This fixes it.\n. Yes. I think PMD went into infinite recursion trying to deal with the varargs. This fixes it.\n. It failed for me: in Ant and Buck on the command line, and in Intellij. I am using a MacBook.\nI was able to make it work by tweaking my $JAVA_HOME (I have multiple versions of JDK installed), and add /include/darwin to the parameters to start C/C++ compiler instead of /include/linux. I was not sure how to get it working for all Mac users reliably, so I disabled it.\n. Adding the additional include path works reliably with buck test. Let me submit a PR to do that for now. Thanks for the explanation.\n. @Coneko \n. @Coneko , you beat me to it:-). Closing this one.\n. My bad. Should have been an || instead. It's updated.\n. This was a bad rebase. It is fixed, and all tests pass now.\n. All the paths are filtered, so the result is empty. I removed variable assignment, as it's not used. What we want to make sure in this test is that the path filtering in getPathToSourceFolders works without NPEs, so invoking it is enough here.\n. The PMD error is fixed. Would you please let us know the official build command for building buck? I typically do: buck test, which does not run static analysis I think.\nWould something like ant clean && ant build && ant lint be sufficient?\n. That's good to know. Sorry about the back and forth, and thanks for pushing this through.\n. I think it was flagging a different one, which is fixed now.\nThis one is used below in getPaths to create an emptyList().\n. ",
    "trinh-binh": "How we generate a Intellij project by \"buck project \" command ?. I installed buck and build successfully, but i want to generate a project which allow to edit by an IDE.\n. Thanks you. I have read it but i need buckbone to create buck project and use \"buck project --ide intellij\" to generate it to an Intellij project.\n. ",
    "ovanes": "I have the same issue and came across this post. Can you please, what is the flow to work with IntelliJ in general. So if I edit code I just use application target, which depends on entire project to make the build. Tests which are run, are not reflected in the default test execution tool.\nBut the main question, how do I run a particular target in a debugger when working with the buck project/plug-in?\n. Seems like I figured it out. After buck project one needs to create a sub-directory for IntelliJ output and setup the path to it in the Project Structure (\u2318;)  Project Settings / Project / Project Compiler Output. In addition verify please, that SDK was properly set. Don't know, why the Buck plug-in can't do it.\n. ",
    "jiangty-addepar": "@sdwilsh ok, I signed it!\n. @sdwilsh ok, I signed it!\n. I'm using xterm with bash on Ubuntu 14.04. This was also reproduced with xterm and bash on OS X.\n. I'm using xterm with bash on Ubuntu 14.04. This was also reproduced with xterm and bash on OS X.\n. Hmm, I've been seeing this bug for a much longer time (~a month?) than I've been seeing #363 , though.\n. Hmm, I've been seeing this bug for a much longer time (~a month?) than I've been seeing #363 , though.\n. Still seeing this happen on https://github.com/liuyang-li/buck/commits/88c2b52bfa8672a559a6bac749d5dcd4650041da .\n. Still seeing this happen on https://github.com/liuyang-li/buck/commits/88c2b52bfa8672a559a6bac749d5dcd4650041da .\n. We'd rather not publicly reveal what tests we're running / our logs; what information in particular are you looking for?\n. We'd rather not publicly reveal what tests we're running / our logs; what information in particular are you looking for?\n. Ah, I do see a line with [error]:\n```\n[2015-06-24 16:56:45.780][debug][command:null][tid:852][class com.martiansoftware.nailgun.NGSession] Nail finished.\n[2015-06-24 16:56:45.780][error][command:null][tid:852][class com.martiansoftware.nailgun.NGSession] Caught NGExitException, cleaning up session and writing exit command to client.\ncom.martiansoftware.nailgun.NGExitException: ExitException: status 1\n    at com.martiansoftware.nailgun.NGSecurityManager.checkExit(NGSecurityManager.java:56)\n    at java.lang.Runtime.exit(Runtime.java:107)\n    at java.lang.System.exit(System.java:971)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1059)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1075)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:338)\n[2015-06-24 16:56:45.780][debug][command:null][tid:852][class com.martiansoftware.nailgun.NGSession] Closing client streams and socket.\n``\n. Ah, I do see a line with[error]`:\n```\n[2015-06-24 16:56:45.780][debug][command:null][tid:852][class com.martiansoftware.nailgun.NGSession] Nail finished.\n[2015-06-24 16:56:45.780][error][command:null][tid:852][class com.martiansoftware.nailgun.NGSession] Caught NGExitException, cleaning up session and writing exit command to client.\ncom.martiansoftware.nailgun.NGExitException: ExitException: status 1\n    at com.martiansoftware.nailgun.NGSecurityManager.checkExit(NGSecurityManager.java:56)\n    at java.lang.Runtime.exit(Runtime.java:107)\n    at java.lang.System.exit(System.java:971)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1059)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1075)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:497)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:338)\n[2015-06-24 16:56:45.780][debug][command:null][tid:852][class com.martiansoftware.nailgun.NGSession] Closing client streams and socket.\n``\n. I didbuck run` a few more times and did not see the above error message again, so I guess that was a red herring... sorry!\nStill, hopefully your fix will help?\n. I did buck run a few more times and did not see the above error message again, so I guess that was a red herring... sorry!\nStill, hopefully your fix will help?\n. sorry, I was on vacation for a week!\nUnfortunately, it's still happening, even after we updated :(\n. sorry, I was on vacation for a week!\nUnfortunately, it's still happening, even after we updated :(\n. for reference, I'm running https://github.com/liuyang-li/buck/commits/88c2b52bfa8672a559a6bac749d5dcd4650041da . I'm fairly sure none of our commits should cause this problem.\n. for reference, I'm running https://github.com/liuyang-li/buck/commits/88c2b52bfa8672a559a6bac749d5dcd4650041da . I'm fairly sure none of our commits should cause this problem.\n. @tgummerer , in our branch https://github.com/liuyang-li/buck/commit/88c2b52bfa8672a559a6bac749d5dcd4650041da , we've already deleted the System.out.println()s, so I don't think that's the issue :/\n. @tgummerer thanks for looking into it though!\n. @liuyang-li has a fix that he'll open a PR for soon!\n. https://github.com/facebook/buck/pull/401\n. Not fixed for me. Error is now in  JavaTest.java:413:\nPath testResultFile = getProjectFilesystem().getPathForRelativePath(\n              getPathToTestOutputDirectory().resolve(path));\nI'm still on 3d44018978210721a8a8dc5326972bebb1ada78d (+ a few local commits), but it includes the commit from #401 .\nOn master, the offending line is at https://github.com/facebook/buck/blob/master/src/com/facebook/buck/java/JavaTest.java#L431\n. @Coneko was this fixed?\n. wait, PR is into the wrong repo :( thanks github :(\n. we forked buck to add this a while ago; I guess we should try to push this upstream\nhttps://github.com/Addepar/buck/commit/7350b59d49948b734492b062623e7c595774633a\n. Thanks for the information! We're still running our fork (which is very, very far behind master) locally, so I haven't really seen the message about the deprecation removal.\nWe have a pretty decent number of applications in our repository and often add new modules / change dependencies, so it seems like we may need to continue generating .iml files.\nRelatedly, it seems like the Buck repository itself uses one root-level .iml file, allowing IntelliJ to essentially not think about dependencies at all and just treat everything as one big IntelliJ module; that's probably not recommended if we are running multiple applications from the same repository, right?\nRe: your answers to 5 and 6: currently we often have BUCK files that contain multiple java_library / java_test / java_binary targets, but you're saying it's preferable to put one target per directory? I guess we have some refactoring to do :)\nWe'll be trying out switching to the latest version of Buck and using the new project generation, so I'll ask again if any new questions pop up!. We're past ~~500~~ 200 iml files, so I guess that's why our performance is slowing down :(\nThe targets all have the same language level and type, so hopefully they'll work for now while we change to a longer-term solution with smaller BUCK files.. Related to this PR: I've been confused about this for a while, since the Buck fork we're using is well behind master: with Buck IntelliJ integration, are developers intended to build/test/run code through IntelliJ, or should they be only using the Buck plugin?\nThe reason I'm asking this is that my original impression of \"new project generation\" was for Buck and IntelliJ to build in the same way (i.e. only through Buck) instead of having IntelliJ and Buck both build things, possibly in slightly different ways. Pardon me if I'm misunderstanding something.. Related to this PR: I've been confused about this for a while, since the Buck fork we're using is well behind master: with Buck IntelliJ integration, are developers intended to build/test/run code through IntelliJ, or should they be only using the Buck plugin?\nThe reason I'm asking this is that my original impression of \"new project generation\" was for Buck and IntelliJ to build in the same way (i.e. only through Buck) instead of having IntelliJ and Buck both build things, possibly in slightly different ways. Pardon me if I'm misunderstanding something.. @styurin what are the performance issues here compared to the buck build command in the plugin?. @ttsugriy I upgraded to 1.8.0_144 and get the same error.. also, maybe my IntelliJ settings are wrong, but the buck IntelliJ project isn't building in IntelliJ either. (I'm just using buck.iml and didn't run buck project.). Hmm... after multiple (3+?) cycles of ant clean -> ant, ant found one additional java file to build, and now compilation works.\nVery strange.\nIntelliJ is still confused, though.. +1 - we've seen this problem as well, though it was on a pretty old version of buck, so we didn't report it.. @yiding slightly tangential question: do you also use watchman / incremental builds on CI servers? (We haven't been successful in doing so, though it's probably because we do some sketchy things in our build scripts such that buck's caching mechanism doesn't quite work correctly...). @ttsugriy ah yeah, that's what I meant. Thanks!. @styurin https://github.com/Addepar/buck/commit/0fcb0d1d86131aa7630c32f7acf41b05bbf5e2ae (fixed in later comment)\nUnfortunately when I run the integration test it says TESTS PASSED (with some assumption violations), and I can't run the integration test in IntelliJ because it complain about the Android SDK (which I don't have.) What should I do to get sane test results?\nHowever, I know the test doesn't pass, because I ran buck project with this BUCK file and it gave me something like\nxml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<module type=\"JAVA_MODULE\" version=\"4\">\n  <component name=\"NewModuleRootManager\" inherit-compiler-output=\"true\">\n    <exclude-output />\n    <content url=\"file://$MODULE_DIR$\">\n      <sourceFolder url=\"file://$MODULE_DIR$\" isTestSource=\"false\" packagePrefix=\"com.facebook.buck.ide.intellij.testdata.project_with_mixed_library_and_test.modules\" />\n      <sourceFolder url=\"file://$MODULE_DIR$/test\" isTestSource=\"false\" />\n      <sourceFolder url=\"file://$MODULE_DIR$/test/test2\" isTestSource=\"true\" packagePrefix=\"test2\" />\n    </content>\n    <orderEntry type=\"inheritedJdk\" />\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\n    <orderEntry type=\"module\" module-name=\"src_com_facebook_buck_cli_bootstrapper\" scope=\"COMPILE\" />\n  </component>\n</module>\nwhereas I would like something like\nxml\n<sourceFolder url=\"file://$MODULE_DIR$/test\" isTestSource=\"true\" />\nI'm not worried about the packagePrefix because I ran buck project from the buck project root (unlike the integration test), but this is more about the XML structure: /test/ is treated as a non-test source, whereas test2 is a test source.\nMaybe this is on purpose, since :test_util is a java_library? But it's included in the tests = [...] list... I tried removing :test_utils from tests = [ ... ] and got the same result. So maybe this is more of a feature request than a bug report.\nThis is particularly worrying because even the buck project itself uses this pattern of mixing in test_utils with tests, but buck project would not create clean test_source_roots for that.. I think I figured some stuff out -- I got the Android SDK (which is required for all of these tests for some reason? Might be able to refactor it so that android project integration tests are in one place, but that's minor) and I realized I didn't specify .idea/modules.xml.expected.\nHowever, I still get the error Project IDE is not specified when trying to run the test (edit: oh, need a .buckconfig). Also, when I edit test fixtures and re-run ./bin/buck test test/com/facebook/buck/ide/intellij:intellij, buck very often, but not always, decides it needs to rebuild the whole project (or at least, all the deps of that test target?), and I don't understand why.\nhttps://github.com/Addepar/buck/commit/d26e660613f7591df9bf24cbf9670b1d15c2545a the test successfully fails now :). Ok, I think I know what's going on now. When Buck sees a common ancestor of some sources / test sources dir, it tries to combine them into one sources dir. I don't really agree with this behavior.\nI think I still prefer the old behavior from project_config where we could specify some src_roots and some test_roots :(\nAlternatively, things in tests = [ ... ] should \"take precedence\": in the first pass, we do the computation for marking source root types for everything without the tests = [ ... ], and in the second pass, we do the computation for the members of tests = [ ... ], marking them all as test_sources / test_resources and overwriting what the first pass did.\nI could be convinced that this is fine if it actually doesn't matter how IntelliJ marks sources vs test sources, which might be true? Honestly, I don't know what the actual effects of these labels are, and just want things to be marked as the right kind of source in some sane way. (One annoyance is that when we \"Find Usages\" in IntelliJ, tests in the same directory as test_utils are now marked \"Production,\" since they're under a source root but not a test source root.). Bump: still haven't really found a way to replicate our old behavior of marking everything in src/test/java as a test source root, since src/test/java contains both java_library and java_test targets. It'd be nice to be able to do this again.. Never mind, this is actually breaking our upgrade. We have a directory structure like\ntest\n|_ java\n   |_ foo\n      |_ bar\n      |  |_ FooBarTest.java\n      |_ FooTest.java\n      |_ FooTestUtils.java\nwhere FooTest.java imports a public static inner class from FooBarTest.java.\nPreviously, when test/java was marked as a Test Source Root, this would compile.\nBut now test/java/foo/bar is marked as a Test Source Root, while /test/java is only marked as a normal Source Root; IntelliJ then fails to compile the \"source\" file FooTest.java because it can't see the inner class of the \"test\" file FooBarTest.java.\nOne could argue that this isn't a good way to structure code, and that's probably true, but it's going to be a lot of work to clean up cases like this when things previously would \"just work.\". ```python\nTEST_SRCS = glob(['test/java/foo//*Test.java])\nTEST_UTILS_SRCS = glob(['test/java/foo//*.java], excludes = TEST_SRCS)\njava_library(\n  name = 'test_utils',\n  srcs = TEST_UTILS_SRCS\n)\njava_test(\n  name = 'test',\n  srcs = TESTS_SRCS,\n  deps = ':test_utils',\n)\nSRCS = glob(['src/java/foo/*/.java'])\njava_library(\n  name = 'foo',\n  srcs = SRCS,\n  tests = [':test'] # or [':test', ':test_utils']; doesn't seem to change anything? but it might\n)\n.python\nTEST_SRCS = glob(['test/java/foo//*Test.java])\nTEST_UTILS_SRCS = glob(['test/java/foo//*.java], excludes = TEST_SRCS)\njava_library(\n  name = 'test_utils',\n  srcs = TEST_UTILS_SRCS\n)\njava_test(\n  name = 'test',\n  srcs = TESTS_SRCS,\n  deps = ':test_utils',\n)\nSRCS = glob(['src/java/foo/*/.java'])\njava_library(\n  name = 'foo',\n  srcs = SRCS,\n  tests = [':test'] # or [':test', ':test_utils']; doesn't seem to change anything? but it might\n)\n```. I think for us, if we have a test and srcs in the same directory, we would actually prefer to merge them together under a test root (i.e. the opposite behavior of what it currently is.) [EDIT: the previous sentence turned out to be quite inaccurate after thinking about it some more :) I tried to implement it and realized it didn't make sense.]\nThe way our code is structured, src files never depend on anything underneath a test/ directory; that is, everything under test/ is a test source/resource, even if it's part of a java_library. Same with test resources.\nThe reason we still want to build with IntelliJ is that our core developer workflows involve building / refactoring / analyzing / running / debugging our applications with IntelliJ. The Buck plugin doesn't seem to support running and possibly debugging through IntelliJ very well right now, if I'm not mistaken?\nI understand the problem of IntelliJ modules being less flexible / general than Buck targets, which is unfortunate, but at least for now, we'd probably like to continue building directly using IntelliJ rather than through the Buck plugin.. I think for us, if we have a test and srcs in the same directory, we would actually prefer to merge them together under a test root (i.e. the opposite behavior of what it currently is.) [EDIT: the previous sentence turned out to be quite inaccurate after thinking about it some more :) I tried to implement it and realized it didn't make sense.]\nThe way our code is structured, src files never depend on anything underneath a test/ directory; that is, everything under test/ is a test source/resource, even if it's part of a java_library. Same with test resources.\nThe reason we still want to build with IntelliJ is that our core developer workflows involve building / refactoring / analyzing / running / debugging our applications with IntelliJ. The Buck plugin doesn't seem to support running and possibly debugging through IntelliJ very well right now, if I'm not mistaken?\nI understand the problem of IntelliJ modules being less flexible / general than Buck targets, which is unfortunate, but at least for now, we'd probably like to continue building directly using IntelliJ rather than through the Buck plugin.. Update: it turns out this doesn't really break buck project [target], since the prebuilt_jar is still populated into IntelliJ.\nIt's still annoying to have all the \"proxy\" java_librarys interpreted as actual IntelliJ modules, though, so for now I'll just delete the .iml files in our wrapper script and exclude the lib/ directory.. Bump - would still be nice (but not super high priority) to be able to exclude some java_librarys from generating .imls, perhaps by label? I might be able to try this if I have time, but I'd be happy if someone else did it ;). Updating to the latest version of watchman fixed the problem.. oh, maybe it's because I'm doing from os import path! Let me try import os.path instead. Nope, still fails.\nSorry if I didn't make this clear: I want to import the \"unsafe\" version of os.path without using with allow_unsafe_imports() in a lot of different places.. Well, I got around the problem by just going back to using with allow_unsafe_import(), but it turned out pretty ugly :(. Hmm...\n- We're using a somewhat custom version of remote_file (taken from some old Gerrit code from back when they used Buck) that does local caching outside of Buck. We could try switching to remote_file instead, though it'd be nice to replicate their local caching functionality; I don't know whether the implementation of remote_file has something similar.\n- We've also been playing around with dynamically getting dependencies from internal artifacts we upload to Maven; this is probably an antipattern in Buck :(\n- We have a macro that's used in hundreds of targets to reduce code duplication. In the macro, we use os.path.exists() to check if a test resources directory exists, to let us know whether to include resources+resources_root in our java_test; maybe this wouldn't be needed if we could (a) glob an empty set of resources and (b) set a possibly nonexistent resources root without Buck complaining? Alternatively, we could just pass in whether the test resources exist in the macro definition.\n- In another macro, we search the filesystem to check if a file exists; this can probably be done via genrule?. Oh, that's even simpler than what I was thinking! Nice :). Thanks!. wait... there's command_alias()\nlet me try that!. oh, that doesn't quite work, since this is a genrule and not a sh_binary :(. ok, I guess one idea for this is:\n```python\nfoo/BUCK\nfor i in ['macos', 'linux']:\n  genrule(\n    name = 'bar-' + i,\n    cmd = \"do_stuff {} $OUT\".format(i),\n    out = 'bar-'+i,\n  )\n  sh_binary(\n    name = 'bar-generate'+i,\n    src = \":bar-\"+i,\n  )\ncommand_alias(\n  name = 'bar-multiplatform',\n  platform_exe = {\n    'macos': ':bar-generate-macos',\n    'linux': ':bar-generate-linux',\n  },\n)\n```\nI hope I used sh_binary correctly? It'd be nice to not need this intermediate sh_binary though. Oh, that helps! Thanks :). Also, a tangentially related question: what does this comment mean?\nhttps://github.com/facebook/buck/blame/master/src/com/facebook/buck/io/filesystem/impl/DefaultProjectFilesystemFactory.java#L90. Also, a tangentially related question: what does this comment mean?\nhttps://github.com/facebook/buck/blame/master/src/com/facebook/buck/io/filesystem/impl/DefaultProjectFilesystemFactory.java#L90. Came up with a horrendous 4th solution as well: get the file to be syntactically correct in both bash and python.\n```bash\n!/bin/bash\na=''' '\nbody of shell script\na=' '''\n```. Came up with a horrendous 4th solution as well: get the file to be syntactically correct in both bash and python.\n```bash\n!/bin/bash\na=''' '\nbody of shell script\na=' '''\n``. Thanks for the recommendations! I'll probably do hack option 4 for now and figure out a transition plan for renaming./buckafter I finish the upgrade.. Thanks for the recommendations! I'll probably do hack option 4 for now and figure out a transition plan for renaming./buckafter I finish the upgrade.. @davidaurelio . @davidaurelio . bump---has anyone taken a look at this?. Exciting! :). Exciting! :). @styurin . @styurin . P.S.mode = 'REFERENCE'inexport_file` isn't documented :(. Another thing that seems to be a bug:\nSay I use mode = 'REFERENCE' in the export_file definition, i.e.\npython\nexport_file(\n  name = 'logback.xml',\n  src = 'logback.template.xml',\n  mode = 'REFERENCE',\n  visibility = ['PUBLIC'],\n)\nNow, say I change the export_file target's name to logback.xml.2 and update the reference in the definition of //foo:bar_lib. Buck does not rename utils/logback.xml to utils/logback.xml.2 inside the bar_lib jar! (In fact, it doesn't rebuild the jar at all.)\nBuck correctly rebuilds the jar if mode = 'COPY'. Also, I have artifact caching disabled.. I have a sort-of-workaround if I create a new jar\npython\njava_library(\n  name = 'logback',\n  resources = ['//utils:logback.xml'],\n  resources_root = './',\n  visibility = ['PUBLIC'],\n)\nand add that jar to the dependencies of //foo:bar_lib. Kind of sad to do that though, since it adds some unnecessary overhead :(\nI guess I could just generate all the logback.xmls and check them in as well, but that's going to be a lot of code duplication.... I ran both ant and ./bin/buck test successfully locally...\n@styurin \nThe build failures on TravisCI\nFAILURE: Build failed with an exception.\n* What went wrong:\nTask 'assemble' not found in root project 'buck'.\nW: Failed to fetch http://ppa.launchpad.net/chris-lea/redis-server/ubuntu/dists/precise/main/binary-amd64/Packages  Unable to connect to ppa.launchpad.net:http:\nand on AppVeyor\nmark-successful-build:\n    [touch] Creating C:\\projects\\buck\\build\\successful-build\ndefault:\nBUILD SUCCESSFUL\nTotal time: 1 minute 24 seconds\nbin\\buck build buck\nNot using buckd because watchman isn't installed.\nBUILD FAILED: Unable to locate watchman on PATH, or it's not marked as being executable\nCommand exited with code 1\ndefinitely seem to be problems with the build infrastructure, not my PR :). I ran both ant and ./bin/buck test successfully locally...\n@styurin \nThe build failures on TravisCI\nFAILURE: Build failed with an exception.\n* What went wrong:\nTask 'assemble' not found in root project 'buck'.\nW: Failed to fetch http://ppa.launchpad.net/chris-lea/redis-server/ubuntu/dists/precise/main/binary-amd64/Packages  Unable to connect to ppa.launchpad.net:http:\nand on AppVeyor\nmark-successful-build:\n    [touch] Creating C:\\projects\\buck\\build\\successful-build\ndefault:\nBUILD SUCCESSFUL\nTotal time: 1 minute 24 seconds\nbin\\buck build buck\nNot using buckd because watchman isn't installed.\nBUILD FAILED: Unable to locate watchman on PATH, or it's not marked as being executable\nCommand exited with code 1\ndefinitely seem to be problems with the build infrastructure, not my PR :). How do I trigger a rebuild?. How do I trigger a rebuild?. Thanks @ttsugriy !. Thanks @ttsugriy !. @ttsugriy The year-old commit I linked in my PR description actually deleted the --dry-run command-line option; in fact, on master, when I run \n``bash\n./bin/buck test --dry-run\n````\nit tells me\"--dry-run\" is not a valid option`.\nThis PR should only delete some internal references to --dry-run, so what you're saying is quite surprising!. @ttsugriy wow, I guess I missed that! I'm still confused though: are you saying that \"if we delete the references in BaseRunner, things will break\"?\nAlso, currently, does Buck only support --dry-run for Java tests?. To summarize: facebook internally uses --dry-run, so we shouldn't delete it? Why does buck test --dry-run not work on master for me then?. Sweet :). Sweet :). Build failed: Failed to compile: No space left on device\n    When running <javac_jar>.\n:( @ttsugriy . Also, should I split this into multiple PRs?. Ok, I replaced this with #1662 #1663 #1664 #1665 . Didn't include the \"delete dry_run_testng\" change in case we don't want to delete the dry-run stuff.. SuperConsoleBusListenerTest seems to have failed, but I'm pretty sure I didn't touch it?. Test setup failures cause the test to be skipped; in practice, there don't seem to be other reasons that cause skipped tests (other than throwing a SkipException, I guess). It's possible that in combination with https://github.com/facebook/buck/pull/1665 , we might be able to mark skipped tests as skipped instead (\"assumption violation\", perhaps? It seems there isn't a ResultType.SKIPPED), but ASSUME tests don't seem to fail the build.. Test setup failures cause the test to be skipped; in practice, there don't seem to be other reasons that cause skipped tests (other than throwing a SkipException, I guess). It's possible that in combination with https://github.com/facebook/buck/pull/1665 , we might be able to mark skipped tests as skipped instead (\"assumption violation\", perhaps? It seems there isn't a ResultType.SKIPPED), but ASSUME tests don't seem to fail the build.. I can change this behavior in #1665 if desired, but before that goes in, it's better to be stricter with potentially failing tests.. I can change this behavior in #1665 if desired, but before that goes in, it's better to be stricter with potentially failing tests.. Any other comments on this PR? Did SuperConsoleBusListenerTest get fixed / un-flaked, and if so, how do I re-run the CI?. Any other comments on this PR? Did SuperConsoleBusListenerTest get fixed / un-flaked, and if so, how do I re-run the CI?. Hello?. Ok, I can do something like:\n\nif a test was skipped because setup failed, mark it as ResultType.ASSUMPTION_VIOLATION\nif a test is skipped otherwise, mark it as ResultType.DISABLED\n\nHowever, this change will require combining this PR with #1665 (to properly handle test setup failures), and there are a bunch of intermediate changes between them. I could go back to just combining all these PRs (#1662 , #1663 , #1664 , #1665), or I could merge this PR as a temporary state before going to the \"desired state\" in #1665 .. bump again.\nAnother thing I could do is open this as a PR into #1663, #1663 into #1664, #1664 into #1665 and then merge #1665 as one big PR. (edit: oops, reversed). @styurin isn't that what these PRs are?. I can try rewriting them again to concentrate the refactors in one place, I guess?. @styurin Ok, I removed the change to test timeouts in this PR.. @styurin Ok, I removed the change to test timeouts in this PR.. Going to replace this with some smaller PRs.. Going to replace this with some smaller PRs.. Replaced by #1722 . Might be able to close this for now. I haven't had time to try to fix the TODO.. Wow, thanks! Was this posted anywhere that I should've seen?. Oh, it looks like it's restricted to certain email domains; can an admin add the @addepar.com domain to the whitelist?. Thanks!. Caused by: java.io.IOException: No space left on device errors on TravisCI again. Caused by: java.io.IOException: No space left on device errors on TravisCI again. @ttsugriy sorry, fixed!. heh, trying to commit from a non-work computer caused some problems, but I managed to revert the change!. @ttsugriy oh, I think this is because the previous PR (#1706) was merged; fixing. this and #1707 should have their merge conflicts resolved now. @ttsugriy sorry about that!\nIs there an easy way to tell IntelliJ to run formatting on all changed files or something?. @ttsugriy sorry about that!\nIs there an easy way to tell IntelliJ to run formatting on all changed files or something?. I'm really confused -- I'm running this test locally and it not only compiles, but passes?\n./bin/buck test test/com/facebook/buck/testrunner:testrunner -f TestNGLoggingIntegrationTest\nBuilding: finished in 0.4 sec (100%) 551/551 jobs, 0 updated, 0.0% cache miss\n  Total time: 0.6 sec\nTesting: finished in 11.5 sec (2 PASS/0 FAIL)\nRESULTS FOR SELECTED TESTS\nPASS     10.7s  2 Passed   0 Skipped   0 Failed   com.facebook.buck.testrunner.TestNGLoggingIntegrationTest\nTESTS PASSED\nnot only that, it compiles in IntelliJ. I'm really confused -- I'm running this test locally and it not only compiles, but passes?\n./bin/buck test test/com/facebook/buck/testrunner:testrunner -f TestNGLoggingIntegrationTest\nBuilding: finished in 0.4 sec (100%) 551/551 jobs, 0 updated, 0.0% cache miss\n  Total time: 0.6 sec\nTesting: finished in 11.5 sec (2 PASS/0 FAIL)\nRESULTS FOR SELECTED TESTS\nPASS     10.7s  2 Passed   0 Skipped   0 Failed   com.facebook.buck.testrunner.TestNGLoggingIntegrationTest\nTESTS PASSED\nnot only that, it compiles in IntelliJ. hmm, perhaps it's a semantic merge conflict (TemporaryPaths changed packages?); I'll rebase on master and try again. hmm, perhaps it's a semantic merge conflict (TemporaryPaths changed packages?); I'll rebase on master and try again. # More Investigation + Root Cause\nI tried putting \"123\".encode(\"ascii\") at various points in buck.py to see what failed and what didn't, and I think I figured it out.\nWhen we parse a BUCK file, it's called inside _import_whitelist_manager.allow_unsafe_import(False) (buck.py#L1503). This context manager (spec here for convenience) overrides builtins.__import__ and blocks the import of most modules within the buck project; we'll get to this in a bit.\nThe first time we call str.encode(), we need to initialize the list of codecs: https://github.com/python/cpython/blob/2.7/Lib/encodings/init.py#L99 \nencodings isn't a safe module to import according to the import whitelist. This is usually not a problem, since encodings/__init__.py isn't a buck project file.\nHowever... if we create a virtualenv inside the buck project, the __init__.py we're looking at is now inside the buck project! Buck checks the predicate is_in_dir(path, self._project_root): buck.py#L872. So it blocks the import of encodings.ascii (which, I guess, fails silently?), and we can no longer encode strings as ascii.\nIf we encode any string before entering this context manager, we don't need to attempt to import encodings.ascii while inside the context manager, so things work normally. If we don't, we try to import something that's not whitelisted, and string encodings will fail.. Proposed fix is above, but I haven't written tests yet so I didn't make a PR into this repo yet.. Similar(?) bug is happening where parsing Buck / python files while in a virtualenv emits lots of Access to a non-tracked file detected! warnings, whereas doing so outside of the virtualenv does not emit those warnings (since the python file is definitely referenced by include_defs). Still trying to work this out.. Ah, as expected, it's something similar.\nIn a virtualenv, https://github.com/python/cpython/blob/2.7/Lib/linecache.py#L131 is \"inside the buck project\" as defined by _called_from_project_file() here.. It's a separate change, and I can make a separate 1-line PR instead, if that's preferred. We originally had these together in 1 commit, which is why they're together.. Or, could I combine this timeout removal with some of the \"structural refactors\" from #1663 ?. I thought there is always a time limit per test target specified in .buckconfig?. basically, I'm afraid of introducing \"non-transparent\" timeouts inside Buck; users should always know that their timeout is specified explicitly somewhere, imo. oops, sorry!. I installed the IntelliJ plugin, but I guess it doesn't auto-format :( . we can fail instead, but I don't think \"failure to toString an object\" should be enough to block a developer from seeing their test results. ",
    "maxme": "You can get your dependency list by running the gradle dependencies task and then run the assemble task in debug mode to get the dependency locations. Here is an example with WordPress for Android:\n- First run the assembleDebug task and redirect the output to a file\nshell\n$ ./gradlew --debug :WordPress:assembleDebug > assembleDebug.log\n- Get your dependency list (drop group ids)\nshell\n$ ./gradlew :WordPress:dependencies --configuration compile \\\n  | grep -Eo '([^ ]+:[^ ]+)' | cut -d : -f2 | sort | uniq > deps.txt\ndeps.txt contains a list of artifact ids needed to build your app.\n- Then grep your log file for each of your depengency and filter aar and jar files.\nshell\n$ cat deps.txt| xargs -I % grep % assembleDebug.log | grep -E \"aar$|jar$\" \\\n  | grep -Eo \"(/[^ ]+)\" | sort | uniq > aar-jar-dependencies.txt\n- You now have a list of files in aar-jar-dependencies.txt, you can probably copy all of them to your libs/ directory.\nshell\n$ cat aar-jar-dependencies.txt\n/Users/max/.gradle/caches/modules-2/files-2.1/com.android.tools/annotations/24.2.3/5cfce42220293835e7988ceefd9b0f4e9f284791/annotations-24.2.3.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.automattic/rest/1.0.1/6417f4914155fa53bfa34fd0bca64e115f3efb03/rest-1.0.1.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.crashlytics.sdk.android/answers/1.1.2/ed296a685026c8ad31b5206946f497786cdaeff/answers-1.1.2.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.crashlytics.sdk.android/beta/1.1.2/42291d3475b024588a351a6dcddbe4b02b7b0e89/beta-1.1.2.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.crashlytics.sdk.android/crashlytics/2.2.2/b0b2570cfe1a36d8f4b9680ad62d2aabe51dc2f7/crashlytics-2.2.2.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.getbase/floatingactionbutton/1.9.0/fb558177ace2158ebda8877737d089bdf93a426b/floatingactionbutton-1.9.0.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.github.chrisbanes.photoview/library/1.2.3/208ab4f80277a819e7694c87f84fe3135d5563c8/library-1.2.3.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.google.code.findbugs/annotations/2.0.0/d8dff1d83a79f0c0609c360f02bcd2f2fc1f1369/annotations-2.0.0.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.google.code.gson/gson/2.2.2/1f96456ca233dec780aa224bff076d8e8bca3908/gson-2.2.2.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.google.code.gson/gson/2.2.4/a60a5e993c98c864010053cb901b7eab25306568/gson-2.2.4.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.helpshift/android-aar/3.8.0/175d441289ca733a0f3594551ecfa913c0ad3a1d/android-aar-3.8.0.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.koushikdutta.async/androidasync/2.1.3/52aed89a155265a48984ecc06aa8dec12674edad/androidasync-2.1.3.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.mcxiaoke.volley/library/1.0.10/8d62b91f5ccb6f7f872313191c016c03bb61a792/library-1.0.10.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.mcxiaoke.volley/library/1.0.16/d8f5b9114ebe0f76de7fbf55e950540959ce4ff8/library-1.0.16.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/com.simperium.android/simperium/0.6.4/c4c7ff9570a982a92790fcd17a39511cdb1166b4/simperium-0.6.4.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/commons-lang/commons-lang/2.6/ce1edb914c94ebc388f086c6827e8bdeec71ac2/commons-lang-2.6.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/commons-logging/commons-logging/1.1.1/5043bfebc3db072ed80fbd362e7caf00e885d8ae/commons-logging-1.1.1.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/de.greenrobot/eventbus/2.4.0/ddd166d01b3158d1c00576d29f7ed15c030df719/eventbus-2.4.0.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/io.fabric.sdk.android/fabric/1.2.0/3ccb675269c6fc7b002bba0a97318d0109c4e3ae/fabric-1.2.0.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/io.fabric.tools/gradle/1.19.1/f2fe59de5bafc0e0eed90d672d8bf1140b79b376/gradle-1.19.1.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.0.3/fcacc35075d9c3114da4c4122b42d78786135c90/httpclient-4.0.3.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.apache.httpcomponents/httpclient/4.1.1/3d1d918f32709e33ba7ddb2c4e8d1c543ebe713e/httpclient-4.1.1.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.ccil.cowan.tagsoup/tagsoup/1.2.1/5584627487e984c03456266d3f8802eb85a9ce97/tagsoup-1.2.1.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.1/860340562250678d1a344907ac75754e259cdb14/hamcrest-core-1.1.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/2.0.14-beta/d2327fbe166e3f7f9486f328a707326e2ed1da03/mockito-core-2.0.14-beta.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.robolectric/robolectric-annotations/2.4/936c649cb0958d7fb5d3c09b31c56b3997f80650/robolectric-annotations-2.4.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.thoughtcrime.ssl.pinning/AndroidPinning/1.0.0/1a3bcfa0b90580c3119f0eb2a620560b6e99495/AndroidPinning-1.0.0.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.wordpress/drag-sort-listview/0.6.1/238699f638a40b9850d7dfabe65ffdf93cd9bfa2/drag-sort-listview-0.6.1.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.wordpress/emailchecker/0.3/d5f9d7dbb36560357b4894495366bd80303d031d/emailchecker-0.3.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.wordpress/gcm/1.0.0/a6d7bce795a14c7f86111756c4ceb44b79de14aa/gcm-1.0.0.jar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.wordpress/graphview/3.3.0/79679f36b26fa568acc4b4d2bf5aa01a225eb3ea/graphview-3.3.0.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.wordpress/mediapicker/1.2.3/1f900af0a32c9830cd275d368104956c8a74b269/mediapicker-1.2.3.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.wordpress/passcodelock/1.0.0/b203d519db2f6ec0507fd1cb46e3f001da4db10e/passcodelock-1.0.0.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.wordpress/persistentedittext/1.0.1/ed8c682b51d2bdf70bf4dc879b92bc676422a1e8/persistentedittext-1.0.1.aar\n/Users/max/.gradle/caches/modules-2/files-2.1/org.wordpress/slidinguppanel/1.0.0/225937b13cd93277379dbd5168206706a0f049a7/slidinguppanel-1.0.0.aar\n/Users/max/work/android-sdk-mac/build-tools/22.0.1/dx\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/appcompat-v7/22.2.0/appcompat-v7-22.2.0.aar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/cardview-v7/22.2.0/cardview-v7-22.2.0.aar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/design/22.2.0/design-22.2.0.aar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/recyclerview-v7/22.2.0/recyclerview-v7-22.2.0.aar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/support-annotations/21.0.3/support-annotations-21.0.3.jar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/support-annotations/22.2.0/support-annotations-22.2.0.jar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/support-v13/21.0.3/support-v13-21.0.3.aar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/support-v13/22.2.0/support-v13-22.2.0.aar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/support-v4/21.0.3/support-v4-21.0.3.aar\n/Users/max/work/android-sdk-mac/extras/android/m2repository/com/android/support/support-v4/22.2.0/support-v4-22.2.0.aar\n. List your dependencies for the compile configuration (make sure to change :WordPress by your project name).\nshell\n./gradlew :WordPress:dependencies --configuration compile > /tmp/step1\nHere is what you get for the previous command:\n$ cat /tmp/step1\ncompile - Classpath for compiling the main sources.\n+--- com.google.code.findbugs:annotations:2.0.0\n+--- com.crashlytics.sdk.android:crashlytics:2.2.2\n|    +--- com.crashlytics.sdk.android:answers:1.1.2\n|    |    \\--- io.fabric.sdk.android:fabric:1.2.0\n|    +--- io.fabric.sdk.android:fabric:1.2.0\n|    \\--- com.crashlytics.sdk.android:beta:1.1.2\n|         \\--- io.fabric.sdk.android:fabric:1.2.0\n+--- org.wordpress:mediapicker:1.2.3\n[... truncated ...]\nRemove tree formating by matching xxx:xxx\nshell\n$ grep -Eo '([^ ]+:[^ ]+)' /tmp/step1 > /tmp/step2\nHere is what you get for the previous command:\nshell\n$ cat /tmp/step2\ncom.google.code.findbugs:annotations:2.0.0\ncom.crashlytics.sdk.android:crashlytics:2.2.2\ncom.crashlytics.sdk.android:answers:1.1.2\nio.fabric.sdk.android:fabric:1.2.0\nio.fabric.sdk.android:fabric:1.2.0\ncom.crashlytics.sdk.android:beta:1.1.2\nio.fabric.sdk.android:fabric:1.2.0\norg.wordpress:mediapicker:1.2.3\n[... truncated ...]\nOnly keep artifact ids (annotations, crashlytics, answers, ...)\nshell\ncut -d : -f2 /tmp/step2 > /tmp/step3\nOptional, remove dups\nshell\nsort /tmp/step3 | uniq > deps.txt\nNote: this will help you, you still have to filter jars and aars you need (for instance don't keep N versions of the same library) - step 3 (droping group ids) is kind of bad - It's easy to write a better script for a better result than this one liners.\n. ",
    "Stoff81": "Hey @k21 Im just running through this tutorial: https://buckbuild.com/setup/manual_quick_start.html and am getting the same error. You may want to update this doc as well.\n. In fact, the walkthrough works by just removing the target field from the android_binary() call\n. ",
    "somechris": "\nI can't apply this cleanly, [...]\nCan you rebase and retest you changes?\n\nI rebased the PR.\nTesting using the buck test suite is a bit tricky, as Travis is failing on current master (before my PR).\n'ant test' is also already failing on current master (before my PR).\n(FWIW ... 'ant test' is still failing the same tests in exactly the same way after my PR.)\nBut buck builds just fine with my patch sets.\nAnd running it on test projects works out just fine.\nAlso the generated jacoco.exec is fine and usable.\nAlso the generated JaCoCo reports are fine.\n(Both on JDK 7 and JDK 8)\n\nError occurred during initialization of VM agent library failed to init: instrument\n\nThis error message never showed up for me.\nHow can I reproduce it?\n\nCan you also add the source jar of the agent while you are here?\n\nDone.\n(The jacocoagent.jar belongs to the org.jacoco.agent artifactId,\nhence the org.jacoco.agent-0.7.5.201505241946-sources.jar are the\nsources for both org.jacoco.agent-0.7.5.201505241946.jar and\njacocoagent.jar.)\n. > I can't apply this cleanly, [...]\n\nCan you rebase and retest you changes?\n\nI rebased the PR.\nTesting using the buck test suite is a bit tricky, as Travis is failing on current master (before my PR).\n'ant test' is also already failing on current master (before my PR).\n(FWIW ... 'ant test' is still failing the same tests in exactly the same way after my PR.)\nBut buck builds just fine with my patch sets.\nAnd running it on test projects works out just fine.\nAlso the generated jacoco.exec is fine and usable.\nAlso the generated JaCoCo reports are fine.\n(Both on JDK 7 and JDK 8)\n\nError occurred during initialization of VM agent library failed to init: instrument\n\nThis error message never showed up for me.\nHow can I reproduce it?\n\nCan you also add the source jar of the agent while you are here?\n\nDone.\n(The jacocoagent.jar belongs to the org.jacoco.agent artifactId,\nhence the org.jacoco.agent-0.7.5.201505241946-sources.jar are the\nsources for both org.jacoco.agent-0.7.5.201505241946.jar and\njacocoagent.jar.)\n. ",
    "sdfzq123": "ThemeOverlay.AppCompat.Dark.ActionBar  and TextAppearance.AppCompat.Title.Inverse declared in v7-appcompat\nappbar_scrolling_view_behavior declared in android-support-design\n. @sdwilsh BTW, I also tried to use gradle to build this app, gradle works.\n. ",
    "ruijun": "@tgummerer Thanks.How can I management the so files? \n. @tgummerer Thanks.How can I management the so files? \n. ",
    "skyisle": "Now, it's out of beta with android build 1.5.0 release.\n. Now, it's out of beta with android build 1.5.0 release.\n. @jasta You are right. Only some modules is released such as compiler, base libs not extensions. https://android.googlesource.com/platform/frameworks/data-binding/+/9adb2e8a1fdd7352599ccb16e471c97049f97ae9%5E%21/#F0\n. ",
    "jasta": "@skyisle I believe this library remains in beta, according to both https://bintray.com/android/android-tools/com.android.databinding.dataBinder/view and https://android.googlesource.com/platform/frameworks/data-binding/+/studio-master-dev\n. @skyisle I believe this library remains in beta, according to both https://bintray.com/android/android-tools/com.android.databinding.dataBinder/view and https://android.googlesource.com/platform/frameworks/data-binding/+/studio-master-dev\n. Databinding appears to be out of beta and is now using version 1.0 and 1.1 as the two latest releases.\n. ",
    "archmages": "Android data binding now is beta version, I hope Buck will support it when it update to stable version\n. ",
    "nbonavia": "Any feedback on buck supporting Android databinding? It's the only blocker I have to start using buck for my build processes.\n. ",
    "jaggs6": "any updates on this?\n. @Coneko obviously I have read the comment above. It's been three months. Things might have changed.\n. @sdwilsh any updates?\n. @sdwilsh any updates?\n. ",
    "connected-jallen": "@sdwilsh The reason why no one at Facebook is using Data Binding is because Buck does not support Data Binding. The reason you give is a catch 22 :) Data Binding is pretty awesome. It might be better for Android dev in Facebook if Buck kicked off a Gradle job in the end.. @sdwilsh The reason why no one at Facebook is using Data Binding is because Buck does not support Data Binding. The reason you give is a catch 22 :) Data Binding is pretty awesome. It might be better for Android dev in Facebook if Buck kicked off a Gradle job in the end.. ",
    "yangwuan55": "I think we can use the freeline now.. ",
    "zhaoshuyu": "buck supports android databinding now ?  thanks. ",
    "ameyab10": "Oh gosh, total catch 22 here.. Would be awesome if buck could support this since databinding is pretty mainstream now.. Oh gosh, total catch 22 here.. Would be awesome if buck could support this since databinding is pretty mainstream now.. ",
    "sangeetsuresh": "Any luck on data binding support in buck ?. ",
    "youyuo": "I found this code in file 'MiniAapt.java'\nif (!RESOURCE_TYPES.containsKey(resourceType)) {\n          throw new ResourceParseException(\n              \"Invalid resource type '<%s>' in '%s'.\",\n              resourceType,\n              valuesFile);\n        }\n. I found this code in file 'MiniAapt.java'\nif (!RESOURCE_TYPES.containsKey(resourceType)) {\n          throw new ResourceParseException(\n              \"Invalid resource type '<%s>' in '%s'.\",\n              resourceType,\n              valuesFile);\n        }\n. sorry,I just found that the public.xml is copy error,and the content is like that:\n\nBy the way, does buck support utf-8 code?\nBecause the .java file in my project has some chinese\uff0cand when I compile with buck will have below warning:\n....../test.java:62: ??: ??ASCII???????* ??????????????????????????????????test?????????????????????????????????????????????????????????????\nthank you for your answer~~\n. sorry,I just found that the public.xml is copy error,and the content is like that:\n\nBy the way, does buck support utf-8 code?\nBecause the .java file in my project has some chinese\uff0cand when I compile with buck will have below warning:\n....../test.java:62: ??: ??ASCII???????* ??????????????????????????????????test?????????????????????????????????????????????????????????????\nthank you for your answer~~\n. ",
    "jimevans": "@sdwilsh While I agree that PowerShell is in most ways superior to a simple command prompt, at the moment, it's impossible to integrate Buck into a build process that uses Visual Studio for part of the build, as that product requires specific environment variables to be set, and the product provides command-prompt shortcuts preinstalled for developers to use. Adding a batch file option allows seamless integration with existing Visual Studio-centric build processes.\n. @sdwilsh While I agree that PowerShell is in most ways superior to a simple command prompt, at the moment, it's impossible to integrate Buck into a build process that uses Visual Studio for part of the build, as that product requires specific environment variables to be set, and the product provides command-prompt shortcuts preinstalled for developers to use. Adding a batch file option allows seamless integration with existing Visual Studio-centric build processes.\n. ",
    "ieugen": "Hi, \nNo. I am not trying to package buck. I wish to package gerrit which uses buck. One way is to have buck export an ant build.xml (similar to export intrllij idea or xcode project). \nI made some progress by transforming the json format that buck outputs to ant build.xml . Looks promissing but is hard to maintain long term. Upstream support for buck to ant xml would be very nice.\nI'll share some of my code when I'm done.\n. ",
    "bkase": "How did you know! I was using apktool, an aapt dump diff shows my error:\n```\n<       A: targetSdkVersion=0x16\n<       A: minSdkVersion=0x10\n\n\n  A: android:minSdkVersion=0x10\n  A: android:targetSdkVersion=0x16\n\n```\n\nI can't believe it was that simple -- thanks!\nP.S.: Life is good, what's up with you?\n. EDIT:\nThe cache-hit-check-time is back to ~2-5s per module. Before I built with gradle, it was 100-200ms. Post gradle build, I can't seem to get that to com back.\nI'll keep my old comment here, but I assume it is unrelated to the speedup I briefly saw.\n\n~~I don't know why, but my cache-hit-check-time went down to ~100-200ms!~~\nThe only thing I changed was this:\n(in a file that declares a prebuilt jar for the kotlin runtime)\ngenrule(\n        name = 'kotlin-runtime-jar',\n        out = 'kotlin-runtime.jar',\n-       cmd = 'ln -s ~/kotlin2/dist/kotlinc/lib/kotlin-runtime.jar $OUT',\n+       cmd = 'ln -s ' + os.environ[\"KOTLINPATH\"] + '/dist/kotlinc/lib/kotlin-runtime.jar $OUT',\n )\nand\n(in a script that pretends to be javac)\n-    exit(call([\"/Users/highlight/kotlin2/dist/kotlinc/bin/kotlinc\"] + params))\n+    exit(call([os.environ[\"KOTLINPATH\"] + \"/dist/kotlinc/bin/kotlinc\"] + params))\nIt's slow immediately before this commit, fast immediately after.\n~~I'll leave this issue open (I'm happy to tweak my build settings to help you guys figure out why this was happening), but feel free to close it. Builds are fast.~~\n. I am using buckd (at least \"Using buckd.\" is printed every time buck runs).\nI have a genrule that copies all *.kt to *.kt.java to spoof the android_library rule. Could this be causing the hashes to be recomputed?\nIf this is the cause, is there an easy way to make the android_library rule send my \"javac\" *.kt files as well as *.java? I don't mind forking Buck if necessary.\n. I want to build *.kt files but utilize all the machinery that buck provides via android_library (like build R.java properly first etc.).\nThe android_library rule seems to only passes the java files to the compiler for the build steps that require compiling code (which makes sense if all of your code is in java). Running the rule without changing the filenames results in an empty jar.\nIt would be nice if I could get the android_library rule to give kotlin files to the compiler.\nThe genrule is a hack modified from https://github.com/kargs/buckexp\n```\nandroid_library(\n    name = name,\n    visibility = visibility,\n    srcs = [':kotlin-src-' + name],\n    compiler = 'kotlincw',\n    deps = kwargs.get('deps', []),\n    exported_deps = kwargs.get('exported_deps', []),\n  )\ngenrule(\n    name = 'kotlin-src-' + name,\n    srcs = srcs,\n    out = 'kotlin-' + name + '.src.zip',\n    cmd = 'echo \"$SRCS\" | awk -F\" \" \\'{ for(i = 0; ++i <= NF;) print $i }\\' | xargs -I{} cp {} {}.java && echo \"$SRCS\" | awk -F\" \" \\'{ for(i = 0; ++i <= NF;) print $i }\\' | xargs -I{} echo {}.java | zip -@ \"$OUT\"',\n  )\n```\nEssentially, we copy *.kt files to *.kt.java and stick them in kotlin-srcs-<name>.zip then rewrite them back *.kt in the compiler script.\n. Hi -- Android Kotlin user and Buck fan here. I'll try to invest some time getting a (hopefully) non-trivial kotlin Android example to work with the new rules as soon as I can (which unfortunately is likely to be next week since I'm about to go on vacation)\n. Hit a snag when trying to build a Kotlin MainActivity in an Android app since there is no android_library equivalent kotlin Buck rule.\nSee https://github.com/bkase/buckitup\n. @dsyang makes sense, ship it!\n. Very busy through September, but afterwards I may have some spare cycles\n. Very busy through September, but afterwards I may have some spare cycles\n. ",
    "markhughes": "Sorry, I just gave up on trying to setup Buck! I will have a try later and see if the same issue still arises.\n. Just for ref., I gave buck a try again. Instead of compiling from source I just used homebrew to install it - which was a much easier solution for me! \nSo now I'm off to implement it across projects for trials. Heres hoping that goes well! :beers: \n. ",
    "jkeljo": "What revision of checkerframework are you using? How frequent is this NPE?\nI saw an issue once where an annotation processor that loaded resources would, very occasionally, fail to do so when run inside buckd as part of a very large build. I was never quite able to bottom it out, but it went away if I removed the close() call on the classloader. It seemed to be that closing one class loader was somehow invalidating resources used by another. (Since the class loaders were referencing the same files, this seems not entirely crazy.) If switching to a singleton fixes the issue for you, it sounds like it might be related.\n. For me the problem only cropped up in buckd with lots of parallelism. Running env NO_BUCKD=1 buck build or buck build -j1 both seemed to make the issue much harder to repro. I'd be curious to see exactly what is NPEing...what revision of the checker framework source should I be looking at for that stack trace?\n@sdwilsh, the change to annotation processor classloader behavior we were discussing yesterday should probably mitigate this (it's effectively what @mread mentions they've done locally but with allowances for annotation processors that can't handle parallel builds in one process).\n. Sorry, missed that reply. Looking at the source for that revision of checkerframework, it looks like the NPE is that the visitor field of some SourceChecker is null, and exactly how that could happen depends on which particular SourceChecker is actually involved in the stack trace. Regardless, seems like the right thing to do in Buck here is to reuse ClassLoaders whenever it is safe to do so.\n. Yeah, making it less friendly is exactly the idea. Or at least giving you a way to opt out of the friendliness, either globally or per-processor.\n\nOn Jan 21, 2016, at 8:59 AM, grumpyjames notifications@github.com wrote:\nThat rather goes against the spirit of the comment in Jsr199Javac:\n// N.B. You might think that we could avoid some overhead by using the same classloader every\n// time we create an instance of annotation processor.  In an ideal world, that would work well,\n// but many annotation processors aren't thread-safe, and they store state in class-static\n// variables.  In the interest of maximum safety, we'll create a new ClassLoader every time we\n// need an annotation processor.\nThat looks like Buck attempting to make up for the shortcomings of annotation processors; perhaps it could be made less friendly?\n\u2014\nReply to this email directly or view it on GitHub.\n. Yeah, this is me. I'm on it.\n. Fixed with e463578c5b9f417ff1d7845ae817dc64c89664f5\n. Fixed with e463578c5b9f417ff1d7845ae817dc64c89664f5\n. @Coneko I don't seem to have permissions to close issues. Would you, please?\n. @Coneko I don't seem to have permissions to close issues. Would you, please?\n. Re the classloader thing, what @asp2insp said. :-). @hzsweers is App A looking at the classpath at runtime, or the processor looking at it at compile time?\n\nIf the processor, what API call is it using? I've got processors that do this kind of thing and are working fine with Buck, so hopefully I can help figure that out.\nIf the app, is this an Android app by chance? Java resources don't usually make it into APKs built with Buck. I don't know whether that's intentional or not, but I know I've taken advantage of it in the past. :-)\nI just joined the Slack channel so feel free to hit me up there too.. I've been working in the ABI code a bunch recently, so I'll take a look. Do you happen to have a repro with something that I can clone and build?. Thanks for the repro case! I've root-caused this and I'm working up a fix now.. Fixed!. Hey @kageiit, have you seen the new java_annotation_processor rule? My intention is to remove the old annotation_processors/annotation_processor_deps stuff and then document java_annotation_processor as the way to work with APs in Buck.\nAs the implementation of that rule stands, the way to do what you want would be to define a java_annotation_processor rule whose deps includes both error-prone and any custom checks (edit: and then refer to that rule in the plugins parameter of rules you want checked). Does that work for you?. Hey @kageiit, have you seen the new java_annotation_processor rule? My intention is to remove the old annotation_processors/annotation_processor_deps stuff and then document java_annotation_processor as the way to work with APs in Buck.\nAs the implementation of that rule stands, the way to do what you want would be to define a java_annotation_processor rule whose deps includes both error-prone and any custom checks (edit: and then refer to that rule in the plugins parameter of rules you want checked). Does that work for you?. @kageiit on documentation, I'm letting the design bake a little bit before putting docs up on the site, but I will do so soon.\nThe processor_class would be error prone's processor itself. Or is it a custom compiler or something?. Making processor_class optional should make that work as long as error-prone is run out of process from Buck. Is that the scenario? I don't think this PR or making processor_class optional would be sufficient to make it run in-process, because of the way Buck creates annotation processors for use with an inproc compiler.. Hm, and it finds checkers even on modules that don't use another AP?. Yeah, I'm just surprised there's a class loader getting created for that at all.. Ah, I see. It's because the processorpath option is still handled by the FileManager. OK, that makes sense. So making the processor_class optional should also work.. I've seen this with buckd, but never without. Are you sure you get it even with NO_BUCKD=1?. I've seen this with buckd, but never without. Are you sure you get it even with NO_BUCKD=1?. @kageiit yeah that commit does make Buck want a compiler that looks a little more like javac than previously, though still it's not expecting specific javac internals so it felt like fair game at the time.\nI could probably make BuckJavacTask be more forgiving of differences, but there are going to be features that stop working if the custom compiler doesn't support all of javac's public APIs, such as the coming source ABI generation which depends on a full implementation of the Compiler Tree API.. What's your preferred way of viewing traces? Do you use about:tracing or the Buck builtin webserver?\nIt looks like there was a change recently to enable streaming of gzipped traces, which could help with this.. Enable the server and the trace link is printed after the build, or you can navigate to its root page and go from there. However, the buck builtin web server uses a really old version of the viewer, so you're better off with chrome://tracing anyway.\nI just tried the new streaming support on a big trace and it seems like it may not actually work yet.. Sorry for the delay; I was on vacation. ;-)\nI'm not gonna say never, but there are no concrete plans right now.\nMethod usage/change tracking would require a fundamentally different approach to what Buck currently does with class usage/change tracking. \nThe class stuff relies on the fact that there is one .class file per class. During compilation, it tracks which class files are actually read by the compiler, and then when generating the dependency file rule key it adds only those class files to the key.\nMethod tracking would require switching to a static-analysis-based means of detecting dependencies, and some way of hashing single methods into the rule key.\nThe static analysis is doable and I think we might actually be able to piggyback off work the compiler already does. At some point I think we'll probably want to switch even the class-level stuff to static analysis. The file-based approach to dependency detection was quick to implement, but it does have its blind spots (e.g. technically for correctness adding a class in a module should have a similar effect to what you're seeing with adding a method, though I think we're not doing that right now).\nThe implications for rulekey computation are less obvious to me. I expect hashing individual methods has some subtleties. It would also add roughly another order of magnitude to the number of things being hashed for a dependency rule key, and those are already kinda slow to compute. I'd probably want to do some performance experiments around that before diving too deeply into the rest of it.. In-memory compilation is referring to Jsr199Javac, which invokes the compiler in-process with Buck. It's a ton faster than exec'ing javac for each rule (e.g. for Buck itself literally 100% faster), because it eliminates invocation and VM startup overhead, allows the compiler (and in some cases annotation processor) classes to be loaded just once, enables some cross-build caching of JAR directories, lets the HotSpot JIT get the compiler code nice and speedy, allows us to build the output JARs in memory, enables dependency file support, and probably some other things I'm forgetting. The list keeps getting longer since most of our Java-specific performance efforts are focused on this mode.\nOne alternative that can be done now is to create extra build rules with the dependencies hooked up in such a way that the checking rules will always run any time the compilation rule does. However, that way has other challenges, in that it can slow down the initial processing of the BUCK files, put additional stress on cache servers (and require more cache fetches), and make the graph generally harder to understand.. In-memory compilation is referring to Jsr199Javac, which invokes the compiler in-process with Buck. It's a ton faster than exec'ing javac for each rule (e.g. for Buck itself literally 100% faster), because it eliminates invocation and VM startup overhead, allows the compiler (and in some cases annotation processor) classes to be loaded just once, enables some cross-build caching of JAR directories, lets the HotSpot JIT get the compiler code nice and speedy, allows us to build the output JARs in memory, enables dependency file support, and probably some other things I'm forgetting. The list keeps getting longer since most of our Java-specific performance efforts are focused on this mode.\nOne alternative that can be done now is to create extra build rules with the dependencies hooked up in such a way that the checking rules will always run any time the compilation rule does. However, that way has other challenges, in that it can slow down the initial processing of the BUCK files, put additional stress on cache servers (and require more cache fetches), and make the graph generally harder to understand.. @brettwooldridge yes, that's totally true. Buck is still using the ABIs for change detection, even though it's not compiling against them. That's a bug.. @hzsweers neat! That should be straightforward to plug in. The ABI filtering happens in https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/abi/AbiFilteringClassVisitor.java. That class has a unit test (AbiFilteringClassVisitorTest) and there's also more end-to-end style testing in StubJarTest.. @hzsweers neat! That should be straightforward to plug in. The ABI filtering happens in https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/abi/AbiFilteringClassVisitor.java. That class has a unit test (AbiFilteringClassVisitorTest) and there's also more end-to-end style testing in StubJarTest.. I'm OK with this as a workaround, but let's not mark it as a fix...the real fix (at least for this specific issue) is to make the ABI generator aware of Kotlin's metadata for inline functions, and include the bodies of same. I'd like to keep the issue open until that can be done.. This should be really straightforward to do in JarBuilder. Although deciding on the proper ordering will be interesting.. Although deciding on the proper ordering will be interesting.. The docs imply, but don't outright state, that the iteration order is the order in which the names appear. The OpenJDK source looks like it's indeed doing it in order. And yeah, following existing precedent makes sense.. The docs imply, but don't outright state, that the iteration order is the order in which the names appear. The OpenJDK source looks like it's indeed doing it in order. And yeah, following existing precedent makes sense.. I think @cwoodwar6's guess is right on. RobolectricTestDescription is setting setTrackClassUsage based on what the JavacOptions say, without considering that pure Kotlin doesn't actually support it yet. https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/RobolectricTestDescription.java#L184. Mixed Kotlin+Java doesn't really support it either, so really if there's any non-Java code in there at all it should probably be turned off to prevent weirdly incorrect cache behaviors.. I'm working in this area right now, might as well fix this while I'm at it.. @kageiit I expect so.. Yeah I would think that module-info.class will be required for correct compilation with javac 9. Buck doesn't yet support javac 9, and as you say all of this will likely change once the official release occurs, but why ignore the files now? Was it causing some kind of issue to leave them in?. Yeah I would think that module-info.class will be required for correct compilation with javac 9. Buck doesn't yet support javac 9, and as you say all of this will likely change once the official release occurs, but why ignore the files now? Was it causing some kind of issue to leave them in?. Glancing at the history for the ASM 6.0 branch it looks to be mostly dealing with modules, so it seems pretty safe to use. If the ABI tests are passing, I'm good with that part.\nFor log4j, I think you should work around that in your own build. Use a java_binary rule with a blacklist to build a new jar that strips out the module-info.class files rather than put the exclusion in Buck itself. You can then either check that jar in instead of the log4j one, or wrap the java_library in a prebuilt_jar and depend on that rule instead of one for the raw log4j jar.. Glancing at the history for the ASM 6.0 branch it looks to be mostly dealing with modules, so it seems pretty safe to use. If the ABI tests are passing, I'm good with that part.\nFor log4j, I think you should work around that in your own build. Use a java_binary rule with a blacklist to build a new jar that strips out the module-info.class files rather than put the exclusion in Buck itself. You can then either check that jar in instead of the log4j one, or wrap the java_library in a prebuilt_jar and depend on that rule instead of one for the raw log4j jar.. @brettwooldridge, it's on java_binary, and it is documented. 6th one down on https://buckbuild.com/rule/java_binary.html. There is a similar (also documented) feature on java_library (remove_classes), but it only affects things that would be included in the java_library itself. Since you want to construct a jar that is exactly like an existing jar minus a few files, java_binary is what you need.\nAs to the documentation thing. I'm not a core Buck team member so don't take the following as authoritative. I agree that we shouldn't be suggesting undocumented features as solutions (at least without filing a task to document them). I think that requiring everything to be supported (with some things marked experimental) would require a change in how Buck is developed, such as using feature branches instead of developing things in master under feature flags or simply undocumented until they're stable, and would probably slow down feature development.. Not terribly surprising. Thanks for the PR, we'll get it in.. Thanks for the report. Looking into it now.. Fix coming shortly.. > it runs under Java 9\nWell, sort of. Some codepaths in the Java compilation support don't like it much. :-). I think I might need to just see a proof of concept to fully understand what you're suggesting, but here are my thoughts based on what I think you're saying.\n\nSo we could make a custom rule, called kotlin-annotation-processor which would be responsible for the steps 1 and 2.\n\nI would suggest that you have separate rules for 1 and 2. That way if Buck detects nothing has changed about the stubs, it can just skip running the annotation processors. This does not mean that the user has to manually write these rules. Buck would simply create them during action graph creation, in much the same way as it already expands a java_library into DefaultJavaLibrary and CalculateAbiFromSource and a few others.\n\nThis rule would give you all the options you need to get kapt to work properly, for example, as tools.jar is a plugin, and the ap jar is a plugin as well, you would have an array of plugins (then on Java9, you simply don't pass the tools.jar)\n\nI want to reiterate that I think the right way to give kapt access to the stuff that lives in tools.jar on Java <=8 on Java 9 is by controlling which class loader you use to load the compiler.\nRelated, since we're running kapt in process...does it have an API that lets the caller instantiate the annotation processors, like javac does? If so, might as well give Kotlin the annotation processor ClassLoader sharing that Java has had with Buck for a while now. It's a huge perf win for people who use a lot of APs.\n\nyou could stablish the output for the generated sources, which is basically an entry called kapt.kotlin.generated with the value as the desired path on the apoptions plugin parameter.\nAnd them on the kotlin rule you set that path as one of the sources to look at.\n\nThis makes sense. From a Buck standpoint you'll want to make sure that the generated sources are considered the default output of the rule that runs annotation processors, and that you use a BuildTargetSourcePath to represent that when giving it to the kotlin rule.\n. I think I might need to just see a proof of concept to fully understand what you're suggesting, but here are my thoughts based on what I think you're saying.\n\nSo we could make a custom rule, called kotlin-annotation-processor which would be responsible for the steps 1 and 2.\n\nI would suggest that you have separate rules for 1 and 2. That way if Buck detects nothing has changed about the stubs, it can just skip running the annotation processors. This does not mean that the user has to manually write these rules. Buck would simply create them during action graph creation, in much the same way as it already expands a java_library into DefaultJavaLibrary and CalculateAbiFromSource and a few others.\n\nThis rule would give you all the options you need to get kapt to work properly, for example, as tools.jar is a plugin, and the ap jar is a plugin as well, you would have an array of plugins (then on Java9, you simply don't pass the tools.jar)\n\nI want to reiterate that I think the right way to give kapt access to the stuff that lives in tools.jar on Java <=8 on Java 9 is by controlling which class loader you use to load the compiler.\nRelated, since we're running kapt in process...does it have an API that lets the caller instantiate the annotation processors, like javac does? If so, might as well give Kotlin the annotation processor ClassLoader sharing that Java has had with Buck for a while now. It's a huge perf win for people who use a lot of APs.\n\nyou could stablish the output for the generated sources, which is basically an entry called kapt.kotlin.generated with the value as the desired path on the apoptions plugin parameter.\nAnd them on the kotlin rule you set that path as one of the sources to look at.\n\nThis makes sense. From a Buck standpoint you'll want to make sure that the generated sources are considered the default output of the rule that runs annotation processors, and that you use a BuildTargetSourcePath to represent that when giving it to the kotlin rule.\n. @thalescm, each src is just a SourcePath, so you should be able to use getSourcePathToOutput and just add that to the sources. It can even be a .src.zip (at least for Java).. I'm happy with the changes you made for me. I'll leave it to @styurin . I'm happy with the changes you made for me. I'll leave it to @styurin . With the module notation in those callstacks it looks like Java 9. I imagine com.sun.security got locked down with Jigsaw.. Just saw this. annotation_processor_params will do this as well.. \"any\" is correct, actually. The rest of the document goes on to explain that there are multiple types of rule keys. The default rule key is very naively computed -- if any input or parameter to the rule or any of its transitive dependencies changes, the default rule key will change. That means there are many cases in which a rule's default rule key will change but the output of the rule will not. The other rulekey types (input-based, ABI, dependency file) are more cleverly computed, and if any of them does not change then the rule output must not have changed.. So perhaps the clarification that is needed is to introduce the concept of multiple rule keys earlier in the doc?. @andrewjcg . Hmmm...it might not change the output, but could it change the result? I.e., might error prone fail the build in response to a change in one of those otherwise-unnecessary classes?. Do you know why error-prone is loading these things? Is it doing any analysis on them that could result in it outputting errors?\nEventually I think the used-classes stuff should move to a language-level analysis rather than its current expedient implementation, but if EP is doing some transitive data flow analysis or something that could throw a wrench in things.. Unfortunately I don't think stopping before analyze works...the compiler will read classes during that phase that it hasn't read before. Stopping before generate might be OK. Edit: except that the compiler interleaves those two, doing analyze for one class, then generate, then analyze for another, so really it'd be about turning the tracking off and on over and over.. This is not the same as the binary name (https://docs.oracle.com/javase/specs/jls/se8/html/jls-13.html#jls-13.1), so you'd need some additional logic to translate it appropriately.. Use of getOrDefault here is going to create a garbage LinkedHashSet every time. computeIfAbsent is better. You also won't need the putIfAbsent afterwards.. Minor: If you have isService also confirm that the name does not end in / (i.e., is not a directory) you can Preconditions.checkNotNull in the initializer rather than having this check.. Er, don't do that. Can you just use a JavaBuckConfig?. It looks like this path is used to initialize a ClassLoader that is used to load the compiler? If that's the only usage, ToolProvider.getSystemToolClassLoader will get you a ClassLoader that is equivalent to including tools.jar. You can use that as the parent ClassLoader.\nNote that ToolProvider is not actually thread safe (yay!) so we need to ensure all our usages of it are synchronized. Right now the only usage is in JdkProvidedInMemoryJavac; you'll need to factor out some new synchronized wrapper class to use both here and there.\nThat will allow you to get rid of the scary java_home finding logic too right?. Rather than duplicating code between the branches, do something like the below. It makes the function of the switch clearer and eliminates the possibility of drift in the duplicated code over time.\n```\nFluentIterable packages = FluentIterable.from(\n    unionPackage.map(Collections::singletonList).orElse(Collections.emptyList());\nif (!skipPrebuiltRDotJava) {\n    packages = packages.append(\n        FluentIterable.from(androidResourceDeps)\n            .transform(HasAndroidResourceDeps::getRDotJavaPackage));\n}\nreturn packages\n    .transform(this::getPathToRDotJava)\n    .toSortedSet(natural());\n``. The change loses this comment, and it's an important one. Similar feedback here -- there's a lot of code duplication here that should be eliminated.. That reference doesn't contradict what I'm saying...it's expecting to be able to use its defaultClassLoaderto load certain classes that live intools.jaron Java 8-. Controlling theClassLoaderas I describe above should work for that without having to directly referencetools.jar.. This feels like too broad a location as we try to modularize Buck further. Should probably be at leastcom.facebook.buck.jvm. @styurin probably has the most skin in the game here, though, so I defer to him.. No abbreviations, please.. No abbreviations, please. By the name I would have expected this to be getting the path to the annotation processor itself, and that's not what it's doing.. BecauseToolProvideritself is not thread safe, you'll need to synchronize this with the (currently single) other usage ofToolProvider, or else there may be strange and intermittent failures when running underbuckd.. This is another reason to do these as rules rather than steps -- you won't need to special case this since ajava_libraryrule with empty sources already does the right thing.. Yep, I get that. I don't know what the policy is on \"core\" pieces of Buck knowing about the various plugins though.. That should do it. If you wouldn't mind, though, factor that out into a helper class somewhere so that we don't have to repeat the comment every time..This is common when...is all an implementation detail; someone writingBUCKfiles would never need to use this capability for that purpose..glob('*.java')`. Internal CI is failing because annotation processors are not run on the Java parts of a mixed Java & Kotlin module, presumably because of this line.. ",
    "ldjhust": "@llj098 how do you solve the problem? I just have the same problem too\nThank you. Hi @hitYOUcry @marcinkosiba , does this problem has already sloved? I just have the same problem\nThank you. OK, thanks very much, I'll try it.. Sorry, I found the solution on a previous issue #1001 .\nThank you for your response!. found the reason.. Thanks for your response @Coneko, and here is my .buckconfig and .buckjavaargs, I'm setting it exactly according to the doc. Is there args that I need to set?\n.buckconfig\n\n.buckjavaargs\n\n. @kageiit thank you for your response, I have tried your suggestion, but it failed with a strange exception in the split_zip step:\nBUILD FAILED: //:release_apk failed on step split_zip with an exception:\nclasspath com/big/location/scheduler/d/a is contained in multiple dex stores\nI searched it in my project, there was just one com/big/location/scheduler/d/a in one of my jar library. I previously used the buck-v2016.11.11.01 version, and it's fine with split_zip step, but failed in smart_dex step due to OOM like above. Do you have opinion about this?\nBy the way, my .buckversion file content is below:\neacfc4f0fc372a755d3c4f6c33867e032659c7dc:refs/heads/master. @marcinkosiba thank you for your response, I just use the use_split_dex arg, and didn't use other special args. Here is my android_binary rule:\nshell\nandroid_binary(\n    name = \"release_apk\",\n    keystore = \":release_keystore\",\n    skip_crunch_pngs = True,\n    includes_vector_drawables = True,\n    proguard_config = \"conf/proguard/proguard.cfg\",\n    android_sdk_proguard_config = \"none\",\n    package_type = \"release\",\n    use_split_dex = True,\n    manifest = \":test\",\n    deps = [\n        \":res\",\n        \":lib\",\n    ]\n). @marcinkosiba I find a workaround, add the \"-keep class com.big.location.scheduler.**\" to the ProGuard config file, and then the split_dex error disappeared. But I don't why. thank you guys, I have already knew it~. OK, thanks very much @Coneko !. OK, thanks very much @Coneko !. ",
    "ajtulloch": "@LegNeato  were you planning on PR'ing https://github.com/LegNeato/buck/commit/9e14600b0ff704ae8574b77cf256f31340b7fbc3?\n. @LegNeato  sure, that would be great. We'll test internally.\n. ",
    "prince-gill": "Any update on this? Or a workaround? Attempting to use play-services-8.4.0.aar.\n. ",
    "nemith": "We should be good.  I rebased it internally and it should be merged here soon.  Thanks again for getting this started.\n. Should this be a buck wide config setting?   Bazel looks like it may be per BUILD file.\n. Should this be a buck wide config setting?   Bazel looks like it may be per BUILD file.\n. @mikekap \n. @mikekap \n. Somehow there are some color characters getting mixed in with the command output.  I don't see these color codes when running go env from my shell so buck is adding them somehow.\nhttp://i.imgur.com/hvDXNzg.png\n. If i set the following in .buckconfig\n[color]\n   ui = false\nIt works fine.\n. Yeah I added it internally and it works now.  Thanks for looking!\n. This just came up internally, there should be a good way to not copy the same deps and srcs for tests in the same package so imho something would be nice but macros or another kwarg (like this diff) would be fine.  \nThe package name is less of an issue.\n. This just came up internally, there should be a good way to not copy the same deps and srcs for tests in the same package so imho something would be nice but macros or another kwarg (like this diff) would be fine.  \nThe package name is less of an issue.\n. I don't think that would be too restrictive.  Internal packages should live in the same directory as the package they are testing.  We already use the location of BUCK file to determine the package name so there is a strong relation between BUCK file and Go package.  It would make sense to have a tight relationship with internal tests as well.\nFor external tests there shouldn't be any restrictions as they are really standalone packages.\n. How would this work for testing go_binary() rules?  The same logic should apply right even if the parameter is called 'library'?\n. Good question.  This could be documented better.  Buck should support two ways of handling third-party packages.\n1) Use vendor directories.  Just like the go tool Buck will search up the path of your package for a directory called 'vendor' and automatically include it when looking for packages.  Vendor directories still require TARGET files!\n2) You can set a global third-party directory with go.vendor_path config option: https://buckbuild.com/concept/buckconfig.html#go.vendor_path.  It works like the vendor directories where a TARGET file for each dep is required.\nRight now it is up to you to download the packages, all dependencies and create the TARGET files or create a tool to do this (using go command as a reference)\nProbably should leave this issue open to document the vendor directory behavior.\n. Can genrules be referenced in resources?  Seems like a better place than srcs or deps.\nhttps://buckbuild.com/rule/go_test.html#resources. Not yet.   Internally at facebook we use a utility that generates the BUCK files and build rules using the build package, but this is useful only if you support a single platform.\nIdeally some sort of source file filtering would be included into Buck, but doesn't exist yet.. Not yet.   Internally at facebook we use a utility that generates the BUCK files and build rules using the build package, but this is useful only if you support a single platform.\nIdeally some sort of source file filtering would be included into Buck, but doesn't exist yet.. Yes, the sources are just passed directly into the compiler.  The compiler itself doesn't do any filtering of files, all that is inside the go tool which buck bypasses.\nYou could wrap the compiler with a small go program that would take all source, inspect them and only pass the ones that match the current build context on.   Maybe it could be another step inside buck itself which would allow automatic cgo builds, etc as well.. Yes, the sources are just passed directly into the compiler.  The compiler itself doesn't do any filtering of files, all that is inside the go tool which buck bypasses.\nYou could wrap the compiler with a small go program that would take all source, inspect them and only pass the ones that match the current build context on.   Maybe it could be another step inside buck itself which would allow automatic cgo builds, etc as well.. That functionality doesn't exist yet.  At facebook we wrote a small go utility that creates BUCK files with the correct files based off of build.Package (https://golang.org/pkg/go/build/#Context.Import)\nLess than ideal but it works.  Buck doesn't inspect the contents of files so it cannot work the same as go build. . That functionality doesn't exist yet.  At facebook we wrote a small go utility that creates BUCK files with the correct files based off of build.Package (https://golang.org/pkg/go/build/#Context.Import)\nLess than ideal but it works.  Buck doesn't inspect the contents of files so it cannot work the same as go build. . You still need to be explicit about your dependencies in your BUCK file.\nAdd deps=['//vendor/github.com/stretchr/testify/assert:assert] and create a BUCK file for assert.. You still need to be explicit about your dependencies in your BUCK file.\nAdd deps=['//vendor/github.com/stretchr/testify/assert:assert] and create a BUCK file for assert.. Rewrites the import paths. It only works because your 'vendor_path' is called vendor and it's at the root level.\nDirectories named 'vendor' are automatically traversed to find a dependency.\nFor example if you have:\na/b/c/{BUCK,main.go} it will automatically look for a dep in a/b/c/vendor, a/b/vendor, a/vendor and finally vendor.  If it finds the dep it will make sure the rewrite works so instead of importing \"a/b/c/vendor/github.com/stretchr/testify/assert\" you can just import \"github.com/stretchr/testify/assert\".  It essentially just tells the linker where to find that import.  \nFor Facebook we have a monorepo with all languages in it which means a directory called 'vendor' doesn't work and so vendor_path was required to set it to another location.. So either you have the full package name in your BUCK target for the external dep, or it's cached somehow already.\nIt works here\n```\n$ buck build //gobin/...\nGuessing 2645680beb2bdbbb4cef865a248234eb96102568 as the last one used version.\n/home/bbennett/bucktest/gobin/main.go:3: can't find import: \"github.com/pkg/errors\"\nBuild failed: Command failed with exit code 2.\nstderr: \n    When running .\n    When building rule //gobin:gobin#compile,linux_amd64.\nBuilding: finished in 0.3 sec (100%) 5/5 jobs, 1 updated, 20.0% cache miss\n  Total time: 0.7 sec\n$\u00a0echo -ne \"[go]\\n\\tvendor_path = \\\"third-party/go\\\"\\n\" >> .buckconfig \n$ buck build //gobin/...\nGuessing 2645680beb2bdbbb4cef865a248234eb96102568 as the last one used version.\nBuilding: finished in 0.5 sec (100%) 6/6 jobs, 2 updated, 33.3% cache miss\n  Total time: 0.9 sec\n$\n```\n```\n$ cat gobin/BUCK \ngo_binary(\n    name = \"gobin\",\n    srcs = [\"main.go\"],\n    deps = [\"//third-party/go/github.com/pkg/errors:errors\"],\n)\n$ cat third-party/go/github.com/pkg/errors/BUCK\nThis TARGETS file was created automatically by 'fbgo' and any manual changes\nmay be overwritten.\ngo_library(\n    name = \"errors\",\n    srcs = [\n        \"errors.go\",\n        \"stack.go\",\n    ],\n    tests = [\n        \":errors_test\",\n    ],\n    visibility = [\"PUBLIC\"],\n)\ngo_test(\n    name = \"errors_test\",\n    srcs = [\n        \"bench_test.go\",\n        \"errors_test.go\",\n        \"format_test.go\",\n        \"stack_test.go\",\n    ],\n    library = \":errors\",\n)\ngo_test(\n    name = \"errors_xtest\",\n    srcs = [\n        \"example_test.go\",\n    ],\n    deps = [\n        \":errors\",\n    ],\n)\n```\n. If you turn on verbose output you can see exactly what Buck is doing.\nNO_BUCKD=1 buck build //gobin/... -v 3 \nGuessing 2645680beb2bdbbb4cef865a248234eb96102568 as the last one used version.\n2018-01-03 10:10:41,181 [WARNING][buck_tool.py:469] Not using buckd because NO_BUCKD is set.\nPARSING BUCK FILES... 1.3s (100%)\nCREATING ACTION GRAPH: FINISHED IN 0.1s\nverify_symlink_tree\nverify_symlink_tree\nverify_symlink_tree\nrm -f -r buck-out/bin/gobin/__gobin#transitive-symlink-tree__tree\nrm -f -r buck-out/bin/third-party/go/github.com/pkg/errors/__errors#linux_amd64,symlink-tree__tree\nrm -f -r buck-out/bin/gobin/__gobin#compile,linux_amd64,symlink-tree__tree\nmkdir -p buck-out/bin/gobin/__gobin#compile,linux_amd64,symlink-tree__tree\nmkdir -p buck-out/bin/gobin/__gobin#transitive-symlink-tree__tree\nmkdir -p buck-out/bin/third-party/go/github.com/pkg/errors/__errors#linux_amd64,symlink-tree__tree\nlink tree @ buck-out/bin/gobin/__gobin#compile,linux_amd64,symlink-tree__tree\nlink tree @ buck-out/bin/gobin/__gobin#transitive-symlink-tree__tree\nlink tree @ buck-out/bin/third-party/go/github.com/pkg/errors/__errors#linux_amd64,symlink-tree__tree\nmkdir -p buck-out/gen/third-party/go/github.com/pkg/errors/errors#linux_amd64\nBUILT 1/7 JOBS 0.1s //gobin:gobin#transitive-symlink-tree\n(cd /home/bbennett/bucktest && GOROOT=/usr/lib/golang GOOS=linux GOARCH=amd64 /usr/lib/golang/pkg/tool/linux_amd64/compile -p third-party/go/github.com/pkg/errors -pack -trimpath /home/bbennett/bucktest -nolocalimports -o buck-out/gen/third-party/go/github.com/pkg/errors/errors#linux_amd64/errors.a -I /home/bbennett/bucktest/buck-out/bin/third-party/go/github.com/pkg/errors/__errors#linux_amd64,symlink-tree__tree -complete /home/bbennett/bucktest/third-party/go/github.com/pkg/errors/errors.go /home/bbennett/bucktest/third-party/go/github.com/pkg/errors/stack.go)\nBUILT 2/7 JOBS 0.1s //third-party/go/github.com/pkg/errors:errors\nBUILT 3/7 JOBS 0.1s //gobin:gobin#compile,linux_amd64,symlink-tree\nBUILT 4/7 JOBS 0.1s //third-party/go/github.com/pkg/errors:errors#linux_amd64,symlink-tree\nmkdir -p buck-out/gen/gobin/gobin#compile,linux_amd64\n(cd /home/bbennett/bucktest && GOROOT=/usr/lib/golang GOOS=linux GOARCH=amd64 /usr/lib/golang/pkg/tool/linux_amd64/compile -p main -pack -trimpath /home/bbennett/bucktest -nolocalimports -o buck-out/gen/gobin/gobin#compile,linux_amd64/gobin.a -I /home/bbennett/bucktest/buck-out/bin/gobin/__gobin#compile,linux_amd64,symlink-tree__tree -importmap 'github.com/pkg/errors=third-party/go/github.com/pkg/errors' -complete /home/bbennett/bucktest/gobin/main.go)\nmkdir -p buck-out/gen/gobin/gobin\n(cd /home/bbennett/bucktest && GOROOT=/usr/lib/golang GOOS=linux GOARCH=amd64 /usr/lib/golang/pkg/tool/linux_amd64/link -o buck-out/gen/gobin/gobin/gobin -buildmode exe -L /home/bbennett/bucktest/buck-out/bin/gobin/__gobin#transitive-symlink-tree__tree -extld /bin/g++ buck-out/gen/gobin/gobin#compile,linux_amd64/gobin.a)\nBUILT 5/7 JOBS 0.1s //gobin:gobin#compile,linux_amd64\nBUILT 6/7 JOBS 0.3s //third-party/go/github.com/pkg/errors:errors#linux_amd64\nBUILT 7/7 JOBS 0.3s //gobin:gobin\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES\nBUILDING: FINISHED IN 2.8s (100%) 7/7 JOBS, 7 UPDATED, 42.9% CACHE MISS\nBUILD SUCCEEDED\nSpecifically the compile command has imports mapped.\n(cd /home/bbennett/bucktest && GOROOT=/usr/lib/golang GOOS=linux GOARCH=amd64 /usr/lib/golang/pkg/tool/linux_amd64/compile -p main -pack -trimpath /home/bbennett/bucktest -nolocalimports -o buck-out/gen/gobin/gobin#compile,linux_amd64/gobin.a -I /home/bbennett/bucktest/buck-out/bin/gobin/__gobin#compile,linux_amd64,symlink-tree__tree -importmap 'github.com/pkg/errors=third-party/go/github.com/pkg/errors' -complete /home/bbennett/bucktest/gobin/main.go)\nSince it's still hard to see -importmap 'github.com/pkg/errors=third-party/go/github.com/pkg/errors' which does the mapping to make the compiler happy.  It's not a really big feature but useful for us.. See https://buckbuild.com/concept/skylark.html\nYou can also see https://buckbuild.com/extending/macros.html which defines the .bzl extention as \n\nThese files must have an extension; we recommend that you use the extension, .bzl (Build Zebeline Language). :). instead of \"no Rulekey\" how about \"none of the RuleKeys\". Since we are doing Go >1.8 now is there any reason why we wouldn't want to do -json here?   We can get CGOFLAGs from it as well.  We don't need to fix it for this PR.. -json was there in Go 1.0 so no worries.\n\nhttps://github.com/golang/go/blob/release-branch.go1/src/cmd/go/list.go#L71. ",
    "petersibley": "I'm seeing this same issue with the updated homebrew package from facebook/fb HEAD tap.\n. This appears to be fixed as of last night\nOn Thursday, September 24, 2015, Shawn Wilsher notifications@github.com\nwrote:\n\n@petersibley https://github.com/petersibley, can you provide more\ndetails? @marcinkosiba https://github.com/marcinkosiba can hopefully\nhelp you out tomorrow.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/facebook/buck/issues/421#issuecomment-143066889.\n. Are there any plans to support dynamic frameworks as a target type?\n. O cool. You might consider updating the docs to reflect this. It wasn't clear to me that you could do that. Thanks.\n. \n",
    "cbrauchli": "I'd love to see this too. Is anyone actively working on it? Can I be of help?\n. Gotcha. Can you explain how these parameters would be used? E.g., if static_lib and static_pic_lib are both provided how should Buck decide which one to use? Also, I missed that cxx_library even talked about pic\u2014does static_lib mean that the library is position-dependent? \nI assumed that the reason prebuilt_cxx_library had the weird interface was because compilers have the convention that libraries are named lib{name}.{a,so}. If SourcePaths to the libraries are passed in directly, what should happen if they happen to not follow that naming convention? Raise an exception?\nThanks for the help!\n. Gotcha. Can you explain how these parameters would be used? E.g., if static_lib and static_pic_lib are both provided how should Buck decide which one to use? Also, I missed that cxx_library even talked about pic\u2014does static_lib mean that the library is position-dependent? \nI assumed that the reason prebuilt_cxx_library had the weird interface was because compilers have the convention that libraries are named lib{name}.{a,so}. If SourcePaths to the libraries are passed in directly, what should happen if they happen to not follow that naming convention? Raise an exception?\nThanks for the help!\n. ",
    "fkorotkov": "How can I specify a particular swift version? I've tried to use *_toolchains_override but with no luck :-( Buck chooses the latest toolchain but my app is not ready for Swift 3.0.\n. @nguyentruongtho thank you! It worked!\n. @nguyentruongtho thank you! It worked!\n. I continued playing with Buck and Swift and faced some strange behaviour while running Swift tests only. Objective-C tests are working fine! And even a mix of Objective-C and Swift is working fine.\nI've created a small example that illustrates the issues here: https://github.com/fkorotkov/buck-sandbox. \nEven added Travis so you can easily see output! \ud83d\ude1c https://travis-ci.org/fkorotkov/buck-sandbox/builds/162268899\n. I continued playing with Buck and Swift and faced some strange behaviour while running Swift tests only. Objective-C tests are working fine! And even a mix of Objective-C and Swift is working fine.\nI've created a small example that illustrates the issues here: https://github.com/fkorotkov/buck-sandbox. \nEven added Travis so you can easily see output! \ud83d\ude1c https://travis-ci.org/fkorotkov/buck-sandbox/builds/162268899\n. @nguyentruongtho I would love to but brew install --HEAD buck is failing. Fixed it here: https://github.com/facebook/buck/pull/898\n. @nguyentruongtho I would love to but brew install --HEAD buck is failing. Fixed it here: https://github.com/facebook/buck/pull/898\n. @nguyentruongtho I built Buck locally with the fix and only swift tests are working now!\n. @nguyentruongtho I built Buck locally with the fix and only swift tests are working now!\n. BTW I'm working on a fix for https://github.com/facebook/buck/issues/909. \n. Agreed on a bad example structure. Fixed the example :-) see https://github.com/facebook/buck/issues/909#issuecomment-250474596 \n. @robbertvanginkel @ryu2 what do you think about changing type of framework from SourcePath to BuildRule. That way it will be possible to create these prebuilt frameworks from remote_files and genrules?. @robbertvanginkel @ryu2 what do you think about changing type of framework from SourcePath to BuildRule. That way it will be possible to create these prebuilt frameworks from remote_files and genrules?. Nice! Didn't know about that!. Nice! Didn't know about that!. @nguyentruongtho agreed on a bad example structure. I've moved Version.h to objc/version folder and #import \"version/Version.h\" or #import \"Bridging/Version.h\" are still failing(https://github.com/fkorotkov/buck-sandbox/commit/c486eea6d34a2bb3717b206842d8fb0513df6835).\n. Actually after deleting buck-out #import \"Bridging/Version.h\" works. But should version/Version.h work as well?\nAlso in my more complex application that I'm trying to port to Buck #import \"TARGET_NAME/Foo.h\" still doesn't work. Will try to understand what's the difference.\n. Also a disclaimer: I have experience with different build systems like Pants and Blaze but not so much with iOS. That's why my iOS related questions in the beginning might be stupid. :-) But I'm learning quick! \ud83d\ude05 \n. @ryu2 it works! I thought I don't need to include it but now it make sense! Will try on my big app and report back. Thanks a lot!\nBTW I noticed that in the resulting cmd the bridging header is passed like -import-objc-header complex_objc_swift/Foo-Bridging-Header.h. Should it use a symlink one instead though? https://github.com/facebook/buck/blob/master/src/com/facebook/buck/swift/SwiftCompile.java#L149\n. @ryu2 it's weird but after nuking build-out it stopped working. I did some further investigation and came up with a workaround: https://github.com/fkorotkov/buck/commit/58096d0367391cc08fda3f0d773442c170614846\nIt fixed my issue on the small example and it also works on my app. What do you think? If it makes sense I'll add some tests and submit a PR.\nSeems Buck includes symlink trees of deps but not of the target itself.\n. Note: This does not work for an apple_test target since there is an extra apple-test-library flavor. Now I'm not sure if this approach is right :-( /cc @ryu2\n. ^^ just a rebase\n. ^^ just a rebase\n. @ryu2 I've addressed the comments but CI is being failing for days on master so I can't rely on it :-(\n. @ryu2 I've addressed the comments but CI is being failing for days on master so I can't rely on it :-(\n. @ryu2 indeed! I don't know what's going on there so I moved the test back to just build since we are testing a proper compilation.\nI've verified though that this test is failing without my changes and it can compile and run tests for my sandbox: https://github.com/fkorotkov/buck-sandbox\n. @ryu2 indeed! I don't know what's going on there so I moved the test back to just build since we are testing a proper compilation.\nI've verified though that this test is failing without my changes and it can compile and run tests for my sandbox: https://github.com/fkorotkov/buck-sandbox\n. @ryu2 nice! Just fixed it! PTAL\n. @ryu2 nice! Just fixed it! PTAL\n. @nguyentruongtho sorry I missed the c-headers on Linux but could you please clarify what exactly does it mean? \nMaybe exportedHeaders is a miss-leading naming. I should probably rename it to additionalHeaders since it's only used if there is a bridging header which needs them.\n. My bad :-)\n. My bad :-)\n. Don't know why it's failing now :-( ^^\n. Had to comment some things out since we are using unsafe imports: 61dd53e05eb25f8166be141f0e8eaa9bf42d5c62\nPTAL\n. @Coneko reverted. PTAL.\n. Created a separate PR https://github.com/facebook/buck/pull/936 \n. @Coneko PTAL. I've fixed failing tests here: https://github.com/facebook/buck/pull/941\n. @Coneko maybe I'm using buck.iml incorrectly but I just opened buck folder in IJ ultimate 2016.3 EAP and classes like com.facebook.buck.model.BuildTarget and some other are not resolved. I found them in build/gen and build/src-gen. After including them everything is resolved correctly and I don't see any \"red code\" in IJ.\n. Indeed! Now it's in build-ij folder. I was always running buck build buck and buck test <target> before and haven't tried building from IJ even once. Thanks!\n. @nguyentruongtho SGTM. \n. Part about headers seems reasonable to me. Seems my logic had bugs for more complicated project structure.\n. Part about headers seems reasonable to me. Seems my logic had bugs for more complicated project structure.\n. I've also noticed that we had a Buck version from December and after updating it I can't actually reproduce the issue. Going to close for now. . @Coneko it's not actually an exported header, it's true. Maybe my comment is misleading but my intention was to make it consistent with Xcode behaviour. \nI agree that it's more idiomatic to include with just a header name. But that's make it way harder to migrate an existing application from Xcode to Buck(our app for example is ~500K LOC of Swift and ObjC mix). We can try to change our code base to follow such best practices but third party libraries is another case.\nHow do you guys handle third party libraries? Or you don't have any Swift/ObjC libraries?. @robbertvanginkel it comes from the same target. Here is an example of a pod that I tried to move to Buck: https://github.com/Quick/Nimble/blob/master/Sources/NimbleObjectiveC/DSL.m#L2\nHow do you handle third party? Do you fork or maybe pre-built them?. @Coneko how do you think I can approach this issue? It's blocking us from using Nimble and Quick without forking them.\nI can't use the same technique with creating symlinks like for normal headers because I need to compile sources to emit the header. \nDo you think it make sense to create another flavor that depends on swift-compile and then provide both of rules(with swift-companion) for mixed targets from SwiftLibraryDescription#createCompanionBuildRule method?. just a quick update: we started using a fork with this change internally and it proved to unblock us from many issues we've seen. We are able now to maintain Buck and Xcode builds at the same time with minimum changes to the code.\nThis change might not be the ideal solution but it definitly works :-). @ryu2 we are seeing a race condition when CxxDescriptionEnhancer.getHeaderSymlinkTreePath is empty when we are compiling swift companion. It make sense since apple library depends on the companion and not visa versa. \nCan you suggest how to fix it? I tried to use requireHeaderSymlinkTree but it goes in infinite loop because of apple library/swift library dependencies. . @sdwilsh what about having a BUCK for them? I know I can use genrule to run something. But how for example I can have a genrule that will generate sources for my apple_library for example?. @sdwilsh what about having a BUCK for them? I know I can use genrule to run something. But how for example I can have a genrule that will generate sources for my apple_library for example?. I basically want something like:\n```\nremote_file(\n  name = 'SomePodSources',\n  visibility = ['PUBLIC'],\n  url = 'https://github.com/ABC/pod/releases/download/0.3.1/pod-v0.3.1.zip',\n  sha1 = '3f230c063f2a219605db17af479919f75e4e6926',\n  type = 'exploded_zip'\n)\napple_library(\n  name = 'SomePod',\n  context = ':SomePodSources'\n  info_plist = 'Info.plist',\n  srcs = glob(['*.swift']),\n  ...\n)\n```\nin this case context field will tell Buck to put outputs of SomePodSources so they are available as srcs. I basically want something like:\n```\nremote_file(\n  name = 'SomePodSources',\n  visibility = ['PUBLIC'],\n  url = 'https://github.com/ABC/pod/releases/download/0.3.1/pod-v0.3.1.zip',\n  sha1 = '3f230c063f2a219605db17af479919f75e4e6926',\n  type = 'exploded_zip'\n)\napple_library(\n  name = 'SomePod',\n  context = ':SomePodSources'\n  info_plist = 'Info.plist',\n  srcs = glob(['*.swift']),\n  ...\n)\n```\nin this case context field will tell Buck to put outputs of SomePodSources so they are available as srcs. But it will be super nit for OSS projects outside of a monorepo :-). Worked around it by adding buck/gen to project.ignore because of https://github.com/facebook/buck/blob/667dc14f7852dfde1d54a43bc7e894a8332cd1c2/src/com/facebook/buck/io/ProjectFilesystem.java#L304. @samjoch updated buck version with no effect. Internally we are using at most two weeks old master and this is just my sandbox for sharing things externally :-). @ryu2 yeah. Doesn't work. I also saw it while testing but didn't quickly find a way to fix it. Ideally I should somehow just get rid of extra flavors(https://github.com/facebook/buck/blob/master/src/com/facebook/buck/apple/AppleTestDescription.java#L174) instead of hardcoding a check on AppleTestLibrary. \nDo you have any suggestion how can I do it in a clear fashion?\n. Yeah. Doing it at the moment. But need to refactor dependencies a bit because I need to filter flavors from AppleDebugFormat as well.\nThis is my additional refactoring https://github.com/facebook/buck/pull/916\n. @nguyentruongtho me too. I'm testing stripping SwiftLibraryDescription.SUPPORTED_FLAVORS, AppleDebugFormat and SwiftLibraryDescription.Type now.\nI was looking for a method that returns header tree for a given target but haven't found one.\n. @ryu2 I clearly see in my debugger it creates headers,iphonesimulator-x86_64 symlink tree. But for apple_test it anyways ends up with #apple-test-library,headers,iphonesimulator-x86_64. I'm kind of lost and don't understand who appends apple-test-library in this case.\n. @dreiss it was weirdly failing with:\nNo rule found when resolving target //test/com/facebook/buck/apple:apple in build file //test/com/facebook/buck/apple/BUCK\nDefined in file: /home/travis/build/facebook/buck/test/com/facebook/buck/apple/BUCK\nAfter my first commit: https://travis-ci.org/facebook/buck/builds/166817601\nI assume it's because of this: https://github.com/facebook/buck/blob/master/test/com/facebook/buck/apple/BUCK#L21\nWhere //test/com/facebook/buck/apple:apple is available only on darwin. But Travis is running precise.\n. I can submit it in a separate PR. Just noticed that it seems like a bug.\n. ",
    "nguyentruongtho": "In the mean time, you could use this settings:\n[apple]\n  iphonesimulator10.0_toolchains_override = com.apple.dt.toolchain.Swift_2_3,com.apple.dt.toolchain.XcodeDefault\n  iphoneos10.0_toolchains_override = ...\n. yeah, apple_test can handle mixed swift & objective-c (thanks to this PR: https://github.com/facebook/buck/pull/881). For swift-only target, I've just landed https://github.com/facebook/buck/pull/895, that PR should make apple_test to work with swift-only target, but obviously I have not tested it yet, you can try.\n. yeah, apple_test can handle mixed swift & objective-c (thanks to this PR: https://github.com/facebook/buck/pull/881). For swift-only target, I've just landed https://github.com/facebook/buck/pull/895, that PR should make apple_test to work with swift-only target, but obviously I have not tested it yet, you can try.\n. Very nice, I didn't think of this when working on https://github.com/facebook/buck/pull/895. Good to know :rocket:!\n. Very nice, I didn't think of this when working on https://github.com/facebook/buck/pull/895. Good to know :rocket:!\n. I doesn't look like an issue to me, you should not include a header from parent folder like in objc/Foo.h, but I might be wrong, @ryu2 probably knows more.\n. Currently, swift_library can export its generated header, but not for an apple_library that contains swift files, feel free to open a ticket for it.\nYour example is actually a special case of dependency problem, where a swift_library cannot have an apple_library target as a dependency. I'm currently working to fix this.\n. @steeve The solution for now is to split your big target into smaller, independent ones.. I created a PR a while ago https://github.com/facebook/buck/pull/917 for this split, but observed a minor improvement. Can you link me to your PR?. @huy-le  Framework doesn't work yet for swift as I commented in https://github.com/facebook/buck/issues/1237#issuecomment-286421087. \nBuck doesn't use xcodebuild, it uses command line tools (https://developer.apple.com/download/more/).. @btc @noahsark769 @Usipov apology for the late reply. We are having a few refactoring to be able to merge things back to master. \nBeginning of this year we have completed swift support in buck and was in a process of merging back to master. Tricky part is that at the time we had it, swift didn't have support for creating static library afaik. Beside, we couldn't afford having too many frameworks for our app because it significantly reduces the app performance, so we came up with a solution to create a single app by linking all objects file of swift targets together in one shot. To support this solution, we made quite a few unconventional commits on our buck fork and therefore we are paying it back by trying to do thing right.\nWe have a plan to bring what we have to master, but let's discuss further on our slack group.. @ryu2 I think you are talking about this flag: -parse-as-library https://github.com/nguyentruongtho/buck/blob/b3b99b1577764c00fa4e479f41980671ae53c61f/src/com/facebook/buck/swift/SwiftLibrary.java#L238-L241. I completely forgot about it when I used the new approach. The question is: how do you know whether there is a main in objc source so that we can ignore the implicitly one generated by swift.\n. @ryu2 I think you are talking about this flag: -parse-as-library https://github.com/nguyentruongtho/buck/blob/b3b99b1577764c00fa4e479f41980671ae53c61f/src/com/facebook/buck/swift/SwiftLibrary.java#L238-L241. I completely forgot about it when I used the new approach. The question is: how do you know whether there is a main in objc source so that we can ignore the implicitly one generated by swift.\n. I think @bhamiltoncx has a valid point. Updated the PR to reflect that.\n. I think @bhamiltoncx has a valid point. Updated the PR to reflect that.\n. This only works for macos platform at this moment as it supports static linking. I'll update this PR for ios soon.\n. Interestingly, static linking also works for iOS module, please have a look at the third example from here: https://github.com/nguyentruongtho/buck_swift_test/tree/master/swift_on_swift. I haven't check if cyclic dependences is a problem here. For example: \n- A depends on B, B depends on X\n- A depends on C, C depends on X\nWill X be statically linked to A twice (compilation error)?\nHowever it would be interesting to link swift libraries statically (I believe it is not documented by Apple).\nThe problem I had earlier was that, flavors of parent target weren't populated to swift deps before preprocess stage (swift header generation happened before this). Because of that, swift deps used the default cxx platform, macosx, specified in .buckconfig, as the result parent target couldn't get linked with its swift dependency. When I specify swift platform explicitly, it works.\n. getting final dylib would not be a problem, xcode always does that at the end for a swift library compilation. We can just add an additional step for swift_library for it.\nThis is what xcode does:\nclang\n-arch x86_64\n-dynamiclib\n-isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk\n-L$BUILD/Products/Debug\n-F$BUILD/Products/Debug\n-filelist $BUILD/Intermediates/swift_on_swift.build/Debug/dep1.build/Objects-normal/x86_64/dep1.LinkFileList\n-install_name /usr/local/lib/libdep1.dylib\n-Xlinker\n-rpath\n-Xlinker @executable_path/../Frameworks\n-Xlinker\n-rpath\n-Xlinker @loader_path/../Frameworks\n-mmacosx-version-min=10.11\n-Xlinker\n-no_deduplicate\n-L/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/swift/macosx\n-Xlinker\n-add_ast_path\n-Xlinker $BUILD/Intermediates/swift_on_swift.build/Debug/dep1.build/Objects-normal/x86_64/dep1.swiftmodule\n-single_module\n-compatibility_version 1\n-current_version 1\n-Xlinker\n-dependency_info\n-Xlinker $BUILD/Intermediates/swift_on_swift.build/Debug/dep1.build/Objects-normal/x86_64/dep1_dependency_info.dat\n-o $BUILD/Products/Debug/libdep1.dylib\nWe should run some tests to measure the time to run this task. If it can take long, I think it make sense to make the dylib generation step optional.\nThe problem I mentioned with the platform flavor is more complicated, I'm working on it right now.\n. I run the test manually and it worked, forgot that @ryu2 has added the test in https://github.com/facebook/buck/pull/843. It should work now.\n. Pay off a bit by using a NoopBuildRule during creating build rule for apple targets when there is no swift source in the target. However, it looks better to me since most of the logic are now enclosed in SwiftLibraryDescription.\n. Please ignore, I accidentally pushed the changes. \n. @ryu2 No worries, I'll update it in a bit. Just tried with my new version, it is working :)\n. \n@ryu2 @Coneko no more WIP, plz help reviewing the PR. Thanks.\n. Sorry for some spam commits, this is when I start to like arc lint \ud83d\ude10 \n. unfortunately, it doesn't. Let's put this issue up here so we won't forget. The fix should be easy, I guess.\n. unfortunately, it doesn't. Let's put this issue up here so we won't forget. The fix should be easy, I guess.\n. Are you saying that we can use configs as an attribute of apple_bundle for xcode project generation? is it documented somewhere?\n. Are you saying that we can use configs as an attribute of apple_bundle for xcode project generation? is it documented somewhere?\n. Closed in favor of using 2 smaller PRs https://github.com/facebook/buck/issues/896 & https://github.com/facebook/buck/pull/899.\n. Closed in favor of using 2 smaller PRs https://github.com/facebook/buck/issues/896 & https://github.com/facebook/buck/pull/899.\n. \n. @ryu2 plz don't import it yet as we'll need to add a constraint to not adding SwiftSupport folder when there is no swift file included.\n. I've just discussed with @Coneko on this, we will need to cover an edge case about the building order and caching problem.\nThis PR is planed for changes. You can have a look to understand what is going on, and what we are trying to do, but this is subject to change soon.\n. I've just discussed with @Coneko on this, we will need to cover an edge case about the building order and caching problem.\nThis PR is planed for changes. You can have a look to understand what is going on, and what we are trying to do, but this is subject to change soon.\n. no, let's close this as there are issues described in https://github.com/facebook/buck/pull/907#issuecomment-250240761, and also swift3 probably changed the way this works.. This really confuses me, or it looks like a bad practice imho, since if you are right about it, by looking at objc/Foo.h itself, you have no idea of where Version.h is located.\n. @robbertvanginkel has some WIP on generating module map for an apple library: https://github.com/facebook/buck/pull/842/files. \nFor swift framework, we need to add the generated header to module map as well.\n. CI became crazy~\n. CI became crazy~\n. interestingly, travis rebases your diff autoz and build with the rebased version, that's why it failed!\n. interestingly, travis rebases your diff autoz and build with the rebased version, that's why it failed!\n. Just rebased for huge java8 changes ^.\n. Just rebased for huge java8 changes ^.\n. > Rather than having CxxCreateArgFileStep and CxxCreateFileListStep encode so much information about the specifics of their use case, making them very unintuitive to use, merge them into a single class that is more reusable and behaves more like a normal step: don't delete the output before writing out the new one, and pass in an optional escaper to use.\n\nAlso you still have to address the issue of splitting SwiftCompile.\n\nI preserved SwiftPrepareForCompile as a composite step of the other two, one has to follow the other in the right order. Not quite follow the deletion suggestion, I thought we did the same thing in CxxPrepareForLinkStep? \nI think creating filelist step is worth to be taken out since it is going to be used in both linking (CxxLink) and compiling (SwiftCompile), maybe we can remove CxxCreateArgFileStep, but it's not clearly better though.\nAny suggestion for splitting the step? \n. hmm, but for SwiftCompile, I don't need the args file, CxxCreateFileListStep is what I actually need. We don't want to duplicate the logic for creating file list in both CxxCreateFileListStep and CxxPrepareForLinkStep, that's why I want to split it into 2 steps.\nSo, if we want to keep CxxPrepareForLinkStep class, we need to rename it, since it is going to be used for SwiftCompile also, agree?\n. Brilliant! Didn't notice that we could make one common step out of the two.\n. just rebasing on top of the other PR, I'll inform you when it is ready for review :)\n. just rebasing on top of the other PR, I'll inform you when it is ready for review :)\n. @Coneko Rebased. It should pass the test now but plz don't import it yet. I've just found an edge case when this fails. I'll fix it and add more test soon.\n. Pushed a wrong branch, just force pushed again with the right one. But the failing edge case is still not handled.\n. ok, let's come back to this mess \ud83d\ude3f \n. Not going to work more further on this, as we had some benchmarking @Uber and come to a conclusion that building one target in one shot is much faster than building file by file.. that's very interesting result, can you put up a branch with your modifications?. Nice, thanks @daedric and @steeve I'll check if we can get a significant improvement on our side, if yes, we should reopen this and work to get it landed together :).. I had a look through https://github.com/daedric/buck/tree/swift-zenly-rebased, there is not a lot of changes comparing to this original pr, I'm glad that it works for your project. \nI think this approach would work for a large target (many files) with a lot of separate parts in it, since in this case, there shouldn't be lot of dependencies between the files/classes, and buck will be able to parallelize the jobs better when compiling per-file targets. I would ague that if this situation happens, we should refactor the big target and split it into smaller targets. However, this approach won't benefit much in general, and doesn't guarantee that it will be always faster, at least in our case, it is slower than compiling per-target with whole module optimization enabled.\nWe found a better way of doing this and will not continue to support this pr anymore, but we will revisit supporting better parallelization compilation for swift later. . its already in ~.~ https://github.com/facebook/buck/commit/8457c4d9095eaab80a3fa1d0646816b2d09eeb7b\n. its already in ~.~ https://github.com/facebook/buck/commit/8457c4d9095eaab80a3fa1d0646816b2d09eeb7b\n. This issue will be solved within a week, don't worry :)\n. This issue will be solved within a week, don't worry :)\n. Sorry for the delay, I had a working version for framework, which probably can fix problem for swift_library has an apple_library dependency, https://github.com/nguyentruongtho/buck/tree/framework_flavor1, but it needs to be cleaned up a bit.\n. 'MyLibrary-Swift.h' <---------------------------------------- this doesn't work\nWe had a big internal project to be taken care of recently but this one is our high priority now and I'm heavily working on this. I think what you want is to be able to import a mixed target (contains objc and swift), we want the same thing but our method is different. We are not gonna use exported headers with generated swift header (likes above), we will generate module from the target and use the generated module instead. \nCurrently blocked by this pR https://github.com/facebook/buck/pull/983, as soon as it lands, I will put something up for the above idea.\n. 'MyLibrary-Swift.h' <---------------------------------------- this doesn't work\nWe had a big internal project to be taken care of recently but this one is our high priority now and I'm heavily working on this. I think what you want is to be able to import a mixed target (contains objc and swift), we want the same thing but our method is different. We are not gonna use exported headers with generated swift header (likes above), we will generate module from the target and use the generated module instead. \nCurrently blocked by this pR https://github.com/facebook/buck/pull/983, as soon as it lands, I will put something up for the above idea.\n. This is part of the ongoing work for creating module from a target, but I guess it can solve your problem already: https://github.com/nguyentruongtho/buck/tree/tho/swift_exported_header\nYou can find very dummy poc sample here: https://github.com/nguyentruongtho/buck_swift_test/tree/master/swift_export_headers\nRun: rm -rf buck-out && buck run :parent#macosx-x86_64\nLet me know if you find any edge cases.\n. As I pointed out here: https://github.com/facebook/buck/pull/1153#issuecomment-276615983, module-Swift.h is a private header (https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html).\nWe won't allow to export module-Swift.h in buck as it is wrong. I don't know how that work with Xcode but this is terrible that Apple tooling is not consistent with their documentation.\nWe should use @import module syntax instead for importing external module and we have it working at Uber, will start merging stuff back to master.\nIf you all are agree, plz close this ticket. @ryu2 . appveyor uses windows for testing, nice!\n. I think it was passing, on Appveyor at least. Travis hung for some reasons.\nI normally run related tests locally but not all the tests we have in buck. The last failure test was because it was run on windows (couldn't help )\nI rather let CI run all tests because everytime I do it locally, it eats up 100% cpu and ram on my machine, takes 15-20 mins at least #movefast :)\n. I can't retrigger Travis, can you do it?\n. There is a problem with travis for mac builds\nhttps://www.traviscistatus.com/\nI've tested it locally, everything is good. Possible to merge in? You guys did it quite a few time already, didn't you?\n. not, it wasn't! I had two fails from com.facebook.buck.apple.* due to my local setting.\n. Let me check, sounds like os dependent problem again.\n. should this be tested on Linux machine? Feel like some failure of TravisCI last week affected the result of the PR. I'm rebasing and pushing it just for checking.\n. I have gcc on my mac, but it passed, let me try get a linux box and try.\n. sorry for the delay, working to fix the framework resource propagation, almost finish. I'll get back to this one after that gets done.\n. I've cast a spell on Travis \ud83d\udc4d \n\n. Travis resists to approve my PR, even it is not my fault this time. Well played, Travis.\n/home/travis/build/facebook/buck/src/com/facebook/buck/lua/AbstractNativeExecutableStarter.java:172: error: no suitable method found for filter(java.lang.Iterable<capture#1 of ? extends com.facebook.buck.cxx.CxxPreprocessorDep>,com.google.common.base.Predicate<java.lang.Object>)\n        Iterables.filter(deps, Predicates.not(BuildRule.class::isInstance))) {\n                 ^\n    method com.google.common.collect.Iterables.<T>filter(java.lang.Iterable<T>,com.google.common.base.Predicate<? super T>) is not applicable\n      (cannot infer type-variable(s) T,T\n        (argument mismatch; com.google.common.base.Predicate<capture#1 of ? extends com.facebook.buck.cxx.CxxPreprocessorDep> cannot be converted to com.google.common.base.Predicate<? super capture#1 of ? extends com.facebook.buck.cxx.CxxPreprocessorDep>))\n    method com.google.common.collect.Iterables.<T>filter(java.lang.Iterable<?>,java.lang.Class<T>) is not applicable\n      (no instance(s) of type variable(s) T exist so that com.google.common.base.Predicate<T> conforms to java.lang.Class<T>)\nErrors: 1. Warnings: 0.\n. > I just fixed it. It was a jdk version problem. Try rebasing and it should be fine (well, or at least fail on something else)\n\n. +1 for how fast facebook has moved, migrated java7->java8 within a week and requires me to rebase my PR everytime :trollface: \n. Unrelated failure because of special characters:\nhttps://github.com/facebook/buck/blob/779d7cd99fe6c2b8bedc08706e52b9e52b03359f/test/com/facebook/buck/cxx/CxxSourceRuleFactoryTest.java#L502-L502\n. > I have found that swift does not recognize objC files in the module, unless they are specifically included in the modules bridging header.\nYes, this is how module works, your headers need to be in exported header (public headers) for other module to use it. We are currently generate umbrella header for all exported headers. In the future, I want to add the ability to use a manually created umbrella header.\n\nI have also not been able to have external modules (eg a test module) reference an exported modules swift class from objc.\n\nThis will come in follow on PR.\n. My gos, problem with Windows again.\n. @stowy sure, I'll test your sample project once I get a CI pass for this PR  \ud83d\ude04 \n. @ryu2 you mean facebook internal CI or on your machine? what is the error message and traces? It is passing for me locally and also passed 2 CI checks with Travis & CircleCI. I'm in blind now, could you have a look at it?\n. ok, we are having issue with 8.1 internally, so we can't upgrade to use it yet. I'll download it later once I get to my office today. Still, it'd be helpful to know the error message that you are getting.\n. If there are only 2 failing test cases left, then they should be fixed now. Really have no idea why it passed before.\n. If there are only 2 failing test cases left, then they should be fixed now. Really have no idea why it passed before.\n. So, after a few ping/pong with fb peeps about failure of the tests on their internal CI, but they passed on both github CI and my local. I found out that if you run ant test, it will stop at the first failing unit test you get, which is bad, since sometimes, due to environment differences, random tests might fails, even they are not relate to your changes.\nWe should run ant test -Dtest.haltonfailure=false instead, in fact, I'm thinking about we should change the default behavior of ant test not to halt on failure.\n. So, after a few ping/pong with fb peeps about failure of the tests on their internal CI, but they passed on both github CI and my local. I found out that if you run ant test, it will stop at the first failing unit test you get, which is bad, since sometimes, due to environment differences, random tests might fails, even they are not relate to your changes.\nWe should run ant test -Dtest.haltonfailure=false instead, in fact, I'm thinking about we should change the default behavior of ant test not to halt on failure.\n. Travis fails because of Android tests, I'm sure this PR is perfect now.\n. I didn't notice that, but I think it has many good reasons to fail. The test was setup incorrectly in https://github.com/facebook/buck/pull/911.\nAFAIK, a test target cannot be a module, therefore importing like this #import \"SwiftCallsComplexObjC/Foo.h\"  is wrong.\nI am going to revert https://github.com/facebook/buck/pull/911 as I think that PR https://github.com/facebook/buck/pull/911 is doing wrongly. It tries to fix a problem using header maps but it should use module (has a module map with umbrella header) instead. If there is no offend from @fkorotkov. \nThe correct way of doing it should come after this PR. \n/cc @rmaz \n. any output that I can see, /cc @mzlee if you find a reproduceable steps.\n. any output that I can see, /cc @mzlee if you find a reproduceable steps.\n. Just updated with some architecture changes for creating module map, the bug caught by your internal CI has not yet been addressed.\n. Cool, thanks for being very descriptive about this \ud83d\udc83 \nI'll take a look during this weekend, was too busy with other stuffs recently.\n. Can you briefly explain about it, there is too many files to look into.\n. > Sure sorry, the main change is at https://github.com/stowy/buck/blob/21d4cf21eacb3191c774973772b354db37043b51/src/com/facebook/buck/swift/SwiftDescriptions.java#L67\n\nIt changes the header map to be the shortened version of { 'header_prefix_path/filename.h' : 'absolute/path/to/file/filename.h'} instead of what it is currently, which is { 'relative/path/to/filename.h' : 'absolute/path/to/file/filename.h'}. The former allows normal imports in ObjC, the latter breaks ObjC imports.\n\nI think you are right, swift companion target should know about its parent header_path_prefix and should be able to search for its parent headers during compilation. The approach looks good, I suggest you to create a simpler sample for the issue.\nSince this is issue regarding headers, @ryu2 would know more. And also, there was similar works on this part was done by @fkorotkov https://github.com/facebook/buck/pull/911. Are you guys reviewing this PR?\n. > Sure sorry, the main change is at https://github.com/stowy/buck/blob/21d4cf21eacb3191c774973772b354db37043b51/src/com/facebook/buck/swift/SwiftDescriptions.java#L67\n\nIt changes the header map to be the shortened version of { 'header_prefix_path/filename.h' : 'absolute/path/to/file/filename.h'} instead of what it is currently, which is { 'relative/path/to/filename.h' : 'absolute/path/to/file/filename.h'}. The former allows normal imports in ObjC, the latter breaks ObjC imports.\n\nI think you are right, swift companion target should know about its parent header_path_prefix and should be able to search for its parent headers during compilation. The approach looks good, I suggest you to create a simpler sample for the issue.\nSince this is issue regarding headers, @ryu2 would know more. And also, there was similar works on this part was done by @fkorotkov https://github.com/facebook/buck/pull/911. Are you guys reviewing this PR?\n. You might not need this PR. Indeed, I'm finishing up something that could cover this case, and also the previous case https://github.com/facebook/buck/pull/911.\n. You might not need this PR. Indeed, I'm finishing up something that could cover this case, and also the previous case https://github.com/facebook/buck/pull/911.\n. It shouldn't be an exported header. Generated headers are to be seen from targets that depend on the swift target containing generated header (if that swift target is a module, require module enabled) via modulemap.. Good point, I'll do that instead. I also don' like changing buck for something like this.. @robbertvanginkel has an idea that we can expand the location macro in PythonTest instead of in PythonTestDescription.. @robbertvanginkel has an idea that we can expand the location macro in PythonTest instead of in PythonTestDescription.. Update: I've just verified watchman 4.6.0 doesn't have this issue.. Update: I've just verified watchman 4.6.0 doesn't have this issue.. I think there is a disconnection between two parts, creating the header rule (this PR) and using the output header (https://github.com/facebook/buck/pull/1164). Why don't we require the header rule somewhere before creating swift compile?. @zayhero Yes, I think that is the idea. The approach is a bit hacky to me, since you created the rules (for private and public headers) way before they are actually used in SwiftCompile. The disconnection will make it hard to understand about why we need to add those rules as dependencies before looking at SwiftCompile.\nFurthermore, if the target is not a mixed target, then there will be no swift target and rule, and we are adding header targets for nothing.. RichStream is nice, I feel very much outdated... Will update the PR soon.. Framework doesn't work currently, because exported headers from apple_library are not propagated up to the bundle. The support for framework started at https://github.com/facebook/buck/pull/1032, and we are currently not actively working on it. Instead, we find another way without frameworks by supporting clang modules https://github.com/facebook/buck/pull/983.\nWe are discussing about continue our effort on supporting framework after module support, we also heard that Facebook is working on it @Coneko? Maybe we should have a meeting around this thing to make sure we are not duplicating our work.\n. Yes, I'm breaking up https://github.com/facebook/buck/pull/983 into smaller PRs, the first one is recently merged https://github.com/facebook/buck/issues/1238, and working on following up PRs.\nPlease read up about modules http://clang.llvm.org/docs/Modules.html, it is a similar concept to framework, and if it fits your case, you should wait for that PR to be merged.. If we are going to create the swift_library companion rule at the transformation phrase, we will have to populate manually its constructor arguments from its implicit parent (apple_library or apple_binary), create artificial build target & flavors, etc... This task is pretty much similar to parsing, not to mention that we will also have to change the constructor args of the parent (for removing swift sources), which is supposed to be immutable at this phrase. \nI spent sometimes today trying to do it properly, but the implementation doesn't look pretty, if you guys have a way to start with, I would love to know. Otherwise, I will take the alternative way.\n. I'll update the diff with this direction soon and see if that looks better to you :)\n. TODO: return Optional.absent()\n. One of the downside of this approach (modify the action graph during transformation phrase) is that you have to filter the source codes for swift & non-swift in apple targets. Doing it in the parsing phrase makes more sense to me. Any idea for improving this? \n. I did that on purpose since I didn't want compilation step for swift to run twice (first for preprocess to generate the header, at this step, most of flavors from it parent are not yet passed through, second is the real compile step for building the module). We could end up with two generated headers for example: App1Binary#swift/App1Binary-Swift.h and App1Binary#dwarf-and-dsym,iphonesimulator-x86_64,strip-non-global,swift/App1Binary-Swift.h, but I think you are right, it is more importing to pass the flavors through.\n. err, almost forgot about this test!\n. I thought about that.\nTo create a SourcePathResolver instance, I will need a BuildRuleResolver instance, eventually need a TargetGraph instance, and a graph transformer. Problem is that, this function hasSwiftSource is being called during findDepsForTargetFromConstructorArgs which is in the middle of building a TargetGraph instance. \nI could use TargetGraph.EMPTY and the default transformer, it should work, but I think it is not necessary, and probably this way works a bit simpler. \nSuggestion?\n. nvm, I found a solution for it. just gimme a few mins.\n. @Coneko \nSince we couldn't obtain a proper instance of SourcePathResolver at this point (explained here https://github.com/facebook/buck/pull/847#discussion_r75711254) and my last attempt (by always add a swift companion target for the apple target) didn't work well because it messed up with the TargetGraph, we can't share the logic with filterSwiftSources. \nIf we look at SourcePathTypeCoercer, there are only 2 possible types of a SourcePath in here, BuildTargetSourcePath and PathSourcePath, but BuildTargetSourcePath is not for element in srcs so we can cast sourcePath to PathSourcePath and check for its extension.\n. The previous approach has 2 issues:\n1. Since there are extra swift-lib targets even when there is no swift source, project generation task will have to filter them out, this is considered overhead. Indeed, project generation has nothing to do with the companion target, we should better off generate xcode project without creating the companion target.\n2. There is the case that AppleTestDescription delegate its findDepsForTargetFromConstructorArgs to corresponding AppleLibraryDescription, here is where the mess gets bigger, since we have a companion target for apple_test as well, this makes the project generation way more complicated.\nSince I haven't started with project generation, I would not touch before I have a clear picture of this part. I will update PR to cover the case of BuildTargetSourcePath and will update this when we start to work with project generation.\nThe change in code would not be big though, sound good to you @Coneko ?\n. Just looked at the how BuildTargetSourcePath can be included in srcs (like the one in genrule), we don't know that path without a BuildRuleResolver (https://github.com/facebook/buck/blob/405d49e6685071f12884998c0b3066dcdcc67193/src/com/facebook/buck/rules/SourcePathResolver.java#L191-L191). But the case of using genrule to add swift source file is quite trivial at this moment, we can just ignore it for now. I'll revisit this again when working on project generation. \n. That's a great idea, actually, it is quite similar to my original approach (the one with modification done in DefaultTargetNodeToBuildRuleTransformer) in the sense of not touching TargetGraph but only modify the ActionGraph. \nChanges is coming.\n. You are absolutely right.\n. \n. Didn't notice that, IntelliJ should be smarter with style auto-formatting after refactoring.\n. This is definitely something I'll need to update. I originally wanted to copy XCode behavior of always creating dylib during swiftmodule compilation, this is just 1 to 1 behavior -> implementation mapping.\n. only companion swift library does contain SWIFT_LIBRARY_FLAVOR, we don't want to generate dylib for it but link statically swift source and objc in a mix target.\nMaybe I should rename SWIFT_LIBRARY_FLAVOR to SWIFT_COMPANION_FLAVOR.\n. I wonder if we can just do the comparison check: type == SHARED instead of this, but I wanted to keep the old code here. I would prefer to use the comparison instead of having a method/attribute in the enum.\n. hmm, i think i wont use the comparison, Apple could be crazy enough to have another type of dynamic library in the future.\n. hmm, I thought about it too, but CxxPlatform is also used for non-swift targets, make no sense to add swift flags for those targets. Additionally, flag won't work for getNativeLinkableDeps, see SwiftLibrary\n. \nIndeed, we use the comparison everywhere, I guess it is safe to use it again :trollface: \n. I've updated SwiftRuntimeNativeLinkable so that the pseudo build target remains the same for all instances, it will benefit the performance since we don't have to do graph transformation for this class instances more than one.\n. The problem I mentioned above doesn't seem to work with flags. By using flags, I will have to put those flags inside SwiftLibrary#getNativeLinkableInput, and this will cause duplication.\nLet take an example, we have an apple_binary A depends on apple_library B and another swift_library C which B depends on. A has another dependence swift_library D. We want to create a binary for A with dynamic linking to all its dependencies (link_style=shared). We would end up with duplication of swift runtime flags for the linker like this:\n\n. @ryu2 can provide you more context since I took action on his comment about this duplication of runtime flags.\n. I think the problem with NativeLinkableInput is that it is concatenated in order (that is why we are using ImmutableList in here). If they can be flexible in order, we could use a set and there would not be any duplication, but order is important in linking step.\nUsing pseudo NativeLinkable works, since all NativeLinkable created in SwiftLibrary#getNativeLinkableDeps has the same build target, therefore you will have only one SwiftRuntimeNativeLinkable instance in the list of accumulated linkables after this: https://github.com/facebook/buck/blob/b83ae5538a7c553ccd10f06b2ee034dccfa412d6/src/com/facebook/buck/cxx/NativeLinkables.java#L231-L238. \nI've already tested. It works pretty well. There could be still a duplication because of this https://github.com/facebook/buck/blob/34fedbea306a4b02bd47d1e5d8847a6bac87f780/src/com/facebook/buck/swift/SwiftLibraryDescription.java#L287-L287. But there can only be a duplication of 2 at most. This is not a big issue, I'll find a way to fix this properly in follow-on diff.\n. I haven't looked at how metadata works in buck, which I'm going to dig in more to support prebuilt_framework for swift after this. The solution is very clear that we just need a way to communicate with the top level target that it has a swift dependency and it needs swift runtime flags for linking. We just need to find the most suitable implementation.\nI would be happy to merge this in for now. I'll see what I can do after working with the metadata.\n. agree that adding the flags at binary level is the best solution, I already did that anyway for SwiftLibraryDescription (since we know for sure with this description, swift stuff is included): https://github.com/facebook/buck/blob/34fedbea306a4b02bd47d1e5d8847a6bac87f780/src/com/facebook/buck/swift/SwiftLibraryDescription.java#L287-L287\n. should break this into lines when there are both extends and implements\n. Optional.<SourcePath>of()\n. I think you don't really need a separate class for this, just need a method in ProjectGenerator. should also put it inside project_generator package.\nIf you really want it, you should make it an utility class, see https://github.com/shatlykuber/buck/blob/f103eebf4f162efb6503780120f043e7dbcaf3fb/src/com/facebook/buck/apple/AppleDescriptions.java#L100-L100\n. During testing, ios loads the bundle and inject the test code to the process, therefore we need to add loader path to the list.\nYou might ask, why am I always adding this, even when it is not for test? Well, xcode is doing the same thing and it doesn't hurt by having it in.\n. I deleted both Info.plist and dep1.h since they were generated by xcode. I should have not committed those files.\n. Updated.\n. .. is there because the output folder is fixed: https://github.com/nguyentruongtho/buck/blob/eba8551d87158e76ee395ddc9fd88cea7dc9fbd1/test/com/facebook/buck/apple/project_generator/ProjectGeneratorTest.java#L157-L157, a bit weird, but its fine.\n. \ud83d\udc4d  It was a quick fix for lint issues, I prefer using assertThat also.\n. we actually don't need argfile for swift, but I don't want to duplicate stuff by creating similar class like CxxPrepareForLinkStep. \n. When merging all single file outputs, the output is another swift module, not an object file.\n. I really don't like this syntactic sugar.\n. newline\n. do you need this file?\n. I don't think it's gonna work for swift companion target. In general, I dont think it is a good idea to strip off all flavors like this.\n. should we put all individual compiled file to the same folder like this, or use separate folders like cxx precompile?\nI thought it could be a race condition when you compile file1.swift and file2.swift in parallel given file2.swift depending on file1.swift, but apparently compiling file2.swift doesn't result to compiling file1.swift (maybe it will do parsing & semantic analysis but won't actually compile file1.swift?). This is a really interesting topic and we need to understand more about swift compiler.\n. done. Also rebased to resolve conflict\n. You are right, feel free to open a PR to fix this. Thanks. I wonder why it still passed the parser validation.\n. shouldn't it be removed from the docs & code?\n. lets see if its gonna work, always fail locally for me, because of some tests for golang\n. no, coz the file list is used by all separate file build rules (dependencies of SwiftPrepareForCompile build target), better to create it upfront.\n. make sense, will do.\n. right, I forgot about the absolute path issue, will update.\n. wasnt it in the original CxxPrepareForLinkStep, was it?\n. true, I wanted to have CxxPrepareForLinkStep taking care of filelist args as the original one has. I'll move it in here.\n. \n. why does swift has exportedHeaders? isn't it something Apple-specific? Does swift on *nix have it?\n. what is the reason for this change?\n. Again, can you confirm that swift does generate c-headers on Linux too?\n. good point, that should be decoupled from swift compile. I think exportedHeaders should be ok to be included, as long as we don't have any dependency from com.facebook.buck.apple inside swift package.\n. ... and also it shouldn't affect compilation on linux machine.\n. this is a newline at the end of the file.\n. good catch, I copy-pasted -_-\n. remember that java doesn't care about generic type at compile time anyway, this is totally safe.\n. I think this should be in AppleNativeTargetDescriptionArg as binary and test rule might need it too.\n. args instanceOf AppleNativeTargetDescriptionArg\n. did you run ant lint? coz I don't think it allow you to have a condition block without brackets.\n. @AddToRuleKey for caching\n. Will it be required for mixed apple_binary target?. populateHeadersArg. not sure about the reason we need this, can we just passing the headers around without relying on the args. The args is for different purpose.. We should not use defaultCxxPlatform here. I think you should use an optional of specified cxxPlatform, otherwise, it might work for default platform specified in the .buckconfig but it won't work for target with platform flavors, for example if you want to build A#iphoneos-x86_64, but you have default_platform = iphonesimulator-x86_64, you will get problem with this.\nAbove of this, I would argue that we don't need extra params here, createCompanionBuildRule simply for creating SwiftLibrary rule (a place holder rule without any compile steps), SwiftLibrary doesn't care about cxxPlatform. Also, createCompanionBuildRule forwards all inputs from apple_binary and apple_library's createBuildRule method, so as long as apple description can get those cxx information, why can't Swift library description?\nI haven't looked much at bridging header support, I need to look through the issue again and get back with suggestion.. Implicitly use targetName.h as the umbrella header file of a module if exists (which is the way xcode structures a framework), otherwise we use umbrella directory (http://clang.llvm.org/docs/Modules.html#umbrella-directory-declaration). \nAnother way for doing this more explicitly is that we can add an extra argument for cxx_*, apple_* rules to point to the umbrella header.. Always create module map doesn't hurt, except that if the target name is not in a good format for module name, then we have to normalize it (see below). ",
    "steeve": "hey folks, how is this going ?\nwhile the swift support is working, it is currently rebuilding all the swift files if only one of them changes\nFor instance, here is my BUCK file using for the demo app modified to use some SwiftProtobuf generated models:\n```\napple_resource(\n  name = 'BuckDemoAppResources',\n  files = glob(['*.png']),\n  dirs = [],\n)\napple_bundle(\n  name = 'BuckDemoApp',\n  binary = ':BuckDemoAppBinary',\n  extension = 'app',\n  info_plist = 'Info.plist',\n  info_plist_substitutions = {\n    'PRODUCT_BUNDLE_IDENTIFIER': 'bucktest',\n    'CURRENT_PROJECT_VERSION': '1',\n  },\n)\napple_binary(\n  name = 'BuckDemoAppBinary',\n  deps = [':BuckDemoAppResources', \":SwiftProtobuf\"],\n  srcs = glob([\n    '.swift',\n    'models/.swift',\n  ]),\n  frameworks = [\n    '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n    ':SwiftProtobuf',\n  ],\n)\napple_package(\n  name = 'BuckDemoAppPackage',\n  bundle = ':BuckDemoApp',\n)\nprebuilt_apple_framework(\n    name = 'SwiftProtobuf',\n    framework = 'Carthage/Build/iOS/SwiftProtobuf.framework',\n)\n```\nThe output:\n[-] PROCESSING BUCK FILES...FINISHED 0.2s [100%] \ud83d\udc33  New buck daemon\n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...20.8s [27%] (3/11 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\n |=> IDLE\n |=> //bucktest/bucktest:BuckDemoAppBinary#dwarf-and-dsym,iphonesimulator-x86_64,strip-non-global,swift-compile...  2)\n |=> IDLE\n |=> IDLE\n[-] BUILDING...FINISHED 48.7s [100%] (11/11 JOBS, 8 UPDATED, 8 [72.7%] CACHE MISS)\n[-] INSTALLING...FINISHED 5.5s. @nguyentruongtho yes, I'm using another PR that does exactly this: create a target per file\nworks well. Btw, I'm actually using a custom buck build from this PR, and it works great !\nHopefully this will get merged soon. We had the exact opposite experience. Compiling file by file is much faster (and also incremental).\nWe can open a new PR if you guys want (we made some modifications).. We also have some CocoaPods helpers (made in python) to parse and use pods from inside a BUCK file.. ",
    "huy-le": "@nguyentruongtho Hi Tho, I found that you have many experiences on the Buck for Swift, I tried to build a dynamic framework by Buck, anything seems ok until the compiler cannot compile a file that is implemented the extension for a protocol.\nDo you know what is the tool Buck use to build the files of Swift, does it use xcodebuild? \nThis is the BUCK file I use, the code compiled well on xctool, xcodebuild or xcode:\napple_binary(\n    name = 'build',\n    srcs = glob(['*/*.swift']),\n    link_style = 'shared',\n    frameworks = [\n        '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n        '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n        '$SDKROOT/System/Library/Frameworks/PlaygroundSupport.framework',\n        ':XCGLogger',\n        ':BrightFutures',\n        ':Result',\n        ':ATRestKit',\n        ':Alamofire',\n        ':Reachability',\n        ':KZPropertyMapper',\n        ':ATUtils',\n        ':RealmSwift',\n        ':Realm.Private',\n        ':Realm',\n    ]\n)\nThe error code said I do extend an undeclared class. It make me thing the compiler try compile file per file, not a whole framework.\n. ",
    "btc": "What's the status of Swift support? Is it implemented, but undocumented? Where can I find documentation (or the equivalent)?\nWhen I try to compile an apple_binary with a main.swift, I am informed that the CXX platform doesn't contain a swift compiler, so I suppose I am in a C/C++/Obj-C context.. Ah, so the Uber engineers added Swift support themselves?. ",
    "vhbit": "Uber engineers got it working on their 500KLoc codebase so it should be\n good. But it wasn't upstreamed yet. Hopefully there will be more info\nabout it in #1302 soon.\n-- \nSent from mobile\n. @adc-amatosov my guess is that a better person to ask would be @milend as he is pushing a lot of Swift-related changes since August.. @alanzeino it's a completely offtop, but do you have any idea which is timeline for Swift support upstreaming?. ",
    "Usipov": "@alanzeino, can you comment on this? Looks like you are the most competent in that \ud83d\ude00. ",
    "keith": "\nswift didn't have support for creating static library afaik\n\nFWIW, you could always create Swift static libraries manually, or with SwiftPM, the only problem here is that Xcode has never (and still doesn't) support doing this.. ",
    "TosinAF": "@nguyentruongtho How does one find this Slack group? Is it open to the public? Also is there a branch, would love to take a look.. ",
    "FredLoh": "@adc-amatosov Check out: https://medium.com/airbnb-engineering/building-mixed-language-ios-project-with-buck-8a903b0e3e56. ",
    "dinhviethoa": "I think the current state is the you can mix Swift and Objective-C in an apple_library rule. Can you verify that everything works for you?. @ryu2 Could you take a look at this one?\n. @ryu2 what do you think?\n. We could kill .fakebuckversion altogether.\nYou can achieve the same effect using the environment variable BUCK_FAKE_VERSION.\nWhat do you think?. Could you explain what you're trying to achieve with this change?\nhttps://github.com/tiagmoraismorgado/buck/tree/patch-1\n. Could you explain what you're trying to achieve with this change?\nhttps://github.com/tiagmoraismorgado/buck/tree/patch-1\n. Is it a work in progress?. Is it a work in progress?. About the argument type, it's probably fine as is.. About the argument type, it's probably fine as is.. Thanks for helping with it!. All good! I think it's just a matter of adding comments now.. It looks like coupleof tests in //test/com/facebook/buck/apple/xcode:xcode fail.. Alright, last one request and I think that will be it: could you rebase your code?\nWe need all the fixes for Xcode 9 that are already in the repo before committing the code in the repo.. @milend could you take a look at this one?. @milend you should take a look at it.. I think you need to rebase and then we can land it.. Could you fix the following unit test?\n//test/com/facebook/buck/apple:apple_test_integration - watchApplicationBundle (com.facebook.buck.apple.AppleBundleIntegrationTest) (platform: macosx)\nTo reproduce:\nbuck test //test/com/facebook/buck/apple:apple_test_integration --filter AppleBundleIntegrationTest#watchApplicationBundle\n. Could you fix the following unit test?\n//test/com/facebook/buck/apple:apple_test_integration - watchApplicationBundle (com.facebook.buck.apple.AppleBundleIntegrationTest) (platform: macosx)\nTo reproduce:\nbuck test //test/com/facebook/buck/apple:apple_test_integration --filter AppleBundleIntegrationTest#watchApplicationBundle\n. cc @milend what's your opinion on it?. @AttilaTheFun were you able to make Xcode not crash by setting the entries in Info.plist properly?. @AttilaTheFun were you able to make Xcode not crash by setting the entries in Info.plist properly?. You're not using this value to write data to the file yet?. It looks too short :/\nMaybe we could use PRE_ACTION nad POST_ACTION.. Is there any reason why you disable it here?\nMaybe you could add a comment?. Why do you have to set it explicitly here?. ",
    "rFlex": "@milend Is that because Swift librairies are compiled as static libs? Any hope to have the debugger working for static libraries at some point or is that just never going to work until the dynamic framework workflow is implemented?. ",
    "KieranLafferty": "I managed to get my apple_binary and all dependencies building properly for a swift app but am getting a weird error when it tries to launch on simulator/device. Any idea whats going on here?\n\n. Ok! So the app now launches and runs the main.m but I'm unable to make reference to my AppDelegate file that's contained in the apple_library. \nI've attempted the following with no success\n```\nimport \nimport \nint main(int argc, char * argv[])\n{\n    @autoreleasepool {\n        return UIApplicationMain(argc, argv, nil, NSStringFromClass([AppDelegate class]));\n    }\n}\n``\nThis gets very close and code completion works for this file but I get a compilation error because the #import <CompanyLibrary/CompanyLibrary-swift.h> contains a  reference to@import MyCustomLib;which complainsModule 'MyCustomLib' can not be found`\nI also tried simply going into  and finding the class definition for my AppDelegate class which I found to have the following definition:\nSWIFT_CLASS(\"_TtC11YarnLibrary11AppDelegate\")\n@interface AppDelegate : UIResponder <UIApplicationDelegate, UNUserNotificationCenterDelegate>\nI thought that simply copying the string _TtC11YarnLibrary11AppDelegate to main.m's UIApplicationMain(argc, argv, nil,  @\"_TtC11YarnLibrary11AppDelegate\"); but that didn't work either. \nDefinitely getting closer but would be great to hear how you got it to load your AppDelegate that was contained in dependency\nNote:\nI've also removed @UIApplicationMain from my AppDelegate file and added the following to my buck config as per your comment\n[apple]\n  use_swift_delegate=false\n. Thanks for the response @adc-amatosov, I tried what you suggested (with and without @objc before the class) and didn't have any luck. \nWithout @objc in AppDelegate\nint main(int argc, char * argv[])\n{\n    @autoreleasepool {\n        return UIApplicationMain(argc, argv, nil, @\"CompanyLibrary.AppDelegate\");\n    }\n}\nWith @objc in AppDelegate\nint main(int argc, char * argv[])\n{\n    @autoreleasepool {\n        return UIApplicationMain(argc, argv, nil, @\"AppDelegate\");\n    }\n}\nIn both situations I get the following error\nTerminating app due to uncaught exception 'NSInternalInconsistencyException', reason: 'Unable to instantiate the UIApplication delegate instance. No class named AppDelegate is loaded.'. Tried that too but it can\u2019t compile the Lib-swift.h (see my previous comment above) because the header tried to import another swift library of mine using @import which isn\u2019t supported yet by buck. Note: a lot of those are from a similar issue whereby the app can't find OpenSSL given this buck file\n```\nprebuilt_cxx_library(\n  name = 'crypto',\n  preferred_linkage = 'static',\n  static_lib = 'lib/libcrypto.a',\n  header_dirs = [\n    'include/openssl',\n  ],\n  exported_headers = glob([\n    '*.h',\n  ]),\n)\nprebuilt_cxx_library(\n  name = 'ssl',\n  preferred_linkage = 'static',\n  static_lib = 'lib/libssl.a',\n  header_dirs = [\n    'include/openssl',\n  ],\n  exported_headers = glob([\n    '*.h',\n  ]),\n)\napple_library(\n  name = 'OpenSSL',\n  visibility = ['PUBLIC'],\n  exported_headers = glob([\n    '*/.h',\n  ]),\n  deps = [\n    ':crypto',\n    ':ssl'\n  ]\n)\n```\nNot sure if the two are completely separate or if a configuration setting is missing and causing both issue. . Can someone please review this?. ",
    "beefon": "Currently there is no clean documentation about Swift support in Buck. It supports it up to some degree and I personally don't know what is that degree (e.g. does it support Swift 4/4.1/4.2?), but you can check out the unit tests as they have some clues how would you combine ObjC and Swift in a single module. The rest of the information is available in this thread. I wish it could be structured somehow on buckbuild.com. This is what we have now.. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. I've noticed go_binary does not have resources. Do you need them for tests only? Should you have \"traditional\" approach for this instead, like creating go_resources() and making go_binary/go_library/go_test possible to depend go_resource? Does it make any sense to have that?\n. ok then. I wonder what happened with builds though. Can you please rebase and retrigger CI? \n. @facebook-github-bot shipit\n. And please make sure CI builds are all green.\n. Now it is possible to specify these. Please refer to the updated docs, there are 2 new fields: app_icon and launch_image.\nhttps://buckbuild.com/rule/apple_asset_catalog.html\n. Nice! Thanks a lot for implementing this! \n. One last bit: do you think it is possible to add a test into AppleTestIntegrationTest.java so you will also cover buck test .. invocation as well? I'm interested in target that will have both ui tests and unit tests, making sure UI tests are just skipped, while unit tests still work (and passed/failed). I think successOnTestPassing may be easily copy-pasted (including test data folder) and adopted.\n. Sorry for continuous ping-pong on this PR, I just want to make sure test suite for your new feature is around. :)\n. @facebook-github-bot shipit\n. Are you going to make a PR to change this?. > I'm wondering if its ever safe to cache stripped binary output, at least on apple platforms.\nI remember I wrote this chain of deps, and it was hard to understand and remember, so let me go through the memory, and then we might see what is not working in your case.\nAs far as I remember, it used to be safe to cache any binary built in Apple platform as long as its UUID (and dSYM's one) are replaced with a predictable values. This happens in LcUuidContentsScrubber which replaces UUID with a hash of file contents I think, and then DarwinLinker provides this class as a scrubber via getScrubbers. Next, CxxLink build rule contains a file scrubbing step which post-processes the unstripped binary and overrides UUID.\nCxxStrip is SupportsInputBasedRuleKey, so it should just \"map\" the unstripped binary with \"normalized\" UUID into stripped binary with the same UUID. Then, when dSYM gets generated, it will inherit UUID from the input, which is unstripped binary (CxxLink). \nBut then, what gets copied into a bundle is a AppleDebuggableBinary rule. It requires all deps as runtime deps, which means that all deps must be materialised by the time when build finishes. In case of #dwarf-and-dsym, these deps are stripped binary (CxxStrip) and dSYM (AppleDsym, requires unstripped CxxLink as normal deps).\nAppleBundle also has all deps as runtime ones. It depends on AppleDebuggableBinary. \nSo, bundle requires these deps to be on disk: AppleDebuggableBinary, which in turn needs AppleDsym, CxxStrip. CxxStrip might be cached, it is input based rule, and CxxLink is not in a cache (but it does not really matter in your case as it is already materialised in buck-out by the linker by the time when CxxStrip is loaded from cache). Both AppleDsym and CxxStrip depend on CxxLink normally.\nThe problem that you've described: CxxLink is not being cached, but CxxStrip + AppleDsym are being cached. And you are having an issue when AppleDebuggableBinary's UUID and AppleDsym's UUID are different. Why this could happen? It could be that AppleBundle depends on a different AppleDebuggableBinary, which effectively means that there are two CxxLink rules are being invoked. \nIt could also be an issue with actually just updating an already present AppleBundle inside buck-out: AppleBundle uses cp -R to copy its binary/dSYM into a new place inside itself, and if the binary/dSYM are already in place, cp -R will silently ignore this and keep copying. Apparently it does not override the destination. I remember how it was easy to forget to add RmStep, and I can see Buck deletes an existing dSYM before copying a new one into the place, so the issue with binary and dSYM are out of sync could be related to this. Perhaps you could try and add RmStep for the binary before copying it. \nThat's my knowledge, I hope this will help you somehow, but something tells me you've knew all these details before. :) I think the right way of fixing this is not actually disabling the ability to cache the CxxStrip, this will mitigate an actual issue for you but the root won't be touched. I think cxx.skip_links actually was added because the linker outputs are way too big and it did not make sense to upload them into a remote cache, but I might be wrong. CxxStrip should \"mirror\" its CxxLink and AppleBundle should just receive a right instance of CxxStrip and AppleDsym. . >  I think it still makes sense to not cache stripped binaries and fat binaries\nFor sure you're right.. > It seems the scrubber is using the contents of the load commands up to the LC_UUID load command to generate the replacement hash value. Is this deterministic?\nI think it hashes the whole file contents:\n```java\n    map.rewind();\nHasher hasher = Hashing.sha1().newHasher();\nwhile (map.hasRemaining()) {\n  hasher.putByte(map.get());\n}\n\n```\n\nlooking at the code this eventually passes down to Files.copy(resolve(source), resolve(target), StandardCopyOption.REPLACE_EXISTING)\n\nAppleBundle uses CopyStep.forFile which delegates to cp shell command which seems to be not overriding the file if it exists.\nI'd suggest adding a RmStep for all binaries before copying them into a bundle. AppleBundle already removes dSYM before moving a new one into a bundle folder, so it could be that you're experiencing a situation when AppleBundle correctly overwrites dSYM but fails to update binary file inside bundle folder, leading to the situation when UUIDs mismatch. I mean, cache may contain a correct binary, but the buck-out state is incorrect because AppleBundle does not perform a necessary cleaning before copying a binary file.. > The execute method calls filesystem.copy.\nTotally I was wrong! Now I see it does not use cp indeed. :)\n\nMight be worth sticking with the linkers UUID as it seems more deterministic potentially?\n\nThe UUID scrubbing was added on purpose, as we've been experiencing a different UUIDs of the binary for the same linker inputs out of the box. I've tried now with a simple SPM project and if you just delete the binary, it will re-link it and keep UUID the same. It could be that Apple has made UUID generator to have persistent outputs these days, but in 2016 it was not the case at least for our internal builds that have been using Buck build artifacts.\n\nFor the builds in question the buck-out folder is always wiped at the start of the run\n\nI thought it was not on CI but on local machine. If this happens on CI then this sounds more like a rule key issue to me. \n\nPotentially this is caused by hashing the entire contents of the binary when some flags are present? \n\nI assume if it hashes the whole thin/thick binary, then it's hash should also include UUID that has been scrubbed. Theoretically this should cover all cases. And it did before, I think. Perhaps you could try and investigate why rule key is the same for the binaries with different UUIDs. There is a rulekey_diag2 script which does a lot of rule key printing magic, and perhaps its author, @plamenko, could hint how would you start using it.\nAlso, I wonder when have you started experiencing this issue? Could it be related to a recent Apple toolchain/Xcode updates? Could it be that something additional needs to be put into rule keys now?. Flavors usually change the behaviour, so, unless they are not being treated in a special way (e.g. stripped inside corresponding Description), they affect the output path at minimum. At maximum they may completely change the output. Thus, this is a feature. But I agree flavors are kind of messy and sometimes they produce exactly the same output.. > excluding destination / flavor where possible\nThat is the key, this requires a knowledge about any potential flavor. Buck treats some flavors internally in a special way and skips them if needed. These flavors are actually internal ones in most cases.\n\nif we would only cache based on hashes of all involved files, options(excluding destination / flavor where possible) and env variables we would have less cache misses\n\nYes, but the chance of getting a corrupted/incorrectly built binaries will also increase.. I think the better approach in your case could be to introduce two different targets with different deps, so then you can build them like buck build :main_foo and buck build :main_bar. In this case, if both targets depend on A, its cached output should be correctly reused.. > Can an user defined flavor change the action graph?\nIt depends, different codepaths either propagate the passed flavors down to the deps or not, there is no consistency. I think this is still the case, but Buck maintainers may have changed this already. You may notice there is no documentation about the flavors, so there should not be any expectation or assumption how do they work internally. This is unfortunate, but this is reality.\nI totally agree with you: this could be implemented in a better and more understandable and predictable way. I guess if you have any imagination what can be done in order to make flavors better or even remove them, please share your thoughts. When I was on a Buck team, we raised this a couple of times and there was not clear way of fixing this. It was all messy, and I think it is still like that, but again, something may have been improved over the last year or so. :)\n\nIn some libraries we have more than 10 binary options. This approach would result in more than >2^10 different variations foreach rule.\n\nThen this is definitely not a solution for you. . Please revert these changes\n. Please revert these changes\n. I think this should be renamed to FIX_UUID_TEMPLATE = \"fix-uuid.st\" as this script does not actually build anything.\n. I think you can also revert this.\n. nit: replace fix-uuid.st with FIX_UUID_TEMPLATE const\n. nit: replace build-with-buck.st with BUILD_WITH_BUCK_TEMPLATE const\n. I think its better to move \"PUBLIC\" to a constant value.\n. Maybe its better to rename this ivar. initialRequest and List types don't sound together well. Maybe something like initialRequestDeps or something like that?\n. Is it necessary to generalise the type of exception? Or some callable method throws Exception?\n. Also, this method looks quite big. Maybe splitting it to smaller ones can help a bit.\n. You can reuse const for PUBLIC here then.\n. Can you revert this change to make PR a bit lighter please?\n. i is used outside for loop, so it's better to name it accordingly. Like indexOfShellPassThroughArgListSeparator or how ever you'd call this special argument.\n. Should you let AppleTest decide if it can run UI tests or not? There is a useXctest boolean flag. I wonder, if it is set to true, can it invoke ui tests using xctest?\n. There is TargetNode.castArg() method that is usually used to cast the arg, and it returns Optional.absent() if cast is not possible. Should it help you here?\n. Hm, I don't think we should add such kind of flag to TestRule, I think it would be better to just not instantiate TestRule at all if we don't want to run it.\n. I think class name should be FooXCUITest here.\n. Currently there are no tests here. And Buck prints out NOTESTS. Which is right-ish. I think what you want is to have some tests here, and then test that Buck actually skips them and still outputs NOTESTS for this file.\n. ",
    "mikekap": "Sounds great - I just remember blaze run //:test-target from the original :X\n. I addressed all comments but the test main generator pseudo-rule. Would it just be easier to switch to a generator per rule for now and leave a TODO to fix it at some point?\n. Addressed all of the above, sans the symlink tree.\n. Seems I managed to make it work, but I don't know why. @shs96c do you have any context re: why we manually add direct dependencies to the collect request on passed in artifacts?\n``` patch\ndiff --git a/src/com/facebook/buck/maven/Resolver.java b/src/com/facebook/buck/maven/Resolver.java\nindex a534ede..76e5d8c 100644\n--- a/src/com/facebook/buck/maven/Resolver.java\n+++ b/src/com/facebook/buck/maven/Resolver.java\n@@ -405,28 +405,6 @@ public class Resolver {\n     for (String coord : mavenCoords) {\n       DefaultArtifact artifact = new DefaultArtifact(coord);\n       collectRequest.addDependency(new Dependency(artifact, JavaScopes.RUNTIME));\n-\n-      ArtifactDescriptorRequest descriptorRequest = new ArtifactDescriptorRequest();\n-      descriptorRequest.setArtifact(artifact);\n-      // Setting this appears to have exactly zero effect on the returned values. sigh\n-//      descriptorRequest.setRequestContext(JavaScopes.RUNTIME);\n-      descriptorRequest.setRepositories(repos);\n-      ArtifactDescriptorResult descriptorResult = repoSys.readArtifactDescriptor(\n-          session,\n-          descriptorRequest);\n-\n-      for (Dependency dependency : descriptorResult.getDependencies()) {\n-        if (isTestTime(dependency)) {\n-          continue;\n-        }\n-        collectRequest.addDependency(dependency);\n-      }\n-      for (Dependency dependency : descriptorResult.getManagedDependencies()) {\n-        if (isTestTime(dependency)) {\n-          continue;\n-        }\n-        collectRequest.addManagedDependency(dependency);\n-      }\n     }\n DependencyFilter filter = DependencyFilterUtils.classpathFilter(JavaScopes.RUNTIME);\n\n```\n. Looks like travis does indeed work with this change :)\n. Alright - should be ready I think.\n. The new version is unfortunately a package - there's multiple files. I'd have to change the way pexs are built - if you're ok with that, I can try it. (ref: https://github.com/jaraco/setuptools/tree/18.5/pkg_resources )\n. Done - I've tested with a buck.pex and it seems to work.\n. Hmm it's hard to say - is pkg_resources.zip in /path/to/repo/buck-out/tmp/buck_run.QGbq97/resources/f2342654476907498e0de7165ecdc2af81415e93/path_to_pex/src/com/facebook/buck/python/ at least? If not, is it anywhere in that pex?\n. So without more debugging info, I assumed that the .zip file was missing. I rewrote the make_pex script to pull in the pkg_resource that it's using into the result pex (it's a bit meta).\nUnfortunately this makes make_pex a bigger part of buck.pex bootstrap - it pulls in the correct pkg_resources at runtime via path inspection (i.e. the dependency isn't declared anywhere in BUCK files). Let me know if we should declare it - it would only be superficial afaict.\n. No rush. I'm a bit more confident in this version working in an arbitrary environment that the old version worked in. The downside is it's a bit more magical.\n. Seems like a bug in python for windows: you have to call close() on a temporary file for it to be readable: https://bugs.python.org/issue14243 . I tested a workaround on my windows box and it seems to work. I'll have a patch in a few minutes since I don't have enough development tools on windows :P \n. Bazel only allows it at top-level (note the \"globally unique target\"). However, this is only for defaults - any go_library can override the absolute import path via package_name. In that sense, you could implement this feature as a monkey-patch of go_library, but I figured this might be friendlier.\n. ping :)\n. Sorry I didn't mean to rush, just wanted to make sure this didn't get dropped given the pex commit/revert stuff.\n. If it'll help, I can split this up into two changes: one to add pex_inplace and the other to optimize the ~400ms interpreter lookup.\n. Particularly, zinc is almost a necessity with any size scala project. It works a bit differently than the normal compiler. It's an incremental compiler to the extent that it wants the previously compiled class files & uses a nailgun daemon itself.\nI'm not sure how to integrate that into buck yet (other than \"externally\"), but certainly some scala support is better than no scala support :)\n. Shoot sorry :( Unfortunately testing on windows isn't quite easy for me - is there a chance you guys might want to set up appveyor or similar?\nI think I've got a patch for the crash - AFAICT pex has a bug where it removes sys.prefix from sys.path on windows, so allof the stdlib becomes inaccessible.\n. Shoot sorry :( Unfortunately testing on windows isn't quite easy for me - is there a chance you guys might want to set up appveyor or similar?\nI think I've got a patch for the crash - AFAICT pex has a bug where it removes sys.prefix from sys.path on windows, so allof the stdlib becomes inaccessible.\n. Would you like to try landing this again? Pex is still a bit buggy on windows, but at this point I don't think there are regressions.\n. Would you like to try landing this again? Pex is still a bit buggy on windows, but at this point I don't think there are regressions.\n. Thanks for the work James - it was very easy to add the Scala rules. Some thoughts about what other stuff needs to happen for scala:\nScala is definitely weirder compared to Java and I haven't found a good way to let the rules express that. Particularly, Scala has a concept of macros, which is similar to Java's annotation processors, except they don't look special when you're using them. Scala macro usage look like a regular function call. This makes it very hard to actually know when you're using a macro - it's considered an implementation detail of the function you're calling.\nTo make that work for now, I've basically forced deps to propagate up scala_library targets (i.e. all deps are exported_deps). However I can't tell if that works completely correctly in the presence of abi jars. I couldn't quite grasp when the abi jars are used. It also definitely doesn't work correctly with prebuilt_jars unless you do s/deps/exported_deps/ in your BUCK file.\nSeparately in order to make Scala development sane on buck (it currently takes ~10s to compile a 10 line file), using a cached compiler is pretty much a requirement. Unfortunately that means compiling java_binary/scala_test more like python - transitively gathering the sources & throwing them at the compiler in one go. It's a pretty terrible reality of developing Scala :(.\n. Thanks for the work James - it was very easy to add the Scala rules. Some thoughts about what other stuff needs to happen for scala:\nScala is definitely weirder compared to Java and I haven't found a good way to let the rules express that. Particularly, Scala has a concept of macros, which is similar to Java's annotation processors, except they don't look special when you're using them. Scala macro usage look like a regular function call. This makes it very hard to actually know when you're using a macro - it's considered an implementation detail of the function you're calling.\nTo make that work for now, I've basically forced deps to propagate up scala_library targets (i.e. all deps are exported_deps). However I can't tell if that works completely correctly in the presence of abi jars. I couldn't quite grasp when the abi jars are used. It also definitely doesn't work correctly with prebuilt_jars unless you do s/deps/exported_deps/ in your BUCK file.\nSeparately in order to make Scala development sane on buck (it currently takes ~10s to compile a 10 line file), using a cached compiler is pretty much a requirement. Unfortunately that means compiling java_binary/scala_test more like python - transitively gathering the sources & throwing them at the compiler in one go. It's a pretty terrible reality of developing Scala :(.\n. I think in some cases the decision of whether this library is provided should be in the library itself. We have several (~7) libraries that depend on hadoop-client in our repo - we could manually go through and set it as provided_deps on each one, but it seemed more logical to put that decision in the library itself, since nobody should ever makes a fat jar with hadoop-client in it (that's just not how hadoop works).\nThis is sort of mirroring the sbt \"provided\" scope; my goal is to make the maven resolver use this to support \"provided\" deps.\n. Hmm are you sure that works? From reading the code, I don't think provided deps propagate, while exported deps do. Assuming lib1 -> hadoop-client -> hadoop-client-private, buck will rewrite the graph to have lib1 -> hadoop-client-private directly, but wouldn't put it in as a provided dep, so it would end up in the jar.\n. Ping\n. It definitely does, but if you also want to use said output as a resource (e.g. to execute at runtime), it becomes a little annoying (i.e. you have to have the target that you include as a resource & the target that you run be two separate X & X_run or something like that).\n. Hmm I'll try tomorrow, but from a glance, it looks like it would include the bootstrap .sh script as a resource, but not the actual main script.\n. Confirmed; here's what I tried:\n``` python\ngenrule(\n    name='bin-rule',\n    cmd='echo \"echo hi\" > $OUT && chmod +x $OUT',\n    out='bin.sh',\n)\nsh_binary(\n    name='bin',\n    main=':bin-rule',\n)\npython_library(\n    name='res',\n    resources=[':bin'],\n)\npython_binary(\n    name='test',\n    main_module='json.tool',\n    deps=[':res'],\n)\n```\n$ buck build test && unzip buck-out/gen/test.pex\n...\n  inflating: PEX-INFO\n  inflating: __main__.py\n  inflating: __main__.pyc\n  inflating: bin\n$ cat bin\n...\nBUCK_PROJECT_ROOT=$BUCK_TMP_ROOT \"$BUCK_TMP_ROOT/$SCRIPT_TO_RUN\" \"$@\"\nSo the actual script wasn't included in the pex.\n. Ping :)\n. Now with docs\n. That path is definitely weird. I'm especially surprised about the newline at the end - are you sure it's not a wrapped line? There's an explicit trim around go env GOTOOLDIR.\nCould you paste the output of go env (and maybe go env GOTOOLDIR) here? I'm really failing to see how $CWD got prepended to the path.\n. That path is definitely weird. I'm especially surprised about the newline at the end - are you sure it's not a wrapped line? There's an explicit trim around go env GOTOOLDIR.\nCould you paste the output of go env (and maybe go env GOTOOLDIR) here? I'm really failing to see how $CWD got prepended to the path.\n. Ah I see; seems I forgot to say EXPECTING_STD_OUT when running go env GOTOOLDIR. Could you try https://github.com/mikekap/buck/tree/fix_go_discovery and let me know if it works?\n. I think that would work in most cases, but I think it's possible to have circular dependencies (i.e. Test->Util->Test) that make compiling the java_library alone impossible. Certainly most buck code I've seen is not in any danger here.\n. I think that would work in most cases, but I think it's possible to have circular dependencies (i.e. Test->Util->Test) that make compiling the java_library alone impossible. Certainly most buck code I've seen is not in any danger here.\n. Ah well that explains why there were indices everywhere else :X. Seems implicit positional .format() is 2.7-only. Fixed (& tested on 2.6).\n. Ah well that explains why there were indices everywhere else :X. Seems implicit positional .format() is 2.7-only. Fixed (& tested on 2.6).\n. I didn't actually touch any of my PRs today. You may want to check if your bot is becoming...proactive :D\n. I didn't actually touch any of my PRs today. You may want to check if your bot is becoming...proactive :D\n. @k21 is it related to the change in list output? That's really the only change that affects the external test runner. I could easily put that behind a different flag to keep the test runner working if it helps speed things along.\n. Updated the format of --list-tests to the original. The other change is fixing a bug in -r that caused test matching fail for class names due to an extra __class__ (all the test cases had the class __builtin__.type when matching).\n. FAIL //test/com/facebook/buck/parser:parser - seems to be the same as what's happening in master, so likely unrelated to this change.\n. FAIL //test/com/facebook/buck/parser:parser - seems to be the same as what's happening in master, so likely unrelated to this change.\n. This should be ready. There's a chance this will break the external test runner you guys use. I swapped what testName & testCaseName mean for python tests (it was reversed).\nJust to make sure this doesn't get committed and immediately reverted, it would be nice to test that (and fix the runner if it depends on the incorrect behavior).\n. Done.\n. This idea isn't quite original: Bazel had it first https://github.com/bazelbuild/bazel/blob/master/tools/build_rules/go/def.bzl#L199 , although Bazel implemented it for all go_library targets (rather than just go_test), which doesn't quite make sense to me.\n. This idea isn't quite original: Bazel had it first https://github.com/bazelbuild/bazel/blob/master/tools/build_rules/go/def.bzl#L199 , although Bazel implemented it for all go_library targets (rather than just go_test), which doesn't quite make sense to me.\n. My thoughts generally are to mirror bazel's go support, as described in https://docs.google.com/document/d/1_fNIFC-2gLETPBXWipNDaZEi1NCKDJRBqGN7lF0Eo7k/view . That is, if you're using Go, you probably shouldn't actually be writing BUCK files by hand.\nThat doesn't mean generated BUCK files should be cluttered, hence this change. It mostly lives to remove duplication between the go_library & go_test rules for the same package.\nIn terms of the frontend for it - I'm a little skeptical of macros. My mental model of macros is straightforward substitution (e.g. linker flags the linker command line). In this case the value of package_name would affect srcs & deps, which seems a bit strange. The internal test pattern is actually more common in go than the external test pattern (i.e. different package name in the tests), so I think making it not-too-special-looking would be nice.\nHaving said that, I'm not too attached to any particular approach, especially given you can already achieve this with some duplication. If this sets a bad precedent within Buck that you'd rather avoid, I'm ok with just dropping this change.\n. My thoughts generally are to mirror bazel's go support, as described in https://docs.google.com/document/d/1_fNIFC-2gLETPBXWipNDaZEi1NCKDJRBqGN7lF0Eo7k/view . That is, if you're using Go, you probably shouldn't actually be writing BUCK files by hand.\nThat doesn't mean generated BUCK files should be cluttered, hence this change. It mostly lives to remove duplication between the go_library & go_test rules for the same package.\nIn terms of the frontend for it - I'm a little skeptical of macros. My mental model of macros is straightforward substitution (e.g. linker flags the linker command line). In this case the value of package_name would affect srcs & deps, which seems a bit strange. The internal test pattern is actually more common in go than the external test pattern (i.e. different package name in the tests), so I think making it not-too-special-looking would be nice.\nHaving said that, I'm not too attached to any particular approach, especially given you can already achieve this with some duplication. If this sets a bad precedent within Buck that you'd rather avoid, I'm ok with just dropping this change.\n. @Coneko Do you mean something like:\npy\nif test_target.library:\n    assert test_target in library_target.tests\nor\npy\nfor test in library_target.tests:\n    assert test.library == library_target\n?\nWe can do the former, but the latter wouldn't work - you can have \"external\" tests that use a different package name and only exercise the public interface (the current go_test defaults to creating that kind of test by inferring package_name as path + \"_test\").\n. Yea you really shouldn't be creating internal tests for different packages. I'd love to limit library to targets in the same file, but maybe that's too restrictive. I'll implement the assert.\n. Hmm I don't believe that currently works (you can't depend on a go_binary from a go_test). It probably should though, but perhaps via special casing - I don't think there's a good reason to support go_library depending on go_binary generically.\nTo answer your question, we could use library or create a new property. Running tests that are part of the main package is a bit weird since I'm not sure how to distinguish which main function to use. This probably needs some more go build reverse engineering :(\n. Seems the testrunner test is still angry: //test/com/facebook/buck/testrunner:testrunner failed with exit code 137\n. Seems the testrunner test is still angry: //test/com/facebook/buck/testrunner:testrunner failed with exit code 137\n. small note: the hardcoded pkg_resources name in the test is required due to https://github.com/pantsbuild/pex/issues/210 .\n. Ping\n. Ping\n. ping\n. ping\n. I could add a different Linker.LinkType.RELOCATABLE_SHARED instead. Would that be preferable?\n. @Coneko @andrewjcg any word on what's the path forward here? Would you guys prefer to keep this out of the mainline tree?\n. @Coneko @andrewjcg any word on what's the path forward here? Would you guys prefer to keep this out of the mainline tree?\n. Travis just doesn't like me: //test/com/facebook/buck/testrunner:testrunner failed with exit code 137\n. The metadata approach seems to just remove the need for noop build rules that propagate information. That seems pretty good to me - I can use it for go_test(...library=...) propagation as well.\nIf I have multiple types of metadata would the class type be the right way to switch on what to return, or are flavors the preferred route?\n. Done, I think? Let me know if this is what you had in mind.\n. re: requireMetadata - it's pretty solid. Here's some of my thoughts:\n- it's a bit of a shame that there's no way to really \"cache\" work between createBuildRule and createMetadata without round-tripping through the metadata. e.g. the GoTestDescription needs the package name GoLibraryDescription would have been compiled with to copy it over to the test (in case library= is specified). I currently just duplicated the ~ 1 line of logic.\n- Optional isn't very useful in this case. It feels more of a programming error when you ask for metadata that the description can't provide. IMO that could easily be @Nullable and an exception in requireMetadata.\n- metadataClass is a bit clunky - it's supposed to help with type safety, but since you need to use metadataClass.cast everywhere, it doesn't help much. I ran into a runtime error when I forgot to call .build() in one of the return sites - easy to fix, annoying that it can happen.\n- In general I think there's a problem between how \"macro\"-like descriptions interact (or perhaps there aren't easy enough helpers). That is, I was looking into adding Go-thrift generation support. This wasn't terribly difficult until I realized ThriftLibraryDescription now needs to support createMetadata just the same, which it would propagate to the language-specific enhancers. It's a bit weird how this is a lot easier to do with macros and rule suffixes (e.g. %s__go_compile).\n. re: requireMetadata - it's pretty solid. Here's some of my thoughts:\n- it's a bit of a shame that there's no way to really \"cache\" work between createBuildRule and createMetadata without round-tripping through the metadata. e.g. the GoTestDescription needs the package name GoLibraryDescription would have been compiled with to copy it over to the test (in case library= is specified). I currently just duplicated the ~ 1 line of logic.\n- Optional isn't very useful in this case. It feels more of a programming error when you ask for metadata that the description can't provide. IMO that could easily be @Nullable and an exception in requireMetadata.\n- metadataClass is a bit clunky - it's supposed to help with type safety, but since you need to use metadataClass.cast everywhere, it doesn't help much. I ran into a runtime error when I forgot to call .build() in one of the return sites - easy to fix, annoying that it can happen.\n- In general I think there's a problem between how \"macro\"-like descriptions interact (or perhaps there aren't easy enough helpers). That is, I was looking into adding Go-thrift generation support. This wasn't terribly difficult until I realized ThriftLibraryDescription now needs to support createMetadata just the same, which it would propagate to the language-specific enhancers. It's a bit weird how this is a lot easier to do with macros and rule suffixes (e.g. %s__go_compile).\n. When I say \"macro\"-like descriptions, it's generally any rule descriptions that uses other descriptions to create it's output. e.g. thrift_library#lang can be \"expanded\" as:\n- genrule(cmd='$(thrift_compiler) --gen lang...')\n- lang_rule(srcs=[':compiler_output']).\nAs someone writing ThriftLibraryDescription, let's say I wanted to implement it exactly like that: using GenruleDescription and $(Lang)LibraryDescription. If you do that, you have to delegate createBuildRule/createMetadata/findDepsForTargetFromConstructorArgs to the proper class based on flavor. Compare it to writing these as macros in python: you don't have to do much other than list a few dynamic srcs entries. It would be nice if that was taken care of for you somehow - either via utilities or an ability to add TargetNodes with different descriptions to the graph.\nFor reference, there's a high chance I'm going to run into this problem in a worse way with the go_test rule. go_test is essentially a sequence of 4 rules:\n- go_compile(name='test_lib', srcs=srcs)\n- go_binary(name='test_main_gen', srcs=['testmaingen.go'])\n- genrule(name='test_main', cmd='$(test_main_gen) --out $OUT $SRCS', srcs=srcs)\n- go_binary(name='test', srcs=[':test_main'], deps=[':test_lib'])\nWhich expands even further since go_binary is a GoCompile + link step. If I wanted to expand go_library to support linking with cxx rules (the go linker can generate .a & .so files), I'm betting I'll run into some annoying flavoring problems when fixing up go_test.\nA little more generally, it would be nice if descriptions weren't ever called again for the same target listed in the BUCK file - similar to the way macros work. That is, if thrift_library(name='hi'), appears as a dep :hi#go in go_library, then createBuildRule doesn't need to be invoked again for :hi#go,linux_amd64,library. I think the reentry becomes necessary because  createBuildRule gets called too late for deps - BuildRuleParams already resolves targets to rules by that point. Maybe the right answer is to add a hook between findDepsForTargetFromConstructorArgs and createBuildRule that would allow propagating/adding the flavors from go_binary to go_library before the deps are constructed? It might make it a lot easier to follow the code of how symlink trees, flag sets, etc. get created. Although this likely won't work with heterogenous deps either :X\nThis is mostly a minor point though, since few rules actually need the full dynamism. You likely shouldn't be using GenruleDescription to implement ThriftLibraryDescription :)\n. When I say \"macro\"-like descriptions, it's generally any rule descriptions that uses other descriptions to create it's output. e.g. thrift_library#lang can be \"expanded\" as:\n- genrule(cmd='$(thrift_compiler) --gen lang...')\n- lang_rule(srcs=[':compiler_output']).\nAs someone writing ThriftLibraryDescription, let's say I wanted to implement it exactly like that: using GenruleDescription and $(Lang)LibraryDescription. If you do that, you have to delegate createBuildRule/createMetadata/findDepsForTargetFromConstructorArgs to the proper class based on flavor. Compare it to writing these as macros in python: you don't have to do much other than list a few dynamic srcs entries. It would be nice if that was taken care of for you somehow - either via utilities or an ability to add TargetNodes with different descriptions to the graph.\nFor reference, there's a high chance I'm going to run into this problem in a worse way with the go_test rule. go_test is essentially a sequence of 4 rules:\n- go_compile(name='test_lib', srcs=srcs)\n- go_binary(name='test_main_gen', srcs=['testmaingen.go'])\n- genrule(name='test_main', cmd='$(test_main_gen) --out $OUT $SRCS', srcs=srcs)\n- go_binary(name='test', srcs=[':test_main'], deps=[':test_lib'])\nWhich expands even further since go_binary is a GoCompile + link step. If I wanted to expand go_library to support linking with cxx rules (the go linker can generate .a & .so files), I'm betting I'll run into some annoying flavoring problems when fixing up go_test.\nA little more generally, it would be nice if descriptions weren't ever called again for the same target listed in the BUCK file - similar to the way macros work. That is, if thrift_library(name='hi'), appears as a dep :hi#go in go_library, then createBuildRule doesn't need to be invoked again for :hi#go,linux_amd64,library. I think the reentry becomes necessary because  createBuildRule gets called too late for deps - BuildRuleParams already resolves targets to rules by that point. Maybe the right answer is to add a hook between findDepsForTargetFromConstructorArgs and createBuildRule that would allow propagating/adding the flavors from go_binary to go_library before the deps are constructed? It might make it a lot easier to follow the code of how symlink trees, flag sets, etc. get created. Although this likely won't work with heterogenous deps either :X\nThis is mostly a minor point though, since few rules actually need the full dynamism. You likely shouldn't be using GenruleDescription to implement ThriftLibraryDescription :)\n. Ah that makes sense. If BuildRuleParams doesn't create dependencies eagerly a lot of the weirdness just goes away. I'll look forward to seeing it :)\nAs for metadataClass - although it's a bit different, I think the easiest way to get rid of it is to only allow one type of metadata supplier per rule. There's a lot to lose by doing that though - caching being the biggest. As it is now, you're effectively implementing typeless \"get attribute\" which is difficult to formalize in a type system. Bazel does this via effectively duck typing, so this isn't too far off.\n. Ah that makes sense. If BuildRuleParams doesn't create dependencies eagerly a lot of the weirdness just goes away. I'll look forward to seeing it :)\nAs for metadataClass - although it's a bit different, I think the easiest way to get rid of it is to only allow one type of metadata supplier per rule. There's a lot to lose by doing that though - caching being the biggest. As it is now, you're effectively implementing typeless \"get attribute\" which is difficult to formalize in a type system. Bazel does this via effectively duck typing, so this isn't too far off.\n. There was a lint error in there; might want to re-import \ud83d\ude2c. Sorry.\n. There was a lint error in there; might want to re-import \ud83d\ude2c. Sorry.\n. I'm in between jobs until next week, so I have a lot of free time...\n. Ping\n. Ping\n. This PR is approaching 2.5 months now. Is there any chance of this getting committed? All it does is introduce pex tool flags & change the python version fetching implementation. I can probably rip out the latter too if that's the issue, though it's more correct since it distinguishes interpreter types (PyPy/Jython/CPython).\n. No worries; I was more wondering whether there was something off with the change. Thanks for pushing it through \ud83d\udc4d \n. Go builds generally don't need the sub-package parallelism. Go packages are a single shared private namespace: people generally don't throw too much stuff in a single package. Most public go packages have ~2-3 .s files maximum and generally less than 20 .go files. I realize that parallelism is easy to achieve here, but I don't think there's a need for it. If we wanted sub-package parallelism, it would make a lot more sense to target .go files themselves - I think you can compile a single .go file to a single .o file, but I don't know if there's a performance improvement there.\n. Go builds generally don't need the sub-package parallelism. Go packages are a single shared private namespace: people generally don't throw too much stuff in a single package. Most public go packages have ~2-3 .s files maximum and generally less than 20 .go files. I realize that parallelism is easy to achieve here, but I don't think there's a need for it. If we wanted sub-package parallelism, it would make a lot more sense to target .go files themselves - I think you can compile a single .go file to a single .o file, but I don't know if there's a performance improvement there.\n. Ping\n. Go doesn't really have any support for resources itself - i.e. resources for tests are just files in the working directory. You can't really have a relocatable go executable with resources unless you embed them in the binary via something like https://github.com/jteeuwen/go-bindata.\n. Travis is busted due to ia32-libs not working: https://github.com/travis-ci/travis-ci/issues/5707; windows is busted because some new code made it in that doesn't work on windows & some things time out on appveyor.\n. I'm going to pause working on this until #691 is closed. It's a pretty big merge conflict at this point. Also CI is busted for every PR so I can't make it green.\n. Updated and addressed comments.\n. Yep, I get notified for inline comments. Emojis are always welcome though :)\n. @Coneko I managed to repro this locally and added a fix. If you install that particular revision of java (i.e. not just the latest java7u80, but java7u45), you'll see that failure. It's not terribly easy to install it either since the installer doesn't work on the latest osx.\nThe fix is just to add the annotations to the classpath - they were indeed missing. I added the fix as a separate commit since I'm not quite sure if I'm doing that right. Either way it's definitely strange that this happens on a particular version of java.\n. @Coneko I managed to repro this locally and added a fix. If you install that particular revision of java (i.e. not just the latest java7u80, but java7u45), you'll see that failure. It's not terribly easy to install it either since the installer doesn't work on the latest osx.\nThe fix is just to add the annotations to the classpath - they were indeed missing. I added the fix as a separate commit since I'm not quite sure if I'm doing that right. Either way it's definitely strange that this happens on a particular version of java.\n. The compiler is definitely a mistake and shouldn't be there. We should remove it from the class path deps - it's only needed as a compile time dep.\nAs for the scala library itself - I don't think buck can claim to make uber jars if said jars require you to have scala installed. We could make a scala_binary that does what you're describing, but Java binaries are meant to be run via java -jar, and excluding the scala library would break that.\nYou can however mark the scala library target as provided (undocumented option on prebuilt_jar) - that might work. Just be aware you would lose the ability to use java_binary targets in genrules if you just use $(exe).\n. The compiler is definitely a mistake and shouldn't be there. We should remove it from the class path deps - it's only needed as a compile time dep.\nAs for the scala library itself - I don't think buck can claim to make uber jars if said jars require you to have scala installed. We could make a scala_binary that does what you're describing, but Java binaries are meant to be run via java -jar, and excluding the scala library would break that.\nYou can however mark the scala library target as provided (undocumented option on prebuilt_jar) - that might work. Just be aware you would lose the ability to use java_binary targets in genrules if you just use $(exe).\n. If you're interested in contributing, improving the docs around this might be awesome. :)\n. If you're interested in contributing, improving the docs around this might be awesome. :)\n. I have a proof-of-concept for this at https://github.com/mikekap/buck/tree/persistent-workers if anybody is interested.\n. Totally agree about the rule key, but I couldn't find a way to get it. If nobody else is working on this, I wouldn't mind picking this up, but I think I'd need a tip on how to pull out the rule key - it seems to currently reside deep in CachingBuildEngine. I could add something to ExecutionContext that exposes a getRuleKey - would that be the way to go?\n. LGTM. I would suggest adding a test in so this doesn't break again - there's already an egg test there (though you'd want to build a universal wheel since the tests needs to pass on py2.7 & py2.6).\n. Not sure how the FB folks feel about this, though if you don't want to have a fork of buck, I've previously implemented something similar with a DEFS-like file. Basically you replace python_library with something that sets base_module based on '.'.join(get_base_path().split('/')[1:]).\n. Why wouldn't it make sense for other tests? Perhaps their output wouldn't be quite intelligible (or even considered stable), but it does make sense to run them. Go & Python tests are already this way.\nThe goal here is to make sh_test buck run-able. Ideally that would mean teaching the run command how to run tests. I don't have the expertise to do that. While having sh_test be executable isn't great, I'm really doubting anyone would ever use that. Making sh_test runnable for debugging purposes however, is extremely useful for debugging hangs and the like.\nMaking an sh_binary from an sh_test isn't always possible. It's not currently possible to have runtime deps for sh_binary (seems like a bug in resources handling), and moreover the values of some macros (e.g. classpath, location) should never be written to an artifact (they contain absolute paths and hence don't cache well). This makes an equivalent sh_binary for an sh_test with args & env containing macros impossible.\n. As a workaround, you can use NO_BUCKD=1 buck run ... (though it's a bit slower).\n. As a workaround, you can use NO_BUCKD=1 buck run ... (though it's a bit slower).\n. https://bugs.python.org/issue4710 :'( Updated with a custom unzipper.\n. https://bugs.python.org/issue4710 :'( Updated with a custom unzipper.\n. ping\n. Ah no problem. Feel free to lmk about those cases - I'm more than happy to fix them myself (I just don't normally test on 2.6 because that requires finding a docker container).\n. Well this is \ud83d\ude2d worthy:\n```\n\nlen('C:\\cygwin\\data\\temp\\buck-e827d919-22bd-4490-a98a-39648d155ade\\test\\com\\facebook\\buck\\jvm\\java\\java_test_java_tmp\\junit1759102774629287037\\buck-out\\gen\\genjardir\\junit2\\org\\junit\\experimental\\theories\\PotentialAssignment$CouldNotGenerateValueException.class')\n260\n```\n\nI'll see if I can prepend \\\\?\\ and still have everything work...\n. Well this is \ud83d\ude2d worthy:\n```\n\nlen('C:\\cygwin\\data\\temp\\buck-e827d919-22bd-4490-a98a-39648d155ade\\test\\com\\facebook\\buck\\jvm\\java\\java_test_java_tmp\\junit1759102774629287037\\buck-out\\gen\\genjardir\\junit2\\org\\junit\\experimental\\theories\\PotentialAssignment$CouldNotGenerateValueException.class')\n260\n```\n\nI'll see if I can prepend \\\\?\\ and still have everything work...\n. ping\n. ping\n. Fixed - sorry about that. Turns out pyenv doesn't create a shim for python2 which is what buck prefers over python.\n. Fixed - sorry about that. Turns out pyenv doesn't create a shim for python2 which is what buck prefers over python.\n. The go tests don't currently work on windows - I think the change that removed them from the blacklist was erroneous: https://github.com/facebook/buck/commit/5fa1d7be1f5d6ee4626af5ab7f3ae8c1e71eb4ce . They might pass with assumption violations if you don't have go installed though.\n. The go tests don't currently work on windows - I think the change that removed them from the blacklist was erroneous: https://github.com/facebook/buck/commit/5fa1d7be1f5d6ee4626af5ab7f3ae8c1e71eb4ce . They might pass with assumption violations if you don't have go installed though.\n. ping\n. @dsyang If you'd like, it would be pretty easy to add the kotlin library as an implicit target. Scala does that already - you would need to mimic https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/scala/ScalaLibraryDescription.java#L82 & https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/scala/ScalaLibraryDescription.java#L144 for kotlin. Otherwise, LGTM.\nIn terms of (internal) API, the buck JVM rules feel a bit clunky, but that's not the fault of this CR. Particularly, DefaultJavaLibrary is a behemoth that has a mix of java specific (e.g. SuggestBuildRules) and non-java-specific code & 18 constructor parameters. I think the best refactoring there might be to make it less graph-like - i.e. stop doing transitive closures in the rule itself and defer those to the descriptions. The hope is to make DefaultJavaLibrary really dumb - it should really just shell out to javac/scalac/kotlinc/etc. But that change that's outside the scope of this PR.\n. I think this is a bad behavior with buck run in general - stdin isn't sent to the process. Running the output directly wouldn't have this behavior.\nAlso note that for that simple case, you could use sh_binary.\n. I think this is a bad behavior with buck run in general - stdin isn't sent to the process. Running the output directly wouldn't have this behavior.\nAlso note that for that simple case, you could use sh_binary.\n. If that is indeed the commit responsible, you may be able to fix it by setting java.track_class_usage=false, e.g.\nbuck test --config java.track_class_usage=false\nor putting it into .buckconfig.\n. Sounds like a great approach. In case you haven't seen it, buck has a maven importer already that can import pom.xml files (though probably not in a 100% foolproof way). You can run it via buck run maven-importer in the buck repo. The source code is at https://github.com/facebook/buck/blob/master/src/com/facebook/buck/maven/Resolver.java . You may want to mention how far off that is from what you'd like to see.\n. Exactly that.\n. Yes. This does not attempt to fix the flaky test problem generally - that problem already exists with Buck test result caching. What this attempts to do is give the user the chance to re run failing tests without rerunning the whole test suite. It's particularly useful in speeding up flaky CI when there are a lot of tests and only one fails.\n. It doesn't do that unfortunately. This re-runs the entire test targets that failed. Buck only has test suite unrolling for JVM based tests and that's only for UI. We could in theory generate the proper filter to re-run only the failed test cases here. That might be for another time though.\n. @yiding @Coneko ping\n. @marcinkosiba ping\n. @marcinkosiba ping\n. @Coneko not sure about the kill -9 bit. I don't think it's possible to force terminate the worker processes, but they will definitely get their stdin closed. With some luck they will terminate too, but there's no way to be sure of it.\nIn case it's a more graceful exit, we do tear down the worker pools on daemon shutdown.\n. JsonReader throws IllegalStateException for some classes of parse errors unfortunately. In particular beginObject/endObject/beginArray/endArray all throw IllegalStateExceptions. Otherwise it can throw MalformedJsonException (a subclass of IOException) and raw IOExceptions.\n. Not sure why travis is choking on Go, but it's unrelated.. Ping. Ping. Looks like there's more failures now in travis related to timeouts.. Looks like there's more failures now in travis related to timeouts.. I believe if you want to update pex, you have to do a tiny patch that stops it from bundling setuptools: https://github.com/facebook/buck/commit/ca391dfdb3bf5914f3f5618eb054211507dc3466 . See https://github.com/facebook/buck/blob/master/third-party/py/pex/README.facebook for the full list of local patches - some of those may have been upstreamed as well.. I believe if you want to update pex, you have to do a tiny patch that stops it from bundling setuptools: https://github.com/facebook/buck/commit/ca391dfdb3bf5914f3f5618eb054211507dc3466 . See https://github.com/facebook/buck/blob/master/third-party/py/pex/README.facebook for the full list of local patches - some of those may have been upstreamed as well.. Not sure what those failures are about, but they seem unrelated.. ping. @yuriy-yarosh you mean like:\ngenrule(name='foo', out='foo_out', cmd='echo foo > $OUT')\ngenrule(name='bar', out='bar_out', cmd='echo bar > $OUT')\ngenrule(name='baz', out='baz_out', cmd='cat $(location :foo) $(location :bar) > $OUT'). So here's my issue - the test main generator does not vary per test. It felt weird to compile N test main generators when I only need one.\nI can obviously compile N, so if you'd like that, I can easily change it.\n. Unfortunately not - the file itself depends on almost all other files in that directory. Most of the other stuff in that file isn't needed for the test main generation, but they live in the same file. Bazel did something very similar, but removed some features (coverage, TestMain & test case matching). See https://github.com/bazelbuild/bazel/blob/master/tools/build_rules/go/tools/generate_test_main.go .\nI can alternatively try to not copy that code and write something buck-specific.\n. SymlinkTree used SourcePaths, which I thought were generally from source files. In this case all the entries are build rule outputs. Is it still encouraged to use SymlinkTree with BuildTargetSourcePath in that case?\n. Agreed. I can do a separate CR to add that, but since Tool is so widely used, I have a few choices:\n- Attempt to fix all the places that call getCommandPrefix to also pass-through getEnvironment. There's about 90 places where it's used, and this will likely be merge hell for you guys (or me).\n- Add the abstraction, but leave all the places that use them in a buggy state. Not great, but leaves a bunch of surprising tech debt.\n- Add environment variables as a new Tool builder that basically defers to /usr/bin/env X=Y ... to set the env variables. Easiest, but not particularly clean.\nThoughts?\n. Updated to include the timeout in the assert (go's testing does this by default)\n. See the sys.path stuff above - we're trying to ensure this imports the bundled one. I don't know how successful it is, but it's certainly as successful as it was before - pex uses pkg_resources internally.\n. pkg_resources is part of a \"pex stdlib\" (i.e. every pex made by buck will include pkg_resources) so it's an implicit dependency of every python_library. It just creates two copies of pkg_resources in the resulting python_binary which doesn't end well.\n. So this is where it gets a bit...hand-wavy. There are two explanations for each mode in which pex.py runs:\n- repo mode - In this case, pex.py changes sys.path to ensure it imports pkg_resources in third-party at runtime, so it doesn't need the dependency explicitly.\n- pex mode - in this case pex.py does NOT use the pkg_resources that exist in the repo (i.e. it does not use the dependency) - it uses whatever it was compiled with. That is, building buck.pex (say A) from a buck.pex (say B) will include pkg_resources(B) in buck.pex(A). This was already the case before, so it's not new behavior, but the intent was to clarify it.\n. One thing I'm not sure about (although I guess there's no change here) is how good the standalone pex.py isolates itself from the enclosing environment - i.e. if the local system has a pkg_resources, do we actually do enough to make sure that the correct one is loaded? I think some site-packages magic might cause pkg_resources to be imported with sys so we'd always pick up the system one.\n. file:// worked previously - see _normalize() - it just adds a file:// prefix. This just makes sure fragments are ignored when there's no scheme or the scheme is file://\n. I'm actually going to try to upstream these in https://github.com/pantsbuild/pex/pull/198\n. I hit that too, but it wasn't the subprocess call - it was the fp returned by mkstemp\n. I think the crash you saw was an extreme example of the bug - the windows box I used to test doesn't have any packages installed, so the actual thing I saw was an ImportError trying to import json. To trace it down further I set PEX_VERBOSE=5 and saw that the stdlib was being \"scrubbed\" from the path.\n. Hmm AFAICT ExecutableFinder might need some changes to respect \"in this path\", since the binaries here are called something very generic (compile and link), and should not be looked up in $PATH.\nI may just revert this change, since go tests still fail due to lack of C linker. Go technically doesn't need a C linker, but it doesn't seem like there's a way to check if the linker is \"real\" or not.\n. I can try doing this, but this takes ~ 2-3m longer per CI run. appveyor machines have jdk7 pre-installed (this line is technically a noop), but jdk8 takes a while to install.\n. Yea, I barely know how to set up the android sdk on linux, much less windows. Perhaps https://github.com/googlesamples/android-ndk/blob/master/appveyor.yml is a good place to start?\n. I was looking at that, but I think the \"fast path\" (https://github.com/facebook/buck/blob/master/src/com/facebook/buck/io/ExecutableFinder.java#L121) makes it a bit weird. If you create a file called \"compile\" in the root of your project, it will prefer that even with an explicit directory passed in. Is that intentional?\n. I have absolutely no idea why this worked. Added a trim.\n. I'll leave it until next time & open an issue once this goes in.\n. Great point - turns out that didn't work at all.\n. Hmm I think if the goal is to remove most of the pex-specific parts of the code, I think just adding something like python:pex_args and using the existing python platform flavor machinery might be the right approach. At that point I think it would make sense to convert the INPLACE style to this scheme, by e.g. having a magic path_to_pex value that uses the existing inplace code. Alternatively, an option might be to extract the existing inplace code into a java binary, although that might be a bit more of a rewrite.\n. Yep. I think this might also help windows tests since you can't use shebangs.\n. This is a private helper to the functions above. The packer doesn't accept any flags, so it doesn't have an extra flags config key. I can make it an optional, but it seemed less verbose to use an empty string.\n. It's not quite the prefix. We're iterating through prefixes, but we're checking for <prefix>/vendor - i.e. for a package in a/b/c we'll check (& overwrite - longest wins here): vendor/, a/vendor/, a/b/vendor/, a/b/c/vendor/.\n. There goes my brain. You're completely right of course.\n. These aren't real paths - this attempts to get enough ../ so that a module placed in a directory specified in args.baseModule would find the \"root\".\n. Yes this makes all shared libraries relocatable without using LD_LIBRARY_PATH. Although I think android ignores rpaths anyway.\n. This (and below) are mostly cosmetic - it's to get rid of guaranteed assumption violations. In this case the pex tool isn't used for anything but the STANDALONE package style - on any platform/installation. It's not an assumption violation - it's just an artifact of parametrized tests that the externalPexToolAffectsRuleKey[INPLACE,*] test even exists. It boils down to giving a green build rather than a yellow one.\n. Added gross casting to please javac.\nI'm just using invokeAll on an Collection<Callable<...>>. The listeningDecorator returns ListenableFutures, but the interface demands List<Future<...>>, so hence the casting.\n. I think you're misreading the code a bit. \nThe code looks like:\njava\nList<ListenableFuture<...>> results = exec.invokeAll(List<Callable<...>>);\ninvokeAll is a List<Callable<...>> => List<ListenableFuture<...>> and Futures.allAsList just transforms List<ListenableFuture<...>> => ListenableFuture<List<...>> so I could call .get. This is all just a very annoying way of doing a parallel map - I'm more than happy to change it if there's a better solution.\n. These are exclusions - the maven model doesn't have classifiers or packaging types for exclusions. Though it looks like this was indeed wrong - I changed the logic around here to better match what other places are doing (using \"\" \"\")\n. I think these are usually declared somewhere above (this \"block\" is just full of builder.register)\n. In my case I actually have some tools that need to be restarted between buck runs. i.e. they would fail to run correctly if run on the same logical namespace with two different contents at https://github.com/ladderlife/loonie. Would you mind supporting both use cases? (i.e. both a .buckconfig default + per-worker override?)\n. the processStdoutReader.endArray() can throw an IllegalStateException.\n. A ton of my tests (java & go) were failing without this :(. Not sure why CI didn't catch it.\n. There are still some guarantees there, especially if you're just using genrule (not cxx_genrule or similar). That way multiarch doesn't even come into play.\nThis can be especially useful for java-based projects without JNI that don't have multiarch to worry about at all. Non-persistent processes can cache class instances to avoid loading them into memory without having to worry about cache invalidation (though they do have to worry about undeclared dependencies).\n. Opened #960 and reverted this. Originally the callers only caught IOException and this seemed IO-ish, but it's probably more error-proof to just catch Exception in callers.\n. Ah I see, I didn't realize that. I think from the perspective of the code, it's still one build though - each time a BuildCommand gets created a new ExecutionContext gets created with it (which is what holds the ephemeral workers right now).\nThe issue I'm facing is with the Clojure compiler (though I think Scala may have a similar issue). The basic problem is that loading files - compiled or not - is really slow because it executes a lot of static-level code. A good way to \"cache\" that load step is simply to not unload the output. The current worker_tool is perfect for that. Let's say I have 2 rules with dependencies: //:a -> //:b.\n- On a clean build of //:a, a new worker_tool simply compiles //:b and keeps it in-memory. Then when //:a is compiled, we add the output of //:b to the classpath, but the classloader ignores it since the compiled class is already loaded.\n- If we change //:a's input and build //:a again, the new worker_tool will add //:b's output to the classpath to load the compiled code rather than recompiling //:b again.\n- Unfortunately this doesn't work if a new \"version\" of //:b is compiled with the same worker - there's really no way to force unload a class in java cleanly.\nWith this approach the worker_tool never ends up reloading code unless it really needs to. The downside is that targets need precise deps or the builds won't be deterministic. The way that's accomplished in the project I linked above is via an autodeps-like mechanism that reads the code to figure out the exact dependency graph.\nIs there a chance we can keep the two kinds of persistent processes coexisting (though perhaps not as a default)?\n. This seems to be a unified way to do something regardless whether a rule has been built or restored from cache (i.e. when steps aren't run). At the point initializeFromDisk is called, OnDiskBuildInfo actually has getRuleKey called on it quite a few times, so I think this is actually faster than rehashing the key via the factory. If not - seems like OnDiskBuildInfo could use a cache.\n. I believe toString prepends a cell prefix if there's a cell involved.\n. Sorry - I misread the question there. We could definitely recompute the rule key to avoid relying on the build info, but I don't know if that's much better. RuleKeyBuilderFactory will have to hash the source files anyway, which are likely build outputs and as mutable as the written rule key file. If anything, I think it would help if the data in OnDiskBuildInfo wasn't coming directly from disk but rather from the data with which the build was started.\n. Ah I see. Makes sense - thanks for the explanation!\n. Various reasons. OOM is an easy one. Another is: when canceling a build, the Thread running WorkerShellStep gets interrupted, which means various system calls start failing with InterruptedException - reading files is one of them on SOME filesystems.. ",
    "mogers": "I think I had this at some point (at least the allpaths wording fix) but maybe messed it up when splitting diffs.\n. @Coneko , feature request? :)\n. Hi @k21 , I'm sorry, I completely forgot about this. I'll try to do it in the next couple of days.\n. Hi @k21, I apologize again. I've been having too much on my plate. \nI tried to pick this again but my CLA expired and I'm having problems rebasing with the current version. \nI think this change is not important, so I will abandon this pr.\n. You're right, it's inconsistent. Should I change this in all 'buck query' calls in this page?\n. Sorry for the delay. I added the $ below. \nIt's my first upstream PR. I had some conflicts and ended up with 5 commits. Do I need to merge them into one?\n. Not sure if 'lib/9.txt' works on Windows. Could someone confirm?\n. You're right, this piece is still copy+paste, and the Lexer was imported from Bazel with minor changes.\nIIRC, unit tests are the only place TargetLiteral#toString() is used. I think this comment is a warning to keep this method consistent with the rules for quoting arguments, in order to compare the expected values properly. \nHowever, I now realize that the Lexer does not enforce all the rules mentioned in the comments (e.g. an unquoted word starting by '*' or '$' does not trigger any error).\n. ",
    "milch": "\nAlso, can you please try replacing bucksamples/cross-platform-scale-2015-demo/common in the directory entry with bucksamples/cross-platform-scale-2015-demo and try using the modified file? \n\nI had already tried that, it works regardless which working directory is used, but I agree it needs to be fixed - some tools might work, some probably won't. \n\nThe extra args key is not mentioned in the specification, but it is also not forbidden, so I don't think it makes the database invalid.\n\nIt isn't explicitly forbidden, but if you try accessing the compilation database through the clang tooling API (the one I posted in the original issue) you get a CXCompilationDatabase_CanNotLoadDatabase error. \n. The docs (and the whole API, really) are a bit weird there, I believe you can't pass a file name directly, only the dir where the file is. clang_CompilationDatabase_fromDirectory is the name of the function, you can then test to see if worked by inspecting the ErrorCode pointer you pass in. \nThe documentation also isn't clear on what to name the compilation database itself, but compile_commands.json should work. \n. Nice! Thanks for the quick solution, everyone. \n. ",
    "kastiglione": "Note that this does not work for clang 3.7, which still expects the command string and doesn't handle arguments array. EDIT: @Coneko suggested a simple post-processing script to strip the arguments key, leaving just the command key. The resulting compilation database works as expected.\n. Note that this does not work for clang 3.7, which still expects the command string and doesn't handle arguments array. EDIT: @Coneko suggested a simple post-processing script to strip the arguments key, leaving just the command key. The resulting compilation database works as expected.\n. ",
    "mindows": "Any updates on this? How would I add something like facebook sdk to my app? generated xcode project that depends on the framework would be pretty broken without the framework + headers included properly, right?\n. ",
    "aledalgrande": "Looks like there was a development here, but it was never documented. https://github.com/facebook/buck/pull/1263 adds docs.. I think this should be added in the .buckconfig file of the iOS demo folder. Also fixes:\n\nApple bundle requires an Apple platform, found 'default'. Oh cool, sorry I missed that. I'll send a quick PR.. (just accepted the terms). Thanks, I'll see if I can come up with a script to generate a BUCK file from a Podspec, as they require more or less the same info.. @ChristianOrgler blocked by some other stuff atm, I will get to it soon hopefully, but feel free to work on it.. Yeah I had to do manually. Although I tried Buck for the performance, the new iOS build system is fast enough IMHO.. Yeah I had to do manually. Although I tried Buck for the performance, the new iOS build system is fast enough IMHO.. @ryu2 do you know what is the effort to make a built-in rule for Metal? Maybe I can take a shot at it.. Thanks for the review @Coneko.. I successfully used a \"not-quite-a-framework-that's-packaged-like-a-framework\" without the preferred_linkage flag, so don't think it's required. Is that what you meant?. Yeah, I have version 2016.11.11.01 (the one from Homebrew) and your PR was merged in after that release. Maybe time for a new release?\n\nI will add a note about project generation support.. ",
    "brucetoo": "Yup,ignore buggy and difficult steps,may Buck will be more famous\n. ",
    "neeraj541": "Looking at the dependency graph of spark-core-1.3.1\nspark-core-1.3.1 -> haddop-client-2.2.0 -> hadoop-map-reduce-client-2.2.0 -> yarn-client-2.2.0 \n        |\nspark-parent-1.3.1 -> yarn-client-1.0.4 (Does not exist in maven central)\nhadoop-yarn-client-1.0.4 does not exist in maven central. While resolving the transitive dependency, aether is trying to get yarn-client-1.0.4. This is causing the  exception.\nIn the latest release of spark-core i.e. 1.5.2, they have updated the spark-parent to 1.5.2 which depends on hadoop-yarn-client 2.2.0. So spark-core 1.5.2 is working fine with our resolver.\nSo I don't think  there is any problem with resolver.\n. ",
    "hujin1860": "https://github.com/hujin1860/buck-test\nwith buck command\nshell\nbuck build //app:src\n. sorry for my mistake, I already fix the problem. Please try it again\n. sorry for my mistake, I already fix the problem. Please try it again\n. I use homebrew install buck, the version is facebook/fb/buck-2015.10.19.01\n. I use homebrew install buck, the version is facebook/fb/buck-2015.10.19.01\n. ",
    "ASCE1885": "you have to be aware that 'res/.svn' is not a file but a directory, in AaptStep.java:\njava\npublic static boolean isSilentlyIgnored(Path path) {\n    String fileName = path.getFileName().toString();\n    return \".gitkeep\".equalsIgnoreCase(fileName) ||\n        \".svn\".equalsIgnoreCase(fileName) ||\n        \".git\".equalsIgnoreCase(fileName) ||\n        \".ds_store\".equalsIgnoreCase(fileName) ||\n        MoreStrings.endsWithIgnoreCase(fileName, \".scc\") ||\n        \"cvs\".equalsIgnoreCase(fileName) ||\n        \"thumbs.db\".equalsIgnoreCase(fileName) ||\n        \"picasa.ini\".equalsIgnoreCase(fileName) ||\n        fileName.endsWith(\"~\");\n  }\nwhat it ignore is just file, and this cannot solve the problem,the code cause this exception is:\n``` java\nvoid processFileNamesInDirectory(ProjectFilesystem filesystem, Path dir)\n      throws IOException, ResourceParseException {\n    String dirname = dir.getFileName().toString();\n    int dashIndex = dirname.indexOf('-');\n    if (dashIndex != -1) {\n      dirname = dirname.substring(0, dashIndex);\n    }\nif (!RESOURCE_TYPES.containsKey(dirname)) {\n  throw new ResourceParseException(\"'%s' is not a valid resource sub-directory.\", dir);\n}\n\n...\n```\nand RESOURCE_TYPES is one of this:\n``` java\npublic static enum RType {\n    ANIM,\n    ANIMATOR,\n    ARRAY,\n    ATTR,\n    BOOL,\n    COLOR,\n    DIMEN,\n    DRAWABLE,\n    FRACTION,\n    ID,\n    INTEGER,\n    INTERPOLATOR,\n    LAYOUT,\n    MENU,\n    MIPMAP,\n    PLURALS,\n    RAW,\n    STRING,\n    STYLE,\n    STYLEABLE,\n    TRANSITION,\n    XML;\n@Override\npublic String toString() {\n  return super.toString().toLowerCase();\n}\n\n}\n```\nso maybe we should not throw an exception when meet '.svn' dir,but just ignore it and return.\n. In Android Studio, I have many modules as library, for example, I have four modules :  app, common, fund, treasure. fund depends on common, treasure depends on common. In fund module, it needs to refer a resource like drawable or string in common module, but when run\njava\nbuck install --run ...\nfund module cannot find the R.drawable.* or R.string.* in common module.\n. I have two module, common and safetykeyboardnew,\ncommon/BUCK\n``` java\nandroid_resource(\n    name = 'res_main',\n    res = 'src/main/res',\n    package = 'com.pingan.fstandard.common',\n    assets = 'src/main/assets',\n    deps = [\n        '//safetykeyboardnew:res_main',\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n)\nandroid_library(\n    name = 'src',\n    srcs = glob([\n        'src/main/java/*/.java',\n    ]),\n    manifest = 'src/main/AndroidManifest.xml',\n    annotation_processors = [\n        'com.paic.hyperion.core.hfjson.compiler.JsonAnnotationProcessor',\n    ],\n    annotation_processor_deps = [\n        '//.okbuck/annotation_processor_deps/common:all_jars',\n        '//.okbuck/annotation_processor_deps/common:all_aars',\n    ],\n    deps = [\n        ':res_main',\n        ':build_config',\n        '//safetykeyboardnew:src',\n        '//safetykeyboardnew:res_main',\n        ':native_libs',\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n)\n```\nIn safetykeyboardnew/BUCK\n``` java\nandroid_resource(\n    name = 'res_main',\n    res = 'src/main/res',\n    package = 'com.soft.safetykeyboardlibery',\n    deps = [\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n)\nandroid_library(\n    name = 'src',\n    srcs = glob([\n        'src/main/java/*/.java',\n    ]),\n    manifest = 'src/main/AndroidManifest.xml',\n    deps = [\n        ':res_main',\n        ':build_config',\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n)\n```\nand the error message is:\njava\n/common/ImageConfig.java:14: error: \u627e\u4e0d\u5230\u7b26\u53f7\n    .showImageOnFail(R.drawable.ic_launcher)    //error\nic_launcher is in safetykeyboardnew/res/drawable-xxhdpi.\n. \u627e\u4e0d\u5230\u7b26\u53f7 means cannot find symbol\n. ",
    "lucidsheep": "Unfortunately not. I tried generating a fresh project on a different machine and got a different stack:\n[2015-10-29 14:04:59.626][error][command:95ec69fd-030f-42ea-82d8-09de65141931][tid:169][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.lang.ArrayIndexOutOfBoundsException: 0\n    at sun.nio.fs.UnixPath.normalize(UnixPath.java:508)\n    at com.facebook.buck.apple.WorkspaceGenerator$1.visitFile(WorkspaceGenerator.java:232)\n    at com.facebook.buck.apple.WorkspaceGenerator$1.visitFile(WorkspaceGenerator.java:1)\n    at com.facebook.buck.apple.WorkspaceGenerator.walkNodeTree(WorkspaceGenerator.java:175)\n    at com.facebook.buck.apple.WorkspaceGenerator.writeWorkspace(WorkspaceGenerator.java:252)\n    at com.facebook.buck.apple.WorkspaceAndProjectGenerator.generateWorkspaceAndDependentProjects(WorkspaceAndProjectGenerator.java:378)\n    at com.facebook.buck.cli.ProjectCommand.generateWorkspacesForTargets(ProjectCommand.java:825)\n    at com.facebook.buck.cli.ProjectCommand.runXcodeProjectGenerator(ProjectCommand.java:710)\n    at com.facebook.buck.cli.ProjectCommand.runWithoutHelp(ProjectCommand.java:430)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:154)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:84)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:846)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:1211)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1272)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1301)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:331)\nSome notes about my setup:\n- I'm making an Xcode project with a single apple_bundle as its target\n- We don't currently have any tests in the project\n- I'm creating the project with --build-with-buck. Full command is \"buck project //:targetName --build-with-buck\"\n- The Xcode project mostly generates. I can open the .xcworkspace and it has all targets, but no schemes. I can manually create the schemes and the project will run\n- The .xcodeproj file does not have a name (it generates as \".xcodeproj\" instead of \"targetName.xcodeProj\")\n- Project generation works fine on the sample buck ios project\n- Buck version is a965937ccdadf8119a98ab766c3feb0708dc424e\nSorry, I wish I had more specifics! I will update if I make any more progress on the issue. \n. Unfortunately not. I tried generating a fresh project on a different machine and got a different stack:\n[2015-10-29 14:04:59.626][error][command:95ec69fd-030f-42ea-82d8-09de65141931][tid:169][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.lang.ArrayIndexOutOfBoundsException: 0\n    at sun.nio.fs.UnixPath.normalize(UnixPath.java:508)\n    at com.facebook.buck.apple.WorkspaceGenerator$1.visitFile(WorkspaceGenerator.java:232)\n    at com.facebook.buck.apple.WorkspaceGenerator$1.visitFile(WorkspaceGenerator.java:1)\n    at com.facebook.buck.apple.WorkspaceGenerator.walkNodeTree(WorkspaceGenerator.java:175)\n    at com.facebook.buck.apple.WorkspaceGenerator.writeWorkspace(WorkspaceGenerator.java:252)\n    at com.facebook.buck.apple.WorkspaceAndProjectGenerator.generateWorkspaceAndDependentProjects(WorkspaceAndProjectGenerator.java:378)\n    at com.facebook.buck.cli.ProjectCommand.generateWorkspacesForTargets(ProjectCommand.java:825)\n    at com.facebook.buck.cli.ProjectCommand.runXcodeProjectGenerator(ProjectCommand.java:710)\n    at com.facebook.buck.cli.ProjectCommand.runWithoutHelp(ProjectCommand.java:430)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:154)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:84)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:846)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:1211)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1272)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1301)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:331)\nSome notes about my setup:\n- I'm making an Xcode project with a single apple_bundle as its target\n- We don't currently have any tests in the project\n- I'm creating the project with --build-with-buck. Full command is \"buck project //:targetName --build-with-buck\"\n- The Xcode project mostly generates. I can open the .xcworkspace and it has all targets, but no schemes. I can manually create the schemes and the project will run\n- The .xcodeproj file does not have a name (it generates as \".xcodeproj\" instead of \"targetName.xcodeProj\")\n- Project generation works fine on the sample buck ios project\n- Buck version is a965937ccdadf8119a98ab766c3feb0708dc424e\nSorry, I wish I had more specifics! I will update if I make any more progress on the issue. \n. Unfortunately not. I tried generating a fresh project on a different machine and got a different stack:\n[2015-10-29 14:04:59.626][error][command:95ec69fd-030f-42ea-82d8-09de65141931][tid:169][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.lang.ArrayIndexOutOfBoundsException: 0\n    at sun.nio.fs.UnixPath.normalize(UnixPath.java:508)\n    at com.facebook.buck.apple.WorkspaceGenerator$1.visitFile(WorkspaceGenerator.java:232)\n    at com.facebook.buck.apple.WorkspaceGenerator$1.visitFile(WorkspaceGenerator.java:1)\n    at com.facebook.buck.apple.WorkspaceGenerator.walkNodeTree(WorkspaceGenerator.java:175)\n    at com.facebook.buck.apple.WorkspaceGenerator.writeWorkspace(WorkspaceGenerator.java:252)\n    at com.facebook.buck.apple.WorkspaceAndProjectGenerator.generateWorkspaceAndDependentProjects(WorkspaceAndProjectGenerator.java:378)\n    at com.facebook.buck.cli.ProjectCommand.generateWorkspacesForTargets(ProjectCommand.java:825)\n    at com.facebook.buck.cli.ProjectCommand.runXcodeProjectGenerator(ProjectCommand.java:710)\n    at com.facebook.buck.cli.ProjectCommand.runWithoutHelp(ProjectCommand.java:430)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:154)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:84)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:846)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:1211)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1272)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1301)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:331)\nSome notes about my setup:\n- I'm making an Xcode project with a single apple_bundle as its target\n- We don't currently have any tests in the project\n- I'm creating the project with --build-with-buck. Full command is \"buck project //:targetName --build-with-buck\"\n- The Xcode project mostly generates. I can open the .xcworkspace and it has all targets, but no schemes. I can manually create the schemes and the project will run\n- The .xcodeproj file does not have a name (it generates as \".xcodeproj\" instead of \"targetName.xcodeProj\")\n- Project generation works fine on the sample buck ios project\n- Buck version is a965937ccdadf8119a98ab766c3feb0708dc424e\nSorry, I wish I had more specifics! I will update if I make any more progress on the issue. \n. Good call! Taking the target out of the top level fixed the issue. The project generates with no problems. It would be good to note this in documentation or with an error message, like you said.\nThanks for your help!\n. Good call! Taking the target out of the top level fixed the issue. The project generates with no problems. It would be good to note this in documentation or with an error message, like you said.\nThanks for your help!\n. Added an integration test - fails on master and passes on this branch. Let me know if it looks good!\n. Thanks for the review @Coneko . I added some .expected files for the generated project. \n. Thanks for the review @Coneko . I added some .expected files for the generated project. \n. Was there a fix for this issue? If I set ndk_version = 11.2.2725575 in .buckconfig I get a different error:\nBUILD FAILED: could not extract version from NDK repository at com.facebook.buck.io.ProjectFilesystem@b8d30b1e (projectRoot=/Users/kevin/android/android-ndk-r11c, whiteListedPaths=Optional.absent(), blackListedPaths=[]: /Users/kevin/android/android-ndk-r11c/RELEASE.TXT\n. I've confirmed IntelliJ generation works, including building the project and running on a device, with the following settings:\nAndroid Studio 2.2\nAndroid API level 21\nJava 1.8\nmacOS Sierra\nbuck version 4fae534820183f5c71afbca0300ebfffb7e30b39\n. I've confirmed IntelliJ generation works, including building the project and running on a device, with the following settings:\nAndroid Studio 2.2\nAndroid API level 21\nJava 1.8\nmacOS Sierra\nbuck version 4fae534820183f5c71afbca0300ebfffb7e30b39\n. ",
    "jbrownson": "@Coneko Great to make it an error rather than a crash, but are there bigger plans to make projects at the root work too? Would you consider a pr if it's not a priority for you guys?\n. ",
    "brentleyjones": "This is still happening btw.. This is still happening btw.. This is still happening.. This is still happening.. https://bugs.swift.org/browse/SR-2660 ?. https://bugs.swift.org/browse/SR-2660 ?. The same include is missing from the related apple_test (but I assume that whatever fix for apple_library will fix that as well). Same for other dependent targets in a combined project.. The same include is missing from the related apple_test (but I assume that whatever fix for apple_library will fix that as well). Same for other dependent targets in a combined project.. When building a combined project (buck project --ide Xcode --combined-project), only one of the targets had a flavor based xcconfig (like 3 above: SwiftLibraryC#iphonesimulator-x86_64-Debug.xconfig). It didn't have a duplicate non-flavor based one though.. When building a combined project (buck project --ide Xcode --combined-project), only one of the targets had a flavor based xcconfig (like 3 above: SwiftLibraryC#iphonesimulator-x86_64-Debug.xconfig). It didn't have a duplicate non-flavor based one though.. Might be related to #1936.. Might be related to #1936.. Related, it seems that the BUNDLE_LOADER needs to be BUNDLE_LOADER = $BUILT_PRODUCTS_DIR/App.app/Binary for iOS. The more complicated form confuses Xcode because it includes //.. Related, it seems that the BUNDLE_LOADER needs to be BUNDLE_LOADER = $BUILT_PRODUCTS_DIR/App.app/Binary for iOS. The more complicated form confuses Xcode because it includes //.. @mgrebenets Sorry, I moved on from trying to get buck to work.. ",
    "adamhowardprice": "What about an optional argument to the buck project command?\n. What about an optional argument to the buck project command?\n. Sounds great!\n. Log 1\nLog 2\n. Log 1\nLog 2\n. I am pulling the same Buck binary from a shared Artifactory.\nI'm really confused about the relevance of the Watch app path in the cache key if I'm not building a watch app. Isn't that something that can be gleaned from the .buckconfig or BUCK files?\n. I am pulling the same Buck binary from a shared Artifactory.\nI'm really confused about the relevance of the Watch app path in the cache key if I'm not building a watch app. Isn't that something that can be gleaned from the .buckconfig or BUCK files?\n. Updated xctool, everything works. Thanks for the dummycheck :)\n. Updated xctool, everything works. Thanks for the dummycheck :)\n. Actually, I called it with a different version of Buck and I got this now:\npython: can't open file 'file:/Users/adamprice/Code/glue/.buckd/resources/da9e44dde29e5ee7ba5adf2b96ad886b7e83aabc/buck_server!/com/facebook/buck/apple/fix_uuid.py': [Errno 2] No such file or directory\n. Actually, I called it with a different version of Buck and I got this now:\npython: can't open file 'file:/Users/adamprice/Code/glue/.buckd/resources/da9e44dde29e5ee7ba5adf2b96ad886b7e83aabc/buck_server!/com/facebook/buck/apple/fix_uuid.py': [Errno 2] No such file or directory\n. ... I have too many versions of Buck floating around.\nUpdating to the latest fixed it.\n. ... I have too many versions of Buck floating around.\nUpdating to the latest fixed it.\n. @beefon I'm not sure how Facebook's internal bot handles situations like this. When you tell the bot \"ship it\", can you still append more commits on top? I found some bugs in the tests, which were being skipped previously, so I added a commit to fix that. Can you review that commit and import it too? Or should I just open a new pull request once this one gets merged?\n. @beefon I'm not sure how Facebook's internal bot handles situations like this. When you tell the bot \"ship it\", can you still append more commits on top? I found some bugs in the tests, which were being skipped previously, so I added a commit to fix that. Can you review that commit and import it too? Or should I just open a new pull request once this one gets merged?\n. Any update on this?\n. Done\n. Done\n. Done\n. :heavy_check_mark: \n. :heavy_check_mark: \n. ",
    "symphony2512": "I make this project like buckbonejave file in github\nAnd I see there are 3 buck file\nAnd when I build this project, I cd into root directory of project and enter \"buck build app\"\nHere is a BUCK file in same package with MainActivity.java\nandroid_library(\n    name = 'app',\n    srcs = glob(['*.java']),\n    visibility = [ 'PUBLIC' ],\n    deps = [\n        # Uncomment this if you want to include otto as a maven dependency\n        # ':otto',\n    ],\n)\nExample of maven dependencies\nmaven('com.squareup:otto:1.3.7')\nproject_config(src_target = ':app')\nAnd here is a BUCK file in apps/com/android/example\nandroid_binary(\n    name = 'app',\n    manifest = 'AndroidManifest.xml',\n    keystore = ':debug_keystore',\n    deps = [\n        '//java/com/androi/example:app',\n        '//res/com/androi/example:res',\n    ],\n)\nkeystore(\n    name = 'debug_keystore',\n    store = 'debug.keystore',\n    properties = 'debug.keystore.properties',\n)\nproject_config(src_target = ':app')\nand here is BUCK file in res/com/android/example/\nandroid_resource(\n    name = 'res',\n    res = 'res',\n    assets = 'assets',\n    package = 'com.androi.example',\n    visibility = [\n        '//apps/com.androi.example:',\n    ],\n)\nproject_config(src_target = ':res', src_roots = None)\n. Thank you so much. It works!.\n. No, it doesn't have that line.\nHere is .buckconfig\nThe files and modifications provided by Facebook are for testing and evaluation purposes only.  Facebook reserves all rights not expressly granted.\n[alias]\n  antennapod = //:antennapod\n[cache]\n  mode = dir\n  dir_max_size = 1GB\n[android]\n  target = Google Inc.:Google APIs:19\n. I attached buck-0.txt\nYou can check\n. Edited by @k21: I have moved the log to a gist at https://gist.github.com/k21/c3ede2850ba38e9a1055, it is better suited for that kind of data than Github comments. \n. Today, I will check. Maybe it is correct\n. Here is the log after i remove config outside\n[2015-10-30 15:55:49.608][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Main] Starting up (build date 1970-01-01 07:59:59 +0800, rev N/A), args: [build, antennapod]\n[2015-10-30 15:55:49.613][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Main] System properties: {java.vendor=Oracle Corporation, sun.java.launcher=SUN_STANDARD, sun.management.compiler=HotSpot 64-Bit Tiered Compilers, jnidispatch.path=/home/ai/Downloads/AntennaPod-buck/.buckd/tmp/buck_run.swioFU/jna-3112/jna1610624873081634211.tmp, os.name=Linux, sun.boot.class.path=/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rhino.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/classes, sun.desktop=gnome, java.vm.specification.vendor=Oracle Corporation, java.runtime.version=1.7.0_79-b14, buck.path_to_intellij_py=/home/ai/Downloads/buck-master/src/com/facebook/buck/command/intellij.py, buck.testrunner_classes=/home/ai/Downloads/buck-master/build/testrunner/classes, buck.logging_config_file=/home/ai/Downloads/buck-master/config/logging.properties, buck.path_to_sh_binary_template=/home/ai/Downloads/buck-master/src/com/facebook/buck/shell/sh_binary_template, user.name=ai, buck.path_to_pywatchman=/home/ai/Downloads/buck-master/third-party/py/pywatchman, buck.report_generator_jar=/home/ai/Downloads/buck-master/build/report-generator.jar, buck.path_to_python_test_main=/home/ai/Downloads/buck-master/src/com/facebook/buck/python/test_main.py, buck.git_commit=N/A, user.language=en, sun.boot.library.path=/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/amd64, java.version=1.7.0_79, user.timezone=Asia/Ho_Chi_Minh, buck.test_util_no_tests_dir=true, sun.arch.data.model=64, java.endorsed.dirs=/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/endorsed, sun.cpu.isalist=, sun.jnu.encoding=UTF-8, file.encoding.pkg=sun.io, file.separator=/, java.specification.name=Java Platform API Specification, buck.jacoco_agent_jar=/home/ai/Downloads/buck-master/third-party/java/jacoco/jacocoagent.jar, java.class.version=51.0, user.country=US, java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre, java.vm.info=mixed mode, os.version=3.13.0-32-generic, buck.path_to_static_content=/home/ai/Downloads/buck-master/webserver/static, buck.version_uid=N/A, org.eclipse.jetty.util.log.class=org.eclipse.jetty.util.log.JavaUtilLog, buck.abi_processor_classes=/home/ai/Downloads/buck-master/build/abi_processor/classes, path.separator=:, java.vm.version=24.79-b02, java.awt.printerjob=sun.print.PSPrinterJob, sun.io.unicode.encoding=UnicodeLittle, awt.toolkit=sun.awt.X11.XToolkit, buck.dx=/home/ai/Downloads/buck-master/third-party/java/dx/etc/dx, buck.git_commit_timestamp=-1, user.home=/home/ai, buck.path_to_asm_jar=/home/ai/Downloads/buck-master/third-party/java/asm/asm-debug-all-5.0.3.jar, java.specification.vendor=Oracle Corporation, buck.git_dirty=0, java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib, java.vendor.url=http://java.oracle.com/, java.vm.vendor=Oracle Corporation, java.runtime.name=OpenJDK Runtime Environment, sun.java.command=com.facebook.buck.cli.bootstrapper.ClassLoaderBootstrapper com.martiansoftware.nailgun.NGServer local:.buckd/sock 60000, java.class.path=/home/ai/Downloads/buck-master/build/bootstrapper/bootstrapper.jar, buck.buckd_dir=/home/ai/Downloads/AntennaPod-buck/.buckd, buck.path_to_pathlib_py=/home/ai/Downloads/buck-master/third-party/py/pathlib/pathlib.py, buck.buckd_launch_time_nanos=2378845179508, java.vm.specification.name=Java Virtual Machine Specification, com.martiansoftware.nailgun.NGServer.outputPath=/home/ai/Downloads/AntennaPod-buck/.buckd/tmp/buck_run.swioFU/ngserver-out, java.vm.specification.version=1.7, sun.cpu.endian=little, sun.os.patch.level=unknown, java.awt.headless=true, java.io.tmpdir=/home/ai/Downloads/AntennaPod-buck/.buckd/tmp/buck_run.swioFU, buck.android_agent_path=/home/ai/Downloads/buck-master/assets/android/agent.apk, java.vendor.url.bug=http://bugreport.sun.com/bugreport/, jna.platform.library.path=/usr/lib/x86_64-linux-gnu:/lib/x86_64-linux-gnu:/lib64:/usr/lib:/lib, os.arch=amd64, java.awt.graphicsenv=sun.awt.X11GraphicsEnvironment, buck.path_to_pex=/home/ai/Downloads/buck-master/src/com/facebook/buck/python/pex.py, java.ext.dirs=/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext, java.util.logging.config.class=com.facebook.buck.cli.bootstrapper.LogConfig, user.dir=/home/ai/Downloads/AntennaPod-buck, line.separator=\n, java.vm.name=OpenJDK 64-Bit Server VM, buck.native_exopackage_fake_path=/home/ai/Downloads/buck-master/assets/android/native-exopackage-fakes.apk, file.encoding=UTF-8, java.specification.version=1.7}\n[2015-10-30 15:55:49.833][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Config] Loaded a configuration file /home/ai/Downloads/AntennaPod-buck/.buckconfig: {alias={antennapod=//:antennapod}, cache={mode=dir, dir_max_size=1GB}, android={target=Google Inc.:Google APIs:19}}\n[2015-10-30 15:55:49.834][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Config] Adding configuration overrides: {}\n[2015-10-30 15:55:49.941][info ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.io.Watchman] Creating for: .\n[2015-10-30 15:55:49.962][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.ListeningProcessExecutor] Launching process with params ProcessExecutorParams{command=[/usr/local/bin/watchman, version], directory=Optional.absent(), environment=Optional.absent(), redirectInput=Optional.absent(), redirectOutput=Optional.absent(), redirectError=Optional.absent()}\n[2015-10-30 15:55:50.102][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.ListeningProcessExecutor] Successfully launched process com.zaxxer.nuprocess.linux.LinuxProcess@6524f39a\n[2015-10-30 15:55:50.102][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.ListeningProcessExecutor] Waiting for process com.facebook.buck.util.ListeningProcessExecutor$LaunchedProcessImpl@5cf53756 timeout 1000000000 NANOSECONDS\n[2015-10-30 15:55:50.149][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.ListeningProcessExecutor] Wait for process returned 0\n[2015-10-30 15:55:50.269][info ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.io.Watchman] Adding watchman root: /home/ai/Downloads/AntennaPod-buck/.\n[2015-10-30 15:55:50.270][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.ListeningProcessExecutor] Launching process with params ProcessExecutorParams{command=[/usr/local/bin/watchman, watch-project, /home/ai/Downloads/AntennaPod-buck/.], directory=Optional.absent(), environment=Optional.absent(), redirectInput=Optional.absent(), redirectOutput=Optional.absent(), redirectError=Optional.absent()}\n[2015-10-30 15:55:50.275][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.ListeningProcessExecutor] Successfully launched process com.zaxxer.nuprocess.linux.LinuxProcess@28a2f76f\n[2015-10-30 15:55:50.278][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.ListeningProcessExecutor] Waiting for process com.facebook.buck.util.ListeningProcessExecutor$LaunchedProcessImpl@6322ad40 timeout 1000000000 NANOSECONDS\n[2015-10-30 15:55:50.649][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.ListeningProcessExecutor] Wait for process returned 0\n[2015-10-30 15:55:50.651][info ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.io.Watchman] Took 380 ms to add root /home/ai/Downloads/AntennaPod-buck/.\n[2015-10-30 15:55:50.656][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Main] Watchman capabilities: [SUPPORTS_PROJECT_WATCH, DIRNAME, WILDMATCH_GLOB] Watch root: Optional.of(/home/ai/Downloads/AntennaPod-buck) Project prefix: Optional.absent() Glob handler config: PYTHON Final glob handler: PYTHON\n[2015-10-30 15:55:50.692][warn ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.apple.AppleConfig] Could not execute xcode-select, continuing without developer dir.\n[2015-10-30 15:55:50.775][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cxx.CxxPlatforms] Using system default C++ platform CxxPlatform{flavor=default, as=com.facebook.buck.rules.HashedFileTool@513d2d11, asflags=[], aspp=com.facebook.buck.cxx.DefaultPreprocessor@759e0c2, asppflags=[], cc=com.facebook.buck.cxx.DefaultCompiler@1db2e453, cflags=[], cxx=com.facebook.buck.cxx.DefaultCompiler@4bac1460, cxxflags=[], cpp=com.facebook.buck.cxx.DefaultPreprocessor@e6dd170, cppflags=[], cxxpp=com.facebook.buck.cxx.DefaultPreprocessor@4bd11776, cxxppflags=[], ld=com.facebook.buck.cxx.GnuLinker@c5b6add, ldflags=[], runtimeLdflags={}, strip=com.facebook.buck.rules.HashedFileTool@45c4d981, stripFlags=[], ar=com.facebook.buck.cxx.GnuArchiver@7ea3c7ef, arflags=[], lex=Optional.of(com.facebook.buck.rules.HashedFileTool@329b5cdd), lexFlags=[], yacc=Optional.of(com.facebook.buck.rules.HashedFileTool@75edcb1f), yaccFlags=[-y], sharedLibraryExtension=so, debugPathSanitizer=com.facebook.buck.cxx.DebugPathSanitizer@4eb29cb5, flagMacros={}}\n[2015-10-30 15:55:50.883][warn ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.apple.AppleConfig] Could not execute security, continuing without codesign identity.\n[2015-10-30 15:55:50.958][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Main] Starting up daemon for project root [/home/ai/Downloads/AntennaPod-buck]\n[2015-10-30 15:55:51.153][warn ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Main] Can't start web server\n[2015-10-30 15:55:51.167][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.event.listener.SuperConsoleEventBusListener] Starting render scheduler (interval 100 ms)\n[2015-10-30 15:55:51.358][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:28][com.facebook.buck.event.listener.LoggingBuildListener] CommandStarted(build, isDaemon: true)\n[2015-10-30 15:55:51.440][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.WatchmanWatcher] Writing query to Watchman: [\"query\",\"/home/ai/Downloads/AntennaPod-buck\",{\"since\":\"n:buckd1afa4861-3c64-40d6-b387-505aaed8bc9e\",\"expression\":[\"not\",[\"anyof\",[\"type\",\"d\"],[\"dirname\",\"buck-out\"],[\"dirname\",\".idea\"],[\"dirname\",\".buckd\"],[\"dirname\",\"buck-cache\"],[\"match\",\".pbxproj\"],[\"match\",\".xcscheme\"],[\"match\",\".xcworkspacedata\"]]],\"empty_on_fresh_instance\":true,\"fields\":[\"name\",\"exists\",\"new\"]}]\n[2015-10-30 15:55:51.440][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.WatchmanWatcher] Parsing JSON output from Watchman\n[2015-10-30 15:55:51.466][info ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.WatchmanWatcher] Fresh watchman instance detected. Posting overflow event to flush caches.\n[2015-10-30 15:55:51.468][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.cache.WatchedFileHashCache] Invalidating all\n[2015-10-30 15:55:51.469][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.parser.Parser] Parser invalidating entire cache on overflow.\n[2015-10-30 15:55:51.469][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.parser.Parser] Invalidating all cached data.\n[2015-10-30 15:55:51.470][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.WatchmanWatcher] Posted 0 Watchman events. Waiting for subprocess to exit...\n[2015-10-30 15:55:51.470][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.WatchmanWatcher] Watchman exited cleanly.\n[2015-10-30 15:55:51.496][info ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:28][com.facebook.buck.event.listener.LoggingBuildListener] Build started at 2015-10-30 15:55:51.438\n[2015-10-30 15:55:51.509][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.parser.Parser] Parser invalidating entire cache on default include change.\n[2015-10-30 15:55:51.510][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.parser.Parser] Invalidating all cached data.\n[2015-10-30 15:55:51.510][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.parser.Parser] Invalidating all cached data.\n[2015-10-30 15:55:51.511][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.parser.Parser] Parsing BUCK file: /home/ai/Downloads/AntennaPod-buck/BUCK\n[2015-10-30 15:55:51.517][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:28][com.facebook.buck.event.listener.LoggingBuildListener] BuckFilesParseStarted()\n[2015-10-30 15:55:51.544][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.json.ProjectBuildFileParser] Creating temporary buck.py instance...\n[2015-10-30 15:55:52.321][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.json.ProjectBuildFileParser] Created temporary buck.py instance at /home/ai/Downloads/AntennaPod-buck/.buckd/tmp/buck_run.swioFU/buck3375507578443326015.py.\n[2015-10-30 15:55:52.322][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.json.ProjectBuildFileParser] Starting buck.py command: [/usr/bin/python2, -u, /home/ai/Downloads/AntennaPod-buck/.buckd/tmp/buck_run.swioFU/buck3375507578443326015.py, --allow_empty_globs, --watchman_watch_root, /home/ai/Downloads/AntennaPod-buck, --project_root, /home/ai/Downloads/AntennaPod-buck, --build_file_name, BUCK] environment: Optional.of({DISPLAY=:0.0, UBUNTU_MENUPROXY=libappmenu.so, NAILGUN_FILESEPARATOR=/, LESSOPEN=| /usr/bin/lesspipe %s, NAILGUN_TTY_2=1, NAILGUN_TTY_1=1, PATH=/usr/lib/lightdm/lightdm:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games, NAILGUN_TTY_0=1, LOGNAME=ai, COLORTERM=gnome-terminal, MANDATORY_PATH=/usr/share/gconf/ubuntu-2d.mandatory.path, XAUTHORITY=/home/ai/.Xauthority, DESKTOP_SESSION=ubuntu-2d, SHELL=/bin/bash, DEFAULTS_PATH=/usr/share/gconf/ubuntu-2d.default.path, XDG_SESSION_PATH=/org/freedesktop/DisplayManager/Session0, GNOME_DESKTOP_SESSION_ID=this-is-deprecated, XDG_CONFIG_DIRS=/etc/xdg/xdg-ubuntu-2d:/etc/xdg, SESSION_MANAGER=local/ai-VirtualBox:@/tmp/.ICE-unix/1346,unix/ai-VirtualBox:/tmp/.ICE-unix/1346, WINDOWID=71303174, LANG=en_US.UTF-8, LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:.tar=01;31:.tgz=01;31:.arj=01;31:.taz=01;31:.lzh=01;31:.lzma=01;31:.tlz=01;31:.txz=01;31:.zip=01;31:.z=01;31:.Z=01;31:.dz=01;31:.gz=01;31:.lz=01;31:.xz=01;31:.bz2=01;31:.bz=01;31:.tbz=01;31:.tbz2=01;31:.tz=01;31:.deb=01;31:.rpm=01;31:.jar=01;31:.war=01;31:.ear=01;31:.sar=01;31:.rar=01;31:.ace=01;31:.zoo=01;31:.cpio=01;31:.7z=01;31:.rz=01;31:.jpg=01;35:.jpeg=01;35:.gif=01;35:.bmp=01;35:.pbm=01;35:.pgm=01;35:.ppm=01;35:.tga=01;35:.xbm=01;35:.xpm=01;35:.tif=01;35:.tiff=01;35:.png=01;35:.svg=01;35:.svgz=01;35:.mng=01;35:.pcx=01;35:.mov=01;35:.mpg=01;35:.mpeg=01;35:.m2v=01;35:.mkv=01;35:.webm=01;35:.ogm=01;35:.mp4=01;35:.m4v=01;35:.mp4v=01;35:.vob=01;35:.qt=01;35:.nuv=01;35:.wmv=01;35:.asf=01;35:.rm=01;35:.rmvb=01;35:.flc=01;35:.avi=01;35:.fli=01;35:.flv=01;35:.gl=01;35:.dl=01;35:.xcf=01;35:.xwd=01;35:.yuv=01;35:.cgm=01;35:.emf=01;35:.axv=01;35:.anx=01;35:.ogv=01;35:.ogx=01;35:.aac=00;36:.au=00;36:.flac=00;36:.mid=00;36:.midi=00;36:.mka=00;36:.mp3=00;36:.mpc=00;36:.ogg=00;36:.ra=00;36:.wav=00;36:.axa=00;36:.oga=00;36:.spx=00;36:*.xspf=00;36:, XDG_SEAT_PATH=/org/freedesktop/DisplayManager/Seat0, XDG_CURRENT_DESKTOP=Unity, GPG_AGENT_INFO=/tmp/keyring-1EQ3av/gpg:0:1, HOME=/home/ai, DBUS_SESSION_BUS_ADDRESS=unix:abstract=/tmp/dbus-gIIIIDWHCi,guid=006bc26dc430348324ef271900000037, XDG_SESSION_COOKIE=e7bc3edc533c0e493de520bf00000008-1446192993.693637-1123899586, XDG_DATA_DIRS=/usr/share/ubuntu-2d:/usr/share/gnome:/usr/local/share/:/usr/share/, LESSCLOSE=/usr/bin/lesspipe %s %s, NAILGUN_PATHSEPARATOR=:, GDMSESSION=ubuntu-2d, USER=ai, TERM=xterm, GNOME_KEYRING_CONTROL=/tmp/keyring-1EQ3av})\n[2015-10-30 15:55:52.325][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.json.ProjectBuildFileParser] Started process com.facebook.buck.util.ProcessExecutor$LaunchedProcessImpl@183ad8dd successfully\n[2015-10-30 15:55:52.567][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:28][com.facebook.buck.event.listener.LoggingBuildListener] ParseBuckFileStarted(/home/ai/Downloads/AntennaPod-buck/BUCK)\n[2015-10-30 15:55:52.570][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.json.ProjectBuildFileParser] Parsing output of process com.facebook.buck.util.ProcessExecutor$LaunchedProcessImpl@183ad8dd using format JSON...\n[2015-10-30 15:55:52.719][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.json.ProjectBuildFileParser] Parsed 30 rules from process\n[2015-10-30 15:55:52.721][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:28][com.facebook.buck.event.listener.LoggingBuildListener] ParseBuckFileFinished(/home/ai/Downloads/AntennaPod-buck/BUCK)\n[2015-10-30 15:55:52.780][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.json.ProjectBuildFileParser] Waiting for process com.facebook.buck.util.ProcessExecutor$LaunchedProcessImpl@183ad8dd to exit...\n[2015-10-30 15:55:52.782][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.json.ProjectBuildFileParser] Process com.facebook.buck.util.ProcessExecutor$LaunchedProcessImpl@183ad8dd exited cleanly.\n[2015-10-30 15:55:52.783][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:28][com.facebook.buck.event.listener.LoggingBuildListener] BuckFilesParseFinished()\n[2015-10-30 15:55:52.788][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.event.listener.SuperConsoleEventBusListener] Stopping render scheduler\n[2015-10-30 15:55:52.793][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Main] Failing build on exception.\ncom.facebook.buck.util.HumanReadableException: //:dslv-res: parameter 'res': no such file or directory 'submodules/dslv/library/res'\n    at com.facebook.buck.parser.Parser$CachedState.get(Parser.java:1388)\n    at com.facebook.buck.parser.Parser$CachedState.get(Parser.java:1283)\n    at com.facebook.buck.parser.Parser.getTargetNode(Parser.java:478)\n    at com.facebook.buck.parser.Parser.resolveTargetSpec(Parser.java:287)\n    at com.facebook.buck.parser.Parser.resolveTargetSpecs(Parser.java:331)\n    at com.facebook.buck.parser.Parser.buildTargetGraphForTargetNodeSpecs(Parser.java:367)\n    at com.facebook.buck.cli.BuildCommand.run(BuildCommand.java:289)\n    at com.facebook.buck.cli.BuildCommand.runWithoutHelp(BuildCommand.java:246)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:154)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:84)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:852)\n    at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:1222)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1283)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1312)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:606)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:331)\n[2015-10-30 15:55:52.804][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.event.listener.ChromeTraceBuildListener] Writing Chrome trace to buck-out/log/traces/build.2015-10-30.15-55-51.9c085fad-e31c-4868-93ff-83c87c0f3a59.trace\n[2015-10-30 15:55:52.814][warn ][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.util.Console] Build failure: //:dslv-res: parameter 'res': no such file or directory 'submodules/dslv/library/res'\n[2015-10-30 15:55:52.867][debug][command:9c085fad-e31c-4868-93ff-83c87c0f3a59][tid:15][com.facebook.buck.cli.Main] Done.\n. ",
    "petrumarius": "Hey @strangemonad,\nBuilding the plugin with buck is kinda broken at the moment. However, in $buck_src_dir/src/.../intellij/plugin there is a full IntelliJ project (you don't need to buck project that, just use the way it is) and you should be able to build the plugin with IntelliJ (eg, Build -> Prepare plugin module ...). \nRunning tests with the plugin is not yet supported, there was some work on this, but is definitely not ready.\n. ",
    "rambowding": "@sdwilsh Yes, a lot of methods, Gradle build my project successfully with multidex, Buck never build successfully. I think there's some error, but I can't find it, no log to show the error\n. @sdwilsh Yes, a lot of methods, Gradle build my project successfully with multidex, Buck never build successfully. I think there's some error, but I can't find it, no log to show the error\n. ",
    "frank-fan": "@dreiss Thanks, I just found that, it truely speed up the process.\n. @dreiss Thanks, I just found that, it truely speed up the process.\n. ",
    "ryu2": "@adamhowardprice What version of xctool are you on?  I couldn't reproduce the buck test Client --verbose 5 failure locally.\nBuck version: da9e44dde29e5ee7ba5adf2b96ad886b7e83aabc (the one in your .buckversion)\nxctool version: 2a72305de60c30dcf3ba738ab5668beb6da91b2a (current HEAD on github as of now)\nAlso, just in case: I'm on Xcode 7.1 (7B91b), the current production version.\n. Can you paste the output including the errors?\n. @facebook-github-bot shipit\n. @robbertvanginkel We should just propagate the framework flavor if it's a apple_bundle (with apple_library) or prebuilt_apple_framework.\n. We currently aren't using the #framework flavor; instead we're using apple_bundle with a apple_library + #shared rule (which does the same thing).\n. Closed in af4a756e8a982781783f8e643184b25901bf0899\n. A SourcePath can be a build rule, although I haven't tried it in the context of prebuilt frameworks. \ne.g. if you specify //foo:bar to any input that takes a SourcePath, it's shorthand for the output of that rule.. Good catch -- I'm guessing it's due to the underlying ObjC method returning a proxy object, not a NSString.\n@facebook-github-bot  shipit\n. @facebook-github-bot shipit\n. Thanks!  We're getting there.\nI'm getting a duplicate symbol error in the integration test (you can repro by copying the objc_mix_swift into a separate dir, renaming BUCK.fixture to BUCK and then buck build -v 3 //:DemoMix)\nI remember there's a flag you need to pass to the swift to make it not generate a implicit main as well (I'll try to look it up)\n```\nBUILT 1/7 JOBS 0.1s //:DemoMix#macosx-x86_64,private-headers\nBUILT 2/7 JOBS 0.0s //:DemoMix#macosx-x86_64,preprocessor-deps\nBUILT 3/7 JOBS 0.3s //:DemoMix#Swift\nmkdir -p /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/gen/DemoMix#macosx-x86_64,preprocess-main.m.mi0c561741\nrm -r -f /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#macosx-x86_64,preprocess-main.m.mi0c561741-tmp && mkdir -p /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#macosx-x86_64,preprocess-main.m.mi0c561741-tmp\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -arch x86_64 '-mmacosx-version-min=10.11' -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -arch x86_64 '-mmacosx-version-min=10.11' -I buck-out/gen/DemoMix#macosx-x86_64,private-headers.hmap -I buck-out -I buck-out/gen/DemoMix#Swift -F /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/System/Library/Frameworks -x objective-c -E -MD -MF /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#macosx-x86_64,preprocess-main.m.mi0c561741-tmp/dep.tmp main.m\nmkdir -p /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/gen/DemoMix#compile-main.m.od32f9e30,macosx-x86_64\nrm -r -f /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#compile-main.m.od32f9e30,macosx-x86_64-tmp && mkdir -p /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#compile-main.m.od32f9e30,macosx-x86_64-tmp\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -arch x86_64 '-mmacosx-version-min=10.11' -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk -arch x86_64 '-mmacosx-version-min=10.11' -Xclang -fdebug-compilation-dir -Xclang .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////// -x objective-c-cpp-output -c buck-out/gen/DemoMix#macosx-x86_64,preprocess-main.m.mi0c561741/main.m.mi -o buck-out/gen/DemoMix#compile-main.m.od32f9e30,macosx-x86_64/main.m.o\nBUILT 4/7 JOBS 0.1s //:DemoMix#macosx-x86_64,preprocess-main.m.mi0c561741\nmkdir -p /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/gen\nrm -r -f /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#binary-tmp && mkdir -p /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#binary-tmp\nprepares arg file that will be passed to the linker\nBUILT 5/7 JOBS 0.1s //:DemoMix#compile-main.m.od32f9e30,macosx-x86_64\n(cd /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift && TMPDIR=/Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#binary-tmp /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++ @/Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#binary__argfile.txt)\nduplicate symbol _main in:\n    /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/gen/DemoMix#Swift/DemoMix.o\n    /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/gen/DemoMix#compile-main.m.od32f9e30,macosx-x86_64/main.m.o\nld: 1 duplicate symbol for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nBUILD FAILED: //:DemoMix#binary failed with exit code 1:\n(cd /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift && TMPDIR=/Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#binary-tmp /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++ @/Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/bin/DemoMix#binary__argfile.txt)\nstderr: duplicate symbol _main in:\n    /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/gen/DemoMix#Swift/DemoMix.o\n    /Users/markwang/devtools/buck/test/com/facebook/buck/swift/testdata/objc_mix_swift/buck-out/gen/DemoMix#compile-main.m.od32f9e30,macosx-x86_64/main.m.o\nld: 1 duplicate symbol for architecture x86_64\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n```\nI think there's \n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Thanks!  Please rebase past 8f92c86ddc77bfac25629b3772332b0728892e31.\n\nShould we make this dylib generation optional\nCurrently, I create the dylib inside SwiftCompile, right after the process of creating .swiftmodule and object files since I think it is not necessary to use another flavor (shared_flavor) for it. Any objection?\n\nEventually, I feel it'd be a good idea to support static libraries on platforms such as OS X which can generate them.  We can do this in a follow-on diff.\n\nThe name of dylib is currently based on the swift_library target name, maybe we should use moduleName instead.\n\nIs there a case where these would or should ever differ?\n\nCurrently ignore Mach-O-Bundle, maybe we are going to need it for swift_test?\n\nCan do this as a follow-on diff.\n. This diff doesn't work properly with swift libraries that depend on ObjC libraries (see the test in test/com/facebook/buck/swift/testdata/swift_calls_objc)\n. ant test -Dtest.class=SwiftOSXBinaryIntegrationTest\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. cc: @robbertvanginkel \n. @facebook-github-bot shipit\n. We pass configs to Xcode, not info_plist_substitutions.  The latter is used by Buck builds only.\nXcode will do the substitution based on the configs dictionary.\nIn pretty much all cases though, configs are just the same value as info_plist_substitutions wrapped in an additional layer for Xcode project settings:\n{ 'Debug': <configs>, 'Release': <configs> }\n. We pass configs to Xcode, not info_plist_substitutions.  The latter is used by Buck builds only.\nXcode will do the substitution based on the configs dictionary.\nIn pretty much all cases though, configs are just the same value as info_plist_substitutions wrapped in an additional layer for Xcode project settings:\n{ 'Debug': <configs>, 'Release': <configs> }\n. lgtm -- as soon as you sign the CLA, we can merge this.  Thanks!\n. lgtm -- as soon as you sign the CLA, we can merge this.  Thanks!\n. @AquaGeek I think this is probably good for now.  Going forward, if we can see how to sign a directory with existing libraries, we can avoid multiple invocations of swift-stdlib-tool which would help build times a bit.\n. @AquaGeek I think this is probably good for now.  Going forward, if we can see how to sign a directory with existing libraries, we can avoid multiple invocations of swift-stdlib-tool which would help build times a bit.\n. @AquaGeek Not sure about the failing test, but it was happening before this revision so I wouldn't worry too much about it (some of them are flakey).\n. We should already support including the symlink trees.  Does it work if you include the bridging header in the exported_headers?\n. @fkorotkov Thanks, that sounds like the right fix.  Feel free to submit a PR.\n. @fkorotkov Does this test fail for you locally with \"The same include path maps to multiple files\"?  It is for me.\nant test -Dtest.class=SwiftOSXBinaryIntegrationTest\n. @fkorotkov Does this test fail for you locally with \"The same include path maps to multiple files\"?  It is for me.\nant test -Dtest.class=SwiftOSXBinaryIntegrationTest\n. Our internal version of Buck actually uses those dependencies for stripped-out things in the open source version (e.g. logging to our own internal endpoints).  In theory, we should refactor so that the autodeps are clean for the open-source version, but this PR as is breaks things.\n. Our internal version of Buck actually uses those dependencies for stripped-out things in the open source version (e.g. logging to our own internal endpoints).  In theory, we should refactor so that the autodeps are clean for the open-source version, but this PR as is breaks things.\n. java.lang.IllegalArgumentException: resource modulemap.st relative to com.facebook.buck.cxx.HeaderSymlinkTreeWithHeaderMap not found.\n@nguyentruongtho  This failure seems related, can you check?\n. I'm still getting a failure in CompilationDatabaseIntegrationTest under testCreateCompilationDatabaseForAppleBinaryWithDeps\n. @nguyentruongtho On my machine and the internal CI.  I'm running Xcode 8.1, how about you?  This might have something to do with it.\n. ```\n   [junit] Testsuite: com.facebook.buck.apple.CompilationDatabaseIntegrationTest\n    [junit] Tests run: 2, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 3.761 sec\n    [junit]\n    [junit] Testcase: testCreateCompilationDatabaseForAppleLibraryWithNoDeps took 2.841 sec\n    [junit]     FAILED\n    [junit]\n    [junit] Expected: <[/private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang, -fPIC, -fPIC, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', '-std=gnu11', -Wno-deprecated, -Wno-conversion, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', -I, buck-out/gen/Libraries/EXExample/EXExample#iphonesimulator-x86_64,private-headers.hmap, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64.hmap, -I, buck-out, -F, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks, -Xclang, -fdebug-compilation-dir, -Xclang, .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////, -x, objective-c, -c, -MD, -MF, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/dep.tmp, Libraries/EXExample/EXExample/EXExampleModel.m, -o, buck-out/gen/Libraries/EXExample/EXExample#compile-pic-EXExampleModel.m.o7063e286,iphonesimulator-x86_64/EXExample/EXExampleModel.m.o]>\n    [junit]      but: was <[/private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang, -fPIC, -fPIC, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', '-std=gnu11', -Wno-deprecated, -Wno-conversion, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', -I, buck-out/gen/Libraries/EXExample/EXExample#iphonesimulator-x86_64,private-headers.hmap, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64.hmap, -I, buck-out, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64, -F, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks, -Xclang, -fdebug-compilation-dir, -Xclang, .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////, -x, objective-c, -c, -MD, -MF, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/dep.tmp, Libraries/EXExample/EXExample/EXExampleModel.m, -o, buck-out/gen/Libraries/EXExample/EXExample#compile-pic-EXExampleModel.m.o7063e286,iphonesimulator-x86_64/EXExample/EXExampleModel.m.o]>\n    [junit] junit.framework.AssertionFailedError:\n    [junit] Expected: <[/private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang, -fPIC, -fPIC, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', '-std=gnu11', -Wno-deprecated, -Wno-conversion, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', -I, buck-out/gen/Libraries/EXExample/EXExample#iphonesimulator-x86_64,private-headers.hmap, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64.hmap, -I, buck-out, -F, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks, -Xclang, -fdebug-compilation-dir, -Xclang, .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////, -x, objective-c, -c, -MD, -MF, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/dep.tmp, Libraries/EXExample/EXExample/EXExampleModel.m, -o, buck-out/gen/Libraries/EXExample/EXExample#compile-pic-EXExampleModel.m.o7063e286,iphonesimulator-x86_64/EXExample/EXExampleModel.m.o]>\n    [junit]      but: was <[/private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang, -fPIC, -fPIC, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', '-std=gnu11', -Wno-deprecated, -Wno-conversion, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', -I, buck-out/gen/Libraries/EXExample/EXExample#iphonesimulator-x86_64,private-headers.hmap, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64.hmap, -I, buck-out, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64, -F, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks, -Xclang, -fdebug-compilation-dir, -Xclang, .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////, -x, objective-c, -c, -MD, -MF, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path3195316497910570628/dep.tmp, Libraries/EXExample/EXExample/EXExampleModel.m, -o, buck-out/gen/Libraries/EXExample/EXExample#compile-pic-EXExampleModel.m.o7063e286,iphonesimulator-x86_64/EXExample/EXExampleModel.m.o]>\n    [junit]     at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:18)\n    [junit]     at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:6)\n    [junit]     at com.facebook.buck.apple.CompilationDatabaseIntegrationTest.assertFlags(CompilationDatabaseIntegrationTest.java:315)\n    [junit]     at com.facebook.buck.apple.CompilationDatabaseIntegrationTest.testCreateCompilationDatabaseForAppleLibraryWithNoDeps(CompilationDatabaseIntegrationTest.java:117)\n    [junit]\n    [junit] Testcase: testCreateCompilationDatabaseForAppleBinaryWithDeps took 0.898 sec\n    [junit]     FAILED\n    [junit]\n    [junit] Expected: <[/private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', '-std=gnu11', -Wno-deprecated, -Wno-conversion, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', -I, buck-out/gen/Apps/Weather/Weather#iphonesimulator-x86_64,private-headers.hmap, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64.hmap, -I, buck-out, -F, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks, -Xclang, -fdebug-compilation-dir, -Xclang, .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////, -x, objective-c, -c, -MD, -MF, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/dep.tmp, Apps/Weather/Weather/EXViewController.m, -o, buck-out/gen/Apps/Weather/Weather#compile-EXViewController.m.ob61ea5f6,iphonesimulator-x86_64/Weather/EXViewController.m.o]>\n    [junit]      but: was <[/private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', '-std=gnu11', -Wno-deprecated, -Wno-conversion, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', -I, buck-out/gen/Apps/Weather/Weather#iphonesimulator-x86_64,private-headers.hmap, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64.hmap, -I, buck-out, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64, -F, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks, -Xclang, -fdebug-compilation-dir, -Xclang, .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////, -x, objective-c, -c, -MD, -MF, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/dep.tmp, Apps/Weather/Weather/EXViewController.m, -o, buck-out/gen/Apps/Weather/Weather#compile-EXViewController.m.ob61ea5f6,iphonesimulator-x86_64/Weather/EXViewController.m.o]>\n    [junit] junit.framework.AssertionFailedError:\n    [junit] Expected: <[/private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', '-std=gnu11', -Wno-deprecated, -Wno-conversion, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', -I, buck-out/gen/Apps/Weather/Weather#iphonesimulator-x86_64,private-headers.hmap, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64.hmap, -I, buck-out, -F, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks, -Xclang, -fdebug-compilation-dir, -Xclang, .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////, -x, objective-c, -c, -MD, -MF, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/dep.tmp, Apps/Weather/Weather/EXViewController.m, -o, buck-out/gen/Apps/Weather/Weather#compile-EXViewController.m.ob61ea5f6,iphonesimulator-x86_64/Weather/EXViewController.m.o]>\n    [junit]      but: was <[/private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', '-std=gnu11', -Wno-deprecated, -Wno-conversion, -isysroot, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk, -arch, x86_64, '-mios-simulator-version-min=8.0', -I, buck-out/gen/Apps/Weather/Weather#iphonesimulator-x86_64,private-headers.hmap, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64.hmap, -I, buck-out, -I, buck-out/gen/Libraries/EXExample/EXExample#headers,iphonesimulator-x86_64, -F, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/xcode-developer-dir/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks, -Xclang, -fdebug-compilation-dir, -Xclang, .///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////, -x, objective-c, -c, -MD, -MF, /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5735745041404018234/dep.tmp, Apps/Weather/Weather/EXViewController.m, -o, buck-out/gen/Apps/Weather/Weather#compile-EXViewController.m.ob61ea5f6,iphonesimulator-x86_64/Weather/EXViewController.m.o]>\n    [junit]     at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:18)\n    [junit]     at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:6)\n    [junit]     at com.facebook.buck.apple.CompilationDatabaseIntegrationTest.assertFlags(CompilationDatabaseIntegrationTest.java:315)\n    [junit]     at com.facebook.buck.apple.CompilationDatabaseIntegrationTest.testCreateCompilationDatabaseForAppleBinaryWithDeps(CompilationDatabaseIntegrationTest.java:204)\n    [junit]\nBUILD FAILED\n/Users/markwang/devtools/buck/build.xml:612: Test com.facebook.buck.apple.CompilationDatabaseIntegrationTest failed\n``\n. Still getting this due to thebuck-out/gen/library_with_header#default,headers` being added:\n[junit] Testsuite: com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest\n    [junit] Tests run: 6, Failures: 4, Errors: 0, Skipped: 0, Time elapsed: 16.89 sec\n    [junit]\n    [junit] Testcase: testCompilationDatabase took 6.908 sec\n    [junit]     FAILED\n    [junit] expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/test#default,headers -]Xclang -fdebug-compi...>\n    [junit] junit.framework.AssertionFailedError: expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/test#default,headers -]Xclang -fdebug-compi...>\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.assertHasEntry(CxxCompilationDatabaseIntegrationTest.java:536)\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.testCompilationDatabase(CxxCompilationDatabaseIntegrationTest.java:247)\n    [junit]\n    [junit] Testcase: binaryWithDependenciesCompilationDatabase took 1.455 sec\n    [junit]     FAILED\n    [junit] expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/library_with_header#default,headers -]Xclang -fdebug-compi...>\n    [junit] junit.framework.AssertionFailedError: expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/library_with_header#default,headers -]Xclang -fdebug-compi...>\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.assertHasEntry(CxxCompilationDatabaseIntegrationTest.java:536)\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.binaryWithDependenciesCompilationDatabase(CxxCompilationDatabaseIntegrationTest.java:122)\n    [junit]\n    [junit] Testcase: testUberCompilationDatabase took 1.266 sec\n    [junit]     FAILED\n    [junit] expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/test#default,headers -]Xclang -fdebug-compi...>\n    [junit] junit.framework.AssertionFailedError: expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/test#default,headers -]Xclang -fdebug-compi...>\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.assertHasEntry(CxxCompilationDatabaseIntegrationTest.java:536)\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.testUberCompilationDatabase(CxxCompilationDatabaseIntegrationTest.java:312)\n    [junit]\n    [junit] Testcase: compilationDatabaseFetchedFromCacheAlsoFetchesSymlinkTreeOrHeaderMap took 2.935 sec\n    [junit] Testcase: libraryCompilationDatabase took 1.436 sec\n    [junit]     FAILED\n    [junit] expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/library_with_header#default,headers -]Xclang -fdebug-compi...>\n    [junit] junit.framework.AssertionFailedError: expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/library_with_header#default,headers -]Xclang -fdebug-compi...>\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.assertHasEntry(CxxCompilationDatabaseIntegrationTest.java:536)\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.libraryCompilationDatabase(CxxCompilationDatabaseIntegrationTest.java:186)\n    [junit]\n    [junit] Testcase: compilationDatabaseWithDepsFetchedFromCacheAlsoFetchesSymlinkTreeOrHeaderMapOfDeps took 2.849 sec\n. Still getting this due to the buck-out/gen/library_with_header#default,headers being added:\n[junit] Testsuite: com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest\n    [junit] Tests run: 6, Failures: 4, Errors: 0, Skipped: 0, Time elapsed: 16.89 sec\n    [junit]\n    [junit] Testcase: testCompilationDatabase took 6.908 sec\n    [junit]     FAILED\n    [junit] expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/test#default,headers -]Xclang -fdebug-compi...>\n    [junit] junit.framework.AssertionFailedError: expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/test#default,headers -]Xclang -fdebug-compi...>\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.assertHasEntry(CxxCompilationDatabaseIntegrationTest.java:536)\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.testCompilationDatabase(CxxCompilationDatabaseIntegrationTest.java:247)\n    [junit]\n    [junit] Testcase: binaryWithDependenciesCompilationDatabase took 1.455 sec\n    [junit]     FAILED\n    [junit] expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/library_with_header#default,headers -]Xclang -fdebug-compi...>\n    [junit] junit.framework.AssertionFailedError: expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/library_with_header#default,headers -]Xclang -fdebug-compi...>\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.assertHasEntry(CxxCompilationDatabaseIntegrationTest.java:536)\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.binaryWithDependenciesCompilationDatabase(CxxCompilationDatabaseIntegrationTest.java:122)\n    [junit]\n    [junit] Testcase: testUberCompilationDatabase took 1.266 sec\n    [junit]     FAILED\n    [junit] expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/test#default,headers -]Xclang -fdebug-compi...>\n    [junit] junit.framework.AssertionFailedError: expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/test#default,headers -]Xclang -fdebug-compi...>\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.assertHasEntry(CxxCompilationDatabaseIntegrationTest.java:536)\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.testUberCompilationDatabase(CxxCompilationDatabaseIntegrationTest.java:312)\n    [junit]\n    [junit] Testcase: compilationDatabaseFetchedFromCacheAlsoFetchesSymlinkTreeOrHeaderMap took 2.935 sec\n    [junit] Testcase: libraryCompilationDatabase took 1.436 sec\n    [junit]     FAILED\n    [junit] expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/library_with_header#default,headers -]Xclang -fdebug-compi...>\n    [junit] junit.framework.AssertionFailedError: expected:<...s.hmap -I buck-out -[]Xclang -fdebug-compi...> but was:<...s.hmap -I buck-out -[I buck-out/gen/library_with_header#default,headers -]Xclang -fdebug-compi...>\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.assertHasEntry(CxxCompilationDatabaseIntegrationTest.java:536)\n    [junit]     at com.facebook.buck.cxx.CxxCompilationDatabaseIntegrationTest.libraryCompilationDatabase(CxxCompilationDatabaseIntegrationTest.java:186)\n    [junit]\n    [junit] Testcase: compilationDatabaseWithDepsFetchedFromCacheAlsoFetchesSymlinkTreeOrHeaderMapOfDeps took 2.849 sec\n. [junit] @testable import SwiftCallsComplexObjC\n    [junit]                  ^\n    [junit] swift/Foo+Greeting.swift:1:11: error: use of undeclared type 'Foo'\n    [junit] extension Foo {\n    [junit]           ^~~\n    [junit] swift/FooTest.swift:8:41: error: use of unresolved identifier 'Foo'\n    [junit]         XCTAssertEqual(\"Hello, World!\", Foo().greeting())\n    [junit]                                         ^~~\n    [junit] Swift.Bool:41:15: note: did you mean 'Bool'?\n    [junit] public struct Bool {\n    [junit]               ^\n    [junit]\n    [junit]\n    [junit] BUILD FAILED: //:SwiftCallsComplexObjC#dwarf,iphonesimulator-x86_64,mach-o-bundle,swift-compile failed with exit code 1:\nwhen I do ant test -Dtest.class=SwiftTestIOSIntegrationTest\n. Since we don't have public Mac CI yet, most of the Swift stuff still needs to be locally tested.\n. @facebook-github-bot shipit\n. https://gist.github.com/ryu2/4727f513a5064244ef2711f4656c27e5\nhas the stack trace.  It basically can't find a boost header accumulators.hpp which is a cross-cell target.\nThe issue is that perf_test_hg.py renames the repo directory temporarily, which invalidates all symlinks in header trees. Before, this test was still passing, presumably because we were using header maps for boost. For some reason this diff breaks this.\n. https://gist.github.com/ryu2/4727f513a5064244ef2711f4656c27e5\nhas the stack trace.  It basically can't find a boost header accumulators.hpp which is a cross-cell target.\nThe issue is that perf_test_hg.py renames the repo directory temporarily, which invalidates all symlinks in header trees. Before, this test was still passing, presumably because we were using header maps for boost. For some reason this diff breaks this.\n. It's an internal app, but you can try to repro it as follows with whatever app you have (not sure of the exact conditions yet needed for this error to occur):\nFrom your repo dir (e.g. repo)\nrm -rf buck-out\nbuck build -v 3 --config cache.mode=dir --config cache.dir=/tmp/buck-cache --deep <target>\nRename repo to something else, e.g. _repo\nThen from _repo\nbuck clean\nbuck build -v 3 --config cache.mode=dir --config cache.dir=/tmp/buck-cache --deep <target>\n. It's an internal app, but you can try to repro it as follows with whatever app you have (not sure of the exact conditions yet needed for this error to occur):\nFrom your repo dir (e.g. repo)\nrm -rf buck-out\nbuck build -v 3 --config cache.mode=dir --config cache.dir=/tmp/buck-cache --deep <target>\nRename repo to something else, e.g. _repo\nThen from _repo\nbuck clean\nbuck build -v 3 --config cache.mode=dir --config cache.dir=/tmp/buck-cache --deep <target>\n. Will be broken up into smaller PRs.. cc: @nguyentruongtho \n. @facebook-github-bot shipit\n. @robbertvanginkel I think that solution works for now.. @robbertvanginkel I think that solution works for now.. @robbertvanginkel  I've fixed the duplicate resources issue for now in  87eb248acecc0947d4a32244a7a73689900cf504 by not propagating the resources dependencies of any shared apple_library or cxx_library. @robbertvanginkel  I've fixed the duplicate resources issue for now in  87eb248acecc0947d4a32244a7a73689900cf504 by not propagating the resources dependencies of any shared apple_library or cxx_library. @facebook-github-bot shipit. You'll want to set the config cxx.default_platform to a iOS SDK, e.g. iphonesimulator-x86_64 or iphoneos-arm64 to get Buck to use a iOS SDKROOT.. What version of Xcode are you running?\nCan you build a iOS app normally through Xcode itself?. @facebook-github-bot shipit. It's on our radar for this half.\nInternally, we pretty much build all third-party dependencies (such as OCMock) from source if possible.  For closed-source libs, a workaround is:\n\n\nDeclare a dummy library with the headers so you can include them as needed:\ncxx_library(\n  name = 'foobar',\n  srcs = ['dummy.c'],\n  exported_headers = subdir_glob([\n    ('src', 'foobar_public/foobar.h')\n  ]),\n  visibility = ['PUBLIC'],\n)\n(You might be able to get away with a empty srcs but if not, a dummy file e.g. dummy.c will definitely work.)\n\n\nIn your apple_binary, include the real library so that it links:\nlibraries = [\n    'lib/libfoobar.a',\n  ],\nwhere you've checked in the actual libfoobar.a somewhere in your source tree.\n. @facebook-github-bot shipit. Check out prebuilt_apple_framework.  It's currently a work in progress and not documented yet, but you can look at the integration test in \n\n\ntest/com/facebook/buck/apple/testdata/prebuilt_apple_framework_static\nfor an example.\n. cc @robbertvanginkel who did the work for prebuilt_apple_framework. cc @robbertvanginkel who did the work for prebuilt_apple_framework. >  I want to know does buck work with swift?\nYes, we have basic Swift support although it's a work in progress.  If you have specific problems, please open a separate issue.. >  I want to know does buck work with swift?\nYes, we have basic Swift support although it's a work in progress.  If you have specific problems, please open a separate issue.. You need to include the SystemConfiguration framework in the frameworks section of your apple_binary.  I.e.\n```\nframeworks = [\n...\n    '$SDKROOT/System/Library/Frameworks/SystemConfiguration.framework',\n...\n  ],\n``. Thanks!  You can look atcheckCodeSigning()inAppleBundleIntegrationTest` for test examples.. Once tests are added, this should be good to merge.. Yeah, you're right -- there currently isn't a nice way to do it.  What do you mean about \"changing the rule names\"?\nYou could try defining a macro that is shared between Lib1 and Lib2 which calls apple_library and prepends a unique prefix to the rule name, so you avoid repeating the common bits.\ne.g.\n```\nIn DEFS\ndef my_apple_library(prefix, args, *kwargs):\n  apple_library(\n    name = prefix + kwargs[name],\n    kwargs)\nIn Lib1/BUCK\nmy_apple_library('Lib1')\nIn Lib2/BUCK\nmy_apple_library('Lib2')\n```\n. For iOS extensions, you actually don't want the #shared flavor.\nFor storyboards, if you include the xib in apple_resources if should compile it automatically.. Looks like AppleLibraryIntegrationTest is failing:\n[junit] Testcase: testBuildAppleLibraryUsingBridingHeaderAndSwiftDotH took 10.48 sec\n    [junit]     FAILED\n    [junit] Expected exit code 0 but was 1.\n    [junit] junit.framework.AssertionFailedError: Expected exit code 0 but was 1.\n    [junit]     at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertExitCode(ProjectWorkspace.java:785)\n    [junit]     at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertSuccess(ProjectWorkspace.java:746)\n    [junit]     at com.facebook.buck.apple.AppleLibraryIntegrationTest.testBuildAppleLibraryUsingBridingHeaderAndSwiftDotH(AppleLibraryIntegrationTest.java:702). Looks like AppleLibraryIntegrationTest is failing:\n[junit] Testcase: testBuildAppleLibraryUsingBridingHeaderAndSwiftDotH took 10.48 sec\n    [junit]     FAILED\n    [junit] Expected exit code 0 but was 1.\n    [junit] junit.framework.AssertionFailedError: Expected exit code 0 but was 1.\n    [junit]     at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertExitCode(ProjectWorkspace.java:785)\n    [junit]     at com.facebook.buck.testutil.integration.ProjectWorkspace$ProcessResult.assertSuccess(ProjectWorkspace.java:746)\n    [junit]     at com.facebook.buck.apple.AppleLibraryIntegrationTest.testBuildAppleLibraryUsingBridingHeaderAndSwiftDotH(AppleLibraryIntegrationTest.java:702). @facebook-github-bot shipit. @facebook-github-bot shipit. @facebook-github-bot shipit. @facebook-github-bot shipit. @nguyentruongtho Have you filed a radar on Apple yet?  This should really be fixed on their end rather than hardcoding these workarounds in Buck.. It looks like this is indeed a bug where Buck generates Xcode projects that copies the transitive dependencies of the app bundle including the Watch bundles unnecessarily.\nThis should not be an issue when Buck is building the app.\n. Since we build our production apps internally with Buck and only use Xcode for local development, fixing this isn't a high priority for us but feel free to submit a PR.\nYou can use this as a model: https://github.com/facebook/buck/commit/87eb248acecc0947d4a32244a7a73689900cf504\n. It might be a codesigning issue.  \nWhat does codesign -d -vvvv <path to framework in your app bundle in buck-out> give you?. It might be a codesigning issue.  \nWhat does codesign -d -vvvv <path to framework in your app bundle in buck-out> give you?. This isn't very helpful.  Please provide a full stack trace at least.. What makes you think this is a Buck issue?  Does the Buck-generated project work properly when built with Xcode?  Is this the same issue you're describing as #1209?. What makes you think this is a Buck issue?  Does the Buck-generated project work properly when built with Xcode?  Is this the same issue you're describing as #1209?. What shows up in the watchman logs during a buck run?\nhttp://facebook.github.io/watchman/docs/troubleshooting.html. Cc @bhamiltoncx who might have an idea. . @facebook-github-bot shipit. @facebook-github-bot shipit. It looks like you're using Linux javac on Windows through WSL.  This isn't supported; either use native Windows JDK or use a actual Linux system or VM.. Yes but it's a work in progress.\nhttps://buckbuild.com/setup/getting_started.html\nSent from my iPhone\nOn Mar 14, 2017, at 7:27 PM, kross notifications@github.com<mailto:notifications@github.com> wrote:\nSo....I can run buck on windows without any problem? @ryu2https://github.com/ryu2\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://github.com/facebook/buck/issues/1240#issuecomment-286622141, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AAbDbOh2eJeai3YXeUjC6tMCbIeqGV7kks5rl0xfgaJpZM4McEep.\n. //test/com/facebook/buck/swift:integration - testAppleTestToWorkWithSwift (com.facebook.buck.swift.SwiftTestIOSIntegrationTest)\nseems to be failing; you'll probably need to re-add enable-testing to the test fixture's .buckconfig.. @facebook-github-bot shipit. We should probably rethink the way we handle entitlements altogether.\nRight now, we specify them via the CODE_SIGN_ENTITLEMENTS key in info_plist_substitutions for a apple_bundle which is counterintuitive.  This was chosen at the time because it was similar to how Xcode handled things, but we should probably add entitlements as an actual arg to apple_bundle instead.\nIdeally we'd pass the entitlements arg to the apple_binary target in createBundleBuildRule() and AppleBinary would take care of adding the linker flags accordingly.\nThis way, we handle the specification the same way for simulator and device builds.. cc: @yiding @Coneko --- can you guys review?. IIRC, this was what Xcode adds automatically in its WatchOS builds, or was at the time of the original commit.  Since Apple's App Store validation is a bit of a black box, I wanted to play it safe and replicate Xcode's flags as much as possible.\n@rmaz If you've built and successfully submitted an app to Apple with this change, then sure we can land as-is.\nHowever, if you need to add those flags to the BUCK file in order for a app to pass validation, then we will have to make sure this change doesn't break releases.. @robbertvanginkel Have you done comparisons across a variety of languages?  Binary plists use UTF-16 encoding for text, and we found (at least for us) having UTF-8 encoded strings files saved overall app size.  (We don't have comments in our .strings files though.)\nPerhaps make this configurable?. We have a slack at https://buckbuild.slack.com/. Make sure the line is <= 100 chars.\n. space after (NSDictionary) cast\n. nit: remove space before \"com\n. nit: remove space before \"com\n. Do we need this for a simulator x86_64 build?\n. Please use the standard copyright header.\n. Easier to just use ImmutableSet.of() directly here for a singleton set.\n. Easier to say \nBuildTargets.getGenPath( getProjectFilesystem(), target, \"%s\")\n. buildTarget\n. nit: greatings -> greetings\n. I think that what you have is already reasonable.  Either way, you're effectively splitting based on extension.  The only difference is where.\nArchitecturally, we want to keep the parser as simple as possible and avoid putting rule-specific logic in there.\n. This seems unnecessarily complex.  Better to say\npublic static final Flavor SWIFT_FLAVOR = ImmutableFlavor.of(\"swift\")\nAlso flavors should be all lower-case.\n. Don't need .withAppendedFlavors as you already have the platform flavor in swiftCompanionTarget.\n. parentTarget.withAppendedFlavor(SWIFT_FLAVOR) is safer as it passes through any other flavors.\n. Don't need cxxPlatform anymore with the below changes.\n. The file needs to be called .buckconfig (no .fixture suffix)\n. This is better controlled via a .buckconfig parameter, as you can't mix different swift versions.\n. Here, it's perfectly fine to leave it uninitialized.\n. Not currently I believe; feel free to implement it. ;)\n. Perhaps a static method in a AppleFrameworks utility class?\n. Perhaps we can make a non-framework flavor and explicitly specify it in a rule's deps to include libraries that we want to force to be normal libs.  (Or analogously specify the framework flavor to force to be frameworks)\n. Since these flags will only be added when a binary is included in a framework bundle, I'm thinking we just do it here, and use the bundle's platformName to choose.\n. pathResolver.getAbsolutePath(path).getFileName().toString() is safer\n. MorePaths.getFileExtension(resolver.getAbsolutePath(src.getSourcePath())) is safer\n. We still need this line; this applies to the dependencies and not the bundle itself.\n. Please also add install_name_tool to FakeAppleRuleDescriptions so the tests can work.\n. @robbertvanginkel Just out of curiousity, I'm wondering if @import works, since you already have the .modulemap file.  That would be a good thing to support if it doesn't already.\n. This doesn't seem to be needed.\n. Please use the same header copyright format as the other files.\n. You'll also need to copy xctool to a temporary directory and add it to a .buckconfig file; otherwise this will fail (similar to below)\nhttps://github.com/facebook/buck/blob/master/test/com/facebook/buck/apple/AppleTestIntegrationTest.java#L320\n. @fkorotkov Does it work for tests with with the apple-test-library flavor propagated? \n. You should be able to filter out just the platform flavor and SwiftLibraryDescription.SUPPORTED_FLAVORS.\n. Maybe a better approach is CxxDescriptionEnhancer.requireHeaderSymlinkTree?\n. https://github.com/facebook/buck/blob/master/src/com/facebook/buck/apple/AppleTestDescription.java#L177\n. It looks like the flavor isn't actually used for headers; you should be able to safely remove it from AppleTestDescription and AppleTestIntegrationTest.\ncc: @k21 who introduced it just in case there's something I overlooked.\n. Need to update SwiftLibraryIntegrationTest as well to set args.exportedHeaders to Optional.absent()\n. You should use fbxctest here.  See https://gist.github.com/ryu2/350a5d773e86fb70d5383cfd1e2c0ee0 for an example.\nUnfortunately, after I made that change, it fails with this\n[junit] Testcase: swiftCallingComplexObjCRunsAndPrintsMessageOnOSX took 1.007 sec\n    [junit]     Caused an ERROR\n    [junit] The same include path maps to multiple files:\n    [junit]   Include path: SwiftCallsComplexObjC/FBASLParser.h\n    [junit]   Conflicting files:\n    [junit]     /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5100542076165353880/fbxctest/bin/FBControlCore.framework/Versions/A/Headers/FBASLParser.h\n    [junit]     /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5100542076165353880/fbxctest/bin/FBControlCore.framework/Headers/FBASLParser.h\n    [junit] com.facebook.buck.util.HumanReadableException: The same include path maps to multiple files:\n    [junit]   Include path: SwiftCallsComplexObjC/FBASLParser.h\n    [junit]   Conflicting files:\n    [junit]     /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5100542076165353880/fbxctest/bin/FBControlCore.framework/Versions/A/Headers/FBASLParser.h\n    [junit]     /private/var/folders/79/r8x23p3x5z962kr42g6qfnt0x713m8/T/junit-temp-path5100542076165353880/fbxctest/bin/FBControlCore.framework/Headers/FBASLParser.h\n    [junit]     at com.facebook.buck.apple.AppleDescriptions.convertToFlatCxxHeaders(AppleDescriptions.java:197)\n    [junit]     at com.facebook.buck.apple.AppleDescriptions.parseAppleHeadersForUseFromOtherTargets(AppleDescriptions.java:151)\n    [junit]     at com.facebook.buck.apple.AppleDescriptions.convertAppleHeadersToPublicCxxHeaders(AppleDescriptions.java:114)\n    [junit]     at com.facebook.buck.apple.AppleDescriptions.populateCxxConstructorArg(AppleDescriptions.java:224)\n    [junit]     at com.facebook.buck.apple.AppleDescriptions.populateCxxLibraryDescriptionArg(AppleDescriptions.java:288)\n    [junit]     at com.facebook.buck.apple.AppleLibraryDescription.requireSingleArchUnstrippedBuildRule(AppleLibraryDescription.java:352)\n    [junit]     at com.facebook.buck.apple.AppleLibraryDescription.requireUnstrippedBuildRule(AppleLibraryDescription.java:330)\n    [junit]     at com.facebook.buck.apple.AppleLibraryDescription.createLibraryBuildRule(AppleLibraryDescription.java:256)\n    [junit]     at com.facebook.buck.apple.AppleTestDescription.createTestLibraryRule(AppleTestDescription.java:366)\n    [junit]     at com.facebook.buck.apple.AppleTestDescription.createBuildRule(AppleTestDescription.java:225)\n    [junit]     at com.facebook.buck.apple.AppleTestDescription.createBuildRule(AppleTestDescription.java:1)\n    [junit]     at com.facebook.buck.rules.DefaultTargetNodeToBuildRuleTransformer.transform(DefaultTargetNodeToBuildRuleTransformer.java:48)\n    [junit]     at com.facebook.buck.rules.BuildRuleResolver.requireRule(BuildRuleResolver.java:120)\n    [junit]     at com.facebook.buck.rules.ActionGraphCache$1.visit(ActionGraphCache.java:152)\n    [junit]     at com.facebook.buck.rules.ActionGraphCache$1.visit(ActionGraphCache.java:1)\n    [junit]     at com.facebook.buck.graph.AbstractBottomUpTraversal.traverse(AbstractBottomUpTraversal.java:62)\n    [junit]     at com.facebook.buck.rules.ActionGraphCache.createActionGraph(ActionGraphCache.java:161)\n    [junit]     at com.facebook.buck.rules.ActionGraphCache.getActionGraph(ActionGraphCache.java:90)\n    [junit]     at com.facebook.buck.cli.TestCommand.runWithoutHelp(TestCommand.java:482)\n    [junit]     at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:198)\n    [junit]     at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:92)\n    [junit]     at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:1234)\n    [junit]     at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(ProjectWorkspace.java:478)\n    [junit]     at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(ProjectWorkspace.java:420)\n    [junit]     at com.facebook.buck.testutil.integration.TestDataHelper$CacheClearingProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(TestDataHelper.java:111)\n    [junit]     at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommand(ProjectWorkspace.java:354)\n    [junit]     at com.facebook.buck.swift.SwiftOSXBinaryIntegrationTest.swiftCallingComplexObjCRunsAndPrintsMessageOnOSX(SwiftOSXBinaryIntegrationTest.java:146)\n. In theory, this will never be a non PathSourcePath.\nInstead of if you should use Preconditions.checkArgument(input instanceof PathSourcePath) to assert this.  Don't return null in any case.\n. Space after (PathSourcePath)\n. Remove extra whitespace\n. Use \"\" instead.\n. You don't mean OnOSX here.\n. Calling toString() here is incorrect.  You want getPathForRelativePath() in ProjectFilesystem instead.. Same issue as above.. Same as above.. Need to change this, since you made XctoolRunTestsStep take an Optional<String>.. SWIFT_COMPANION_FLAVOR?\nAlso consider using a FlavorDomain, then you can call withoutFlavors(flavorDomain.getFlavors()). ",
    "copumpkin": "@sdwilsh thanks, glad it's not just me :smile:. Is it expected that the broken file would crash my ant build, or is something weird also going on on my side?\n. Yeah, I figured out that that was a post-processing step I was running inadvertently, sorry!\n. ",
    "aiked": "The remaining empty jars are being used for project generation and we do not need them to contain something.\n. The error message gives me the following information:\n- Buck found a NDK with version 11.2.2725575\n- You specified your target NDK version is r11c based on the name of the folder android-ndk-r11c, as expected.\nThe problem comes from the inconsistency between the naming of the folder and how version is defined in source.properties where is stored in the form Pkg.Revision = 11.2.2725575. This was a change introduced with r11*. In previous versions, it was stored in RELEASE.TXT in the form of r10c.\nThe solution to this is to either let Buck find the latest NDK version or specify ndk_version = 11.2 or ndk_version = 11.2.2725575. We could hack around this but it wouldn't change the fact naming convention changed with the latest NDK version and we should adapt to it.\n. @FuegoFro thank you for the tip, I was unaware we were doing that. I think a0b7991a8835ccce81d83c00a584529a2c3ad0fb should fix the issue. Added bonus is not mistaking r10e and r10e-rc4 anymore. Let me know if this continues to be a problem.\n. @FuegoFro thank you for the tip, I was unaware we were doing that. I think a0b7991a8835ccce81d83c00a584529a2c3ad0fb should fix the issue. Added bonus is not mistaking r10e and r10e-rc4 anymore. Let me know if this continues to be a problem.\n. Hello @mlostekk,\nNDK versions > v11 do not contain a RELESE.TXT file, instead they have a machine readable source.properties file. Do you have that file inside /Users/mlostek/Library/Android/sdk/ndk-bundle? Have you defined ANDROID_NDK variable at your problem?\n. @ceozhu can you share your exception and also the contents of source.properties and where ANDROID_SDK, ANDROID_NDK, ANDROID_HOME, or all the env vars point?\nA few things have changed in this area the last few months. Also, how you get Buck, as package or you build the source?. @ceozhu can you share your exception and also the contents of source.properties and where ANDROID_SDK, ANDROID_NDK, ANDROID_HOME, or all the env vars point?\nA few things have changed in this area the last few months. Also, how you get Buck, as package or you build the source?. @ceozhu glad you managed to resolve this. I will close this now.. @mlostekk I think if your project has a source.properties file then you define the NDK as 12.1 or 13.1 and not as r11a or r12c.. Hello @mlostekk,\nIs it possible for you to give me the logs of the failed build? I'm afraid that I don't have enough data  from the Homebrew log. The log can be found under /buck-out/log and the problematic command.\n. Can you tell me if you are using Android NDK r12b? This might be related to something else.\n. Can you tell me if you are using Android NDK r12b? This might be related to something else.\n. Hello @coofee,\nProbably @marcinkosiba can answer this.\n. @coofee I will close this but if it's something you really want we are open to patches :)\n. Hello @kageiit,\nMaybe this can help you: https://buckbuild.com/rule/java_library.html, search for remove_classes. It could also be used to remove other types of files since it accepts a pattern. This test is a good example how you could use it. Tell me if that was helpful.\n. Hello @kageiit,\nMaybe this can help you: https://buckbuild.com/rule/java_library.html, search for remove_classes. It could also be used to remove other types of files since it accepts a pattern. This test is a good example how you could use it. Tell me if that was helpful.\n. Sorry for the late response, I have not forgotten of this issue. @marcinkosiba do you think we should implement this?\nUntil then @kageiit you can create a genrule that open the jar, removes the file and zips it again. It's a messy hack but it should do for now.\n. A quick update:\n- You can also wrap the prebuilt_jar in a java_binary, that has blacklist = ['LISENSE.TXT'] and then use the result of the java_binary in a prebuild_jar.\n- If you are in a hurry, make the changes and send a pull request, cc me to get on it faster.\n- The task went in our queue and it will be done in the future.\nI will close this one but feel free to open it if you want more info. \n. You can read this post: #808.\nexported_deps in this is broken and do not work for aar, they only work for jars and classpath\n. The problem is with https://github.com/facebook/buck/commit/7886e4581651276c255003cce53435fd0c1163b8. I will check it out and see how we can address this.\n. The problem is with https://github.com/facebook/buck/commit/7886e4581651276c255003cce53435fd0c1163b8. I will check it out and see how we can address this.\n. @maiergre wrote the diff that changed this logic, maybe he has more knowledge for this one.\n. @maiergre wrote the diff that changed this logic, maybe he has more knowledge for this one.\n. I pushed 2aab2deef16d9151e5a250e8ebdf5eeba5973fc1 that should address a possible issue behind this. Other than that the specific NDK has a weird structure and I think it's causing the issue. I tested with a few different NDKs and I could not reproduce.\nI will close this but feel free to re-open if you can provide more info about what is happening.. I pushed 2aab2deef16d9151e5a250e8ebdf5eeba5973fc1 that should address a possible issue behind this. Other than that the specific NDK has a weird structure and I think it's causing the issue. I tested with a few different NDKs and I could not reproduce.\nI will close this but feel free to re-open if you can provide more info about what is happening.. Hello @SirCmpwn,\nBuck does not currently support this. You could use buck without the daemon by using NO_BUCKD=1 buck <command> until we actually write the flag, which does not look complicated.\nWe also accept pull requests if you want to speed this up :). Hello @SirCmpwn,\nBuck does not currently support this. You could use buck without the daemon by using NO_BUCKD=1 buck <command> until we actually write the flag, which does not look complicated.\nWe also accept pull requests if you want to speed this up :). Could I ask why you want this? You don't want to use Watchman? You don't have a Watchman version that works well? You don't want the caches of the daemon? Depending the need the flag will have different behaviour.. Could I ask why you want this? You don't want to use Watchman? You don't have a Watchman version that works well? You don't want the caches of the daemon? Depending the need the flag will have different behaviour.. Cool, I will close this one but feel free to open it if it's not good enough and you need something more complicated.. Cool, I will close this one but feel free to open it if it's not good enough and you need something more complicated.. Hello @androidhuoniao,\nIt looks like maxSdkVersion is no longer supported. Check https://developer.android.com/guide/topics/manifest/uses-sdk-element.html.\nThe current version of the Merger used by Buck contains the following comments:\n{@code @maxSdkVersion}: obsolete, ignored. Not used in comparisons and not merged.\nYou can check #1018 that will update the manifest merger.. Hello @androidhuoniao,\nIt looks like maxSdkVersion is no longer supported. Check https://developer.android.com/guide/topics/manifest/uses-sdk-element.html.\nThe current version of the Merger used by Buck contains the following comments:\n{@code @maxSdkVersion}: obsolete, ignored. Not used in comparisons and not merged.\nYou can check #1018 that will update the manifest merger.. Hello @androidhuoniao,\nYou will have to give me more information. I guess this is from your code.\nAre the questions marks chinese characters? It is possible that Windows do not have knowledge of those characters?. Hello @androidhuoniao,\nYou will have to give me more information. I guess this is from your code.\nAre the questions marks chinese characters? It is possible that Windows do not have knowledge of those characters?. Awesome!. Awesome!. @andrewjcg could you take a look at this?. Hello @zayhero, I think @ryu2 will be able to help you with this.. Being honest, I put this under our wish list. But we also accept pull requests. . This is a tricky issue. From the okBuck I can only see one dex job running, is that correct? If that's the case the only way to address is to increase the heap size, but you tried that already.\nYou could also check https://buckbuild.com/concept/buckconfig.html#resources to tweak what resources go where, that could remove some parallelism that would free up the system to succeed.. This is a tricky issue. From the okBuck I can only see one dex job running, is that correct? If that's the case the only way to address is to increase the heap size, but you tried that already.\nYou could also check https://buckbuild.com/concept/buckconfig.html#resources to tweak what resources go where, that could remove some parallelism that would free up the system to succeed.. @Macarse glad it got addressed.. Why do you assume this is a fault of Buck? Did you change buck versions and that happened?. Why do you assume this is a fault of Buck? Did you change buck versions and that happened?. Is the file there? Do you know what target actually includes the header somewhere?. Open this again if you still have an issues but it doesn't look we can help you with this. It looks like a project specific issue.. I will close this since we didn't have an answer. @raviagarwal7 feel free to reopen if you have more info.. @raviagarwal7 Glad this got resolved.. @nguyentruongtho thank you for this quick fix!. @runningcode I'm on it.. Yeap, I didn't find any issues. Glad it got resolved.. I updated the homebrew version to v2017.03.29.01. . @aledalgrande it's a bit more complicated than that.\nThere are cases where a glob depends on platform or another factor and it's an accepted scenario to not have headers or sources for some cases. Printing a message then it would confuse the user.\nWhat we could do is create a strict mode for the BUCk files that throws in the cases that you never expect an empty glob. I think that would be a good compromise.\ncc'ing @Coneko that might care about this, what do you think?. Great! I will close this now.. This sounds like a good idea! I will admit that probably won't have time to get to it but if you can hack it up I would be happy to review etc. The code you need is located at https://github.com/facebook/buck/blob/master/src/com/facebook/buck/cli/QueryCommand.java. Update: the issue has been resolved internally but for unrelated reasons open-source buck is a bit behind, I expect this to be resolved tomorrow and a new working version to be out soon.. ",
    "twoism": "Thanks for the help! We we able to fix it by changing cxx_binary to cxx_library. Should cxx_binary work for XCode projects?\n. OK, I'll close this then. Thanks!\n. ",
    "Timeszoro": "thanks\n. thanks\n. ",
    "njlr": "Has anyone made any progress on this? \nI am having a similar issue where a legacy build system generates a folder of headers that I need to reference. Unfortunately the legacy build system is very complex, and reimplementing it properly in Buck is probably unrealistic, hence the need to \"wrap\" it. . @Coneko Thanks for the response. Is there a recommended approach when there are hundreds of files? I don't think it's possible to read the output directory of the make genrule to get the list of header files. . Yes, that works. \nFor those who stumble on this, try something like: \n```\ndef extract(x):\n  genrule(\n    name = x,\n    out = x,\n    cmd = 'cp $(location :make)/install/include/' + x ' $OUT',\n  )\n  return ':' + x\nheaders = [\n  'generated_header.h',\n]\nprebuilt_cxx_library(\n  name = 'my-lib',\n  exported_headers = dict({ (x, extract(x)) for x in headers }),\n  # etc... \n```. Have any more plans been made regarding this? \nIs rule[file] still the preferred syntax? . For people stumbling on this, you can now set executable = True on a genrule. . I did choco install python2, rebooted, rebuilt and now it works. I think that I installed Python 3 the first time.\nPerhaps the docs should be clearer, or maybe the Buck program should check the Python version and throw a warning? . Can confirm the same issue on macOS - the platform is \"default\" . Can confirm the same issue on macOS - the platform is \"default\" . I get the error when running just buck build :my-target. Do we have to specify the target for every build? Seems like it would be more streamlined if the platform macro expanded to the actual host platform by default. . I get the error when running just buck build :my-target. Do we have to specify the target for every build? Seems like it would be more streamlined if the platform macro expanded to the actual host platform by default. . I have made a small C++ project here: https://github.com/njlr/buck-platforms. \nHere are my results on macOS: \n```\n  buck run :hello\n  Hello from default\nbuck run :hello#macosx-x86_64\n  Hello from macOS\nbuck run :hello#linux-x86_64\n  Unrecognized flavor in target //:hello#linux-x86_64 while parsing //BUCK\n```\n. I have made a small C++ project here: https://github.com/njlr/buck-platforms. \nHere are my results on macOS: \n```\n  buck run :hello\n  Hello from default\nbuck run :hello#macosx-x86_64\n  Hello from macOS\nbuck run :hello#linux-x86_64\n  Unrecognized flavor in target //:hello#linux-x86_64 while parsing //BUCK\n``\n. I had a go at fixing this here: https://github.com/facebook/buck/pull/1562. Relevant setting https://buckbuild.com/files-and-dirs/buckconfig.html#cxx.should_remap_host_platform. Interestingly if I runbuck testagain it succeeds. Perhaps a cache is affecting this? . I don't mean the resources have to be embedded, just put alongside the executable. . @ryu2 Yes, this is the solution I arrived at. What is slightly annoying is that you cannot launch agenrule` via Buck (or can you?)\nbuck run :game-bundle. As a work-around you can install an old version. For example: \nbrew unlink buck\nbrew install https://raw.githubusercontent.com/facebook/homebrew-fb/7511722fd58e999e5d8c3a415d4e8cd1deee8f21/buck.rb. I ran the following to get the latest version working: \n```\nInstalled an old version\nbrew unlink buck\nbrew install https://raw.githubusercontent.com/facebook/homebrew-fb/7511722fd58e999e5d8c3a415d4e8cd1deee8f21/buck.rb\nYour suggestion\nbuck kill\nInstall latest\nbrew unlink buck\nbrew install --HEAD facebook/fb/buck \n```\nSo it may have been the reinstall or buck kill (or both!) that did the trick. . According to this, libstdc++ is linked when g++ is used as the linker. g++ may well be your default. \nWhat if you override the linker using a .buckconfig (docs)? \nbash\n[cxx]\n  ld = /usr/bin/ld\nBTW, I have a BUCK file for Sodium here. . How are you testing that the C++ standard library is being linked? . I think that setting the linker to gcc in .buckconfig does the trick. \nHere is my ldd output: \n$ ldd ./buck-out/gen/xkcd936\n    linux-vdso.so.1 =>  (0x00007fff4afba000)\n    libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f2239b6d000)\n    /lib64/ld-linux-x86-64.so.2 (0x0000559044bf0000)\nI believe these are just C libraries? \nAll of the code is in my fork. \n. Work-around:\n```\nprebuilt_cxx_library(\n  name = 'pthread',\n  header_only = True,\n  exported_linker_flags = [\n    '-lpthread',\n  ],\n)\ncxx_binary(\n  name = 'main2',\n  srcs = [\n    'main.cpp',\n  ],\n  deps = [\n    ':pthread',\n  ],\n)\n```\nWhich gives us this argfile: \n-o\nbuck-out/gen/main2\n\"buck-out/gen/main2#compile-main.cpp.oa5b6a1ba,default/main.cpp.o\"\n-lpthread\nNote that -lpthread is now after the object file main.cpp.o. . Perhaps you could pull the Objective C++ files out into their own target and set the flags in compiler_flags? \n```\ncxx_library(\n  name = 'cpp',\n  srcs = [\n    'core.cpp',\n  ], \n  compiler_flags = [\n    '-x c++',\n  ],\n)\ncxx_library(\n  name = 'objective-cpp',\n  srcs = [\n    'sample.cpp',\n  ], \n  compiler_flags = [\n    '-x objective-c++',\n  ],\n  deps = [\n    ':cpp',\n  ],\n)\n```\nDo you have a public repo available? \n. Perhaps you could pull the Objective C++ files out into their own target and set the flags in compiler_flags? \n```\ncxx_library(\n  name = 'cpp',\n  srcs = [\n    'core.cpp',\n  ], \n  compiler_flags = [\n    '-x c++',\n  ],\n)\ncxx_library(\n  name = 'objective-cpp',\n  srcs = [\n    'sample.cpp',\n  ], \n  compiler_flags = [\n    '-x objective-c++',\n  ],\n  deps = [\n    ':cpp',\n  ],\n)\n```\nDo you have a public repo available? \n. Thanks @bertmaher. \nThis capability is quite critical for us, and we would be willing to contribute the code if required to make it happen. Do you think one of the Buck team could provide some design direction? \ncc @nikhedonia . cc @nikhedonia @isundaylee. cc @nikhedonia @isundaylee. Buck supports this via configs passed in at the command-line. See: https://github.com/facebook/buck/issues/1470#issuecomment-333800409\nFlavours should only be used for build platform targets (e.g. macosx-x86_64). cc @nikhedonia . cc @nikhedonia . I have created a patch for this (https://github.com/njlr/buck/tree/feature/buckconfig.auto). Happy to send a PR. . I have created a patch for this (https://github.com/njlr/buck/tree/feature/buckconfig.auto). Happy to send a PR. . Interesting idea - we would need a well defined stacking order if multiple configs are possible. . Interesting idea - we would need a well defined stacking order if multiple configs are possible. . That sounds feasible but I think that it would prove inconvenient for users, since they would always want to pass in the values or the build will fail. . That sounds feasible but I think that it would prove inconvenient for users, since they would always want to pass in the values or the build will fail. . Would someone from the Buck team be able to provide guidance on this? . @ttsugriy I had a closer look at the --config command line option and I don't think it will fit our use-case, since we have different generated .buckconfig.local files for each cell. \nSo, the top level .buckconfig.local might look like this: \n[repositories]\n  datasift.served = buckaroo/official/datasift/served\n  boost.date-time = buckaroo/official/boost/date-time\n  boost.config = buckaroo/official/boost/config\nAnd buckaroo/official/datasift/served/.buckconfig.local might look like this: \n[repositories]\n  boost.assert = ../assert\n  boost.config = ../config\n  boost.static-assert = ../static-assert\n  boost.throw-exception = ../throw-exception\n  boost.utility = ../utility\n  boost.functional = ../functional\nI don't think the --config option allows specific overrides for different cells? . This feature is really powerful, but I think the syntax makes it a bit painful for setting properties used in every build. buck build :app is much nicer than buck build @configs/release :app, for example. Of course, this could be hidden inside a script (e.g. buckaroo.sh containing buck build @configs/buckaroo :app), but I think this harms usability because: \n\nYou can no longer easily call Buck from subfolders in the project\nYou are no longer directly interfacing with Buck, so we have to explain the extra level of indirection to new-comers. This is barrier to entry. \nWe would need a build script for each target, which adds friction... or create a more generic script, which is more confusing! \nA script would (probably) be platform-specific. \n\nFor these reasons, I think that buckconfig.auto (or similar) is a good solution. What are the thoughts on this from the Buck side? . It seems that this is no longer possible. \nWith this config:\n--config\nrepositories.abc=./deps/abc\nI get the following error: \n\nBUILD FAILED: Overriding repository locations from the command line is not supported. Please place a .buckconfig.local in the appropriate location and use that instead.\n. There is now the .buckconfig.d folder. . Some environment information: \n\nPython 2.7.13\njava version \"1.8.0_121\"\nJava(TM) SE Runtime Environment (build 1.8.0_121-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)\nApache Ant(TM) version 1.10.1 compiled on February 2 2017. I was able to fix this by adding the following to my Appveyor config:\nenvironment:\n  BUCK_EXTRA_JAVA_ARGS: \"-Djna.nosys=true\". Looks like there is now an official package! :heart: . My understanding is that the Buck team can make breaking changes because the version of Buck can be locked down inside of a project. Perhaps this isn't the case though? \nI think in the long run it is easier to fix the behaviour than to add a switch. If the switch is off by default, then users will still have to perform an arbitrary action to build cross-platform projects (flipping the switch instead of adding the platform flavor). If the switch is on by default, then we would be breaking some builds anyway, so why not fix just the build? After all, the default platform is a forgotten TODO, rather than a conscious design decision. \nThe migration procedure is quite easy. \nFor example, this:\nplatform_preprocessor_flags = [\n  ('default', [ '-DFOO=1' ]),\n  ('^macos.*', [ '-DFOO=2' ]),\n],\n... might become... \nplatform_preprocessor_flags = [\n  ('^macos.*', [ '-DFOO=2' ]),\n  ('*', [ '-DFOO=1' ]),\n],\nWhat are your thoughts on this? . My understanding is that the Buck team can make breaking changes because the version of Buck can be locked down inside of a project. Perhaps this isn't the case though? \nI think in the long run it is easier to fix the behaviour than to add a switch. If the switch is off by default, then users will still have to perform an arbitrary action to build cross-platform projects (flipping the switch instead of adding the platform flavor). If the switch is on by default, then we would be breaking some builds anyway, so why not fix just the build? After all, the default platform is a forgotten TODO, rather than a conscious design decision. \nThe migration procedure is quite easy. \nFor example, this:\nplatform_preprocessor_flags = [\n  ('default', [ '-DFOO=1' ]),\n  ('^macos.*', [ '-DFOO=2' ]),\n],\n... might become... \nplatform_preprocessor_flags = [\n  ('^macos.*', [ '-DFOO=2' ]),\n  ('*', [ '-DFOO=1' ]),\n],\nWhat are your thoughts on this? . Yes, perhaps not the best example. We are placing generic settings in default and then also setting the ^linux.* and ^macos.* entries (even if they are the same), so for us it is not much of change. \nEither way, we would be really happy to see this get included, even if it is behind a flag for a while. \ud83d\udc4d . Yes, perhaps not the best example. We are placing generic settings in default and then also setting the ^linux.* and ^macos.* entries (even if they are the same), so for us it is not much of change. \nEither way, we would be really happy to see this get included, even if it is behind a flag for a while. \ud83d\udc4d . Sounds reasonable \ud83d\udc4d . Can confirm that the output is a little weird in https://github.com/njlr/buck-sh-binary: https://github.com/njlr/buck-sh-binary. @timmych So it is! Although arguably the behaviour should be to take the host flavour when no flavour is specified (particularly with should_remap_host_platform). . Unfortunately Buck does not give you any control over where a dynamic library is placed during the build process. This means that Buck will work out-of-the-box using buck run ... but it can a pain when creating a deployment. \nMy suggestion is to patchelf to tweak the paths after Buck has built them. \nI have created an example of this here: https://github.com/njlr/buck-fixup-rpath\nIt's a little annoying, but the alternatives (e.g. CMake) are hardly better. \nIn the long run, it would be amazing if Buck offered some way to prepare a bundle of an executable, resources and dynamic libraries for release. \nPerhaps it could look like this: \npython\ncxx_bundle(\n  name = 'my-app',\n  executable = '//:app',\n  bin_path = 'bin/app',\n  resources = glob([\n    'README.md',\n    'assets/**/*.png', \n    'assets/**/*.wav',\n  ]),\n  shared_libs = {\n    'lib/libtest': '//:test',\n  },\n)\nAnd the output would be a folder like: \n.\n\u251c\u2500\u2500 assets\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 img\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 skylark.png\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 snd\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 birds.wav\n\u251c\u2500\u2500 bin\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 app\n\u251c\u2500\u2500 lib\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 libtest.so\n\u2514\u2500\u2500 README.md\n. ",
    "crylico": "Sorry, just got a chance to get around to this! I tried values ranging from 100ms to 2500ms with no success\n. Currently looking through the runBundleOfDevice source\n. It seems to be a problem only with iOSConsole. Calling iOSConsole -d <uuid> --run <bundle-id> hangs in the same fashion.  It's even consistent with apps that I didn't write.  However, if the app is running in the background, things proceed as expected\n. ",
    "ScottPierce": "So this approach assumes that you are able to predict every file in the output. It seems like a common case that the output file names aren't known at rule generation time, and instead the ability to to deal with the output as a folder is needed. Is there any way to handle this case?\nThe reason this approach makes me slightly uncomfortable is that it assumes that the java to objc transpiler I'm using always has a 1 to 1 relationship between the input java file and the output java file. That may be the case, but it's certainly not documented, and it could change in the future. Ideally I'd be able to use gen_rule to generate an output directory, and then somehow gain access to the folder, delivering sources to other genrules by calling glob() on it, or even just being able to deliver the folder path to another rule that takes a path.\n. I've migrated to the approach suggested above and I'm having a few issues:\nThis was my header declaration for my apple_library():\npython\nheaders = subdir_glob([('source', '**/*.h')]),\nNow I'm using:\npython\nheaders = [':' + x for x in OBJC_HEADERS],\nI'm having difficulty matching the subdir_glob() function, and instead I believe what I'm doing would be the same as me using glob() function instead of the subdir_glob() function. Because of this, I have header conflicts, and even if I didn't I need to keep my header paths:\n``` error\njava.lang.IllegalArgumentException: Multiple entries with same key: package-info.h=Pair(//rxjava:rx/package-info.h, Optional.absent()) and package-info.h=Pair(//rxjava:rx/schedulers/package-info.h, Optional.absent())\n```\nI haven't been able to come up with any creative way around it either. Any suggestions?\n. I've migrated to the approach suggested above and I'm having a few issues:\nThis was my header declaration for my apple_library():\npython\nheaders = subdir_glob([('source', '**/*.h')]),\nNow I'm using:\npython\nheaders = [':' + x for x in OBJC_HEADERS],\nI'm having difficulty matching the subdir_glob() function, and instead I believe what I'm doing would be the same as me using glob() function instead of the subdir_glob() function. Because of this, I have header conflicts, and even if I didn't I need to keep my header paths:\n``` error\njava.lang.IllegalArgumentException: Multiple entries with same key: package-info.h=Pair(//rxjava:rx/package-info.h, Optional.absent()) and package-info.h=Pair(//rxjava:rx/schedulers/package-info.h, Optional.absent())\n```\nI haven't been able to come up with any creative way around it either. Any suggestions?\n. Thanks for your response @Coneko . I appreciate it.\n\nYou can do the same thing as subdir_glob by specifying a dictionary instead of a list for headers: the key will be the path with which you can include the header, the value is the reference to the header itself.\n\nI had thought of trying to generate the header dictionary myself, but I believe the header dictionary has access to the actual file paths for the value, doesn't it? The dictionary value is why I chose not to do it in the first place, and it's the part of your suggestion that I don't understand also.\nWhat do you mean by the reference to the header itself for the value? Could the value be a String reference to the build rule, like this:\nOBJC_HEADER_DICT = { header : (':' + header) for header in OBJC_HEADERS }\n\nAs for the code generation not knowing the number and names of the files being generated, there's no way to solve that in Buck. All the actions have to be determined before they are executed. It's a pretty hard limitation to deal with and we're not happy with it either, but that's how it is right now.\n\nAre there any plans / ideas to overcome this in the future, or is this not even on the radar?\n. Thanks for your response @Coneko . I appreciate it.\n\nYou can do the same thing as subdir_glob by specifying a dictionary instead of a list for headers: the key will be the path with which you can include the header, the value is the reference to the header itself.\n\nI had thought of trying to generate the header dictionary myself, but I believe the header dictionary has access to the actual file paths for the value, doesn't it? The dictionary value is why I chose not to do it in the first place, and it's the part of your suggestion that I don't understand also.\nWhat do you mean by the reference to the header itself for the value? Could the value be a String reference to the build rule, like this:\nOBJC_HEADER_DICT = { header : (':' + header) for header in OBJC_HEADERS }\n\nAs for the code generation not knowing the number and names of the files being generated, there's no way to solve that in Buck. All the actions have to be determined before they are executed. It's a pretty hard limitation to deal with and we're not happy with it either, but that's how it is right now.\n\nAre there any plans / ideas to overcome this in the future, or is this not even on the radar?\n. > The limitation is part of the design. We know how to change the design to support that by making it more like shake, but we haven't yet decided whether we want to.\nIs there any discussion around this, or way to track it so that I could follow it and see what's decided? I'd like to better understand the pros / cons.\n\nYeah it can be a reference to a target. It should work as you suggested.\n\nWhen I use the approach I listed above, it's trying to read the files in the wrong location. I get several errors when I try to use all these build targets in an apple_library(). I get the same error on each file. Here is an example:\nerror: error reading 'buck-out/gen/rxjava/rx/Observable.m/rx/Observable.m'\n1 error generated.\nIt's trying to read buck-out/gen/rxjava/rx/Observable.m/rx/Observable.m as the file, but that is actually the folder containing the file, which is what's causing the error. buck-out/gen/rxjava/rx/Observable.m/rx/Observable.m/Observable.m is actually the file that it needs to be reading.\nFor reference, here is my BUCK file. What am I still missing?\n``` python\nRXJAVA_SRC_DIR = 'src-1.1.0'\nRXJAVA_JAVA_SRC = glob([RXJAVA_SRC_DIR + '/main/java/*/.java'])\nOBJC_FILES = []\nOBJC_HEADERS = []\nfor javaPath in subdir_glob([(RXJAVA_SRC_DIR + '/main/java', '*/.java')]):\n  javaPathNoSuffix = javaPath[:-4]\n  OBJC_FILES.append(javaPathNoSuffix + 'm')\n  OBJC_HEADERS.append(javaPathNoSuffix + 'h')\njava_library(\n  name = 'java',\n  srcs = RXJAVA_JAVA_SRC,\n  tests = [\n    ':java-tests'\n  ],\n  visibility = [\n    'PUBLIC'\n  ],\n)\njava_test(\n  name = 'java-tests',\n  srcs = glob(['src-1.1.0/test/java/*/.java']),\n)\ngenrule(\n  name = 'objc-generate',\n  srcs = [\n    RXJAVA_SRC_DIR,\n  ],\n  cmd = '$(exe //scripts:Java2ObjC) ' + RXJAVA_SRC_DIR + '/main/java $OUT',\n  out = 'src-objc',\n)\ndef objcGenRule(objc_filename):\n  genrule(\n    name = objc_filename,\n    cmd = 'mkdir -p $OUT && cp $(location :objc-generate)/' + objc_filename + ' $OUT',\n    out = objc_filename,\n  )\nfor src in OBJC_FILES: \n  objcGenRule(src)\nfor header in OBJC_HEADERS:\n  objcGenRule(header)\nOBJC_HEADER_DICT = { header : (':' + header) for header in OBJC_HEADERS }\nA sample of what the j2objcc command runs when running for osx\nxcrun clang -fobjc-arc -I /j2objc/j2objc-0.9.8.2.1/include -Werror -Wno-parentheses -fno-strict-overflow -std=c11 -ljre_emul -l icucore -l z -l j2objc_main -l c++ -framework Foundation -framework Security -framework ExceptionHandling -L /j2objc/j2objc-0.9.8.2.1/lib/macosx\napple_library(\n  name = 'objc',\n  deps = [\n    ':objc-generate',\n    '//j2objc:include',\n    '//j2objc:jre_emul',\n  ],\n  preprocessor_flags = [\n    '-fobjc-arc', \n    '-fno-strict-overflow',\n    '-std=c11',\n    '-Werror', \n    '-Wno-parentheses',\n    '-c',\n  ],\n  headers = OBJC_HEADER_DICT  ,\n  srcs = [':' + x for x in OBJC_FILES],\n  exported_linker_flags = [\n    '-lc++',\n    '-licucore',\n    '-lz',\n  ],\n  frameworks = [\n    '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n    '$SDKROOT/System/Library/Frameworks/Security.framework',\n  ],\n  visibility = [\n    'PUBLIC',\n  ],\n)\n```\nI get the error when I use the build command on a rule that has the objc rule as a dependency.\n. @Coneko I've tried several other approaches based around the first approach that you gave, and I can't seem to get any of them to work. I'm back to the example I gave immediately above.\n. @sdwilsh Thanks for stepping in. I appreciate it.\nSo I believe that's what @Coneko originally recommended. When I run that I get the No such file or directory error from the cp command:\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/functions/Func6.h/rx/functions/Func6.h: No such file or directory\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/internal/operators/OperatorFilter.m/rx/internal/operators/OperatorFilter.m: No such file or directory\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/internal/util/UtilityFunctions.m/rx/internal/util/UtilityFunctions.m: No such file or directory\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/subscriptions/RefCountSubscription.h/rx/subscriptions/RefCountSubscription.h: No such file or directory\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/internal/operators/OperatorSwitch.h/rx/internal/operators/OperatorSwitch.h: No such file or directory\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/schedulers/TimeInterval.h/rx/schedulers/TimeInterval.h: No such file or directory\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/internal/util/atomic/LinkedQueueNode.m/rx/internal/util/atomic/LinkedQueueNode.m: No such file or directory\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/internal/operators/OperatorSampleWithObservable.h/rx/internal/operators/OperatorSampleWithObservable.h: No such file or directory\ncp: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/schedulers/CachedThreadScheduler.m/rx/schedulers/CachedThreadScheduler.m: No such file or directory\nTo give some more explanation to what's happening. The value of objc_filename is a path. For the first error, the value would be rx/functions/Func6.h. Is the fact that it's a path what's causing this error?\nIt's because of these errors that I added the mkdir -p $OUT.\nAny thoughts on where I go from here?\n. @Coneko When I try that I get the following:\nBUILD FAILED: Couldn't get dependency '//rxjava:rx/Notification.h' of target '//rxjava:objc':\n//rxjava:rx/Notification.h: no such macro \"dirname\"\n. That didn't work, I got the No such file or directory error again:\nmkdir: /Users/myuser/Documents/workspace/j2objc-test/buck-out/gen/rxjava/rx/internal/util/unsafe/BaseLinkedQueuePad0.h/rx/internal/util: No such file or directory\n...\nI see what you are trying to do though so I added the -p to the mkdir again, and it worked! Thank you so much for your help figuring this out @Coneko and @sdwilsh .\nFor anyone who finds this and has the same issue, the script above is exactly the same, except for objcGenRule() function, which has been changed to:\npython\ndef objcGenRule(objcFilePath):\n  genrule(\n    name = objcFilePath,\n    cmd = 'mkdir -p `dirname $OUT` && cp $(location :objc-generate)/' + objcFilePath + ' $OUT',\n    out = objcFilePath,\n  )\n. I see what you were trying there, and it makes sense, but it still ends up trying to find the file:\nBUILD FAILED: java.lang.RuntimeException: java.nio.file.NoSuchFileException: /blah/blah/blah/j2objc-test/j2objc/lib/libz.a\n. Your solution did end up leading me to what I needed though. I just added the \nexported_linker_flags = [\n    '-lc++',\n  ],\nto my apple_library, and that did the trick. I remember reading that in the documentation. Not sure why it didn't occur to me.\nThanks again for your prompt and helpful responses @sdwilsh !\n. ",
    "illuminace": "Fair point. Perhaps I misjudged it, but I took the \"standard\" part of the name to relate to Buck's internal JDK type name as opposed to the IntelliJ type name/version. I.e. newStandardJdk sets the internal type to \"jdk\", whereas there's a similar method called newInheritedJdk which sets the internal type to \"inheritedJdk\". I felt like this distinction should be clearly reflected in the method signature, hence I opted to leave the name as-is. However, one could quite correctly argue that newJdk, without any modifier, naturally reflects a \"standard\" or \"default\" state, so I'm perfectly open to the idea of renaming it. \nAs for separating the methods, deferring to the original; we could do, but I don't see much benefit over simply using Optional's defaults? I.e. I can't envisage a case at this juncture where the added indirection would be useful - why would we need to call the original method, to enforce use of JDK 1.7? I took that to be a Facebook-ism, addressed by the comments at the top of Project.java: \"Hopefully over time, the Facebook-specific logic will be removed\". I've most probably overlooked something though, so I'm perfectly happy to adjust it if you'd prefer.\nCheers\n. Hi @marcinkosiba. No problem at all, thanks for following up!\nI hadn't considered the android_resource rules. You make a really good point, it might be possible to aggregate project resources from existing configuration rules and avoid additional configuration. \nMy use-case is a little different to your example though, as I'm dealing with plain old java projects as opposed to Android projects. I don't think java_library's resources section can help us achieve this - targets, bespoke entries for particular libs... it wouldn't give us what we need. We could perhaps attempt to infer based on resource_roots, which looks more viable, but it smacks of overloading and I suspect would cause problems in the real world.\nI'm very open to suggestions - any superfluous configuration that can be removed/not added in the first place is a positive thing. Or alternatively if there's a more formal definition we can envisage that could be reused in other ways...?\nThanks\n. Hi @marcinkosiba. No problem at all, thanks for following up!\nI hadn't considered the android_resource rules. You make a really good point, it might be possible to aggregate project resources from existing configuration rules and avoid additional configuration. \nMy use-case is a little different to your example though, as I'm dealing with plain old java projects as opposed to Android projects. I don't think java_library's resources section can help us achieve this - targets, bespoke entries for particular libs... it wouldn't give us what we need. We could perhaps attempt to infer based on resource_roots, which looks more viable, but it smacks of overloading and I suspect would cause problems in the real world.\nI'm very open to suggestions - any superfluous configuration that can be removed/not added in the first place is a positive thing. Or alternatively if there's a more formal definition we can envisage that could be reused in other ways...?\nThanks\n. ",
    "tapthaker": "The posts don't seem to be available anymore. Can someone repost them?. ",
    "dxxchen": "As far as I can tell, this is not yet resolved?\npython\njava_library(\n  name = 'foo',\n  resources = ...,\n  resources_root = \"src/main/resources\",\n  ...\n)\ncreates an .iml file that contains\nxml\n<sourceFolder url=\"file://$MODULE_DIR$/src/main/resources\" isTestSource=\"false\" .../>\nI would expect that resource folders have the attribute type=\"java-resource\".. As far as I can tell, this is not yet resolved?\npython\njava_library(\n  name = 'foo',\n  resources = ...,\n  resources_root = \"src/main/resources\",\n  ...\n)\ncreates an .iml file that contains\nxml\n<sourceFolder url=\"file://$MODULE_DIR$/src/main/resources\" isTestSource=\"false\" .../>\nI would expect that resource folders have the attribute type=\"java-resource\".. I unfortunately cannot sign the CLA (yet?), but our fork replaces that line with something like http://stackoverflow.com/a/1115074.\n. I unfortunately cannot sign the CLA (yet?), but our fork replaces that line with something like http://stackoverflow.com/a/1115074.\n. ",
    "ryandm": "@brettwooldridge fixed this in #84 by allowing a prebuilt_jar rule to pull in duplicate classes in a JAR if those classes are duplicate but identical (as in the case of xmlbeans).. (Closing as old/low-pri). The way I see it, the upside of interacting with a third-party toolchain is getting to steal that mental model (and ecosystem) for free. The downside is it's only free for someone already familiar with thinking in terms of Maven/Gradle/Ivy for dependencies.\nThe goal here is a complete, sustainable solution for Java dependency management needs.\n- Let's do that without adding a new toolchain, if we can. But so far, I don't see how we can.\n- Tackling #602 is clearly a requirement for this goal; @davido thanks for re-raising that issue.\nOkBuck's approach to dependencies is in a similar vein, except of course that the description up top calls for materializing BUCK files into the tree and then using vanilla buck. Other than feature completeness, the main outcome I'd like to see is a clear recommendation in Buck docs for how to import Java 3rd-party libraries.\n(still gotta check out the bazel/maven_jar/skylark stuff)\n. Suppose we add a transitive = True flag. How do we satisfy Buck's core need for reproducibility? From Buck's perspective, the only way to make the guarantee is to commit something (e.g. a checksum) into the source tree. Unless I'm missing a creative escape hatch, any kind of transitivity implies running a separate command to resolve dependencies before the actual build.\nHiding Maven/Gradle/Ivy as an implementation detail is tempting... whether this can be done without creating a leaky abstraction is a judgment call. Based on evaluating this for Maven (with prototyping) I currently think that such an abstraction will either leak, or effectively reinvent dependency management. The biggest issue is how to cleanly surface all failures.\nWhat should Buck implement/recommend as the current approach for managing Java dependencies?\nIs there an approach that's more complete+supportable than mvn/gradle plugins that write BUCK files for resolved dependencies?\n. (Closing as likely beyond the scope of buck per se.). ",
    "husky-yooho": "I found the solution by searching other issue.\nadd such code in BUCK file:\nandroid_binary(\n      ...\n      linear_alloc_hard_limit = 16 * 1024 * 1024,\n      use_split_dex = True,\n      use_linear_alloc_split_dex = True,\n      ...\n)\nThank you \uff01\n. ",
    "ruibm": "Thanks for sending this PR. Looks good - I just added few minor comments.\n. Looks good! Thanks for the changes. Proceeding with the merge.\n. Hi @grumpyjames! Reliable sources tell me you are a strong point of contact to diagnose/fix this. :)\nCould you please take a look? Thanks!\n. Touch\u00e9!! Thanks for tracking this down @grumpyjames. I'll chase after this @facebook-github-bot now. :)\n. For reference, here's the commit that added the real jars:\nhttps://github.com/facebook/buck/commit/9491d945304ec53e80f09acd8aa0920474c5749e\n. Unit test and fix on its way. Thanks for reporting @sea36! :)\n. Ok this checkin should have fixed it @sea36 (and ideally the tests will prevent regressions) => https://github.com/facebook/buck/commit/a713875dbcccda8210a316d1becb62c26a26be13\nPlease let me know if it's all fine now. Thanks!\n. Ok this checkin should have fixed it @sea36 (and ideally the tests will prevent regressions) => https://github.com/facebook/buck/commit/a713875dbcccda8210a316d1becb62c26a26be13\nPlease let me know if it's all fine now. Thanks!\n. Closing this now, please re-open if it's still a problem. Thanks!\n. Closing this now, please re-open if it's still a problem. Thanks!\n. Hum, this is quite annoying from the latest OkHttpClient. :(\nLet me take a quick look at what is the least evasive way of sorting this out without too many changes.\n. The PR seems fine @yschimke. I'll make the fix for the test and push it in tomorrow. Thanks.\n. Still doesn't seem to be in maven however if you are up to adding the new jar versions to your PR I can still include it in this push.\n. Still doesn't seem to be in maven however if you are up to adding the new jar versions to your PR I can still include it in this push.\n. Cool thanks! I've pulled your updates now.\n. Cool thanks! I've pulled your updates now.\n. Can you make \"scala\" a constant please? It seems to be used in a lot of places in this class.\n. Could you please have two different HumanReadableExceptions? \n1. for the case where SCALA_HOME is not defined and.. .\n2. the case when it's defined in the env however the file does not exist.\n. For consistency, either keep the @Hint annotation in the same line or breakline like in line #163.\n. ",
    "mrkane27": "Not sure if you're going to add it back, but currently the documentation for export_file has an example genrule() with a deps argument in it, which might be misleading.\n. Not sure if you're going to add it back, but currently the documentation for export_file has an example genrule() with a deps argument in it, which might be misleading.\n. Thanks for the reply!\nRe: transitive dependencies, what would be a preferred workflow in the context of SNAPSHOTs and generally Maven JARs that change rather frequently? Would the resolver need to be invoked before every build to regenerate the rules?\nRe: authentication, the use case is accessing artifacts stored in a Nexus Repository that uses a basic authentication scheme (which as far as I understand is a header dance of WWW-Authenticate and Authorization).\ngit grep-ping for auth, 401 or realm suggests it's not currently supported. I think it might just be a matter of allowing credentials to be specified in either remote_file() itself or [maven_repositories], and adding support in the downloader to interpret the 401 response code and reissuing the request. I could try writing it and sending a PR, if it seems reasonable.\n. @Coneko , thanks for the code review on this. Is there a flow for adding documentation, should I follow up?\n. Trivial workaround I reckon would be removing the trailing , \\.\n. Will do! Is the overall approach reasonable?\n. Sorry about that :blush:.\n. @grumpyjames thanks for the feedback. It does look like this is indeed more involved than I assumed initially. I've added support for creating @ files, but I would need to look at the other PR as well.\n. I might be misunderstanding the model, but as far as I can tell:\n- remote_file and buck fetch use [maven_repositories], but have no understanding of transitive dependencies;\n- Resolver (or maven-importer as aliased in .buckconfig) is a command line tool that takes a bunch of artifacts, downloads them along with transitive deps, and sets up prebuilt_jar rules for all of them. It seems to be using some Eclipse Maven tooling. I don't know if there is any documentation for it to begin with. It was initially added here.\nHappy to add documentation and such.\n. I might be misunderstanding the model, but as far as I can tell:\n- remote_file and buck fetch use [maven_repositories], but have no understanding of transitive dependencies;\n- Resolver (or maven-importer as aliased in .buckconfig) is a command line tool that takes a bunch of artifacts, downloads them along with transitive deps, and sets up prebuilt_jar rules for all of them. It seems to be using some Eclipse Maven tooling. I don't know if there is any documentation for it to begin with. It was initially added here.\nHappy to add documentation and such.\n. Happy to follow up with a documentation PR.\n. Another thing I'd be interested in doing would be to give the Maven importer a mode of operation where it produces remote_file rules instead of immediately downloading everything.\n. The merge conflicts are in BUCK.autodeps files. I tried pulling and resolving them, however buck autodeps gets stuck:\n[+] PARSING BUCK FILES...384.0s\nI also tried having a separate, clean, Buck checkout and running buck from there, same effect. Have you guys seen this before?\n. I also tried checking out the merge-conflicting BUCK.autodeps files from both my commit, and the new master - basically, valid structure, possibly incorrect contents - same effect.\n. \nDoesn't seem to be printing anything else to the log, at this point. Will try to attach the debugger now.\n. Here's a gist of the thread dump.\nI also tried attaching to the Python process from IntelliJ but sadly it hangs on \"Attaching to...\". Please let me know where to go from here.\n. Ah, thanks for clarifying. I was wrong about the compiler, it's not actually bundled (I just looked for scala.tools.nsc.Main in my jar and it wasn't there. Thanks for the tips on the library. I'll close this off.\n. Ah, thanks for clarifying. I was wrong about the compiler, it's not actually bundled (I just looked for scala.tools.nsc.Main in my jar and it wasn't there. Thanks for the tips on the library. I'll close this off.\n. After this change, you could have multiple repos with the same URI but different aliases. Should I perhaps use a BiMap instead?\n. I would probably move this elsewhere if you decide to go with this PR.\n. I saw that ExternalJavac supports passing things off via @ listfiles. That might be something to support in Scala as well.\n. It's mostly to do with credentials, which I'd be slightly more comfortable having in a JSON than over the command line.\n. :+1: \n. I've fixed it up a bit, but the format of that JSON will still have to be specified in the documentation bit. Alternatively, I can modify usage() to show the format as well.\n. That's what args4j seems to suggest.\n. :+1:\nNot sure what happened there, I love the Oxford comma. \n. ",
    "trevorriles": "\nHeh; I didn't know this was possible; neither the groovy documentation (www.groovy-lang.org/groovyc.html) or groovyc's usage documents it.\n\nI noticed that as well, but I tested it out and the command line and it seems to work. I'll look into opening a ticket with the groovy team to get it documented.\n. Awesome, thanks @grumpyjames \n. Awesome, thanks @grumpyjames \n. ",
    "dflems": "Any updates on this? I'm having a similar issue.\n. Any updates on this? I'm having a similar issue.\n. @Coneko: Thanks. Perhaps it would make more sense to make prebuilt frameworks a first-class citizen? Though they're not particularly favorable, they're probably around to stay. Third-party SDKs frequently ship these as the only integration option.\nMaybe something like this:\npython\napple_prebuilt_framework(\n  name = 'MyFramework',\n  path = 'path/to/MyFramework.framework', # or output of another genrule, etc.\n  frameworks = ['$SDKROOT/System/Library/Frameworks/Foundation.framework'],\n  exported_linker_flags = [],\n  exported_preprocessor_flags = [],\n  exported_deps = [':AnotherFramework'],\n  force_static = False,\n  link_style = 'static', # might need dynamic for OSX? not sure\n  visibility = ['PUBLIC'],\n)\nIMO, it makes sense to make this syntactically closer to apple_library than to prebuilt_cxx_library. Frameworks are an Apple construct and may implicitly require other system frameworks, etc.\n. ",
    "ilya-klyuchnikov": "@zlwen, do you still have problems with windows compilation? I have just checked that buck is built OK on windows.\n. @mattpodwysocki, Visual C++ support is work in progress right now.\n. here is the possible solution: https://github.com/ilya-klyuchnikov/buck/commit/861cd1a7ed31a7f9b76794d8f293df8db7eff2e7. Travis in container mode is jealous about resources (especially when multiple JVMs are running). The idea is to run the heaviest tests in a single thread mode. The corresponding successful run is: https://travis-ci.org/ilya-klyuchnikov/buck/builds/240916902. Buck on windows is not supposed/prepared to work with UNC paths in general. Do you really need to put selenium on UNC path here?\nTwo workarounds for this particular build:\n1. Clone selenium into c:\\selenium, not into c:\\vagrant\\selenium OR\n2. I you use c:\\vagrant\\selenium - run c:\\buck\\bin\\buck build //java/client/src/org/openqa/selenium/security:security -c log.chrome_trace_generation=no\nThe reason is that buck on windows use hardlinks (symlinks on windows is not so easy in general case because of setting this up correctly with privileges). And hardlinks do not work with UNC paths. In particular, chrome-like trace generation (which is on by default) uses links. Passing -c log.chrome_trace_generation=no turns off this tracing.. Buck does support native code compilation on Windows. But you have to specify VS toolchain explicitly. See examples in https://github.com/ilya-klyuchnikov/buck-windows-cxx. Or you can run buck from VS dev console - then it will pick up cl.exe, link.exe, etc automatically.. I failed to reproduce it. @jeeloo could you run the following command in Powershell Get-WmiObject Win32_Process -filter \"CommandLine like 'buckd%'\" and put the output here?. @jeeloo could you try https://github.com/ilya-klyuchnikov/buck/commit/c2a8dcbedf2a63a1f591cc4e33a70fdaa4bdacbd? Thanks. According to your logs you have Windows 7 Enterprise. \nInternally, buckd on windows uses windows named pipes for communication between client/server. We are testing/supporting it only on Windows 10 reliably so far. It is quite possible that we hit default system settings when we create named pipes and these settings are forbidding to create named pipes on your machine. \nI am sorry, but we don't have any bandwidth to investigate/fix it right now. \nYou could enable NO_BUCKD=1 system var, and use buck without daemon.. I tracked the root cause: nailgun-server doesn't start correctly on appveyor (via named pipes). However, we never experience this when testing internally. A further investigation is needed.. Update: the root cause is that appveyor has its own (incompatible with what we use) jna libraries (tracked by this run of nailgun: https://ci.appveyor.com/project/ilya-klyuchnikov/nailgun/build/b10/artifacts). \nThis is the simple fix:  https://github.com/ilya-klyuchnikov/buck/commit/f1f7fa50af44ccddfb01ae48616be6ea18361c5d (and corresponding CI: https://ci.appveyor.com/project/ilya-klyuchnikov/buck-07nvh/build/6).\nI will land the fix next week.. landed:     1a039d5. We are not going to support android development on windows in the nearest future. The biggest problem is ndk (changing commands to be with .exe on windows, but the biggest sub-problem is that we use argfiles for ndk and how we do it doesn't work on windows).. prebuilt_cxx_library is not supported on windows, but prebuilt_cxx_library_group is supported. Could you switch to prebuilt_cxx_library_group?. Basically, I agree with @brettwooldridge that now the behavior of NuProcess on windows is correct and is aligned with mac and linux. I will look into buck on windows problems soon. @brettwooldridge - I am leaving it to @styurin. (Basically, we have found some problems with our tooling for testing on windows, but not problems with buck on windows - it just takes some time to deploy the newer version of our tooling internally, launch tests again, etc). @brettwooldridge - I am leaving it to @styurin. (Basically, we have found some problems with our tooling for testing on windows, but not problems with buck on windows - it just takes some time to deploy the newer version of our tooling internally, launch tests again, etc). We consider precompiled headers as an anti-pattern (they are not hermetic - see https://github.com/bazelbuild/bazel/issues/1215). We do have precompiled headers only for historical reasons - and the implementation is rather non-trivial - we do not cache them (because of non-determinism).. @shybovycha - are windows precompiled headers deterministic/hermetic? Does cl.exe produce byte-to-byte identical output? Simple unit test is a weak proof. An integration test is anticipated (see WindowsCxxIntegrationTest).. At appvoyer Path ends with the space (unfortunately). Then a java Path object is constructed. It is illegal to have trailing spaces in file names on windows.\n. http://www.dostips.com/DtTipsStringManipulation.php#Snippets.Remove\nThe subtlety is that C:\\go\\bin may be in the end of the path or in the middle, that is why I have two cases here.\n. ",
    "achieverForever": "Thanks for your information, I will check it out.\n. Thanks for your information, I will check it out.\n. ",
    "tcyrus": "@Coneko \n$ java -version\njava version \"1.8.0_71\"\nJava(TM) SE Runtime Environment (build 1.8.0_71-b15)\nJava HotSpot(TM) 64-Bit Server VM (build 25.71-b15, mixed mode)\n. @Coneko \n$ java -version\njava version \"1.8.0_71\"\nJava(TM) SE Runtime Environment (build 1.8.0_71-b15)\nJava HotSpot(TM) 64-Bit Server VM (build 25.71-b15, mixed mode)\n. ",
    "ExtremeMan": "I don't think it is actually related to that issue. The error says that you most likely used newer deployment target sdk when building a test bundle.. I don't think it is actually related to that issue. The error says that you most likely used newer deployment target sdk when building a test bundle.. ",
    "rmaz": "You are probably right, I dont have the sample project around any more to check. Variants fixes this. Adding the asset_catalog as a dependency of the apple_binary instead of the apple_bundle seems to work however.\n. Adding the asset_catalog as a dependency of the apple_binary instead of the apple_bundle seems to work however.\n. Seems like this is causing some issues on a more complex project of ours, need to take another look at this.\n. Configured as:\n```\napple_bundle(\n  name = 'AppBundle',\n  binary = ':AppBinary',\n  extension = 'app',\n  info_plist = 'Info.plist',\n  deps = [\n    ':WatchAppExtension',\n  ],\n)\napple_binary(\n  name = 'AppBinary',\n  headers = glob([\n    ...\n  ]),\n  srcs = [\n    ...\n  ]),\n)\napple_bundle(\n  name = 'WatchAppExtension',\n  binary = ':WatchAppExtensionBinary',\n  extension = 'appex',\n  xcode_product_type = 'com.apple.product-type.watchkit-extension',\n  info_plist = 'WatchExtensionInfo.plist',\n  deps = [\n    ':WatchApp#legacy_watch',\n  ],\n)\napple_binary(\n  name = 'WatchAppExtensionBinary',\n  headers = glob([\n    ...\n  ]),\n  srcs = glob([\n   ...\n  ]),\n)\napple_bundle(\n  name = 'WatchApp',\n  extension = 'app',\n  binary = ':WatchAppBinary',\n  xcode_product_type = 'com.apple.product-type.application.watchapp',\n  info_plist = 'WatchAppInfo.plist',\n)\napple_binary(\n  name = 'WatchAppBinary',\n)\n```\n. Configured as:\n```\napple_bundle(\n  name = 'AppBundle',\n  binary = ':AppBinary',\n  extension = 'app',\n  info_plist = 'Info.plist',\n  deps = [\n    ':WatchAppExtension',\n  ],\n)\napple_binary(\n  name = 'AppBinary',\n  headers = glob([\n    ...\n  ]),\n  srcs = [\n    ...\n  ]),\n)\napple_bundle(\n  name = 'WatchAppExtension',\n  binary = ':WatchAppExtensionBinary',\n  extension = 'appex',\n  xcode_product_type = 'com.apple.product-type.watchkit-extension',\n  info_plist = 'WatchExtensionInfo.plist',\n  deps = [\n    ':WatchApp#legacy_watch',\n  ],\n)\napple_binary(\n  name = 'WatchAppExtensionBinary',\n  headers = glob([\n    ...\n  ]),\n  srcs = glob([\n   ...\n  ]),\n)\napple_bundle(\n  name = 'WatchApp',\n  extension = 'app',\n  binary = ':WatchAppBinary',\n  xcode_product_type = 'com.apple.product-type.application.watchapp',\n  info_plist = 'WatchAppInfo.plist',\n)\napple_binary(\n  name = 'WatchAppBinary',\n)\n```\n. @ryu2 Not sure if the issue is related, but when codesigning a legacy watch app with a single arch, the app fails to install with:\nWatchApp did not match stub hash for cputype 12 cpusubtype 12: <7c0a6be2 87af00ca e5eb9885 7f7c0085 4a8920e9> != <fc4d6073 3d8b1846 54e9c4f8 f5e72988 fbf1d029>\n. Awesome, any idea of a rough eta? Cheers.\n. Nice one, seems to have fixed our code signing woes, cheers.\n. Easy fix, I'll try and get a PR up tomo.\n. I've done a bit of digging on this, it does appear that Xcode uses a similar approach with a blacklist of keys not to merge into the entitlements file. The list seems to include:\ncom.apple.developer.icloud-container-development-container-identifiers\ncom.apple.developer.icloud-container-environment\ncom.apple.developer.icloud-container-identifiers\ncom.apple.developer.icloud-services\ncom.apple.developer.restricted-resource-mode\ncom.apple.developer.ubiquity-container-identifiers\ncom.apple.developer.ubiquity-kvstore-identifier\ninter-app-audio\ncom.apple.developer.homekit\ncom.apple.developer.healthkit\ncom.apple.developer.in-app-payments\ncom.apple.developer.associated-domains\ncom.apple.security.application-groups\ncom.apple.developer.maps\ncom.apple.developer.networking.vpn.api\ncom.apple.external-accessory.wireless-configuration\nThe behaviour is complex enough that it seems pretty risky trying to replicate it inside buck itself. Perhaps a wrapper around the system entitlements merging code is the best approach here?\n. Yes, this is unfortunate. I have tracked down the class that does most of the heavy lifting, it is in an Xcode framework: https://github.com/luisobo/Xcode-RuntimeHeaders/blob/master/IDEFoundation/IDEArchivePackagerEntitlementsMerger.h\nSo the options we have are:\n- Wrap this framework in a command line tool that we optionally build when we have a Mac host\n- Reimplement its logic in buck\nI was leaning towards the first approach and using JNI to invoke the framework, but this seems to be impossible due to the way that the rpath has been setup for the framework, it would require manually loading every single dependent framework as it seems runpath search flags are not correctly passed down to the JNI framework. Wrapping this in a C tool is still an option, and probably the safest course if a bit fiddly.\nOtherwise we just work out what it is doing and replicate the logic, but it is unfortunately doing quite a lot more than you would expect, including adding in defaults, replacing wildcards, blacklisting a whole bunch of keys (which presumably change with every tooling upgrade) and doing some verification of some of the keys.\nI think in the short term we should take the second approach and look to make this more solid down the line, thoughts?\n. OK, I added a blacklist to filter out invalid keys for now. There is also some validation behaviour that I left out, but from what I can tell this is to do with $(TeamIdentifier) variable substitution that doesn't work with buck anyway, so seems safe to leave out for now.\n. It looks like buckd is the magic making this work, but we cannot run this on our CI architecture currently.\n. I'm going to close this one for now, we have got buckd working on our CI machines. I am not sure if this setting makes sense in .buckconfig though, it seems like something that shouldn't be customisable. Maybe when buckd is not enabled there should be no timeout? Or at least the task should run until at least some %age of the cache has been cleaned?\n. @Coneko the umbrella header generation is part of this PR because without it Xcode will generate warnings and will not correctly generate a module map for the framework.\nThis is lacking a lot of tests and some cleanup, but is fully functional at this point. It would be great to get some feedback on this general approach before I start sinking some time into cleaning this up. The worst part here IMO is the framework flavour propagation, which takes a large amount of very ugly special casing. If you have any suggestions about better ways to implement this I am all ears.\n. @Coneko the umbrella header generation is part of this PR because without it Xcode will generate warnings and will not correctly generate a module map for the framework.\nThis is lacking a lot of tests and some cleanup, but is fully functional at this point. It would be great to get some feedback on this general approach before I start sinking some time into cleaning this up. The worst part here IMO is the framework flavour propagation, which takes a large amount of very ugly special casing. If you have any suggestions about better ways to implement this I am all ears.\n. This is still very much a WIP while we work out the bugs. The performance profile of the isFramework method is currently O(n^2), but we will eventually implement this as a single pass tree traversal and cache the data we need rather than walking up potentially the entire target graph every time we need to know if this is a framework or not, which will bring us back to O(n). This should give us acceptable performance and allow for general metadata collection for all target nodes that require flavour propagation.\n. Whoops, thought I had run that one. Updated.. I had a quick look to see if there was a simple way to resolve this, but I could not find a decent integration point to fetch the output location to put the symbol map in. It feels like bitcode enabling and hiding should be handled by flavours, as it has to handle both compile flag additions and output location aware link flags which cannot be handled in BUCK files directly.. any movement on this one?. Thanks for merging this one in.\n\nIIRC, this was what Xcode adds automatically in its WatchOS builds\n\nThis is what is added automatically by Xcode when archiving, but it also adds a path for the bitcode symbol map to be placed at, which is required. Its equivalent to stripping more or less, but has to happen at link time, so unfortunately is not a great fit for bucks existing strip flavour approach. I could not see an obvious place to add this without adding a whole new flavour, so it seemed more sensible to just omit the flags for now and let users add them for their own release builds. This at least makes it possible to link a watch binary, and matches what users have to do for any iOS app with bitcode enabled.\n\nHowever, if you need to add those flags to the BUCK file in order for a app to pass validation, then we will have to make sure this change doesn't break releases.\n\nI don't believe this is required to pass validation, but desirable for sure. Open to suggestions for the best way of getting this implemented. The same issue applies to all app store apps, not just watch apps, so we should come up with a clean way of handling this in general. IMO the only way to get this done is by adding a bitcode flavour, which we could use to apply the correct compiler and linker flags and output the symbol map next to the dSYM. Then the flavour could be applied separately for release builds, avoiding slowing down debug builds and so on. Thoughts?. Oh, misunderstood the phab import message, rebased now. Oh, misunderstood the phab import message, rebased now. Tricky, looks like all tests requiring code signing have been disabled. I'll just pull out this test for now, doesn't seem possible to validate as this only applies to device builds.. Tricky, looks like all tests requiring code signing have been disabled. I'll just pull out this test for now, doesn't seem possible to validate as this only applies to device builds.. Updated per comments, if you have some preferred naming let me know. Updated per comments, if you have some preferred naming let me know. done, is this what you were after?. Is it possible to build a pex with functionality removed?. Anything contributing significantly to the pex size that we do not use (eg the distbuild command). Just curious if it is easy to build without support for features that we do not use to help with keeping this binary small.. @ryu2 might be another one for you, looks good?. Digging in to the current Xcode implementation, it seems that the behaviour has changed to use a short whitelist instead of a large blacklist. It seems we only need to include:\nbeta-reports-active\nget-task-allow\ncom.apple.developer.team-identifier\ncom.apple.developer.aps-environment. @milend @ryu2 this was a required change to get our app to pass app store validation. We have numerous wildcard entitlements in our production profile that we do not use any more, and merging them fails app store validation. I took a look at the current Xcode entitlements merging code and from what I could see it has changed from a blacklist to a whitelist with only the 4 keys added in this PR merged in. This produced identical signing entitlements between Xcode and buck for our app.. > Though, is the specific com.apple.developer.icloud-container-environment entitlement correctly addressed? It is dynamically added by Xcode during export and is not meant to be part of App Entitlements (or potentially populated with a Development value).\nWe have it set to Production in our app store entitlements file and have been signing fine with Xcode with no warnings. \nUnless this key is set, app store submission would fail in either case. In the current behaviour the following would be merged in to the xcent file:\n<key>com.apple.developer.icloud-container-environment</key>\n<array>\n<string>Development</string>\n<string>Production</string>\n</array>\nThis is not valid and would fail submission. In the new behaviour the key would simply not be present, which is also invalid. I think the only reasonable way to handle this is to put the required value in the entitlements file, how else would buck know what iCloud environment is required at signing time?\n  . > Though, is the specific com.apple.developer.icloud-container-environment entitlement correctly addressed? It is dynamically added by Xcode during export and is not meant to be part of App Entitlements (or potentially populated with a Development value).\nWe have it set to Production in our app store entitlements file and have been signing fine with Xcode with no warnings. \nUnless this key is set, app store submission would fail in either case. In the current behaviour the following would be merged in to the xcent file:\n<key>com.apple.developer.icloud-container-environment</key>\n<array>\n<string>Development</string>\n<string>Production</string>\n</array>\nThis is not valid and would fail submission. In the new behaviour the key would simply not be present, which is also invalid. I think the only reasonable way to handle this is to put the required value in the entitlements file, how else would buck know what iCloud environment is required at signing time?\n  . You are right that it is basically impossible to mimic what Xcode does as it is a moving target with no command line tool we can use to merge entitlements (feel free to file a radar around this to dupe mine). I think the most sensible path here is the most conservative, do the absolute minimum of magic and allow the users to set the entitlements as much as possible. Entitlements and code signing is already different enough in buck that it doesn't seem a big deal to add keys you wouldn't normally have to to get an app to pass validation, definitely preferred to the case where your entitlements are forcibly merged incorrectly making it impossible to submit an app to the store.. You are right that it is basically impossible to mimic what Xcode does as it is a moving target with no command line tool we can use to merge entitlements (feel free to file a radar around this to dupe mine). I think the most sensible path here is the most conservative, do the absolute minimum of magic and allow the users to set the entitlements as much as possible. Entitlements and code signing is already different enough in buck that it doesn't seem a big deal to add keys you wouldn't normally have to to get an app to pass validation, definitely preferred to the case where your entitlements are forcibly merged incorrectly making it impossible to submit an app to the store.. @milend any chance you could review this one? thanks. @milend thanks for pushing this through.\n\nDid you test your PR with your latest changes? Does it produce the same output as Xcode?\n\nI just checked with the latest change, yes, we have the same entitlements for our app with embedded watch app and extensions.. Updating shortly with optimisation flag fixes.. > In this case I might want to put all three frameworks directly under the App bundle, whereas (correct me if I'm wrong) your changes would cause Framework3 to be embedded in both Framework1 and Framework2.\nAre these all prebuilt frameworks? In that case they will be embedded in the first containing bundle (ie App).. > In this case I might want to put all three frameworks directly under the App bundle, whereas (correct me if I'm wrong) your changes would cause Framework3 to be embedded in both Framework1 and Framework2.\nAre these all prebuilt frameworks? In that case they will be embedded in the first containing bundle (ie App).. Thanks for the detailed comment. I had not noticed the UUIDs were being scrubbed, that definitely changes things. I'll take a closer look at this and update the PR. What is interesting about the issue is that it only occurred for a single architecture of a fat binary, need to think about what could cause that.\n\nI think the right way of fixing this is not actually disabling the ability to cache the CxxStrip, this will mitigate an actual issue for you but the root won't be touched.\n\nYou are right when it comes to fixing this bug, but I think it still makes sense to not cache stripped binaries and fat binaries for the same reason that it makes sense to not cache linked binaries in the first place. That can be a separate PR though.. > This happens in LcUuidContentsScrubber which replaces UUID with a hash of file contents I think\nIt seems the scrubber is using the contents of the load commands up to the LC_UUID load command to generate the replacement hash value. Is this deterministic? \n\nIt could also be an issue with actually just updating an already present AppleBundle inside buck-out: AppleBundle uses cp -R to copy its binary/dSYM into a new place inside itself, and if the binary/dSYM are already in place, cp -R will silently ignore this and keep copying. Apparently it does not override the destination.\n\nThis seemed like a likely explanation, but looking at the code this eventually passes down to Files.copy(resolve(source), resolve(target), StandardCopyOption.REPLACE_EXISTING), so should be overwriting the destination by default. \n\nIt could be that AppleBundle depends on a different AppleDebuggableBinary, which effectively means that there are two CxxLink rules are being invoked.\n\nI'm not entirely clear on what you mean with this one. The issue we had was caused by the cached multiarch binary having a different UUID to the cached dSYM. In what case could these not match up correctly?. > This happens in LcUuidContentsScrubber which replaces UUID with a hash of file contents I think\nIt seems the scrubber is using the contents of the load commands up to the LC_UUID load command to generate the replacement hash value. Is this deterministic? \n\nIt could also be an issue with actually just updating an already present AppleBundle inside buck-out: AppleBundle uses cp -R to copy its binary/dSYM into a new place inside itself, and if the binary/dSYM are already in place, cp -R will silently ignore this and keep copying. Apparently it does not override the destination.\n\nThis seemed like a likely explanation, but looking at the code this eventually passes down to Files.copy(resolve(source), resolve(target), StandardCopyOption.REPLACE_EXISTING), so should be overwriting the destination by default. \n\nIt could be that AppleBundle depends on a different AppleDebuggableBinary, which effectively means that there are two CxxLink rules are being invoked.\n\nI'm not entirely clear on what you mean with this one. The issue we had was caused by the cached multiarch binary having a different UUID to the cached dSYM. In what case could these not match up correctly?. > I think it hashes the whole file contents\nAh, I see, it hashes everything except the UUID, makes sense. Isn't this more or less what the UUID is in the first place incidentally? The linker uses md5 though and seems to skip some binary sections that contain timestamps and other variable bits. Might be worth sticking with the linkers UUID as it seems more deterministic potentially?\n https://opensource.apple.com/source/ld64/ld64-253.6/src/ld/OutputFile.cpp.auto.html\n\nAppleBundle uses CopyStep.forFile which delegates to cp shell command which seems to be not overriding the file if it exists.\n\nDoes it actually delegate? I thought those getDescription calls were just to output something useful in the logs. The execute method calls filesystem.copy. Regardless, cp will always override its destination file unless -n is passed.\n\nit could be that you're experiencing a situation when AppleBundle correctly overwrites dSYM but fails to update binary file inside bundle folder, leading to the situation when UUIDs mismatch\n\nFor the builds in question the buck-out folder is always wiped at the start of the run, so I don't think this can be the issue in our case. It seems more like we have a rulekey matching a binary that has a different UUID to a rebuilt binary with the same input. Potentially this is caused by hashing the entire contents of the binary when some flags are present? eg embedded bitcode and so on. Maybe we should be removing the UUID scrubbing step entirely, it seems like the linker is going a decent job of this anyway. Either that or match its behaviour, but this is more difficult as Apple tends to be a bit tardy releasing the source of their build tools, so we would miss any added functionality for newer Xcodes for a year or so.\nThoughts?. > Also, I wonder when have you started experiencing this issue? Could it be related to a recent Apple toolchain/Xcode updates?\nI would like to say that we noticed this straight away, but TBH this could have been happening for years (ever?), we only discovered it recently by accident. We would have to dig through the build archives to know for sure.\n\nPerhaps you could try and investigate why rule key is the same for the binaries with different UUIDs.\n\nI will try and script this to see if I can repro locally. . Also fine with just doing isCacheable( return false; ), or filtering for Apple platforms or something equivalent. . This requires further changes, in its current state this makes the problem even worse as the dSYM itself is getting cached but none of the binaries are.. Looks like this has been partially added in f6ab94c0f15c14b08e16e82ec955b9633abe7d10. I'll put up a new PR with the additional pieces of not caching fat binaries and dSYMs.. Looks like this has been partially added in f6ab94c0f15c14b08e16e82ec955b9633abe7d10. I'll put up a new PR with the additional pieces of not caching fat binaries and dSYMs.. @williamtwilson any concerns with this one, or good to go?. Tested by rebuilding the same binary a few times and verifying the UUID was the same each time.. Abandoning in favour of #2150 . Abandoning in favour of #2150 . Any updates on this one?. Any updates on this one?. This also needs to be done in ProjectGenerator, this is what we are using internally:\n```\ndiff --git a/src/com/facebook/buck/cxx/toolchain/HeaderSymlinkTreeWithModuleMap.java b/src/com/facebook/buck/cxx/toolchain/HeaderSymlinkTreeWithModuleMap.java\nindex 3cb344149e..a68da1baee 100644\n--- a/src/com/facebook/buck/cxx/toolchain/HeaderSymlinkTreeWithModuleMap.java\n+++ b/src/com/facebook/buck/cxx/toolchain/HeaderSymlinkTreeWithModuleMap.java\n@@ -93,6 +93,11 @@ public final class HeaderSymlinkTreeWithModuleMap extends HeaderSymlinkTree {\n       Path umbrellaHeaderPath = Paths.get(moduleName, moduleName + \".h\");\n       if (!paths.contains(umbrellaHeaderPath)) {\n\n\n// We don't want the swift header in the umbrella header,\n// this creates a circular reference when the swift header\n// references the objc umbrella header. This will be\n// exposed via the module extension instead.\nPath swiftGeneratedHeader = Paths.get(moduleName + \"-Swift.h\");\n             builder.add(\n                 new WriteFileStep(\n                     getProjectFilesystem(),\n@@ -101,6 +106,7 @@ public final class HeaderSymlinkTreeWithModuleMap extends HeaderSymlinkTree {\n                             getLinks()\n                                 .keySet()\n                                 .stream()\n.filter(x -> !x.getFileName().equals(swiftGeneratedHeader))\n                                 .map(x -> x.getFileName().toString())\n                                 .collect(ImmutableList.toImmutableList()))\n                         .render(),\ndiff --git a/src/com/facebook/buck/features/apple/project/ProjectGenerator.java b/src/com/facebook/buck/features/apple/project/ProjectGenerator.java\nindex e88b3c4959..a9d2347cba 100644\n--- a/src/com/facebook/buck/features/apple/project/ProjectGenerator.java\n+++ b/src/com/facebook/buck/features/apple/project/ProjectGenerator.java\n@@ -2756,10 +2756,14 @@ public class ProjectGenerator {\n   private void writeUmbrellaHeaderIfNeeded(\n       String moduleName, ImmutableSortedSet headerPaths, Path headerSymlinkTreeRoot)\n       throws IOException {\n// the -Swift.h header should not be present in the umbrella header\n// this causes a circular reference as the generated header imports the umbrella\nPath swiftHeader = Paths.get(moduleName + \"-Swift.h\");\n     ImmutableList headerPathStrings =\n         headerPaths\n             .stream()\n             .map(Path::getFileName)\n.filter(x -> !x.equals(swiftHeader))\n             .map(Path::toString)\n             .collect(ImmutableList.toImmutableList());\n     if (!headerPathStrings.contains(moduleName + \".h\")) {\ndiff --git a/test/com/facebook/buck/features/apple/project/ProjectGeneratorTest.java b/test/com/facebook/buck/features/apple/project/ProjectGeneratorTest.java\nindex ee0f40e397..fc9c7f0a3a 100644\n--- a/test/com/facebook/buck/features/apple/project/ProjectGeneratorTest.java\n+++ b/test/com/facebook/buck/features/apple/project/ProjectGeneratorTest.java\n@@ -729,7 +729,11 @@ public class ProjectGeneratorTest {\n     List headerSymlinkTrees = projectGenerator.getGeneratedHeaderSymlinkTrees();\n     assertThat(headerSymlinkTrees, hasSize(2));\n     assertEquals(\"buck-out/gen/_p/CwkbTNOBmb-pub\", headerSymlinkTrees.get(0).toString());\nassertTrue(projectFilesystem.isFile(headerSymlinkTrees.get(0).resolve(\"lib/lib.h\")));\n+\nPath umbrellaHeaderPath = headerSymlinkTrees.get(0).resolve(\"lib/lib.h\");\nOptional umbrellaContents = projectFilesystem.readFileIfItExists(umbrellaHeaderPath);\nassertTrue(umbrellaContents.isPresent());\nassertFalse(umbrellaContents.get().contains(\"lib-Swift.h\"));\n   }\n\n@Test\n```\n. This also needs to be done in ProjectGenerator, this is what we are using internally:\n```\ndiff --git a/src/com/facebook/buck/cxx/toolchain/HeaderSymlinkTreeWithModuleMap.java b/src/com/facebook/buck/cxx/toolchain/HeaderSymlinkTreeWithModuleMap.java\nindex 3cb344149e..a68da1baee 100644\n--- a/src/com/facebook/buck/cxx/toolchain/HeaderSymlinkTreeWithModuleMap.java\n+++ b/src/com/facebook/buck/cxx/toolchain/HeaderSymlinkTreeWithModuleMap.java\n@@ -93,6 +93,11 @@ public final class HeaderSymlinkTreeWithModuleMap extends HeaderSymlinkTree {\n       Path umbrellaHeaderPath = Paths.get(moduleName, moduleName + \".h\");\n       if (!paths.contains(umbrellaHeaderPath)) {\n\n\n// We don't want the swift header in the umbrella header,\n// this creates a circular reference when the swift header\n// references the objc umbrella header. This will be\n// exposed via the module extension instead.\nPath swiftGeneratedHeader = Paths.get(moduleName + \"-Swift.h\");\n             builder.add(\n                 new WriteFileStep(\n                     getProjectFilesystem(),\n@@ -101,6 +106,7 @@ public final class HeaderSymlinkTreeWithModuleMap extends HeaderSymlinkTree {\n                             getLinks()\n                                 .keySet()\n                                 .stream()\n.filter(x -> !x.getFileName().equals(swiftGeneratedHeader))\n                                 .map(x -> x.getFileName().toString())\n                                 .collect(ImmutableList.toImmutableList()))\n                         .render(),\ndiff --git a/src/com/facebook/buck/features/apple/project/ProjectGenerator.java b/src/com/facebook/buck/features/apple/project/ProjectGenerator.java\nindex e88b3c4959..a9d2347cba 100644\n--- a/src/com/facebook/buck/features/apple/project/ProjectGenerator.java\n+++ b/src/com/facebook/buck/features/apple/project/ProjectGenerator.java\n@@ -2756,10 +2756,14 @@ public class ProjectGenerator {\n   private void writeUmbrellaHeaderIfNeeded(\n       String moduleName, ImmutableSortedSet headerPaths, Path headerSymlinkTreeRoot)\n       throws IOException {\n// the -Swift.h header should not be present in the umbrella header\n// this causes a circular reference as the generated header imports the umbrella\nPath swiftHeader = Paths.get(moduleName + \"-Swift.h\");\n     ImmutableList headerPathStrings =\n         headerPaths\n             .stream()\n             .map(Path::getFileName)\n.filter(x -> !x.equals(swiftHeader))\n             .map(Path::toString)\n             .collect(ImmutableList.toImmutableList());\n     if (!headerPathStrings.contains(moduleName + \".h\")) {\ndiff --git a/test/com/facebook/buck/features/apple/project/ProjectGeneratorTest.java b/test/com/facebook/buck/features/apple/project/ProjectGeneratorTest.java\nindex ee0f40e397..fc9c7f0a3a 100644\n--- a/test/com/facebook/buck/features/apple/project/ProjectGeneratorTest.java\n+++ b/test/com/facebook/buck/features/apple/project/ProjectGeneratorTest.java\n@@ -729,7 +729,11 @@ public class ProjectGeneratorTest {\n     List headerSymlinkTrees = projectGenerator.getGeneratedHeaderSymlinkTrees();\n     assertThat(headerSymlinkTrees, hasSize(2));\n     assertEquals(\"buck-out/gen/_p/CwkbTNOBmb-pub\", headerSymlinkTrees.get(0).toString());\nassertTrue(projectFilesystem.isFile(headerSymlinkTrees.get(0).resolve(\"lib/lib.h\")));\n+\nPath umbrellaHeaderPath = headerSymlinkTrees.get(0).resolve(\"lib/lib.h\");\nOptional umbrellaContents = projectFilesystem.readFileIfItExists(umbrellaHeaderPath);\nassertTrue(umbrellaContents.isPresent());\nassertFalse(umbrellaContents.get().contains(\"lib-Swift.h\"));\n   }\n\n@Test\n```\n. Side note: probably time to remove watch os1 support, I don't think anyones going to be building any of those any time soon.. Side note: probably time to remove watch os1 support, I don't think anyones going to be building any of those any time soon.. any more needed on this one, or good to go?. any more needed on this one, or good to go?. @williamtwilson another month another gentle ping, let me know if there are any issues with this one. This is going to be used as part of umbrella header generation for building frameworks with buck too, so belongs in a separate class.\n. No, that was a mistake, I've updated this to be a little bit clearer and also to set LD_RUNPATH_SEARCH_PATHS by default.\n. How can I add a test to cover DirsContainingResourceDirs too?. I was a bit confused about DirsContainingResourceDirs, is this only the output of genrules or also other stuff? How can I set up a BUCK config to check this?. If we move this to CopyStep, do you want this to be enabled globally or just for apple bundle resources?. done. I'll wind this one back, I am inclined to agree. The current behaviour is to merge with the application-identifier in the entitlements, yes.. @robbertvanginkel this means we will have collisions if there are multiple files with the same name in a target. Better to store them with BUCK relative paths?. This is missing llvm flags that need to be passed through, so will default of O0. Updated to read from the filelist instead. ",
    "sea36": "Yep, that's fixed the problem. Thank you very much!\n. ",
    "hutm": "is it a reasonable feature request? I was not able to find a way to launch a flavored \"build all\" for cpp project.\n. ",
    "ukreator": "Any way to do that in the latest revisions of Buck?. ",
    "GunNan": "Hi, I have a similar problem when build my app on Windows. \nHere's the log:\n`BUILT 157/161 JOBS 0.9s //:jars__libs\\eup_1.9.14__allproguad_rqdp.jar#dex\nBUILD FAILED: Multiple entries with same key: com\\tencent\\feedback\\proguard\\E.class=HashCodeAndFileType{type=FILE,getHashCode=44cacdc0161040a4916554e84e1ceed1, children=[]} and com\\tencent\\feedback\\proguard\\e.class=HashCodeAndFileType{type=FILE,getHashCode=40bf25f328d1275b1870c8b941239427, children=[]}\njava.lang.IllegalArgumentException: Multiple entries with same key: com\\tencent\\feedback\\proguard\\E.class=HashCodeAndFileType{type=FILE,getHashCode=44cacdc0161040a4916554e84e1ceed1, children=[]} and com\\tencent\\feedback\\proguard\\e.class=HashCodeAndFileType{type=FILE,getHashCode=40bf25f328d1275b1870c8b941239427, children=[]}\njava.lang.IllegalArgumentException: Multiple entries with same key: com\\tencent\\feedback\\proguard\\E.class=HashCodeAndFileType{type=FILE,getHashCode=44cacdc0161040a4916554e84e1ceed1, children=[]} and com\\tencent\\feedback\\proguard\\e.class=HashCodeAndFileType{type=FILE,getHashCode=40bf25f328d1275b1870c8b941239427, children=[]}\nat com.google.common.collect.ImmutableMap.checkNoConflict(ImmutableMap.java:136)\nat com.google.common.collect.RegularImmutableMap.checkNoConflictInKeyBucket(RegularImmutableMap.java:98)\nat com.google.common.collect.RegularImmutableMap.fromEntryArray(RegularImmutableMap.java:84)\nat com.google.common.collect.ImmutableMap$Builder.build(ImmutableMap.java:295)\nat com.facebook.buck.util.cache.JarContentHasher.getContentHashes(JarContentHasher.java:72)\nat com.facebook.buck.util.cache.AbstractHashCodeAndFileType.getContents(AbstractHashCodeAndFileType.java:49)\nat com.facebook.buck.util.cache.HashCodeAndFileType.getContents(HashCodeAndFileType.java:215)\nat com.facebook.buck.util.cache.DefaultFileHashCache.get(DefaultFileHashCache.java:210)\nat com.facebook.buck.util.cache.StackedFileHashCache.get(StackedFileHashCache.java:111)\nat com.facebook.buck.util.cache.StackedFileHashCache.get(StackedFileHashCache.java:111)\nat com.facebook.buck.rules.RuleKeyBuilder.setArchiveMemberPath(RuleKeyBuilder.java:289)\nat com.facebook.buck.rules.keys.DefaultDependencyFileRuleKeyBuilderFactory$BuilderWrapper.addToRuleKey(DefaultDependencyFileRuleKeyBuilderFactory.java:228)\nat com.facebook.buck.rules.keys.DefaultDependencyFileRuleKeyBuilderFactory$DependencyFileRuleKeyBuilder.build(DefaultDependencyFileRuleKeyBuilderFactory.java:167)\nat com.facebook.buck.rules.keys.DefaultDependencyFileRuleKeyBuilderFactory.build(DefaultDependencyFileRuleKeyBuilderFactory.java:64)\nat com.facebook.buck.rules.CachingBuildEngine.calculateDepFileRuleKey(CachingBuildEngine.java:1367)\nat com.facebook.buck.rules.CachingBuildEngine.access$8(CachingBuildEngine.java:1345)\nat com.facebook.buck.rules.CachingBuildEngine$6.apply(CachingBuildEngine.java:616)\nat com.facebook.buck.rules.CachingBuildEngine$6.apply(CachingBuildEngine.java:1)\nat com.facebook.buck.rules.CachingBuildEngine$16.apply(CachingBuildEngine.java:1710)\nat com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\nat com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\nat com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\nat com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\nat com.facebook.buck.util.concurrent.WeightedListeningExecutorService$3.call(WeightedListeningExecutorService.java:102)\nat com.facebook.buck.util.concurrent.WeightedListeningExecutorService$1.apply(WeightedListeningExecutorService.java:65)\nat com.facebook.buck.util.concurrent.WeightedListeningExecutorService$1.apply(WeightedListeningExecutorService.java:1)\nat com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1442)\nat com.google.common.util.concurrent.Futures$AsyncChainingFuture.doTransform(Futures.java:1433)\nat com.google.common.util.concurrent.Futures$AbstractChainingFuture.run(Futures.java:1408)\nat com.google.common.util.concurrent.Futures$2$1.run(Futures.java:1177)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n`\n. hi, I still have problems, and I have put it on the #808. Thanks!\n. ",
    "xiaoaihhh": "@mremick have you solved this problem?  thanks!. I have found SDKROOT = /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk, how can i change it?. Thanks for your reply.\nI have set cxx as follow, but it also didn't work for me. And i can't find keyword \"default _platform\" at Buck website. https://buckbuild.com/concept/buckconfig.html#cxx.\n[cxx]\ndefault_platform = iphonesimulator-x86_64\ncflags = -g\n\u57282016-12-29\uff0cMark Wang notifications@github.com \u5199\u9053:-----\u539f\u59cb\u90ae\u4ef6-----\n \u53d1\u4ef6\u4eba: Mark Wang notifications@github.com\n \u53d1\u9001\u65f6\u95f4: 2016\u5e7412\u670829\u65e5 \u661f\u671f\u56db\n \u6536\u4ef6\u4eba: facebook/buck buck@noreply.github.com\n \u6284\u9001: SwiftlyFly fanshuaifei@tju.edu.cn, Author author@noreply.github.com\n \u4e3b\u9898: Re: [facebook/buck] framework not found UIKit when i build my project (#1070)\nYou'll want to set the config cxx.default_platform to a iOS SDK, e.g. iphonesimulator-x86_64 or iphoneos-arm64 to get Buck to use a iOS SDKROOT.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. The version of Xcode is 8.2.1, and I can build and run a iOS app through Xcode.\nThanks.\n\u57282016-12-29\uff0cMark Wang notifications@github.com \u5199\u9053:-----\u539f\u59cb\u90ae\u4ef6-----\n \u53d1\u4ef6\u4eba: Mark Wang notifications@github.com\n \u53d1\u9001\u65f6\u95f4: 2016\u5e7412\u670829\u65e5 \u661f\u671f\u56db\n \u6536\u4ef6\u4eba: facebook/buck buck@noreply.github.com\n \u6284\u9001: SwiftlyFly fanshuaifei@tju.edu.cn, Author author@noreply.github.com\n \u4e3b\u9898: Re: [facebook/buck] framework not found UIKit when i build my project (#1070)\nWhat version of Xcode are you running?\n Can you build a iOS app normally through Xcode itself?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thank you very much, I have solved my problem. I have installed buck manually before, maybe there is some questions. Now I install it with homebrew, and everything is OK.  \nThank you again for your answer\uff01\n\u57282016-12-29\uff0cMark Wang notifications@github.com \u5199\u9053:-----\u539f\u59cb\u90ae\u4ef6-----\n \u53d1\u4ef6\u4eba: Mark Wang notifications@github.com\n \u53d1\u9001\u65f6\u95f4: 2016\u5e7412\u670829\u65e5 \u661f\u671f\u56db\n \u6536\u4ef6\u4eba: facebook/buck buck@noreply.github.com\n \u6284\u9001: SwiftlyFly fanshuaifei@tju.edu.cn, Author author@noreply.github.com\n \u4e3b\u9898: Re: [facebook/buck] framework not found UIKit when i build my project (#1070)\nWhat version of Xcode are you running?\n Can you build a iOS app normally through Xcode itself?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n.  I am using apple_library, and have set header_namespace = '', but it not worked for me. \nWhen  I am using prebuilt_cxx_library, it worked. I am depressed. \nnow, i found it must  set exported_headers if you want let it work, when i used cxx_library, everything is ok, but when i used apple_library,  it error with message as follow:\nUncaught exception at top level\nBuck\njava.lang.IllegalArgumentException: Multiple entries with same key: Jastor.h=/Users/baidu/Desktop/BuckTech/baidu/searchbox-ios/NewTech/buckboxapp/BBAPods/Parser/Jastor/Jastor.h and Jastor.h=/Users/baidu/Desktop/BuckTech/baidu/searchbox-ios/NewTech/buckboxapp/BBAPods/Parser/Jastor/Jastor.h\nBuck\n    at com.google.common.collect.ImmutableMap.checkNoConflict(ImmutableMap.java:136)\nBuck\n    at com.google.common.collect.ImmutableSortedMap.fromEntries(ImmutableSortedMap.java:348)\nBuck\n    at com.google.common.collect.ImmutableSortedMap.access$100(ImmutableSortedMap.java:57)\nBuck\n    at com.google.common.collect.ImmutableSortedMap$Builder.build(ImmutableSortedMap.java:500)\nBuck\n    at com.facebook.buck.apple.AppleDescriptions.convertAppleHeadersToPrivateCxxHeaders(AppleDescriptions.java:145)\nBuck\n    at com.facebook.buck.apple.AppleDescriptions.populateCxxConstructorArg(AppleDescriptions.java:237)\nBuck\n    at com.facebook.buck.apple.AppleDescriptions.populateCxxLibraryDescriptionArg(AppleDescriptions.java:292)\nBuck\n    at com.facebook.buck.apple.AppleLibraryDescription.requireSingleArchUnstrippedBuildRule(AppleLibraryDescription.java:360)\nBuck\n    at com.facebook.buck.apple.AppleLibraryDescription.requireUnstrippedBuildRule(AppleLibraryDescription.java:338)\nBuck\n    at com.facebook.buck.apple.AppleLibraryDescription.createLibraryBuildRule(AppleLibraryDescription.java:260)\nBuck\n    at com.facebook.buck.apple.AppleLibraryDescription.createBuildRule(AppleLibraryDescription.java:167)\nBuck\n    at com.facebook.buck.apple.AppleLibraryDescription.createBuildRule(AppleLibraryDescription.java:68)\nBuck\n    at com.facebook.buck.rules.DefaultTargetNodeToBuildRuleTransformer.transform(DefaultTargetNodeToBuildRuleTransformer.java:46)\nBuck\n    at com.facebook.buck.rules.BuildRuleResolver.requireRule(BuildRuleResolver.java:136)\nBuck\n    at com.facebook.buck.rules.ActionGraphCache$1.visit(ActionGraphCache.java:152)\nBuck\n    at com.facebook.buck.rules.ActionGraphCache$1.visit(ActionGraphCache.java:147)\nBuck\n    at com.facebook.buck.graph.AbstractBottomUpTraversal.traverse(AbstractBottomUpTraversal.java:36)\nBuck\n    at com.facebook.buck.rules.ActionGraphCache.createActionGraph(ActionGraphCache.java:161)\nBuck\n    at com.facebook.buck.rules.ActionGraphCache.getActionGraph(ActionGraphCache.java:90)\nBuck\n    at com.facebook.buck.cli.BuildCommand.createActionGraphAndResolver(BuildCommand.java:660)\nBuck\n    at com.facebook.buck.cli.BuildCommand.run(BuildCommand.java:409)\nBuck\n    at com.facebook.buck.cli.BuildCommand.runWithoutHelp(BuildCommand.java:352)\nBuck\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:205)\nBuck\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:92)\nBuck\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:1283)\nBuck\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:705)\nBuck\n    at com.facebook.buck.cli.Main.nailMain(Main.java:2056)\nBuck\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nBuck\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nBuck\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nBuck\n    at java.lang.reflect.Method.invoke(Method.java:498)\nBuck\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:338)\n. I had set the binary = ':DemoExtensionLibrary#shared' for the demo but it did not work. The today extension is always show \u201cUnable to Load\u201d message.  It can't load TodayViewController file.. In my project, there is much code like this:\n #ifdef DEBUG\n    NSLog(@\"log\");\n #endif\nNow, I need define preprocessor macros to deal with it. It didn't work if i define marcos in file named DEFS.  I had set DEFS file in buildfile field.  Do you can give me a example how to define it in DEFS file? Thanks.\n. In my project, there is much code like this:\n #ifdef DEBUG\n    NSLog(@\"log\");\n #endif\nNow, I need define preprocessor macros to deal with it. It didn't work if i define marcos in file named DEFS.  I had set DEFS file in buildfile field.  Do you can give me a example how to define it in DEFS file? Thanks.\n. The type of rule is apple_library, the rule define as \napple_library(\n  name = 'example',\n  libraries = [\n    '$SDKROOT/usr/lib/libxml2.dylib',\n  ],\n  visibility = ['PUBLIC'],\n)\nWhen i import the header such as #import <libxml/HTMLparser.h>,HTMLparser.h can't be found. I should adjust header search paths to ${SDKROOT}/usr/include/libxml2 in order to found header files. The default search path is ${SDKROOT}/usr/include.. @Coneko  Assumimg BUCK file at //dir1/dir2,  but i want to adjust header search path to //dir1, what format i should add to exported_preprocessor_flags?  It can be achieved?. I just configured headers in my target, Here is a demo that the error will happen. You can build target //ViewController:ViewController.. I just configured headers in my target, Here is a demo that the error will happen. You can build target //ViewController:ViewController.. For .plist resource, the files field of apple_resource() rule can't be used like this files = glob(['**/*.plist']), , you should  use like this files = glob(['*.plist']),.  This is the reason Why i can't install app.. My app crashed, crass message is EXC_BAD_INSTRUCTION (code=EXC_I386_INVOP, subcode=0x0).. ",
    "janicduplessis": "No I was not, I tried installing watchman version 3.7.0 and now I get this error\nC:\\Users\\janic\\Developer\\react-native>buck fetch ReactAndroid/src/main/java/com/facebook/react\nUsing watchman.\nTraceback (most recent call last):\n  File \"C:\\Users\\janic\\Developer\\buck\\bin\\..\\programs\\buck.py\", line 54, in <module>\n    propagate_failure(main(sys.argv))\n  File \"C:\\Users\\janic\\Developer\\buck\\bin\\..\\programs\\buck.py\", line 47, in main\n    return buck_repo.launch_buck(build_id)\n  File \"C:\\Users\\janic\\Developer\\buck\\programs\\buck_tool.py\", line 124, in launch_buck\n    self.launch_buckd(buck_version_uid=buck_version_uid)\n  File \"C:\\Users\\janic\\Developer\\buck\\programs\\buck_tool.py\", line 251, in launch_buckd\n    env=self._environ_for_buck())\n  File \"C:\\Python27\\lib\\subprocess.py\", line 663, in __init__\n    raise ValueError(\"preexec_fn is not supported on Windows \"\nValueError: preexec_fn is not supported on Windows platforms\n. I made the change you suggested and now I get the first error again.\n```\nC:\\Users\\janic\\Developer\\react-native>buck fetch ReactAndroid/src/main/java/com/facebook/react\nUsing watchman.\nNGServer 0.9.2-SNAPSHOT started on local socket .buckd/sock.\njava.lang.UnsatisfiedLinkError: Error looking up function 'shutdown': The specified procedure could not be found.\n    at com.sun.jna.Function.<init>(Function.java:212)\n    at com.sun.jna.NativeLibrary.getFunction(NativeLibrary.java:541)\n    at com.sun.jna.NativeLibrary.getFunction(NativeLibrary.java:518)\n    at com.sun.jna.NativeLibrary.getFunction(NativeLibrary.java:504)\n    at com.sun.jna.Native.register(Native.java:1655)\n    at com.sun.jna.Native.register(Native.java:1529)\n    at com.sun.jna.Native.register(Native.java:1252)\n    at com.martiansoftware.nailgun.NGUnixDomainSocketLibrary.<clinit>(NGUnixDomainSocketLibrary.java:123)\n    at com.martiansoftware.nailgun.NGUnixDomainServerSocket.<init>(NGUnixDomainServerSocket.java:103)\n    at com.martiansoftware.nailgun.NGUnixDomainServerSocket.<init>(NGUnixDomainServerSocket.java:93)\n    at com.martiansoftware.nailgun.NGServer.run(NGServer.java:428)\n    at java.lang.Thread.run(Thread.java:745)\n\ncom.martiansoftware.nailgun.builtins.NGAlias: 0/0\ncom.martiansoftware.nailgun.builtins.NGClasspath: 0/0\ncom.martiansoftware.nailgun.builtins.NGServerStats: 0/0\ncom.martiansoftware.nailgun.builtins.NGStop: 0/0\ncom.martiansoftware.nailgun.builtins.NGVersion: 0/0\nNGServer shut down.\nWarning raised by BUCK file parser: Traceback (most recent call last):\nWarning raised by BUCK file parser:   File \"C:\\Users\\janic\\Developer\\react-native\\buck-out\\tmp\\buck_run.cnaacg\\buck4074454790671455173.py\", line 2279, in \nWarning raised by BUCK file parser:     main()\nWarning raised by BUCK file parser:   File \"C:\\Users\\janic\\Developer\\react-native\\buck-out\\tmp\\buck_run.cnaacg\\buck4074454790671455173.py\", line 851, in main\nWarning raised by BUCK file parser:     for section, contents in bser.loads(f.read()).iteritems():\nWarning raised by BUCK file parser:   File \"C:/Users/janic/Developer/buck/third-party/py/pywatchman\\pywatchman\\pybser.py\", line 292, in loads\nWarning raised by BUCK file parser:     raise RuntimeError('bser data len != header len')\nWarning raised by BUCK file parser: RuntimeError: bser data len != header len\nWarning raised by BUCK file parser: Traceback (most recent call last):\nWarning raised by BUCK file parser:   File \"C:\\Users\\janic\\Developer\\react-native\\buck-out\\tmp\\buck_run.cnaacg\\buck3303395427419168582.py\", line 2279, in \nWarning raised by BUCK file parser:     main()\nWarning raised by BUCK file parser:   File \"C:\\Users\\janic\\Developer\\react-native\\buck-out\\tmp\\buck_run.cnaacg\\buck3303395427419168582.py\", line 851, in main\nWarning raised by BUCK file parser:     for section, contents in bser.loads(f.read()).iteritems():\nWarning raised by BUCK file parser:   File \"C:/Users/janic/Developer/buck/third-party/py/pywatchman\\pywatchman\\pybser.py\", line 292, in loads\nWarning raised by BUCK file parser:     raise RuntimeError('bser data len != header len')\nWarning raised by BUCK file parser: RuntimeError: bser data len != header len\nParse error for build file C:\\Users\\janic\\Developer\\react-native\\ReactAndroid\\src\\main\\java\\com\\facebook\\react\\BUCK: Parser exited unexpectedly\n```\n. @sdwilsh That solves the watchman / buckd issues but I still get that Parser exited unexpectedly error :(\nbuck fetch ReactAndroid/src/main/java/com/facebook/react\nWarning raised by BUCK file parser: Traceback (most recent call last):\nWarning raised by BUCK file parser:   File \"C:\\Users\\janic\\Developer\\react-native\\buck-out\\tmp\\buck_run.dns0oz\\buck6697034944139676414.py\", line 2279, in <module>\nWarning raised by BUCK file parser:     main()\nWarning raised by BUCK file parser:   File \"C:\\Users\\janic\\Developer\\react-native\\buck-out\\tmp\\buck_run.dns0oz\\buck6697034944139676414.py\", line 851, in main\nWarning raised by BUCK file parser:     for section, contents in bser.loads(f.read()).iteritems():\nWarning raised by BUCK file parser:   File \"C:/Users/janic/Developer/buck/third-party/py/pywatchman\\pywatchman\\pybser.py\", line 292, in loads\nWarning raised by BUCK file parser:     raise RuntimeError('bser data len != header len')\nWarning raised by BUCK file parser: RuntimeError: bser data len != header len\nWarning raised by BUCK file parser: Traceback (most recent call last):\nWarning raised by BUCK file parser:   File \"C:\\Users\\janic\\Developer\\react-native\\buck-out\\tmp\\buck_run.dns0oz\\buck6576104595802619759.py\", line 2279, in <module>\nWarning raised by BUCK file parser:     main()\nWarning raised by BUCK file parser:   File \"C:\\Users\\janic\\Developer\\react-native\\buck-out\\tmp\\buck_run.dns0oz\\buck6576104595802619759.py\", line 851, in main\nWarning raised by BUCK file parser:     for section, contents in bser.loads(f.read()).iteritems():\nWarning raised by BUCK file parser:   File \"C:/Users/janic/Developer/buck/third-party/py/pywatchman\\pywatchman\\pybser.py\", line 292, in loads\nWarning raised by BUCK file parser:     raise RuntimeError('bser data len != header len')\nWarning raised by BUCK file parser: RuntimeError: bser data len != header len\nParse error for build file C:\\Users\\janic\\Developer\\react-native\\ReactAndroid\\src\\main\\java\\com\\facebook\\react\\BUCK: Parser exited unexpectedly\nNot using buckd because NO_BUCKD is set.\n. @wez Any tips on how to get that data? Seems to be happening in a generated script so I can't really just add a print.\n. I can get the string in buf from pybser.py:287 before the RuntimeError is raised. It is 'yandroidtarget'.\n. That should actually be what f.read() returned.\n. 00:01:05:79:00:00:00:01:03:02:02:03:07:61:6e:64:72:6f:69:64:01:03:01:02:03:06:74:61:72:67:65:74:02:03\n. Thanks everyone for the help! :)\nI submitted a PR to fix the last issue so I'll close this.\n. cc @sdwilsh \n. cc @sdwilsh \n. There's already OnDiskMavenDownloaderTest but it tests using a mock unix filesystem so it didn't catch this issue. I can add a test like shouldDownloadFileFromLocalMavenRepo that uses a windows mock filesystem instead or maybe run all the tests in this file on the 3 different file system mocks (unix, osx, windows).\n. There's already OnDiskMavenDownloaderTest but it tests using a mock unix filesystem so it didn't catch this issue. I can add a test like shouldDownloadFileFromLocalMavenRepo that uses a windows mock filesystem instead or maybe run all the tests in this file on the 3 different file system mocks (unix, osx, windows).\n. Does something like this looks good? This new test breaks before my fix.\n. Does something like this looks good? This new test breaks before my fix.\n. There you go!\n. There you go!\n. Oupsi, fixed.\n. Oupsi, fixed.\n. ",
    "mzlee": "So the underlying issue is in the CommandLineTargetNodeSpecParser which doesn't take into account the cross cell. We're currently working on this, and moving away from using '@' to specify the cross cell to prevent the '@' command line functionality from args4j. Instead, you should be able to use jgit//:jgit.\n. I totally agree that there are breaking changes all the time, but I'm just thinking about all of the hardcoded places where this might come up. The platform_preprocessor_flags you've shown is actually unsound, it went from -DFOO=1 on MacOS to -DFOO=2 (I'm assuming you meant '.*' for the default argument).\nThe switch is to be able to stage the rollout and fix things or quickly revert if necessary. I know some places where I hardcode default, but I'm not sure where else they might be lurking.. @ttsugriy https://github.com/facebook/buck/issues/2073 is the announcement issue. I was hoping they'd be automatically linked.. @ttsugriy https://github.com/facebook/buck/issues/2073 is the announcement issue. I was hoping they'd be automatically linked.. ",
    "Nexen23": "Is there any workaround for this (pic of my cmd output)?\nSeems like probably the same error as author has.\n. Is there any workaround for this (pic of my cmd output)?\nSeems like probably the same error as author has.\n. @k21, I haven't done anything. Just git clone then ant then buck --help.\nCan't find any attaching options here, so uploaded .buckconfig here.\nAlso, that bug happed only if I do win+R -> cmd -> cd .... -> buck --help\nIf I run buck directly from its bin folder via shift+mouse right click -> open cmd here -> buck --help - it will use 100% of 1 CPU core forever doing nothing.\n. @k21, I haven't done anything. Just git clone then ant then buck --help.\nCan't find any attaching options here, so uploaded .buckconfig here.\nAlso, that bug happed only if I do win+R -> cmd -> cd .... -> buck --help\nIf I run buck directly from its bin folder via shift+mouse right click -> open cmd here -> buck --help - it will use 100% of 1 CPU core forever doing nothing.\n. ",
    "yiding": "Why did we make AbstractDescriptionArg... all for licenses? that seems a bit silly.\nI'd like this to eventually do something like immutables, so you can include a bunch of interfaces and then the actual record class gets codegenned from all the interface methods.\n. Why did we make AbstractDescriptionArg... all for licenses? that seems a bit silly.\nI'd like this to eventually do something like immutables, so you can include a bunch of interfaces and then the actual record class gets codegenned from all the interface methods.\n. Might want to use -v 9 and/or look into the buck-out/log and buck-out/log/traces to get the actual command line that's used.\n. Might want to use -v 9 and/or look into the buck-out/log and buck-out/log/traces to get the actual command line that's used.\n. I am not working on this, I was just categorizing.. Perhaps @dreiss @asp2insp @jkeljo or @cjhopman . Closed on behalf of @beefon\n. I should have fixed this. Let us know if it crops up again.\n. In the future we'll likely have pre-packaged macros you can invoke to get a basic extension.\nFor now, something like this might get you started:\n```\n  apple_bundle(\n    name = 'FooShareExtension',\n    extension = 'appex',\n    binary = ':FooShareExtensionBinary',\n    info_plist = 'FooShareExtension-Info.plist',\n    xcode_product_type = 'com.apple.product-type.app-extension',\n    linker_flags = [-e', '_NSExtensionMain'],\n    visibility=['PUBLIC'],\n  )\napple_binary(\n    name = 'FooShareExtensionBinary',\n    ... usual stuff ...\n  )\napple_bundle(\n    name = 'FooApp',\n    ... usual stuff ...\n    deps = [\n      ':FooShareExtension',\n    ],\n  )\n```\nFeel free to re-open with more questions.\n. In the future we'll likely have pre-packaged macros you can invoke to get a basic extension.\nFor now, something like this might get you started:\n```\n  apple_bundle(\n    name = 'FooShareExtension',\n    extension = 'appex',\n    binary = ':FooShareExtensionBinary',\n    info_plist = 'FooShareExtension-Info.plist',\n    xcode_product_type = 'com.apple.product-type.app-extension',\n    linker_flags = [-e', '_NSExtensionMain'],\n    visibility=['PUBLIC'],\n  )\napple_binary(\n    name = 'FooShareExtensionBinary',\n    ... usual stuff ...\n  )\napple_bundle(\n    name = 'FooApp',\n    ... usual stuff ...\n    deps = [\n      ':FooShareExtension',\n    ],\n  )\n```\nFeel free to re-open with more questions.\n. Feel free to contribute documentation updates as well. Docs are in the docs/ directory, changes are automatically generated into gh-pages, which goes to the website.\n. Looks like Genrule constructs an environment variable DEPS that contains the output paths of all transitive dependencies. \nAbstractGenruleStep allows this DEPS env var to be set based on a substring check for the string DEPS (ostensibly this is a substring check so that it can be maximally permissive in matching env accessing constructs, e.g. $DEPS %DEPS%). The script triggering this issue happens to have LINT_DEPS, which would match, at which point this huge environment variable gets shoved into the exec call, which fails with E2BIG. \nSince this feature isn't documented anywhere I'll try and delete it in hopes that it's unused. A true macro (that is expanded when generating the script, rather than an environment variable) can implement this behavior if it's needed in the future.\n. Looks like Genrule constructs an environment variable DEPS that contains the output paths of all transitive dependencies. \nAbstractGenruleStep allows this DEPS env var to be set based on a substring check for the string DEPS (ostensibly this is a substring check so that it can be maximally permissive in matching env accessing constructs, e.g. $DEPS %DEPS%). The script triggering this issue happens to have LINT_DEPS, which would match, at which point this huge environment variable gets shoved into the exec call, which fails with E2BIG. \nSince this feature isn't documented anywhere I'll try and delete it in hopes that it's unused. A true macro (that is expanded when generating the script, rather than an environment variable) can implement this behavior if it's needed in the future.\n. The currently logic will clean after you write 'dir_max_size / 2` bytes. Obviously this will reset when buck is restarted. Cleaning is also very slow due to the dir cache basically storing files naively on the file system without any form of index, so it will traverse all the files to get a sense of what's there, then delete the the oldest entries. \n- In the short term an option to clean-on-startup, or a dedicated command to clean dir cache, is useful. \n- In the long term we probably want to re-think the implementation of the directory cache such that cleaning is not a slow monolithic operation.\n. I'm going to revert this diff since adding the repo root to quoted include paths is a very poor way of solving the problem you have here.  Not only does it break invariants and allow rules to access arbitrary headers relative to the root via quoted includes, it doesn't even fix your problem for any case other than when the target is defined at the root of the repo. It will also breaks caching if not for DebugPathSanitizer doing a last-ditch effort to clean up repo roots.\nIf you can give a detailed description of what the problem is, complete with a repro case, I can probably replace this solution with something more sensible.. I think the correct action here is to ensure the include directives in the swiftc generated file follows the pattern of include directives for buck-based apple targets. This might involve a rewrite step in SwiftCompile to rewrite the include directives in the -Swift.h bridging header if swiftc doesn't allow this to be specified manually. Additionally, the input objc bridging header should be added to the exported headers, so that the output -Swift.h bridging header can be accessed from other libraries.\n. I think the correct action here is to ensure the include directives in the swiftc generated file follows the pattern of include directives for buck-based apple targets. This might involve a rewrite step in SwiftCompile to rewrite the include directives in the -Swift.h bridging header if swiftc doesn't allow this to be specified manually. Additionally, the input objc bridging header should be added to the exported headers, so that the output -Swift.h bridging header can be accessed from other libraries.\n. Correct, essentially, SwiftCompile.getBuildSteps will return another step after the compile step which fixes the generated header file.\nHowever do note that this bridging header should either be explicitly or implicitly added to the exported headers of the library in question, so that the inclusion directive actually references a valid file, especially when used from another library.. Correct, essentially, SwiftCompile.getBuildSteps will return another step after the compile step which fixes the generated header file.\nHowever do note that this bridging header should either be explicitly or implicitly added to the exported headers of the library in question, so that the inclusion directive actually references a valid file, especially when used from another library.. Feel free to have a go at it. If you leave it to me who knows when it'll be done.. Feel free to have a go at it. If you leave it to me who knows when it'll be done.. The one we use internally is a bit complex, I'll let @andrewjcg talk about that one if he wants to. \nThe general gist of it (but not an actual gist..):\n\nMake a genrule that includes all the thrift files as srcs...\nThe genrule will invoke fbthrift compiler with each file by itself...\nYou create one genrule per OUTPUT file that was created (since the thrift compiler creates a directory of files). This genrule just copies a file out of that directory and use it as its own output. (We probably want a better way to express this, either in the original genrule or in export_file).\nUsing those genrules representing individual files, you can construct a cxx_library rule with srcs and headers fields filled with those genrule outputs.\n\nIf I get a simple working example code, I'll post it here.. We have open sourced some of the internal buck \npython definitions we use for things like thrift over in the  https://github.com/facebookexperimental/buckit/ repo, check out in particular https://github.com/facebookexperimental/buckit/blob/master/infra_macros/macro_lib/convert/thrift_library.py\n. I think the 'preferred_linkage' flag is required, where \"shared\" means the usual framework, while \"static\" is the not-quite-a-framework-that's-packaged-like-a-framework.\n. I did add some project generation support for the case of real frameworks, where they will be copied into Frameworks/ directory of the bundle, and set various search paths and linker flags, like what you'd get with Xcode \"embedded frameworks\" feature.. Okay seems like it's fine.. Try adding your prebuilt_apple_framework targets directly into the apple_bundle's deps field. I realize this is a bit annoying to do, especially if the app gets bigger, as it seems like this information can be derived automatically...\nCurrently prebuilt_apple_frameworks are not collected from transitive dependencies as the resulting layout is ambiguous and we don't have a good way of specifying it (flatten all frameworks into the top level bundle, nest frameworks into other frameworks, etc). This likely doesn't involve your case of only prebuilt frameworks, but all the code for dealing with framework embedding are entwined and not fully fleshed out. This can probably be improved.\nA note in the docs about this would probably be good too.. The apple_binary might need it in its dependency list as well for linking.\nAs for the error, what version of buck are you using? I fixed this in:\nhttps://github.com/facebook/buck/commit/7cd86eeafd9baa6c8cc7387f490bd99f7bd43af2\nhttps://github.com/facebook/buck/commit/40933eba3a70cf844714442d6f755e0667a497d4. @runningcode I think we are await your response regarding the aforementioned questions.. I think we should either test buck with python 2.6 or drop support for it. Meanwhile, I'll fix this.. > But you're using command which skips over my PATH and chooses first python2, which is 2.6\nCan you elaborate here? command respects your PATH unless -p is given. From the Bash man page:\ncommand [-pVv] command [arg ...]\n       Run command with args  suppressing  the  normal  shell  function\n       lookup.  Only builtin commands or commands found in the PATH are\n       executed.  If the -p option is given, the search for command  is\n       performed  using  a default value for PATH that is guaranteed to\n       find all of the standard utilities.  If  either  the  -V  or  -v\n       option is supplied, a description of command is printed.. Fixed in b2af4022fe7168a4a31571a771ebda426af702eb. . Can this be implemented via wrapper scripts around the compiler, such that compiler invocations can also fork off a linter check? You can also wrap ar and ld to collect these lint outputs. In this manner you can create build+lint without any special build system support. The only issue is that caching of these analysis would not be well supported.. What is \"in-memory compilation\"? . What is \"in-memory compilation\"? . Buck does not do global constraint solving of any kind (except maybe versioned dependencies, which i defer to @andrewjcg ). . Try setting ANDROID_NDK_REPOSITORY to the parent directory of the particular versioned ndk folder, in your case: F:\\TDDownload\\android-ndk-r14b-windows-x86_64\\. I failed to reproduce this behavior on rev db6deb45da0188f542fa1c2f862522e586abc7bf (the current master).\nHere is a terminal transcript of what I did (where ~/buck-oss is my checkout)\n```\n~/tmp/2017-06-27/test\n\u276f ls -a\n.           ..          .buckconfig .buckd      buck-out    foo_test\n~/tmp/2017-06-27/test\n\u276f cat .buckconfig\n[project]\nignore = foo_test/**\n~/tmp/2017-06-27/test\n\u276f ls -l foo_test\ntotal 8\n-rw-r--r--  1 yiding  THEFACEBOOK\\Domain Users  73 Jun 27 16:10 BUCK\n~/tmp/2017-06-27/test\n\u276f cat foo_test/BUCK\ngenrule(\n  name = 'foo',\n  srcs = ['foo.c'],\n  cmd = '''echo $SRCS''',\n)\n~/tmp/2017-06-27/test\n\u276f NO_BUCKD=1 PATH=~/buck-oss/bin:$PATH buck targets --json\nNot using buckd because NO_BUCKD is set.\n[\n]\n``. I tried it with an empty .watchmanconfig, and behavior was still correct.. Your change adds an exclusion fortestwhich ignores that particular path, not paths within that directory. This is contrary to what you reported in your initial post here.. Looks like okbuck creates a.buckconfig.local` which overwrites project.ignore with:\n[project]\n    ignore = .git, **/.svn\nThis is an issue with okbuck, not buck itself.. It seems like https://github.com/facebook/buck/pull/1122 adds documentation for working with android on windows, but I'm not sure how well supported windows actually is, this could very well simply be broken, as we at Facebook do not use windows for developing android. \nGiven the log it seems like buck isn't properly invoking gcc for compiling native bits of the code.\n@ilya-klyuchnikov do you know if this should work?. We should probably update documentation to not talk about android development on windows.. You should specify a config option to set the platform to one that uses xcode's toolchain. The platform \"default\" is a generic unix platform.  \nYou can pass\n--config cxx.default_platform=iphonesimulator-x86_64\nor set in the config file:\n[cxx]\ndefault_platform=iphonesimulator-x86_64\nor pass the platform as a flavor directly to the target\nbuck build //:MyFirstBuckProject#iphonesimulator-x86_64\nYou can get a list of valid platform flavors via:\nbuck audit flavors //:MyFirstBuckProject\nTake note that buck's swift support is very rudimentary, so you might encounter other bugs.\n. You can fix it by constructing your aar file with the correct layout.. *.swift only matches files in the given directory. Your swift files in BuckDemoApp directory were not picked up in the glob.\nSee: https://buckbuild.com/function/glob.html. *.swift only matches files in the given directory. Your swift files in BuckDemoApp directory were not picked up in the glob.\nSee: https://buckbuild.com/function/glob.html. BTW android rules that uses the NDK doesn't currently work properly on windows, so @ilya-klyuchnikov  tells me.. BTW android rules that uses the NDK doesn't currently work properly on windows, so @ilya-klyuchnikov  tells me.. Still has test failures.. per-file flags should come at the end of the command line so it can overwrite earlier flags. The fact that it isn't doing that is a bug and we should fix it. I am fixing it.. Fixed in 5f06d90f3aa9ca5830e4746e5f1515182eb68760.. There's some legit test failures in com.facebook.buck.apple.CompilationDatabaseIntegrationTest. There's some failures that you can see in the \"travis ant\" build. namely ant pmd and google java format stuff. I tried to just fix it internally but the tool keeps overwriting my changes.. There's some failures that you can see in the \"travis ant\" build. namely ant pmd and google java format stuff. I tried to just fix it internally but the tool keeps overwriting my changes.. Yeah, the PMD parser has a bit of trouble with some java 8 stuff.. Yeah, the PMD parser has a bit of trouble with some java 8 stuff.. We use google-java-format now, which sometimes organize imports differently vs intellij: https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style. We use google-java-format now, which sometimes organize imports differently vs intellij: https://github.com/facebook/buck/blob/master/CONTRIBUTING.md#code-style. ant compile-tests gives some compiler errors:\n```\n[javac] 1. ERROR in test/com/facebook/buck/apple/AppleTestDescriptionTest.java (at line 103)\n    [javac]     TargetNode testHostBinaryNode = AppleBinaryBuilder\n    [javac]     ^^^^^^^^^^\n    [javac] TargetNode is a raw type. References to generic type TargetNode should be parameterized\n    [javac] ----------\n[javac] 2. ERROR in test/com/facebook/buck/apple/AppleTestDescriptionTest.java (at line 107)\n    [javac]     TargetNode testHostBundleNode = AppleBundleBuilder\n[javac] 3. ERROR in test/com/facebook/buck/apple/AppleTestDescriptionTest.java (at line 124)\n    [javac]     AppleTest test = (AppleTest) testBuilder.build(resolver, targetGraph);\n    [javac]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    [javac] Unnecessary cast from AppleTest to AppleTest\n``. This could very well be the case. It looks like the code sets the deps correctly (which ensures the.aare built) but does not set the rule key correctly (which ensures that changes to the .a will change the cache key).. This could very well be the case. It looks like the code sets the deps correctly (which ensures the.aare built) but does not set the rule key correctly (which ensures that changes to the .a will change the cache key).. It is not, thanks for reporting this though. There's probably a lot of race conditions I have to work through.. It is not, thanks for reporting this though. There's probably a lot of race conditions I have to work through.. @kageiit I fixed a few issues. If you want you can give it another shot. The option is now:build.action_graph_parallelization=enabled. You can also useexperiment` to do a 50% random sampling (based on hostname/username).\nI'm optimistic about android related rules now, but ios rules will still likely to have problems.. We've been using this for our android builds for a while now without any problems.. We've been using this for our android builds for a while now without any problems.. As you can see in the screenshot, this is used for the FileHashCache, which... caches the hashes of files. There doesn't seem to be an option to disable it though, so if you don't want to spend the memory for this you can probably add an option to build.file_hash_cache_mode to disable it (probably replacing it with a noop cache).\nThe implementation of FileSystemMap doesn't seem very impressive though. There's probably some optimization opportunities for greatly reducing memory usage.. Repro?. Repro?. I think we don't notice it @ facebook because we use watchman, and our watchman config excludes buck-out. It seems like the logic for excluding buck-out for certain operations should be applied in buck directly.. I think we do use watchman on CI. . \"Static\" frameworks are not really supported by apple, and there isn't a built-in method for creating them in buck. The #static flavor simply denotes the archive (.a) output containing the library object files, without transitive includes.\nIf you mean to use this for creating a distributable SDK, I would suggest a shell script involving buck query to get transitive dependencies, a buck build to build them, and using ar or ld -r on the result to generate a large .o or .a.\nIf you want to implement this capability in buck, I would suggest adding a rule which can perform the archive merging or ld -r'ing of a listed set of dependencies, or support a deps_query, as opposed to automatically including all transitives, as that's very rarely how software tends to be packaged, and may lead to duplicate symbols when composing such libraries with common dependencies.. #py3 is not a flavor. The interpreter used is based purely on the platform attribute of the binary/test rule.\nThe error when you tried is due to the fact that that support file is not re-extracted into buck-out/res if you delete the directory, and don't restart buck. As nuking buck-out is not a rare operation, that behavior should probably be changed.. I believe this means that you have references to resources without corresponding definitions.. I believe this means that you have references to resources without corresponding definitions.. @ryu2 do you recall why you set these flags? your commit did not provide any rationale for these flags.. @ryu2 do you recall why you set these flags? your commit did not provide any rationale for these flags.. Have you looked at using the ddplist library, which buck already uses to write plists for the xcode project generator, to read and write the plist files? It should support binary plists.\nI would rather use that instead of a system utility.. Have you looked at using the ddplist library, which buck already uses to write plists for the xcode project generator, to read and write the plist files? It should support binary plists.\nI would rather use that instead of a system utility.. How about you add the braces hack as described, and open a github issue on https://github.com/3breadt/dd-plist, so that we can update our dd-plist library if/when this is supported?. How about you add the braces hack as described, and open a github issue on https://github.com/3breadt/dd-plist, so that we can update our dd-plist library if/when this is supported?. I'm okay with this hack.. I'm okay with this hack.. It's probably best to pass version-min set via buckconfig to swift compiler as well so the behavior is consistent. @milend and @robbertvanginkel are familiar with buck's swift integration.. I agree that it doesn't make sense for private headers to be exported in the module map. If a test wants to do whitebox testing over the libraries, it should just include the headers in the test rule directly. If swift targets support multiple header maps, we might be able to create two of them, one for public and one for private headers. I don't know if that's possible, and it's not something I'm looking at.\n. I agree that it doesn't make sense for private headers to be exported in the module map. If a test wants to do whitebox testing over the libraries, it should just include the headers in the test rule directly. If swift targets support multiple header maps, we might be able to create two of them, one for public and one for private headers. I don't know if that's possible, and it's not something I'm looking at.\n. Is this in line with the behavior of test bundles generated with buck during buck build?. Is this in line with the behavior of test bundles generated with buck during buck build?. It seems like the changes here does more than merely strip unused architectures and other misc files. Namely, it's also changing which prebuilt frameworks are embedded. Is this intentional? If so, can you update the message to reflect that?\nStripping unneeded files and arches is good. My main concern is with the recursive traversal for finding frameworks to embed. This takes away some control over how an app bundle is laid out, since previously embedding is controlled directly by making the framework a dependency of the bundle.\nNamely, consider this situation of \"diamond\" framework dependencies:\nApp -> Framework1\nApp -> Framework2\nFramework1 -> Framework3\nFramework2 -> Framework3\nIn this case I might want to put all three frameworks directly under the App bundle, whereas (correct me if I'm wrong) your changes would cause Framework3 to be embedded in both Framework1 and Framework2.. It seems like the changes here does more than merely strip unused architectures and other misc files. Namely, it's also changing which prebuilt frameworks are embedded. Is this intentional? If so, can you update the message to reflect that?\nStripping unneeded files and arches is good. My main concern is with the recursive traversal for finding frameworks to embed. This takes away some control over how an app bundle is laid out, since previously embedding is controlled directly by making the framework a dependency of the bundle.\nNamely, consider this situation of \"diamond\" framework dependencies:\nApp -> Framework1\nApp -> Framework2\nFramework1 -> Framework3\nFramework2 -> Framework3\nIn this case I might want to put all three frameworks directly under the App bundle, whereas (correct me if I'm wrong) your changes would cause Framework3 to be embedded in both Framework1 and Framework2.. If that's how the code works it should be fine. Someone on the buck team should probably import this and test to make sure it doesn't break for our internal apps which relies on this property.. If a bundle depends on another bundle (for instance, an app bundle with an app extension bundle as dependecy), this method is reached via createAppleBundle() -> AppleBundle.createMetadata() -> AppleBinary.createMetadata(), the platform flavor may not be set on this build target because a user doesn't usually annotate a bundle's binary parameter with a pre-existing platform.\nAlso not sure how this takes into account of multiarch files.. This error message should just print the full build target. I encountered a case where if the build target has no flavors, it just prints a message \"Could not find cxx platform in:\" which is entirely unhelpful.. \"build tool\" is the correct term here, not \"building tool\".. Headings delimit sections. Explicit horizontal rules are presentation markup which isn't really necessary here.. These images don't add anything and aren't necessary.\nWe are not an apache project so adding an ASF logo doesn't even make sense.. Do you think it would make sense to run the the plist through plutil either way? This way any comments can still be stripped.. ",
    "artemyarulin": "Hm, thanks, probably I've missed this from the docs\n. Ahh, OK - I was thinking that all those commands are just Python function calls and I'm free to do usual Python staff here: named, not named arguments, etc.\n. ",
    "bviktor": "Just a headsup: the latest Win10 builds will support non-elevated symlinking as well:\nhttps://blogs.windows.com/buildingapps/2016/12/02/symlinks-windows-10/\nNot to mention that Bash is also integrated now, so 2 points are eliminated by MS, the rest is up to Buck devs (docs, path separators, test coverage).. Just a headsup: the latest Win10 builds will support non-elevated symlinking as well:\nhttps://blogs.windows.com/buildingapps/2016/12/02/symlinks-windows-10/\nNot to mention that Bash is also integrated now, so 2 points are eliminated by MS, the rest is up to Buck devs (docs, path separators, test coverage).. Yeah, cool, didn't work for me for gerrit plugins, and all they had to say to me was that \"Buck doesn't support Windows, don't bother\".. ",
    "ray-milkey": "This is not a new file, I just added a Test method to an existing one, so the year in the comment should be correct.\n. Ah sorry, I was looking at the java test file, not the resource. I'll fix it.\n. OK the year in the copy right notice is updated.\n. ",
    "gaozhenpeng": "help me \n When running a \" buck build :conceal_android\" i get message is  \"BUILD FAILED: Failed to read NDK version from /home/Android/Sdk/ndk-bundle\"\nhow do?\n. ",
    "flopex": "It seems that buck depends on the file RELEASE.TXT to exist under the ANDROID_NDK path. See https://github.com/facebook/buck/blob/master/src/com/facebook/buck/android/DefaultAndroidDirectoryResolver.java#L125\nTo \"fix\" this just add the file RELEASE.TXT to the ANDROID_NDK path with the following contents\nExample: /opt/android-ndk-r11c/RELEASE.TXT\nr11c (64-bit)\n. ",
    "vigilancer": "@flopex, thanks\n[ndk] thingy works for project build, but to install buck one still need to make ln -s.\n. @Coneko, I ment installing Buck afresh with brew install. \nMaybe there is a way to specify gcc_version at install time I'm not aware of.\n. @Coneko \nI suppose my problem relate to this issue. \nIf you do not agree I'll move description to new issue.\nUntil than, here it is:\n$brew uninstall buck\n$brew update && brew upgrade --all\n$brew info android-ndk\nandroid-ndk: stable r11c\n...\n$brew install buck\n==> Installing buck from facebook/fb\n==> Downloading https://api.github.com/repos/facebook/buck/tarball/v2016.03.28.01\nAlready downloaded: /Library/Caches/Homebrew/buck-2016.03.28.01.01\n==> ant\n==> ./bin/buck build buck\nLast 15 lines from /Users/developer/Library/Logs/Homebrew/buck/02.buck:\n        at com.facebook.buck.rules.KnownBuildRuleTypes.createBuilder(KnownBuildRuleTypes.java:352)\n        at com.facebook.buck.rules.KnownBuildRuleTypes.createInstance(KnownBuildRuleTypes.java:226)\n        at com.facebook.buck.rules.KnownBuildRuleTypesFactory.create(KnownBuildRuleTypesFactory.java:49)\n        at com.facebook.buck.rules.Cell.(Cell.java:120)\n        at com.facebook.buck.rules.Cell.createCell(Cell.java:182)\n        at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:779)\n        at com.facebook.buck.cli.Main.tryRunMainWithExitCode(Main.java:1467)\n        at com.facebook.buck.cli.Main.runMainThenExit(Main.java:1552)\n        at com.facebook.buck.cli.Main.main(Main.java:1570)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:497)\n        at com.facebook.buck.cli.bootstrapper.ClassLoaderBootstrapper.main(ClassLoaderBootstrapper.java:62)\n\nWorkaround is to create and edit RELEASE.TXT and ln -s arm-linux-androideabi-4.9 arm-linux-androideabi-4.8 as @flopex suggested.\n. ",
    "alisdair04": "@facebook-github-bot shipit\n. @facebook-github-bot shipit\n. @facebook-github-bot shipit\n. Please could you rebase (to get travis working) and fix the following test:\nTESTS FAILED: 1 FAILURE\nFailed target: //test/com/facebook/buck/android:unit\nFAIL com.facebook.buck.android.GenAidlTest\n[Tue, 19 Apr 2016 10:33:37 -0700] Step \"Testing with Buck\" failed with: Summary (beta): \nFAILURE com.facebook.buck.android.GenAidlTest testSimpleGenAidlRule: gen_aidl() should use the aidl binary to write .java files. expected:<...usr/local/bin/aidl -[b -]p/home/root/android/...> but was:<...usr/local/bin/aidl -[]p/home/root/android/...>\n. https://buckbuild.com/rule/apple_library.html. ",
    "bocon13": "@sdwilsh No worries! Thanks\n. I have pushed a new commit that simplifies the implementation by using String manipulation instead of Path manipulation because I was worried that the Path-based implementation might be causing a test failure in TravisCI (which was not reproducible locally).\n. Ping... it's been a few weeks; just wanted to see what the status is on this pull request.\nThanks!\n. @marcinkosiba Ah, I see. Thanks for the update!\nLet me know if I can be of any assistance.\n. @Coneko Yes, 83a0d0ab08f975d79933ab1da9942e17810b6e71 fixes the issue. I am not sure exactly how, though. I will close this issue and the associated pull request. Thanks!\n. fixed by 83a0d0ab08f975d79933ab1da9942e17810b6e71\n. @sdwilsh The artifact type (extension) and classifier are not explicitly omitted from the expander. I can extend the documentation to contain the full format.\n. It seems like the {literal} tag blocks HTML escaping, and that < and > are not auto-escaped within the HTML template without {literal}. However, we can make things more readable with a {let} block, which should render/escape the angle brackets on replacement. I will push an update.\n. ",
    "Dominator008": "@k21 Hmmm. I can't reproduce it either. I guess buck audit is fine then. We removed the JGit cell for now so some state of the project might have changed on my machine. Commands like:\nsh\nbuck build //lib/jgit/org.eclipse.jgit:jgit__download_bin\nstill throw an exception, but that's part of the reported issue. \n. @davido I'd expect a clear error message instead of an exception.\n. Thanks. Fixed.\n. Done.\n. ",
    "borgstrom": "PS.  I would have submitted a PR for this normally, but I didn't want to jump through the hoops of signing a CLA for such a small fix.  If it would expedite the fix let me know and I'll schedule some time to review the agreement in better detail.\n. PS.  I would have submitted a PR for this normally, but I didn't want to jump through the hoops of signing a CLA for such a small fix.  If it would expedite the fix let me know and I'll schedule some time to review the agreement in better detail.\n. Those check failures don't look to be related to my changes.  In both cases it seems java was killed with signal 9 while running java tests.\n. Those check failures don't look to be related to my changes.  In both cases it seems java was killed with signal 9 while running java tests.\n. @sdwilsh I did that already.\n. @sdwilsh I did that already.\n. All good.  Thanks for looking :)\n. All good.  Thanks for looking :)\n. @mikekap @sdwilsh -- python prebuilt test updated.\nI commented out the the copy_package call to add _markerlib and confirmed the test failed:\n```\n=== Expected exit code 0 but was 1. ===\n=== STDERR ===\n[-] PARSING BUCK FILES...FINISHED 0.0s [100%]\nBUILT //:python_whl (1/2 JOBS)\nBUILT //:main_whl (2/2 JOBS)\n[-] BUILDING...FINISHED 0.7s [100%]\nTraceback (most recent call last):\n  File \".bootstrap/_pex/pex.py\", line 314, in execute\n  File \".bootstrap/_pex/pex.py\", line 78, in _activate\n  File \".bootstrap/_pex/environment.py\", line 132, in activate\n  File \".bootstrap/_pex/environment.py\", line 184, in _activate\n  File \".bootstrap/_pex/environment.py\", line 147, in _resolve\n  File \".bootstrap/pkg_resources/init.py\", line 854, in resolve\n  File \".bootstrap/pkg_resources/init.py\", line 2617, in requires\n  File \".bootstrap/pkg_resources/init.py\", line 2818, in _dep_map\n  File \".bootstrap/pkg_resources/init.py\", line 2835, in _compute_dependencies\nImportError: No module named _markerlib\n=== STDOUT ===\n====ERROR LOGS====\n[2016-04-25 10:08:09.772][warn ][tid:274][com.facebook.buck.python.PythonBinaryDescription] //:main_egg: parameter main is deprecated, please use main_module instead.\n[2016-04-25 10:08:10.663][warn ][tid:274][com.facebook.buck.python.PythonBinaryDescription] //:main_whl: parameter main is deprecated, please use main_module instead.\nPASS     300ms 19 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonBinaryDescriptionTest\nASSUME   26.1s 36 Passed  12 Skipped   0 Failed   com.facebook.buck.python.PythonBinaryIntegrationTest\nPASS    <100ms 15 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonBuckConfigTest\nPASS    <100ms  3 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonLibraryDescriptionTest\nPASS    <100ms  1 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonLibraryTest\nPASS    <100ms  3 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonPackageableComponentsTest\nPASS    <100ms  1 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonPackagedBinaryTest\nPASS      4.3s  1 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonSrcZipIntegrationTest\nPASS    <100ms 10 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonTestDescriptionTest\nPASS     11.1s  8 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonTestIntegrationTest\nPASS     140ms  1 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PythonUtilTest\nTESTS FAILED: 1 FAILURE\nFailed target: //test/com/facebook/buck/python:python\nFAIL com.facebook.buck.python.PrebuiltPythonLibraryIntegrationTest\n```\n. The prebuilt python library test passed in CI, even though the overall job failed:\nPASS      3.4s  1 Passed   0 Skipped   0 Failed   com.facebook.buck.python.PrebuiltPythonLibraryIntegrationTest\n. Gotcha.  It doesn't like my Python names in the Java sources.  Fix incoming...\n. @sdwilsh -- fixed, and ant lint passes locally now.\n. Hey @sdwilsh -- Why is the commit that landed in master attributed to you (7aca2fb) instead of my original commit (ae17e91)?\nI looked through a bunch of other commits in master and it seems like any contribution to Buck is being attributed to FB employees rather than the person who actually authored the commit.\nI understand that this is applicable under the copyright license grant in the CLA, but I feel it's bad for the community to remove proper attribution.\nThoughts?  Is there somewhere else I should take this discussion?  I tried to bring it up on the FB Developers group, but someone there said I should just respond here.\n. Thanks for the replies, @k21 & @sdwilsh. \nI definitely didn't think anyone was doing something nefarious to try and take credit, it's more that I thought this was some internal policy thing at FB.  Glad to hear it's just a regression in a tool.\n. @mikekap -- Thanks for the info.  I was thinking that I could use something along those lines as a fallback, but in the sprit of Buck I'm trying to keep my BUCK files as simple as possible here.\nI believe this is a fairly non-intrusive change that you fully need to opt-in to, so hopefully the FB folks are open to this change.  :)\n. ",
    "tpbrown": "@sdwilsh CLA signed, but I think the bot didn't update the label.\n. ",
    "FuegoFro": "It looks like that's coming from this readVersion function, which indeed is only checking for the (now removed) RELEASE.TXT file. It seems like rather than duplicating the logic in the findNdkVersionFromPath function, we should re-use it, either by passing the version into the place that the readVersion call happens or pulling it out into a static function somewhere. I don't know enough about the code to know which approach would be preferred, but if someone wants to weigh in I'd be happy to submit a pull request.\n. It looks like that's coming from this readVersion function, which indeed is only checking for the (now removed) RELEASE.TXT file. It seems like rather than duplicating the logic in the findNdkVersionFromPath function, we should re-use it, either by passing the version into the place that the readVersion call happens or pulling it out into a static function somewhere. I don't know enough about the code to know which approach would be preferred, but if someone wants to weigh in I'd be happy to submit a pull request.\n. Great, thank you so much for merging this in @ttsugriy! :D. ",
    "raliste": "Thank you @nemith .\nWould you consider to provide an official tool to create TARGET files? The bazel team is working on open sourcing glaze, Google's internal tool to create BUILD files for go packages.\nSeems like a nice addition to buck autodeps https://buckbuild.com/command/autodeps.html\n. ",
    "fho": "any updates? :-). any updates? :-). ",
    "mkaczanowski": "Closing it. Automation can be used to generate BUCK files (for example @vmagro project). Closing it. Automation can be used to generate BUCK files (for example @vmagro project). hey @daedric I have just landed cgo support for buck. Since your diff was a year old I reworked quite a bit.\nThanks a lot for contributing and enjoy the cgo feature in buck!\nCommit: https://github.com/facebook/buck/commit/28b54757c5eb81137eae088dc7327b5c0f696701. hey @daedric I have just landed cgo support for buck. Since your diff was a year old I reworked quite a bit.\nThanks a lot for contributing and enjoy the cgo feature in buck!\nCommit: https://github.com/facebook/buck/commit/28b54757c5eb81137eae088dc7327b5c0f696701. @Dimagog it's been a while, do you still run into this issue?. @Dimagog it's been a while, do you still run into this issue?. Closing issue. The issue was reported a year ago and I know people who have been building successfully on  windows.\nFeel free to reopen if you still happen to have issue. Also our integration tests are passing. Closing issue. The issue was reported a year ago and I know people who have been building successfully on  windows.\nFeel free to reopen if you still happen to have issue. Also our integration tests are passing. I will look into this in a short while.. I will look into this in a short while.. @lloyd you should be able to include the genrule to \"srcs\" with this change\nplease let me know if that fits your usecase. Second thought: I forked the buckissue repo but this won't work.\nThe expectation is to have an asset generated in the main directory where binary is present (not for compile time - like it is with srcs).\nThis shouldn't be difficult to fix (I think). I modified the buckissue main paths:\n$ ./buck-out/gen/buckissue/main/main \nHello World! ./buck-out/gen/buckissue/main/../generated_asset/generated_asset\nWe're in /home/mkaczanowski\nMy Asset: hello generated asset world\nThe path needs point to the target directory, which sounds legit enough for this use case (it doesn't change the fact that genrules in deps should be a valid case - the behavior would be the same to as if you define genrule dep in srcs). \nPython uses pkg_resources API, with go we don't have such feature so I believe this case is \"mitigated\". This is:\n1. you can use srcs to define the genrule dependency (you need to refer to the build target directory of genrule)\n2. we need to allow genrules in the deps since it feels more correct (srcs should be used to generate the compile time required .go files etc)\n@ttsugriy  @nemith does it sound legit to you?. It can but only for go_test. Buck will symlink the output to current directory while running buck test, for example:\n...\ngo_test_link_tree @ buck-out/gen/buckissue/__test_main_test_output__/working_dir\ngo test\n...\nso the asset can be referenced within current directory. However this is only during buck test execution, so if you try to run:\n./buck-out/gen/buckissue/main_test#test-main/main_test -test.v\nit won't find the file.\nLet's say we add \"resources\" to go_binary then we could mimic the go_test behavior with:\n$ buck run ...\nwhich would change the working directory. The problem is with the cxx_library which doesn't depend on the CGoGenSource. At compile time of cxx_library the _cgo_export.h can't be resolved because it doesn't exist.\nThe solution would be to amend the cxx_deps and add the gen source dep.. Since the cgo_library doesn't accept the c files, the above BUCK file won't simply work (also the first file in srcs is used to infer package name - this fails if you pass C file).\nI fixed that issue in: https://github.com/facebook/buck/commit/dfbc952df89505a49df0d2036d229cd7c2fb00e0\nNow you should be able to access \"_cgo_export.h\" from within \"call_cgo.c\". This is one step forward. main.go currently with buck can't contain import \"C\" cgo directive. You need to create intermediate library instead.\nFor example I applied patch to @monty-uber repro: https://pastebin.com/raw/itEyPXrV\nand it works fine now. Solved in:\nhttps://github.com/facebook/buck/commit/b9012d7b8567043a1624ef5e6c3bc0e819af4dc5. We have the same issue when a file on which you run mockgen (or some other tool) imports packages from GOPATH.\nThe genrule won't make it work unfortunately, I would be curious if the go modules would actually solve the issue.. We solved gomock (https://github.com/golang/mock) issue by set of genrules and reflection mode.\nI don't have any great solution for stringer though. I think the extra rule is not great but on the other hand I don't see any better way.\n@linzhp @vitarb feel free to come up with PR. fixed in revision: https://github.com/facebook/buck/commit/afecad16e8d2ef5ed058794adca7c626e2561fa2. @groob talked with @linzhp on slack (it's great since @linzhp is adapting buck with go feature at Uber). I am closing this issue, most of the questions are answered.\nA few takeaways:\n1. buck doesn't manage vendor packages. Bazel supports fetch from remote endpoints where in buck you'd have to create your vendor repo and manage the deps (internally we have small to do it).\n2. we didn't think about go modules, yet\n3. currently there is no feature to convert bazel go rules to buck. There are similarities between go_binary/go_library in buck and bazel, so it should not be too difficult to come up with some conversion mechanism (NOTE: cgo_library might not be trivial, though).\n4. genrule is used to create \"custom rules\", for example thrift generator or mockgen (with limitation for now, see proposal)\n. I think the java_test approach is reasonable. @philipjameson @styurin what do you think?. I talked to @styurin, the env option is the right approach. I have a diff already in review, expect this to be done soon. I talked to @styurin, the env option is the right approach. I have a diff already in review, expect this to be done soon. Solved in: https://github.com/facebook/buck/commit/09f844339628ff7505af416ae265844074c5842c. Solved in: https://github.com/facebook/buck/commit/09f844339628ff7505af416ae265844074c5842c. I have fix on the way. I have fix on the way. I had to revert the fix, this needs more investigation. I had to revert the fix, this needs more investigation. I don't mind having exported_linker_flags in cgo_library (that is already a customized cxx_library flavor). Feel free to come up with PR. is the header_namespace important here? does it work without it?. I think this should be before \"--\" otherwise the cgoCompilerFlags will be passed to the gcc. I think it's reasonable to add extra arg to CgoLibraryDescription 'cgoCxxCompilerFlags'. ah, crap, thanks for spotting this! I'll fix this soon\n. @linzhp why is this needed? after I removed the instanceof the tests are still passing, if this is really required can you update the test to reflect the case?:\npath instanceof BuildTargetSourcePath\n. please add:\nGoAssumptions.assumeGoVersionAtLeast(\"1.10.0\");. thanks for explanation. @styurin can you check that line? If that is the case likely we might need to update other places as well. ",
    "mtak-": "If anyone else needs to use a static libc++, here's a workaround (YMMV)\n.buckconfig:\n```\n... other settings ...\n[ndk]\n    ... other ndk settings ...\n    cxx_runtime = system\n... more config settings ...\n```\nBUCK file:\n``` python\ncxx_library(\n    ### other settings\ncompiler_flags = [\n    ### other compiler flags\n    '-I**PATH/TO/NDK**/sources/cxx-stl/llvm-libc++/libcxx/include',\n    '-I**PATH/TO/NDK**/sources/cxx-stl/llvm-libc++abi/libcxxabi/include',\n    '-I**PATH/TO/NDK**/sources/android/support/include',\n],\nlinker_flags = [\n    ### other linker flags\n    '-Wl,--whole-archive',\n    '-l**PATH/TO/NDK**/sources/cxx-stl/llvm-libc++/libs/**ARCH**/libc++_static.a',\n    '-Wl,--no-whole-archive',\n]\n\n)\n```\n. ",
    "hey99xx": "Is this the official solution to the problem or is there any cleaner way? \nWe should have double amount of options in https://buckbuild.com/concept/buckconfig.html#ndk.cxx_runtime since all runtimes come with shared and static variations.. ",
    "danoz73": "Awesome! That solved my issues. I guess I lose my head when I don't have my \"gradle sync\" button!\nWow, so all these abstract classes are using annotations to then generate a bunch of boilerplate... I see now. Thanks again. Worth investigating further :)\n. Awesome! That solved my issues. I guess I lose my head when I don't have my \"gradle sync\" button!\nWow, so all these abstract classes are using annotations to then generate a bunch of boilerplate... I see now. Thanks again. Worth investigating further :)\n. ",
    "yschimke": "I need to fix a mocking test broken by a final class\nCannot subclass final class class okhttp3.OkHttpClient$Builder\n. It was failing with a NPE with the diff in this PR, I guess smart mocks return null rather than failing on final classes?\nI made the following edit and that's when it gave me the error above.\n```\ndiff --git a/test/com/facebook/buck/slb/ClientSideSlbTest.java b/test/com/facebook/buck/slb/ClientSideSlbTest.java\nindex 4d58bce..0059687 100644\n--- a/test/com/facebook/buck/slb/ClientSideSlbTest.java\n+++ b/test/com/facebook/buck/slb/ClientSideSlbTest.java\n@@ -50,6 +50,7 @@ public class ClientSideSlbTest {\n   private BuckEventBus mockBus;\n   private Clock mockClock;\n   private OkHttpClient mockClient;\n+  private OkHttpClient.Builder mockClientBuilder;\n   private ScheduledExecutorService mockScheduler;\n   private ClientSideSlbConfig config;\n@@ -63,6 +64,7 @@ public class ClientSideSlbTest {\n     mockBus = EasyMock.createNiceMock(BuckEventBus.class);\n     mockFuture = EasyMock.createMock(ScheduledFuture.class);\n     mockClient = EasyMock.createNiceMock(OkHttpClient.class);\n+    mockClientBuilder = EasyMock.createNiceMock(OkHttpClient.Builder.class);\n     mockScheduler = EasyMock.createMock(ScheduledExecutorService.class);\n     mockClock = EasyMock.createMock(Clock.class);\n     EasyMock.expect(mockClock.currentTimeMillis()).andReturn(42L).anyTimes();\n@@ -81,6 +83,8 @@ public class ClientSideSlbTest {\n   @SuppressWarnings(\"unchecked\")\n   public void testBackgroundHealthCheckIsScheduled() {\n     Capture capture = EasyMock.newCapture();\n+    EasyMock.expect(mockClient.newBuilder()).andReturn(mockClientBuilder);\n+    EasyMock.expect(mockClientBuilder.build()).andReturn(mockClient);\n     EasyMock.expect(mockScheduler.scheduleWithFixedDelay(\n         EasyMock.capture(capture),\n         EasyMock.anyLong(),\n@@ -101,6 +105,8 @@ public class ClientSideSlbTest {\n   @SuppressWarnings(\"unchecked\")\n   public void testAllServersArePinged() throws IOException {\n     Capture capture = EasyMock.newCapture();\n+    EasyMock.expect(mockClient.newBuilder()).andReturn(mockClientBuilder);\n+    EasyMock.expect(mockClientBuilder.build()).andReturn(mockClient);\n     EasyMock.expect(mockScheduler.scheduleWithFixedDelay(\n         EasyMock.capture(capture),\n         EasyMock.anyLong(),\n```\nApologies for the non working PR, but any advice on how to fix would be much appreciated.\n. @ruibm I realize this PR was unprompted, so thanks for the advice here.\n. okhttp 3.3.0 just got released yesterday, do you want me to adjust to include that also.  Or hold off since its so new, and the bigger change it 2 -> 3?\n. It's there http://repo1.maven.org/maven2/com/squareup/okhttp3/okhttp/3.3.0/\nI'll push a new version in a few minutes.  I hope you don't mind if I let travis point out additional test failures, compile worked for //test/... but I get a lot of spurious failures if I run \"./bin/buck test //test/...\", but the individual failing targets work. \n. It's there http://repo1.maven.org/maven2/com/squareup/okhttp3/okhttp/3.3.0/\nI'll push a new version in a few minutes.  I hope you don't mind if I let travis point out additional test failures, compile worked for //test/... but I get a lot of spurious failures if I run \"./bin/buck test //test/...\", but the individual failing targets work. \n. I notice the watchman target skips a native library for bser.  Do you expect this to have any noticeable performance impact?\nhttps://github.com/facebook/buck/blob/master/third-party/py/pywatchman/BUCK\n. LGTM.  But I don't have much experience with this code, generally looks sensible.\n. LGTM.  But I don't have much experience with this code, generally looks sensible.\n. Too early - WIP. Too early - WIP. I don't expect this to work based on the announced version scheme, and the EA\nhttps://blogs.oracle.com/java-platform-group/entry/a_new_jdk_9_version\n$ java -version\njava version \"9-ea\"\nJava(TM) SE Runtime Environment (build 9-ea+116)\nJava HotSpot(TM) 64-Bit Server VM (build 9-ea+116, mixed mode)\n. parenthesis don't look like they match\n. ",
    "vinz243": "^^ just found that I was putting deps into visibility \n. Idk how, but I fixed this issue a long time ago.\n. Here is the SO post:\nhttp://stackoverflow.com/questions/37681117/didnt-find-class-android-support-design-widget-coordinatorlayout-using-buck\n. Thanks! It works like a charm :)\n. Thanks! It works like a charm :)\n. ",
    "alishir": "It doesn't build any .so file for x86-64 architecture. buck-out/bin/jni/__libjni/libs/ directory only contains armeabi subdirectory and there is no x86-64 related directory or .so file.\n. ",
    "rzsombor": "The linked SO thread does contain a solution to this issue. It seems to me that this was a misconfiguration problem rather than something wrong with Buck. \n. ",
    "Waed93": "can you please clarify how you solved it, I'm struggling with the same problem !!. ",
    "castroflavio": "So, this guys claim I can increase the file name this way.\nhttp://stackoverflow.com/questions/27680647/does-max-path-issue-still-exists-in-windows-10\nBut then, the next question is what faced the error, how can I add/edit a manifest file for it.\nFor example, if it was python, Can I link a manifest file to python itself\n. ",
    "cosmin1123": "Thank you!\nI'll better handle that exception.\nIt shouldn't cause any real problems, but you won't be able to do install, build, project, etc from the plugin.\nYou can specify the correct path from:\n\"Preferences/Settings -> Tools -> Buck -> Buck Executable Path\"\nThat suggestion should also be included in the error message.\n. Can you provide more information?\nWhat was the stack trace and message of the exception?\nWas it in the Event Log of Android Studio?\nDid Android Studio close?\nIf it's something about Buck or Adb then the exception is being handled and it tells you how to solve it.\nYou need to set the buck/adb path in \"Preferences/Settings -> Tools -> Buck -> Buck Executable Path/ Adb Executable Path\".\n. ",
    "erva": "@kageiit seems you're right\n. ",
    "tonycosentini": "Going to close this as a duplicate to keep discussion in #795.\n. Would it be possible for someone to take a look at this issue?\nWhile the old project generation also works, it seems like there are quite few advantages to the new project generation system, but any Android app won't be able to use it because of this issue.\n. Re build falure - it seems like Ant can reference the Unzip class, but not Buck. I'll try to figure it out.\n. @dreiss would you be a good person to review this? (heard you might know about how to approach this)\n. @marcinkosiba got it working with your approach (I think). Huge thanks for the review and feedback, makes much more sense now.\n. That makes sense.\nWhat about individual SDKs for specific IntelliJ modules? Does that get overwritten when running buck project? We have a mix of Android and Java modules - when setting the global project SDK to Android, you need to manually set all of the Java modules to a non-Android JDK.\n. This .get() will crash if a jar is not present, but that should be guaranteed by the code added in IjProject. Let me know if there is a better way to handle this.\n. ",
    "elazarl": "What I would do is, give a detailed trace of where the error has occurred.\nFor example, in our case:\n```\nIn file included from\nBUCK:2:include_defs('//bucklets/maven_jar.bucklet')\nIn\nbucklets/gerrit_plugin.bucklet:132:    genrule(\n      name = '%s-static' % name,\n      cmd = 'mkdir -p $TMP/static' +\n        ';unzip -qd $TMP/static $(location %s)' %\n        ':%s__gwt_application' % name +\n        ';cd $TMP' +\n        ';zip -qr $OUT .',\n      out = '%s-static.zip' % name,\n    )\ngenrule command execution failed with:\n```\nThat's way, even someone not familiar with buck's internal, could easily spot the error, understand where it came from, and even fix it.\nMoreover, it would give me a pointer to the genrule command so that I'll be able to look for documentation about it.\nDoes it make sense?\n. What I would do is, give a detailed trace of where the error has occurred.\nFor example, in our case:\n```\nIn file included from\nBUCK:2:include_defs('//bucklets/maven_jar.bucklet')\nIn\nbucklets/gerrit_plugin.bucklet:132:    genrule(\n      name = '%s-static' % name,\n      cmd = 'mkdir -p $TMP/static' +\n        ';unzip -qd $TMP/static $(location %s)' %\n        ':%s__gwt_application' % name +\n        ';cd $TMP' +\n        ';zip -qr $OUT .',\n      out = '%s-static.zip' % name,\n    )\ngenrule command execution failed with:\n```\nThat's way, even someone not familiar with buck's internal, could easily spot the error, understand where it came from, and even fix it.\nMoreover, it would give me a pointer to the genrule command so that I'll be able to look for documentation about it.\nDoes it make sense?\n. Can't the JSON include more information about the build rules?\nAt least \"going to run command X\"?\nSimilar to DWARF at ELF files?\nSeems to me useful for more things.\nOn Tue, Jun 28, 2016 at 5:44 PM, Shawn Wilsher notifications@github.com\nwrote:\n\nThe problem is that Buck isn't parsing the build file (it's parsed in\nPython), so it has no idea about any of the contents. It just gets a\nJSON-like representation of the build rules.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/793#issuecomment-229071145, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AAP4or2GbZpLQ_w_9RTMxg_I6VEbSecdks5qQTNKgaJpZM4I-xaO\n.\n. \n",
    "joewalnes": "Ahh it seems that I have ANDROID_HOME set. That fixed it. Thank you.\nBut this is still a usability hurdle. I now have to explicitly clear ANDROID_HOME for all pure Java projects in case one developer happens to have the SDK installed.\n. Ahh it seems that I have ANDROID_HOME set. That fixed it. Thank you.\nBut this is still a usability hurdle. I now have to explicitly clear ANDROID_HOME for all pure Java projects in case one developer happens to have the SDK installed.\n. @marcinkosiba Next time this happens, I'll look at the log file.\n@shs96c Answering your questions...\n\nit's because the build files aren't valid Python\n\nI don't think that's the cause as I've seen it happen when the BUCK files haven't been changed recently.\n\n\"In particular, \"autodeps\" generated BUCK files\n\nI'm not using autodeps first. (Side note: I'm not using it because of the scary EXPERIMENTAL warning - do you think I should be? Is it relatively stable?)\n\nDoes anything change before you get the BSER warning?\n\nGeneral code changes. Nothing out of the ordinary. Also re-running immediately after the failure seems to fix it.\n\nAlso, are you using watchman\n\nYep. \"Using watchman.\"\n\nI realize my version is pretty old so I'm going to upgrade and assume it's fixed. I'll close the issue. If it re-occurs with latest, I'll re-open.\n. Yes. I built with a4cd1b0561c and saw same error.\nIs there anything else about my environment I can provide that will help?. I have a theory...\nLooking through the recent builds on https://travis-ci.org/facebook/buck/builds, it seems that:\n\nbuilds using java version \"1.8.0_31\" are all failing with the same build error that I'm seeing\nbuilds using java version \"1.8.0_111\" are passing (well, they're still mostly failing, but for other reasons)\n\nSounds like a JDK bug. I'll try upgrading...\n. Can confirm. Upgrading to java version \"1.8.0_121\" fixed the compile issue.. ",
    "chrislacy": "I'm seeing this also. When I follow @kageiit's suggestion and increase ADB_CONNECT_TIMEOUT_MS to 60000 the adb connection (usually) occurs eventually, although when it does so it often takes ~30 seconds for the adb connection to register. \nIn my case, it seems the issue occurs far more often when attempting to run on an emulator. Running on a device is much more reliably.  . ",
    "robbertvanginkel": "You're right my test wasn't sound. Don't mind the pingponging with this fast of a turnaround.\n. Thanks for the feedback. Don't think the defaults need to be changed then.\n. Are we in any way concerned that that will break the current undocumented way the framework flavor works?\n. Are we in any way concerned that that will break the current undocumented way the framework flavor works?\n. Thanks for the response. This does make sense semantically, but it also takes a different direction than some previous commits so to make sure we're aligned please verify the following:\n- Never make apple_library output a framework bundle. Removeapple_library's reaction to#frameworkflavor (as opposed to 8753c2a962492f05c0da17a69a1ba9cacd7eb47c, by @Coneko).\n- Do frameworks throughapple_bundleswith apple_library as binary\n  - There's a recent commit (ce2322644aecddb1fc54a5ead0f506496c272e54) that explicitly doens't propagate the framework flavor through bundles, but it isn't really clear why.\n  - Do we still need a framework flavor? (We can identify a framework throughapple_bundle`'s extension)\n  - How would you suggest we expose headers and other build settings with this appoach? From what I could find apple_bundle doesn't pass any cxx flags around. \nSay we have the follwing:\n```\napple_binary(\n    name = 'BinaryA',\n    deps = [':FrameworkB']\n)\napple_bundle(\n    name = 'FrameworkB',\n    binary = ':LibraryB#shared',\n)\napple_library(\n    name = 'LibraryB',\n    headers = ['header.h']\n)\n```\nNow BinaryA has #import <LibraryB/header.h> somehwere. With the LibraryB#framework approach this would be visible as the apple_binary directly depended on the apple_library, with the suggested apple_bundle+#shared it is not. \nHow do you handle this? Conforming to the  CxxPreprocessorDep protocol if we're a bundle with framework seems like a semantical stretch. Am I overlooking something obvious here? Xcode does this an option -ivfsoverlay, but it seems like buck doens't have any support for that yet. \n. Seem like I was not a 100% right in concluding that Xcode uses -ivfsoverlay, it seems to widely overspecify headers to include in build rules that depend on frameworks. There are also -I and -F flags that seem to be used for this.\nAppleBundle.java already has a getCxxPreprocessorInput, to propagate its headers to a test target that depends on a bundle. Would it be a good approach to propagate the binary's headers there if the bundle is a framework target?\n. I've updated the PR to do the following:\n- In cxx preprocess deps gathering step, go through the frameworks and see if any is a buildrule. If so add that rule as a preprocessing dep step.\n- Simplify the prebuilt_apple_framework build rule to copy the framework to a gen folder, and pass the framework search paths option-F to clang on linking and as an preprocessor dep.\nLets keep this PR restricted to just the prebuilt framework, and I'll incorporate the feedback for frameworks from apple_library's (and removing the apple library #framework flavor) in a future one.\n. > We might want to call this prebuilt_dynamic_apple_framework to distinguish it from a static framework (e.g. basically a .a in a framework bundle)\nYou can also link static frameworks with -framework, you'd just have to copy the resources into the main apple bundle, not copy the framework to a Frameworks folder and don't pass the rpath flags. I think we should keep it a prebuilt_apple_framework and clarify currently only supports dynamic frameworks until someone extends it for bundles with static frameworks.\n. > apple_library's framework flavours should be unrelated since this handles the case of prebuilt frameworks.\nIt should, but it is currently not because of AppleDescriptions.java#L505. That is, if you say your apple_bundle includes frameworks (like we want to to include these prebuilt frameworks), it automatically finds metadata from its dependencies with the #framework flavor. So if the apple_bundle depends on an apple_library that library is built and included with the broken framework flavor. That's a potential issue that will come up if you depend on both. \n\nTo resolve this, maybe we should make new rules (this + apple_framework) as the canonical way to specify frameworks, and transform them differently depending on whether we're building or generating a project.\nIf we want to build libraries for iOS 7 and frameworks for iOS 8+, then best to have a macro in the BUCK file that splits a rule into two (apple_library + apple_framework).\n\nI agree that a separate apple_framework seems like the way to go.\n. Ah, I only checked frameworks not apps. It does break that test and I didn't notice as I only ran the AppleBundle/AppleLibrary IntegrationTests.\nI think the best way forward would be to add a AppleBundleDestinations.FRAMEWORK_DESTINATIONS? Maybe also rename the OSX/IOS destinations to OSX_APP_DESTINATIONS and IOS_APP_DESTINATIONS.\n. Looking at the iOS Simulator frameworks it seems that they are slightly different and don't have a Resources folder. I can't find a good doc about it thought, except that xcode uses a setting UNLOCALIZED_RESOURCES_FOLDER_PATH, which for OSX is defined in the docs  (by default CONTENTS_FOLDER_PATH/Contents/Resources). \nThere's no iOS counterpart though, but when creating a fresh framework project the value\nexport UNLOCALIZED_RESOURCES_FOLDER_PATH=TestFramework.framework is used. This seems like there is a difference and I'll update the PR accordingly.\n16:56 $ tree -L 2/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/GLKit.framework\n.\n\u251c\u2500\u2500 GLKit\n\u251c\u2500\u2500 Headers\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 GLKitBase.h\n\u251c\u2500\u2500 Info.plist\n\u251c\u2500\u2500 en.lproj\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 InfoPlist.strings\n\u251c\u2500\u2500 fsh.xml\n\u251c\u2500\u2500 Modules\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 module.modulemap\n\u251c\u2500\u2500 module.map\n\u2514\u2500\u2500 vsh.xml\n. Looking at the iOS Simulator frameworks it seems that they are slightly different and don't have a Resources folder. I can't find a good doc about it thought, except that xcode uses a setting UNLOCALIZED_RESOURCES_FOLDER_PATH, which for OSX is defined in the docs  (by default CONTENTS_FOLDER_PATH/Contents/Resources). \nThere's no iOS counterpart though, but when creating a fresh framework project the value\nexport UNLOCALIZED_RESOURCES_FOLDER_PATH=TestFramework.framework is used. This seems like there is a difference and I'll update the PR accordingly.\n16:56 $ tree -L 2/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/GLKit.framework\n.\n\u251c\u2500\u2500 GLKit\n\u251c\u2500\u2500 Headers\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 GLKitBase.h\n\u251c\u2500\u2500 Info.plist\n\u251c\u2500\u2500 en.lproj\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 InfoPlist.strings\n\u251c\u2500\u2500 fsh.xml\n\u251c\u2500\u2500 Modules\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 module.modulemap\n\u251c\u2500\u2500 module.map\n\u2514\u2500\u2500 vsh.xml\n. I'm working on removing the cyclic dependency.\n. Update: after dropping this work for some other prio's I'll be working on this again this week.\n. Replacement PR's will start from #1032. Replacement PR's will start from #1032. A problem I am running into is correctly collecting the resources for a framework bundle. Currently this happens in AppleBundleResources.collectResourceDirsAndFiles, which usesAppleBuildRules.getRecursiveTargetNodeDependenciesOfTypes, which traverses the TargetGraph. This is in issue, because depending on the link_style/preferred_linkage argument of the apple_library (and its dependencies), transitive resources should be included or not. But at this point, the target graph that is being traversed is the general graph without flavors, which is unaware of the way it will be linked.\nA possible solution would be to modify the collectResourceDirsAndFiles call, to collect the resources through requireMetaData in combination with a new ResourceMetadata class. Any suggestions on tackling this problem?. A problem I am running into is correctly collecting the resources for a framework bundle. Currently this happens in AppleBundleResources.collectResourceDirsAndFiles, which usesAppleBuildRules.getRecursiveTargetNodeDependenciesOfTypes, which traverses the TargetGraph. This is in issue, because depending on the link_style/preferred_linkage argument of the apple_library (and its dependencies), transitive resources should be included or not. But at this point, the target graph that is being traversed is the general graph without flavors, which is unaware of the way it will be linked.\nA possible solution would be to modify the collectResourceDirsAndFiles call, to collect the resources through requireMetaData in combination with a new ResourceMetadata class. Any suggestions on tackling this problem?. Hmm, yes. I didn't encounter this as all our tests are agnostic and don't have those suffixes. I do want this to be a SourcePath like it is now, so it can be combined with the export_file rule.\n@Coneko Is there a way to have a sourcepath that is unverified?. Looks good to me, but I don't have merging powers.. The difference here should be in mixed app targets vs mixed framework targets. I don't think this can be decided from the level of SwiftCompile.java. Relevant apple doc, especially the import matrixes https://developer.apple.com/library/content/documentation/Swift/Conceptual/BuildingCocoaApps/MixandMatch.html\nWhen doing imports with \"ModuleName/ModuleName-Swift.h\", what are you importing from where? (app importing own swift?, app importing deps' swift?, framework importing own swift?, framework importing deps' swift?). I thought I added and made preffered_linkage required in #1064, maybe you are using an older buck binary?\nThe main reason this wasn't documented is because this rule type has no project generation support yet, and the copying behaviour isn't correct. For dynamic frameworks these should end up in an apple_bundle, for static ones their resources should. I believe both are not implemented, so might be good to note that in the docs.. I ran into this problem as well, and I think there's another important caveat here: the .xcent file that the linker embeds in the binary isn't the same as the entitlements file you specify you want to use for the app.\nThere's a step named ProcessProductPackaging in xcode, that takes your specified entitlements and merges/augments them with some other settings. From the log:\nProcessProductPackaging \"\" /path/to/Test.app.xcent\n...\n    builtin-productPackagingUtility -entitlements -format xml -o /path/to/Test.app.xcent\nWhen I then look at the resulting .xcent file, it has some additional keys in there, compared to the keys in the entitlements file you originally specified.\nUnfortunately builtin-productPackagingUtility is implemented in Xcode's private DevToolsCore.framework. . I think the issue is that the apple_bundle doesn't copy in the shared prebuilt_apple_framework's into the bundle. Either that or there's a bug that doesn't set the correct rpaths for the binary link command.\nThere should be a simulator log, that will contain the reason why the abort is fired.. Sorry, I meant crashlog not regular log. They could also be under ~/Library/Logs/DiagnosticReports/. There are definitely some things that need to happen after this, I suggest we keep a list in a separate task for things like the swiftdoc, choice for invoking per module / per file, etc.\n\nIn order to avoid disruptions to existing users of apple_library with Swift, we could control the new behaviour using a config option in the interim.\n\nI think since it is undocumented, there are no guarrantees. To not disturb current users we have to keep current code paths, which is exactly what I don't want with this refactor.\nI think the best way to go will be to remove the swift delegation, and keep the cxx delegation for now. We then branch based on having mixed swift/obcj sources (and possibly a flag like apple.new_library_flow so people can easily switch over to the new path for objc only for testing).\n. Verified this works locally. Put this in the execution command instead of the .buckconfig is because the test folder is shared across more tests.\nThe import re-ordering was part of some project style.. I must have missed that test. Pushed a fix.. I ran the google-java-formatter and the pmd. I got rid of one pmd error, but I cant seem to fix:\npmd:\n      [pmd] /Users/robbertvanginkel/buck/src/com/facebook/buck/cxx/CxxLibraryDescription.java   -   Error while parsing /Users/robbertvanginkel/buck/src/com/facebook/buck/cxx/CxxLibraryDescription.java\nThat error doesn't seem to fail ant though.. I ran the google-java-formatter and the pmd. I got rid of one pmd error, but I cant seem to fix:\npmd:\n      [pmd] /Users/robbertvanginkel/buck/src/com/facebook/buck/cxx/CxxLibraryDescription.java   -   Error while parsing /Users/robbertvanginkel/buck/src/com/facebook/buck/cxx/CxxLibraryDescription.java\nThat error doesn't seem to fail ant though.. Not sure if you take PR's like this, but I've been working on some PR's related to apple things and I find the import re-ordering quite noisy when reviewing the changes. This is an attempt at auto formatting them to conform to the project's defaults, so that later changes are cleaner.\nLet me know if this is an acceptable change.. Not sure if you take PR's like this, but I've been working on some PR's related to apple things and I find the import re-ordering quite noisy when reviewing the changes. This is an attempt at auto formatting them to conform to the project's defaults, so that later changes are cleaner.\nLet me know if this is an acceptable change.. Ah, I was incorrectly assuming that the file at .idea/codeStyleSettings.xml was up to date, but it seems like the thing I was using is 4 years old.\nI'll start using google-java-format then.. Ah, I was incorrectly assuming that the file at .idea/codeStyleSettings.xml was up to date, but it seems like the thing I was using is 4 years old.\nI'll start using google-java-format then.. I have some other commits that make the full implementation, but I wanted to share this first to get feedback on the long argument type. I'll update with the full implementation.. @dinhviethoa its been a while but I finally found time to rebase this. I incorporated the feedback on the short AdditionalActions enum names. It now also includes the serialisation code and appropriate tests.. You can use $ git diff HEAD~1 --color-words='\\\\w+|[^[:space:]]' to get a better format of what changed in these one line xcschemes. In all cases it added shouldUseLaunchSchemeArgsEnv=\"YES\" as an attribute to ProfileAction.. Let me know if I should split this into smaller PR's. @milend I rebased and updated this. Can you give it another look?. There's a documented apple.xctool_default_destination_specifier, see\nhttps://buckbuild.com/concept/buckconfig.html#apple.xctool_default_destination_specifier. @milend can you review this one?. No, we don't either. . @milend can you take a look at this?. bump?. bump?. Hmm, interesting! Should definitely make this configurable then.. Hmm, interesting! Should definitely make this configurable then.. I did look at the ddplist, the reason this seems tricky to use is that the .strings files we use for translation are ascii/NeXTSTEP plists with a dictionary, but without the enclosing { ... } indicating the top level dict. Because of this, ddplist doesn't read and can't convert the strings files even though plutil could.\nWe could try to read the file and add the curly brackets before passing it to the ddplist parser, that way we could write the binary plists without comments.. I did look at the ddplist, the reason this seems tricky to use is that the .strings files we use for translation are ascii/NeXTSTEP plists with a dictionary, but without the enclosing { ... } indicating the top level dict. Because of this, ddplist doesn't read and can't convert the strings files even though plutil could.\nWe could try to read the file and add the curly brackets before passing it to the ddplist parser, that way we could write the binary plists without comments.. There was an open issue regarding this that was closed as a won'tfix: https://github.com/3breadt/dd-plist/issues/29. The suggested workaround is wrapping the file in the extra chars.\nWe could just do the wrapping in buck, and not attempt to add it to ddplist? Are we okay with this hack?. There was an open issue regarding this that was closed as a won'tfix: https://github.com/3breadt/dd-plist/issues/29. The suggested workaround is wrapping the file in the extra chars.\nWe could just do the wrapping in buck, and not attempt to add it to ddplist? Are we okay with this hack?. @milend . @milend . Suspicously, this target also doesn't have any source files. Is this intended? Maybe this was missed in the move in 8e20872a792a262c2f5c5287df74a9d5331fee16?. This fails before buck query 'deps(testsof(//src/com/facebook/buck/event/chrome_trace/...))'. I understand the concern for a hard error. I copied this behaviour from buck build, see \nhttps://github.com/facebook/buck/blob/08f7f10f21be7759cc582dbca2b1827c514bb986/src/com/facebook/buck/apple/AppleDescriptions.java#L344-L370\nEven though buck build already fails on this, it is possible that it'd cause issues in project generation. Happy to add something but considering the buck build I would try to argue we should keep them the same.. @milend do you have an idea who could help review this? I'm having a bit of trouble figuring out where this can go best. I'll put some comments in the code.. I'll try to look at this a bit more in depth considering the comments. One think I can think of is we don't change the cxx classes but put this in AppleDescription's populateCxxConstructorArg.. @milend I've revised this PR and found a better place to put this. By putting it in populateCxxLibraryDescriptionArg it doesn't have to go into the cxx part of buck and it keeps restricted to the apple part.\nI can add an integration test later when this functionality is needed to not break building, but that requires some more PR's around modulemap generation with buck build to land.. I rebased and added a testcase for the apple_library, let me know what you think of the osx part.. I rebased and added a testcase for the apple_library, let me know what you think of the osx part.. Created a separate PR for the fbxctest update in #1769. Think we should be good with the extra tests now.. Created a separate PR for the fbxctest update in #1769. Think we should be good with the extra tests now.. Removed the fbxctest commit.. Thank you for looking into this!. Any update?. Any update?. This was fixed.. Tests included with code in #1874 #1875. I've tried rebuilding, invalidating IntelliJ caches, doing a fresh checkout and I still get this error every time.. Fixed it by recloning. I did rebuild and tried all other ways of clearing caches, but I must have missed one. Closing for now.. This is not intentional, this is supposed to work. Can you add a sample project/setup that fails? \nThere hasn't been any significant work on the project generator for a while, looking at the last couple of weeks of commits nothing stands out. Do you have a last known working sha?. Modular and bridging-headers are be two mutually exclusive concepts in swift. Either you have a modular library and import objective c into your swift using the -import-underlying-module flag (buck will automatically create a modulemap for the headers that are under exported_headers, or you specify a bridging header it will add that to the swiftc command.\nIt sounds like this is intended, but we should probably make the error messaging more clear by just throwing an error if you specify both a bridging header and modular=True.. Modular and bridging-headers are be two mutually exclusive concepts in swift. Either you have a modular library and import objective c into your swift using the -import-underlying-module flag (buck will automatically create a modulemap for the headers that are under exported_headers, or you specify a bridging header it will add that to the swiftc command.\nIt sounds like this is intended, but we should probably make the error messaging more clear by just throwing an error if you specify both a bridging header and modular=True.. Thinking about the private imports do not work with modular=True on master. The limitation here is that once you expose a library's interface modularly, you can only reference those headers with the modulemap, otherwise you'll get duplicate symbol errors.\nWhen buck creates a test command, it add something like -I dependency#headers,modular -I dependency#headers-private, where dependency#headers-modular contains a module.modulemap file and dependency#headers-private contains a superset of headers from dependency#headers-modular. The compiler can't recognise the headers in dependency#headers-private as part of the module and will complain that some things have duplicate definitions inside and outside of the module. For that reason if your library is marked as modular there are no private interface exposed at this time.\nThe fork you're referencing contains a commit that does something like that (https://github.com/robbertvanginkel/buck/commit/7933322b91248246f1012da298b6b3ed59dee007), but that is a really hacky workaround that hijacks some of the c code to expose a unified input without modulemap if the rule is being tested.\nIdeally, we would find some way to get that functionality into master but I haven't had the ability to look at how we could achieve that in a reasonable way.. Thinking about the private imports do not work with modular=True on master. The limitation here is that once you expose a library's interface modularly, you can only reference those headers with the modulemap, otherwise you'll get duplicate symbol errors.\nWhen buck creates a test command, it add something like -I dependency#headers,modular -I dependency#headers-private, where dependency#headers-modular contains a module.modulemap file and dependency#headers-private contains a superset of headers from dependency#headers-modular. The compiler can't recognise the headers in dependency#headers-private as part of the module and will complain that some things have duplicate definitions inside and outside of the module. For that reason if your library is marked as modular there are no private interface exposed at this time.\nThe fork you're referencing contains a commit that does something like that (https://github.com/robbertvanginkel/buck/commit/7933322b91248246f1012da298b6b3ed59dee007), but that is a really hacky workaround that hijacks some of the c code to expose a unified input without modulemap if the rule is being tested.\nIdeally, we would find some way to get that functionality into master but I haven't had the ability to look at how we could achieve that in a reasonable way.. No, there's no way around this on the buck-file level. If you want private imports in tests, for now you'll have to disable modular (which also doesn't allow you to use it from swift).. No, there's no way around this on the buck-file level. If you want private imports in tests, for now you'll have to disable modular (which also doesn't allow you to use it from swift).. @LegNeato the travis failure for this commit seems to be a flaky test in some undocumented feature named Stampede:\nFAIL      2.6s 11 Passed   0 Skipped   1 Failed   com.facebook.buck.distributed.build_client.StampedeBuildClientTest\nFAILURE com.facebook.buck.distributed.build_client.StampedeBuildClientTest racerBuildKilledWhenMostBuildRulesFinishedThenSynchronizedBuildKilledWhenDistBuildFails: \njava.lang.AssertionError\n    at org.junit.Assert.fail(Assert.java:86)\n    at org.junit.Assert.assertTrue(Assert.java:41)\n    at org.junit.Assert.assertTrue(Assert.java:52)\n    at com.facebook.buck.distributed.build_client.StampedeBuildClientTest.racerBuildKilledWhenMostBuildRulesFinishedThenSynchronizedBuildKilledWhenDistBuildFails(StampedeBuildClientTest.java:352)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout.lambda$new$0(SameThreadFailOnTimeout.java:41)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\nBuilds after ran fine, so I don't think this is related.\n@mgrebenets only library rules should be modular. For binaries you can continue to use the bridging header (but not in combination with modular set to true, because binaries can't be modular.. @LegNeato the travis failure for this commit seems to be a flaky test in some undocumented feature named Stampede:\nFAIL      2.6s 11 Passed   0 Skipped   1 Failed   com.facebook.buck.distributed.build_client.StampedeBuildClientTest\nFAILURE com.facebook.buck.distributed.build_client.StampedeBuildClientTest racerBuildKilledWhenMostBuildRulesFinishedThenSynchronizedBuildKilledWhenDistBuildFails: \njava.lang.AssertionError\n    at org.junit.Assert.fail(Assert.java:86)\n    at org.junit.Assert.assertTrue(Assert.java:41)\n    at org.junit.Assert.assertTrue(Assert.java:52)\n    at com.facebook.buck.distributed.build_client.StampedeBuildClientTest.racerBuildKilledWhenMostBuildRulesFinishedThenSynchronizedBuildKilledWhenDistBuildFails(StampedeBuildClientTest.java:352)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout.lambda$new$0(SameThreadFailOnTimeout.java:41)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\nBuilds after ran fine, so I don't think this is related.\n@mgrebenets only library rules should be modular. For binaries you can continue to use the bridging header (but not in combination with modular set to true, because binaries can't be modular.. Previously buck targets without a specifier would also return explicitly flavored targets. Considering this buckfile: https://gist.github.com/robbertvanginkel/28055312f0e93f8ee9a6d89862c9281c\n$ buck targets\n//:dep\n//:dep#default\n//:rule\nWheras with ... this is omitted.\n$ buck targets ...\nParsing buck files... 0.7 sec\n//:dep\n//:rule\nIs there a way to get this behaviour back if you're interested in listing all targets that have explicitly defined flavors?. Previously buck targets without a specifier would also return explicitly flavored targets. Considering this buckfile: https://gist.github.com/robbertvanginkel/28055312f0e93f8ee9a6d89862c9281c\n$ buck targets\n//:dep\n//:dep#default\n//:rule\nWheras with ... this is omitted.\n$ buck targets ...\nParsing buck files... 0.7 sec\n//:dep\n//:rule\nIs there a way to get this behaviour back if you're interested in listing all targets that have explicitly defined flavors?. Yes, this was specifically to address an issue that passed in buck test but did not in a generated project.. I couldn't find a typesafe way to express that binaryNode has AppleTestDescription.Arg, but after the typecheck this should be true. Suggestions welcome.\n. As far as I know, there is currently no way to run these test from the commandline except for using xcodebuild with a scheme and project. To run these tests you need to use some special testmanager daeamon and setup some more things, I'm think xctest is just for running logic tests. facebook/xctool#534 has some investigation into how involved running uitests is but no one seems to have reverse engineered it yet.\nLetting AppleTest decide this instead of the TestRunner doesn't seem like bad idea. Maybe we should extend the TestRule interface with a isSupported/testCanRun flag that is used for filtering?\n. That works, updated!\n. I couldn't find a good way to not instantiate the TestRule, instead I propose to return an empty list of test steps for ImmutableList<Step> runTests(...), with a dummy tests response that informs the user these tests have not been run.\nThe output of this is as follows:\nRESULTS FOR //mock:TestApp\nNOTESTS <100ms  0 Passed   0 Skipped   0 Failed   XCUITest runs not supported with buck test\n. I'll revert this.\n. I'll revert this.\n. The apple_bundle rule needs an info.plist, I just copied this over from another test fixture. I'll remove some of the keys so the file is generic.\n. I'm not sure if this is the best way to do this in java. Style comments appreciated.\n. This copies each header individually, and doens't work correctly if the symlinktree has subfolder. Is there an easy way to copy the contents of a Symlinktree?\n. These rpaths should be setup differently depending on what type of bundle the binary ends up in. For iOS and for framework bundles it needs to be @loader_path/Frameworks, but for OSX bundles @loader_path/../Frameworks. I think this might not be the best place to add this, and that it could be more appropriate as a flavor on the binary. Including frameworks a bundle that contains a binary influences that binary's linker flags because these rpaths should be set or not (although I'm not sure if its bad if they're always set). The flavor on the binary would add the appropriate linker flags for the platform/bundle combination.\nThoughts?\n. When including frameworks, I do not want to convert all apple_library rules into frameworks by default. I might have a huge library like opencv that would be better linked statically so you can still code strip and don't end up with huge frameworks.\nWe need to figure out an easy way to switch between libs and frameworks that allows fine grained control and doesn't force your whole tree one way or another.\n. I need to write some more asserts for this. It currently builds but doesn't run because of the aforementioned rpath problem. After I fix that I'll update the test case. The test case is elaborate on mixing frameworks/non frameworks and should give a good impression of the requirements for what I'm trying to achieve.\n. Some of this stuff is very similar to the prebuilt frameworks linking support from #818. It'd be good if I can find a way to consolidate the logic for linking with a framework.\n. The problem is that when specifying it here, you do not know what kind of bundle you end up in. Right not this is configured like an exported linker flag: the dependency framework tells the binary that when it links with it that the parent should also set an rpath value so it can find the framework with dyld. \nProblem is that the dependency itself doesn't know if the binary that calls the getNativeLinkableInput is a binary that will go into an osx app bundle, framework bundle or ios app bundle. Based on that info these paths should be different. That's why I don't think this setting can work correctly from here. I'll try to see if I can modify the binary's linker flags from AppleBundleDescription.\n. Yes, I think we'll need some way of saying \"by default everything frameworks or libraries\", but it should be overridable.\nWhat would you say is a better approach, having a non framework flavor or an extra field on apple_library like allows_framework_packaging?\n. I was thinking more like Java's interfaces with default methods, but it seems like they're only available from 8 and onwards.\nThe methods for implementing CxxPreprocessorDep, NativeLinkable as a famework bundle are very short, so I'll see if it makes sense to put them in an apple frameworks utility class.\n. Fixed this with no linker flags and an install_name_tool step in the apple bundle build rule.\n. Yes, that should work!\n. I think you can simplify this by just making it a String, and pass in the String version of the path you get from getResolver().getAbsolutePath(this.snapshotReferenceImagesPath.get().getLeft()) when calling the constructor for this.\nIts important that this is a sourcepath at AppleTest.java line 113, so that the rulekey reference for the cache uses a relative path. After you've called absolute path on it though you can just treat this as a string. No use in two code paths if the only thing you do with the Path is call toString at the end.. No not yet, wanted to get feedback first on if the type for additionalSchemeActions would be acceptable.. This is already present in the Test action. This is to mimic Xcode's default settings of having the same variables on test/profile as launch unless you explicitly specify otherwise.. On line 316, this is set to yes by default. So by default the test action will have the Launch actions environment variables. If however, you specify custom variables for the test action, you should not be using the launch action's variables here.\nIn xcode, shouldUseLaunchSchemeArgsEnv controls a checkbox that greys out the custom environment variables. This is an override that is enabled by default, so to have the custom variables we need to make sure the checkbox is not enabled.. Pushed a fix for this.. I did it like this to keep it consistent with the rest of the file, which all has getFlags with a parameter. With a parameter seems better than just getFlags, as that is a bit generic. If you have swiftBuckConfig.getFlags() which flags are you getting? Now its compiler flags, but that seems arbitrary.. \ud83d\udc4d . Apple's convention is to have a master header which has the same name as the target. This is convention for regular modules/frameworks and required for umbrella frameworks  [1]. When there is a pre-existing header with the same name, I think it is expected that that is the umbrella header.\nI can add an optional parameter to override it, but I don't think there's a strong usecase. It would also require us to add an extra field umbrella_header on apple_library to get user input for it, so maybe we should move the implementation to when that is needed?\n[1] https://developer.apple.com/library/content/documentation/MacOSX/Conceptual/BPFrameworks/Tasks/IncludingFrameworks.html. My bad, I'll fix it to take a name and fix the headers.. Should be absolute at this time. VFS' have an option for having the realpaths relative to the vfs file by specifying the option overlay-relative, but I haven't found a use case for that.. I named it when I was still thinking about the nested directories, I'll update it with something more appropriate. Changing this on a per target basis can be achieved by putting in an empty header with the module name now. We could make this more explicit but I agree that can be left for later.. Will change. Yes, that is correct. It seems non-ideal but after some investigation into how Xcode handles this this seems like the way to go. I couldn't find any configuration of settings in a hand made xcode project which would allow you to use both import styles.. \ud83d\udc4d. \ud83d\udc4d. \ud83d\udc4d . I'll consolidate this a little bit better in project gen so it is the same. As for consolidating between project gen and buck build I think we should change this by having a modular interface, so this logic can be shared between CxxLibrary and SwiftLibrary. This will allow us to implement it into SwiftDescriptions.populateSwiftLibraryDescriptionArg properly.. Confusingly this is named failResultEl2 but on line 340 marked with resulttype = succes. plutil is a util that has been on osx since 10.2, but unlike all these other tools it is not shipped in Xcode. This seemed like the preferred way of getting it here.. I'm not sure this is the correct place to put this. It seems like this might be better in the CxxSourceRuleFactory, but I couldn't find a simple place to inject it. This seemed the easiest place but I'm having a bit of trouble writing a reasonable test for it now, which would suggest that this isn't the best place.\nThe current suggestion I have now is passing along the modulename to CxxSourceRuleFactory if modular is set and it is present, to then add it to the flags through private Iterable<Arg> getRuleCompileFlags(CxxSource.Type type) there.. When looking at this, it seems like buck currently doesn't support osx tests with a bundle_loader/test_host_app. \nWhen I make a test for this, everything builds but when running it runs something like fbxctest -sdk macosx run-tests -appTest /path/to/test.xctest:/path/to/app.app, which fails fbxctest with UITests are not supported on OS X. I tried updating fbxctest in buck using the script at scripts/update-xctest.sh to take in facebook/FBSimulatorControl@67bb15bd0d5eb58730b045fc6892902c2671dac0, but afterwards it tries to run as a uitest.\nThis leaves the question (I'm less familiar with tests on osx), does osx support the application tests in which you compile a test bundle with a bundle_loader? If not than this blacklisting code does not apply, and we should probably throw an error when trying to build a test a bundle with test_host_app for a macosx target.\n. Agreed, I'll change it to test both.. Looked at this again, now it has a test on macos that validates the swift stdlib was linked statically.. In this case a value --test-runner-env could be overwritten by a target specific variable in a test. I think this makes sense as target level is more granular than a setting for a buck test command. However one could also argue that it is better to have a cli value override a value defined from a file. I don't have a strong preference here.. Open to suggestions. environment seems clear enough on apple_test but open to renaming it to something more specific like test_environment. Renaming this to env, to have the same naming as cxx_test and python_test.. Yes, very true and a much better idea. I guess I was so deep in the swift stuff I didn't even consider this. I'll make the change.. Fixed. Refactored into a static method on CxxLibraryMetadataFactory. We could delete the whole branch, but the reason I left it is because the code to copy frameworks into the final bundle will be useful for collecting prebuilt frameworks correctly in a later pr. . Because the apple library won't be built as a framework, so it shouldn't add itself as a framework dependency.. The warning was chosen to be set at error level as this is the level that shows up in the terminal by default. Warning can still be silenced with com.facebook.buck.apple.AppleLibraryDescription.AbstractAppleLibraryDescriptionArg.level=OFF in .bucklogging.properties.. @milend what I realised is that as soon as you remove the info_plist from the arg and still rely on the frameworks flavor, that would already throw an exception here. That makes the config option potentially a little less useful, as you can achieve the testing by just removing all info_plist parameters. Still leaving it in as a one stop switch might be easier than removing all the args.. Not an issue, swift requires unique filenames when compiling a module:\n$ swiftc temp/test.swift test.swift\n<unknown>:0: error: filename \"test.swift\" used twice: 'temp/test.swift' and 'test.swift'\n<unknown>:0: note: filenames are used to distinguish private declarations with the same name. ",
    "lowellk": "Same happening to me.\n. ",
    "lyahdav": "Maybe there should be a way to override the behavior of not specifying a\nplatform and explicitly specify a platform in which case it would set the\nbundle loader to the platform default which would resolve the issue for\nAppCode?\nOn Tuesday, July 12, 2016, Coneko notifications@github.com wrote:\n\nI don't remember the whole story behind that hack, but there are some\ndifferences in how Xcode and Buck see targets because for Xcode a target\ncan only be built for a certain platform, but Buck can build them for any\nplatform (macOS vs iOS for example).\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/806#issuecomment-231961415, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AAV69a11bC8T8TcuV7iMy89A3gTkMlmxks5qU0PngaJpZM4JJ73r\n.\n. \n",
    "raviagarwal7": "cc: @kageiit\n. note: all java test under test_release works fine, only robolectric tests fails.\n. @marcinkwiatkowski created a pull request - https://github.com/facebook/buck/pull/878\n. I agree using aapt would be too slow. \nYes, robolectric 3 resource loader supports styleable now. (we have been using robolectric 3 for a while now). \nFixing MiniApt would not really help as we will have to modify the values again at MergeAndroidResources step. We only care about entry names from miniAapt which is being returned correctly. Fixing it in MergeAndroidResources would suffice.\nI will work on getting the Styleable entries fixed which has base attributes in the same R.java file.\nNot sure how to get the attr values which comes from android.R.java (some styleable entries depend on it). We can either ignore them or just assign random values to it.\n. I agree using aapt would be too slow. \nYes, robolectric 3 resource loader supports styleable now. (we have been using robolectric 3 for a while now). \nFixing MiniApt would not really help as we will have to modify the values again at MergeAndroidResources step. We only care about entry names from miniAapt which is being returned correctly. Fixing it in MergeAndroidResources would suffice.\nI will work on getting the Styleable entries fixed which has base attributes in the same R.java file.\nNot sure how to get the attr values which comes from android.R.java (some styleable entries depend on it). We can either ignore them or just assign random values to it.\n. This is fixed now:\nhttps://github.com/facebook/buck/pull/879\nhttps://github.com/facebook/buck/pull/1068. @marcinkwiatkowski, @marcinkosiba -- bump for review.\n. @marcinkosiba, @russellporter -- bump for review\n. Seems to be a bug in facebook bot while reporting changes (view changes) if the feature branch is rebased on master instead of merged.\nI have squashed the commit with changes onto this branch - https://github.com/raviagarwal7/buck/commits/ravi/resource which is also rebased on top of master.\nHere is full changes of the pull request - https://github.com/facebook/buck/pull/879/commits/69c000ce477bfeca596374cae32eb25da9c6cb80\n. @marcinkosiba, using multimap to store the styleable ints now - https://github.com/facebook/buck/pull/879/commits/7f99ffcec494e47e607979acd23c9f0d61302c45. please re-review\n. @marcinkosiba, using multimap to store the styleable ints now - https://github.com/facebook/buck/pull/879/commits/7f99ffcec494e47e607979acd23c9f0d61302c45. please re-review\n. @marcinkosiba just found out that using multimap and splitting on the first _ is not feasible\nint[] styleable PatternPathMotion { 0x7f060003 }\nint styleable PatternPathMotion_patternPathData 0\nint[] styleable PercentLayout_Layout {  }\nint styleable PercentLayout_Layout_layout_aspectRatio 9\nint styleable PercentLayout_Layout_layout_heightPercent 1\nint styleable PercentLayout_Layout_layout_marginBottomPercent 6\nint styleable PercentLayout_Layout_layout_marginEndPercent 8\nwe can have styleable int[] which have _ in it's name eg: PercentLayout_Layout.\nif we split on first _ will result in no styleable int being found for PercentLayout_Layout.\nI am going to add this testcase and update the pull request to rely on sorting. \n. @marcinkosiba just found out that using multimap and splitting on the first _ is not feasible\nint[] styleable PatternPathMotion { 0x7f060003 }\nint styleable PatternPathMotion_patternPathData 0\nint[] styleable PercentLayout_Layout {  }\nint styleable PercentLayout_Layout_layout_aspectRatio 9\nint styleable PercentLayout_Layout_layout_heightPercent 1\nint styleable PercentLayout_Layout_layout_marginBottomPercent 6\nint styleable PercentLayout_Layout_layout_marginEndPercent 8\nwe can have styleable int[] which have _ in it's name eg: PercentLayout_Layout.\nif we split on first _ will result in no styleable int being found for PercentLayout_Layout.\nI am going to add this testcase and update the pull request to rely on sorting. \n. @marcinkosiba, let me know about the next steps.. @marcinkosiba, let me know about the next steps.. thanks @marcinkosiba, for some reason intellij didn't pick up the project settings. anyways fixed the lint errors and rebased to master as well.. do you have a sample test case where it fails, that I can try out? otherwise it would be hard to figure out what's going on. It works well with our robolectric tests.. I am breaking down the pull request into smaller ones so it's easier to figure out what is causing the failures.\ncreated the first one - https://github.com/facebook/buck/pull/1068. @dreiss -- I have rebased the changes to master, could you please try importing and see if this works?. @dreiss -- updated the pull request.. @dreiss -- updated the pull request.. This is a part of a bigger pull request - https://github.com/facebook/buck/pull/879#issuecomment-266749552. Breaking it down so that we can figure out what exactly breaks FB's robolectric tests.. @dreiss -- are the tests passing in FB's codebases with this change? would love to get this merged soon so I can break https://github.com/facebook/buck/pull/879 further.. nw, thanks for looking into this.. nw, thanks for looking into this.. @marcinkosiba @dreiss -- as discussed in https://github.com/facebook/buck/issues/816#issuecomment-236587468, there is an eaiser way to get resource id's for android_* resources. This change does that. \nBasically we can get the resource values of missing android attributes from int[] styleable of external aar's which generate their R.txt using AAPT. So for a module since we iterate in dependent order this works perfectly.. bump @dreiss -- this change is solely inside the new styleable method getStyleableResources, so should not affect any old behaviour. . sorry forgot to respond here. As @marcinkosiba mentioned it was happening because the java process crashed in between the test runs. Fixing individual test classes fixed the overall run.\n. cc: @dreiss @kageiit . cc: @styurin. cc: @bhamiltoncx @dreiss @kageiit . Closing this out as I am not currently working on this. Feel free to reopen if anyone feels like adding the support.. cc: @k21 @Coneko -- as you last touched this in https://github.com/facebook/buck/commit/3319cd6ce5c0126fea859932cc5c2494e95b63b9.\n. the robolectric_test rule doesn't depend on res_release#resources-symlink-tree and the folder is still created when running buck build //library/core:test_release, but the assets one is not created. \nSeems like a difference in how resources & assets are handled by the robolectric test rule.\ncould you point me in buck which creates the :res_release#resources-symlink-tree folder -- I can look into the implementing something similar for assets.\nCan we reopen the issue as it is still not resolved?\n. the robolectric_test rule doesn't depend on res_release#resources-symlink-tree and the folder is still created when running buck build //library/core:test_release, but the assets one is not created. \nSeems like a difference in how resources & assets are handled by the robolectric test rule.\ncould you point me in buck which creates the :res_release#resources-symlink-tree folder -- I can look into the implementing something similar for assets.\nCan we reopen the issue as it is still not resolved?\n. Thanks for the explanation @k21, will look into it.\nI am adding support for passing assets to robolectric runs - https://github.com/facebook/buck/pull/1180/files. Idea is to create the asset symlink tree only if the assets folder is non-empty. Before passing the assets folder down we need to make sure that the folder is present (https://github.com/facebook/buck/pull/1180/files#diff-8058a85314af62be6be9cf59db009bb9R225) which never fails for resources.\n. Thanks for the explanation @k21, will look into it.\nI am adding support for passing assets to robolectric runs - https://github.com/facebook/buck/pull/1180/files. Idea is to create the asset symlink tree only if the assets folder is non-empty. Before passing the assets folder down we need to make sure that the folder is present (https://github.com/facebook/buck/pull/1180/files#diff-8058a85314af62be6be9cf59db009bb9R225) which never fails for resources.\n. thanks @k21, was able to get it working by adding it to the runtime dependencies. could you please review - https://github.com/facebook/buck/pull/1180. thanks @k21, was able to get it working by adding it to the runtime dependencies. could you please review - https://github.com/facebook/buck/pull/1180. the pull request is merged now.. this seems to be a duplicate of https://github.com/facebook/buck/issues/1325.\n@cwoodwar6 a fix has been landed on master, please verify and close this issue if it works.. cc: @dreiss . tried running the build on ~15 different commits from now till 30th dec 2016, this still doesn't work. can't go before that as the app doesn't build with older versions.\n. tried running the build on ~15 different commits from now till 30th dec 2016, this still doesn't work. can't go before that as the app doesn't build with older versions.\n. verify caches returns no errors\n\u2570\u2500$ ../buck/bin/buck verify-caches\nVerifying file hash caches...\nExamined 5 caches.\nExamined 36137 files.\nNo errors\nVerifying rule key caches...\n. verify caches returns no errors\n\u2570\u2500$ ../buck/bin/buck verify-caches\nVerifying file hash caches...\nExamined 5 caches.\nExamined 36137 files.\nNo errors\nVerifying rule key caches...\n. Update\nSeems like this https://github.com/facebook/buck/commit/67d8a029f87e4a6324f2286fad53073e104a01b2 introduced a regesssion for the default case i.e when client.skip-action-graph-cache is not set or is false. \n(A)\n```\nrm -rf buck-out\nbuck build //app:bin_debug --config client.skip-action-graph-cache=true\nadd a print statement\nbuck build //app:bin_debug --config client.skip-action-graph-cache=true (change is detected)\n```\n(B)\n```\nrm -rf buck-out\nbuck build //app:bin_debug\nadd a print statement\nbuck build //app:bin_debug (change is not detected)\n```\nalso I noticed that after doing (A) if I do (B) with or without buck clean (instead of rm -rf buck-out) the change is detected as there is 100% cache hit from (A) run.\ncc: @bolinfest\n. Update\nSeems like this https://github.com/facebook/buck/commit/67d8a029f87e4a6324f2286fad53073e104a01b2 introduced a regesssion for the default case i.e when client.skip-action-graph-cache is not set or is false. \n(A)\n```\nrm -rf buck-out\nbuck build //app:bin_debug --config client.skip-action-graph-cache=true\nadd a print statement\nbuck build //app:bin_debug --config client.skip-action-graph-cache=true (change is detected)\n```\n(B)\n```\nrm -rf buck-out\nbuck build //app:bin_debug\nadd a print statement\nbuck build //app:bin_debug (change is not detected)\n```\nalso I noticed that after doing (A) if I do (B) with or without buck clean (instead of rm -rf buck-out) the change is detected as there is 100% cache hit from (A) run.\ncc: @bolinfest\n. @bolinfest I remember that building from before 67d8a02 doesn't work as intended as well, but setting client.skip-action-graph-cache=true works.\nI will try again and let you know.. @dreiss . cc @dreiss @cjhopman . 1st Run\n```\n\u2570\u2500$ find buck-out/bin/apps/app -iname *.jar | xargs md5                                                                                     \nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-1.jar) = 38227980524bafee054a1675bb3e1694\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-10.jar) = c9fbf2d012a71b7e2e43d6d11b9b9517\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-11.jar) = da45fc3fb935b794eeadd90742022ebd\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-2.jar) = 60de27808dbb113fe52e9797aa7498b8\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-3.jar) = e9c5c3ed15d308674a6d6737e2e0ffa8\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-4.jar) = 32b7b30f1b9242eb64bddcf8487d908a\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-5.jar) = 659aa818dcde4b1ce8d3aab94c661d3e\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-6.jar) = e85f84daa3aa329aae795b7c429ecf91\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-7.jar) = 2a2d5e995cd1330071c1fa00c2d562fc\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-8.jar) = d9ac33aa22e5050737fa71d44d67f3a9\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-9.jar) = 59570fc4e0e8dd74386903ffb126ccd0\nMD5 (buck-out/bin/apps/app/app/bin_debug_split_zip/primary.jar) = 49006248fe2238af70a8bed5a9fe1d7f\n\u2570\u2500$ find buck-out/bin/apps/app -iname *.dex | xargs md5\nMD5 (buck-out/bin/apps/app/app/.dex/bin_debug/classes.dex) = cce7d23180946226599229d642cc7e0c\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes10.dex) = f3dc9c09ec62862292792dc3a7cd85f2\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes11.dex) = fd321a1ffbc69efe79283e5e80d4c9a9\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes12.dex) = 2cd78146be97550e700ae10a004c9581\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes2.dex) = 739216888f45fda1f793ec663b7cdbad\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes3.dex) = e81526446d000d9e55ebfea4a0e2c09c\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes4.dex) = 6b8c913e2132d115d5baff8aff52ceb5\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes5.dex) = 3b3a3c7c2ab7b2172eae4a233b0abd58\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes6.dex) = 9b2784b2660902e8277bb25e2cd77950\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes7.dex) = 5593d76ea30599b939b52f4fa8bd33f0\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes8.dex) = 570512d498e40e1f6de08b89358a74de\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes9.dex) = 234653e13325d95c0af1f145e4cff2f3\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes.dex) = 4917fbe84393fa75bd617601fa60bec2\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes10.dex) = 25b3022e050783d9bc2af5e8b778515b\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes11.dex) = 25b3022e050783d9bc2af5e8b778515b\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes12.dex) = 25b3022e050783d9bc2af5e8b778515b\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes2.dex) = 664fb88e1a6a6642e3aa99572538a326\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes3.dex) = 4519218930e1e0e1cee71a243edf0254\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes4.dex) = 66590774768249d055f3b9a2f438ce09\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes5.dex) = 3dc764118df47920ca6b67373a7076cb\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes6.dex) = 527880d39233fe19f9aa11d7ce9650d1\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes7.dex) = 9a79a619a9ec1c9e913d8cf027c8b027\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes8.dex) = 425dc4c22d1c71a55c0437139f9177ad\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes9.dex) = 608cf87f8cf7fdd51b284fb15c5a68f8\n```\n2nd Run (after making the above layout changes)\n```\n\u2570\u2500$ find buck-out/bin/apps/app -iname *.jar | xargs md5\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-1.jar) = 113e68937f3d46cd7e4265ef8d134003\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-10.jar) = f64fac524c4b520c8cafc4fb81b20d0e\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-11.jar) = a6a753da68d292fe439dd953b007c2ba\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-2.jar) = ab9125b5cadf9522333a8e9e22c37025\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-3.jar) = 901975f90a489dec9890c5f621ee33d6\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-4.jar) = 045a899905e895c0eb9590b2a0a78ca2\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-5.jar) = af9ed11189e20677886d9e1771e660e9\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-6.jar) = 76b2ed4c0bcc4d061511346d3102cdd0\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-7.jar) = fcf49be2b89e9e5d1c69ae252f301cba\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-8.jar) = 116878f30d04a2cd5ac897d004472bfd\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_zip/secondary-9.jar) = c0068318589282e8a68cf10fd582fc7c\nMD5 (buck-out/bin/apps/app/app/bin_debug_split_zip/primary.jar) = d0201ff6ba3d392f76341112522d4817\n\u2570\u2500$ find buck-out/bin/apps/app -iname *.dex | xargs md5\nMD5 (buck-out/bin/apps/app/app/.dex/bin_debug/classes.dex) = cce7d23180946226599229d642cc7e0c\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes10.dex) = f3dc9c09ec62862292792dc3a7cd85f2\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes11.dex) = fd321a1ffbc69efe79283e5e80d4c9a9\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes12.dex) = 2cd78146be97550e700ae10a004c9581\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes2.dex) = 739216888f45fda1f793ec663b7cdbad\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes3.dex) = e81526446d000d9e55ebfea4a0e2c09c\n(changed) MD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes4.dex) = e22f91d064c85fa801c5d257b9c47842\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes5.dex) = 3b3a3c7c2ab7b2172eae4a233b0abd58\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes6.dex) = 9b2784b2660902e8277bb25e2cd77950\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes7.dex) = 5593d76ea30599b939b52f4fa8bd33f0\n(changed) MD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes8.dex) = 0c43f9d22c3206bb11e35be80359f1f8\nMD5 (buck-out/bin/apps/app/app/bin_debug_secondary_dex/assets/secondary-program-dex-jars/classes9.dex) = 234653e13325d95c0af1f145e4cff2f3\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes.dex) = 4917fbe84393fa75bd617601fa60bec2\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes10.dex) = 25b3022e050783d9bc2af5e8b778515b\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes11.dex) = 25b3022e050783d9bc2af5e8b778515b\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes12.dex) = 25b3022e050783d9bc2af5e8b778515b\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes2.dex) = 664fb88e1a6a6642e3aa99572538a326\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes3.dex) = 4519218930e1e0e1cee71a243edf0254\n(changed) MD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes4.dex) = d02c676ff199b7ab99419be911184ff1\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes5.dex) = 3dc764118df47920ca6b67373a7076cb\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes6.dex) = 527880d39233fe19f9aa11d7ce9650d1\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes7.dex) = 9a79a619a9ec1c9e913d8cf027c8b027\n(changed) MD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes8.dex) = a613ad020ed7612d16562605d8e31b6b\nMD5 (buck-out/bin/apps/app/app/bin_debug_smart_dex/.success/classes9.dex) = 608cf87f8cf7fdd51b284fb15c5a68f8\n```\nOnly changed ones are the classes4.dex & classes8.dex which contained the Java Code changed class files. It seems like R.java is not considered during calculation of the hashes of the generated dex files. \nclasses10.dex, classes11.dex & classes12.dex all have the same calculated hash as they only contain R.java files.\n@cjhopman -- do you know if this is intended? if so how should the R.java be invalidated on a change and added to the dex?\nAlso, deleting buck-out/bin/apps/app/app/__bin_debug_smart_dex__/.success after layout changes and building picks up the changes correctly.. the app doesn't use pre-dexing as the main module is pretty big.\nthis is probably a subset of the issue (https://github.com/facebook/buck/issues/1277) I was looking into with mbolin. This is not related to the action graph cache as the issue happens with or without buckd.\nIn current state we have client.skip-action-graph-cache=true which makes the java code changes detectable but the layout changes are not. The hashes of the dex files computed after the smart dex step for caching don't take into account any R.java files.\n. the app doesn't use pre-dexing as the main module is pretty big.\nthis is probably a subset of the issue (https://github.com/facebook/buck/issues/1277) I was looking into with mbolin. This is not related to the action graph cache as the issue happens with or without buckd.\nIn current state we have client.skip-action-graph-cache=true which makes the java code changes detectable but the layout changes are not. The hashes of the dex files computed after the smart dex step for caching don't take into account any R.java files.\n. seems like classNamesToHashes  doesn't contain any R.class entries and hence not being considered for hash calculation for the dex.\n. seems like classNamesToHashes  doesn't contain any R.class entries and hence not being considered for hash calculation for the dex.\n. @dreiss @cjhopman . @dreiss @cjhopman . pull request for adding abi classpath macro - https://github.com/facebook/buck/pull/1780/. cc: @dreiss @kageiit . @dreiss - please review, have made the requested code review changes.. just rebased to latest master although didn't encounter any merged conflicts.. just rebased to latest master although didn't encounter any merged conflicts.. nw, thanks for landing!. nw, thanks for landing!. closing as it's merged into master now.. closing as it's merged into master now.. not sure why it failed, was able to build, run pmd and test successfully on my local machine.. sorry for the delay, I will get more details about the issue.. note: the class actually ends up in the main dex, but the error still happens\nin primary.jar.txt:\n172 13 1 io/github/inflationx/calligraphy3/CalligraphyInterceptor.class\nin classes.dex:\n\n. note: the class actually ends up in the main dex, but the error still happens\nin primary.jar.txt:\n172 13 1 io/github/inflationx/calligraphy3/CalligraphyInterceptor.class\nin classes.dex:\n\n. cc: @dreiss . Added more context in the description and also added to the macros soy.\nHave fixed the build errors as well.. @styurin -- updated the description with the actual changes, let me know if you have other queries.. @styurin -- updated the description with the actual changes, let me know if you have other queries.. @styurin, updated the description with the suggested format.. the changes to MergeAndroidResourcesStepTest.java takes care of the case I added. I can try adding integration test as well.. cc: @jkeljo, @kageiit . Added tests.. @styurin, I have fixed the typos in the description.  also, seems like it doesn't break Kotlin modules.. do you have action graph caching enabled? if so try skipping the action graph cache and see if it works - https://buckbuild.com/files-and-dirs/buckconfig.html#client.skip-action-graph-cache\n. cc: @styurin . > This change will add proguard target to the deps, but where is it used?\ngetProguardJarOverride is the function which provides the SourcePath corresponding to the specified proguard target or progaurd jar path. The target is added to the deps to make sure it is built before the jar from getProguardJarOverride is used.. @styurin -- Not sure about this failure either. Works locally for me.\nBUILDING: FINISHED IN 1.0s (100%) 5/5 JOBS, 5 UPDATED\nBUILD SUCCEEDED\nBuck encountered an internal error\njava.lang.RuntimeException: com.facebook.buck.core.exceptions.HumanReadableException: Error while trying to close the worker process /bin/bash -e -c /tmp/junit-temp-path5883063720243665947/buck-out/gen/__external_tool__/external_tool.sh --num-jobs 2 --loc /tmp/junit-temp-path5883063720243665947/buck-out/gen/__external_tool__/external_tool.sh.\n    at com.facebook.buck.worker.WorkerProcessPool.close(WorkerProcessPool.java:102)\n    at com.google.common.io.Closer.close(Closer.java:216)\n    at com.facebook.buck.step.AbstractExecutionContext.close(AbstractExecutionContext.java:223)\n    at com.facebook.buck.step.ExecutionContext.close(ExecutionContext.java:50)\n    at com.facebook.buck.cli.AbstractCommand.lambda$prepareExecutionContext$1(AbstractCommand.java:251)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:243)\n    at com.facebook.buck.cli.AbstractContainerCommand.run(AbstractContainerCommand.java:79)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:1282)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(ProjectWorkspace.java:529)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(ProjectWorkspace.java:444)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommand(ProjectWorkspace.java:394)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckBuild(ProjectWorkspace.java:253)\n    at com.facebook.buck.shell.WorkerToolRuleIntegrationTest.testWorkerToolArgs(WorkerToolRuleIntegrationTest.java:166)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout.lambda$new$0(SameThreadFailOnTimeout.java:41)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\nCaused by: com.facebook.buck.core.exceptions.HumanReadableException: Error while trying to close the worker process /bin/bash -e -c /tmp/junit-temp-path5883063720243665947/buck-out/gen/__external_tool__/external_tool.sh --num-jobs 2 --loc /tmp/junit-temp-path5883063720243665947/buck-out/gen/__external_tool__/external_tool.sh.\n    at com.facebook.buck.worker.WorkerProcess.close(WorkerProcess.java:168)\n    at com.facebook.buck.worker.WorkerProcessPool$WorkerLifecycle.close(WorkerProcessPool.java:170)\n    at com.facebook.buck.worker.WorkerProcessPool.close(WorkerProcessPool.java:92)\n    ... 28 more\nCaused by: com.facebook.buck.core.exceptions.HumanReadableException: CommandSender (137553424)'s process was already killed\n    at com.facebook.buck.worker.WorkerProcessProtocolZero$CommandSender.close(WorkerProcessProtocolZero.java:191)\n    at com.facebook.buck.worker.WorkerProcess.close(WorkerProcess.java:143)\n    ... 30 more\n=== STDOUT ===\n====ERROR LOGS====\nPASS      4.3s  3 Passed   0 Skipped   0 Failed   com.facebook.buck.testrunner.TestSelectorsJUnitVersionsIntegrationTest\nPASS      7.3s  3 Passed   0 Skipped   0 Failed   com.facebook.buck.testrunner.TimeoutIntegrationTest\nASSUME   202ms  0 Passed   6 Skipped   0 Failed   com.facebook.buck.util.versioncontrol.HgCmdLineInterfaceIntegrationTest\nTESTS FAILED: 2 FAILURES\nFailed target: //test/com/facebook/buck/features/js:js\nFAIL com.facebook.buck.features.js.JsRulesIntegrationTest\nFailed target: //test/com/facebook/buck/shell:shell\nFAIL com.facebook.buck.shell.WorkerToolRuleIntegrationTest\nThe command \"./scripts/travisci_run.sh\" exited with 32.\nDone. Your build exited with 1.. @styurin -- Not sure about this failure either. Works locally for me.\nBUILDING: FINISHED IN 1.0s (100%) 5/5 JOBS, 5 UPDATED\nBUILD SUCCEEDED\nBuck encountered an internal error\njava.lang.RuntimeException: com.facebook.buck.core.exceptions.HumanReadableException: Error while trying to close the worker process /bin/bash -e -c /tmp/junit-temp-path5883063720243665947/buck-out/gen/__external_tool__/external_tool.sh --num-jobs 2 --loc /tmp/junit-temp-path5883063720243665947/buck-out/gen/__external_tool__/external_tool.sh.\n    at com.facebook.buck.worker.WorkerProcessPool.close(WorkerProcessPool.java:102)\n    at com.google.common.io.Closer.close(Closer.java:216)\n    at com.facebook.buck.step.AbstractExecutionContext.close(AbstractExecutionContext.java:223)\n    at com.facebook.buck.step.ExecutionContext.close(ExecutionContext.java:50)\n    at com.facebook.buck.cli.AbstractCommand.lambda$prepareExecutionContext$1(AbstractCommand.java:251)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:243)\n    at com.facebook.buck.cli.AbstractContainerCommand.run(AbstractContainerCommand.java:79)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:1282)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(ProjectWorkspace.java:529)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommandWithEnvironmentOverridesAndContext(ProjectWorkspace.java:444)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckCommand(ProjectWorkspace.java:394)\n    at com.facebook.buck.testutil.integration.ProjectWorkspace.runBuckBuild(ProjectWorkspace.java:253)\n    at com.facebook.buck.shell.WorkerToolRuleIntegrationTest.testWorkerToolArgs(WorkerToolRuleIntegrationTest.java:166)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)\n    at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)\n    at org.junit.rules.RunRules.evaluate(RunRules.java:20)\n    at com.facebook.buck.testrunner.SameThreadFailOnTimeout.lambda$new$0(SameThreadFailOnTimeout.java:41)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\nCaused by: com.facebook.buck.core.exceptions.HumanReadableException: Error while trying to close the worker process /bin/bash -e -c /tmp/junit-temp-path5883063720243665947/buck-out/gen/__external_tool__/external_tool.sh --num-jobs 2 --loc /tmp/junit-temp-path5883063720243665947/buck-out/gen/__external_tool__/external_tool.sh.\n    at com.facebook.buck.worker.WorkerProcess.close(WorkerProcess.java:168)\n    at com.facebook.buck.worker.WorkerProcessPool$WorkerLifecycle.close(WorkerProcessPool.java:170)\n    at com.facebook.buck.worker.WorkerProcessPool.close(WorkerProcessPool.java:92)\n    ... 28 more\nCaused by: com.facebook.buck.core.exceptions.HumanReadableException: CommandSender (137553424)'s process was already killed\n    at com.facebook.buck.worker.WorkerProcessProtocolZero$CommandSender.close(WorkerProcessProtocolZero.java:191)\n    at com.facebook.buck.worker.WorkerProcess.close(WorkerProcess.java:143)\n    ... 30 more\n=== STDOUT ===\n====ERROR LOGS====\nPASS      4.3s  3 Passed   0 Skipped   0 Failed   com.facebook.buck.testrunner.TestSelectorsJUnitVersionsIntegrationTest\nPASS      7.3s  3 Passed   0 Skipped   0 Failed   com.facebook.buck.testrunner.TimeoutIntegrationTest\nASSUME   202ms  0 Passed   6 Skipped   0 Failed   com.facebook.buck.util.versioncontrol.HgCmdLineInterfaceIntegrationTest\nTESTS FAILED: 2 FAILURES\nFailed target: //test/com/facebook/buck/features/js:js\nFAIL com.facebook.buck.features.js.JsRulesIntegrationTest\nFailed target: //test/com/facebook/buck/shell:shell\nFAIL com.facebook.buck.shell.WorkerToolRuleIntegrationTest\nThe command \"./scripts/travisci_run.sh\" exited with 32.\nDone. Your build exited with 1.. @styurin -- tests seems to have passed. could you please import this. thanks!. @styurin -- tests seems to have passed. could you please import this. thanks!. cc: @styurin . > Can you provide an example how it should be used? We have integration tests for robolectric_test.\nso when providing source path it would be a genrule:\n```\nhttp_file(\n    name = 'android-all-5.0.2_r3-robolectric-r0.jar',\n    urls = [ 'mvn:org.robolectric:android-all:jar:5.0.2_r3-robolectric-r0' ],\n    sha256 = '5e63d4c7f2c691afed648bf0675e0b0a76d19f0e23d93705f4faf9ed3b2734de',\n)\nhttp_file(\n    name = 'android-all-8.1.0-robolectric-4611349.jar',\n    urls = [ 'mvn:org.robolectric:android-all:jar:8.1.0-robolectric-4611349' ],\n    sha256 = '01b3364bc0b4ca099929aa4d818529c7ec05e18b9e4c1e667f99955b16ae19b4',\n)\ntargets = [\n    ':android-all-8.1.0-robolectric-4611349.jar',\n    ':android-all-5.0.2_r3-robolectric-r0.jar',\n]\nbash_list = (\n    [\"mkdir -p $OUT; \"] +\n    ['cp $(location {}) $OUT/{}; '.format(target, target[1:]) for target in targets]\n)\ngenrule(\n    name = 'robolectric_cache',\n    bash = \" \".join(bash_list),\n    out = \"cache\",\n    visibility = [ 'PUBLIC' ],\n)\n```\nNow the robolectric_test rule will have robolectricRuntimeDeps = '//:robolectric_cache as the source path.\nin case of path we would specify robolectricRuntimeDeps = <output of robolectric_cache>\nWe can now have a robolectric_test rule which uses this, but I am not sure how to set that up in the current RobolectricTestRuleIntegrationTest.java class. https://github.com/facebook/buck/blob/master/test/com/facebook/buck/android/RobolectricTestRuleIntegrationTest.java#L39\nany ideas?\n. > I recently updated robolectric integration tests to specify runtime dir in vm_args using a macro: 9a880c6. It looks the same except that you would need to use robolectric_runtime_dependency instead of vm_aergs.\nyup, updated to use  robolectric_runtime_dependency instead of vm_args. also seems like below tests are failing on master and also on this diff. not sure how to fix this.\ncom.facebook.buck.jvm.groovy.GroovyTestIntegrationTest#allTestsPassingMakesTheBuildResultASuccess\ncom.facebook.buck.jvm.groovy.GroovyTestIntegrationTest#oneTestFailingMakesTheBuildResultAFailure\n. cc @kageiit, @cwoodwar6, @thalescm . this is now ready for review.\ncc: @styurin, @thalescm, @kageiit . sure, let me break this PR into smaller ones. . sure, let me break this PR into smaller ones. . will rebase once https://github.com/facebook/buck/pull/2131 gets merged.. will rebase once https://github.com/facebook/buck/pull/2131 gets merged.. @styurin, was the import successful?. Below is the failing test.\nPASS      6.8s  3 Passed   0 Skipped   0 Failed   com.facebook.buck.testrunner.TimeoutIntegrationTest\nASSUME   208ms  0 Passed   6 Skipped   0 Failed   com.facebook.buck.util.versioncontrol.HgCmdLineInterfaceIntegrationTest\nTESTS FAILED: 2 FAILURES\nFailed target: //test/com/facebook/buck/shell:shell\nFAIL com.facebook.buck.shell.WorkerToolRuleIntegrationTest\nThe command \"./scripts/travisci_run.sh\" exited with 32.\nBut passes for me locally. \n\u2570\u2500$ bin/buck test //test/com/facebook/buck/shell:shell --filter com.facebook.buck.shell.WorkerToolRuleIntegrationTest\nBuilding: finished in 3.4 sec (100%) 744/744 jobs, 16 updated\n  Total time: 4.0 sec\nTesting: finished in 13.9 sec (7 PASS/0 FAIL)\nRESULTS FOR SELECTED TESTS\nPASS     12.9s  7 Passed   0 Skipped   0 Failed   com.facebook.buck.shell.WorkerToolRuleIntegrationTest\nTESTS PASSED. Below is the failing test.\nPASS      6.8s  3 Passed   0 Skipped   0 Failed   com.facebook.buck.testrunner.TimeoutIntegrationTest\nASSUME   208ms  0 Passed   6 Skipped   0 Failed   com.facebook.buck.util.versioncontrol.HgCmdLineInterfaceIntegrationTest\nTESTS FAILED: 2 FAILURES\nFailed target: //test/com/facebook/buck/shell:shell\nFAIL com.facebook.buck.shell.WorkerToolRuleIntegrationTest\nThe command \"./scripts/travisci_run.sh\" exited with 32.\nBut passes for me locally. \n\u2570\u2500$ bin/buck test //test/com/facebook/buck/shell:shell --filter com.facebook.buck.shell.WorkerToolRuleIntegrationTest\nBuilding: finished in 3.4 sec (100%) 744/744 jobs, 16 updated\n  Total time: 4.0 sec\nTesting: finished in 13.9 sec (7 PASS/0 FAIL)\nRESULTS FOR SELECTED TESTS\nPASS     12.9s  7 Passed   0 Skipped   0 Failed   com.facebook.buck.shell.WorkerToolRuleIntegrationTest\nTESTS PASSED. @styurin -- seems like the tests passed. please review, this is the first diff broken from https://github.com/facebook/buck/pull/2122. @styurin -- seems like the tests passed. please review, this is the first diff broken from https://github.com/facebook/buck/pull/2122. this change fails the robolectric integration tests (fails locally for me too). Not sure why as it is not modifying any major things in Robolectric tests, running out of ideas. Tried bunch of things but nested buck integration tests is just hard to debug.\n@styurin -- would appreciate some insight into this\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES, 100.0% CACHE MISS\nBUILDING: FINISHED IN 6.4s (100%) 55/55 JOBS, 55 UPDATED\nBUILD SUCCEEDED\nTESTING //java/com/sample/lib:test\nFAIL      3.2s  0 Passed   0 Skipped   1 Failed   com.facebook.sample.ResourcesTest\nFAILURE com.facebook.sample.ResourcesTest testResources: call site initialization exception\njava.lang.BootstrapMethodError: call site initialization exception\n    at java.lang.invoke.CallSite.makeSite(CallSite.java:341)\n    at java.lang.invoke.MethodHandleNatives.linkCallSiteImpl(MethodHandleNatives.java:307)\n    at java.lang.invoke.MethodHandleNatives.linkCallSite(MethodHandleNatives.java:297)\n    at android.content.pm.PackageManager.<init>(PackageManager.java)\n    at org.robolectric.android.StubPackageManager.<init>(StubPackageManager.java)\n    at org.robolectric.res.builder.DefaultPackageManager.<init>(DefaultPackageManager.java:90)\n    at org.robolectric.android.internal.ParallelUniverse.setUpApplicationState(ParallelUniverse.java:63)\n    at org.robolectric.RobolectricTestRunner.beforeTest(RobolectricTestRunner.java:290)\n    at org.robolectric.internal.SandboxTestRunner$2.evaluate(SandboxTestRunner.java:203)\n    at org.robolectric.internal.SandboxTestRunner.runChild(SandboxTestRunner.java:109)\n    at org.robolectric.internal.SandboxTestRunner.runChild(SandboxTestRunner.java:36)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.robolectric.internal.SandboxTestRunner$1.evaluate(SandboxTestRunner.java:63)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runners.Suite.runChild(Suite.java:128)\n    at org.junit.runners.Suite.runChild(Suite.java:27)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:115)\n    at com.facebook.buck.testrunner.JUnitRunner.run(JUnitRunner.java:97)\n    at com.facebook.buck.testrunner.BaseRunner.runAndExit(BaseRunner.java:296)\n    at com.facebook.buck.testrunner.JUnitMain.main(JUnitMain.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.facebook.buck.jvm.java.runner.FileClassPathRunner.main(FileClassPathRunner.java:79)\nCaused by: java.lang.NoClassDefFoundError: android/os/UserHandle\n    at java.lang.Class.getDeclaredMethods0(Native Method)\n    at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\n    at java.lang.Class.privateGetMethodRecursive(Class.java:3048)\n    at java.lang.Class.getMethod0(Class.java:3018)\n    at java.lang.Class.getMethod(Class.java:1784)\n    at org.robolectric.internal.bytecode.ShadowWrangler.findShadowMethodInternal(ShadowWrangler.java:241)\n    at org.robolectric.internal.bytecode.ShadowWrangler.findShadowMethod(ShadowWrangler.java:208)\n    at org.robolectric.internal.bytecode.ShadowWrangler.findShadowMethod(ShadowWrangler.java:142)\n    at org.robolectric.internal.bytecode.RobolectricInternals.findShadowMethod(RobolectricInternals.java:39)\n    at org.robolectric.internal.bytecode.InvokeDynamicSupport.bindCallSite(InvokeDynamicSupport.java:121)\n    at org.robolectric.internal.bytecode.InvokeDynamicSupport.bootstrap(InvokeDynamicSupport.java:63)\n    at java.lang.invoke.CallSite.makeSite(CallSite.java:294)\n    ... 35 more\nCaused by: java.lang.ClassNotFoundException: android.os.UserHandle\n    at org.robolectric.internal.bytecode.SandboxClassLoader.getByteCode(SandboxClassLoader.java:161)\n    at org.robolectric.internal.bytecode.SandboxClassLoader.maybeInstrumentClass(SandboxClassLoader.java:108)\n    at org.robolectric.internal.bytecode.SandboxClassLoader.findClass(SandboxClassLoader.java:101)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    ... 47 more\nTESTS FAILED: 1 FAILURE\nFailed target: //java/com/sample/lib:test\nFAIL com.facebook.sample.ResourcesTest\n=== STDOUT ===\n====ERROR LOGS====\n[2018-12-12 17:04:39.194][warn ][tid:08][com.facebook.buck.cli.Main] Manager cannot be async (as currently set in config) when not on daemon. Initializing blocking manager.\n[2018-12-12 17:04:39.530][warn ][tid:08][com.facebook.buck.apple.AppleConfig] Could not execute xcode-select, continuing without developer dir.\nPASS     13.9s 10 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidAppModularityIntegrationTest\nPASS     10.9s  4 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidConsistencyIntegrationTest\nPASS     20.9s 14 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidLibraryAsAnnotationProcessorHostIntegrationTest\nPASS     21.0s 22 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidLibraryDescriptionIntegrationTest\nPASS      6.6s  4 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidLibraryGraphEnhancerIntegrationTest\nPASS    109.0s 18 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidLibraryIntegrationTest\nPASS     21.8s 12 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidResourceFilterIntegrationTest\nPASS      5.9s  3 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidResourceIntegrationTest\nPASS      7.3s  1 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidResourceLibraryDepIntegrationTest\nPASS      5.7s  1 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidResourceParsePackageFromManifestIntegrationTest\nPASS     10.6s  5 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidXmlFileIntegrationTest\nTESTS FAILED: 4 FAILURES\nFailed target: //test/com/facebook/buck/android:integration1\nFAIL com.facebook.buck.android.RobolectricTestRuleIntegrationTest\nThe command \"./scripts/travisci_run.sh\" exited with 32.\ncache.2\nstore build cache\n0.00s1.62snothing changed, not updating cache\nDone. Your build exited with 1.. this change fails the robolectric integration tests (fails locally for me too). Not sure why as it is not modifying any major things in Robolectric tests, running out of ideas. Tried bunch of things but nested buck integration tests is just hard to debug.\n@styurin -- would appreciate some insight into this\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES, 100.0% CACHE MISS\nBUILDING: FINISHED IN 6.4s (100%) 55/55 JOBS, 55 UPDATED\nBUILD SUCCEEDED\nTESTING //java/com/sample/lib:test\nFAIL      3.2s  0 Passed   0 Skipped   1 Failed   com.facebook.sample.ResourcesTest\nFAILURE com.facebook.sample.ResourcesTest testResources: call site initialization exception\njava.lang.BootstrapMethodError: call site initialization exception\n    at java.lang.invoke.CallSite.makeSite(CallSite.java:341)\n    at java.lang.invoke.MethodHandleNatives.linkCallSiteImpl(MethodHandleNatives.java:307)\n    at java.lang.invoke.MethodHandleNatives.linkCallSite(MethodHandleNatives.java:297)\n    at android.content.pm.PackageManager.<init>(PackageManager.java)\n    at org.robolectric.android.StubPackageManager.<init>(StubPackageManager.java)\n    at org.robolectric.res.builder.DefaultPackageManager.<init>(DefaultPackageManager.java:90)\n    at org.robolectric.android.internal.ParallelUniverse.setUpApplicationState(ParallelUniverse.java:63)\n    at org.robolectric.RobolectricTestRunner.beforeTest(RobolectricTestRunner.java:290)\n    at org.robolectric.internal.SandboxTestRunner$2.evaluate(SandboxTestRunner.java:203)\n    at org.robolectric.internal.SandboxTestRunner.runChild(SandboxTestRunner.java:109)\n    at org.robolectric.internal.SandboxTestRunner.runChild(SandboxTestRunner.java:36)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.robolectric.internal.SandboxTestRunner$1.evaluate(SandboxTestRunner.java:63)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runners.Suite.runChild(Suite.java:128)\n    at org.junit.runners.Suite.runChild(Suite.java:27)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:363)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:137)\n    at org.junit.runner.JUnitCore.run(JUnitCore.java:115)\n    at com.facebook.buck.testrunner.JUnitRunner.run(JUnitRunner.java:97)\n    at com.facebook.buck.testrunner.BaseRunner.runAndExit(BaseRunner.java:296)\n    at com.facebook.buck.testrunner.JUnitMain.main(JUnitMain.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.facebook.buck.jvm.java.runner.FileClassPathRunner.main(FileClassPathRunner.java:79)\nCaused by: java.lang.NoClassDefFoundError: android/os/UserHandle\n    at java.lang.Class.getDeclaredMethods0(Native Method)\n    at java.lang.Class.privateGetDeclaredMethods(Class.java:2701)\n    at java.lang.Class.privateGetMethodRecursive(Class.java:3048)\n    at java.lang.Class.getMethod0(Class.java:3018)\n    at java.lang.Class.getMethod(Class.java:1784)\n    at org.robolectric.internal.bytecode.ShadowWrangler.findShadowMethodInternal(ShadowWrangler.java:241)\n    at org.robolectric.internal.bytecode.ShadowWrangler.findShadowMethod(ShadowWrangler.java:208)\n    at org.robolectric.internal.bytecode.ShadowWrangler.findShadowMethod(ShadowWrangler.java:142)\n    at org.robolectric.internal.bytecode.RobolectricInternals.findShadowMethod(RobolectricInternals.java:39)\n    at org.robolectric.internal.bytecode.InvokeDynamicSupport.bindCallSite(InvokeDynamicSupport.java:121)\n    at org.robolectric.internal.bytecode.InvokeDynamicSupport.bootstrap(InvokeDynamicSupport.java:63)\n    at java.lang.invoke.CallSite.makeSite(CallSite.java:294)\n    ... 35 more\nCaused by: java.lang.ClassNotFoundException: android.os.UserHandle\n    at org.robolectric.internal.bytecode.SandboxClassLoader.getByteCode(SandboxClassLoader.java:161)\n    at org.robolectric.internal.bytecode.SandboxClassLoader.maybeInstrumentClass(SandboxClassLoader.java:108)\n    at org.robolectric.internal.bytecode.SandboxClassLoader.findClass(SandboxClassLoader.java:101)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\n    ... 47 more\nTESTS FAILED: 1 FAILURE\nFailed target: //java/com/sample/lib:test\nFAIL com.facebook.sample.ResourcesTest\n=== STDOUT ===\n====ERROR LOGS====\n[2018-12-12 17:04:39.194][warn ][tid:08][com.facebook.buck.cli.Main] Manager cannot be async (as currently set in config) when not on daemon. Initializing blocking manager.\n[2018-12-12 17:04:39.530][warn ][tid:08][com.facebook.buck.apple.AppleConfig] Could not execute xcode-select, continuing without developer dir.\nPASS     13.9s 10 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidAppModularityIntegrationTest\nPASS     10.9s  4 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidConsistencyIntegrationTest\nPASS     20.9s 14 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidLibraryAsAnnotationProcessorHostIntegrationTest\nPASS     21.0s 22 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidLibraryDescriptionIntegrationTest\nPASS      6.6s  4 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidLibraryGraphEnhancerIntegrationTest\nPASS    109.0s 18 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidLibraryIntegrationTest\nPASS     21.8s 12 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidResourceFilterIntegrationTest\nPASS      5.9s  3 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidResourceIntegrationTest\nPASS      7.3s  1 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidResourceLibraryDepIntegrationTest\nPASS      5.7s  1 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidResourceParsePackageFromManifestIntegrationTest\nPASS     10.6s  5 Passed   0 Skipped   0 Failed   com.facebook.buck.android.AndroidXmlFileIntegrationTest\nTESTS FAILED: 4 FAILURES\nFailed target: //test/com/facebook/buck/android:integration1\nFAIL com.facebook.buck.android.RobolectricTestRuleIntegrationTest\nThe command \"./scripts/travisci_run.sh\" exited with 32.\ncache.2\nstore build cache\n0.00s1.62snothing changed, not updating cache\nDone. Your build exited with 1.. @styurin -- I was able to fix the failure. please review.\nthanks!. @styurin -- I was able to fix the failure. please review.\nthanks!. cc: @kageiit, @romanoid, @styurin . Added tests. > I have changes for this issue in the review already\ncool, I will close this. . > @raviagarwal7 @kageiit I have a branch that reproduces the error we are seeing: uber/okbuck#826\n@artem-zinnatullin, does this shows the behaviour that broke with the pr #2086? \nIf resource union is needed doing union in MergeAndroidResourcesStep is the right way to go which handles styleable correctly. I think the resource_union flag can be removed from android_resource (missed removing it in that pr) and needs to be added to android_binary and robolectric_test. \nsetting resourceUnion would enable resource union with the original package otherwise uses the specified package.\nsetting resourceUnionPackage uses this as the union package.\nSeems like gradle has the same default behaviour and I think this change in BUCK will make it work similarly.\nSo, this requires 2 changes:\n- change buck to handle original package name resource union correctly and remove the flag from android_resource.\n- change okbuck to remove outputting resource_union from android_resource and output correctly according to the above change. \nFrom OkBuck docs.\n```\n  /*\n   * Set to use buck's resource_union behavior with the original package name or the defined by\n   * {@link OkBuckExtension#resourceUnionPackage}\n   /\n  @Input public boolean resourceUnion;\n/* Set to use buck's resource_union behavior with an specific package name /\n  @Nullable @Input public String resourceUnionPackage;\n```\nfeel free to create PR's and cc me on it. . sure, will do\n. it was used to differentiate b/w a styleable int entry from one's which are given unique int values. \nchecking that now using resource.idType == IdType.INT_ARRAY && resource.type == RType.STYLEABLE\n. sure, will move out into a new method\n. good idea, will do\n. this is still O(N). the outer loop goes from 0 to linesInSymbolsFile.size() & the inner loop goes through styleable int entries once more which is at-most N.\nwill move this to a multimap.\n. removed as Intellij was showing a suggestion that nested enums are implicitly static - http://docs.oracle.com/javase/specs/jls/se7/html/jls-8.html#jls-8.9\n. styleableIntArrToIntsMap is a multimap so not needed, we expect multiple values.\n. done. nice catch! fixed the issue, using array length comparison as you suggested.. fixed.. why do we need HashMap<Integer, RDotTxtEntry>? we are only using the idValue below. \nI think it should atleast be HashMap<RDotTxtEntry, RDotTxtEntry> so that equals() on RDotTxtEntry is also called.\n. nit: don't really like setting resource from the map to resource and then replacing it in the next line\nwould prefer resource = resource.copyWithNewIdValue(resourceToIdValuesMap.get(resource).idValue); or using some local variable. nit: move it up on line 457\nRDotTxtEntry styleableResource = \n     getResourceAtIndex(linesInSymbolsFile, styleableIndex + index).copyWithNewParent(resource.name);\n. indentation looks incorrect\ncheck if ant lint passes locally. good point, removed duplicate as you suggested.. remove code duplication. added the comment back. yes removed the comment.. added a check in the rule constructor.. improved the comment. using prebuilt as this scenario is only applicable with union package enabled which in turn only leaves us with prebuilt's R Dot Java. setting this would skip the prebuilt's r dot java.. renamed to isSkipNonUnionRDotJava and documented the param in docs.. getTransitiveClasspathDeps returns both #aar_prebuilt_jar,class-abi and #class-abi flavours. I verified that both the output jars are same, just on different paths.\n```\n//cache:com.support-compat-27.0.2.aar#aar_prebuilt_jar,class-abi\nbuck-out/gen/cache/com.support-27.0.2.aar#aar_prebuilt_jar,class-abi/com.support-27.0.2.aar-abi.jar\n//cache:com.support-compat-27.0.2.aar#class-abi\nbuck-out/gen/cache/com.support-27.0.2.aar#class-abi/com.support-27.0.2.aar-abi.jar\n``\nHow can I filter and keep only the#class-abideps? Also is there a scenario where the output of the two flavours will differ?. just moved the method to be in accordance with others, but will revert back . Intellij was showing suggestions that this is not needed, will revert back.. added a filter to only include rules which have non-nullsourcePathToOutput, same behaviour is inClasspathMacro.. done. usingnew File.(\"file-path-string\")toPath()now, hopefully this would work fine on windows.. done. done. good catch, fixed.. sure, done.. we need it to be aList` to make sure classpath entries from different sources are self sorted and not among themselves.\nNew Ordering for Android (each is sorted individually and added to classpath entries):\n- External Libraries (from compiledTestsLibrary)\n- Dummy R.java jar (from additionalClasspathEntries)\n- Android jar (from bootClasspathEntries)\nPreviously android jar could end up at the start or end of the class-path\nlist since items were sorted with absolute paths where root was not the same.\nThis resulted in robolectric tests randomly failing/passing in some machines.\n/Users/ravi/android-sdk/platforms/android-27/optional/org.apache.http.legacy.jar\n/Users/ravi/android-sdk/platforms/android-27/android.jar\n/Users/ravi/Uber/android/buck-out/gen/tool/pa/rx/lib__src_main__output/src_main.jar\n/Users/ravi/Uber/android/buck-out/gen/lib/foundation/uv/uv/lib__src_release__output/src_release.jar\n/Users/ravi/Uber/android/buck-out/gen/lib/foundation/ut/ut/lib__src_release__output/src_release.jar\nBut still we need to keep the bootclasspath entries in the end so that android.jar\nis at the end of the classpath list. This makes sure unit classes comes from junit jar and not android jar.\nStacktrace:\njava.lang.RuntimeException: Stub!\n    at junit.runner.Version.id(Version.java:5)\n    at org.powermock.modules.junit4.common.internal.impl.JUnitVersion.getJUnitVersion(JUnitVersion.java:28)\n    at org.powermock.modules.junit4.common.internal.impl.JUnitVersion.isGreaterThanOrEqualTo(JUnitVersion.java:23)\n    at org.powermock.modules.junit4.PowerMockRunner.getRunnerDelegateImplClass(PowerMockRunner.java:44)\n    at org.powermock.modules.junit4.PowerMockRunner.<init>(PowerMockRunner.java:34)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\nStackOverflow - https://stackoverflow.com/a/10107368/2383356\n. added a precondition check since at this step it needs to be non null. . this need not be null, but in tests this called with a null groovy buck config which is why I added @Nullable\nhttps://github.com/facebook/buck/blob/3f1c33f5a4fed73559c890383374c6dcc9d9a59e/test/com/facebook/buck/jvm/groovy/GroovyLibraryBuilder.java#L51. providing a non null instance now. . @styurin updated the robolectric test fixture. . sure, updated the pr.. update comment to search for javac plugins. probably make this a constant. I think classpath must be used at other places too.. probably make this a method in JavacPluginProperties abstract class which can be reused.. probably rename to buildJavaAnnotationProcessorParams. probably use a constant. please add some javadoc. would be good to support macros as well in kaptApOptions (eg macro usage in vm_args - https://github.com/facebook/buck/commit/3e0b4cc444d86f565124807f729bbe7d9748c83c#diff-8bd16d403f308d9df417653053234adb). gradle and buck seems to be using different hashing algorithm, so the hashes don't match\n. suggestion\n    @Value.Default\n    default boolean getAllWarningsAsErrors() {\n      return false;\n    }\nyou can provide defaults for all booleans . yes, it does create an implementation which fallbacks to the default implementation if not set.. seems like there is no existing test for KotlinConfiguredCompilerFactory.java. you can probably add one for this method. . also add a section in https://github.com/facebook/buck/blob/master/docs/rule/kotlin_library.soy describing these parameters. . seems like verbose should be true by default as per the usage in below KotlincStep. checkout https://github.com/facebook/buck/blob/master/test/com/facebook/buck/jvm/kotlin/KotlinBuckConfigTest.java for unit tests example\nfor integration tests https://github.com/facebook/buck/blob/master/test/com/facebook/buck/jvm/kotlin/KotlinLibraryIntegrationTest.java\nthere are bunch of test data https://github.com/facebook/buck/tree/master/test/com/facebook/buck/jvm/kotlin/testdata, you can probably add an integration test too. . the change in later version of manifest merger does this to account for all kind of targetApi usages. \nhttps://android.googlesource.com/platform/tools/base/+/5c6d992f405b0d83f3c10e4d5f6d961bef50221c%5E%21/build-system/manifest-merger/src/main/java/com/android/manifmerger. ",
    "marcinkwiatkowski": "@raviagarwal7 You can pass robolectric.dependency.dir as vm_args in robolectric_test rule.\nYou will also need a few more jars:\nandroid-all-5.0.0_r2-robolectric-1.jar\njson-20080701.jar\nshadows-core-3.0-21.jar\ntagsoup-1.2.jar\n. @raviagarwal7 You can pass robolectric.dependency.dir as vm_args in robolectric_test rule.\nYou will also need a few more jars:\nandroid-all-5.0.0_r2-robolectric-1.jar\njson-20080701.jar\nshadows-core-3.0-21.jar\ntagsoup-1.2.jar\n. Html is also generated by default, you can change that by specifying  --code-coverage-format=xml.\n. Html is also generated by default, you can change that by specifying  --code-coverage-format=xml.\n. buck-out/gen/jacoco/code-coverage/coverage.xml, that code-coverage directory is defined here https://github.com/facebook/buck/blob/master/src/com/facebook/buck/jvm/java/coverage/ReportGenerator.java#L70\n. @dreiss updated.\n. @dreiss let me know, we could probably support both versions of the merger for some time.. @dreiss let me know, we could probably support both versions of the merger for some time.. So looks like they use \"android:\" for all implicit permissions. Here's the logic that adds READ_EXTERNAL_STORAGE https://github.com/marcinkwiatkowski/buck/blob/e984badb83ee93f95f52bd2e80629b6e45a9a595/third-party/java/aosp/src/com/android/manifmerger/XmlDocument.java#L489-L489\nWhat's the failure?. So looks like they use \"android:\" for all implicit permissions. Here's the logic that adds READ_EXTERNAL_STORAGE https://github.com/marcinkwiatkowski/buck/blob/e984badb83ee93f95f52bd2e80629b6e45a9a595/third-party/java/aosp/src/com/android/manifmerger/XmlDocument.java#L489-L489\nWhat's the failure?. @dreiss doesn't affect this PR directly but we could potentially remove the whole aosp directory and make the whole setup simpler. Are you upgrading all jars in third-party/java/android?. @kageiit @dreiss I agree, this is only for a test. The naming is bad, addImplicitElements also does validation.\nI think only this block is problematic for @dreiss \n```\n        if (libraryTargetSdk < 4) {\n            addIfAbsent(mergingReport.getActionRecorder(),\n                    USES_PERMISSION,\n                    permission(\"WRITE_EXTERNAL_STORAGE\"),\n                    lowerPriorityDocument.getPackageName() + \" has a targetSdkVersion < 4\");\n            hasWriteToExternalStoragePermission = true;\n        addIfAbsent(mergingReport.getActionRecorder(),\n                USES_PERMISSION,\n                permission(\"READ_PHONE_STATE\"),\n                lowerPriorityDocument.getPackageName() + \" has a targetSdkVersion < 4\");\n    }\n\n``. It's a bit of patching but we could do that @dreiss (see latest commit), I think it makes sense. Do most of your libraries don't specify sdk? I updated test data to reflect that. . It's a bit of patching but we could do that @dreiss (see latest commit), I think it makes sense. Do most of your libraries don't specify sdk? I updated test data to reflect that. . Those were aosp tests, I don't think they need to be run as part of buck pipeline.GenerateManifestStepTestis an integration test that covers our use of the merger. . Yep, subclass should be good.. @dreiss I found the diff changed it in old version https://github.com/facebook/buck/commit/2d63b10fe12522283ddb4a5d62cd22dbf8ba0e8a\nI think instead of patching the merger, the reordering (if needed) should be done as a separate step on a merged document.  Let me look at actual code first though. . @dreiss I found the diff changed it in old version https://github.com/facebook/buck/commit/2d63b10fe12522283ddb4a5d62cd22dbf8ba0e8a\nI think instead of patching the merger, the reordering (if needed) should be done as a separate step on a merged document.  Let me look at actual code first though. . correct, thanks @mzlee . There is a ton of new warnings inManifestMerger2(73!) that ant turns into errors. Buck usescommon-24.2.3,sdk-common-24.2.3, etc.25.2.0comes with different api in many places. If we can upgrade to use25.2.0everywhere, we can get rid of the wholeaosp` hack and just use prebuild jars. we don't have one yet. ",
    "hschottm": "Great, thanks for the info\n. ",
    "alanzeino": "Just encountered this problem. Wanted to have a remote_file download a file, then have an apple_resource add that file to the project as a dep on the apple_binary.\n. Just encountered this problem. Wanted to have a remote_file download a file, then have an apple_resource add that file to the project as a dep on the apple_binary.\n. @robbertvanginkel @nguyentruongtho can you answer?. https://github.com/facebook/buck/pull/1302\nhttps://github.com/facebook/buck/pull/1303. ",
    "dsyang": "@mikekap Thanks for that tip about how scala implicitly adds the dependency! I think I'll add it as a separate PR though. \n. n00b questions: How do I...\n1) See why AppVeyor couldn't build this (though I think it's probably an autodeps confilct)\n2) Update this PR to the current master without adding a ton of commits to the PR\n. Yea I should rebase this to make sure the checks pass. \nre: @bkase and the android issues, I think that belongs in a separate PR. I believe this is enough to start using Kotlin along side other plain-old java programs (like buck!) I can create an issue with \"next steps\" if that's useful. \n. @tiestvilee  thanks for trying this out! \nI wonder if that could be fixed by implicitly adding the kotlin-runtime / kotlin-test dependencies like how @mikekap suggested. Definitely something we should look at after this gets in.\n. I tried adding kotlin to buck as an example of how this would work.  https://github.com/dsyang/buck/pull/1\nI also created this extremely simple cli calculator to verify this PR actually works: https://github.com/dsyang/buckotlin\nYou can see the buck integration is pretty straight forward: https://github.com/dsyang/buckotlin/commit/7326113438366da3e9851ce30dfe2dcd3e89e88b\n. @Coneko  I ran buck test locally and the only test failures I found were related to the swift integration tests (I think that's because I have an old/incomplete swift installation). Maybe it's something broken with the internal tests?\n. Can I import my own code? :)\n@facebook-github-bot shipit\n. #937  enables this.  @kageiit I don't think so, but I think it'd be best to open up a new issue for that\n. It would be whatever version of the .jar you include in the repo and set in .buckconfig.  It should probably match the version of the compiler you specify too. \nIf we use https://github.com/dsyang/buckotlin as an example. That repro has version 1.0.3 in the libs/ folder. It's .buckconfig is configured to use the kotlinc in libs/.  We want the buck target //libs/kotlin/lib:runtime to  be implicitly included in any kotlin_library() rules.  To do this we can add a runtime = //libs/kotlin/lib:runtime property in the project's .buckconfig and update KotlinLibraryDescription.java to implicitly add the buck target to each kotlin_library() invocation. \n\nconfigured via the kotlin library rule description\n\nDo you mean allowing each kotlin_library() rule to decide which version of the runtime to include? or allow them to say whether or not to implicitly include the runtime? If the former, I'm not sure if we want to support multiple kotlin versions in the same project. If the latter, then definitely :)\n. Yea we should definitely have a flag for that then :)\n. I haven't implemented (or really thought closely) about doing this for\nkotlin yet. This sounds like a much better approach. If it works for scala\nthat's awesome and we should merge it. I'm sure we can do something similar\nfor kotlin.\nThanks for doing this @zbsz!!\nOn Oct 2, 2016 21:14, \"Facebook Community Bot\" notifications@github.com\nwrote:\n\n@zbsz https://github.com/zbsz updated the pull request - view changes\nhttps://github.com/facebook/buck/pull/913/files/a937f74cbf1c134b53422a4b720f3aab99956984..aa3eabd3066a78217f9ee13b2b6cc7cd1fe64209\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/913#issuecomment-250992835, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMdyTq0jNoTScwjtmT-cHBhqReXpZks5qwBCJgaJpZM4KME45\n.\n. Re auto detecting the language. Sure I can remove JvmLanguage\n\nRe documentation. Yea I need to write some stuff up for Kotlin. Maybe do a\nblog post too when this lands and gets tested.\nRe testing & installing: I think we can do something like what @mikekap did\nfor scala: add a .buckconfig flag that points to a build target for the\ncompiler. Then we can check in a version of the compiler and use that to\nrun tests. Since its just a .jar we should be able to run this without a\nproblem on existing infrastructure.\nOn Oct 12, 2016 13:30, \"Shawn Wilsher\" notifications@github.com wrote:\n\nAre we going to make sure we have Kotlin installed in the travis/appveyor\njobs so these tests can run?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/937#issuecomment-253330033, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMcF4k6c06eIqyKsEy4s1hdQpEsKkks5qzUNmgaJpZM4KUMcQ\n.\n. Removed changes for removing the language param. Will put out the new PR after this lands.\n\nSomething's broken with the LogFormatter which causes buck builds to fail. Not sure what though since this code doesn't touch that at all\n. @Coneko what specifically about source zips and generated sources do you think this breaks? I think this doesn't break any backwards compatibility (since it tries to default to javac)\n. hmm fair enough. @bolinfest  do you have any thoughts on how we can improve this?\n. @kageiit \nkotlinc does support mixed source compilation but it's not as straightforward as invoking bin/kotlinc with some flags.  You have to call kotlinc on the .kt files first then call javac to compile the rest (https://discuss.kotlinlang.org/t/compiling-mixed-java-and-kotlin-files-on-the-command-line/1553) \nWe should make a new issue for this. . @kageiit \nkotlinc does support mixed source compilation but it's not as straightforward as invoking bin/kotlinc with some flags.  You have to call kotlinc on the .kt files first then call javac to compile the rest (https://discuss.kotlinlang.org/t/compiling-mixed-java-and-kotlin-files-on-the-command-line/1553) \nWe should make a new issue for this. . This approach won't work so I'm closing the PR. This approach won't work so I'm closing the PR. That's awesome @brettwooldridge!\nOn Dec 15, 2016 2:41 PM, \"Brett Wooldridge\" notifications@github.com\nwrote:\n\n@dsyang https://github.com/dsyang @kageiit https://github.com/kageiit\nI have coincidentally started working on in-VM compilation of kotlin rather\nthan shelling out, based on code hijacked from the kotlin ant task\nhttps://github.com/brettwooldridge/kotlin/blob/master/ant/src/org/jetbrains/kotlin/ant/KotlinCompilerAdapter.kt.\nI can sweep up this issue at the same time.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1037#issuecomment-267243972, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMZqvL8UrvUI7pTv6DvTcmNUfggsEks5rINMbgaJpZM4LElHN\n.\n. It is sequential but I believe kotlinc will load and Java classes\nreferenced by a kotlin file when compiling it (see the link above).\n\nYour example should work as long as kotlinc can find B.java\nOn Dec 15, 2016 2:51 PM, \"Brett Wooldridge\" notifications@github.com\nwrote:\n\n@dsyang https://github.com/dsyang As I understand it, this is basically\na sequential compilation currently, correct? Meaning Kotlin and then Java.\nSo the following, in a single project would not be supported?\nA.kt extends B.java\nB.java references C.kt\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1037#issuecomment-267245043, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMfEAcw1-Cu0h_F9LB0feMSXBcEZWks5rINVOgaJpZM4LElHN\n.\n. @brettwooldridge can't wait!\n\nOn Dec 15, 2016 2:57 PM, \"Daniel Yang\" dsyang92@gmail.com wrote:\n\nIt is sequential but I believe kotlinc will load and Java classes\nreferenced by a kotlin file when compiling it (see the link above).\nYour example should work as long as kotlinc can find B.java\nOn Dec 15, 2016 2:51 PM, \"Brett Wooldridge\" notifications@github.com\nwrote:\n\n@dsyang https://github.com/dsyang As I understand it, this is\nbasically a sequential compilation currently, correct? Meaning Kotlin and\nthen Java. So the following, in a single project would not be supported?\nA.kt extends B.java\nB.java references C.kt\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1037#issuecomment-267245043,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMfEAcw1-Cu0h_F9LB0feMSXBcEZWks5rINVOgaJpZM4LElHN\n.\n\n\n. Hey @brettwooldridge this is awesome! \n\nWould you be comfortable putting your changes in kotlin-compiler up in a PR so we could start reviewing it?\nI know there's still some work that you'd like to do but this could make it easier to merge later down the line. \nTotally understand if you'd rather clean it up some more first.. Hey @brettwooldridge this is awesome! \nWould you be comfortable putting your changes in kotlin-compiler up in a PR so we could start reviewing it?\nI know there's still some work that you'd like to do but this could make it easier to merge later down the line. \nTotally understand if you'd rather clean it up some more first.. @runningcode Not sure what you mean by this branch. You can't build a target with mixed sources in the master branch (or any branch right now).  This issue is tracking that feature.  @brettwooldridge  has the most context right now. IIRC #1283 is the first step towards getting this to work.. I'm pretty sure that branch doesn't enable mixed sources yet either.. On mobile so I can't properly review right now but do you need to change a test as well? If we're implicitly including the runtime there should be a kotlin_test integration test that doesn't explicitly use the runtime. @kageiit  can you rebase again? Some internal tests are failing and I think it's b/c of a merge conflict. @kageiit  can you rebase again? Some internal tests are failing and I think it's b/c of a merge conflict. Figuring it out today.\nOn Mar 1, 2017 3:34 PM, \"Gautam Korlam\" notifications@github.com wrote:\n\n@dsyang https://github.com/dsyang any update on the import?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1200#issuecomment-283506934, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMWuY1qyR10j98MQAYKQ65xPyIJtrks5rhgBrgaJpZM4MJB8A\n.\n. Figuring it out today.\n\nOn Mar 1, 2017 3:34 PM, \"Gautam Korlam\" notifications@github.com wrote:\n\n@dsyang https://github.com/dsyang any update on the import?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1200#issuecomment-283506934, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMWuY1qyR10j98MQAYKQ65xPyIJtrks5rhgBrgaJpZM4MJB8A\n.\n. Thanks for putting this up @brettwooldridge! Main reason I suggested it is that it's one step closer to merging (and merging means no more rebases from hell).  . Google just announced kotlin as a official language for Android. @brettwooldridge any chance we can get this PR updated and ready soon? ;). @brettwooldridge sounds good! Anything I can do to help? Happy to patch this PR and help test & fix unit tests.. @brettwooldridge sounds good! Anything I can do to help? Happy to patch this PR and help test & fix unit tests.. Gotcha. I'll try and narrow it down in https://github.com/dsyang/buck/tree/kotlin-compiler2\n\nIs the weird bug you're seeing https://gist.github.com/dsyang/9d5b7562ad676a10b18adc6d427cffda? That's what I see when trying to use this branch.  \nThanks for all your hard work! Hope to have some good news for you tomorrow morning.. Gotcha. I'll try and narrow it down in https://github.com/dsyang/buck/tree/kotlin-compiler2\nIs the weird bug you're seeing https://gist.github.com/dsyang/9d5b7562ad676a10b18adc6d427cffda? That's what I see when trying to use this branch.  \nThanks for all your hard work! Hope to have some good news for you tomorrow morning.. Not sure why I can't submit PRs to @brettwooldridge's buck repo but here's what I found:\n - there was a trivial compilation error that prevented the kotlin tests from running. After fixing that tests would run but I would get a weird kotlin compiler exception (stacktrace)\n - I traced this error to be related to the v1.1.x kotlin compilers.  The tests were running with the kotlinc that was in my system path.  If I tell the tests to use v1.0.7 by adding a .buckconfig like below, then all the tests pass:\n```\nfilename: test/com/facebook/buck/jvm/kotlin/testdata/kotlin_(library|test)_description/.buckconfig\n[kotlin]\n  compiler = \"/Users/dsyang/Downloads/kotlinc-1.0.7/bin/kotlinc\"\n``\n - If I change the test's.buckconfig` to use the compiler_jar, I run into another crash (stacktrace).  @brettwooldridge  was this the crash you were talking about?\nThe last crash is more tractable than the first one because it seems to be in the buck codebase.  I'll try and tackle that later today.\n. Not sure why I can't submit PRs to @brettwooldridge's buck repo but here's what I found:\n - there was a trivial compilation error that prevented the kotlin tests from running. After fixing that tests would run but I would get a weird kotlin compiler exception (stacktrace)\n - I traced this error to be related to the v1.1.x kotlin compilers.  The tests were running with the kotlinc that was in my system path.  If I tell the tests to use v1.0.7 by adding a .buckconfig like below, then all the tests pass:\n```\nfilename: test/com/facebook/buck/jvm/kotlin/testdata/kotlin_(library|test)_description/.buckconfig\n[kotlin]\n  compiler = \"/Users/dsyang/Downloads/kotlinc-1.0.7/bin/kotlinc\"\n``\n - If I change the test's.buckconfig` to use the compiler_jar, I run into another crash (stacktrace).  @brettwooldridge  was this the crash you were talking about?\nThe last crash is more tractable than the first one because it seems to be in the buck codebase.  I'll try and tackle that later today.\n. Looking at kotlin-merge now. I think third-party/java/kotlin is unnecessary for mapdb to work.\nAgreed that it looks like a true installation of kotlin is necessary.  I think the .buckconfig variables at runtime_jar, compiler_jar, and compiler, KotlinBuckConfig only checks kotlin_home as a environment variable.  Maybe we should replace runtime_jar and compiler_jar with kotlin_home.. Looking at kotlin-merge now. I think third-party/java/kotlin is unnecessary for mapdb to work.\nAgreed that it looks like a true installation of kotlin is necessary.  I think the .buckconfig variables at runtime_jar, compiler_jar, and compiler, KotlinBuckConfig only checks kotlin_home as a environment variable.  Maybe we should replace runtime_jar and compiler_jar with kotlin_home.. Do you have a theory about why it would be causing this to fail?\n. Do you have a theory about why it would be causing this to fail?\n. @brettwooldridge  I'm seeing a bunch of \"done\" / \"addressed\" comments without any changes.  Maybe one of your commits got lost in translation?. @brettwooldridge  I'm seeing a bunch of \"done\" / \"addressed\" comments without any changes.  Maybe one of your commits got lost in translation?. what about https://github.com/facebook/buck/pull/1283#discussion_r117647080?\nOr do you think that belongs in a separate PR?. By \"heavy\" I meant cognitive load instead of file size load.  I'm also not worried about the size of those testdata directories.  Perhaps a better way to phrase it is: \"Do we really need these to be testdata directories?\" \nTo me, testdata dirs are useful in places where file content is important (such as KotlinLibraryIntegrationTest where you actually compiling those sources).  In the case of KotlinBuckConfigTest we only care about the existence of those files in that hierarchy. That's exactly what tmp.newExectuableFile() and friends provide: the temporary existence of a file without caring about it's contents. \nThe \"cognitive load\" part comes from locality.  To figure out what that test is doing I need to look at the directory structure, then look at the test.  With the way DBuckConfigTest does it, you only have to look at the test file to understand what's going on. . If you could squash them that'd be great.  I just imported the PR to run it in our internal CI servers in case there are more tests that fail (I don't expect them to). Don't have my computer with me for the next couple of days will look at it\nagain on Thursday\nOn May 30, 2017 3:47 AM, \"Brett Wooldridge\" notifications@github.com\nwrote:\n\n@kageiit https://github.com/kageiit @dsyang https://github.com/dsyang\nAnything else waiting on me here?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1283#issuecomment-304883353, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMV5tN3Z6D6HSDcT7k5k6Ym-cS61Kks5r_B3ogaJpZM4M4A-v\n.\n. @brettwooldridge @kageiit  We're just waiting on some people from the buck team to do a quick once-over for this PR on our internal phabricator import, unfortunately some people have been OoO so it's not moving as fast as I'd like.  I've been rebasing and updating it internally but I don't know how to make it show up here in github. \n\nYou guys shouldn't need to do anything more here.  It's my job now to push someone internally to look at it :/ \n. @brettwooldridge  if you don't want to wait for a release you could also use a .buckversion file https://buckbuild.com/concept/buckversion.html. Looks ok to me. CI failures look unrelated. In retrospect, I don't think this is the right thing to do. \nthird-party/java/kotlin is not used by buck itself but by another third party lib third-party/java/mapdb.\nLooking at the mapdb BUCK file, the version we have in third-party/java/mapdb is 3.0.3. For that version, kotlin is pinned at 1.0.6 (https://github.com/jankotek/mapdb/commit/2fcb185f36ad60f115837538bb691a755845c39b#diff-600376dffeb79835ede4a0b285078036)\nWe probably shouldn't update this until mapdb is updated. cc @bertmaher since he added the mapdb dependency. In retrospect, I don't think this is the right thing to do. \nthird-party/java/kotlin is not used by buck itself but by another third party lib third-party/java/mapdb.\nLooking at the mapdb BUCK file, the version we have in third-party/java/mapdb is 3.0.3. For that version, kotlin is pinned at 1.0.6 (https://github.com/jankotek/mapdb/commit/2fcb185f36ad60f115837538bb691a755845c39b#diff-600376dffeb79835ede4a0b285078036)\nWe probably shouldn't update this until mapdb is updated. cc @bertmaher since he added the mapdb dependency. Closing because of the above comment re: mapdb.  Before doing so though, I'd like to test something out with github's online editor if that's ok @runningcode . Closing because of the above comment re: mapdb.  Before doing so though, I'd like to test something out with github's online editor if that's ok @runningcode . nvm experiment didn't work as I thought it would. nvm experiment didn't work as I thought it would. Yea let's try it out.  Would it remove the need to public a bunch of\nmethods?\nOn Jun 5, 2017 6:21 PM, \"Nelson Osacky\" notifications@github.com wrote:\n\n@runningcode commented on this pull request.\nIn src/com/facebook/buck/jvm/kotlin/KotlincToJarStepFactory.java\nhttps://github.com/facebook/buck/pull/1358#discussion_r120246926:\n\n                     .orElse(ImmutableList.of()))\n             .addAll(declaredClasspathEntries)\n             .build(),\n         kotlinc,\n         extraArguments,\n         filesystem));\n\n+\n+    ImmutableSortedSet javaSourceFiles = ImmutableSortedSet.copyOf(\n+        sourceFilePaths\n+            .stream()\n+            .filter(JAVA_PATH_MATCHER::matches)\n+            .collect(Collectors.toSet()));\n+\n+    // Don't invoke javac if we don't have any java files.\n+    if (!javaSourceFiles.isEmpty()) {\n\nYeah, should i create a new JavacToJarStepFactory here and call\ncreateJarStep on it?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1358#discussion_r120246926, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMbes4yNcr7hO_J3X022UXwLwGTTCks5sBKmZgaJpZM4NnFFa\n.\n. Agree with @kageiit, lets make sure this works for android libraries too (I don't see why it wouldn't).\n\nAlso, I just enabled the kotlin tests on Appveyor and travis with https://github.com/facebook/buck/commit/8fe27d2df7fee3f50c1b23de07a9d14f3bdc0acb. It's using v1.1.2-2 so these new tests will fail. Can you either 1) disable these tests for now or 2) update the kotlinc to use 1.1.3? \nI'd prefer the former until 1.1.3 is officially released.. @runningcode Almost there! Looks like there's still some test failures that are related: https://ci.appveyor.com/project/Facebook/buck/build/3856#L2449. @kageiit  can you rebase? otherwise lgtm. @coneko I think this is fine. I've currently AFK for the next couple of\ndays so if someone else can merge that'd be great\nOn Jul 27, 2017 6:14 PM, \"Eli Hart\" notifications@github.com wrote:\n\n@dsyang https://github.com/dsyang is this able to be merged? It would\nbe awesome to have it in\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1398#issuecomment-318529280, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAgWMT9X_fBkgm2LzfHkikAK3crJVj_Qks5sSTXdgaJpZM4OGBP9\n.\n. @runningcode That's really weird.... lemme try and figure it out. @cwoodwar6  I'm having trouble importing this PR. when you get the chance can you rebase?. @cwoodwar6 it looks like you're right, appveyor's tests didn't fully run.  When running these tests locally there's I see error messages like: https://gist.github.com/dsyang/9e5dec03e5d1f5494b695fc805bceb48\n\n. Right dependencies for appveyor not running the tests? I think it's not just that. Appveyor only runs one test: https://ci.appveyor.com/project/Facebook/buck/build/4833#L2387. Looking at the output of the stack trace, it appears theres a problem with how we're using reflection in JarBackedReflectedKotlinc.java:130-154. Specifically we're missing definitions in the kotlin.reflect package.\nFrom googling the error to digging in other github issues, https://github.com/spring-projects/spring-boot/issues/9984#issuecomment-321195996 makes me think we need to also include the kotlin-reflect.jar in this commit since it's needed by kotlinc.\n. Looking at the output of the stack trace, it appears theres a problem with how we're using reflection in JarBackedReflectedKotlinc.java:130-154. Specifically we're missing definitions in the kotlin.reflect package.\nFrom googling the error to digging in other github issues, https://github.com/spring-projects/spring-boot/issues/9984#issuecomment-321195996 makes me think we need to also include the kotlin-reflect.jar in this commit since it's needed by kotlinc.\n. I'm not using the coercer here. Are you suggesting that I should use it?\n. That looks specific to the java library description (the kotlin library description doesn't ave javacOptions) so I don't think we can add this here.\nUnless you're suggesting we add javac options to this.\n. Why leave these here instead of in their own file (or package)?\n. Maybe we should extract this to a utility/static method instead of duplicating between here and ScalaLibraryDescription\n. nit: feels like this can (and should) be consolidated\n. nit: split into 2 lines\n. I wonder if it's possible to do this without hardcoding ScalaBuckConfig into the default AndroidLibraryDescription. It's not going to scale when we start implementing support for kotlin (and other jvm languages). \n. What if we had a JvmLanguagesConfig interface or base class that theScala/Kotlin/BuckConfig classes implement.  Then we use JvmLanguagesConfig here. \n2) Pass in an android compiler instead of a buck config. Your getCompiler() implementation doesn't look like it uses anything inside this class and can probably be pulled out into some selector class that choose\n. @Coneko @mikekap @grumpyjames what do you guys think?\n. Yea I agree. definitely sounds like something we should to in a separate PR\n. can we also add a test that says compilation will fail if the language parameter isn't something recognized? (\"java\", \"scala\",etc...) \n. I realize this was extracted into #915 but do we have an equivalent test that covers this case? Seems weird to just remove test cases instead of moving them to a different unit test. I could be wrong but that PR didn't seem to have one. \n. (Just trying to understand the codebase better) why did we need to add this?\n. Javadoc\n. Javadoc\n. As long as the arg parsing failure is something like cannot parse language I think that's fine.\n. Style: Lets actually move this to the top of the file lik in SwiftLibraryDescription and CxxLibraryDescription.\n. @shs96c Correct me if I'm wrong but your TODO from line 1352 should be relatively simple to fix right? We're making c/f/b/android/BootClasspathAppender public because of this test and I don't think we need to.\n@zbsz if you think it's easy to update go for it. Otherwise lets create an issue.\n. How about this?\n/**\n  * Factory providing implementations of {@link AndroidLibraryCompiler}\n  * for the specified {@code language}.\n  * {@link AndroidLibraryDescription} uses this factory to handle multiple JVM languages.\n  * Implementations should provide a compiler implementation for every {@link JvmLanguage}. \n  * See {@link DefaultAndroidLibraryCompiler}\n  */\n. /**\n  * Jvm compiler abstraction for android.\n  * Implementations of this class are used in {@link AndroidLibraryDescription} to provide\n * the actual compilation step.\n  * This allows us to use different compilers for different {@link JvmLanguage}.\n  */\n. Will break this out into multiple lines\n. will update this to java 8 syntax\n. oops. will remove\n. will remove extra parens\n. will add newline\n. same here\n. add newline\n. We should test this but my feeling is java_library (and by association android_library before #913) expected all of it's sources to be java files. I've made the languages param optional in the latest update to this PR so we can see what that would be like. After testing the old behavior of java/scala we should decide what to do.\n. nit: move these after com.facebook..... . can we reuse the previous getKotlinHome() result instead of recomputing?. I'm assuming you're going to add more stuff in here in later PRs? Can we either 1) hold off until we actually populate this with new stuff or 2) add a comment explaining why this is hear (and different from JavaLibrary). nit: alphabetize imports. why remove the / / hints?. nit: move behind com..... nit: no space. doesn't look like other files have a newline between com.facebook and com.google. Got it. lets just leave them off then. Better to conform to one of the existing styles than introduce a third variant.. +1 to just using args.X, lets leave off the comments. question. Why is this synchronized?. mark as @nullable?. Question: What does this do?. ruleFinder doesn't exist.. unrelated change. unrelated change. please revert.. unrelated change. javadoc. can you use the above kotlinc here?. Found the culprit!\nWe're running the kotlin compiler with a classpath that includes all the classes loaded for buck.  That's not what we want. The only classes the compiler should know about / have access to are the ones specified in the compilerClassPath.\nChanging this to null allows for successful compilation without needing to change mapdb or anything in third-party.. disregard my previous comment about javadocs here, doesn't seem necessary (and others like AbstractJavacVersion don't do it).. @brettwooldridge I'm curious about this too. Is there going to be custom logic put here in the future?. This is probably copied style from ExternalJavac.  No opinion either way on renaming this.. Is there a better term we can use other than \"in memory\" here? maybe \"externally specified\"? . \"stdlib\"? or \"runtime\"? we should be consistent about this.. Lets be conssitent with getPathTo*Jar().  Rename this to getPathToCompilerBinary() and add javadoc. The types of directory structures we consider valid kotlin_home isn't quite clear.  If I have my kotlinc in ~/bin/kotlinc then this considers ~/bin to be my kotlin_home which seems like it'd be wrong (~/bin/lib/kotlin-runtime.jar? no thanks).\nCan we add a verify method that makes sure kotlin_homes are either structured like:\nkotlin_home_as_downloaded_and_unziped_from_website/\n    bin/\n    lib/\nor \nkotlin_home_as_installed_from_homebrew/\n    bin/\n    libexec/\n        lib/. extra whitespace. address comment or remove. address comment or remove. address comment or remove. remove. I don't think we should create a new testdata directory for this buck config test.  That's pretty heavy when you can just use tmp to create temporary files/directory structures.\nCheck out how DBuckConfigTest,  does it.  We should do it that way and delete the testdata/faux_kotlin_home and testdata/kotlin_compiler_test directories.. i think tests are failing because of kotlin-stdlib / kotlin-runtime naming confusion. Fair points, didn't think about maven or okBuck.  lets keep it this way then!. Can we remove these deps? Its weird that kotlin depends on android. https://travis-ci.org/facebook/buck/jobs/235076076#L4351. https://ci.appveyor.com/project/Facebook/buck/build/3716#L2559. are there warnings left to suppress? I thin we use everything. this change should be reverted since we don't have a faux_kotlin_home directory anymore. Question: Why are we using a UncloseablePrintStream here? Curious what the problem is with just context.getStdErr().. @brettwooldridge an Infer run is complaining about a resource leak here:  Any ideas on the best way to fix this?. instead of explicitly adding a JavacStep can we use JavacToJarStepFactory instead? I'm not a fan of duplicating the code here. . You can use c.f.b.io.PathOrGlobMatcher(String globPattern) here. change package. style nit. one line per argument. If that's the reason wouldn't protected be enough?. if the test succeeded even though these package names were incorrect I'm a little skeptical the test actually ran lol. Did it pass when you tested locally though?. Can you share the full stack Trace? You can run the test from within intellij too. Try a ./bin/buck clean the rebuild? I'm not having this problem on master. keep scope at protected. nit: keep these in the same order as constructor params. nit: move this in line with buildableContext. nit: move to same line as Amender. nit: move to same line as amender. Can we just use junit's @Ignore annotation and link it with a github issue for bumping the compiler? \nSomething like @Ingore(\"https....github/issues/1234\") . Can we just use junit's @Ignore annotation and link it with a github issue for bumping the compiler? \nSomething like @Ingore(\"https....github/issues/1234\") . Can we just use junit's @Ignore annotation and link it with a github issue for bumping the compiler? \nSomething like @Ingore(\"https....github/issues/1234\") . can we update this to be similar to the library test where we have bi-directional calls? . remove. The tests are complaining javaBuckConfig doesn't exist.  Do you have to do the same thing here that you did for the AndroidKotlinBuilder?. https://ci.appveyor.com/project/Facebook/buck/build/3852#L2381\n. Why do you provide a javaBuckConfig for the KotlinAndroidLibraryBuilder but not for the KotlinLibraryBuilder?. Can you just use anyMatch here instead of building a new set? (https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html#anyMatch-java.util.function.Predicate-). buck.jvm.java seems like the wrong place to put Android stuff. Can this be moved to com.facebook.buck.android? . Last small nit: these fields don't seem related to \"AndroidCore\". AndroidLibraryDescription.CoreArg is more \"core\" than this. Maybe rename to AndroidKotlinCoreArg? . ",
    "tiestvilee": "@dsyang this is awesome! Let's get it merged.\nOne thing you might want to look into once it's merged (or I could, but let's wait for the merge) is being a bit more buck like with dependencies. I don't believe you are following them to the degree they should be.\nAfter using the java stuff I would expect the following to work\n``` python\n  kotlin_library(\n    name = \"app-kotlin\",\n    srcs = glob([\"src/main//*.kt\"]),\n    resources = glob([\"src/main/\"], excludes = [\"src/main//*.java\", \"src/main//*.kt\"]),\n    # resources_root = \"src/main\",\n    deps = [\"//:kotlin-runtime\"],\n  )\nkotlin_test(\n    name = \"app-kotlin-test\",\n    srcs = glob([\"src/test//*.kt\"]),\n    resources = glob([\"src/test/\"], excludes = [\"src/test//*.java\", \"src/test//*.kt\"]),\n    deps = [\"//:test-deps\", \":app-kotlin\"],\n  )\n```\nwhere test-deps is a java_library that includes junit and so forth.\nThe above compiles in buck, but the tests fail because they can't see junit (a sub-dependency of test-deps). If I fix that then it fails because it can't see kotlin-runtime - which it should have inherited as a dependency from kotlin_library (would in java_test).\nThis means i have to define lots of dependencies again and again, which sux.\n(also, resources_root doesn't work)\nBut for now - get this into Buck, it's a godsend!\n. ",
    "chinacuizichao": "how to solve this??. ",
    "hitYOUcry": "\u3002\u3002\u3002I remove the  use_linear_alloc_split_dex = True in rule android_binary(),It works fine , but if I don't use use_split_dex=True  build failed again. This is odd.\n. I found the reason.\nbuck will read in the proguard-android.txt file in SDK/tools/proguard.\nThe file has same base android proguard  -keeps.\nWhile my proguard.cfg file have consider every keep and drop situation,so the file is redundant.\nRemove the content of  proguard-android.txt and rebuild release apk, apk file size become normal.\n. Sry for missed the infos.\nThat's awesome ,I missed this config.\nThank you!\n. ",
    "bertmaher": "I've implemented this feature as of this commit: a271a23a24a63e88decba55e176d623717628719.  In addition to properly inheriting stdin, that diff will run commands entirely in the client, so the buckd lock isn't held for the duration of the run.. RECORDED_PATHS is still stored in the filesystem, not the DB.  I fixed a bug a few weeks ago (618ad57c624cec4949341f1e06f49f81983b64b6) where we'd sometimes remove metadata from the filesystem and not the DB, but that particular case shouldn't still be happening.\nDoes this happen to occur after a build is interrupted (Ctrl-C or something like that)?  It's possible that if a build is killed at just the wrong time that the filesystem has been cleared, and not the DB.  Just in case that's what's going on, I'll reorder things so we always clean the DB first, so we'll never go looking for a nonexistent RECORDED_PATHS.. Btw- switching sqlite off should make this go away, if it's a major blocker now.  #sadpanda.. Cool.  If it doesn't go away with sqlite off, let me know that too.  It's entirely possible this is an unrelated bug.. @ShangxuanWu: sqlite isn't enabled by default.  If you want to double-check the setting, make sure that build.metadata_storage=filesystem in your config (and not sqlite).\nIn any event, I don't think that error is related to SQLite; it looks like a corrupt artifact has been stored in your cache.  I've only seen that happen recently on a machine with a bad disk controller.. I'm pretty sure the attached diff will fix this issue -- if you happen to give SQLite a try again, please let me know how it goes!. It's interesting to me that we picked up a new release of nailgun in that time window (I don't know of anywhere we generate InterruptedExceptions aside from nailgun), but I don't see anything to make me suspicious of that bump.  Will keep investigating.. We've been running with NO_BUCKD in our CI, because of exactly this problem :-(.  If it wasn't the nailgun update, I'm sort of at a loss for what could be causing this.  Open to debugging ideas for sure.. Seems like a reasonable idea to me.  I'd like a like a little time to fix up our build configs at FB before merging this, so I don't accidentally start making all our devs run PG :).  Shouldn't take too long (I hope).. The code lgtm, thanks!. Looks like there are still a few failed tests, can you take a look:\nTESTS FAILED: 13 FAILURES\nFailed target: //test/com/facebook/buck/android:aar-integration\nFAIL com.facebook.buck.android.AarWithLibsIntegrationTest\nFAIL com.facebook.buck.android.AndroidPrebuiltAarIntegrationTest\nFAIL com.facebook.buck.android.AndroidBinaryIntegrationTest. One more test - can you take a look at AndroidBinaryIntegrationTest.testProguardDontObfuscateGeneratesMappingFile?\nAfter that this looks good to go.. Argh.  Once I got this running on our CI, I see that we have a number of builds that appear to care about how this setting gets used.  I really want to get those fixed before merging this, but I'm going to be out for a few days.  Lemme see if I can get someone else to take this PR so we can get it in quicker.. Hey @kageiit, as I was fixing up some of our targets I noticed that this diff makes android_sdk_proguard_config default to \"none\" instead of \"default\".  I hadn't thought through the implications until I got bit by it, and I'm worried about other OSS users suddenly getting sub-optimal or wrong results by not using the default PG options.  What do you think?  Would it be reasonable to leave \"default\" alone, but allow a target to disable PG by explicitly setting it to \"none?. Hey @kageiit, as I was fixing up some of our targets I noticed that this diff makes android_sdk_proguard_config default to \"none\" instead of \"default\".  I hadn't thought through the implications until I got bit by it, and I'm worried about other OSS users suddenly getting sub-optimal or wrong results by not using the default PG options.  What do you think?  Would it be reasonable to leave \"default\" alone, but allow a target to disable PG by explicitly setting it to \"none?. Ah, I see your point.  I was thinking that for non-PG builds you'd add android_sdk_proguard_config = \"none\" to your android_binary rule, and leave well enough alone for \"normal\" builds.  But it's probably better to explicitly turn PG on, rather than turn it off :).\nAnyways, I'm almost done updating our internals... should be later today (I hope).. Ah, I see your point.  I was thinking that for non-PG builds you'd add android_sdk_proguard_config = \"none\" to your android_binary rule, and leave well enough alone for \"normal\" builds.  But it's probably better to explicitly turn PG on, rather than turn it off :).\nAnyways, I'm almost done updating our internals... should be later today (I hope).. The short answer is no, Buck doesn't have a way to provide global settings inherited by \"sub-cells\" (and there's not really one on the roadmap, although that may change).  I think copying pieces of .buckconfig is about the best you can do here.  (Assuming the third-party dep actually needs its own .buckconfig -- sometimes you can get away with simply writing a BUCK file for the dep as though it were a \"normal\" part of the project).. I think I spoke too soon -- we may be getting support for \"toolchains\", defined via BUCK rules, soon-ish, which I think should be able to handle your use case.  The design is still high-level right now but I'll keep you posted with the details.. I think I spoke too soon -- we may be getting support for \"toolchains\", defined via BUCK rules, soon-ish, which I think should be able to handle your use case.  The design is still high-level right now but I'll keep you posted with the details.. Sure, will fix on Monday.. Is it possible to unify this with AndroidBinaryBuildable.shouldProguard(). ",
    "tildedave": "@kageiit Hi there, I had a similar issue and I discovered I could get the actual cause of the problem by running buck in verbose mode.\nThis encountered that the actual coverage command was failing, for me it looked like this:\njava -jar /Users/daveking/.gradle/caches/okbuck/buck/build/report-generator.jar \\\n    /Users/daveking/workspace/project/buck-out/gen/jacoco/parameters.properties\nMy issue turned out to be two classes with the same name which causes Jacoco to fail.  Hope this is helpful!. ",
    "HomHomLin": "@zongwu233 Very useful.\n. @zongwu233 Very useful.\n. ",
    "oboolean": "@zongwu233   i still get the same error, even used the newest buck.  see the issue https://github.com/facebook/buck/issues/926\n. @zongwu233   i still get the same error, even used the newest buck.  see the issue https://github.com/facebook/buck/issues/926\n. used the newest buck\nbuck --version\nbuck version 099a899b203f6f24fc3264f3e31b415a4b385f50\n. used the newest buck\nbuck --version\nbuck version 099a899b203f6f24fc3264f3e31b415a4b385f50\n. ",
    "ChaitanyaPramod": "Hi, some us continue to see a similar issue over at #926 which appears to be strongly related to this issue. Can we get some help with #926?. Hi, some us continue to see a similar issue over at #926 which appears to be strongly related to this issue. Can we get some help with #926?. Had the same error. I noticed that dx isn't called with --multi-dex flag even when use_split_dex = True.\nPS: gradle build for the same project succeeded. That was the first thing we tried when we hit the issue and didn't help.\nTried again today and there's no problem, I must have misconfigured earlier. Thanks @kageiit . Facing similar problem with ACRA.\nAgreed that /res/ is mandatory to be present in a .aar, but strictly requiring this inconveniences end developer and breaks interop with Gradle android plugin. Library authors tend to not bother as the artefact is usable with gradle-android-plugin.\nHaving this check is not helping buck or the app developer.. ",
    "markortiz": "@mlostekk how do you solve this problem?\nI got the same error.\n. ",
    "UniverQuie": "so sad ,I got the same error too. @aiked  thanks for u echo ,echo $NDK_HOME  /Users/zhupei/Documents/adt-bundle-mac-x86_64-20140702/sdk/android-ndk-r7b\nI dont think the env is the problem\nI got  the file contents of source.properties  \nPkg.Desc = Android NDK\nPkg.Revision = 13.1.3345770\nwait....\nI dont think the Pke.Revision is right ,So I turn   the value of Pke.Revision  into value  \"r7b\"\nu guess what ,It's working  \nthanks again,appreciated u nice comment above\n. @mlostekk  under path $NDK_HOME /Users/zhupei/Documents/adt-bundle-mac-x86_64-20140702/sdk/android-ndk-r7b/source.properties ,with contents follow as:\nPkg.Desc = Android NDK\nPkg.Revision = 13.1.3345770. \n. \nI have a local.properties with content of sdk and ndk absolute path\nas same got the error \n\n. I got the same problem to \n[ndk]\n  ndk_version = 16.1.4479499\n  app_platform = android-21. I got the same problem to \n[ndk]\n  ndk_version = 16.1.4479499\n  app_platform = android-21. ",
    "mlostekk": "Yep, already did that.. thanks anyways\n. my NDK version is 12.1.2977051 Is this b? I dont know. Where can i find out that human friendly version string?\n. ",
    "zongwu233": "Thanks for your guidance~\nIt's very useful. I'll try.\n. ",
    "jernejstrasner": "@robbertvanginkel any updates on this?\n. @nguyentruongtho sweet!\n@robbertvanginkel any updates on that pull request?\n. ",
    "lacker": "Sorry! I think https://github.com/facebook/buck/pull/849 should fix it\n. ",
    "zbsz": "Got something similar in #913, but instead of creating specific Android{LANG}LibraryDescription I opted to use language config parameter. So far have it implemented for Scala, adding Kotlin and other jvm languages should be quite straightforward then, just wanted to get it accepted for Scala first.\n. True, this files are in 666, and they stay this way.\nDidn't realize that anybody cares about that, isn't exopackage supposed to only be used in development? \nThanks for info.\n. @dsyang thanks for comments. Do you have suggestions how to solve AndroidPlatformTarget and ScalaBuckConfig issues? I'm not very familiar with the code and didn't see any obvious way to do it better, so any tips would be appreciated.\n. Rebased with master.\nAndroid integration test keeps failing on Travis, seems to be caused by limited memory, not sure how to fix that.\n. Rebased with master.\nAndroid integration test keeps failing on Travis, seems to be caused by limited memory, not sure how to fix that.\n. Moved to separate files.\n. Improved a bit\n. Replaced android boot classpath supplier in BuildContext with AndroidPlatformTarget supplier.\n. Not sure how to improve that, we could introduce some additional class for this, something like JvmLanguagesConfig, but it's just moving the same things from arguments list to fields. Any better suggestions?\n. 1) JvmLanguagesConfig would need to include almost everything that is in language specific configs, I mean there doesn't seem to be a common subset of settings that would be enough to instantiate any AndroidLibraryCompiler\n2) getCompiler uses language param, so it can not be created before AndroidLibraryDescription \nWe could pass in some kind of compiler factory if you like.\n3)\nOther option would be to have class providing suppliers for all configs, something like:\nabstract class AndroidLibraryConfig {\n    Supplier<ScalaBuckConfig> getScalaConfigSuplier();\n    Supplier<KotlinBuckConfig> getKotlinConfigSupplier();\n    ...\n}\nAll methods would have default implementations throwing exceptions, so there is no need to specify all configs every time.\nWhat do you think about that?\n. To achieve better reuse it could be good to replace AndroidLibraryCompiler with common JvmLibraryCompiler, this would be more general compiler provider without references to android (placed in jvm.common), then ScalaLIbraryDescription (and others) would use it the same way AndroidLibraryDescription does.\nI'm just afraid that this will end up being a bigger refactoring, and I'm not sure if I want to do it as a part of this PR.\n. Just tried adding AndroidLibraryCompilerFactory, in last commit. Not sure if that's worth it, it ads some indirection, library description doesn't need to know all the configs, but factory will still need them.\n. Ant complains about unused parameters in default implementation, for example: 'The value of the parameter resolver is not used'.\n. Created #915 \n. fixed\n. fixed, yup forgot to revert that\n. Added in AndroidLibraryIntegrationTest, although I'm not sure if that's exactly right, this fails on Arg parsing level, so it's not reported as build failure, but runBuckBuild throws an exception.\n. You're right, I was just lazy, added test in AndroidLibraryDescriptionTest\n. Removed, most likely wasn't need. To be honest I based that on some other args without really understanding what it does.\n. Added small description, any improvements will be welcome. \n. Added small description, any improvements will be welcome.\n. fixed\n. changed to use DefaultJavaLibrary directly, seems to be working\n. replaced\n. replaced\n. Scala was added in #913\nWas thinking about autodetection, was just afraid of backward compatibility issues. Would it be possible that some Java projects contain scala or kotlin sources by accident, and expect to be using javac which just ignores such files?\n. ",
    "coofee": "Very thanks  @marcinkosiba @aiked\nI do not redistribute an obfuscated .jar along with resources, it's because my app has some module, and each module's resources id has different type id.  such as below:\nmodule1: 0x7f070000\nmodule2: 0x7f170000\nmodule3: 0x7f270000 \n. Thank you very much. @aiked \n. ",
    "asp2insp": "@kageiit Do you have a small example project that can show this behavior? Can you share the definition of the src_release rule? \n. This is caused by d08ca15 since JavaTest no longer inherits from JavaLibrary I'll take it on.\n. @davido do you also expect the //gerrit-httpd:httpd_tests jar to appear in the the classpath output?\n. Can you give an example of how you would like this to work and what you would like to accomplish? Right now, query_outputs and query_targets explicitly only support fetching lists of build targets, in order to build a dependency graph, so anything which is not a build target cannot be returned.\nInternally, we've often solved problems related to sharing sub-structure of rules by defining a macro. Would this work in your case?\n. Good question! Here's the declaration for AbstractCxxBinaryDescriptionArg (which inherits from CommonArg The concrete implementation is generated by the immutables annotation processor, so getter methods are synthesized into fields/builders/getter/setter methods.\nIt sounds like this option should go in LinkableCxxConstructorArg. Just add a new getter decorated with @Value.Default. Once you re-build the new arg will show up. camelCase getters are automatically converted into snake_case python params. Let me know if you need a deeper dive into any piece of the puzzle :). Fantastic, thanks!. Hm, the lint is still complaining about the formatting on the java files. Could you run it one more time? Thanks!. If you want an existing test to model, here's where most of the genrule query tests live so far: https://github.com/facebook/buck/blob/master/test/com/facebook/buck/shell/GenruleDescriptionIntegrationTest.java and here's where their buck files are: https://github.com/facebook/buck/blob/master/test/com/facebook/buck/shell/testdata/genrule_classpath_filtering/BUCK.fixture . What's the use case for the mixed-mode outputs/inputs here?. Tests are failing due to the missing dependency on rules/modern for this test.. Looks like the code formatter you used added some whitespace. Please make sure to run Google's Java formatter on the PR (see Contributing.md) . This looks good to me! @andrewjcg would you mind taking a quick look?. This should be @Value instead of @Value.Default since Optional has a sane default . ",
    "felipecsl": "@kageiit we were using the HEAD sha from Buck when we ran into this issue, so I'm pretty sure it still exists\n. This problem is back when using latest master (as of commit aa786c45010d7c70c8680c1dd14d02d451789094). Never mind, red herring!. Using that option in the buckconfig indeed fixed the problem. Thanks!\n. @thalescm sounds like you just volunteered \ud83d\ude04 . no we don't have one (yet) \ud83d\ude04 . ",
    "bopbi": "hi recently i created a build using buck, but it always failed and the output contains: \nUnrecognized plist variable: $(PRODUCT_BUNDLE_IDENTIFIER) when reading from the Info.plist file\nand after i to change the $(PRODUCT_BUNDLE_IDENTIFIER) on the plist to a hardcoded value it work, so does my issue related with this issue?. hi recently i created a build using buck, but it always failed and the output contains: \nUnrecognized plist variable: $(PRODUCT_BUNDLE_IDENTIFIER) when reading from the Info.plist file\nand after i to change the $(PRODUCT_BUNDLE_IDENTIFIER) on the plist to a hardcoded value it work, so does my issue related with this issue?. ",
    "AquaGeek": "I have signed the CLA. I reached out to the email address listed for assistance.\nAlso, it looks like we need to make further changes to ensure that the standard libraries are copied without being code signed (the current implementation signs them by default). However, there seems to be a bug in swift-stdlib-tool where it doesn't properly support the --unsigned-destination argument (it crashes due to the missing --destination flag). I've opened a radar.\nAFAIK, the stdlibs need to be copied without being code signed, so we're going to need to figure out a workaround. Hopefully it doesn't come down to \"iterate Frameworks + PlugIns, copy any matching libs manually from the Toolchain dir.\" \ud83d\ude1e \n. I have signed the CLA. I reached out to the email address listed for assistance.\nAlso, it looks like we need to make further changes to ensure that the standard libraries are copied without being code signed (the current implementation signs them by default). However, there seems to be a bug in swift-stdlib-tool where it doesn't properly support the --unsigned-destination argument (it crashes due to the missing --destination flag). I've opened a radar.\nAFAIK, the stdlibs need to be copied without being code signed, so we're going to need to figure out a workaround. Hopefully it doesn't come down to \"iterate Frameworks + PlugIns, copy any matching libs manually from the Toolchain dir.\" \ud83d\ude1e \n. OK, it looks like swift-stdlib-tool doesn't codesign unless the --sign option is provided, so we should be able to use --destination instead of --unsigned-destination (though once the bug is fixed we probably want to migrate to the latter).\nAlso, it turns out the libraries were being codesigned in the build phase \u2014 the packaging phase was essentially a no-op because the libraries had already been copied (due to the reused temp dir). I added a flag to use a separate temp dir for the packaging phase, and now the libraries are properly copied as-is.\nHappy to hear any thoughts on how to make this better (not super happy with the flag approach), but it appears to at least be functioning properly now.\n. OK, it looks like swift-stdlib-tool doesn't codesign unless the --sign option is provided, so we should be able to use --destination instead of --unsigned-destination (though once the bug is fixed we probably want to migrate to the latter).\nAlso, it turns out the libraries were being codesigned in the build phase \u2014 the packaging phase was essentially a no-op because the libraries had already been copied (due to the reused temp dir). I added a flag to use a separate temp dir for the packaging phase, and now the libraries are properly copied as-is.\nHappy to hear any thoughts on how to make this better (not super happy with the flag approach), but it appears to at least be functioning properly now.\n. Cool. I'll update when I hear back from the CLA folks.\nAny idea why //test/com/facebook/buck/android:integration is failing?\n. @nguyentruongtho The copy swift stdlibs step that the packaging class leverages already takes this into account. I've added another integration test to check that scenario, though.\n. @sdwilsh Our point of contact here for the CLA (@myhrvold) has been trying to get ahold of anybody at FB to add me to the CLA. I think he emailed you late last week with the relevant info. Anything else we need to do on our end?\n. Rebased to fix the merge conflict and did some minor cleanup.\n. Rebased to fix the merge conflict and did some minor cleanup.\n. ",
    "dmays": "@marcinkosiba for any that find this in the future, your proposed solution worked perfectly for me.  \nI created a project with the AS new project wizard and experienced this issue immediately.  Setting includes_vector_drawables = True on android_binary of my app module's build file fixed the android.content.res.Resources$NotFoundException crash at runtime that I was experiencing.\n. @marcinkosiba for any that find this in the future, your proposed solution worked perfectly for me.  \nI created a project with the AS new project wizard and experienced this issue immediately.  Setting includes_vector_drawables = True on android_binary of my app module's build file fixed the android.content.res.Resources$NotFoundException crash at runtime that I was experiencing.\n. ",
    "finik": "buck --version\nbuck version v2016.09.26.01\nenv | grep -i android\nANDROID_HOME=/Users/finik/work/android-sdk\nANDROID_SDK_ROOT=/Users/finik/work/android-sdk\nPATH=/Users/finik/perl5/bin:/usr/local/Cellar/ruby/1.9.3-p327/bin/:/usr/local/share/npm/bin/:/Users/finik/bin:/usr/local/bin:/usr/local/sbin:/Users/finik/work/android-sdk/tools:/Users/finik/work/android-sdk/platform-tools:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin\nenv | grep -i java\nJAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home\n. buck --version\nbuck version v2016.09.26.01\nenv | grep -i android\nANDROID_HOME=/Users/finik/work/android-sdk\nANDROID_SDK_ROOT=/Users/finik/work/android-sdk\nPATH=/Users/finik/perl5/bin:/usr/local/Cellar/ruby/1.9.3-p327/bin/:/usr/local/share/npm/bin/:/Users/finik/bin:/usr/local/bin:/usr/local/sbin:/Users/finik/work/android-sdk/tools:/Users/finik/work/android-sdk/platform-tools:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin\nenv | grep -i java\nJAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home\n. ",
    "zhihuawensc": "@Zetten \nDid you figured out how to use aspectj with buck build?\nIt will be great if you can share your example, thanks a lot.. @Zetten \nDid you figured out how to use aspectj with buck build?\nIt will be great if you can share your example, thanks a lot.. Is there a concrete example about how to use it with Google's Error prone compiler?\nI am also interested in about how to use it with aspectj compiler?\nThe format used by Hugo at https://github.com/JakeWharton/hugo/blob/master/hugo-runtime/build.gradle is like below in gradle\nandroid.libraryVariants.all { variant ->\n  JavaCompile javaCompile = variant.javaCompile\n  javaCompile.doLast {\n    String[] args = [\n        \"-showWeaveInfo\",\n        \"-1.5\",\n        \"-inpath\", javaCompile.destinationDir.toString(),\n        \"-aspectpath\", javaCompile.classpath.asPath,\n        \"-d\", javaCompile.destinationDir.toString(),\n        \"-classpath\", javaCompile.classpath.asPath,\n        \"-bootclasspath\", android.bootClasspath.join(File.pathSeparator)\n    ]\n    MessageHandler handler = new MessageHandler(true);\n    new Main().run(args, handler)\n    def log = project.logger\n    for (IMessage message : handler.getMessages(null, true)) {\n      switch (message.getKind()) {\n        case IMessage.ABORT:\n        case IMessage.ERROR:\n        case IMessage.FAIL:\n          log.error message.message, message.thrown\n          break;\n        case IMessage.WARNING:\n        case IMessage.INFO:\n          log.info message.message, message.thrown\n          break;\n        case IMessage.DEBUG:\n          log.debug message.message, message.thrown\n          break;\n      }\n    }\n  }\n}\n. Is there a concrete example about how to use it with Google's Error prone compiler?\nI am also interested in about how to use it with aspectj compiler?\nThe format used by Hugo at https://github.com/JakeWharton/hugo/blob/master/hugo-runtime/build.gradle is like below in gradle\nandroid.libraryVariants.all { variant ->\n  JavaCompile javaCompile = variant.javaCompile\n  javaCompile.doLast {\n    String[] args = [\n        \"-showWeaveInfo\",\n        \"-1.5\",\n        \"-inpath\", javaCompile.destinationDir.toString(),\n        \"-aspectpath\", javaCompile.classpath.asPath,\n        \"-d\", javaCompile.destinationDir.toString(),\n        \"-classpath\", javaCompile.classpath.asPath,\n        \"-bootclasspath\", android.bootClasspath.join(File.pathSeparator)\n    ]\n    MessageHandler handler = new MessageHandler(true);\n    new Main().run(args, handler)\n    def log = project.logger\n    for (IMessage message : handler.getMessages(null, true)) {\n      switch (message.getKind()) {\n        case IMessage.ABORT:\n        case IMessage.ERROR:\n        case IMessage.FAIL:\n          log.error message.message, message.thrown\n          break;\n        case IMessage.WARNING:\n        case IMessage.INFO:\n          log.info message.message, message.thrown\n          break;\n        case IMessage.DEBUG:\n          log.debug message.message, message.thrown\n          break;\n      }\n    }\n  }\n}\n. ",
    "stowy": "The PR is open here https://github.com/facebook/buck/pull/983\n. @nguyentruongtho this is great, thanks for doing.\nI have tested interop with this here - https://github.com/stowy/buck_swift_test/tree/moduleTests - check the readme. \nI have found that swift does not recognize objC files in the module, unless they are specifically included in the modules bridging header.\nI have also not been able to have external modules (eg a test module) reference an exported modules swift class from objc.\nAre these results expected?\n. Thanks Tho, just to clarify about the reading objC from swift though, I meant that it will not read any objC classes in swift, even if those classes are in exported headers in the generated umbrella header. \nThey will only be recognized if the headers are included in the objc-swift bridging header of the apple-library, which is unrelated to the module umbrella header.\nGood news about the swift-objc interior, thanks. \n. No problems. Not a big issue with this PR, but definitely I would like to\naddress in future PRs.\nGood luck with CI \ud83d\ude1d\nOn Mon, Nov 7, 2016 at 9:20 AM Tho Nguyen notifications@github.com wrote:\n\n@stowy https://github.com/stowy sure, I'll test your sample project\nonce I get a CI pass for this PR \ud83d\ude04\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/983#issuecomment-258900556, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AFpnFDb58ytDxdRF5Zi7EYbvQZH-X9fsks5q7132gaJpZM4KmSB0\n.\n. Looking into this further, it seems that the file organisation in the 'buck-out/gen' folder for the ObjC headers changes when the 'swift-compile' step is included in the build process (because of the presence of swift in the library).\n\nSee this file output below, notice that the headers are included in a single flat directory for the ObjC output, but in a hierarchical directory structure for the swift one. The libraries that rely on this MixedDependency1 then fail to compile because headers are not found. \n@nguyentruongtho\n\nThis only occurs in the test when building :MainBinary, when building MixedDependencyTests/MixedDependency3:MixedDependency3 from clean it does not occur and we get this structure:\n\n. No problems. I've had a further look into it and it seems that the header\nkey maps for the library containing swift do not have the correct,\nshortened keys. I'm thinking it's caused by the swift companion build rule.\nIf I'm able I may write a test for this and try to debug, I'll post a link\nhere if I get one created.\nOn Fri, Nov 4, 2016 at 10:05 AM Tho Nguyen notifications@github.com wrote:\n\nCool, thanks for being very descriptive about this \ud83d\udc83\nI'll take a look during this weekend, was too busy with other stuffs\nrecently.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/991#issuecomment-258489805, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AFpnFDVG2YTVR5Lc-l_Q7QiozLrTdKO1ks5q62XGgaJpZM4Kn_Q0\n.\n. The above PR should fix this issue - it fixes the headermap for the SwiftCompile step.\n. Sure sorry, the main change is at https://github.com/stowy/buck/blob/21d4cf21eacb3191c774973772b354db37043b51/src/com/facebook/buck/swift/SwiftDescriptions.java#L67\n\nIt changes the header map to be the shortened version of { 'header_prefix_path/filename.h' : 'absolute/path/to/file/filename.h'} instead of what it is currently, which is { 'relative/path/to/filename.h' : 'absolute/path/to/file/filename.h'}.  The former allows normal imports in ObjC, the latter breaks ObjC imports. \n. The remainder of the change is to add an interop integration test (https://github.com/stowy/buck/blob/21d4cf21eacb3191c774973772b354db37043b51/test/com/facebook/buck/swift/InteropLibraryIntegrationTest.java#L41) which replicates issue https://github.com/facebook/buck/issues/991 - this passes on this branch but not in the main project. \n. ",
    "ultramiraculous": "With a large mixed ObjC/Swift project we had a huge (Around 60%) speedup from building the target all at once and turning on whole module optimization. . ",
    "daedric": "here you go :)\nhttps://github.com/daedric/buck/tree/swift-zenly-rebased\n. That would be great, do not hesitate asking me question. My branch is unfortunately not clean as it was a bit rushed, but I'm willing to provide any assistance you need to clean it\ncheers,. ",
    "gbrhaz": "@steeve I'd be interested in seeing those CocoaPod scripts - looking at doing this myself. Any chance of putting them up?. ",
    "leeight": "https://github.com/facebook/react-native/issues/2814\n. https://github.com/facebook/react-native/issues/2814\n. @LegNeato build method signature changed, you need add more parameters.\n. ",
    "mafunes": "I have same error, anyone knows how to fix it?. trim_resource_ids = True work for me :) Thanks @kageiit . ",
    "aarongable": "(I'm not sure if facebook-github-bot will auto-update the status here or not, so:)\nI am an employee of Google. I just signed the Corporate CLA with three addresses: my corporate (@google.com), open-source (@chromium.org), and personal (@gmail.com) addresses.\n. ",
    "rnystrom": "@nguyentruongtho update on this?\n. @nguyentruongtho update on this?\n. @nguyentruongtho yup trying to do something similar. Currently writing some unit tests in Swift for an ObjC library to make interop changes blocking. We have a bridging header in our unit test suite but looks like its not picking it up when building.\n. @nguyentruongtho yup trying to do something similar. Currently writing some unit tests in Swift for an ObjC library to make interop changes blocking. We have a bridging header in our unit test suite but looks like its not picking it up when building.\n. ",
    "gontovnik": "@nguyentruongtho, could you please let me know what is the latest status on that? I'd love if you could ping me on Messenger: http://m.me/gontovnik\nThanks!. @nguyentruongtho, could you please let me know what is the latest status on that? I'd love if you could ping me on Messenger: http://m.me/gontovnik\nThanks!. ",
    "runningcode": "I don't think there's anything blocking it.\nI filed this with the jetbrains team: https://youtrack.jetbrains.com/issue/KT-18072\nOtherwise figuring out how to do this will require examining the source code of the gradle kapt plugin and seeing how it works.\nI have some preliminary support for annotation processors in #1358. For example a kotlin class with an @Inject constructor seems to work fine when injected in to a java class. I haven't explored which parts of annotation processors aren't working.. I'll probably take a stab at this soon. I've been taking a look at how this is done in gradle land. This is how it is done in kotlin 1.1.3.\nThere's 4 steps.\n1. kaptGenerateStubsKotlin: \nrun kotlinc with plugin:org.jetbrains.kotlin.kapt3:aptMode=stubs\n2. kaptKotlin\nrun kotlinc with plugin:org.jetbrains.kotlin.kapt3:aptMode=apt\n3. compileKotlin\nrun kotlinc regularly\n4. compileJava\nrun javac with -proc:none and pass the generated sources from step 2.\nThese steps are slightly different with each minor version of kotlin so this will be interesting. It seems there are 3 steps in kotlin 1.1.2:\n1. kaptKotlin\nrun kotlinc with plugin:org.jetbrains.kotlin.kapt3:aptOnly=true\n2. compileKotlin\nrun kotlinc regularly\n3. compileJava\nrun javac with -proc:none and pass the generated sources from step 1.\nI figured these out by running a gradle build on a small kotlin module with --debug.\n. I tried out this branch and I got an error when passing mixed sources to it. error: source entry is not a Kotlin file. Ah, I meant I tried passing java sources and kotlin sources to a module on the brettwooldridge:kotlin-compiler2 branch.. Description updated!. IMO, I think its a common enough pattern to warrant the change. For people using this pattern, having this in the project also lowers the barrier of entry for exopackage.\nIf not, I think @dreiss's alternative should be in the readme/documentation.. ant clean && ant && bin/buck kill solved it!. I've seen this a couple times as well, but its not reproducible. This seems to be a safe SHA 216919bbcc59403eeacfa9ce20a07fa37002da50. I've seen this a couple times as well, but its not reproducible. This seems to be a safe SHA 216919bbcc59403eeacfa9ce20a07fa37002da50. Why does the android_library rule have resources and resources_root options if they are ignored?\nBy default, the Android Gradle Plugin includes resources in the src/main/resources folder of your build. The resources are included based on the following rules: https://google.github.io/android-gradle-dsl/current/com.android.build.gradle.internal.dsl.PackagingOptions.html. Why does the android_library rule have resources and resources_root options if they are ignored?\nBy default, the Android Gradle Plugin includes resources in the src/main/resources folder of your build. The resources are included based on the following rules: https://google.github.io/android-gradle-dsl/current/com.android.build.gradle.internal.dsl.PackagingOptions.html. Yeah we're in the process of migrating our code so we stop relying on this, but I can see this being a blocker for other people trying to use buck. It took me a long time to diagnose. \nAlso, if an android_library rule depends on a java_library rule with these resources, they don't get picked up in that situation either.. Yeah we're in the process of migrating our code so we stop relying on this, but I can see this being a blocker for other people trying to use buck. It took me a long time to diagnose. \nAlso, if an android_library rule depends on a java_library rule with these resources, they don't get picked up in that situation either.. Oops, wrong commits.. BTW, is there a better way to update these libraries other than a manual find and replace?. Rebased off of the in-memory kotlin compiler changes. Can you take a look @dsyang ?. Hang on, I think i made a small typo, and this isn't working. I will update this in a bit.. Ok updated. Annotation processors weren't able to pick up kotlin files without the output of kotlinc being passed to javac. Added a comment.. Good idea. I added a test for a kotlin android library module that has both java and kotlin. This test and the java + kotlin test for a kotlin module are now assumed away with a new assumeCompilerSupportsMixedSources() method.\n. Updated to add @Ignore and mixed sources tests.. @dsyang I might need some help debugging the CI failures. I get different errors on different computers when trying to run the tests locally and none of them are the same as the travis failures.. If the annotation processor is written in kotlin, doesn't it need to be passed to kotlinc?. Can you tell me if you get a similar error on this branch? https://github.com/facebook/buck/pull/1358\nI made some small changes to the way annotation processors are passed to javac in kotlin modules.\nBut actually you're seeing this issue in a pure java module, so i doubt my branch would change anything.. cc @dreiss You mentioned I should change the native agent to match this behavior. It looks to me that the native agent doesn't throw an exception if it fails to find the manifest digest. But my C skills aren't very sharp so perhaps I was reading the code wrong.. Hi, sorry for not responding. I took a break from Android, but I'm back!\nAnyways, I'm now working at a new company and working to transition gradle to buck and we encountered the same problem.\nThere's a CERT.SF and a MANIFEST.MF file.\nThe MANIFEST.MF file is the one that has a long list of contents like so:\n```\nManifest-Version: 1.0\nBuilt-By: Generated-by-ADT\nCreated-By: Android Gradle 3.1.0-alpha08\nName: AndroidManifest.xml\nSHA-256-Digest: Un6YY/J2B4f4GI4xhC0m1a/EGClaOEdg7+ZZOLdcBz4=\nName: META-INF/android.arch.lifecycle_runtime.version\nSHA-256-Digest: 9eXJU0UyhA/NRbsALmnthcYduidTRQ4mtEi33xSB4k0=\nName: META-INF/app_debug.kotlin_module\nSHA-256-Digest: zwWKnIwxvaA649IRJxgIS4/epZhuAYgYvtDp5LcmSAk=\n```\nBut it looks like buck is looking for the SHA-256-Digest in a file ending with *.SF which in this case is the CERT.SF which doesn't contain these SHA-256-Digest lines.\n@dreiss How should we proceed?. Looks like there's a tool called metalava that generates APIs for kotlin libraries. Its being used in the new android extensions library. https://github.com/android/android-ktx/blob/master/build.gradle Look at the updateApi task\nHere's more: https://android.googlesource.com/platform/tools/metalava/. @dsyang If i rename test/com/facebook/buck/jvm/kotlin/testdata/kotlin_library_description/com/example/mixed/BUCK.fixture to BUCK \nand then run \n./bin/buck build test/com/facebook/buck/jvm/kotlin/testdata/kotlin_library_description/com/example/mixed:example \nit seems to work, but when I run the test locally, \n./bin/buck test //test/com/facebook/buck/jvm/kotlin:kotlin \nit fails in the same way as CI.. If I remember correctly, my theory as to why this was failing was that the kotlin compiler only likes the gradle directory structure.\nThis test passes correctly in the okbuck repository and in Square's uses but not here because the directory structure is different.. @jkeljo @thalescm Is it possible to have the AP as a separate rule? I think the reason that it is a step instead of a rule is that you can have human-written code call directly in to the generated code.\nIf the AP fails to generate code, that would mean that the compile \"rule\" failed, but you would only know until you ran the AP.\nAP Generated code and human written code can call each other.. Just need a yes/no and I'll create a PR to do this :). Any thoughts on this?. Any thoughts on this?. This module has no dependencies on those annotations. I'm not sure we want to add them, I'll leave that up to the buck maintainers to decide.. The name is @NonNull in Context.getSystemService(). @rjrjr was referring to the return value for this method.. Is there a difference between this class and DefaultJavaLibrary? I'm new to this codebase and this seems like a common pattern here. I'm just thinking we should document things like this. :). is this the default version on unknown version?\ncan we document the behavior around versions somewhere? how to set the version, what the default is, what happens if none is set?. Yeah, should i create a new JavacToJarStepFactory here and call createJarStep on it?. @dsyang no, those are public so that the KotlincToJarStepFactory can override the getBootClassPath() method with the additional classpaths similar to how JavacToJarStepFactory overrides this method.. These aren't running. All the kotlin tests are ASSUMED on CI. Do you know how to change this?. They would also need to be compiled and run with a version of kotlinc 1.1.3 or higher in order to pass.. I can't figure out how to get tests to run locally nor even compile buck using buck. \n./bin/buck build buck or ./bin/buck test //test/com/facebook/buck/jvm/kotlin:kotlin fail with\nCannot find annotation method 'fieldVisibility()' in type 'com.fasterxml.jackson.annotation.JsonAutoDetect': class file for com.fasterxml.jackson.annotation.JsonAutoDetect not found and some other errors as well.. ```\nnelson$ ./bin/buck test //test/com/facebook/buck/jvm/kotlin:kotlin\nBUILD FAILED: //src/com/facebook/buck/rules/macros:macros failed with exit code 1:\njavac_jar\nstderr: /Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/rules/build_rule#class-abi/build_rule-abi.jar(com/facebook/buck/rules/BuildRule.class):-1: warning: Cannot find annotation method 'fieldVisibility()' in type 'com.fasterxml.jackson.annotation.JsonAutoDetect': class file for com.fasterxml.jackson.annotation.JsonAutoDetect not found\n: warning: unknown enum constant com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility.NONE\nreason: class file for com.fasterxml.jackson.annotation.JsonAutoDetect$Visibility not found\n/Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/rules/build_rule#class-abi/build_rule-abi.jar(com/facebook/buck/rules/BuildRule.class):-1: warning: Cannot find annotation method 'getterVisibility()' in type 'com.fasterxml.jackson.annotation.JsonAutoDetect'\n: warning: unknown enum constant com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility.NONE\n/Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/rules/build_rule#class-abi/build_rule-abi.jar(com/facebook/buck/rules/BuildRule.class):-1: warning: Cannot find annotation method 'fieldVisibility()' in type 'com.fasterxml.jackson.annotation.JsonAutoDetect': class file for com.fasterxml.jackson.annotation.JsonAutoDetect not found\n/Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/rules/build_rule#class-abi/build_rule-abi.jar(com/facebook/buck/rules/BuildRule.class):-1: warning: Cannot find annotation method 'getterVisibility()' in type 'com.fasterxml.jackson.annotation.JsonAutoDetect'\n/Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/rules/build_rule#class-abi/build_rule-abi.jar(com/facebook/buck/rules/BuildRule.class):-1: warning: Cannot find annotation method 'fieldVisibility()' in type 'com.fasterxml.jackson.annotation.JsonAutoDetect': class file for com.fasterxml.jackson.annotation.JsonAutoDetect not found\n/Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/rules/build_rule#class-abi/build_rule-abi.jar(com/facebook/buck/rules/BuildRule.class):-1: warning: Cannot find annotation method 'getterVisibility()' in type 'com.fasterxml.jackson.annotation.JsonAutoDetect'\n/Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/model/model#class-abi/model-abi.jar(com/facebook/buck/model/AbstractBuildTarget.class):-1: warning: Cannot find annotation method 'fieldVisibility()' in type 'com.fasterxml.jackson.annotation.JsonAutoDetect'\n/Users/nelson/Repositories/buck/src/com/facebook/buck/rules/macros/AbstractMacroExpander.java:-1: warning: unknown enum constant com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility.NONE\n/Users/nelson/Repositories/buck/src/com/facebook/buck/rules/macros/QueryMacroExpander.java:52: error: cannot access com.facebook.buck.graph.DirectedAcyclicGraph\n  private Optional targetGraph;\n                  ^\n  class file for com.facebook.buck.graph.DirectedAcyclicGraph not found\n/Users/nelson/Repositories/buck/src/com/facebook/buck/rules/macros/QueryMacroExpander.java:54: error: type argument com.facebook.buck.rules.TargetGraph is not within bounds of type-variable T\n  public QueryMacroExpander(Optional targetGraph) {\n                                     ^\n/Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/event/interfaces#class-abi/interfaces-abi.jar(com/facebook/buck/event/AbstractBuckEvent.class):-1: warning: Cannot find annotation method 'value()' in type 'com.fasterxml.jackson.annotation.JsonView'\n/Users/nelson/Repositories/buck/buck-out/gen/src/com/facebook/buck/event/external/external_lib#verified-source-abi/external_lib-abi.jar(com/facebook/buck/event/external/events/BuckEventExternalInterface.class):-1: warning: Cannot find annotation method 'value()' in type 'com.fasterxml.jackson.annotation.JsonProperty'\n/Users/nelson/Repositories/buck/src/com/facebook/buck/rules/macros/QueryOutputsMacroExpander.java:51: error: type argument com.facebook.buck.rules.TargetGraph is not within bounds of type-variable T\n  public QueryOutputsMacroExpander(Optional targetGraph) {\n                                            ^\n/Users/nelson/Repositories/buck/src/com/facebook/buck/rules/macros/QueryTargetsMacroExpander.java:47: error: type argument com.facebook.buck.rules.TargetGraph is not within bounds of type-variable T\n  public QueryTargetsMacroExpander(Optional targetGraph) {\n                                            ^\nErrors: 4. Warnings: 12.\n``. can you try on a non-facebook computer? ive never gotten buck to compile using buck.. marked as protected.. TheKotlinAndroidLibraryBuilder`? Which part of it?. Well, that's embarrassing. We were only using mixed sources in KotlinAndroidLibrary rules so this wasn't working at all. :P\nIt's fixed.. try with resources?. would be cool to add a test that outputs kotlin files as well ;). ",
    "cubuspl42": "For future reference: https://stackoverflow.com/questions/45217399/how-to-use-kapt-from-command-line-with-kotlinc. ",
    "elihart": "@runningcode any progress on this? It would be awesome to be able to use kapt.. @runningcode any progress on this? It would be awesome to be able to use kapt.. Great to hear :) Thanks!\n. Great to hear :) Thanks!\n. @dsyang is this able to be merged? It would be awesome to have it in. ",
    "cwoodwar6": "@elihart It is still a work in progress. Hoping to have something together in the coming weeks.. @elihart It is still a work in progress. Hoping to have something together in the coming weeks.. @BharathMG sorry, progress has been slow. I haven't had much time to look at it. Step 1 outlined by @runningcode above seems to be failing even with the exact same arguments that Gradle uses. This leads me to believe there is some sort of Step 0 or my arguments are somehow incorrect. I haven't been able to prove either.. I haven't had very much time to look into this since I've posted the preliminary PR. Anyone who wants to pick up where I left off is more than welcome. I'm going to try my best to find time in the near future to work on it.. I haven't had very much time to look into this since I've posted the preliminary PR. Anyone who wants to pick up where I left off is more than welcome. I'm going to try my best to find time in the near future to work on it.. Thankfully, we no longer have to run with pre-dex disabled.\nTo verify, I disabled pre-dex, and was able to modify a resource id without a runtime crash. Looks resolved to me.. Explicitly, I was not aware of annotation_processor_only. Is there an equivalent flag for -proc:none?. Seems related to #1252. Seems related to #1252. What was the conclusion here?. The bump to 1.1.3 will be required if we want to use the latest kapt arguments. Anyone have any ideas why this is failing?. Here is what I changed: https://github.com/cwoodwar6/okbuck/commit/e6ec0ff9e76baa0966737117a7f4016450df1497\nIf I run ./buckw targets I see //test:res_debug. The result is the same no matter how I do it: https://github.com/cwoodwar6/okbuck/commit/c8657ff7bd1c968dbfb52cfc47cee41d85d1c5c2. //app:lint_debug_test\n//app:src_debug_test. We actually aren't actively using that target, it is auto generated for us via OkBuck. But basically it runs lint over the androidTest source directory. I suppose I could remove it to get around this. Is the list sorted alphabetically and picks the first one? I could also try renaming the target to hopefully change the ordering.. I also realize the second target is wrong. This is an instrumentation test, I'd need the android_instrumentation_apk rule (target of //app:instrumentation_debug_test) in order to run this test. //app:src_debug_test is the android_library that compiles the code, but not the target I need to run. I'm guessing this is something that buck query just isn't set to handle?. @dsyang - Could you take a look at this one too please?. I added a test, but it must intentionally fail until we bump the kotlin version in https://github.com/facebook/buck/issues/1371. Then we can test how to use the plugin appropriately.. @dsyang - Are we all good here?. @dsyang - Are we all good here?. Just rebased, how about now?. Looks like this is now done?. @cjhopman as far as I can tell it has always been that way, but I haven't tested older versions.. @cjhopman From what I can tell, this solution would have the same impact on build costs, correct? Because essentially you have to recompile all of the build graph underneath with the new target?\nThis solution is nice because it at least gives me the ability to configure it on the fly but I'd like to hide this detail from users. Is there some way I can bake this into the target so that users aren't required to pass this additional configuration each time they compile a specific target?. @kageiit So that is currently how I am getting around the issue. But this is only when they invoke the target directly and I know that target should be using a different SDK version.\nOn CI we run ./buckw test --include unit which crosses the target boundaries and needs to compile different SDK versions depending on the current target it runs. This is the particular case I am most interested in solving and didn't see an easy way to modify the buck wrapper to help solve that. Any ideas?. Yeah that was going to be my other work around :). cc @cjhopman - Perhaps you could provide more context? Am I missing something that I need to do with that new change?. @kageiit The test APK build doesn't fail, it just never builds the main APK. The same exception occurs on: https://travis-ci.org/uber/okbuck/builds/274047893?utm_source=github_status&utm_medium=notification but I'm not sure if it is the same root cause.. @kageiit The test APK build doesn't fail, it just never builds the main APK. The same exception occurs on: https://travis-ci.org/uber/okbuck/builds/274047893?utm_source=github_status&utm_medium=notification but I'm not sure if it is the same root cause.. This has been blocking us from using the latest buck changes since that commit is now the foundation for later commits and I cannot revert it. We have a custom wrapper that we can use to get around it but would prefer if we could continue to use the test command.. Confirmed cfdefd2 fixes this issue.. Confirmed cfdefd2 fixes this issue.. I actually expected this to fail the test AndroidLibraryIntegrationTest#testAndroidKotlinLibraryExtraArgumentsCompilation because the previous version did not have support for -Xplugin args.. I'll get the test to pass. But are there any changes I can make to get the tests to run in appveyor?. @dsyang You were right about kotlin-reflect.jar. I also had to add kotlin-stdlib.jar.. @dsyang You were right about kotlin-reflect.jar. I also had to add kotlin-stdlib.jar.. Great, thanks for the quick response.. @styurin - Any update here?. @styurin sounds good, thanks for the update.. Any status update on this?. My particular case is on our CI Infrastructure which is running NO_BUCKD=1 so the buck daemon should not be active.. Awesome, thanks @timmych.. Awesome, thanks @timmych.. As was mentioned here: https://github.com/uber/okbuck/issues/651 data-binding is not supported in OkBuck nor is it supported in Buck as far as I am aware. @thalescm might be able to answer to what would be required to support this (assuming I am correct that it isn't supported today).\nI do believe you can use Kotlin Android Extensions as an alternative, which is talked about here. Kotlin Android Extensions is supported by both OkBuck and Buck.\nDepending on how complex it is to set up data binding, it may be simple to enable it using extra_kotlinc_arguments.. @thalescm but it seems difficult to determine that? Because you may be generating java code via kapt. I'm not sure if there is a way to dynamically include something as part of the rule key.. Kotlin library already has extra_arguments which pass arguments to the kotlin compiler. Android library is different since it invokes two compilers.. Done.. I thought about that as well but I realized that it actually needs the set to provide only the java source files to the java compiler. Kolinc actually needs both sets of source files so we didn't need a set of only kotlin files.. Yep, I'll update it.. Yep, I'll move it.. Good suggestion.. Currently it is required when building with JDK 7 or JDK 8. \nAccording to https://docs.oracle.com/javase/9/migrate/toc.htm#JSMIG-GUID-A78CC891-701D-4549-AA4E-B8DD90228B4B the tools jar may be instead replaced by a \"more efficient format in implementation-specific files in the lib directory.\" so we could potentially depend on whatever in tools.jar kapt requires when building with JDK 9.\nI can change the implementation for now to allow users to specify the location. But I'll keep digging to see what kapt in Gradle will do when building with JDK 9 if it is supported yet.. nit: extra indent. Be sure to document this in the rules. E.g. docs/rule/android_library.soy. A test src.zip file would be nice as a reference that this is possible. Also helps ensure it never breaks.. Was this intentional? Seems that you want this as part of your kapt_apoptions. ",
    "BharathMG": "Hi, Is there any progress in this feature? Currently, this is the only thing holding us back from using \nbuck in our android projects. . @cwoodwar6 Thanks for the update! . ",
    "thalescm": "Hey folks, any news on this thread? Setting up buck in my company, but this is a blocker as of now, if I can do anything to help :). Hey folks, any news on this thread? Setting up buck in my company, but this is a blocker as of now, if I can do anything to help :). Yeah, I've just forked buck and I'm reading the PR, getting the changes and stuff and will try to see if I get it working :D\nI'll let you know if I get to anything before @cwoodwar6 does. Yeah, I've just forked buck and I'm reading the PR, getting the changes and stuff and will try to see if I get it working :D\nI'll let you know if I get to anything before @cwoodwar6 does. If you guys can take a look on #1584. It should work now :). Finally merged, I think it's safe to close the issue now. Please test it folks :). #1584 should fix it. @runningcode by gradle directory structure you mean having src/main/(kotlin|java) before the actual package? If so, I could compile only with command line args (no gradle involved) a structure different than gradle's default one (you can see here).\nThe compiler not liking it different doesn't make sense, as buck build ... (by removing the .fixture) works and buck test ... don't (as you said). What makes you think that?  \n@dsyang did you have time to check on this again?. @runningcode by gradle directory structure you mean having src/main/(kotlin|java) before the actual package? If so, I could compile only with command line args (no gradle involved) a structure different than gradle's default one (you can see here).\nThe compiler not liking it different doesn't make sense, as buck build ... (by removing the .fixture) works and buck test ... don't (as you said). What makes you think that?  \n@dsyang did you have time to check on this again?. Well, I've talked a lot with @yanex about how kapt works and what does it need / the options, plugins and etc...\nIt is possible to to use kapt with java 9, though now JRE will warn about reflection access of JDK private declarations.\nWith this in mind, and considering the comments of @kageiit and @jkeljo, I was thinking about the following points:\nAs @runningcode pointed out (and @yanex confirmed), that are four steps:\n1. Generate sutbs\n2. Run apt\n3. CompileKotlin\n4. CompileJava\nToday's kotlin rule already does the steps 3 and 4.\nSo we could make a custom rule, called kotlin-annotation-processor which would be responsible for the steps 1 and 2. \nThis rule would give you all the options you need to get kapt to work properly, for example, as tools.jar is a plugin, and the ap jar is a plugin as well, you would have an array of plugins (then on Java9, you simply don't pass the tools.jar), and you could stablish the output for the generated sources, which is basically an entry called kapt.kotlin.generated with the value as the desired path on the apoptions plugin parameter.\nAnd them on the kotlin rule you set that path as one of the sources to look at.   \nI talked to @cwoodwar6 and he agreed with the changes, WDYT?. Well, I've talked a lot with @yanex about how kapt works and what does it need / the options, plugins and etc...\nIt is possible to to use kapt with java 9, though now JRE will warn about reflection access of JDK private declarations.\nWith this in mind, and considering the comments of @kageiit and @jkeljo, I was thinking about the following points:\nAs @runningcode pointed out (and @yanex confirmed), that are four steps:\n1. Generate sutbs\n2. Run apt\n3. CompileKotlin\n4. CompileJava\nToday's kotlin rule already does the steps 3 and 4.\nSo we could make a custom rule, called kotlin-annotation-processor which would be responsible for the steps 1 and 2. \nThis rule would give you all the options you need to get kapt to work properly, for example, as tools.jar is a plugin, and the ap jar is a plugin as well, you would have an array of plugins (then on Java9, you simply don't pass the tools.jar), and you could stablish the output for the generated sources, which is basically an entry called kapt.kotlin.generated with the value as the desired path on the apoptions plugin parameter.\nAnd them on the kotlin rule you set that path as one of the sources to look at.   \nI talked to @cwoodwar6 and he agreed with the changes, WDYT?. @brettwooldridge does this mean that this implementation break this current behavior of kotlin_library rule? Or is just something you'd want to see on kapt?. Would someone be able to take a look in this PR?. @jkeljo I strongly agree with the proposed changes.\nAbout the rules, today java's AP is not a rule itself either. Though that shouldn't be an argument to not make the best of the way kotlin works, and as kotlin requires more than one call to kotlinc to make apt work when javac doesn't, I've preferred to do this way cause it was the way the PR started, so it was way more intuitive than doing from scratch.\nIf facebook core team decide it's best to do your proposed way, I can probably take a look in the future, but as this works for me right now, I probably won't have work time to allocate on that, so it would be slower.\nAbout the locally scoped requested changes, I'll try to clean them by tomorrow :) \nTks for the review. If you guys can take another look now :). @styurin :done:. Huuum, added the pre commit phase, it apparently didn't change anything. @styurin do you know which files were it complaining? I didn't find any that wasn't on the format. Actually if you check the changes, none of them involved any indentation or spacing in source files. The formatting problem seems unrelated to the changes of this PR.\nBut if there are, if you could point them out it would be a pleasure to fix.. @styurin think I found it (should be fixed in this last commit) \u261d\ufe0f \n. @styurin anything else I need to change?. @joelmccall rebased :). @joelmccall fixed the erros on Travis. Could you take another look? Tks!. @styurin done; Can you check if this is the expected format for the README files?. @styurin implemented the requested changes :). @styurin Rebased. @styurin can you check if 9d7aeed should suffice? . Hi @styurin, any updates here?. @jtorkkola could you take another look?. @jtorkkola any news on the import?. @jtorkkola should be ready now :). @jtorkkola seems like windows tests concerning the changes affected by this PR are fine. @styurin could you please take another look?. @styurin any news on the import?. Did it before opining the PR and all seems to be correct. Test failure seems unrelated. CI error seems unrelated.. I've found a mention, and explains where tools.jar is used on kapt here. I really don't know, the compiler expects tools.jar as a plugin, and use it internally. I'll have to see if there is a way to provide this ClassLoader directly.. My point is, kapt won't run if it doesn't find com.sun.tools.javac.util.Context package. So I need to pass it on the plugin classpath, how will ToolProvider.getSystemToolClassLoader enable me to do that?. I'll wait for his response, then. Tks!. But my point here is that this could be a location to store matchers for any kind of file, not only jvms.\nIf this should be moved to jvm package, I'd say best is to separate into two classes, both inside their on language package, JavaPathMatcher and KotlinPathMatcher. Do you think that wrapping this inside a synchronized (ToolProvider.class) { ... } as JdkProvidedInMemoryJavac does is enough?. It actually does, instigating people to use most recent versions is very good. 1.1.1 is very outdated already :). It's a plugin I have on my IDEA, probably other people have it also, I didn't see any damage on adding this and thus not needing to keep filtering which files to stage. I'll check on how that works and change, tks for the tip!. I've tested a lot, and the , are to keep passing more options together instead of having to provide -P in each of them. I didn't get exactly what do you mean, could you explain better, @dmitry-zaitsev ?. Done \ud83d\udc4d . This change was requested from @jkeljo in order to get this PR done. There was no reason for this class prior to the changes related to this PR. \u2702\ufe0f ?. \u2702\ufe0f ?. None of the other options that are passed to the compiler are constants, I thought of letting the logic remains at is cause it would be strange to add constant for this and not for the others.\nAnd refactoring everything to use constants would only increase the size of this PR with non related to this feature changes. classpath is only used on the two places where there were changes in it. Also there are tests covering the scenarios. But in the end you're right, I'll add it as a constant. This method (getClasspath) is already in ResolvedJavacPluginProperties.\nIf you mean to make a static method which receives a list of properties to join all classpaths, I think it's a good idea \ud83d\udc4d . Not sure there are good prior examples to point to, as no ConfiguredCompilerFactory have tests :( \nYou could add integration tests on KotlinLibraryIntegrationTest.java to see if arguments are working as expected.\nJust contextualising, AFAIK, kotlin features were mainly done by the community, and normally by people (like me when doing kapt features) that did not have a great understanding of how the whole project work, how to get good fakes, what test utils are available and so on. This resulted in it having mainly only integration tests as unit tests were hard.\nOf course this is not an excuse not to make those tests now, just pointing out why it's gonna be hard to find some good prior examples. If feels weird to me to have two places deciding what should go on extra arguments, should we move those two options to KotlinConfiguredCompiler too?\nWhat I mean is that scattering this will make it hard to maintain, as people will not intuitively know that more than one place adds options to this.. Also, the condenseCompilerArguments would remove duplicates for this if user also added them :). I think it was me (or @cwoodwar6 ) who added them in order to get kapt to work. This was actually a copy paste from what gradle outputs when doing the same.\nAlso, could you also remove them from here and here when adding them to KotlinConfiguredCompilerFactory?. I'll change the previous comment to be processorpath instead of classpath. But the logic of providing an empty classpath (if none was defined) was already present in buck.. This was already the implemented way in buck in case no classpath was found. Will change, thanks!. Fixing the tests as the rule type changed. \"Bazel's java_plugin defines plugins for the Java compiler run by Bazel. At the moment, the only supported kind of plugins are annotation processors.\"\nBuck is already different as we have java_annotation_processor rule, also with fields that are very different from bazel's java_plugin rule.\nBazel's java_plugin rule accepts srcs and a bunch of other things that just couples it to a java_library rule instead of only defining it as a javac plugin, as buck does with java_annotation_processor and now java_plugin.\nThis way the API is decoupled from existing code while serving the same purpose.\nAlso, the idea in separating java_plugin from java_annotation_processor is that they are different, for example, it's common to have many processors in a single annotation processor, but not on plugins.\nThe JavacTask provides an API to accept processors, but not plugins, etc...\nSo decoupling them makes sense as they are not the same.. Tests fail if this is not done. I'll try to refactor to not need this \ud83d\udc4d . The JavaAnnotationProcessor BuildRule name changed for JavaAnnotationProcessorPlugin to conform with the names (easy to know that it is a plugin after all).\nThis test is coupled with the name of the build rule. I see, let me know what you guys think it's best. IMO both names are good enough.. @styurin right. I don't think so. There would have to have a big refactor in order to the rest of the ecosystem to understand this. As far as I saw, this was implemented as JavacPluginProperties (and not JavaAnnotationProcessorProperties) since the beginning waiting for when javac plugins were implemented as well.. All right, it will not make much sense on the perspective of code maintenance, but sure, I can change it. \ud83d\ude1e Couldn't this be told earlier also? \nWhy not setting up a pre-commit hook that will run GJF and Buildifier?. I was checking, BUCK inside buck src are not formatted with Buildifier... (you can check all the changes that would appear if running find . -type f -name BUCK | xargs buildifier -mode=build).\nSo i only will commit the files on the BUCK.fixture ones.... Added a check for that, tks :). ",
    "illicitonion": "Merged in 52aa3cd74a68eb344a68c0e150d0aae334916cc1. Throw in a check in PublisherIntegrationTest#testPublishFiles that we get the .asc and I'm happy.. Wherever you want in your repo, and use include_defs (https://buckbuild.com/function/include_defs.html) to include them. At Facebook we tend to use files named DEFS or BUILD_DEFS.. Aha. You need to set the preprocessor_flags attribute on your rules, e.g. https://buckbuild.com/rule/apple_library.html#preprocessor_flags. Ugh. I've got a fix in review internally which actually makes your buck project call work :) Apologies for the half-fix!. @marcinkosiba you changed test filtering a while ago.... Actually include the stdout/stderr here.. Instead of using System.getenv() here, please pass it down through the chain of functions all the way from Main.runMainWithExitCode's clientEnvironment (yeah, it's a long way :()\nI would possibly also be tempted to just pass down {PATH: \"...\"} rather than the whole environment map to be explicit about what's being used.. Rather than a static initialiser, let's look up these paths inside build. Specifically, these are platform-specific, and not all of them need to exist on all platforms, so let's not try to look then up if we're not going to use them.. Can you switch this back to equality, but do the ExecutableFinder lookup again?. Why not just make SwiftBuckConfig#getFlags always just return a (maybe empty) ImmutableList?\nThen I'd slightly prefer this to look like:\njava\nthis.compilerFlags = new ImmutableList.Builder<String>()\n    .addAll(swiftBuckConfig.getFlags())\n    .addAll(compilerFlags)\n    .build();\nor something along those lines.. This is missing the assert that the .asc file was actually PUT?. Actually assert on this random boolean value that you're just computing? :). Can you remove the comment?. I've just send out a change which uses Futures.addCallback rather than Futures.transform, which means this dummy consumer won't be required. (Using the correct API feels nicer than trying to trick the compiler). Please revert the changes to this file.. This change actively breaks this test because targetGraph.getAll is lazy. I have just sent out a change to instead iterate over the values and toString() them. Please revert this bit of the change.. I've sent out a change fixing this in a way which actually fixes the test. Please revert this bit of the change.. assertThat(filenames, Matchers.contains(\nwould give a nicer error message, but what you've got here is definitely an improvement on the status quo so I'd also accept it as-is if you can't be bothered :). Could you make this an ImmutableMap?\n```\ntypeColors = new ImmutableMap.Builder() {{\n  put(\"android_aar\", \"springgreen2\");\n  put(\"android_library\", \"springgreen3\");\n  ...\n}}.build(). For the future, we have RichStream#filter for this:\njava\nRichStream.from(getDeclaredDeps())\n  .filter(NativeLinkable.class)\n  .collect(MoreCollectors.toImmutableSet());\nRichStream also allows you to cleanly stream on Iterables.\nIt's definitely not obviously better, or cleaner, and I'm not going to ask you to use it, but it may be useful to know in the future :). This one would be cleaner as:\nRichStream.from(exportedDeps)\n  .filter(NativeLinkable.class)\n  .concat(RichStream.of(new SwiftRuntimeNativeLinkable...))\n  .collect(MoreCollectors.toImmutableSet());. RichStream.concat. ",
    "anoever": "I have the same issue here. Running the build a few times seems to fix this issue. I have seen that\nunzip /Users/.../buck-out/gen/root/appcompat-v7_aar/appcompat-v7-23.1.1.aar -d /Users/.../buck-out/bin/root/__unpack_appcompat-v7#aar_unzip__\nruns after the cp -R task which seems to be an ordering issue. Once the unzip task has run the next build succeeds.\n. I have the same issue here. Running the build a few times seems to fix this issue. I have seen that\nunzip /Users/.../buck-out/gen/root/appcompat-v7_aar/appcompat-v7-23.1.1.aar -d /Users/.../buck-out/bin/root/__unpack_appcompat-v7#aar_unzip__\nruns after the cp -R task which seems to be an ordering issue. Once the unzip task has run the next build succeeds.\n. Interestingly this was fixed by buck clean   (but not by rm -rf buck-out/). Thanks for the explanation.\n\npy3 is not a flavor. The interpreter used is based purely on the platform attribute of the binary/test rule.\n\nhttps://buckbuild.com/concept/buckconfig.html#python should probably be updated then.\n\nIn case anyone else experiments with python3: Setting python.interpreter to a python 3 binary makes BUCK file parsing fail (ModuleNotFoundError: No module named '__builtin__'). Additionally setting parser.python_interpreter to python 2 makes parsing work, but building pex packages still fails (make_pex.py is executed with with python.interpreter).\n-> If you want to use python 3 add a separate [python#py3] section and a platform attribute on every python_binary/test rule.\n. ",
    "paulcavallaro": "@sdwilsh Hit the nail on the head with your guess!\n\u279c  ptcc git:(master) \u2717 cat .buckversion\nv2016.09.26.01%\nChanging .buckversion to the hash seems to work just fine\n\u279c  ptcc git:(master) \u2717 cat .buckversion\n3707455808970f02055502b82819a3df2cab392a%\n\u279c  ptcc git:(master) \u2717 buck --version\nbuck version 3707455808970f02055502b82819a3df2cab392a\n\u279c  ptcc git:(master) \u2717\nFeel free to close, but seems like this should be fixed somewhere no? Thanks for the help either way.\n. So doing some more digging I discovered macros and defining your own rules. Now I have something like:\n```\ndef multiplatform_python_library(name,\n                                 deps=[],\n                                 os_platform_deps=[],\n                                 kwargs):\n    import distutils.util\n    import re\n    platform = distutils.util.get_platform().replace('-', '').replace('.', '')\n    for (regex, os_deps) in os_platform_deps:\n        if re.match(regex, platform):\n            return python_library(\n                name=name,\n                deps=deps + os_deps,\n                kwargs)\nusage:\nprebuilt_python_library(\n    name='faulthandler-cp27-none-macosx_10_10_x86_64',\n    binary_src='faulthandler-2.4-cp27-none-macosx_10_10_x86_64.whl',\n    deps=[],\n)\nmultiplatform_python_library(\n    name='faulthandler',\n    os_platform_deps=[\n        ('macosx_10_10', [':faulthandler-cp27-none-macosx_10_10_x86_64']),\n    ],\n    visibility=[\n        'PUBLIC',\n    ],\n)\n```\nWondering if this seems reasonable, and if other people have tried this and run into problems. My main concern is that this way isn't really supported, and not sure if it's the correct approach.\nIt might be nice to build into buck something similar to pant's python_requirement_library (http://www.pantsbuild.org/build_dictionary.html) for installing libraries from pypi. The downside is that the builds are no longer quite so hermetic, and BUCK doesn't know the full build graph, and would have to understand python packaging as well.\nAny thoughts?. @Coneko May I ask what the suggested alternative is? What do people at FB use for generating fbthrift libraries?. @Coneko May I ask what the suggested alternative is? What do people at FB use for generating fbthrift libraries?. ",
    "korniltsev": "rebased\n. rebased\n. Yes I did. \u279c  buck git:(stacktraces) git push -f korniltsev\nEverything up-to-date\nMy branch merges with master with no conflicts.\n. Yes I did. \u279c  buck git:(stacktraces) git push -f korniltsev\nEverything up-to-date\nMy branch merges with master with no conflicts.\n. Rebased again, on fresh master (25e90b5)\n. Rebased again, on fresh master (25e90b5)\n. These jars are from intellij 2016.2.1\n. Btw, could you please take a look at comments that I've left here on github. \n. To be honest I don't really like my idea of relying on warning message in the console. We should probably introduce new bus event, something like JVMIsWaitingForDebuggerEvent and handle it in ws client. If we agree on this I can fix it.\n. Replaced Runnable with lambdas\n. Replaced Runnable with lambdas\n. ",
    "seanabraham": "Yup, will close now. For future readers (especially those also using okbuck), this was resolved via: https://github.com/uber/okbuck/pull/239 and https://github.com/uber/okbuck/pull/241\n. @dsyang back yet by chance?. Any word on this? @dreiss would you be the right person to review / merge it?. ",
    "plamenko": "Also, advantage of JSON over some binary format is that it is more or less human readable. As @dreiss  said, we should avoid doing any microoptimizations unless it's a real issue.\n. Also, advantage of JSON over some binary format is that it is more or less human readable. As @dreiss  said, we should avoid doing any microoptimizations unless it's a real issue.\n. ",
    "elucash": "Sorry if the report might be misguiding,\nbut I did nothing to formula, just have run brew upgrade and got the error\nDownload failed: https://github.com/facebook/buck/releases/download/v2016.11.11.01/buck-2016.11.11.01.yosemite.bottle.tar.gz\nliterally, there was no such file, buck-2016.11.11.01.yosemite.bottle.tar.gz\nthe formula has such code, of course\nbottle do\n    root_url \"https://github.com/facebook/buck/releases/download/v#{@@buck_version}\"\n    cellar :any_skip_relocation\n    sha256 \"d8ea7fd04d45e9d2ec63feaaee26fd0093ff6ccbc995672f179d86ae091d5bb9\" => :yosemite_or_later\n  end\nBut, despite this, on my osx 10.11.6 it looks for buck-2016.11.11.01.yosemite.bottle.tar.gz. I would suggest that :yosemite_or_later doesn't always do what it \"should\"\n. As it's still possible to build Buck from sources using brew install buck (not using bottle), feel free to close this report\n. @k21 thank you! I was able to install using bottle\n. @k21 thank you! I was able to install using bottle\n. Ok, made thread dump, figured out it was InetAddress.getLocalhost() then found out the solution https://thoeni.io/post/macos-sierra-java/ and https://stackoverflow.com/questions/33289695/inetaddress-getlocalhost-slow-to-run-30-seconds\nSorry for disturbing, but in case someone else face it, it may also found it here. Thank you!. ",
    "jauco": "I looked into the code, and the problem seems to be that it does not parse the mvn coords as they are usually written. The coords spec as given in several places is groupId:artifactId[:extension[:classifier]]:version valid coords are \norg.codehaus.groovy:groovy-groovysh:2.4.1\norg.codehaus.groovy:groovy-groovysh:jar:2.4.1\norg.codehaus.groovy:groovy-groovysh:jar:indy:2.4.1\nbut not\norg.codehaus.groovy:groovy-groovysh:indy:2.4.1\nThe maven coords as parsed by MavenUrlDecoder are a bit different. Parsing the regex back we get: [server:]groupId:artifactId:extension:version i.e. extension is not optional, classifier is not allowed and server is allowed to have colons in it (presumable to allow something like https://example.org:org.example:something:jar:1.0.0)\nI don't think that regex can be made to work with an optional classifier attribute while also allowing colons in the server part. So at least the javadocs at https://buckbuild.com/javadoc/com/facebook/buck/file/MavenUrlDecoder.html should be fixed. I'd prefer it if maven classifiers where also supported, but I can't think of a backwards compatible way to do so. \nI guess a workaround would be to do the translation myself and simply pass a http url.\nCould you verify my reasoning?\n. I looked into the code, and the problem seems to be that it does not parse the mvn coords as they are usually written. The coords spec as given in several places is groupId:artifactId[:extension[:classifier]]:version valid coords are \norg.codehaus.groovy:groovy-groovysh:2.4.1\norg.codehaus.groovy:groovy-groovysh:jar:2.4.1\norg.codehaus.groovy:groovy-groovysh:jar:indy:2.4.1\nbut not\norg.codehaus.groovy:groovy-groovysh:indy:2.4.1\nThe maven coords as parsed by MavenUrlDecoder are a bit different. Parsing the regex back we get: [server:]groupId:artifactId:extension:version i.e. extension is not optional, classifier is not allowed and server is allowed to have colons in it (presumable to allow something like https://example.org:org.example:something:jar:1.0.0)\nI don't think that regex can be made to work with an optional classifier attribute while also allowing colons in the server part. So at least the javadocs at https://buckbuild.com/javadoc/com/facebook/buck/file/MavenUrlDecoder.html should be fixed. I'd prefer it if maven classifiers where also supported, but I can't think of a backwards compatible way to do so. \nI guess a workaround would be to do the translation myself and simply pass a http url.\nCould you verify my reasoning?\n. Could someone verify my reasoning? If I'm correct I can make a small PR that fixes the documentation and suggests to use http urls as a workaround (it's what I'm doing right now. This bug is not blocking me). Could someone verify my reasoning? If I'm correct I can make a small PR that fixes the documentation and suggests to use http urls as a workaround (it's what I'm doing right now. This bug is not blocking me). I'll get to it tomorrow morning.\n\nJauco\nOp ma 14 nov. 2016 om 18:30 schreef Shawn Wilsher notifications@github.com\n\nCould you provide an example? I would expect that to invalidate things,\nso having a reproducible example would help figure out if there's a bug\nin a specific rule or possibly something else.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1015#issuecomment-260402392, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAEK3gVWXuh2smQsZkjer_TBZhilcXTVks5q-Jq6gaJpZM4KxT-R\n.\n. I'll get to it tomorrow morning.\n\n\nJauco\nOp ma 14 nov. 2016 om 18:30 schreef Shawn Wilsher notifications@github.com\n\nCould you provide an example? I would expect that to invalidate things,\nso having a reproducible example would help figure out if there's a bug\nin a specific rule or possibly something else.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1015#issuecomment-260402392, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAEK3gVWXuh2smQsZkjer_TBZhilcXTVks5q-Jq6gaJpZM4KxT-R\n.\n. I've pushed to the branch buck-issue of https://github.com/huygensING/timbuctoo with a repo that you should be able to use to reproduce the problem.\n\nA transcript of how I triggered it is below:\n\u250c\u2500[\u00b1][BUCK \u2713][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa buck fetch timbuctoo-instancev4 && buck build timbuctoo-instancev4\n[-] PROCESSING BUCK FILES...FINISHED 0.6s [100%]\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 44.3s [100%] (1/1 JOBS, 1 UPDATED, 1 [100.0%] CACHE MISS)\n[-] PROCESSING BUCK FILES...FINISHED 0.1s\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 46.9s [100%] (451/451 JOBS, 450 UPDATED, 450 [99.8%] CACHE MISS)\n\u250c\u2500[\u00b1][BUCK \u2713][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa vim timbuctoo-instancev4/BUCK\n\u250c\u2500[\u00b1][BUCK U:1 \u2717][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa git diff\ndiff --git a/timbuctoo-instancev4/BUCK b/timbuctoo-instancev4/BUCK\nindex 69cd8ff..7709aaa 100644\n--- a/timbuctoo-instancev4/BUCK\n+++ b/timbuctoo-instancev4/BUCK\n@@ -18,7 +18,6 @@ java_library(\n     \"//third-party/neo4j:neo4j-tinkerpop-api\",\n     \"//third-party/poi:poi-ooxml-schemas\",\n     \"//third-party/commons-configuration:commons-configuration\",\n-    \"//third-party/xmlbeans:xmlbeans\",\n     \"//third-party/commons:commons-lang3\",\n     \"//third-party/commons-lang:commons-lang\",\n     \"//third-party/core:jersey-server\",\n@@ -65,4 +64,4 @@ java_library(\n     \"//third-party/tinkerpop:neo4j-gremlin\",\n     \"//third-party/xml-apis:xml-apis\"\n   ]\n-)\n\\ No newline at end of file\n+)\n\u250c\u2500[\u00b1][BUCK U:1 \u2717][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa buck build timbuctoo-instancev4\n[-] PROCESSING BUCK FILES...FINISHED 0.1s [100%] \ud83d\udc0c  File removed\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 0.7s [100%] (397/397 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\nSo that's what was unexpected. To show that the build ought to fail I'll remove the buck-out and do a rebuild\n```\n\u250c\u2500[\u00b1][BUCK U:1 \u2717][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa rm -r buck-out/\n\u250c\u2500[\u00b1][BUCK U:1 \u2717][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa buck fetch timbuctoo-instancev4 && buck build timbuctoo-instancev4\n[-] PROCESSING BUCK FILES...FINISHED 0.0s\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 39.2s [100%] (1/1 JOBS, 1 UPDATED, 1 [100.0%] CACHE MISS)\n[-] PROCESSING BUCK FILES...FINISHED 0.1s \ud83d\udc07\n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...24.6s [99%] (450/451 JOBS, 168 UPDATED, 168 [37.3%] CACHE MISS)\n |=> //timbuctoo-instancev4:timbuctoo-instancev4...  8.9s (running javac[8.8s])\n |=> IDLE\n |=> IDLE\n |=> IDLE\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/database/dto/dataset/VresDto.java:14: mandatory_warning: Avoid introduction of fields (except constants) in abstract value types\n  private Map collectionsByName;\n                                  ^\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/database/dto/dataset/VresDto.java:15: mandatory_warning: Avoid introduction of fields (except constants) in abstract value types\n  private Map collectionsByType;\n                                  ^\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/bulkupload/loaders/excel/styleawarexlsxloader/StylesMapper.java:28: error: cannot access org.apache.xmlbeans.XmlObject\n    final NodeList styleNodes = styles.getCTStylesheet().getDomNode().getChildNodes();\n                                                        ^\n  class file for org.apache.xmlbeans.XmlObject not found\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/server/TinkerpopGraphManager.java:-1: note: Some input files use or override a deprecated API.\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/server/TinkerpopGraphManager.java:-1: note: Recompile with -Xlint:deprecation for details.\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/bulkupload/savers/TinkerpopSaver.java:-1: note: Some input files use unchecked or unsafe operations.\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/bulkupload/savers/TinkerpopSaver.java:-1: note: Recompile with -Xlint:unchecked for details.\nErrors: 1. Warnings: 2.\nRule //timbuctoo-instancev4:timbuctoo-instancev4 has failed to build.\norg.apache.xmlbeans.XmlObject\nTry adding the following deps:\n//third-party/xmlbeans:xmlbeans\n```\n. I've pushed to the branch buck-issue of https://github.com/huygensING/timbuctoo with a repo that you should be able to use to reproduce the problem.\nA transcript of how I triggered it is below:\n\u250c\u2500[\u00b1][BUCK \u2713][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa buck fetch timbuctoo-instancev4 && buck build timbuctoo-instancev4\n[-] PROCESSING BUCK FILES...FINISHED 0.6s [100%]\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 44.3s [100%] (1/1 JOBS, 1 UPDATED, 1 [100.0%] CACHE MISS)\n[-] PROCESSING BUCK FILES...FINISHED 0.1s\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 46.9s [100%] (451/451 JOBS, 450 UPDATED, 450 [99.8%] CACHE MISS)\n\u250c\u2500[\u00b1][BUCK \u2713][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa vim timbuctoo-instancev4/BUCK\n\u250c\u2500[\u00b1][BUCK U:1 \u2717][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa git diff\ndiff --git a/timbuctoo-instancev4/BUCK b/timbuctoo-instancev4/BUCK\nindex 69cd8ff..7709aaa 100644\n--- a/timbuctoo-instancev4/BUCK\n+++ b/timbuctoo-instancev4/BUCK\n@@ -18,7 +18,6 @@ java_library(\n     \"//third-party/neo4j:neo4j-tinkerpop-api\",\n     \"//third-party/poi:poi-ooxml-schemas\",\n     \"//third-party/commons-configuration:commons-configuration\",\n-    \"//third-party/xmlbeans:xmlbeans\",\n     \"//third-party/commons:commons-lang3\",\n     \"//third-party/commons-lang:commons-lang\",\n     \"//third-party/core:jersey-server\",\n@@ -65,4 +64,4 @@ java_library(\n     \"//third-party/tinkerpop:neo4j-gremlin\",\n     \"//third-party/xml-apis:xml-apis\"\n   ]\n-)\n\\ No newline at end of file\n+)\n\u250c\u2500[\u00b1][BUCK U:1 \u2717][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa buck build timbuctoo-instancev4\n[-] PROCESSING BUCK FILES...FINISHED 0.1s [100%] \ud83d\udc0c  File removed\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 0.7s [100%] (397/397 JOBS, 0 UPDATED, 0 [0.0%] CACHE MISS)\nSo that's what was unexpected. To show that the build ought to fail I'll remove the buck-out and do a rebuild\n```\n\u250c\u2500[\u00b1][BUCK U:1 \u2717][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa rm -r buck-out/\n\u250c\u2500[\u00b1][BUCK U:1 \u2717][timbuctoo-buck-issue][]\n\u2514\u2500\u25aa buck fetch timbuctoo-instancev4 && buck build timbuctoo-instancev4\n[-] PROCESSING BUCK FILES...FINISHED 0.0s\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 39.2s [100%] (1/1 JOBS, 1 UPDATED, 1 [100.0%] CACHE MISS)\n[-] PROCESSING BUCK FILES...FINISHED 0.1s \ud83d\udc07\n[+] DOWNLOADING... (0.00 B/S, TOTAL: 0.00 B, 0 Artifacts)\n[+] BUILDING...24.6s [99%] (450/451 JOBS, 168 UPDATED, 168 [37.3%] CACHE MISS)\n |=> //timbuctoo-instancev4:timbuctoo-instancev4...  8.9s (running javac[8.8s])\n |=> IDLE\n |=> IDLE\n |=> IDLE\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/database/dto/dataset/VresDto.java:14: mandatory_warning: Avoid introduction of fields (except constants) in abstract value types\n  private Map collectionsByName;\n                                  ^\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/database/dto/dataset/VresDto.java:15: mandatory_warning: Avoid introduction of fields (except constants) in abstract value types\n  private Map collectionsByType;\n                                  ^\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/bulkupload/loaders/excel/styleawarexlsxloader/StylesMapper.java:28: error: cannot access org.apache.xmlbeans.XmlObject\n    final NodeList styleNodes = styles.getCTStylesheet().getDomNode().getChildNodes();\n                                                        ^\n  class file for org.apache.xmlbeans.XmlObject not found\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/server/TinkerpopGraphManager.java:-1: note: Some input files use or override a deprecated API.\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/server/TinkerpopGraphManager.java:-1: note: Recompile with -Xlint:deprecation for details.\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/bulkupload/savers/TinkerpopSaver.java:-1: note: Some input files use unchecked or unsafe operations.\n/Users/jauco/Documents/timbuctoo-buck-issue/timbuctoo-instancev4/src/main/java/nl/knaw/huygens/timbuctoo/bulkupload/savers/TinkerpopSaver.java:-1: note: Recompile with -Xlint:unchecked for details.\nErrors: 1. Warnings: 2.\nRule //timbuctoo-instancev4:timbuctoo-instancev4 has failed to build.\norg.apache.xmlbeans.XmlObject\nTry adding the following deps:\n//third-party/xmlbeans:xmlbeans\n```\n. I'd like to remove this branch from my repository. I ended up not using buck. Do you want me to keep it around?. ",
    "demon": "Hit this as well. As mentioned, the easy workaround is install coreutils from homebrew, it provides realpath.\nHowever, rewriting in python would make it more platform-agnostic here I think.\n. Hit this as well. As mentioned, the easy workaround is install coreutils from homebrew, it provides realpath.\nHowever, rewriting in python would make it more platform-agnostic here I think.\n. ",
    "gastoncesarf": "@marcinkwiatkowski sorry for my question (in the case that is possible) I need to know an approximate date for this. Can you estimate this? Thanks.. ",
    "ligee": "@brettwooldridge CompilerId is used to search compatible running daemons. And this is most likely has nothing to do with the issues you're having.\nThere is one known racing condition which is usually marked with \"Daemon is dying\" message in the reportingTargets. It happens when several daemons are started in parallel, and then they are making internal elections to limit the number of compatible daemon processes in the memory.\nYou can use the new (since 1.1.1) atomic connectAndLease function that should not fail in these cases. The price will be that the parallelly started compatible daemons will all stay in memory until the appropriate sessions are released (use releaseSession for that.)\nOr use your workaround, it is, in fact, ok for now.\nPlease note that the compiler and daemon APIs are not yet stable and/or complete. We are working on bringing it to the supportable state, but we're not there yet.. @brettwooldridge There are two main \"hooks\" to the daemon lifetime. \nThe first is the clientAliveFlagFile  that you pass to the connect functions. When the file is deleted, the daemon stops. You can use it to ensure that daemon will be stopped when the buckd process is stopped. (I'm usually calling deleteOnExit on this file) But the daemon can exit earlier if some timeout occurs, e.g. by default if there are no compilations happen within 2 hours.\nThe second is the leased sessions. The daemon will not exit on the timeouts while there are leased sessions. But I wouldn't recommend keeping a session open all the time. To my mind, the more economical solution would be to call connectAndLease each time you need a compilation (or maybe several ones in a row).\nThe compilations can be run in parallel on the single daemon instance if required compilerId (thus - compiler jar basically) is the same. There is right now no control on a number of the compilations that can run in parallel. The only way to do it now is to do it is to implement management on your side, and if required run a fresh daemon by specifying different discovery directory (DaemonOptions.runFilesPath).. ",
    "ddevault": "NO_BUCKD will do the trick, thanks! As for why, I want the builds to be self contained and scripted. I don't like the idea of a process forking during the build. In fact the build is broken in my fakeroot build environment, NO_BUCKD will probably fix that.. ",
    "androidhuoniao": "thanks for your reply,i chaned the file encoding to utf-8, errors gone. thanks for your reply,i chaned the file encoding to utf-8, errors gone. I find a solution, set Xmx3g, everything will be ok. I find a solution, set Xmx3g, everything will be ok. ",
    "justinmuller": "@styurin I've introduced IjProjectTest\nI had to extract a @VisibleForTesting method, IjProject#createModuleFactoryResolver(ImmutableSet.Builder<BuildTarget>), and introduce a @VisibleForTesting constructor to make this change testable.  Let me know if I am not matching the unit testing style.\n. Correct.  For example, if this were true by default the classes generated by jmockit would also be included in code coverage.\nEdit: I also considered making this true by default and took guidance from https://github.com/jacoco/jacoco/pull/288#issuecomment-171246829\n. ",
    "nikhedonia": "\nWas there something not working with that approach which made you start using $(rel-lib ...)?\n\n$(lib) expresses the same issue and additionally requires me to set the -rpath manually.\nI use the libs as deps for another shared library and link this library to an executable.\nI discovered that copying the library with the trailing version numbers into the buck-out folder and\nsetting link_style='shared' on the executable solves the problem.\nIt surprises me that link_style makes a difference here as i only have shared libraries in my setup and linking shared libraries statically does not really make sense.. I can confirm. On Linux i have the same behavior but the other way around:\n```\n  buck run :hello\n  Hello from default\nbuck run :hello#linux-x86_64\n  Hello from linux\nbuck run :hello#macosx-x86_64\n  Unrecognized flavor in target //:hello#macosx-x86_64 while parsing //BUCK\n``. Any updates? - as more people and buckaroo packages depend on flavors, this is becoming a bigger annoyance day by day.... Thx for fixing it forloadin the latest release.. do you have a rough date in mind wheninclude_defs` will cease to exist?. Did you guys try to contribute this to skylib?. I'd like to mention that switching from python-dsl to skylark reduced the parsing time from over 3mins to less than 3s.. @ttsugriy depends on a couple of factors:\n- when are you making skylark the default?\n- how much engineering effort does it entail?\nAs parsetimes become quite painful on larger projects - this would be a nice to have.\nWe are also not ready to move the buckaroo ecosystem to skylark - I think we are 3 months away from that.. > Flavors usually change the behaviour, so, unless they are not being treated in a special way (e.g. stripped inside corresponding Description), they affect the output path at minimum\nWe don't know what the different flavors will do but if we would only cache based on hashes of all involved files, options(excluding destination / flavor where possible) and env variables we would have less cache misses.\nAn example - quite common in c++ - are optional features, where we swap one implementation with another eg.:\ncxx_library(\n  name = \"foo\",\n  deps = [\":a, \":b\"] if myCustomOption else ['\":a\"] \n  srcs = srcs\n);\nI also think it is interesting to note if you change options within a flavor, the caching works correctly eg.:\n[cxx#foo]\n  myCustomOption= 1 \n[cxx#bar]\n  myCustomOption= 0\nchanging myCustomOption=0  will correctly reuse the cache where possible.. > I think the better approach in your case could be to introduce two different targets with different deps, so then you can build them like buck build :main_foo and buck build :main_bar\nNot really. In some libraries we have more than 10 binary options. This approach would result in more than >2^10 different variations foreach rule. This is not feasible nor user friendly.\n\nThat is the key, this requires a knowledge about any potential flavor.\nBuck treats some flavors internally in a special way and skips them if needed\n\nI don't see why the name of the flavor matters at all. \nIf a flavor leads to a different sets of commands being executed then this would lead to a different set of hashes.\n\nThese flavors are actually internal ones in most cases.\n\nSo we should have a list of edge cases if required.\nCan an user defined flavor change the action graph?\nIn any case my previous statement should apply and we would not need to worry about any of this if the caching is implemented on the right level.\n\nYes, but the chance of getting a corrupted/incorrectly built binaries will also increase.\n\nThis is almost an argument against any caching solution. It boils down to correctly identifying what affects the artefact hash. I think we know that really well and buck ensures that the used output-path doesn't affect the hash of the result.. Did you guys had a chance to look at this?. how can I access files in the project-root like LICENSE from /scripts/packages/debian ?. ",
    "cushon": "java.lang.IllegalArgumentException\n    at org.objectweb.asm.ClassReader.<init>(ClassReader.java:170)\njavac-9-dev-r3297-3.jar contains a few v53 class files, which asm doesn't support yet. They aren't used and should be removed from the jar.. java.lang.IllegalArgumentException\n    at org.objectweb.asm.ClassReader.<init>(ClassReader.java:170)\njavac-9-dev-r3297-3.jar contains a few v53 class files, which asm doesn't support yet. They aren't used and should be removed from the jar.. > Any clue, what files should I drop from javac-9-dev-r3297-3.jar?\nI think this should do it. The full list is in google/error-prone#534.\nzip -d javac-9-dev-r3297-3.jar module-info.class com/sun/jdi/* \\\ncom/sun/tools/example/* com/sun/tools/jdi/* jdk/internal/jline/*. I filed JDK-8175235 for the error in WatchmanDiagnosticEventListenerTest.\nHere's the workaround:\n```\ndiff --git a/test/com/facebook/buck/io/WatchmanDiagnosticEventListenerTest.java b/test/com/facebook/buck/io/WatchmanDiagnosticEventListenerTest.java\nindex be1388e..d344212 100644\n--- a/test/com/facebook/buck/io/WatchmanDiagnosticEventListenerTest.java\n+++ b/test/com/facebook/buck/io/WatchmanDiagnosticEventListenerTest.java\n@@ -61,11 +61,11 @@ public class WatchmanDiagnosticEventListenerTest {\n         Matchers.contains(ImmutableList.of(\n             new PredicateMatcher<>(\n                 \"warning message containing \\\"a warning\\\"\",\n-                event -> event.getMessage().contains(\"a warning\") &&\n+                (ConsoleEvent event) -> event.getMessage().contains(\"a warning\") &&\n                     event.getLevel() == Level.WARNING),\n             new PredicateMatcher<>(\n                 \"error message containing \\\"an error\\\"\",\n-                event -> event.getMessage().contains(\"an error\") &&\n+                (ConsoleEvent event) -> event.getMessage().contains(\"an error\") &&\n                     event.getLevel() == Level.SEVERE))));\n   }\n@@ -87,10 +87,10 @@ public class WatchmanDiagnosticEventListenerTest {\n         Matchers.contains(ImmutableList.of(\n             new PredicateMatcher<>(\n                 \"message containing \\\"a warning\\\"\",\n-                event -> event.getMessage().contains(\"a warning\")),\n+                (ConsoleEvent event) -> event.getMessage().contains(\"a warning\")),\n             new PredicateMatcher<>(\n                 \"message containing \\\"another warning\\\"\",\n-                event -> event.getMessage().contains(\"another warning\")))));\n+                (ConsoleEvent event) -> event.getMessage().contains(\"another warning\")))));\n   }\n/**\n``. This looks like a bug, these should bebreak;.. I think most of these are deliberate, and should bedefault: // fall outinstead ofdefault: throw new AssertionError();.. Are you sure this is necessary? I can't reproduce a problem with this code.. extra}. This makes the@SuppressWarnings(\"incomplete-switch\")of the method unnecessary, andFRAMEWORKneeds to be beAppleBundleExtension.FRAMEWORK..AppleBundleExtension.APP`. Some of this indentation is off.. Indentation. ",
    "rahultailor": "Thanks. I manually created a res folder. And i was able to build and install. but In Mainactivity on firebase initialization it crashed. Its working fine with gradle. Is there other way to add firebase in buck.. ",
    "kassim": "several of Google's Android libraries have the same issue. ",
    "oleksandroparasc": "I have filled ticket to google about this: https://issuetracker.google.com/issues/77591523 please vote for it. @kageiit I have created a ticket https://partnerissuetracker.corp.google.com/issues/77591523# for them and eventually they will fix it, but as @ojw28 have mentioned buck would need workaround anyway. @kageiit thank you. ",
    "ojw28": "Even if this is a bug in the Android Gradle Plugin (which looks likely), and that bug is fixed at some point, there are still going to be lots of released libraries in the wild that are missing the res directory. Doesn't this imply that a workaround in Buck will be necessary, in practice, to avoid fairly major pain for developers that use it?. ",
    "koudle": "@bhamiltoncx sure\n```\n$ echo $LANG\nzh_CN.UTF-8\n$ echo $LC_CTYPE\n(ps:null)\n```. ",
    "liushuaikobe": "I installed buck via homebrew. But I also have this problem when I try to build the buck demo app as the doc said. \nI checked the .buckconfig file, it's iphonesimulator-x86_64 indeed. \nFinally I found that it's my xcodebuild error. More details here.\nTry \n$ xcodebuild -version\n\nIf you see\nxcode-select: error: tool 'xcodebuild' requires Xcode, but active developer directory \n'/Library/Developer/CommandLineTools' is a command line tools instance\n\nThen use\n$ sudo xcode-select -r\n\nTry again, the error disappeared.. ",
    "clonetwin26": "We are seeing this as well on intellij 1.7.2 using the buck IDEA plugin 2.7.7. Going to polish this a bit more by putting the actions in the gutter.. Last piece of polish is getting the icons to mark on the line where the method is declared.\n@styurin Would you know if there is something more specific then PsiMethod, since this includes the comments and annotations on the method.. Figured out the issue by finding children whose parents are classes and methods. Will redo the screen shots when I get the chance. . Good recommendations was able to remove two whole classes :). I think the icons are a lot more discoverable :). Okay we can extend the default run configuration. If you want we can do that in a follow up diff, or if we do it here, it will have to wait till Wednesday as I have gone on vacation :/. ahhh ty. That's why the ant task is always failing. . ahhh ty. That's why the ant task is always failing. . https://github.com/facebook/buck/commit/5443fc29ac6e5db81aaa3ed3dce9fb4853cd025c. wooooo \\o/. Considered it. My fear with scripts is my users have no way of guessing what the right thing to do on the command line is. I am worried they will pass either too large things or not realize the tool is there in the first place. Plus right clicking around a large file system, feels much better and faster than paying attention to the paths on the command line even with auto complete.\nKeeping aliases in sync for buck project is also not scaling, some of our apps are so big they can bring the ide to a crawl if you generate all the modules. Will think about other command line approaches but it has caused some headaches in the past. . derp. Let me take a look lol. Almost done writing this as an external tool. On the one hand chaining the buck owner query and project query becomes much simpler. Strangely the utilities to find a Buck File make generating projects from a directory more complicated in the scripts than the action. Plus we don't get the path to buck like we do when we use the plugin. I don't think there will be a lot of discoverability behind external tools, which is tough as this issue hits our newest devs the worst, and as such I prefer the implementation inside the plugin. \n\nDo developers open old project and then run buck project on a new package?\n\nYes, and the projects they are generating are much too large for the files they want to edit.\n\nI don't think we want to expose this option to developers, IntelliJ probably can handle changes in the project on a fly, but I'd prefer not to rely on this behavior.\n\nThis is kind of already exposed in the buck tool window as you can buck project the selected target, this just makes the user experience much friendlier. . Here is an implementation of this as an external tool. The install is pretty goofy, not quite ready to update the pr request as through the plugin has a much nicer install:\n\nThis is the shell script\nrun_buck_project.txt\n!/usr/bin/env bash\nprojectRoot=$2\nfileName=$4\nif [[ !  -z  $5  ]]; then\n    echo \"buck query \\\"owner('$projectRoot/$fileName')\\\" | xargs buck project\"\n    buck query \"owner('$projectRoot/$fileName')\" | xargs buck project\nelse\n    directory=$1\n    relativeFilePath=$3\n    relativeModulePath=${directory#$projectRoot}\n    relativeModulePath=${relativeModulePath:1}\n    if [ -e \"$directory/BUCK\" ] > /dev/null; then\n        :\n    elif [ \".\" != \"$relativeFilePath\" ]; then\n       relativeModulePath=${relativeModulePath%$relativeFilePath}\n       if [[ \"$relativeModulePath\" =~ '/'$ ]]; then\n          relativeModulePath=${relativeModulePath%?}\n       fi\n       # The module is not necessarily loaded so relative paths can be broken. Look for a Buck file if we don't have.\n       while [[ ! -e \"$relativeModulePath/BUCK\" && \".\" != \"$relativeModulePath\" ]]; do\n          relativeModulePath=$(dirname \"$relativeModulePath\")\n       done\n       # No Buck file so just generate projects for everything below.\n       if [ $relativeModulePath == \".\" ]; then\n          directory=$1\n          relativeFilePath=$3\n          relativeModulePath=${directory#$projectRoot}\n          relativeModulePath=${relativeModulePath:1}\n       fi\n    fi\n    echo \"buck project $relativeModulePath/...\"\n    buck project $relativeModulePath/...\nfi\n. Okay. Only mystery is registering an external tool via the plugin to fix the install flow. . Multiple targets owning a file is for sure an issue in this approach. Thank you for taking the time to look through this.\nI think the value of main and run, is you can get into the debugger and build system from within the ide, without having to write a test and go through the test runner. You can easily build the whole module too with an empty main, all from within the ide. This is usually my flow when I want to develop a library, and new up instances and test functionality, before I am ready to write a proper unit test.\nWe get quite a few people who try to build through intellij run buttons, and are put through some pretty jarring experiences, as the default runner is no where close to actually using the buck build system to build.\nI will reach out to you first before committing to develop such a feature, and will think more about the multiple owning targets, I suppose I could just build and add all of the classpaths to the program-runner classpath for all owning targets.\nI think if the file is part of a Java library, which is consumed by a Java binary, then the end user would just use the main of the Java binary to run and debug, or add their own main to the library.. You have the right understanding. It also puts all the results of deep build onto the run time classpath. I was unable to do unit tests without degrading ide perf since their configurations don't give virtual files and have to be deduced from a FQN.. Not every main method has a binary. Some are purely contained in a Java or android library. . This is still hardcoded at this point. Once I figure out the stale configurations it should be easy to wire the proper test target.. I thought that was how VirtualFile buckFile = BuckFileUtil.getBuckFile(virtualFile); Worked? . Yup we can generify this quite a bit, since its all about filling out and starting a new configuration.. Nope let's wack it.. Only thing is to make this part of this change or in follow up diffs.. id let's it know that its different. I am going to refactor into two actions so we can generify making run and debug configs for any psi element, denoting a package, file, class, or method.. \ud83e\udd15 . Let's just add support, if buck supports it, then it should be fine.. good catch.. nice.. nice.. This one was actually a pain. Intellij is so picky about which thread it will let you set configurations on.. This is needed since I can't write settings on the thread buck query returns to.. Sorry, Made the change its a nice win :). This was to filter out our own lint targets, and should take all targets instead.. All of the resulting jars from all of the transitive dependencies has to be present to be put on the runtime classpath.. Hard not to duplicate here since it has to pass the target results to other buck commands.. This made this much cleaner ty :). ",
    "paulononaka": "Just figured out that's because OkBuck doesn't support the Transform API yet. :(\nhttps://github.com/uber/okbuck/wiki/Features\nhttps://github.com/realm/realm-java/issues/3971. ",
    "aary": "Yeah running buck targets in the root folder causes buck to fail with an exception that originates from the same line of code. \nI could try and fix it, but I have no idea where the relevant part of that code starts... Could you point me in the right direction and I can give it a shot?. https://github.com/aary/buck-shared-library-error-report I didn't include tbb in the repo, so you will have to run bash build.sh to download and compile it.  And then running buck run :test should show you the error.  \nDoes that work?. @andrewjcg It still gives the same error unfortunately. . ",
    "Leland-Takamine": "NO_BUCKD=1 fixed the issue for me.. NO_BUCKD=1 fixed the issue for me.. ",
    "aventadorm": "I am getting the following error : \nparameter 'assembly': cannot coerce 'D:\\Tools\\companyName\\SDKName\\SDKVersion\\SDKAssembly.dll' to interface com.facebook.buck.core.sourcepath.SourcePath, SourcePath cannot contain an absolute path.\nI am using os.environ['NAME'] to reference the env. variable that points to a certain assembly file on all my build machines. . Sure.\n. ",
    "nguyenhuy": "cc @robbertvanginkel. @robbertvanginkel Ready for another round. Thanks!. ",
    "ProfessaA": "@sdwilsh yeah that buck build line is generated by build_with_buck.py:\npython  buck-out/res/com.facebook.buck.apple.project_generator.ProjectGenerator/build_with_buck.py \\\n    /Users/aaron.levine/workspace/buck-prebuilt-cxx \\\n    /usr/local/bin/buck \\\n    -- \"--show-output --report-absolute-paths\" \\\n    //StaticLib:StaticLib#iphonesimulator-x86_64,static \\\n    dwarf-and-dsym \\\n    dwarf-and-dsym\nThat script doesn't expect the escaped_build_target param to have flavors, so it always appends a \"#\" followed by all flavors.  It seems like that param shouldn't have flavors, but in that case the script wouldn't be properly appending the static flavor, which I think is needed.  Is there any documentation on flavors?. @sdwilsh yeah that buck build line is generated by build_with_buck.py:\npython  buck-out/res/com.facebook.buck.apple.project_generator.ProjectGenerator/build_with_buck.py \\\n    /Users/aaron.levine/workspace/buck-prebuilt-cxx \\\n    /usr/local/bin/buck \\\n    -- \"--show-output --report-absolute-paths\" \\\n    //StaticLib:StaticLib#iphonesimulator-x86_64,static \\\n    dwarf-and-dsym \\\n    dwarf-and-dsym\nThat script doesn't expect the escaped_build_target param to have flavors, so it always appends a \"#\" followed by all flavors.  It seems like that param shouldn't have flavors, but in that case the script wouldn't be properly appending the static flavor, which I think is needed.  Is there any documentation on flavors?. @sdwilsh is the --build-with-buck flag intended to make the tests in the generated project runnable from Xcode? If not, how do you recommend developing iOS apps using buck? Should the app be built and run from Xcode but tested from the command line?. @ryu2 @Coneko is there any chance of supporting product_name for apple_library build rules and not just apple_bundles?  ProjectGenerator.getProductNameForTargetNode has special support for apple_bundles that looks for the product_name attribute and it would be nice to extend that to apple_library as well.  \nAlso, it looks like ProjectGenerator.generateBinaryTarget sets the  product name to getProductNameForBuildTarget, which always uses the short name, but it seems like that should respect the product_name attribute.\nIs there any temporary work around? I've tried setting PRODUCT_NAME in the configs attribute but it creates a disparity between the value in project.pbxproj (how it appears in xcode) and in the actual name of the generated lib, so this doesn't quite work.. @ryu2 @Coneko is there any chance of supporting product_name for apple_library build rules and not just apple_bundles?  ProjectGenerator.getProductNameForTargetNode has special support for apple_bundles that looks for the product_name attribute and it would be nice to extend that to apple_library as well.  \nAlso, it looks like ProjectGenerator.generateBinaryTarget sets the  product name to getProductNameForBuildTarget, which always uses the short name, but it seems like that should respect the product_name attribute.\nIs there any temporary work around? I've tried setting PRODUCT_NAME in the configs attribute but it creates a disparity between the value in project.pbxproj (how it appears in xcode) and in the actual name of the generated lib, so this doesn't quite work.. Hey, thanks for your response! By \"change the rule names\", I mean the name parameter used for the build rule, e.g. having to change Lib1:Lib to Lib:Lib1Lib.  Macros make the rule a little more clear during definition, but still require redundant namespacing when making references to the rule, as withbuck build Lib1:Lib1Lib or having to refer to :Lib1Lib rather than just :Lib1 when specifying dependencies for other rules in Lib1/BUCK.  \nIt seems like a shortcoming of Xcode that it can't distinguish between libraries of the same name produced by different projects.  It would be nice to be able to specify a product name that is only used when constructing xcode projects and is separate from the name parameter of the rule (or maybe to prepend the project name automatically to the product name) , since otherwise xcode imposes an unexpected, artificial constraint on the naming of build rules.. @ryu2 I went through the watchman troubleshooting guide and didn't see any of the error messages mentioned being logged.  I also ran the find-fsevents-bugs tool and nothing came up.  The watchman logs look fairly normal, and are similar to watchman's log output when files are changed in the smaller projects that the buck daemon catches updates in.  This is the output from watchman when I change the file /path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m to make a test fail:\n[notify /path/to/proj] fsevents: got /path/to/proj/Libraries/Injector/InjectorTests/4913 0x14300 ItemCreated ItemRemoved ItemChangeOwner ItemIsFile\n[notify /path/to/proj] add_pending: /path/to/proj/Libraries/Injector/InjectorTests/4913 VIA_NOTIFY\n[notify /path/to/proj] fsevents: got /path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m~ 0x10a00 ItemRemoved ItemRenamed ItemIsFile\n[notify /path/to/proj] add_pending: /path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m~ RECURSIVE VIA_NOTIFY\n[notify /path/to/proj] fsevents: got /path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m 0x1f900 ItemCreated ItemRenamed ItemModified FinderInfoMod ItemChangeOwner ItemXattrMod ItemIsFile\n[notify /path/to/proj] add_pending: /path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m RECURSIVE VIA_NOTIFY\n[io /path/to/proj]  ... wake up (pinged=true)\n[io /path/to/proj] processing 3 events in /path/to/proj\n[io /path/to/proj] w_lstat(/path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m) file=0x7fa84ae54840 dir=0x0 res=0 Undefined error: 0\n[io /path/to/proj] file changed exists=1 via_notify=1 stat-changed=0 isdir=0 /path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m\n[io /path/to/proj] add_pending: /path/to/proj/Libraries/Injector/InjectorTests\n[io /path/to/proj] w_lstat(/path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m~) file=0x7fa84c321530 dir=0x0 res=-1 No such file or directory\n[io /path/to/proj] we're case insensitive, and /path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m~ is ENOENT, speculatively look at parent dir /path/to/proj/Libraries/Injector/InjectorTests\n[io /path/to/proj] w_lstat(/path/to/proj/Libraries/Injector/InjectorTests/4913) file=0x7fa84c321750 dir=0x0 res=-1 No such file or directory\n[io /path/to/proj] we're case insensitive, and /path/to/proj/Libraries/Injector/InjectorTests/4913 is ENOENT, speculatively look at parent dir /path/to/proj/Libraries/Injector/InjectorTests\n[io /path/to/proj] processing 1 events in /path/to/proj\n[io /path/to/proj] opendir(/path/to/proj/Libraries/Injector/InjectorTests) recursive=false\n[io /path/to/proj] in crawler calling process_path on /path/to/proj/Libraries/Injector/InjectorTests/.DS_Store\n[io /path/to/proj] add_pending: /path/to/proj/Libraries/Injector/InjectorTests\n[io /path/to/proj] in crawler calling process_path on /path/to/proj/Libraries/Injector/InjectorTests/Fixtures\n[io /path/to/proj] in crawler calling process_path on /path/to/proj/Libraries/Injector/InjectorTests/Info.plist\n[io /path/to/proj] in crawler calling process_path on /path/to/proj/Libraries/Injector/InjectorTests/InjectorTest.m\n[io /path/to/proj] in crawler calling process_path on /path/to/proj/Libraries/Injector/InjectorTests/Providers\n[io /path/to/proj] processing 1 events in /path/to/proj\n[io /path/to/proj] w_lstat(/path/to/proj/Libraries/Injector/InjectorTests) file=0x7fa84ad3b9c0 dir=0x7fa84ae183a0 res=0 Undefined error: 0\n[io /path/to/proj] file changed exists=1 via_notify=0 stat-changed=1 isdir=1 /path/to/proj/Libraries/Injector/InjectorTests\n[io /path/to/proj] poll_events timeout=20ms\n[io /path/to/proj]  ... wake up (pinged=true)\n[io /path/to/proj] poll_events timeout=20ms\n[io /path/to/proj]  ... wake up (pinged=false)\n[io /path/to/proj] last=22  pending=35\nIn this case buck test continues to report 100% cache hit and all tests passing.  Is there any logging from the buck daemon that might be useful?. @bhamiltoncx do you have any suggestions on why this might be happening and what logs I can look at to debug? thanks!. @bhamiltoncx that helped a lot since I was able to see the queries being made to watchman (the pertinent logs showed up in buck-out/log/<timestamp>_testcommand_<uuid>/buck.log).\nIt turns out that my buckconfig's [project] ignore section had a trailing comma which caused [\"dirname\", \"\"] to be added to the not portion of the watchman query.  I guess this causes everything to be ignored.  That's completely my fault, this issue can be closed.  Thanks for your help!. @Coneko I've addressed this issue in https://github.com/facebook/buck/pull/1315.  can you take a look and make sure the approach is okay? thanks!. Great, thanks!. Okay, so we could add entitlements to apple_binary, and:\n1. if targeting the simulator, the apple binary description would use entitlements to add linker flags to the CxxBinaryDescription.Arg used to construct the binary rule\n1. if targeting a device, the downstream apple_bundle could use getConstructorArg().entitlements on the binary TargetNode to know which entitlements to use for code signing\nThe only thing that's a little awkward is that info_plist would be specified by apple_bundle whereas entitlements would be specified by apple_binary.\n. @LegNeato code-signing does happen right now for simulator builds but it uses the ad-hoc signing identity: codesign -s - /path/to/app, which is what xcode does too.\nThe documentation on \"ad-hoc signing\" is pretty sparse (https://developer.apple.com/legacy/library/documentation/Darwin/Reference/ManPages/man1/codesign.1.html), but it seems to produce a binary without an embedded code signature that can only be run in the simulator.  I modified buck locally to pass in entitlements when using the ad-hoc signing identity (codesign -s - --entitlements /path/to/xcent /path/to/app) but the resulting app crashed on launch.. @ryu2 yup with that patch the location macros are still expand properly.  thanks for the help!. @ryu2 @illicitonion In that case, would it make sense to leave the BuildTargetMacroExpander alone and in the project generator first try to use the LocationMacroExpander, and if that fails fall back to the AsIsLocationMacroExpander?. @ryu2 as an alternative how about https://github.com/ProfessaA/buck/commit/eb8d7c59f2a611244854c71f9ede5aaca07980a4 ? It's the same approach except that the logic added to BuildTargetMacroExpander is moved to the ProjectGenerator's anonymous LocationMacroExpander instance so that the macro expander is left alone.  If it looks good, I'll target that branch instead for this PR.. @ryu2 yup project generation works with export_file rules like:\n```\napple_library(\n  ...\n  exported_linker_flags = ['-force_load', '$(location :libExported.a)'],\n)\nexport_file( name = 'libExported.a' )\n```\nI also updated the ProjectGeneratorTest to make sure that linker flags with location macros referencing export_file as well as genrule targets get properly expanded.\n. ",
    "alevinesc": "@ryu2 or @Coneko are there plans to support prebuilt_cxx_library in generated xcode projects?  If not, do you have suggestions for how to integrate third party libraries (like OCMock) into buck projects?. Thanks!! The missing piece was the libraries field which doesn't seem to be documented.\nThere was one more thing I had to do that feels a little hacky.  When I tried to reference the third party lib from my apple_library target, I initially got a \"refers to a parent directory\" error and had to link the library to be in a child directory.\nFor building third-party dependencies from source, a difficulty I ran into was that a lot of projects have a Prefix header.  I tried to use -include in compiler_flags with the relative path of the .pch file, but the generated project didn't work.  Is there a better way to replicate Xcode's \"Prefix Header\" setting with buck?. perfect that's what I needed, thanks!. ",
    "JoelMarcey": "\n. \n. \n. @bishopmatthew Can you try setting $ANDROID_SDK to just /usr/local/Cellar/android-sdk/ and see if you get the same problem?. @bishopmatthew Ah -- I didn't notice that either. Good catch!. Thank you for noticing this. I will put a fix up asap.. Done!. This was already part of my other pull request. Not sure what happened on the import internally to get it removed :(\nhttps://github.com/facebook/buck/pull/1095. ",
    "MCA-FSF": "I am very very sorry, i did't express clearly. I know frameworks must be a path starting with $SDKROOT or $PLATFORM_DIR.  If i want use static library with the extension \".framework\" that comes from third-party, how to configure build file\uff1f. Is there has field in prebuilt_apple_framework that like header_namespace in prebuilt_cxx_library?. Is there has field in prebuilt_apple_framework that like header_namespace in prebuilt_cxx_library?. Hi, @ryu2 , Now we have a Xcode project with three extensions that using swift. I want to know does buck work with swift? \nAnother thing that I care about is that there is a graph that comparing performance  improvements in build times for Buck vs. Gradle. Is there some comparation between buck and Xcode? \nThank you very much.\n. Hi, @ryu2 , Now we have a Xcode project with three extensions that using swift. I want to know does buck work with swift? \nAnother thing that I care about is that there is a graph that comparing performance  improvements in build times for Buck vs. Gradle. Is there some comparation between buck and Xcode? \nThank you very much.\n. I hope you can help to solve it because when I solved a error, a new error would come. Finally, the error as follows, and i don't know what should i do. Thanks.\nPS: It can build correctly, but can't run.\nAn error was encountered processing the command (domain=MIInstallerErrorDomain, code=4):\nFailed to chmod /Users/FSF/Library/Developer/CoreSimulator/Devices/31479CE8-5233-4EAE-8D1A-AD7666A58A64/data/Library/Caches/com.apple.containermanagerd/Bundle/Application/E89580FD-0757-467D-BE37-8E33B6FD3DA2/DemoAppWithExtension.app/PlugIns/DemoExtension.appex/ DemoApp : No such file or directory. I don't think it is a fault of Buck and I have updated the Buck to the latest version. . I don't think it is a fault of Buck and I have updated the Buck to the latest version. . ",
    "darkforestzero": "Thank you for your quick review.  We are happy to make the changes, but\nhave a few concerns:\n1. It would be nice to keep all the apps together that were made by our\nstudio, rather than having Lyft and Uber interspersed within them.\n2. Currently, all the apps listed are either owned by Facebook or are from\nsingle app companies (Lyft, Uber).  It would be nice if there was a way to\nat least show our company name, if not a link to our app webpages, since\nnearly our entire catalog of apps (most of which have 1m+ downloads) are\nbuilt using buck.\nThanks,\nJonathan\nOn Fri, Jan 13, 2017 at 12:44 PM, Shawn Wilsher notifications@github.com\nwrote:\n\n@sdwilsh requested changes on this pull request.\nTwo things:\n\nI'm trying to keep the apps alphabetized after the Facebook ones.\n   Can you reorder and intermix the applications as appropriate?\nThe moreInfo link is meant to be a blog post, podcast, etc talking\n   about how Buck helped you or how you moved to Buck. If you have something\n   like that, that's great. If not, let's drop the links for now until you do.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1128#pullrequestreview-16648275,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHe1uscX7jbMRhMeujCCenbFXanlW-jFks5rR-I0gaJpZM4LjRH3\n.\n. Of course!  Thanks for your understanding.  Brainium is heavily invested in\nBuck; it is the backbone of our multi-platform build pipeline on nearly all\nour games!  We've also made a few contributions to the buck github and are\nsomewhat active on the google group.\n\nHave a great weekend.\nOn Fri, Jan 13, 2017 at 1:48 PM, Shawn Wilsher notifications@github.com\nwrote:\n\nYeah, I understand. Do you mind if I sit on this over the weekend to\nfigure out a way to accommodate your use case as well as more single-app\nplaces?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1128#issuecomment-272556963, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AHe1us7bYqFji1Y0jr2dSPWYoOEB6BF_ks5rR_EtgaJpZM4LjRH3\n.\n. Hi Shawn,\nWanted to check on the status of the app section change to Showcase.soy.\nThanks\n\nOn Tue, Jan 17, 2017 at 4:17 PM, Shawn Wilsher notifications@github.com\nwrote:\n\nOkay, I've thought it over and talked to some others. I think we have a\ndecent plan forward here, but I won't have time until tomorrow to actually\nimplement the changes to make this work. After that, you can rebase and\nadjust and continue to add apps under your section if you'd like :)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1128#issuecomment-273343500, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AHe1uk7uFsqdrNs_DPJO5nZ_abNC2b8tks5rTVotgaJpZM4LjRH3\n.\n. Oh no!  No worries.  Good luck fixing up your place!\n\nOn Thu, Jan 19, 2017 at 12:01 PM, Shawn Wilsher notifications@github.com\nwrote:\n\nMy plans for the week got a bit derailed. We got a lot of rain recently,\nand water appeared in our basement, so I've had to take some time off to\ndeal with that. I'll get to it as soon as I can!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1128#issuecomment-273882419, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AHe1ujzdCrDDAQTu5Tpg_2feEXwBdqABks5rT8EmgaJpZM4LjRH3\n.\n. @sdwilsh I'm very confused about this whole pull request business.  I'm pretty sure I've got the soy file in a good place, and I see the work my repo (darkforestzero:patch-4), but I don't know how to get that in to master.  I don't even see another pullrequest for it.  So, I'm just going to close this and try to start from scratch. @sdwilsh Hello.  Not sure where to go from here.  looks like the failures were from internal buck stuff. @sdwilsh \nI have a fixed version with correct links to our icons, there was just an extraneous https// before each link.  it's really hard to iterate on this without being able to see the end result.  i committed my fix to patch 5, but I guess that's closed now.  I'd prefer if we use the links on our server which are higher resolution and more up to date.  Also, would be nice to include Wordsearch since it's built with buck.  \n\nI've attached a \"fixed' version of the showcase.soy .  Sorry this is dragging on so long - again it's hard to iterate through a black box :)\nshowcase.soy.txt\n. @sdwilsh thanks for the soyweb-local info.  dang, it looks so good!  too bad about ssl.  How about I upload the images to public google photos so that they're all secure and we link those?\n\n. @sdwilsh This should address the issues we discussed in your pull request (SSL images and missing apps). ping @sdwilsh .  Doesn't look like the travis failures have to do with my changes. @sdwilsh ping. ",
    "cesarferreira": "You are right, thanks!. Yup, it was with OkBuck thanks anyway. Yup, it was with OkBuck thanks anyway. ",
    "weibel": "Closing this and posting on the group instead. Closing this and posting on the group instead. ",
    "zayhero": "@Coneko yes, using quote format works with bridging header.\nHowever, in a complicate file system, this cause too much mess.\nFor example, we have two header files under folderA/A.h and folderB/B.h. In A.h, we do #import <Greeter/B.h>, this won't work with buck right now.\nIf we want to change to this import to quote format, we can either 1) move all these headers to same folder, or 2) have a very complicate import logic in each header. Both ways are quite mess to me.\nThus, I figure out the best way is adding the header map generated for current library into SwiftCompile, so we can import the headers easier.\n. @ryu2 thanks for reviewing! I accidentally remove the private header map from the list, so the new test case no long work. Already fixed, please take a look.. @ryu2 could you take a look at this PR as well?. @yiding We are doing something similar internally. We introduce a script to replace the import statement, so we can ensure it always doing #import <Lib/Lib.h>.\nYour idea here seems better, that just do the replace logic on the *-Swift.h in SwiftCompile.\nAm I understand correctly?. @yiding Thanks for the information! Will you implement this logic into Buck directly? \nIf you are not planning to do that, I can try to implement this logic myself.. This problem is resolve after @milend rewrite Buck. Closing it now.. ",
    "bgwines": "thanks for the prompt response! :) We found an even simpler solution, actually, just now -- turns out you can pass in includes_vector_drawables = True to android_binary!. haha; yeah -- things in general are hard to find if you don't know the exact name of what you're looking for, unfortunately. Definitely a user error on our end for not finding this, though. Thanks so much!. ",
    "jiangjef": "@raviagarwal7 Hi I am running into similar problems. How did you find out which tests caused the crash?. ",
    "Odaym": "Same error here after building successfully and installing successfully.\nNexus 5 phone with Android 6.0.1. meh, too complicated, gave up. ",
    "RimingChen": "@styurin \nthe same problem, after installing ANDROID NDK and setting ANDROID_NDK_REPOSITORY to the path, \nstill no libjni.so generated.\nwhen building the libjni.so it reports:\n\ncross-platform-scale-2015-demo$ buck build //android/cxx:jni\nUsing watchman.\nandroid/cxx/Hello.cpp:9:10: fatal error: 'jni.h' file not found\ninclude \n     ^\n\n1 error generated.\nBUILD FAILED: //android/cxx:jni#compile-Hello.cpp.o11bd3722,default failed with exit code 1:\nc++ preprocess_and_compile\n[-] PROCESSING BUCK FILES...FINISHED 0.3s [100%] \ud83d\udc33  New buck daemon\n[-] DOWNLOADING... (0.00 B/S AVG, TOTAL: 0.00 B, 0 Artifacts)\n[-] BUILDING...FINISHED 2.9s [100%] (4/4 JOBS, 4 UPDATED, 1 [25.0%] CACHE MISS)\n\nseems buck won't search include-path in the ndk platform such as $ANDROID_NDK_REPOSITORY/platforms/android-21/arch-arm/usr/include\nhow to set the config for building this demo?. I've also tried:\n$ buck kill && rm -rf buck-out\n$ buck build demo_app_android\nbut still get no libjni.so\nbuck0_buildlog.txt\n. I'm using the release version installed by home-brew on Mac:\ncross-platform-scale-2015-demo$ buck --version\nbuck version v2017.05.31.01\nAlso I've tried your tips on #1176\n$ buck kill && rm -rf buck-out\n$ buck build demo_app_android\nstill the same problem. . thanks buddy, I checked out the latest code from buck, it works, the shared lib finally came out!\nOne question, the ndk-version I set in the ndk section will not work if setting it to its short name with the new ndk version r14b?\ne.g..\n the following setting reports \"No native platforms detected.\":\nndk_version = r14b\nbut   ndk_version = 14.1.3816874\nworks.. ",
    "vanniktech": "Even failing with buck version at commit 863cc4f30661cc65b2409b0fdbdffa221df1f05e. Even failing with buck version at commit 863cc4f30661cc65b2409b0fdbdffa221df1f05e. Unfortunately adding quotes does not fix this issue.. Unfortunately adding quotes does not fix this issue.. Also tried the following variations with the latest commit (62b8c833ee37b2ef3086096ff6e39d4c2dd4b166) which didn't work either:\nxml\n<string name=\"url\"><![CDATA[https://google.com]]></string>\u2028\n<string name=\"url\"><![CDATA[\"https://google.com\"]]></string>. @dreiss I don't have any hidden characters in my XML and I'm using 25.0.2. You can check out the repro case.. @dreiss I don't have any hidden characters in my XML and I'm using 25.0.2. You can check out the repro case.. Interesting. Thanks for this one. Can buck improve in this scenario and give a more detailed error message or is this up to aapt entirely? If not, feel free to close this issue as there's a proper workaround / fix.. ",
    "EmielM": "I'm using the (afaik undocumented) lang_preprocessor_flags option, found by googling on github for more complex buck examples:\npython\napple_binary(\n  name = 'myApp',\n  preprocessor_flags = ['-fobjc-arc', '-fmodules'],\n  lang_preprocessor_flags = {\n    'OBJC': ['-std=gnu99'],\n    'OBJCXX': ['-std=c++14', '-stdlib=libc++'],\n  }\n  ...\n). ",
    "kaizenapp": "Do you think you will be able to fix that in the near future? If not, could you please at least point to the code, so I can hack on that myself.. ",
    "wdsunny": "I have same issue, anyone find solution?. ",
    "evanj": "I had some success modifying your approach to use the same resolution logic that pip does. This modified rule only requires you list the .whl files, and it should automatically pick up the same one that pip would. Unfortunately I'm blocked by #1330, so the resulting pex doesn't actually work.\nHowever, if I can figure out that one, this suggests it would likely be possible to create a BUCK generator that could take a list of pip requirements, and output the correct rules and download the corresponding wheels so it could then build correctly on multiple platforms.\n```\nwith allow_unsafe_import():\n    import pip.wheel\n    import pip.pep425tags\n# Inspired by https://github.com/facebook/buck/issues/1206\n# Pip wheel resolution from pip.wheel.cached_wheel:\n# https://github.com/pypa/pip/blob/master/pip/wheel.py#L133\ndef multiplatform_python_library(name, deps=[], wheels=[], **kwargs):\n    supported_wheels = []\n    for wheel_filename in wheels:\n        w = pip.wheel.Wheel(wheel_filename)\n        if not w.supported():\n            continue\n        supported_wheels.append((w.support_index_min(), wheel_filename))\n    if len(supported_wheels) == 0:\n        raise ValueError('no wheel for \"%s\" that matches platform \"%s\"' % (\n            name, pip.pep425tags.get_platform()))\n\n    supported_wheels.sort()\n    wheel_file = supported_wheels[0][1]\n    prebuilt_python_library(\n        name=name,\n        binary_src=wheel_file,\n        deps=deps,\n        **kwargs\n    )\n\n```\n. YES! That did the trick, and that confirms it fixes this particular bug: I can now include native .whl dependencies on my Mac and the resulting build works! Thank you!\nI'm willing to submit a pull request with this, however I suspect that this is the sort of change that someone who works on Python support for Buck will probably need to make, since I suspect it could break all sorts of subtle things. :). ",
    "philipjameson": "@sdwilsh, yes, it's in progress, but no firm timeline yet. Well, that definitely shouldn't have happened. Lemme take a look . . Actually, on a reread, this was intentional after discussing with @ttsugriy. It wasn't actually supposed to work that way to start with, we just did it because it was easier for some of our migrations. @ttsugriy , thoughts on making this configure extension files as well?. No it's not, though I believe the skylark parser is marked experimental and cards on the table, I didn't know that anyone really was using it yet other than FB. Mind if we meet and the middle and just toss a config flag to re-export them? I think going forward we'd like new projects to be explicit about using native rules.. .bzl files should use native.go_library and native.genrule. By default (unless you disable it), go_library and genrule will work in BUCK files without the prefix. . This is one way to address GH-1750. Can we please get both the unit tests and integration tests updated here?. Can we please get both the unit tests and integration tests updated here?. Thanks for the updates!. Hey @R1kk3r, it's down to some trickiness around flavored (rules with '#some-platform' at the end) versus unflavored rules (in this case //:a) and their implementation details. cxx_libraries do not have functional unflavored versions, as they need to know what \"platform\" they're building for (this is 'default' for most cxx_binary rules but can be configured). This is why you're not seeing anything get built when you do 'buck build //:a'. 'a' internally is a noop rule, so no deps get built either.\nWhen you build a cxx_test or a cxx_binary, they pull the flavor/platform from your .buckconfig / attributes on the rule, and propagate that to any cxx_libraries that they depend on, and that's why it worked before. If you either do: buck build //:a#default, or create a cxx_binary/cxx_test that depends on //:a, it should run //:b for you. Give that a shot, and let us know if that doesn't work\nWe know that this kind of sucks right now, and we're definitely working on cleaning up some of this logic, but it's a little engrained in the architecture right now, so not really a switch that can be easily flipped afaik.. So it looks like we're just not loading foo.<platform>.so files. I repacked the whl moving objc/_machsignals.cpython-36m-darwin.so -> objc/_machsignals.so and objc/_objc.cpython-36m-darwin.so -> objc/_objc.so and it worked fine. I'll take a look over our loader code to see if there's anything obvious that we need to do. Sorry for the delay!. Is there any reason you can't create a prebuilt_cxx_library that has header_dirs set and header_only set to true, and then depend on that in your cxx_library?. Yep, we're definitely planning first class support for this (in fact, we use it internally at FB though some wrapper scripts). We want to be careful about promoting it before it works on windows, so the timeline is a little squishy. . Hmmm.... I was not aware that python.org's installer installed python3 as 'python', as for all unix envs, python is python2, and python3 is python 3.x. We can probably change this up a bit.. Sorry for the delay on this. We now have a preference for the version installed with chocolatey, and we're pushing a version this afternoon that should have the fix. Thanks for bringing this up!. Awesome, thanks! . So for specific commits, you can definitely use the stuff that @kageiit  mentioned. As far as binary releases, it's a little manual at this point (I'll probably be fixing that up in the coming months as time allows to automate it completely), and the build hosts I was using were a little broken, so I didn't get back around to adding the binary packages.\nSorry for the confusion, and I'm cutting a release right now (https://github.com/facebook/buck/releases/tag/v2018.10.17.01) that should have the packages. \nGoing forward we should have binaries on each release, and they should happen more frequently.. Should be published now, sorry about that, looks like we had some tooling fail during the publish. . Hey @njlr, yeah it was updated earlier and the diff put the wrong hash up. Sorry for the noise! https://github.com/facebook/homebrew-fb/pull/34 should have fixed this. Lemme know if this still persists after you update. . Hey @njlr, yeah it was updated earlier and the diff put the wrong hash up. Sorry for the noise! https://github.com/facebook/homebrew-fb/pull/34 should have fixed this. Lemme know if this still persists after you update. . @mkillianey Can you take a look at this?. Hey @mattfenwick , if you want to get the CLA handled, we can get this merged in. Thanks for helping with the docs!. This should be fine, but can you make this python2.7 python2 python in case, for some reason, a person doesn't have a 2.7 link? . s/\"kapt\" allows to run Java annotation/\"kapt\" allows running Java annotation/. s/\"kapt\" allows to run Java annotation/\"kapt\" allows to running Java annotation/. ",
    "leodeleon22": "I was able to run the demo using \nANDROID_SDK=$ANDROID_HOME buck install --run demo_app_android\nHow should I set my variables so I don't have this problem anymore?. ",
    "samuela": "bump\nI'm having this exact same issue trying to incorporate OpenCV in a buck project. No matter what I do I keep seeing\ndyld: Library not loaded: @rpath/libopencv_videostab.3.2.dylib\n  Referenced from: /..../buck-out/gen/device/main\n  Reason: image not found\nerrors.. Here's an example that should reproduce the issue: https://github.com/samuela/buck-shared-library-bug.. cc @drshrey. cc @drshrey. @ilya-klyuchnikov I'm not on Windows.. ",
    "liuliusc": "Sure. The setup looks like this:\n```\napple_library(\n    name = 'DataModelLib',\n    headers = 'DataModel//*.h',\n    srcs = 'DataModel//*.m',\n    deps = [':DataModel']\n)\napple_test(\n    name = 'DataModelTests',\n    srcs = 'DataModelTests/*/.m',\n    deps = [':DataModelLib', ':DataModel'],\n)\ncore_data_model(\n    name = 'DataModel',\n    path = 'DataModel/DataModel.xcdatamodeld',\n)\n```\nThis is intentionally setup as a normal buck test rather than a host app test because these unit tests would work much better just as normal buck tests.. Thank @Coneko , verified the tip of buck now passes my example with buck test.\nHowever, I was confused why the generated Xcode project moves the data model to resource copy rather than compile phase. I don't quite understand the implication to be honest.\nTo help the discussion:\n```\n\nbuck -V\nbuck version bd6565f63b08746c581630ab7a399d1a621334f0\n```. I think the file in resources gets compiled properly. Will close this task. Thank you!. \n",
    "ChristianOrgler": "@aledalgrande if you need help I would love to make some progress on connecting cocoapods usage with buck, just let me know if I can contribute in some way and where \ud83d\udc4d . @nikhilsh could you fix it?. ",
    "nikhilsh": "Would love to try out any solutions that you guys might have. I'm currently trying to compile a Swift project using Cocoapods with Buck. My BUCK file looks like this:\n```# iOS\napple_asset_catalog(\n  name = 'FjordAssets',\n  dirs = ['Assets.xcassets'],\n)\napple_resource(\n  name = 'FjordResources',\n  dirs = [],\n  files = glob(['.png','.storyboard', '*.xib']),\n)\napple_library(\n    name = 'FjordPods',\n    preprocessor_flags = ['-fobjc-arc'],\n    srcs = glob([\n      '../Pods//*.m',\n      '../Pods//.mm',\n      '../Pods//*.swift',\n    ]),\n    exported_headers = glob([\n      '../Pods//.h',\n    ]),\n    frameworks = [\n    '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n    ],\n)\napple_binary(\n  name = 'FjordBinary',\n  configs = {\n    'Development': {\n    'PRODUCT_NAME' : 'Fjord',\n    'PRODUCT_MODULE_NAME' : 'Fjord-iOS',\n    'CLANG_ENABLE_MODULES' : 'YES',\n'PROVISIONING_PROFILE_SPECIFIER' : '',\n'DEVELOPMENT_TEAM' : 'xxx',\n\n'ALWAYS_EMBED_SWIFT_STANDARD_LIBRARIES' : 'YES',\n'PRODUCT_BUNDLE_IDENTIFIER' : 'xxxx',\n'ONLY_ACTIVE_ARCH' : 'YES',\n'CODE_SIGN_ENTITLEMENTS' : 'Fjord.entitlements',\n'SWIFT_OPTIMIZATION_LEVEL' : '-Onone',\n'GCC_OPTIMIZATION_LEVEL' : '0',\n'VALIDATE_PRODUCT' : 'NO',\n},\n\n},\n  deps = [\n    ':FjordAssets',\n    ':FjordResources',\n    ':FjordPods',\n  ],\n  preprocessor_flags = [\n    '-fobjc-arc',\n    '-fno-objc-arc-exceptions',\n    '-Qunused-arguments',\n  ],\n  srcs = glob([\n    '.m',\n    '.mm',\n    '.swift',\n  ]),\n  headers = glob([\n    '.h',\n  ]),\n  bridging_header = 'Fjord-Bridging-Header.h',\n  frameworks = [\n    '$SDKROOT/System/Library/Frameworks/SystemConfiguration.framework',\n    '$SDKROOT/System/Library/Frameworks/OpenGLES.framework',\n    '$SDKROOT/System/Library/Frameworks/AVFoundation.framework',\n    '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n    '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMotion.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreLocation.framework',\n    '$SDKROOT/System/Library/Frameworks/MobileCoreServices.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMedia.framework',\n  ],\n  visibility = ['PUBLIC'],\n)\napple_bundle(\n  name = 'Fjord',\n  binary = ':FjordBinary',\n  extension = 'app',\n  info_plist = 'Info.plist',\n)\napple_package(\n  name = 'FjordPackage',\n  bundle = ':Fjord',\n)\n```\nand I'm getting the following error:\nerror: no such module 'Alamofire'\nimport Alamofire\n       ^\nBUILD FAILED: //Fjord-iOS:FjordBinary#iphonesimulator-x86_64,swift-compile failed with exit code 1:\nswift compile\nnot sure where I'm going wrong. Any ideas?. Nope I did not. I placed the BUCK file one level higher, but I'm getting the same error again \ud83d\ude22 . Nope there isn't a crash report there.\nIn any case, the console's log from launching the app to the crash can be found here: https://gist.github.com/nikhilsh/8d9f7dc7196970ea541f580052ad4f83. @robbertvanginkel In the last few lines of my original comment, I did paste in the simulator log, if that is what you're referring to. I wasn't sure if I should use prebuilt_apple_framework for Carthage frameworks, but that was what other developers seemed to be doing. . @robbertvanginkel Yep you're right.\n```Process:               Jarvis [99876]\nPath:                  /Users/USER/Library/Developer/CoreSimulator/Devices/3F116BC8-F7F1-4AC5-AC54-F1A7E7EDF8FE/data/Containers/Bundle/Application/53152810-2715-431F-A61A-926E2ABCACB3/Jarvis.app/Jarvis\nIdentifier:            Jarvis\nVersion:               3.0.2 (5)\nCode Type:             X86-64 (Native)\nParent Process:        launchd_sim [88742]\nResponsible:           Jarvis [99876]\nUser ID:               681489511\nDate/Time:             2017-05-12 11:06:06.040 +0800\nOS Version:            Mac OS X 10.12.4 (16E195)\nReport Version:        12\nAnonymous UUID:        D3659C15-A559-F637-895D-50EF2B276667\nSleep/Wake UUID:       8C946CBC-987F-4AC3-B0AB-ACC96A2A5540\nTime Awake Since Boot: 64000 seconds\nTime Since Wake:       2500 seconds\nSystem Integrity Protection: enabled\nCrashed Thread:        0\nException Type:        EXC_CRASH (SIGABRT)\nException Codes:       0x0000000000000000, 0x0000000000000000\nException Note:        EXC_CORPSE_NOTIFY\nTermination Reason:    DYLD, [0x1] Library missing\nApplication Specific Information:\ndyld: launch, loading dependent libraries\nDYLD_FALLBACK_LIBRARY_PATH=/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/usr/lib\nDYLD_ROOT_PATH=/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk\nDYLD_FALLBACK_FRAMEWORK_PATH=/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks\nDYLD_SHARED_REGION=avoid\nDyld Error Message:\n  Library not loaded: @rpath/Alamofire.framework/Alamofire\n  Referenced from: /Users/USER/Library/Developer/CoreSimulator/Devices/3F116BC8-F7F1-4AC5-AC54-F1A7E7EDF8FE/data/Containers/Bundle/Application/53152810-2715-431F-A61A-926E2ABCACB3/Jarvis.app/Jarvis\n  Reason: image not found\nBinary Images:\n       0x10e895000 -        0x10ec1eff7 +sg.com.xxx.jarvis (3.0.2 - 5)  /Users/USER/Library/Developer/CoreSimulator/Devices/3F116BC8-F7F1-4AC5-AC54-F1A7E7EDF8FE/data/Containers/Bundle/Application/53152810-2715-431F-A61A-926E2ABCACB3/Jarvis.app/Jarvis\n       0x10ecc1000 -        0x10ece91f7 +dyld_sim (433.8) <14AD0238-D077-378B-82A8-AC2D2ADC9DDF> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/usr/lib/dyld_sim\n       0x10ed32000 -        0x10eeeaffb  com.apple.avfoundation (2.0 - 1187.37.2.1)  /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/AVFoundation.framework/AVFoundation\n       0x10f0a2000 -        0x10f445fff  com.apple.CFNetwork (811.4.18 - 811.4.18) <2A3090B3-6B46-3D7E-9873-A347640F5CFE> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/CFNetwork.framework/CFNetwork\n       0x10f745000 -        0x10f7c0ff7  com.apple.corelocation (2101.0.62) <968B790E-5600-3884-85B7-362C28BDF0CA> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/CoreLocation.framework/CoreLocation\n       0x10f7e6000 -        0x10f85fffb  com.apple.CoreMedia (1.0 - 1907.59.2.5) <084059F9-BA6F-30FB-B762-BEB28491F031> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/CoreMedia.framework/CoreMedia\n       0x10f8d2000 -        0x10fa1cfff  com.apple.coremotion (2101.0.62) <9AD61504-57B4-364C-800E-01C55AC03BF7> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/CoreMotion.framework/CoreMotion\n       0x10fa64000 -        0x10fd43ffb  com.apple.Foundation (6.9 - 1349.54) <7D69BB8F-8AB9-3AB1-ADD6-BACB312CE32D> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/Foundation.framework/Foundation\n       0x10ff97000 -        0x1100beff7  com.apple.MobileCoreServices (775.2.37 - 775.2.37) <1941C856-FF06-38E9-9862-6075A37BAF55> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/MobileCoreServices.framework/MobileCoreServices\n       0x11018e000 -        0x11019aff3  com.apple.opengles (14.0.15 - 14.0.15) <6A99078B-1F06-386A-BBF0-3AC61F64A8D6> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/OpenGLES.framework/OpenGLES\n       0x1101a7000 -        0x110207ff7  com.apple.SystemConfiguration (1.14 - 1.14)  /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/SystemConfiguration.framework/SystemConfiguration\n       0x110235000 -        0x1110ccfff  com.apple.UIKit (1.0 - 1000) <3C74E187-F388-32B7-A167-056A6B9628BB> /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/System/Library/Frameworks/UIKit.framework/UIKit\n       0x11b0b5000 -        0x11b0f2dc7  dyld (433.5) <8239D0D7-66F6-3C44-A77F-586F74525DA3> /usr/lib/dyld\n```\nSo it seems like the Alamofire library was not copied over properly. Do you have any idea how should I go about doing it? I referenced various issues filed here to get a clue as to how to reference frameworks built by carthage but seems like I went down the wrong lane. @yiding thanks for the reply, and sorry for getting back so late. I think I tried out your proposed solution like so:\n```\napple_binary(\n  name = 'JarvisBinary',\n  configs = {\n    'Development': {\n    'PRODUCT_NAME' : 'Jarvis',\n    'PRODUCT_MODULE_NAME' : 'jarvis',\n    'CLANG_ENABLE_MODULES' : 'YES',\n    'PROVISIONING_PROFILE_SPECIFIER' : '',\n    'DEVELOPMENT_TEAM' : 'xxx',\n    'ALWAYS_EMBED_SWIFT_STANDARD_LIBRARIES' : 'YES',\n    'PRODUCT_BUNDLE_IDENTIFIER' : 'xxx',\n    'ONLY_ACTIVE_ARCH' : 'YES',\n    'CODE_SIGN_ENTITLEMENTS' : 'jarvis/jarvis.entitlements',\n    'SWIFT_OPTIMIZATION_LEVEL' : '-Onone',\n    'GCC_OPTIMIZATION_LEVEL' : '0',\n    'VALIDATE_PRODUCT' : 'NO',\n    },\n  },\n  preprocessor_flags = [\n    '-fobjc-arc',\n    '-fno-objc-arc-exceptions',\n    '-Qunused-arguments',\n  ],\n  srcs = glob([\n    'jarvis//*.m',\n    'jarvis//.mm',\n    'jarvis//*.swift',\n  ]),\n  headers = glob([\n    'jarvis//.h',\n  ]),\n  bridging_header = 'jarvis/Jarvis-Bridging-Header.h',\n  frameworks = [\n    '$SDKROOT/System/Library/Frameworks/SystemConfiguration.framework',\n    '$SDKROOT/System/Library/Frameworks/OpenGLES.framework',\n    '$SDKROOT/System/Library/Frameworks/AVFoundation.framework',\n    '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n    '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMotion.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreLocation.framework',\n    '$SDKROOT/System/Library/Frameworks/MobileCoreServices.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMedia.framework',\n    '$SDKROOT/System/Library/Frameworks/CFNetwork.framework',\n  ],\n  visibility = ['PUBLIC'],\n  deps = [\n    ':JarvisAssets',\n    ':JarvisResources',\n  ],\n)\napple_bundle(\n  name = 'Jarvis',\n  binary = ':JarvisBinary',\n  extension = 'app',\n  info_plist = 'jarvis/Info.plist',\n  deps = [\n    ':Mastercard',\n    ':Fabric',\n    ':Answers',\n    ':Nimble',\n    ':Quick',\n    ':Notification',\n    ':Sentry',\n    ':Crash',\n    ':AppleCalendar',\n    ':CryptoSwift',\n    ':JWT',\n    ':KeychainAccess',\n    ':PlatformAuth',\n    ':Alamofire',\n    ':AlamofireObjectMapper',\n    ':Charts',\n    ':EPSignature',\n    ':IQKeyboardManager',\n    ':IQKeyboardManagerSwift',\n    ':ObjectMapper',\n    ':calabash',\n  ],\n)\n``\n(moved theprebuilt_apple_frameworksfromapple_binarytoapple_bundle` deps field)\nI'm getting this error though:\n\nI'm pretty sure that Alamofire supports iphonesimulator-x86_64. I'm using buck version 05e85b081b4c0795d9d0204b74fd02ace0eecf31\nHmm, I'm still getting the same error upon adding the prebuilt_apple_frameworks to apple_binary like so: \n```\napple_binary(\n  name = 'JarvisBinary',\n  configs = {\n    'Development': {\n    'PRODUCT_NAME' : 'Jarvis',\n    'PRODUCT_MODULE_NAME' : 'jarvis',\n    'CLANG_ENABLE_MODULES' : 'YES',\n    'PROVISIONING_PROFILE_SPECIFIER' : '',\n    'DEVELOPMENT_TEAM' : 'xxx',\n    'ALWAYS_EMBED_SWIFT_STANDARD_LIBRARIES' : 'YES',\n    'PRODUCT_BUNDLE_IDENTIFIER' : 'xxx',\n    'ONLY_ACTIVE_ARCH' : 'YES',\n    'CODE_SIGN_ENTITLEMENTS' : 'jarvis/jarvis.entitlements',\n    'SWIFT_OPTIMIZATION_LEVEL' : '-Onone',\n    'GCC_OPTIMIZATION_LEVEL' : '0',\n    'VALIDATE_PRODUCT' : 'NO',\n    },\n  },\n  preprocessor_flags = [\n    '-fobjc-arc',\n    '-fno-objc-arc-exceptions',\n    '-Qunused-arguments',\n  ],\n  srcs = glob([\n    'jarvis//*.m',\n    'jarvis//.mm',\n    'jarvis//*.swift',\n  ]),\n  headers = glob([\n    'jarvis//.h',\n  ]),\n  bridging_header = 'jarvis/Jarvis-Bridging-Header.h',\n  frameworks = [\n    '$SDKROOT/System/Library/Frameworks/SystemConfiguration.framework',\n    '$SDKROOT/System/Library/Frameworks/OpenGLES.framework',\n    '$SDKROOT/System/Library/Frameworks/AVFoundation.framework',\n    '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n    '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMotion.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreLocation.framework',\n    '$SDKROOT/System/Library/Frameworks/MobileCoreServices.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMedia.framework',\n    '$SDKROOT/System/Library/Frameworks/CFNetwork.framework',\n  ],\n  visibility = ['PUBLIC'],\n  deps = [\n    ':JarvisAssets',\n    ':JarvisResources',\n    ':Mastercard',\n    ':Fabric',\n    ':Answers',\n    ':Nimble',\n    ':Quick',\n    ':Notification',\n    ':Sentry',\n    ':Crash',\n    ':AppleCalendar',\n    ':CryptoSwift',\n    ':JWT',\n    ':KeychainAccess',\n    ':PlatformAuth',\n    ':Alamofire',\n    ':AlamofireObjectMapper',\n    ':Charts',\n    ':EPSignature',\n    ':IQKeyboardManager',\n    ':IQKeyboardManagerSwift',\n    ':ObjectMapper',\n    ':calabash',\n  ],\n)\napple_bundle(\n  name = 'Jarvis',\n  binary = ':JarvisBinary',\n  extension = 'app',\n  info_plist = 'jarvis/Info.plist',\n  deps = [\n    ':Mastercard',\n    ':Fabric',\n    ':Answers',\n    ':Nimble',\n    ':Quick',\n    ':Notification',\n    ':Sentry',\n    ':Crash',\n    ':AppleCalendar',\n    ':CryptoSwift',\n    ':JWT',\n    ':KeychainAccess',\n    ':PlatformAuth',\n    ':Alamofire',\n    ':AlamofireObjectMapper',\n    ':Charts',\n    ':EPSignature',\n    ':IQKeyboardManager',\n    ':IQKeyboardManagerSwift',\n    ':ObjectMapper',\n    ':calabash',\n  ],\n)\n```. @gabrielzanoni Nope I was not able to. Thanks for the tip @gabrielzanoni! Looks like this issue is resolved then. I can't try it out as my team has gone back to using Cocoapods, but I'll close this issue for now. Thanks for the tip @gabrielzanoni! Looks like this issue is resolved then. I can't try it out as my team has gone back to using Cocoapods, but I'll close this issue for now. ",
    "gsabran": "How do you deal with pods that are not straightforwards? I'm struggling with Realms that has several files with the same name (SO). @aledalgrande did you find a way to generate BUCK files from Podspecs? I'm often coming across pods that are not just a bunch of headers but more complex libraries, with dependencies on other pods. It's been quite hard to find how to build them with BUCK so far. @aledalgrande did you find a way to generate BUCK files from Podspecs? I'm often coming across pods that are not just a bunch of headers but more complex libraries, with dependencies on other pods. It's been quite hard to find how to build them with BUCK so far. So it turns out Realm is really not a straightforwards pod, including submodules and some scripts to be run when generating the project.\nI think I've been able to deal with the header mappings, but that's not enough to get things to work. If you want to have a look I've set up a debug project trying:\n- building from the code downloaded with cocoapods (commit)\n- using the framework downloaded directly (commit)\nAre you planning for a direct support of Pod / Carthage so that modules imports is much simpler?. ",
    "makadaw": "We did everything manually :( But after this, we can use cocoapods for updates, just keep your BUCK files. Here is small post install hook\nbash\ngit diff --name-only --diff-filter=D | grep BUCK | xargs git checkout. We did everything manually :( But after this, we can use cocoapods for updates, just keep your BUCK files. Here is small post install hook\nbash\ngit diff --name-only --diff-filter=D | grep BUCK | xargs git checkout. I don't think it compiles intentdefinition, just add as a resource into intent and an app target, but yes, I can't also use BUCK for autogenerations step.. ",
    "timofticiuc": "Thanks dude, thought i was losing my mind. So as i see it, it's either let them link as static libraries or wait for #983 to be merged. ",
    "RPallas92": "Is it now possible to generate a .framework that can be exported to Xcode app ?\nWe try to do it like:\n```\nload(\"//Config:buck_rule_macros.bzl\", \"apple_lib\", \"apple_pod_lib\")\nload(\"//Config:configs.bzl\", \"info_plist_substitutions\")\napple_pod_lib(\n    name = \"Shared\",\n    srcs = glob([\n        \"/.swift\",\n    ]),\n        supported_platforms_regex = '^(iphoneos|iphonesimulator).',\n        exported_headers = glob([\n            \"/*.h\",\n        ]),\n        swift_version = \"4.2\",\n        deps = [\n            \"//Frameworks:PromiseKit\",\n            \"//Frameworks:RealmSwift\",\n            \"//Frameworks:AdyenCSE\",\n            \"//Frameworks:BlurKit\",\n            \"//Frameworks:Differ\",\n            \"//Frameworks:Lottie\",\n            \"//Frameworks:nanopb\",\n            \"//Frameworks:netfox\",\n            \"//Frameworks:Nuke\",\n            \"//Frameworks:Protobuf\",\n            \"//Frameworks:Realm\",\n            \"//Frameworks:Starscream\",\n            \"//Frameworks:SwiftyBeaver\",\n            \"//Frameworks:Swinject\",\n            \"//Frameworks:ZXingObjC\",\n            \"//LegacyDependencies/AdidasUINew:AdidasUINew\",\n            \"//LegacyDependencies/TrackingCore:TrackingCore\",\n            \"//LegacyDependencies/AdidasUI:adidasUI\",\n            \"//LegacyDependencies/PhoneNumberKit:PhoneNumberKit\",\n            \"//LegacyDependencies/StoreFinder:StoreFinder\",\n            \"//LegacyDependencies/ConfirmedCore:ConfirmedCore\",\n            \"//LegacyDependencies/CustomerChatCore:CustomerChatCore\",\n            \"//LegacyDependencies/CustomerChatUI:CustomerChatUI\",\n            \":SharedAssets\"\n    ],\n        link_style = 'shared',\n        header_path_prefix = 'ObjcFramework',\n)\napple_resource(\n    name = \"SharedResources\",\n    visibility = [\"PUBLIC\"],\n    files = glob([\n            \"/*.xib\",\n            \"/*.storyboard\",\n        ]),\n)\napple_asset_catalog(\n    name = \"SharedAssets\",\n    visibility = [\"PUBLIC\"],\n    dirs = glob([\"*/.xcassets\"]),\n)\napple_bundle(\n    name = \"SharedBundle\",\n    visibility = [\n        \"PUBLIC\",\n    ],\n    extension = \"framework\",\n    binary = \":Shared#static\",\n    product_name = \"Shared\",\n    info_plist = \"Info.plist\",\n        deps = [\n        \":SharedResources\",\n    ],\n        info_plist_substitutions = info_plist_substitutions(\"Shared\"),\n)\n```\nthe frameworks gets build, but I can't be imported from Xcode code\n. Is it now possible to generate a .framework that can be exported to Xcode app ?\nWe try to do it like:\n```\nload(\"//Config:buck_rule_macros.bzl\", \"apple_lib\", \"apple_pod_lib\")\nload(\"//Config:configs.bzl\", \"info_plist_substitutions\")\napple_pod_lib(\n    name = \"Shared\",\n    srcs = glob([\n        \"/.swift\",\n    ]),\n        supported_platforms_regex = '^(iphoneos|iphonesimulator).',\n        exported_headers = glob([\n            \"/*.h\",\n        ]),\n        swift_version = \"4.2\",\n        deps = [\n            \"//Frameworks:PromiseKit\",\n            \"//Frameworks:RealmSwift\",\n            \"//Frameworks:AdyenCSE\",\n            \"//Frameworks:BlurKit\",\n            \"//Frameworks:Differ\",\n            \"//Frameworks:Lottie\",\n            \"//Frameworks:nanopb\",\n            \"//Frameworks:netfox\",\n            \"//Frameworks:Nuke\",\n            \"//Frameworks:Protobuf\",\n            \"//Frameworks:Realm\",\n            \"//Frameworks:Starscream\",\n            \"//Frameworks:SwiftyBeaver\",\n            \"//Frameworks:Swinject\",\n            \"//Frameworks:ZXingObjC\",\n            \"//LegacyDependencies/AdidasUINew:AdidasUINew\",\n            \"//LegacyDependencies/TrackingCore:TrackingCore\",\n            \"//LegacyDependencies/AdidasUI:adidasUI\",\n            \"//LegacyDependencies/PhoneNumberKit:PhoneNumberKit\",\n            \"//LegacyDependencies/StoreFinder:StoreFinder\",\n            \"//LegacyDependencies/ConfirmedCore:ConfirmedCore\",\n            \"//LegacyDependencies/CustomerChatCore:CustomerChatCore\",\n            \"//LegacyDependencies/CustomerChatUI:CustomerChatUI\",\n            \":SharedAssets\"\n    ],\n        link_style = 'shared',\n        header_path_prefix = 'ObjcFramework',\n)\napple_resource(\n    name = \"SharedResources\",\n    visibility = [\"PUBLIC\"],\n    files = glob([\n            \"/*.xib\",\n            \"/*.storyboard\",\n        ]),\n)\napple_asset_catalog(\n    name = \"SharedAssets\",\n    visibility = [\"PUBLIC\"],\n    dirs = glob([\"*/.xcassets\"]),\n)\napple_bundle(\n    name = \"SharedBundle\",\n    visibility = [\n        \"PUBLIC\",\n    ],\n    extension = \"framework\",\n    binary = \":Shared#static\",\n    product_name = \"Shared\",\n    info_plist = \"Info.plist\",\n        deps = [\n        \":SharedResources\",\n    ],\n        info_plist_substitutions = info_plist_substitutions(\"Shared\"),\n)\n```\nthe frameworks gets build, but I can't be imported from Xcode code\n. Running buck instal with verbosity level 8:\n```\n$ buck  install //App:ExampleAppBundle --run --verbose 8                               ()\n[2019-01-09 10:24:30.599][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.util.environment.MacWifiSsidFinder] Getting current SSID..\n[2019-01-09 10:24:30.600][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.util.environment.MacWifiSsidFinder] Getting SSID from Wi-Fi interface:  [interfaceName=en0]\n[2019-01-09 10:24:30.601][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.util.environment.MacWifiSsidFinder] Found SSID: adi_connect\n[2019-01-09 10:24:30.601][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.cli.Main] InvocationInfo BuildId=[f98a69c4-0236-489d-924b-0135d7aee5ed] Args=[install, //App:ExampleAppBundle, --run, --verbose, 8]\n[2019-01-09 10:24:32.303][info ][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:222][com.facebook.buck.event.listener.LoggingBuildListener] Build started at 2019-01-09 10:24:32.303\n[2019-01-09 10:24:32.311][info ][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.core.model.actiongraph.computation.ActionGraphProvider] ActionGraph cache hit.\n[2019-01-09 10:24:32.312][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.core.build.engine.impl.MetadataChecker] Checking metadata_storage for /Users/pallaric/Documents/Mobile/projects/training/BuckSample\nPARSING BUCK FILES: FINISHED IN 0.0s\nCREATING ACTION GRAPH: FINISHED IN 0.0s\n[2019-01-09 10:24:32.337][warn ][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:232][com.facebook.buck.rules.keys.RuleKeyBuilder] Attempting to add absolute path to rule key. Only using file name: /usr/bin/codesign\nFOUND 1/1 JOBS 0.0s //App:ExampleAppBundle#dwarf-and-dsym,no-include-frameworks\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES, 0.0% CACHE MISS\nBUILDING: FINISHED IN 0.0s (100%) 1/1 JOBS, 0 UPDATED\nBUILD SUCCEEDED\n[2019-01-09 10:24:32.353][info ][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:222][com.facebook.buck.event.listener.LoggingBuildListener] Build finished at 2019-01-09 10:24:32.351\n[2019-01-09 10:24:32.399][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleCoreSimulatorServiceController] Getting list of services with [launchctl, list]\n[2019-01-09 10:24:32.422][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleCoreSimulatorServiceController] Found matching service name: com.apple.CoreSimulator.CoreSimulatorService\n[2019-01-09 10:24:32.423][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleCoreSimulatorServiceController] Getting status of service com.apple.CoreSimulator.CoreSimulatorService with [launchctl, print, user/1887745167/com.apple.CoreSimulator.CoreSimulatorService]\n[2019-01-09 10:24:32.445][warn ][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.cli.InstallCommand] Core simulator service path Optional.empty does not match developer directory /Applications/Xcode.app/Contents/Developer, killing all simulators.\n[2019-01-09 10:24:32.446][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleCoreSimulatorServiceController] Getting list of services with [launchctl, list]\n[2019-01-09 10:24:32.461][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleCoreSimulatorServiceController] Found matching service name: com.apple.CoreSimulator.CoreSimulatorService\n[2019-01-09 10:24:32.462][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleCoreSimulatorServiceController] Killing simulator services: [com.apple.CoreSimulator.CoreSimulatorService]\n[2019-01-09 10:24:32.462][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleCoreSimulatorServiceController] Killing simulator process with with [launchctl, remove, com.apple.CoreSimulator.CoreSimulatorService]\n[2019-01-09 10:24:32.479][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleCoreSimulatorServiceController] Command ProcessExecutorParams{command=[launchctl, remove, com.apple.CoreSimulator.CoreSimulatorService]} exited with code 0\n[2019-01-09 10:24:32.480][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.cli.InstallCommand] Choosing simulator for //App:ExampleAppBundle#dwarf-and-dsym,no-include-frameworks\n[2019-01-09 10:24:32.480][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleSimulatorDiscovery] Running xcrun simctl list to get list of simulators\n[2019-01-09 10:24:33.405][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: == Device Types ==\n[2019-01-09 10:24:33.405][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 4s (com.apple.CoreSimulator.SimDeviceType.iPhone-4s)\n[2019-01-09 10:24:33.406][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 4s (com.apple.CoreSimulator.SimDeviceType.iPhone-4s)\n[2019-01-09 10:24:33.406][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 5 (com.apple.CoreSimulator.SimDeviceType.iPhone-5)\n[2019-01-09 10:24:33.406][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 5 (com.apple.CoreSimulator.SimDeviceType.iPhone-5)\n[2019-01-09 10:24:33.407][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 5s (com.apple.CoreSimulator.SimDeviceType.iPhone-5s)\n[2019-01-09 10:24:33.407][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 5s (com.apple.CoreSimulator.SimDeviceType.iPhone-5s)\n[2019-01-09 10:24:33.407][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 6 (com.apple.CoreSimulator.SimDeviceType.iPhone-6)\n[2019-01-09 10:24:33.407][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 6 (com.apple.CoreSimulator.SimDeviceType.iPhone-6)\n[2019-01-09 10:24:33.407][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 6 Plus (com.apple.CoreSimulator.SimDeviceType.iPhone-6-Plus)\n[2019-01-09 10:24:33.408][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 6 Plus (com.apple.CoreSimulator.SimDeviceType.iPhone-6-Plus)\n[2019-01-09 10:24:33.408][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 6s (com.apple.CoreSimulator.SimDeviceType.iPhone-6s)\n[2019-01-09 10:24:33.408][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 6s (com.apple.CoreSimulator.SimDeviceType.iPhone-6s)\n[2019-01-09 10:24:33.408][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 6s Plus (com.apple.CoreSimulator.SimDeviceType.iPhone-6s-Plus)\n[2019-01-09 10:24:33.409][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 6s Plus (com.apple.CoreSimulator.SimDeviceType.iPhone-6s-Plus)\n[2019-01-09 10:24:33.409][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 7 (com.apple.CoreSimulator.SimDeviceType.iPhone-7)\n[2019-01-09 10:24:33.409][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 7 (com.apple.CoreSimulator.SimDeviceType.iPhone-7)\n[2019-01-09 10:24:33.409][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 7 Plus (com.apple.CoreSimulator.SimDeviceType.iPhone-7-Plus)\n[2019-01-09 10:24:33.410][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 7 Plus (com.apple.CoreSimulator.SimDeviceType.iPhone-7-Plus)\n[2019-01-09 10:24:33.410][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 8 (com.apple.CoreSimulator.SimDeviceType.iPhone-8)\n[2019-01-09 10:24:33.410][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 8 (com.apple.CoreSimulator.SimDeviceType.iPhone-8)\n[2019-01-09 10:24:33.411][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 8 Plus (com.apple.CoreSimulator.SimDeviceType.iPhone-8-Plus)\n[2019-01-09 10:24:33.411][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone 8 Plus (com.apple.CoreSimulator.SimDeviceType.iPhone-8-Plus)\n[2019-01-09 10:24:33.411][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone SE (com.apple.CoreSimulator.SimDeviceType.iPhone-SE)\n[2019-01-09 10:24:33.411][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone SE (com.apple.CoreSimulator.SimDeviceType.iPhone-SE)\n[2019-01-09 10:24:33.412][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone X (com.apple.CoreSimulator.SimDeviceType.iPhone-X)\n[2019-01-09 10:24:33.412][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone X (com.apple.CoreSimulator.SimDeviceType.iPhone-X)\n[2019-01-09 10:24:33.412][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone Xs (com.apple.CoreSimulator.SimDeviceType.iPhone-XS)\n[2019-01-09 10:24:33.412][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone Xs (com.apple.CoreSimulator.SimDeviceType.iPhone-XS)\n[2019-01-09 10:24:33.412][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone Xs Max (com.apple.CoreSimulator.SimDeviceType.iPhone-XS-Max)\n[2019-01-09 10:24:33.413][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone Xs Max (com.apple.CoreSimulator.SimDeviceType.iPhone-XS-Max)\n[2019-01-09 10:24:33.413][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone X\u0280 (com.apple.CoreSimulator.SimDeviceType.iPhone-XR)\n[2019-01-09 10:24:33.413][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPhone X\u0280 (com.apple.CoreSimulator.SimDeviceType.iPhone-XR)\n[2019-01-09 10:24:33.413][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad 2 (com.apple.CoreSimulator.SimDeviceType.iPad-2)\n[2019-01-09 10:24:33.414][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad 2 (com.apple.CoreSimulator.SimDeviceType.iPad-2)\n[2019-01-09 10:24:33.414][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Retina (com.apple.CoreSimulator.SimDeviceType.iPad-Retina)\n[2019-01-09 10:24:33.414][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Retina (com.apple.CoreSimulator.SimDeviceType.iPad-Retina)\n[2019-01-09 10:24:33.414][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Air (com.apple.CoreSimulator.SimDeviceType.iPad-Air)\n[2019-01-09 10:24:33.414][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Air (com.apple.CoreSimulator.SimDeviceType.iPad-Air)\n[2019-01-09 10:24:33.419][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Air 2 (com.apple.CoreSimulator.SimDeviceType.iPad-Air-2)\n[2019-01-09 10:24:33.420][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Air 2 (com.apple.CoreSimulator.SimDeviceType.iPad-Air-2)\n[2019-01-09 10:24:33.420][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad (5th generation) (com.apple.CoreSimulator.SimDeviceType.iPad--5th-generation-)\n[2019-01-09 10:24:33.420][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad (5th generation) (com.apple.CoreSimulator.SimDeviceType.iPad--5th-generation-)\n[2019-01-09 10:24:33.420][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (9.7-inch) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--9-7-inch-)\n[2019-01-09 10:24:33.420][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (9.7-inch) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--9-7-inch-)\n[2019-01-09 10:24:33.421][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (12.9-inch) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro)\n[2019-01-09 10:24:33.421][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (12.9-inch) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro)\n[2019-01-09 10:24:33.421][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (12.9-inch) (2nd generation) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--12-9-inch---2nd-generation-)\n[2019-01-09 10:24:33.421][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (12.9-inch) (2nd generation) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--12-9-inch---2nd-generation-)\n[2019-01-09 10:24:33.422][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (10.5-inch) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--10-5-inch-)\n[2019-01-09 10:24:33.422][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (10.5-inch) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--10-5-inch-)\n[2019-01-09 10:24:33.422][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad (6th generation) (com.apple.CoreSimulator.SimDeviceType.iPad--6th-generation-)\n[2019-01-09 10:24:33.423][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad (6th generation) (com.apple.CoreSimulator.SimDeviceType.iPad--6th-generation-)\n[2019-01-09 10:24:33.423][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (11-inch) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--11-inch-)\n[2019-01-09 10:24:33.426][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (11-inch) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--11-inch-)\n[2019-01-09 10:24:33.426][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (12.9-inch) (3rd generation) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--12-9-inch---3rd-generation-)\n[2019-01-09 10:24:33.426][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iPad Pro (12.9-inch) (3rd generation) (com.apple.CoreSimulator.SimDeviceType.iPad-Pro--12-9-inch---3rd-generation-)\n[2019-01-09 10:24:33.427][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple TV (com.apple.CoreSimulator.SimDeviceType.Apple-TV-1080p)\n[2019-01-09 10:24:33.427][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple TV 4K (com.apple.CoreSimulator.SimDeviceType.Apple-TV-4K-4K)\n[2019-01-09 10:24:33.427][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple TV 4K (at 1080p) (com.apple.CoreSimulator.SimDeviceType.Apple-TV-4K-1080p)\n[2019-01-09 10:24:33.427][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple Watch - 38mm (com.apple.CoreSimulator.SimDeviceType.Apple-Watch-38mm)\n[2019-01-09 10:24:33.428][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple Watch - 42mm (com.apple.CoreSimulator.SimDeviceType.Apple-Watch-42mm)\n[2019-01-09 10:24:33.428][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple Watch Series 2 - 38mm (com.apple.CoreSimulator.SimDeviceType.Apple-Watch-Series-2-38mm)\n[2019-01-09 10:24:33.428][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple Watch Series 2 - 42mm (com.apple.CoreSimulator.SimDeviceType.Apple-Watch-Series-2-42mm)\n[2019-01-09 10:24:33.428][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple Watch Series 3 - 38mm (com.apple.CoreSimulator.SimDeviceType.Apple-Watch-Series-3-38mm)\n[2019-01-09 10:24:33.429][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple Watch Series 3 - 42mm (com.apple.CoreSimulator.SimDeviceType.Apple-Watch-Series-3-42mm)\n[2019-01-09 10:24:33.429][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple Watch Series 4 - 40mm (com.apple.CoreSimulator.SimDeviceType.Apple-Watch-Series-4-40mm)\n[2019-01-09 10:24:33.429][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: Apple Watch Series 4 - 44mm (com.apple.CoreSimulator.SimDeviceType.Apple-Watch-Series-4-44mm)\n[2019-01-09 10:24:33.430][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: == Runtimes ==\n[2019-01-09 10:24:33.430][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iOS 10.0 (10.0 - 14A345) - com.apple.CoreSimulator.SimRuntime.iOS-10-0\n[2019-01-09 10:24:33.430][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iOS 10.2 (10.2 - 14C89) - com.apple.CoreSimulator.SimRuntime.iOS-10-2\n[2019-01-09 10:24:33.431][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iOS 12.0 (12.0 - 16A366) - com.apple.CoreSimulator.SimRuntime.iOS-12-0\n[2019-01-09 10:24:33.431][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: iOS 12.1 (12.1 - 16B91) - com.apple.CoreSimulator.SimRuntime.iOS-12-1\n[2019-01-09 10:24:33.431][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: tvOS 12.1 (12.1 - 16J602) - com.apple.CoreSimulator.SimRuntime.tvOS-12-1\n[2019-01-09 10:24:33.431][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: watchOS 5.1 (5.1 - 16R591) - com.apple.CoreSimulator.SimRuntime.watchOS-5-1\n[2019-01-09 10:24:33.432][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: == Devices ==\n[2019-01-09 10:24:33.432][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: -- iOS 10.0 --\n[2019-01-09 10:24:33.432][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line:     iPhone 5 (A680A962-39E8-4263-A937-346909B54882) (Shutdown)\n[2019-01-09 10:24:33.433][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: -- iOS 10.2 --\n[2019-01-09 10:24:33.433][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: -- iOS 12.0 --\n[2019-01-09 10:24:33.433][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line:     iPhone 7 (3DB7D4DE-5D37-428F-9EA0-DC57C80971F5) (Shutdown)\n[2019-01-09 10:24:33.433][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: -- iOS 12.1 --\n[2019-01-09 10:24:33.433][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line:     iPhone 6 (E981B42B-CB14-4EC4-BEC3-823C990309BD) (Shutdown)\n[2019-01-09 10:24:33.434][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line:     iPhone X (D642276F-C4F2-4A99-A102-56C81729B8F7) (Shutdown)\n[2019-01-09 10:24:33.434][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: -- tvOS 12.1 --\n[2019-01-09 10:24:33.437][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: -- watchOS 5.1 --\n[2019-01-09 10:24:33.437][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line: == Device Pairs ==\n[2019-01-09 10:24:33.437][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.SimctlListOutputParsing] Parsing simctl list output line:\n[2019-01-09 10:24:33.438][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.apple.simulator.AppleSimulatorDiscovery] Discovered simulators: []\n[2019-01-09 10:24:33.438][warn ][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:14][com.facebook.buck.util.Console] Build failure: Cannot install //App:ExampleAppBundle#dwarf-and-dsym,no-include-frameworks (no appropriate simulator found)\nBUILD FAILED: Cannot install //App:ExampleAppBundle#dwarf-and-dsym,no-include-frameworks (no appropriate simulator found)\nINSTALLING: FINISHED IN 1.1s\n[2019-01-09 10:24:33.439][debug][command:f98a69c4-0236-489d-924b-0135d7aee5ed][tid:217][com.facebook.buck.util.perf.ProcessTracker] shutDown\n```. ",
    "krossford": "So....I can run buck on windows without any problem? @ryu2 . ",
    "samjoch": "@fkorotkov it seems that your .buckversion file is too old. (here for more info) ;-). @fkorotkov you should replace buck-out, \\ with buck-out here.\nI noticed the ini validator mixup the cache section value with the project section values.. ",
    "ccascone": "Hi @Coneko is there any chance support for thrift target types will be added again soon? If not, why was it removed in the first place?. Hi @Coneko is there any chance support for thrift target types will be added again soon? If not, why was it removed in the first place?. @Coneko that would be great, thank you!. @Coneko that would be great, thank you!. @Coneko any chance you can publish somewhere your build defs for building with thrift?. ",
    "supercoolgreatcoder": "any update on this? thrift_library() rule was essential feature of buck build. . ",
    "Skilence": "Proxy requires permission authentication, but can not find the place to set username and password..\nSo:\n[2017-03-27 14:21:18.352][info ][command:58d59f82-ee71-4f04-be9c-83b3385bd7c9][tid:27][com.facebook.buck.file.HttpDownloader] Unable to download https://oss.sonatype.org/content/repositories/snapshots/org/projectfloodlight/openflowj/3.0.0-SNAPSHOT/openflowj-3.0.0-20161029.095322-40.jar: authenticationrequired\n. @Coneko Thanks for your help!\nI can download maven file because we have the maven mirrors, but other files  need to be downloaded by proxy. So set the credentials can not solve the problem.\nI try to download the jar file by manual and put them to buck-out/bin or buck-out/gen dir, but it didn't work. Do you know how to  handle it?. ",
    "alexshtin": "@brettwooldridge, can you share your code snippet?. ",
    "revolter": "Same problem in different library \ud83d\ude22 . Same problem in different library \ud83d\ude22 . ",
    "icandoitbig": "Any solution for this issue. @ProfessaA @revolter . ",
    "ramubhai": "Got same error.\nPython 2.7 and 3.6 are both installed on my windows 10 laptop. Edited the PATH variable to include the python 2.7 path above the 3.6 one and now it's running fine.. ",
    "zoom2manoj": "I'm also getting this issue as below commends : \nTraceback (most recent call last):\n  File \"D:\\react_native\\test_cases\\buck\\bin\\..\\programs\\buck.py\", line 8, in <mo\ndule>\n    from buck_tool import BuckToolException, RestartBuck, install_signal_handler\ns\n  File \"D:\\react_native\\test_cases\\buck\\programs\\buck_tool.py\", line 15, in <mod\nule>\n    from pynailgun import NailgunConnection, NailgunException\n  File \"D:\\react_native\\test_cases\\buck\\third-party\\nailgun\\pynailgun\\__init__.p\ny\", line 1, in <module>\n    from ng import NailgunConnection, NailgunException\nModuleNotFoundError: No module named 'ng'\nCan anyone please suggest me what am I missing during installation. \nThanks in advance!. Thanks for your support @JoelMarcey . Thanks for your support @JoelMarcey . ",
    "cjhopman": "It could be related to rulekey caching if disabling actiongraph caching doesn't have the problem.. This is only used for exo-for-resources. It only supports package id of 0x7f because that's the only thing that aapt writes by default.\nBut what are you trying to do? I really can't tell if this code is even relevant to you.. This is only used for exo-for-resources. It only supports package id of 0x7f because that's the only thing that aapt writes by default.\nBut what are you trying to do? I really can't tell if this code is even relevant to you.. Yeah, this should definitely be fixed. It's always behaved this way right? It's not a regression?. What we've tended to do for this is to create a directory \"mode/\" that contains files of command line args that configure buck in different ways.\nFor example, have a file at mode/android-26 that just contains\n--config\nandroid.target=android-26\nand then invoke buck like buck build @mode/android-26 //my/fancy:apk.\nThe biggest reason that we are hesitant to add the ability to configure this at the apk level is that it affects the entire build graph underneath that apk and it makes it easy to accidentally greatly increase build costs.. Should be a straightforward fix, the test apk just needs a runtime dep on the tested apk.. @kageiit it should.. @brettwooldridge We found some issues with alignment on some platforms. I think it was an easy fix. @styurin should know more (and I think he reached out to you directly on slack).. @brettwooldridge We found some issues with alignment on some platforms. I think it was an easy fix. @styurin should know more (and I think he reached out to you directly on slack).. @brettwooldridge we got reports that https://github.com/brettwooldridge/NuProcess/commit/4989a9edc2a8f0dbed19bc03b9dfaa6a0963067d#diff-9973b36943d6182ee7db84c55a8cf709R49 broke on aarch64. They said that nuprocess's own tests hang after that change.\nThe report indicated that the nuprocess epoll_data structure is 8 bytes, but on aarch64 it should be 16 bytes. \nAlso, they indicated that changing the alignment back to ALIGN_GNUC resolved the issue.\nI can reach out to them if you need more information.. Are the stringified args being added to the rulekey? That doesn't seem right.. Ok, here's what happens:\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/rules/args/WriteToFileArg.java#L35 adds prefix to rulekey\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/rules/macros/AbstractStringWithMacrosConverter.java#L124 computes that including the macro hashCode()\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/rules/macros/AbstractClasspathAbiMacro.java is a BuildTargetMacro. It's hashCode is then just basically target.hashCode();\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/model/AbstractBuildTarget.java#L50 will include the unflavored buildtarget's hashCode\nhttps://github.com/facebook/buck/blob/master/src/com/facebook/buck/model/AbstractUnflavoredBuildTarget.java#L71 includes the absolute path of the cell in its hashCode.. I think we'd need more information, we haven't seen any such regression on very large iOS builds and I don't really see how this would cause such a regression.\nCould you compare (or even better, share) build traces from these builds to get some better idea of what regressed?. Maybe @brettwooldridge or @cwoodwar6 know.. Can you write a binary that converts g++ flags to something that your compiler understands and then forward to your real compiler? Then you could just specify that binary as your compiler.. What you wrote under \"I expect\" is exactly what happens, though, isn't it? An exe expanded in a genrule isn't going to propagate the cxx platform from some random cxx_library that depends on it, it's going to use the builds default platform.. ",
    "renchiyansc": "@kageiit @aiked . ",
    "deadmoto": "Hitting the same error message with prebuilt jars.\nThe recipe described in the linked issue (java_library + remove_classes) did not work for me.\nMy dependencies are set up as following:\n//app:apk (android_binary) -> //libs:mockito-core (java_library + remove_classes) -> //libs/mockito-core-jar (prebuilt_jar)\nUPDATE: I got it wrong at the beginning, finally I got it to work.\nHere is a basic snippet in case someone needs it:\nhttps://gist.github.com/deadmoto/8f8468fe30386b444402da6c21365fbc. Hitting the same error message with prebuilt jars.\nThe recipe described in the linked issue (java_library + remove_classes) did not work for me.\nMy dependencies are set up as following:\n//app:apk (android_binary) -> //libs:mockito-core (java_library + remove_classes) -> //libs/mockito-core-jar (prebuilt_jar)\nUPDATE: I got it wrong at the beginning, finally I got it to work.\nHere is a basic snippet in case someone needs it:\nhttps://gist.github.com/deadmoto/8f8468fe30386b444402da6c21365fbc. ",
    "mustafasc": "@Coneko - Can you elaborate on how Buck will bundle built Java classes into PEX (my assumption was that it's for bundling Python code)? \nIf there is already documentation on the details, that'd be great. \nThanks!. @Coneko - Can you elaborate on how Buck will bundle built Java classes into PEX (my assumption was that it's for bundling Python code)? \nIf there is already documentation on the details, that'd be great. \nThanks!. ",
    "voznesenskym": "Confirmed - Ditto for us. Let me know if you need an example project created. . Confirmed - Ditto for us. Let me know if you need an example project created. . cc @Mmatheson, we found this together.. Will do, but should be ok :) Just need to get a little better at figuring out how BUCK parses the files, and then I should be able to hook it all up. . @asp2insp \nNVM. The parsing fucked my shit up pretty good.\npublic static CxxLinkAndCompileRules createBuildRulesForCxxBinaryDescriptionArg\nWhere do args come from for that? I would like to add a new one. \nI guess i have all the pieces here, the critical piece of logic is:\nLinker.LinkableDepType linkStyle = args.getLinkStyle().orElse(\n        args.getStaticPicLib().isPresent()\n            ? Linker.LinkableDepType.STATIC_PIC\n            : Linker.LinkableDepType.STATIC);\nHowever, I have no idea how to get the current staticPicLib at that point. I know it is there because at\npublic NativeLinkable.Linkage getPreferredLinkage(CxxPlatform cxxPlatform) {\nif I log what I have, I can see the values.\nPrebuiltCxxLibraryDescriptionArg{staticPicLib=/Users/michaelvoznesensky/Uber/mapdisplay/libs/linux/x86/libicu/libicuuc_pic.a, headerOnly=false, exportedHeaders=SourceList{type=UNNAMED, unnamedSources=[]}, exportedPlatformHeaders=com.facebook.buck.rules.coercer.PatternMatchedCollection@1, headerNamespace=, provided=false, linkWhole=false, forceStatic=false, exportedPreprocessorFlags=[], exportedPlatformPreprocessorFlags=com.facebook.buck.rules.coercer.PatternMatchedCollection@1, exportedLangPreprocessorFlags={}, exportedLinkerFlags=[], exportedPlatformLinkerFlags=com.facebook.buck.rules.coercer.PatternMatchedCollection@1, linkWithoutSoname=false, canBeAsset=false, frameworks=[], libraries=[], exportedDeps=[//libs:icuuc_headers], supportsSharedLibraryInterface=false, labels=[], licenses=[], name=icu, deps=[]}\n. Ahh, thats exactly where I had but I missed the decorator! Thanks, will try. . Ahh, thats exactly where I had but I missed the decorator! Thanks, will try. . Fixed it. PR after beer.. Fixed it. PR after beer.. @asp2insp PR is up. It does not appear as though I have permissions to resolve conflicts or push. LMK what next steps are.. @asp2insp PR is up. It does not appear as though I have permissions to resolve conflicts or push. LMK what next steps are.. The lib mentioned above is indeed PIC enabled. I can make an example\nproject if you like.\nOn Mon, Oct 9, 2017 at 11:01 PM andrewjcg notifications@github.com wrote:\n\nSorry, I think I'm missing some additional context here. From the original\nissue mentioned above, it sounds like the original libicuuc.a library is\nnot PIC-enabled, yet you're specifying it via the static_pic_lib (this\nfield is only meant for prebuilt static archives which are PIC enabled)?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1538#issuecomment-335345972, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AEiPNBC4Qr92HE2EaNWqH21CuOcmk24gks5sqt4JgaJpZM4Phyn4\n.\n. The lib mentioned above is indeed PIC enabled. I can make an example\nproject if you like.\n\nOn Mon, Oct 9, 2017 at 11:01 PM andrewjcg notifications@github.com wrote:\n\nSorry, I think I'm missing some additional context here. From the original\nissue mentioned above, it sounds like the original libicuuc.a library is\nnot PIC-enabled, yet you're specifying it via the static_pic_lib (this\nfield is only meant for prebuilt static archives which are PIC enabled)?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1538#issuecomment-335345972, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AEiPNBC4Qr92HE2EaNWqH21CuOcmk24gks5sqt4JgaJpZM4Phyn4\n.\n. It will be a couple of weeks to make the example project. . Im at conferences, hence the delay in making a project. I cannot send you my current project as it belongs to Uber and not myself. Until then, more than happy to explain the bug further. \n\nlibiccuc.a is a full pic-enabled library. All my dependencies are.  The whole output of the BUCK target is a pic-enabled compiled lib inside a cxx binary. Let me know any and all questions you may have about what I am trying to do! . @asp2insp There are not actually conflicts\n```\n<<<<<<< michaelv/fix1538\n=======\n\n\n\n\n\n\n\nmaster\n```\n\n\n\n\n\n\n\nAs I fixed them by hand. Let me know what next steps are here!. @asp2insp There are not actually conflicts\n```\n<<<<<<< michaelv/fix1538\n=======\n\n\n\n\n\n\n\nmaster\n```\n\n\n\n\n\n\n\nAs I fixed them by hand. Let me know what next steps are here!. I am running it manually w/\n./scripts/check-java-file-format ~/my_path/google-java-format-1.4-all-deps.jar src/com/facebook/buck/cxx/CxxLibraryDescription.java \nAnd it produces no delta. What I am missing?. I am running it manually w/\n./scripts/check-java-file-format ~/my_path/google-java-format-1.4-all-deps.jar src/com/facebook/buck/cxx/CxxLibraryDescription.java \nAnd it produces no delta. What I am missing?. ",
    "varun531": "On a related note, is there any way to make Buck use a provisioning profile for simulator builds?\nI ask because it is the provisioning profile that gives my app access to things like the keychain when I build with XCode, and because provisioning profiles seem to be ignored for buck simulator builds, my app cannot access the keychain when running on a simulator.\nThis would also hinder one's ability to (say) set up an integration test suite that runs on a simulator.\nDo Facebook/Uber/etc... face a similar issue (lack of keychain access, other entitlements) when building their apps for the simulator, or am I missing something?\nAny help would be appreciated!. Hi,\nAppreciate the response @ryu2 \nSo the situation as I understand it is this:\n1) Buck does not currently insert entitlements into simulator builds\n2) It is theoretically possible to insert entitlements w/ linker flags\n3) However, using linker flags doesn't embed the exact entitlements that XCode would\nGiven (3), should I still try to manually pass in linker flags to enable keychain access for simulator builds? Something like this:\napple_binary(\n  name = 'MyBinary',\n  linker_flags = '-sectcreate __TEXT __entitlements /path/to/entitlements.xcent',\n  // Rest of apple_binary config\n )\nAnd this would only be for x86_64 builds, so as not to interfere/conflict with the signing that Buck does for device/app store builds, correct?. @ryu2 Thanks again, I've got it working now!\nFor those who run into this same issue, this was the syntax I needed to get the linker flags to work:\nplatform_linker_flags = [('iphonesimulator*',\n                         ['-Wl,-sectcreate,__TEXT,__entitlements,path/to/entitlements.xcent'])],. Hi,\nI'm trying to install and run an app on my physical device with a debugger attached. Is this currently supported? I try to run an app on my device with the following command:\nbuck install -d -r calc_free_app\nI've set \"device_helper_path\" in .buckconfig to point at homebrew-installed simctl v0.4.0. The app IS loaded onto my phone, but it's not running. This is some of my output:\nInstalled //:CalcFreeApp#dwarf-and-dsym,iphoneos-arm64,no-include-frameworks to device 7fa1437093100eaa5b36cfc5d38b6fb8ec3c897c (Varun iPhone  6s | Unknown | iPhone 6s | iOS 10.2.1 | arm64)\n'[\"--json\", \"7fa1437093100eaa5b36cfc5d38b6fb8ec3c897c\", \"launch\", \"secretcalcfree\"]' does not match '[fbsimctl {{ [output] | [management] | <set> | --set <directory> }}* [targets]? {{ <format> | --format <Target Format> }}? {{ [action] ... -- [action] }}+\nThen at the very end of the output:\nBUILD FAILED: Failed to run //:CalcFreeApp#dwarf-and-dsym,iphoneos-arm64,no-include-frameworks on device \"7fa1437093100eaa5b36cfc5d38b6fb8ec3c897c\" (Varun iPhone  6s | Unknown | iPhone 6s | iOS 10.2.1 | arm64)\nI also get the same error when I build fbsimctl from master:\nbrew install fbsimctl --HEAD\nAny thoughts? Have other people gotten buck-built apps to run on the device with a debugger?\nAny guidance is appreciated.\n. Oops sorry, it appears it's done in the .buckconfig file via:\n[apple]\niphoneos_target_sdk_version = 9.0\nAnd the actual SDK Buck links against is whatever SDK\nxcodebuild -sdk -version\nprints out that matches the platform (iphoneos, iphonesimulator) you're trying to build for. That's where the 10.2 comes from.. An update:\nAfter digging through the source code, it turns out you CAN control the choice of simulator like this:\napple_test(\n  name = 'TestName,\n  destination_specifier = {'platform': 'iOS Simulator', 'OS': '11.0', 'name': 'iPhone 6'},\n)\nHowever, this isn't documented anywhere on the apple_test page, so I am hesitant to start relying on it.\nI must be missing something. What is the tried and true way to control what simulator an apple_test runs on?. @robbertvanginkel \nYeah I saw this.\nWhat I wanted was a way to run the same apple_test on multiple simulators, programmatically (if I had view tests, for example, where I take a snapshot of screens across various screen sizes to ensure there are no regressions).. ",
    "shepting": "This has helped us as well. Here is our syntax that worked:\nplatform_linker_flags = [('iphonesimulator*',\n                         ['-Wl,-sectcreate,__TEXT,__entitlements,ios/Entitlements-Debug.plist'])],. This would be really great actually. @mgrebenets did you have any success on a workaround for this?. Does the logic in this integration test work for you? https://github.com/facebook/buck/blob/74a4ea8f385ad8eb17568c6763930e6bea61352b/test/com/facebook/buck/apple/AppleBundleIntegrationTest.java#L938-L973. @ttsugriy Anything holding up this PR?. Would love support for Swift 4.2 on either a whole project (.buckconfig) or apple_library basis.. I would have really appreciated some default settings when getting started with Buck. These could still be overridden as you mention, but would really help new engineers to enable debugging right from the start.. I would have really appreciated some default settings when getting started with Buck. These could still be overridden as you mention, but would really help new engineers to enable debugging right from the start.. This will be great to get integrated!. This will be great to get integrated!. @williamtwilson Could you have a look at this? Both Uber and Airbnb are already using this internally.. @williamtwilson Could you have a look at this? Both Uber and Airbnb are already using this internally.. Was this duplication intended?. ",
    "xzstar": "The reason is System.getProperty(\"java.home\")  points to a jre directory.\nWorkaround: copy your jdk/lib/tools.jar to jre/lib/tools. ",
    "c4urself": "Got the same issue:\nbuck version v2017.10.01.01. ",
    "msridhar": "Ah nice, slice_trace.py looks like a good option; thanks!. cc @lazaroclapp can you take a quick look on this one?. Perhaps less common, but daemon also needs to be restarted if an external javac_jar is changed. Hi @ttsugriy so to clarify, you would need all jars relevant to Error Prone (including Error Prone itself) inside the buck repo?\nI am going to follow up with EP folks regarding their Bazel integration.  There are some aspects of it I don't understand.  E.g., if they are sticking the entire javac jar in the bootclasspath, that can lead to weirdness in terms of getting the parent classloader relationship right for annotation processors.  Will report back here once I have some answers.. Hi @ttsugriy, an update here.  I got some info on the Error Prone Bazel integration: mailing list message\nIt looks like they have a bootstrap_deploy.jar shipped with Bazel that they stick in the bootclasspath.  I think for Buck integration doing the same thing would make sense.\nAs far as their handling of hiding EP-bundled classes from annotation processors, that requires some classloader trickery and I'm not too sure how to integrate this into Buck.  AFAIK, with Bazel, Error Prone is the only version of javac that is supported.  With Buck this will not be the case, and so I don't know if adding the classloader magic would make sense.  We could just make it a documented issue with EP integration that annotation processors may have to watch out for conflicts with EP-bundled libraries.  (FWIW, this has not really been much of an issue for us at Uber.)\nTo summarize, I think we could do the following:\n1. Figure out the way to most easily package up Bazel's bootstrap_deploy.jar for use with Buck.\n2. Document how to use Error Prone with Buck\nLet me know your thoughts.  I'll test out 1 on our internal builds. Hi @ttsugriy, an update here.  I got some info on the Error Prone Bazel integration: mailing list message\nIt looks like they have a bootstrap_deploy.jar shipped with Bazel that they stick in the bootclasspath.  I think for Buck integration doing the same thing would make sense.\nAs far as their handling of hiding EP-bundled classes from annotation processors, that requires some classloader trickery and I'm not too sure how to integrate this into Buck.  AFAIK, with Bazel, Error Prone is the only version of javac that is supported.  With Buck this will not be the case, and so I don't know if adding the classloader magic would make sense.  We could just make it a documented issue with EP integration that annotation processors may have to watch out for conflicts with EP-bundled libraries.  (FWIW, this has not really been much of an issue for us at Uber.)\nTo summarize, I think we could do the following:\n1. Figure out the way to most easily package up Bazel's bootstrap_deploy.jar for use with Buck.\n2. Document how to use Error Prone with Buck\nLet me know your thoughts.  I'll test out 1 on our internal builds. Some further clarity on classloader stuff.  My understanding of bootstrap_deploy.jar was way off in the above comment.  What actually happens is:\n1. Bazel places the full javac jar in the bootclasspath here\n2. Separate code manages the bootclasspath used when running javac, through a mix of passing the -bootclasspath parameter and calling the file manager APIs, e.g., here and here.  This makes sense, as for example if you're targeting 1.6, you want the bootclasspath seen by the compiler to match a 1.6 JVM.\nAnyway, wanted to clarify that.  Still thinking about the right integration for Buck; will post back when I have something.. /cc @kageiit . @sbalabanov not sure what you consider a slow drive, but this was on an SSD on a MacBook Pro.  Also only three build tasks were running (I have a quad core), so there should have been a CPU thread available to do the writes.  I guess it's possible that IO is the bottleneck, but I suspect something else is going on.. Hi @sbalabanov, here is some more info from the heap dump I have.\n\nThe outputExecutor is a java.util.concurrent.ThreadPoolExecutor, whose workQueue field is a java.util.concurrent.LinkedBlockingQueue with a count field of 16160.\nThe item of each node in the LinkedBlockingQueue is a FutureTask, whose callable is a lambda allocated here.  The lambda captures a ChromeTraceEvent.\nUsually the ChromeTraceEvents retain very little memory, but some of them retain ~1MB of memory.  In such cases, the category field is \"javac\", the name field is \"analyze\", and the memory is retained in the args map.  The entries in the args map are either (1) a key like file 1021 with a value being a path to a source file, or (2) a key like type 1021 with a value being a class name.  So all the memory seems to be in Strings.\n\nHope that is helpful.  Let me know what other info I can provide.. ",
    "sleighsoft": "How can you slice a json?. It fails for me with \"unhashable type\". I am using python 2.7. Well probably my file is not in the same format that is used by buck. Forget my question. ",
    "gabrielzanoni": "Hi @nikhilsh, did you manage to fix this? I'm getting error here \ud83d\ude1e . @nikhilsh There is a \"hack\" you need to do. You have to copy the carthage frameworks you're using to a folder called Frameworks and use it as a apple_resource in you apple_bundle.\nIn your case, it would be something like this:\n```python\napple_asset_catalog(\n  name = 'JarvisAssets',\n  app_icon = 'AppIcon',\n  dirs = ['jarvis/Assets.xcassets'],\n)\napple_resource(\n  name = 'JarvisResources',\n  dirs = [],\n  files = glob(['jarvis/.png','jarvis/.storyboard', 'jarvis/.xib', 'jarvis/Fonts/.ttf', 'jarvis/Geomanist OTF/*.otf']),\n)\napple_binary(\n  name = 'JarvisBinary',\n  configs = {\n    'Development': {\n    'PRODUCT_NAME' : 'Jarvis',\n    'PRODUCT_MODULE_NAME' : 'jarvis',\n    'CLANG_ENABLE_MODULES' : 'YES',\n    'PROVISIONING_PROFILE_SPECIFIER' : '',\n    'DEVELOPMENT_TEAM' : 'xxx',\n    'ALWAYS_EMBED_SWIFT_STANDARD_LIBRARIES' : 'YES',\n    'PRODUCT_BUNDLE_IDENTIFIER' : 'xxx',\n    'ONLY_ACTIVE_ARCH' : 'YES',\n    'CODE_SIGN_ENTITLEMENTS' : 'jarvis/jarvis.entitlements',\n    'SWIFT_OPTIMIZATION_LEVEL' : '-Onone',\n    'GCC_OPTIMIZATION_LEVEL' : '0',\n    'VALIDATE_PRODUCT' : 'NO',\n    },\n  },\n  preprocessor_flags = [\n    '-fobjc-arc',\n    '-fno-objc-arc-exceptions',\n    '-Qunused-arguments',\n  ],\n  srcs = glob([\n    'jarvis//*.m',\n    'jarvis//.mm',\n    'jarvis//*.swift',\n  ]),\n  headers = glob([\n    'jarvis//.h',\n  ]),\n  bridging_header = 'jarvis/Jarvis-Bridging-Header.h',\n  frameworks = [\n    '$SDKROOT/System/Library/Frameworks/SystemConfiguration.framework',\n    '$SDKROOT/System/Library/Frameworks/OpenGLES.framework',\n    '$SDKROOT/System/Library/Frameworks/AVFoundation.framework',\n    '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n    '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMotion.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreLocation.framework',\n    '$SDKROOT/System/Library/Frameworks/MobileCoreServices.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMedia.framework',\n    '$SDKROOT/System/Library/Frameworks/CFNetwork.framework',\n  ],\n  visibility = ['PUBLIC'],\n  deps = [\n    ':JarvisAssets',\n    ':JarvisResources',\n    ':Fabric',\n    ':Answers',\n    ':Nimble',\n    ':Quick',\n    ':Sentry',\n    ':Crash',\n    ':AppleCalendar',\n    ':CryptoSwift',\n    ':JWT',\n    ':KeychainAccess',\n    ':Alamofire',\n    ':AlamofireObjectMapper',\n    ':Charts',\n    ':EPSignature',\n    ':IQKeyboardManager',\n    ':IQKeyboardManagerSwift',\n    ':ObjectMapper',\n    ':calabash',\n    ':ZDCChat',\n    ':ZDCChatAPI',\n  ],\n)\napple_bundle(\n  name = 'Jarvis',\n  binary = ':JarvisBinary',\n  extension = 'app',\n  deps = ['CarthageFrameworks'],\n  info_plist = 'jarvis/Info.plist',\n)\napple_resource(\n  name = 'CarthageFrameworks',\n  dirs = ['Frameworks'] # here you put all your carthage frameworks\n)\napple_package(\n  name = 'JarvisPackage',\n  bundle = ':Jarvis',\n)\nprebuilt_apple_framework(\n    name = 'Fabric',\n    preferred_linkage = 'shared',\n    framework = 'Fabric.framework',\n)\nprebuilt_apple_framework(\n    name = 'Answers',\n    preferred_linkage = 'shared',\n    framework = 'Answers.framework',\n)\nprebuilt_apple_framework(\n    name = 'Nimble',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Nimble.framework',\n)\nprebuilt_apple_framework(\n    name = 'Quick',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Quick.framework',\n)\nprebuilt_apple_framework(\n    name = 'Sentry',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Sentry.framework',\n)\nprebuilt_apple_framework(\n    name = 'Crash',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/KSCrash.framework',\n)\nprebuilt_apple_framework(\n    name = 'AppleCalendar',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/JTAppleCalendar.framework',\n)\nprebuilt_apple_framework(\n    name = 'CryptoSwift',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/CryptoSwift.framework',\n)\nprebuilt_apple_framework(\n    name = 'JWT',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/JWT.framework',\n)\nprebuilt_apple_framework(\n    name = 'KeychainAccess',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/KeychainAccess.framework',\n)\nprebuilt_apple_framework(\n    name = 'Alamofire',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Alamofire.framework',\n)\nprebuilt_apple_framework(\n    name = 'AlamofireObjectMapper',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/AlamofireObjectMapper.framework',\n)\nprebuilt_apple_framework(\n    name = 'Charts',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Charts.framework',\n)\nprebuilt_apple_framework(\n    name = 'EPSignature',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/EPSignature.framework',\n)\nprebuilt_apple_framework(\n    name = 'IQKeyboardManager',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/IQKeyboardManager.framework',\n)\nprebuilt_apple_framework(\n    name = 'IQKeyboardManagerSwift',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/IQKeyboardManagerSwift.framework',\n)\nprebuilt_apple_framework(\n    name = 'ObjectMapper',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/ObjectMapper.framework',\n)\nprebuilt_apple_framework(\n    name = 'calabash',\n    preferred_linkage = 'shared',\n    framework = 'calabash.framework',\n)\nprebuilt_apple_framework(\n    name = 'ZDCChat',\n    preferred_linkage = 'shared',\n    framework = 'ZDCChat/ZDCChat.framework',\n)\nprebuilt_apple_framework(\n    name = 'ZDCChatAPI',\n    preferred_linkage = 'shared',\n    framework = 'ZDCChat/ZDCChatAPI.framework',\n)\n``. @nikhilsh There is a \"hack\" you need to do. You have to copy the carthage frameworks you're using to a folder calledFrameworksand use it as aapple_resourcein youapple_bundle`.\nIn your case, it would be something like this:\n```python\napple_asset_catalog(\n  name = 'JarvisAssets',\n  app_icon = 'AppIcon',\n  dirs = ['jarvis/Assets.xcassets'],\n)\napple_resource(\n  name = 'JarvisResources',\n  dirs = [],\n  files = glob(['jarvis/.png','jarvis/.storyboard', 'jarvis/.xib', 'jarvis/Fonts/.ttf', 'jarvis/Geomanist OTF/*.otf']),\n)\napple_binary(\n  name = 'JarvisBinary',\n  configs = {\n    'Development': {\n    'PRODUCT_NAME' : 'Jarvis',\n    'PRODUCT_MODULE_NAME' : 'jarvis',\n    'CLANG_ENABLE_MODULES' : 'YES',\n    'PROVISIONING_PROFILE_SPECIFIER' : '',\n    'DEVELOPMENT_TEAM' : 'xxx',\n    'ALWAYS_EMBED_SWIFT_STANDARD_LIBRARIES' : 'YES',\n    'PRODUCT_BUNDLE_IDENTIFIER' : 'xxx',\n    'ONLY_ACTIVE_ARCH' : 'YES',\n    'CODE_SIGN_ENTITLEMENTS' : 'jarvis/jarvis.entitlements',\n    'SWIFT_OPTIMIZATION_LEVEL' : '-Onone',\n    'GCC_OPTIMIZATION_LEVEL' : '0',\n    'VALIDATE_PRODUCT' : 'NO',\n    },\n  },\n  preprocessor_flags = [\n    '-fobjc-arc',\n    '-fno-objc-arc-exceptions',\n    '-Qunused-arguments',\n  ],\n  srcs = glob([\n    'jarvis//*.m',\n    'jarvis//.mm',\n    'jarvis//*.swift',\n  ]),\n  headers = glob([\n    'jarvis//.h',\n  ]),\n  bridging_header = 'jarvis/Jarvis-Bridging-Header.h',\n  frameworks = [\n    '$SDKROOT/System/Library/Frameworks/SystemConfiguration.framework',\n    '$SDKROOT/System/Library/Frameworks/OpenGLES.framework',\n    '$SDKROOT/System/Library/Frameworks/AVFoundation.framework',\n    '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n    '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMotion.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreLocation.framework',\n    '$SDKROOT/System/Library/Frameworks/MobileCoreServices.framework',\n    '$SDKROOT/System/Library/Frameworks/CoreMedia.framework',\n    '$SDKROOT/System/Library/Frameworks/CFNetwork.framework',\n  ],\n  visibility = ['PUBLIC'],\n  deps = [\n    ':JarvisAssets',\n    ':JarvisResources',\n    ':Fabric',\n    ':Answers',\n    ':Nimble',\n    ':Quick',\n    ':Sentry',\n    ':Crash',\n    ':AppleCalendar',\n    ':CryptoSwift',\n    ':JWT',\n    ':KeychainAccess',\n    ':Alamofire',\n    ':AlamofireObjectMapper',\n    ':Charts',\n    ':EPSignature',\n    ':IQKeyboardManager',\n    ':IQKeyboardManagerSwift',\n    ':ObjectMapper',\n    ':calabash',\n    ':ZDCChat',\n    ':ZDCChatAPI',\n  ],\n)\napple_bundle(\n  name = 'Jarvis',\n  binary = ':JarvisBinary',\n  extension = 'app',\n  deps = ['CarthageFrameworks'],\n  info_plist = 'jarvis/Info.plist',\n)\napple_resource(\n  name = 'CarthageFrameworks',\n  dirs = ['Frameworks'] # here you put all your carthage frameworks\n)\napple_package(\n  name = 'JarvisPackage',\n  bundle = ':Jarvis',\n)\nprebuilt_apple_framework(\n    name = 'Fabric',\n    preferred_linkage = 'shared',\n    framework = 'Fabric.framework',\n)\nprebuilt_apple_framework(\n    name = 'Answers',\n    preferred_linkage = 'shared',\n    framework = 'Answers.framework',\n)\nprebuilt_apple_framework(\n    name = 'Nimble',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Nimble.framework',\n)\nprebuilt_apple_framework(\n    name = 'Quick',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Quick.framework',\n)\nprebuilt_apple_framework(\n    name = 'Sentry',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Sentry.framework',\n)\nprebuilt_apple_framework(\n    name = 'Crash',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/KSCrash.framework',\n)\nprebuilt_apple_framework(\n    name = 'AppleCalendar',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/JTAppleCalendar.framework',\n)\nprebuilt_apple_framework(\n    name = 'CryptoSwift',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/CryptoSwift.framework',\n)\nprebuilt_apple_framework(\n    name = 'JWT',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/JWT.framework',\n)\nprebuilt_apple_framework(\n    name = 'KeychainAccess',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/KeychainAccess.framework',\n)\nprebuilt_apple_framework(\n    name = 'Alamofire',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Alamofire.framework',\n)\nprebuilt_apple_framework(\n    name = 'AlamofireObjectMapper',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/AlamofireObjectMapper.framework',\n)\nprebuilt_apple_framework(\n    name = 'Charts',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/Charts.framework',\n)\nprebuilt_apple_framework(\n    name = 'EPSignature',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/EPSignature.framework',\n)\nprebuilt_apple_framework(\n    name = 'IQKeyboardManager',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/IQKeyboardManager.framework',\n)\nprebuilt_apple_framework(\n    name = 'IQKeyboardManagerSwift',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/IQKeyboardManagerSwift.framework',\n)\nprebuilt_apple_framework(\n    name = 'ObjectMapper',\n    preferred_linkage = 'shared',\n    framework = 'Carthage/Build/iOS/ObjectMapper.framework',\n)\nprebuilt_apple_framework(\n    name = 'calabash',\n    preferred_linkage = 'shared',\n    framework = 'calabash.framework',\n)\nprebuilt_apple_framework(\n    name = 'ZDCChat',\n    preferred_linkage = 'shared',\n    framework = 'ZDCChat/ZDCChat.framework',\n)\nprebuilt_apple_framework(\n    name = 'ZDCChatAPI',\n    preferred_linkage = 'shared',\n    framework = 'ZDCChat/ZDCChatAPI.framework',\n)\n```. ",
    "michaeleiselsc": "Awesome! Now is there any way to get that output without doing a full build? I just want to lint a few of the files in my project each time (those that changed in whatever PR). so i'm now facing an issue where there are two more requirements:\n- sign the dylib\n- have it work with xcodebuild\nthe reason is that i want to distribute my app to internal testers with the address sanitizer turned on, and the address sanitizer requires that libclang_rt.asan_ios_dynamic.dylib is included and signed. in an xcode project, this is easy to do by adding it to the \"embedded binaries\" section under \"General\" in the target settings (which in turn adds an \"embed libraries\" build phase), but i don't see how to do this with buck. any ideas? thanks!. yeah, you basically just need to build for the correct architectures, package it up with libtool and link it in at the end. yeah, you basically just need to build for the correct architectures, package it up with libtool and link it in at the end. I'm using Rust version 1.17.0. What about if I want to build a rust_library as part of an apple_binary in Xcode? Currently, no build commands for rust seem to be generated. What about if I want to build a rust_library as part of an apple_binary in Xcode? Currently, no build commands for rust seem to be generated. Also, let's say I have two files in the src directory of a rust crate, lib.rs, the root, and log.rs, which can be referred to in lib.rs. My buck file is as such:\nrust_library(\n    name = 'Rustic',\n    srcs = ['src/lib.rs',],\n    visibility = ['PUBLIC'],\n    crate = 'logger',\n    crate_root = 'src/lib.rs',\n)\nIt will only copy lib.rs to the temporary buck-out folder to build, and won't include log.rs. This causes the build to fail. If I try to include log.rs into the srcs array, then it will try to build log.rs independently, which is not what's supposed to happen and will also fail.. Also, let's say I have two files in the src directory of a rust crate, lib.rs, the root, and log.rs, which can be referred to in lib.rs. My buck file is as such:\nrust_library(\n    name = 'Rustic',\n    srcs = ['src/lib.rs',],\n    visibility = ['PUBLIC'],\n    crate = 'logger',\n    crate_root = 'src/lib.rs',\n)\nIt will only copy lib.rs to the temporary buck-out folder to build, and won't include log.rs. This causes the build to fail. If I try to include log.rs into the srcs array, then it will try to build log.rs independently, which is not what's supposed to happen and will also fail.. The issue is that if I add it to srcs then buck will try to compile it with rustc, which is not what I want. In rust, you only want to compile one file, in this case, lib.rs, which imports other files as needed. So I can either copy it over and have it cause a compile failure, or not copy it over and then lib.rs can't find it. So it's different from, say, a C++ library.. The issue is that if I add it to srcs then buck will try to compile it with rustc, which is not what I want. In rust, you only want to compile one file, in this case, lib.rs, which imports other files as needed. So I can either copy it over and have it cause a compile failure, or not copy it over and then lib.rs can't find it. So it's different from, say, a C++ library.. @jsgf thanks, upgrading and running it with the #lib flavor has gotten rid of the issues I described above. However, I get the following error:\n``\n$ buck build //Libraries/Rustic:Rustic#lib\nerror[E0463]: can't find crate fortimer`\n --> buck-out/bin/Libraries/Rustic/Rustic#iphonesimulator-x86_64,lib-container/Libraries/Rustic/src/tty_logger.rs:3:1\n  |\n3 | extern crate timer;\n  | ^^^^^^^^^^^^^^^^^^^ can't find crate\nerror: aborting due to previous error\nBuild failed: Command failed with exit code 101.\nstderr: error[E0463]: can't find crate for timer\n --> buck-out/bin/Libraries/Rustic/Rustic#iphonesimulator-x86_64,lib-container/Libraries/Rustic/src/tty_logger.rs:3:1\n  |\n3 | extern crate timer;\n  | ^^^^^^^^^^^^^^^^^^^ can't find crate\nerror: aborting due to previous error\nWhen running <rust-build>.\nWhen building rule //Libraries/Rustic:Rustic#iphonesimulator-x86_64,lib.\n\nBuilding: finished in 0.2 sec (100%) 1/1 jobs, 1 updated, 100.0% cache miss\n  Total time: 0.4 sec\nHere is my BUCK file:\nrust_library(\n    name = 'Rustic',\n    srcs = glob(['src/*.rs']),\n)\n```\nI tried rearranging the order of the \"extern crate\" calls, and each time the top one would have the issue.\nHere's a small example where cargo build works, but buck build //:bucktest#lib does not. @jsgf thanks, upgrading and running it with the #lib flavor has gotten rid of the issues I described above. However, I get the following error:\n``\n$ buck build //Libraries/Rustic:Rustic#lib\nerror[E0463]: can't find crate fortimer`\n --> buck-out/bin/Libraries/Rustic/Rustic#iphonesimulator-x86_64,lib-container/Libraries/Rustic/src/tty_logger.rs:3:1\n  |\n3 | extern crate timer;\n  | ^^^^^^^^^^^^^^^^^^^ can't find crate\nerror: aborting due to previous error\nBuild failed: Command failed with exit code 101.\nstderr: error[E0463]: can't find crate for timer\n --> buck-out/bin/Libraries/Rustic/Rustic#iphonesimulator-x86_64,lib-container/Libraries/Rustic/src/tty_logger.rs:3:1\n  |\n3 | extern crate timer;\n  | ^^^^^^^^^^^^^^^^^^^ can't find crate\nerror: aborting due to previous error\nWhen running <rust-build>.\nWhen building rule //Libraries/Rustic:Rustic#iphonesimulator-x86_64,lib.\n\nBuilding: finished in 0.2 sec (100%) 1/1 jobs, 1 updated, 100.0% cache miss\n  Total time: 0.4 sec\nHere is my BUCK file:\nrust_library(\n    name = 'Rustic',\n    srcs = glob(['src/*.rs']),\n)\n```\nI tried rearranging the order of the \"extern crate\" calls, and each time the top one would have the issue.\nHere's a small example where cargo build works, but buck build //:bucktest#lib does not. bucktest.zip\n. bucktest.zip\n. It says that deps only works for rust_library and rust_prebuilt_library dependencies. What about a crate from crates.io, how can I use one of those?. Got it, thanks!. Got it, thanks!. ",
    "phoenixuprising": "Sorry for the bit of delay. I was just able to test this and it looks like it is now working properly. Thanks for the fix.. ",
    "nordlow": "Doesn't work for me:\n[$USER:~/ware/buck] master \u00b1 bin/buck build buck --show-output\n/usr/bin/python2: can't open file './bin /home/per/ware/buck/bin/../programs/buck.py': [Errno 2] No such file or directory\nUpdate:\nAhh, I hade to use full path to buck binary\n~/ware/buck/bin/buck build buck --show-output\neven when I'm already in ~/ware/buck.. ",
    "jeeloo": "@ilya-klyuchnikov here you go buckd.txt\n. @ilya-klyuchnikov I still get the same behaviour. . ",
    "marvinarroz": "@Coneko , I'd also like to hear if you have any pointers to share about implementing caching in an external test runner. With the change to remove caching, our CI servers now run the full test suite for all PRs. \nI would appreciate some guidance in getting us back to the behavior we had before . @Coneko , I'd also like to hear if you have any pointers to share about implementing caching in an external test runner. With the change to remove caching, our CI servers now run the full test suite for all PRs. \nI would appreciate some guidance in getting us back to the behavior we had before . ",
    "ShangxuanWu": "I am getting a same error here. Is it fixed or there is some workaround? How to turn sqlite off?\nMy error message goes like this:\n[-] PROCESSING BUCK FILES...FINISHED 17.7s [100%] \ud83d\udc33  New buck daemon\n[-] DOWNLOADING... (1.49 MB/S AVG, TOTAL: 2.76 MB, 348 Artifacts)\n[-] BUILDING...FINISHED 51.3s [100%] (528/3203 JOBS, 7 UPDATED, 6 [0.2%] CACHE MISS)\n    Details: http://localhost:53844/trace/83b3a004-038f-41b6-bdc4-65687a655293\n[2017-06-25 21:18:19.173][error][command:null][tid:30][com.facebook.buck.cli.Main] Uncaught exception at top level\njava.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Building rule [//proxygen/facebook/httpclient:http_client_utils#compile-pic-EventBaseFuncWithTag.cpp.o9287e4c1,gcc-4.9-glibc-2.20,v9110ab1] failed. Caused by [ZipException]:\narchive is not a ZIP archive\n        at com.facebook.buck.command.Build.executeAndPrintFailuresToEventBus(Build.java:382)\n        at com.facebook.buck.cli.BuildCommand.executeBuild(BuildCommand.java:924)\n        at com.facebook.buck.cli.BuildCommand.executeLocalBuild(BuildCommand.java:855)\n        at com.facebook.buck.cli.BuildCommand.executeBuildAndProcessResult(BuildCommand.java:509)\n        at com.facebook.buck.cli.BuildCommand.run(BuildCommand.java:415)\n        at com.facebook.buck.cli.BuildCommand.runWithoutHelp(BuildCommand.java:381)\n        at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:222)\n        at com.facebook.buck.cli.AbstractContainerCommand.run(AbstractContainerCommand.java:66)\n        at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:80)\n        at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:968)\n        at com.facebook.buck.cli.Main.runMainThenExit(Main.java:351)\n        at com.facebook.buck.cli.Main.nailMain(Main.java:1856)\n        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n        at java.lang.reflect.Method.invoke(Method.java:498)\n        at com.martiansoftware.nailgun.NGSession.run(NGSession.java:338)\nCaused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: Building rule [//proxygen/facebook/httpclient:http_client_utils#compile-pic-EventBaseFuncWithTag.cpp.o9287e4c1,gcc-4.9-glibc-2.20,v9110ab1] failed. Caused by [ZipException]:\narchive is not a ZIP archive\n        at com.facebook.buck.command.Build.executeBuild(Build.java:278)\n        at com.facebook.buck.command.Build.executeAndPrintFailuresToEventBus(Build.java:331)\n        ... 16 more\nCaused by: java.lang.RuntimeException: Building rule [//proxygen/facebook/httpclient:http_client_utils#compile-pic-EventBaseFuncWithTag.cpp.o9287e4c1,gcc-4.9-glibc-2.20,v9110ab1] failed. Caused by [ZipException]:\narchive is not a ZIP archive\n        at com.facebook.buck.rules.CachingBuildEngine.maybeAttachBuildRuleNameToException(CachingBuildEngine.java:1190)\n        at com.facebook.buck.rules.CachingBuildEngine.access$1400(CachingBuildEngine.java:117)\n        at com.facebook.buck.rules.CachingBuildEngine$2.onFailure(CachingBuildEngine.java:1140)\n        at com.facebook.buck.util.concurrent.MoreFutures$1.onFailure(MoreFutures.java:138)\n        at com.google.common.util.concurrent.Futures$4.run(Futures.java:1123)\n        at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:435)\n        at com.google.common.util.concurrent.AbstractFuture.executeListener(AbstractFuture.java:900)\n        at com.google.common.util.concurrent.AbstractFuture.complete(AbstractFuture.java:811)\n        at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:675)\n        at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:112)\n        at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:988)\n        at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submit$5(WeightedListeningExecutorService.java:104)\n        at com.facebook.buck.util.concurrent.WeightedListeningExecutorService.lambda$submitWithSemaphore$3(WeightedListeningExecutorService.java:78)\n        at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:211)\n        at com.google.common.util.concurrent.AbstractTransformFuture$AsyncTransformFuture.doTransform(AbstractTransformFuture.java:200)\n        at com.google.common.util.concurrent.AbstractTransformFuture.run(AbstractTransformFuture.java:130)\n        at com.google.common.util.concurrent.MoreExecutors$5$1.run(MoreExecutors.java:988)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.util.zip.ZipException: archive is not a ZIP archive\n        at org.apache.commons.compress.archivers.zip.ZipFile.positionAtEndOfCentralDirectoryRecord(ZipFile.java:806)\n        at org.apache.commons.compress.archivers.zip.ZipFile.positionAtCentralDirectory(ZipFile.java:736)\n        at org.apache.commons.compress.archivers.zip.ZipFile.populateFromCentralDirectory(ZipFile.java:481)\n        at org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:216)\n        at org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:192)\n        at org.apache.commons.compress.archivers.zip.ZipFile.<init>(ZipFile.java:153)\n        at com.facebook.buck.zip.Unzip.extractZipFile(Unzip.java:187)\n        at com.facebook.buck.zip.Unzip.extractZipFile(Unzip.java:239)\n        at com.facebook.buck.rules.CachingBuildEngine.unzipArtifactFromCacheResult(CachingBuildEngine.java:1487)\n        at com.facebook.buck.rules.CachingBuildEngine.tryToFetchArtifactFromBuildCacheAndOverlayOnTopOfProjectFilesystem(CachingBuildEngine.java:1434)\n        at com.facebook.buck.rules.CachingBuildEngine.performRuleKeyCacheCheck(CachingBuildEngine.java:583)\n        at com.facebook.buck.rules.CachingBuildEngine.lambda$buildOrFetchFromCache$3(CachingBuildEngine.java:475)\n        ... 8 more. ",
    "gongyujun": "Okay, thank you so much! I have solved it.. ",
    "yuriy-yarosh": "@Coneko, sure thing, but what if I want to run two genrule's simultaneously as a dependencies of a third one ?. Thank you @Coneko and @mikekap . ",
    "AttwellBrian": "Thanks @jkeljo!\nClosing this task since it is more of a question than a Feature Request.. ",
    "littlebobert": "Were you all able to workaround this? I think I\u2019m having the same problem. I filed: https://github.com/facebook/buck/issues/2089. Hmm it appears that the real Fabric and Crashlytics .framework directories are inside an iOS subdirectory. After updating my BUCK file to use the correct paths this problem went away.. buck build //Procore:Analytics doesn\u2019t produce any errors but it doesn\u2019t seem to put anything into buck-out/gen. Am I using core_data_model correctly?. In Xcode we\u2019re using codegen set to Class Definition for the entities in Analytics.xcdatamodeld. Is the problem that buck doesn\u2019t support code generation? So we need to first build with Xcode for code generation and then copy those generated files from derived data into the project?. Ah, exported_preprocessor_flags = ['-I/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator.sdk/usr/include/libxml2'] works (I removed the newlines and space between -I and the start of the path), but exported_preprocessor_flags = ['-I${SDKROOT}/usr/include/libxml2'] doesn\u2019t. buck doesn\u2019t seem to expand ${SDKROOT}.. ",
    "mgrebenets": "So I finally got rid of bridging header and no luck :(\nhttps://github.com/facebook/buck/issues/2074. Same here, the list of email domains is pretty restricting and I don't happen to own any of those :)\nIs that list of domains limited to companies using Buck?\nI guess adding gmail.com would be too much then.\nIn that case, could it be possible to add @cba.com.au?\nWe are looking into using buck and I have tons of questions to ask around :). +1 here.\nDoesn't just happen for zip files, but for ipa files as well when building iOS packages.\nWell, ipa is a zip file anyways.\nLooks like when there were no changes detected and nothing had to be recompiled/relinked, the new .ipa is still zipped or maybe even copied from the cache and that ipa has Friday, 1 February 1985 at 12:00 am both as created and modified dates.\nHappened to me both with HTTP cache server and without it.\nMaybe it's nothing bad, but there may be some side-effects I'm not aware about.\nP.S.\nWould a simple touch package.ipa maybe be a good temporary workaround? \ud83e\udd14. +1.\nWe've been migrating existing library projects from CocoaPods to Buck.\nPlaygrounds were working with CocoaPods when we added playground to the same workspace as the framework project.\nThe same wouldn't work with Buck so far.\nI've tried adding playground using other_xcode_files as well as other_xcode_sources.\nI've tried to manually add playground to autogenerated Xcode workspace as well.\nIn all cases the error is error: MyPlanground.playground:10:8: error: no such module 'MyLibrary'.\nIt must be due to the fact that buck creates a static library target, while with cocoapods we've been using dynamic libraries so far.\nAnother question that is interesting, is how can we use playgrounds together with libraries that have additional resources. While using dynamic frameworks, the resources would be packaged inside .framework bundle and would be available to the app and/or playground as part of that bundle.\nWhen building library as a static library, the resources come as a separate dependency. Which is fine for the apps, the resources will be copied directly to the application bundle and can be accessed there.\nBut what about playgrounds? How would a playground be able to access those resources without some extra support from buck tool?\nWhile static libraries with extra resources and playgrounds is not something that's buck-specific, it would be helpful to have support for playgrounds from buck anyway.. +1.\nWe've been migrating existing library projects from CocoaPods to Buck.\nPlaygrounds were working with CocoaPods when we added playground to the same workspace as the framework project.\nThe same wouldn't work with Buck so far.\nI've tried adding playground using other_xcode_files as well as other_xcode_sources.\nI've tried to manually add playground to autogenerated Xcode workspace as well.\nIn all cases the error is error: MyPlanground.playground:10:8: error: no such module 'MyLibrary'.\nIt must be due to the fact that buck creates a static library target, while with cocoapods we've been using dynamic libraries so far.\nAnother question that is interesting, is how can we use playgrounds together with libraries that have additional resources. While using dynamic frameworks, the resources would be packaged inside .framework bundle and would be available to the app and/or playground as part of that bundle.\nWhen building library as a static library, the resources come as a separate dependency. Which is fine for the apps, the resources will be copied directly to the application bundle and can be accessed there.\nBut what about playgrounds? How would a playground be able to access those resources without some extra support from buck tool?\nWhile static libraries with extra resources and playgrounds is not something that's buck-specific, it would be helpful to have support for playgrounds from buck anyway.. Hm... I\u2019m pretty sure I tired that... I\u2019ll fibe it another go to be 100% sure. . @shepting \nNot really a good workaround, but for now I ended up adding a patched versions of the original entitlements, e.g. MyProject.patched.entitlements. \nThe patched entitlements are created by first copying the original entitlements file and then making the substitutions, such as resolving variables. Buck is also watching the .patched.entitlements to detect changes in them.\nHaven't tried the code from tests.\n. @robbertvanginkel \nI've tried to create a sample project but couldn't reproduce it.\nWhat I did instead is I captured logs for the version of buck that works (which is pretty much your fork with one extra commit cherry-picked: https://github.com/mgrebenets/buck/tree/uber/modular_swift_appex_fix) and the latest master (6c2f9a).\nbuck-from-fork.log\nbuck-from-master.log\nAfter diffing the logs, I noticed one major difference.\nThe older version of buck has this line:\n-I buck-out/gen/pods/mylib.ios/MyLibDebug#iphonesimulator-x86_64,private-headers.hmap\nbut the logs created by latest buck don't have this line.\nI'd assume this is where unit test target would be able to find private headers of the library target. I should add that it fails with buck command line calls like buck test MyLib I didn't even generate Xcode project.. While I couldn't get the initial issue reproduced, I managed to get a similar one here:\nhttps://github.com/mgrebenets/test-app-with-bridging-header\nThe bridging header is where important things happen.\nIf I use import statement like so #import \"ObjCProtocol.h\" I get a failing build for buckw build sample_tests.\nIf I change it to #import \"ObjC/ObjCProtocol.h\" the works.\nI don't know exactly, but from reading info in other issues I assumed that for headers like \"ObjCProtocol.h\" a symlinks should be created by buck, so #import \"ObjCProtocol.h\" would then resolve into a symlink which will then point to correct header. ObjcProtocol.h -> .....ObjC/ObjCProtocol.h.\nI've seen these kinds of links created in another project, but they never got created in this sample project. In fact, the ObjCProtocol.h never ends up copied to buck-out directory at all.\n. So here's few more findings  on the issue.\nA colleague of mine has found out that using relative paths in bridging headers fixes the build issue with latest version of buck from master.\nIn other words, if I have a structure like this:\n\u2514\u2500\u2500 Sources\n    \u251c\u2500\u2500 Module\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 MyHeader.h\n    \u2514\u2500\u2500 Supporting\\ Files\n        \u2514\u2500\u2500 Bridging-Header.h\nThen if I have this in Bridging-Header.h:\n```objc\nimport \"MyHeader.h\"\n```\nit works with the older fork of buck mentioned in this issue and it works in Xcode thanks to USER_HEADER_SEARCH_PATHS, but it does not work with latest version from master -  it can't find \"MyHeader.h\" any more.\nWhat we had to do as a workaround is to use relative paths in the bridging header, for example:\n```objc\nimport \"../Modulde/MyHeader.h\" // Path to MyHeader.h relative to Bridging-Header.h\n```\nThis is a strange workaround and looks like breaking change in latest buck version, but something we probably could live with, because it's still backwards compatible with Xcode build system.\n\nThe other issue is still there, the one where it can't find private and protected headers for Objective-C libraries test targets.\nIt only happens for libraries that have Objective-C code only.\nWhat I noticed though is if I add modular=False to the apple_library rule for this Objective-C module, the error goes away...\n\nSo to sum it up, I now have a project in which I can reproduce the issue:\nhttps://github.com/mgrebenets/buck-private-header-demo\nIf you look in BUCK file, line 8:\npython\n    # If you comment this line, the build will pass...\n    modular=True,\nIf this line is commented, then buckw test mylib command is successful, otherwise it fails wiht this error:\n```\nTests/MyLibTests.m:5:9: fatal error: 'MyLibPrivateClass.h' file not found\nimport \"MyLibPrivateClass.h\"\n    ^~~~~~~~~~~~~~~~~~~~~\n\n1 error generated.\nBuild failed: Command failed with exit code 1.\nstderr: Tests/MyLibTests.m:5:9: fatal error: 'MyLibPrivateClass.h' file not found\nimport \"MyLibPrivateClass.h\"\n```\nThis seems to be the breaking change compared to older versions.\n\n@milend @robbertvanginkel \nIs there something I'm doing wrong?\nI did my best going through diffs of swift and apple folders of Java source, but the code base unfortunatelly doesn't make too much sense to me since I'm not familiar with it. \nI have noticed few things like use_modulewrap (didn't change anything) and addition of isModular (which made me try modular=False)\n.\nThe main 2 questions I have:\n\nShould we only set modular=True for Swift and Mix-n-Match apple library targets, but not for Objective-C-only targets? (that's how it works at least on the master)\nShould we always use full relative paths in Swift bridging headers or is there some other flag for apple_binary which we can use to alter the behavior (it used to work earlier too)?\n\nThanks in advance \ud83d\udc4d \n\nUPD. Unfortunately setting modular=False is not the best workaround for us :(\nAfter making this change, all statements like @import MyLib; will stop working.\nI guess it totally makes sense, since there's no more underlying module for MyLib, but still doesn't make much sense why setting modular=True renders private headers \"invisible\" to test target.. So here's few more findings  on the issue.\nA colleague of mine has found out that using relative paths in bridging headers fixes the build issue with latest version of buck from master.\nIn other words, if I have a structure like this:\n\u2514\u2500\u2500 Sources\n    \u251c\u2500\u2500 Module\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 MyHeader.h\n    \u2514\u2500\u2500 Supporting\\ Files\n        \u2514\u2500\u2500 Bridging-Header.h\nThen if I have this in Bridging-Header.h:\n```objc\nimport \"MyHeader.h\"\n```\nit works with the older fork of buck mentioned in this issue and it works in Xcode thanks to USER_HEADER_SEARCH_PATHS, but it does not work with latest version from master -  it can't find \"MyHeader.h\" any more.\nWhat we had to do as a workaround is to use relative paths in the bridging header, for example:\n```objc\nimport \"../Modulde/MyHeader.h\" // Path to MyHeader.h relative to Bridging-Header.h\n```\nThis is a strange workaround and looks like breaking change in latest buck version, but something we probably could live with, because it's still backwards compatible with Xcode build system.\n\nThe other issue is still there, the one where it can't find private and protected headers for Objective-C libraries test targets.\nIt only happens for libraries that have Objective-C code only.\nWhat I noticed though is if I add modular=False to the apple_library rule for this Objective-C module, the error goes away...\n\nSo to sum it up, I now have a project in which I can reproduce the issue:\nhttps://github.com/mgrebenets/buck-private-header-demo\nIf you look in BUCK file, line 8:\npython\n    # If you comment this line, the build will pass...\n    modular=True,\nIf this line is commented, then buckw test mylib command is successful, otherwise it fails wiht this error:\n```\nTests/MyLibTests.m:5:9: fatal error: 'MyLibPrivateClass.h' file not found\nimport \"MyLibPrivateClass.h\"\n    ^~~~~~~~~~~~~~~~~~~~~\n\n1 error generated.\nBuild failed: Command failed with exit code 1.\nstderr: Tests/MyLibTests.m:5:9: fatal error: 'MyLibPrivateClass.h' file not found\nimport \"MyLibPrivateClass.h\"\n```\nThis seems to be the breaking change compared to older versions.\n\n@milend @robbertvanginkel \nIs there something I'm doing wrong?\nI did my best going through diffs of swift and apple folders of Java source, but the code base unfortunatelly doesn't make too much sense to me since I'm not familiar with it. \nI have noticed few things like use_modulewrap (didn't change anything) and addition of isModular (which made me try modular=False)\n.\nThe main 2 questions I have:\n\nShould we only set modular=True for Swift and Mix-n-Match apple library targets, but not for Objective-C-only targets? (that's how it works at least on the master)\nShould we always use full relative paths in Swift bridging headers or is there some other flag for apple_binary which we can use to alter the behavior (it used to work earlier too)?\n\nThanks in advance \ud83d\udc4d \n\nUPD. Unfortunately setting modular=False is not the best workaround for us :(\nAfter making this change, all statements like @import MyLib; will stop working.\nI guess it totally makes sense, since there's no more underlying module for MyLib, but still doesn't make much sense why setting modular=True renders private headers \"invisible\" to test target.. Could it be the changes in AppleLibraryDescription.java?\nThere's quite a few changes and some of them use isModular check.\nFor example, on the older fork I can see code like this:\njava\n ImmutableList.of(privateInput.get(), publicInput.get())))\nbut on the latest master there's no privateInput. Well, there's no publicInput either, so things might have been refactored.\nStill feels like this is where things changed.. Could it be the changes in AppleLibraryDescription.java?\nThere's quite a few changes and some of them use isModular check.\nFor example, on the older fork I can see code like this:\njava\n ImmutableList.of(privateInput.get(), publicInput.get())))\nbut on the latest master there's no privateInput. Well, there's no publicInput either, so things might have been refactored.\nStill feels like this is where things changed.. I may have mixed things up.\nIn fact, bridging header and using private headers in apple_test rule are 2 separate issues and I've linked 2 separate examples for them.\nIt's just that at some point I thought those may be connected (and both behaviors have changed compared to the older fork).\nBridging headers aside, what do you think may be the root cause for a combination or apple_library + apple_test to stop working for Objective-C only library when modular=True is set?\nIt's the 2nd example here: https://github.com/mgrebenets/buck-private-header-demo\nThe library doesn't have any bridging header.\nI'll just stick the BUCK file here as well for reference:\n```python\napple_library(\n    name='MyLib',\n    module_name='MyLib',\n    header_path_prefix='MyLib',\n    # If you comment this line, the build will pass...\n    modular=True,\n    visibility=['PUBLIC'],\n    headers=glob([\n        'Sources//*.h',\n    ]),\n    exported_headers=glob([\n        'Sources//.h',\n    ], exclude=[\n        # I tried commenting this line as well, doesn't change the outcome either.\n        'Sources/Nested/MyLibPrivateClass.h',\n    ]),\n    srcs=glob([\n        'Sources//.m',\n    ]),\n    tests=[\n        ':MyLibTests',\n    ],\n    frameworks=[\n        '$SDKROOT/System/Library/Frameworks/Foundation.framework'\n    ]\n)\napple_test(\n    name='MyLibTests',\n    module_name='MyLibTests',\n    deps=[\n        ':MyLib',\n    ],\n    info_plist='Tests/Info.plist',\n    info_plist_substitutions={\n        'PRODUCT_BUNDLE_IDENTIFIER': 'org.test.' + 'MyLibTests',\n    },\n    headers=glob([\n        'Tests//*.h',\n    ]),\n    srcs=glob([\n        'Tests//*.m',\n    ]),\n    frameworks=[\n        '$PLATFORM_DIR/Developer/Library/Frameworks/XCTest.framework',\n    ]\n)\n``. I may have mixed things up.\nIn fact, bridging header and using private headers inapple_test` rule are 2 separate issues and I've linked 2 separate examples for them.\nIt's just that at some point I thought those may be connected (and both behaviors have changed compared to the older fork).\nBridging headers aside, what do you think may be the root cause for a combination or apple_library + apple_test to stop working for Objective-C only library when modular=True is set?\nIt's the 2nd example here: https://github.com/mgrebenets/buck-private-header-demo\nThe library doesn't have any bridging header.\nI'll just stick the BUCK file here as well for reference:\n```python\napple_library(\n    name='MyLib',\n    module_name='MyLib',\n    header_path_prefix='MyLib',\n    # If you comment this line, the build will pass...\n    modular=True,\n    visibility=['PUBLIC'],\n    headers=glob([\n        'Sources//*.h',\n    ]),\n    exported_headers=glob([\n        'Sources//.h',\n    ], exclude=[\n        # I tried commenting this line as well, doesn't change the outcome either.\n        'Sources/Nested/MyLibPrivateClass.h',\n    ]),\n    srcs=glob([\n        'Sources//.m',\n    ]),\n    tests=[\n        ':MyLibTests',\n    ],\n    frameworks=[\n        '$SDKROOT/System/Library/Frameworks/Foundation.framework'\n    ]\n)\napple_test(\n    name='MyLibTests',\n    module_name='MyLibTests',\n    deps=[\n        ':MyLib',\n    ],\n    info_plist='Tests/Info.plist',\n    info_plist_substitutions={\n        'PRODUCT_BUNDLE_IDENTIFIER': 'org.test.' + 'MyLibTests',\n    },\n    headers=glob([\n        'Tests//*.h',\n    ]),\n    srcs=glob([\n        'Tests//*.m',\n    ]),\n    frameworks=[\n        '$PLATFORM_DIR/Developer/Library/Frameworks/XCTest.framework',\n    ]\n)\n```. I see, thanks for the explanation!\nI'll try to cherry-pick the commit you referenced and see if it works.\nWould it be completely impossible to try to hack around this issue on BUCK file level?\nE.g. try to add -I dependency#headers-private to compiler_flags of apple_test rule somehow?\nOr to have some genrule that creates symlinks for private headers and puts them somewhere just for buck to pick up?\nSorry if I'm talking nonsense :)\nWould be nice to have a workaround on config level though.. I see, thanks for the explanation!\nI'll try to cherry-pick the commit you referenced and see if it works.\nWould it be completely impossible to try to hack around this issue on BUCK file level?\nE.g. try to add -I dependency#headers-private to compiler_flags of apple_test rule somehow?\nOr to have some genrule that creates symlinks for private headers and puts them somewhere just for buck to pick up?\nSorry if I'm talking nonsense :)\nWould be nice to have a workaround on config level though.. If anyone runs into this problem, we have somewhat ugly-ish workaround for it.\nThe trick is to add those private headers that apple_test can't find to its headers option, for example\n```python\napple_test(\n    headers=glob([\n        'Tests/*/.h',\n    ] + [\n        'Sources/PrivateHeader1.h',\n        'Sources/PrivateHeader2.h',\n        'Sources/PrivateHeaderEtc.h',\n    ]),\n```\nNow apple_test target will be able to find them.\nFinal change is to use <MyLib/PrivateHeader.h> imports in the test files, instead of \"PrivateHeader.h\", for example:\n```objc\n// MyLibTests.m\n// #import \"PrivateHeader.h\" // --> This will NOT work with modular=True\nimport  // --> This works\n```\nThe <MyLib/PrivateHeader.h> is also backwards compatible with Xcode, i.e. it still works with our current pre-buck Xcode projects, which we have to keep around still.\nI'm yet to check if it works with projects generated by buck project command.. If anyone runs into this problem, we have somewhat ugly-ish workaround for it.\nThe trick is to add those private headers that apple_test can't find to its headers option, for example\n```python\napple_test(\n    headers=glob([\n        'Tests/*/.h',\n    ] + [\n        'Sources/PrivateHeader1.h',\n        'Sources/PrivateHeader2.h',\n        'Sources/PrivateHeaderEtc.h',\n    ]),\n```\nNow apple_test target will be able to find them.\nFinal change is to use <MyLib/PrivateHeader.h> imports in the test files, instead of \"PrivateHeader.h\", for example:\n```objc\n// MyLibTests.m\n// #import \"PrivateHeader.h\" // --> This will NOT work with modular=True\nimport  // --> This works\n```\nThe <MyLib/PrivateHeader.h> is also backwards compatible with Xcode, i.e. it still works with our current pre-buck Xcode projects, which we have to keep around still.\nI'm yet to check if it works with projects generated by buck project command.. Afaik, a lot of companies have their own in-house scripts for that which is used during migration from CocoaPods to Buck and then never used again.\nThat totally would be an awesome feature to have as part of Buck.\nWe have our own as well, which is not very sharable at the current state, but what we do is this:\n\nRead podspec into JSON which is as easy as\n\nruby\nrequire \"cocoapods-core\"\nrequire \"json\"\nputs Pod::Specification.from_file(path).to_json\n\nPass that JSON to a python script which is using jinja2 template to convert JSON to BUCK file.\n\nI guess we could do all of it in Ruby or in any other language.. Afaik, a lot of companies have their own in-house scripts for that which is used during migration from CocoaPods to Buck and then never used again.\nThat totally would be an awesome feature to have as part of Buck.\nWe have our own as well, which is not very sharable at the current state, but what we do is this:\n\nRead podspec into JSON which is as easy as\n\nruby\nrequire \"cocoapods-core\"\nrequire \"json\"\nputs Pod::Specification.from_file(path).to_json\n\nPass that JSON to a python script which is using jinja2 template to convert JSON to BUCK file.\n\nI guess we could do all of it in Ruby or in any other language.. @robbertvanginkel just to double check, this would only apply to apple_library but not to apple_binary?\nAfaik, using bridging header with mix-n-match iOS app targets is the recommended way so we should still be able to use bridging headers with apple_binary. @robbertvanginkel just to double check, this would only apply to apple_library but not to apple_binary?\nAfaik, using bridging header with mix-n-match iOS app targets is the recommended way so we should still be able to use bridging headers with apple_binary. We've just experienced same issue with //.\nXcode actually resolves the path and displays it correctly in the error message, but it can't find it however.\n\n@brentleyjones do you have any nice way to massage generated Xcode projects and xcconfigs after buck has done its job?\nor should it be the job of buck wrapper shell script?. Another related issue is that autogenerated projects will have ONLY_ACTIVE_ARCH set to NO for all configurations.\nWhich causes build folder to be Debug-iphoneos even if simulator is selected as a target.\nI guess it's not a big deal as long as tests can find its host app the actual path doesn't matter much.\nStill not having the flag set will cause some extra build time.. Finally, LD_RUNPATH_SEARCH_PATHS has no value set in autogenerated project, which (at least in Xcode 10) causes tests to fail to run with error like this:\ndyld: Library not loaded: @rpath/libswiftCore.dylib\n  Referenced from: /Users/bigmac/Library/Developer/CoreSimulator/Devices/17728BBD-4269-4600-B3B4-729A93D44E9F/data/Containers/Bundle/Application/A96CB704-1AF4-41A7-B8D2-147B30450B4C/TestHost.app/TestHost\n  Reason: image not found\nThe fix is to set LD_RUNPATH_SEARCH_PATHS to $(inherited) '@executable_path/Frameworks' '@loader_path/Frameworks'. Cool. Thanks @ghvg1313 .\nI'll keep an eye on when it's imported and test it then.. Cool. Thanks @ghvg1313 .\nI'll keep an eye on when it's imported and test it then.. The generated Xcode still works.\nWell, after patching generated project wiht workarounds for https://github.com/facebook/buck/issues/1944 and https://github.com/facebook/buck/issues/1943.. Comparing the build.trace from before and after I do see a lot of changes\nthe older version of buck has way more compiler flags\nfor example, each framework used by the host app is added to tests bundle compile command like so:\n\n-I -Xcc path/to/static-library-used-by-host-app.hmap\n-I -Xcc path/to/static-library-folder\n\nnow all of those entries are gone, which is probably good since test bundle doesn\u2019t need to see those frameworks (or does it?)\ne.g. CocoaPods has inherit! :search_paths to make all frameworks visible to host app available to tests bundle too\nnext is more interesting\nthe older version also has this flag:\n\n-I -Xcc path/to/host-app-binary-folder\n\nand\n\n-I full/path/to/host-app-binary-folder\n-I -Xcc path/to/host-app/Bridging-Header.h\n\nI\u2019d assume these changes were intentional, I vaguely remember some conversation about not being able to mix bridging headers and modules\nnot sure exactly\nbut it seems that some of these flags missing is what causes the compile error I\u2019m seeing. Comparing the build.trace from before and after I do see a lot of changes\nthe older version of buck has way more compiler flags\nfor example, each framework used by the host app is added to tests bundle compile command like so:\n\n-I -Xcc path/to/static-library-used-by-host-app.hmap\n-I -Xcc path/to/static-library-folder\n\nnow all of those entries are gone, which is probably good since test bundle doesn\u2019t need to see those frameworks (or does it?)\ne.g. CocoaPods has inherit! :search_paths to make all frameworks visible to host app available to tests bundle too\nnext is more interesting\nthe older version also has this flag:\n\n-I -Xcc path/to/host-app-binary-folder\n\nand\n\n-I full/path/to/host-app-binary-folder\n-I -Xcc path/to/host-app/Bridging-Header.h\n\nI\u2019d assume these changes were intentional, I vaguely remember some conversation about not being able to mix bridging headers and modules\nnot sure exactly\nbut it seems that some of these flags missing is what causes the compile error I\u2019m seeing. It's most likely related to https://github.com/facebook/buck/issues/1918.\nIf I'd try to sum it up.\nBuck\nIf you want to import MyApp in your Swift tests, then MyApp must be built with modular=True.\nIf you want to use modular=True, then you can't use bridging_header (there's an error message for that now).\nSo if you happen to have an existing mix-n-match project with bridging header and unit tests written in Swift, you can't really use buck, at least with the latest version.\nOne workaround would be to refactor all the Objective-C code exposed via bridging header into separate modules, in which case there's no need for bridging header any more.\nXcode\nThings \"just work\".\nI Wish...\nIt's worth mentioning that CocoaPods has a special case inherit! :search_paths to expose search paths of the host app to the test target:\nruby\ntarget :MyApp do\n  target :MyAppTests do\n    inherit! :search_paths\n  end\nend\nI would love for buck to have the the analogue of inherit! :search_paths, e.g. an option I could opt-in to use to be able to build existing mix-n-match project.\nYes there are possibilities of duplicate symbol definitions and such, but the \"I know what I'm doing\" option imho would be nice to have.. Update\nSo I got rid of the bridging header for good and added modular=True to the apple_binary rule.\nThen... I still get same error \ud83d\ude31\n\nerror: no such module 'MyApp'\n@testable import MyApp\n\nI was told that enabling modular builds and getting rid of bridging header will solve the problem \ud83d\ude22 \nI using this buck release: https://github.com/facebook/buck/releases/tag/v2018.10.29.01\n. Update\nSo I got rid of the bridging header for good and added modular=True to the apple_binary rule.\nThen... I still get same error \ud83d\ude31\n\nerror: no such module 'MyApp'\n@testable import MyApp\n\nI was told that enabling modular builds and getting rid of bridging header will solve the problem \ud83d\ude22 \nI using this buck release: https://github.com/facebook/buck/releases/tag/v2018.10.29.01\n. I've updated the sample to have super flat setup: https://github.com/mgrebenets/test-app-with-bridging-header\n@robbertvanginkel Would you have any idea on what I'm doing wrong?\nI've enabled modular=True for apple_binary.\n```python\napple_binary(\n    name='AppBinary',\n    module_name='App',\n    modular=True,\n    visibility=['PUBLIC'],\n    entitlements_file='Sources/Entitlements.entitlements',\n    preprocessor_flags=[\n        '-fobjc-arc',\n        '-Wno-objc-designated-initializers',\n    ],\n    headers=glob([\n        'Sources//*.h',\n    ]),\n    exported_headers=glob([\n        'Sources//.h',\n    ]),\n    srcs=glob([\n        'Sources//*.swift',\n        'Sources//.m'\n    ]),\n    frameworks=[\n        '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n        '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    ]\n)\napple_bundle(\n    name='AppBundle',\n    visibility=['PUBLIC'],\n    binary=':AppBinary',\n    extension='app',\n    info_plist='Sources/Info.plist',\n    tests=[':Tests']\n)\napple_test(\n    name='Tests',\n    # modular=True,\n    info_plist='Tests/Info.plist',\n    info_plist_substitutions={\n        'PRODUCT_BUNDLE_IDENTIFIER': 'org.' + 'Tests',\n    },\n    srcs=glob([\n        'Tests//*.swift',\n        'Tests//*.m',\n    ]),\n    # test_host_app=':AppBundle',\n    deps=[\n        ':AppBundle',\n    ],\n    frameworks=[\n        '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n        '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n        '$PLATFORM_DIR/Developer/Library/Frameworks/XCTest.framework',\n    ]\n)\n``. In the sample I\u2019ve shared, if I capture theswiftccommand produced bybuckw build tests, then add-I buck-out/gen/AppBinary#iphonesimulator-x86_64,swift-compile`\nthe compilation then succeeds\n-I buck-out/gen/AppBinary\\#iphonesimulator-x86_64,swift-compile is where the following files are sitting:\nApp-Swift.h\nApp.o\nApp.swiftmodule\nbuild-command-scripts.zip. It appears to be the case only for apple_binary / apple_bundle and apple_test combination.\nThere's absolutely no issue with using @testable import MyLib when working with apple_library and apple_test.. ",
    "zorroblue": "I too am facing the same issue. Would be great if the maintainers could resolve it. :)\nI managed to do a temporary hack to resolve this, in GccCompiler.java and GccPreprocess.java of src/com/facebook/buck/cxx/toolchain/, you could return Optional.<ImmutableList<String>>empty() in the function getFlagsForColorDiagnostics(). \nI guess even removing the function from both files would do the job as it is overriden. . ",
    "linzhp": "Any updates on this?. OK. We are planning to implement some improvement on this. srcs=['.'] doesn't work.. The native Go compiler does filter files. If you run go build github.com/jessevdk/go-flags, only source files in the package compatible with the current platform are included. I am trying to figure out how Buck turns that filtering off and how I can turn it on again. Any hint?. If I have to add deps and create a BUCK file for assert, then it works even without specifying vendor_path. So what does vendor_path do?. Could you give me an example? With the deps and BUCK file, import \"github.com/stretchr/testify/assert\" works both with and without vendor_path. What kind of path rewrite does it do?. Thanks for the detailed reply. I just renamed the 'vendor' directory to 'third-party/go' and update the deps to '//third-party/go/github.com/stretchr/testify:assert'. In addition, the .buckconfig file is intentionally set to:\n[go]\n  vendor_path = wrong/path\nNow buck test //:command_test still works. It seems that go.vendor_path is not used by Buck at all.. Now I see the reason. I have package_name='github.com/stretchr/testify/assert' in the BUCK file. So it overrides the vendor_path. Thanks for the help!. @styurin Let's move the discussion on the directory support here:\nWe've considered the zipping option before implementing this PR, but felt it might slow down the build. And I couldn't remember if I figured out how to unzip the source files in go_library either. We are open to more discussion on that issue.. The output of UnzipStep is a directory. So in the end, we still have to deal with source directories anyway. Zipping and unzipping merely add some unnecessary computational cost. Do you see any benefits?. Done. Hope this is the last rebase I have to do before it gets merged. I've done several times before for this PR, and it got conflicts after hanging here for a few more days:(. The Travis CI is complaining about some unused local variables. Could you make all Travis CI tests and checks pass?. Awesome! It works. Added the working example to here for future reference.\nThanks for the fix!. Travis CI passed. Are you using Go at all in Facebook? If not, it may only require a configuration change in your CI environment, similar to this one. Good point! Just added test assumptions for cgo related test. Now your internal integration tests should be happy:). @ttsugriy @styurin Please review. That goest to buck-out/gen/test/com/facebook/buck/features/go/testdata/go_test/__test_test-failure_output__/results, which is separate from what buck test prints out on the terminal. I am trying to figure out what goest to the termimal.. When --ide=GoLand, Buck will skip project file generator, and only run pre_process and post_process scripts. This is a very generic approach, as some IDEs/Code editors use the source code as the ground truth, and don't need a project file to start with but need some processing to put code into right place. We may also think about defaulting to this behavior when --ide is neither intellij or xcode.. Isn't this .buckconfig option designed to do so?. This is currently a blocking issue for us. As a compromise, can we keep Go in the core temporarily, and we are committed to move it back to features once you have that plugin extension point ready? JVM and Apple languages are still in the core anyway, and that is why project command is able to create IntelliJ and XCode projects.\nWe don't like the idea of keeping a private fork for this PR, as it moves many files, and changes from upstream are likely to result in a painful conflict and merge process. It's relatively easier to Go out of core.\n. Figured out a way to load Go extension in runtime. So now Go module is out of core again. Please take another look @styurin . Figured out a way to load Go extension in runtime. So now Go module is out of core again. Please take another look @styurin . Pinging @styurin @ttsugriy @philipjameson Could you review this PR?. Pinging @styurin @ttsugriy @philipjameson Could you review this PR?. Pinging @styurin @ttsugriy @philipjameson again. @mkaczanowski You imported this PR 4 days ago. Could you check why it is still not merged yet?. @mkaczanowski Could you import this PR again? I updated an outdated doc related to cgo too.. I am not concerned about not being able to use STATIC (otherwise I would have sent you a PR already :D ) Eliminating invalid option to avoid issues sounds good to me.. This PR is not about the generation process, but about the compilation of generated cgo files that include generated .h files. cxx_genrule is not capable of compiling cgo files, as I don't see a good way to call the cgo command from the configured GOROOT.. Any more concerns with this PR?. That would be great. The test case introduced by this PR capture the scenario that's currently blocking us. It is essentially a generated Go package that has cgo, C, and headers. Ideally, a cgo_libary should be able to take all cgo, C source files and headers as input without having to rely on a cxx_library.\nCould you merge this PR as a temporary fix so that we can be unblocked without having to maintain our fork before your larger improvement comes in?. @bobyangyf Did you build succeed in your internal CI? . @bobyangyf Moved that logic to the parsing phase. Please take another look. Cool! Could you land it?. @kageiit You can write integration tests similar to this. - The same reasoning for the support of publishing to Maven repo should apply here\n- The document of buck publish never mentions that it is dedicated for Java/Maven only. This PR just made it as generic as it is supposed to be. - The same reasoning for the support of publishing to Maven repo should apply here\n- The document of buck publish never mentions that it is dedicated for Java/Maven only. This PR just made it as generic as it is supposed to be. Closing this. Will send out another PR so it can publish zip_files to Maven repo. Closing this. Will send out another PR so it can publish zip_files to Maven repo. @ttsugriy Could you take a look?. @ttsugriy Could you take a look?. Updated description. @styurin . @kageiit Thanks, I am aware of this change. @mkaczanowski did a good job in communicating breaking changes. cc @vitarb. Buck is actually running \"go list\" to filter the platform specific Go files. Maybe we can get package name out of it too.. stringer and mockery are two examples.. The reason of this is Buck maintains some metadata in buck-out/bin to decide whether a target with the same input has been built before. If it is, Buck will report \"FOUND\" and assume the output is already in buck-out/gen, thus skipping the target. In this case, it doesn't even attempt to look up the cache, so --no-cache flag doesn't apply. The way to force Buck rebuild a target is by deleting the target from buck-out/bin and use --no-cache during next build.. @nemith. Yes, I can still reproduce it with latest Buck from master. I use buckd, and it restarts when I run buck clean. That's great! Thanks!. @styurin @ttsugriy @philipjameson  Could you take a look?. Fixed. @LLITCHEV @bobyangyf Please take another look. @LLITCHEV Just ran buildifier to format that file. Please try again. Thanks. reduced the binary file size and rebased onto master. @styurin . Looking forward to it. Tested it. It works. Thank you!. Thanks!. It will most likely break. Should I skip that test for now and put a comment to enable it only after Buck officially supports Go 1.7?. Added the check for Go version. Please take another look. Good catch! Updated to use regex.. I was struggling to pass the integration test on Travis CI. GOROOT was set somewhere to /usr/local/go, cause go list command to throw an error go: cannot find GOROOT directory: /usr/local/go.\nDo you know how GOROOT gets the value /usr/local/go in Travis CI? Running integration tests locally doesn't have the problem.. The caller of this method will throw an exception if it returns an empty list. So I have to return some command. What other command do you suggest?. The new regex allows both variants. The new regex ignores the patch version as there shouldn't be any new feature added as the patch version changes.. Throwing an exception here will crash buck. As this step doesn't expect any stdout, putting a message in the stdout will result in a warning message in Buck's output (colored as red). If there are things in this package needed by other packages, the build will fail with message saying something is undefined. Combined with the warning message here, it's easy to track down the problem. If the build succeeds regardless, it means this package is not necessary for the current platform, although it might be necessary for other platforms. Buck should tolerate such scenario too.. The compile command will fail if there is no source file, producing an error message prompting the correct format of the command line arguments, which can be used in place of this echo message. I do the due diligence check for lack of input files here, but the existence of raw source files doesn't guarantee the existence of filtered source files.. The length of srcs can not be determined until GoListStep is executed. So in GoCompile.getBuildSteps, we are not always sure whether to skip GoCompileStep. In this method, when GoCompileStep is about to execute, it's probably too late to yank it out. Do you see a way to skip GoCompileStep after GoListStep is executed?. This issue is really not about supporting directories. The FilteredSourceFiles only takes individual source files, not directories. What it does is run a \"go list\" command on the parent directory of each file, and decide whether to ignore the source file. Removing the support for directories doesn't affect any code in this filtering logic. One can still pass a Windows specific Go file into go_library, by either using glob or the file name, and try to compile it on Linux. This filtering still has to happen in order to have the compiler skip that file.\n. Go source files have build constraints, which specify whether a source file should be compiled for the current platform. In order for Buck to honor the build constraints, there are two options:\n\n\nRunning \"go list\" command on the directory each go file resides. As \"go list\" command only returns source files with all build constraints satisfied, we can know whether we should pass a file to the compiler by checking if it's in the output of \"go list\"\n\n\nImplement a constraints solver ourselves. Then it won't rely on \"go list\" command, and we don't need GoListStep anymore. Also, we will know early on whether to skip GoCompileStep in GoCompile.getBuildSteps. However, the constraint solver will need to update whenever the definition of Go build constraints changes\n\n\nIn either option, the build constraints are checked on file-to-file basis. All directories passed in from build rules have been expanded before the filtering logic takes place, so the filtering logic only sees files, not directories. Do you see how this logic can be simplified if the directory support is removed?. It is a method implemented in C programming language. For more information about Go calling into code written in C, please refer to the official cgo document.. Good idea. Updated now. Oh, I wasn't aware of such option before. Thanks for pointing out.. @monty-uber is working on a big change that has a side effect of adding the backward compatibility. The change is not self contained, and cannot be cherry-picked to this PR.\nBefore his PR is ready, this PR will enable Buck work with the latest version of Go.. Those line breaks are added by Google Java formatter, in order to pass CI checks. Yes there are, but we don't. Figuring out a proper default package name will need to load another class from go module and use the same reflection trick to call its methods. . No, initGoWorkspace only scans go_library rules. If there is no such rule in the workspace, it is a no-op.. vendor is a place to put third-party libraries. Go toolchain and IDEs is able to automatically pick up the Go packages in vendor directory. It is a good place to put Go packages that we don't want to put into source control.. We really need this feature now. Since changes in this PR is very localized, it is easy to change whenever you migrate project command. I am happy to assist you for migrating this piece of code.. Vendor directory can be anywhere under GOPATH/src, and Go toolchain automatically detects that. if (fs.exists(Paths.get(\"src\"))) is just in case buck root is at GOPATH, i.e., the parent of src directory. Of course, this logic would fail if buck root is in a higher directory than GOPATH. In that case, Buck has to search all directories under buck root for src. It is expensive and non-deterministic (e.g., what if there are more than one src?). We don't want to sacrifice the performance and make the logic more complicated to handle a scenario that doesn't exist for us. We will leave it for future users when they have a real use case.. No, unfortunately. header_namespace = \"\" allows the C compiler running from buck root to compile CGo-generated C files with #include \"lib.h\". Otherwise, C compiler would try to find lib.h from its current directory (i.e., buck root), resulting a failure.\nThe --I flag in this fix only tells the CGo compiler to find lib.h from the target's base directory. It doesn't pass that message to the C compiler.. Fixed.. @mkaczanowski Thanks for landing this PR. Looks like this line disappeared during merging, effectively disabling this test. Could you fix it?. This has been tested for GoLand and Visual Studio Code. Yes, it is just copying files. This is sufficient for these IDEs to work. Go is more like \"convention over configuration\" style. So it has strong conventions about where packages should be put, rather than relying on configuration files to tell the IDEs and Go toolchain where to search for packages.. Go toolchain and IDEs don't take configurations like that, unfortunately. Only packages in the main src directory and vendor directories are recognized. . The approach here is very flexible, not repository specific at all. If a project has its own vendor folder at GOPATH/src/foo/bar/vendor, and the buck root is at GOPATH, then the generated code will be copied into GOPATH/src/vendor. If the buck root is at GOPATH/src/foo, the the generated code will be copied to GOPATH/src/foo/vendor. All of these vendor folders are recognized by Go toolchain and IDEs at the same time.\nOf course, if you want the vendor folder location to be further configurable by users, I can do that too.\nOverall, I see this PR a temporary solution to unblock Go developers using Buck. For long term solution, there are discussions on Bazel side for over a year (1, 2). We may want to watch with Bazel community and see what they end up with. Whatever the long term solution ends up, I am happy to assist the migration.\nIf you have further concerns about this feature, I can also add a configuration that disable this feature by default.\nI also notice that @mkaczanowski recently commit changes trying to support IDEs (great thanks to @mkaczanowski), but the performance is somehow quite bad (I need to dig a bit deeper to understand why), and I am not quite sure about symlink tree too, as people in Bazel run into problems with symlink trees (3). This change is not quite related to this PR. It is more related to a previous concern @styurin raised about passing directories as srcs [1]. As this PR restricts the header include directory to BuildTargetSourcePath, I realized we may need similar restriction here too.\nWhether it is really required is a question for @styurin. I am going to put this in another PR to unblock this one.. If backward compatibility is the preference, I can certainly make it happen by keeping all the existing flags and adding another flag call isMaven. However, this new flag is mutually exclusive of the to-maven-central. It feels a bit redundant.\nI can also set the default value of toMaven to be true, to keep the changes to existing use cases minimal.. Because of a NoClassDef error. Something to use as the placeholder for non-printable characters. If you don't like this one, please suggest another one, I will replace.. Just a placeholder for non-printable characters. If I don't specify any, those will be skipped by default and the output may be empty.. If a test expects a function to return some text, but that function actually returns a binary string, go test will print out both strings, which includes non-printable characters.\nAny suggestion for the replacement character?. ",
    "ZacSweers": "Thanks! I'll take a look.\nIn the meantime, I think a good start would also be to re-enable ABI jars for pure java projects depending on kotlin projects to allow some progress. For java there's no difference, so I don't think there's a reason for blocking that. It's only kotlin projects depending on other kotlin projects that really need it proper ABI jar support. Why not support the modern prefixing pattern? It hasn't changed in some time. NDK r16 has been released. 17 is now out, this is broken again :/. CC @kageiit . It likely would need to come as a community contribution like all the other kotlin support. It likely would need to come as a community contribution like all the other kotlin support. Did you not need to handle the annotation processing jar?. Did you not need to handle the annotation processing jar?. The reason I ask is because our internal build failed due to okbuck trying\nto download it, so I wasn't sure where in the pipeline that was happening\nOn Thu, Nov 16, 2017 at 10:19 AM Gautam Korlam notifications@github.com\nwrote:\n\nDid you not need to handle the annotation processing jar?\nIts not required for compilation. kapt support is being handled separately\nby @cwoodwar6 https://github.com/cwoodwar6 's kapt PR that will attach\nthe jar as a compiler argument instead\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1627#issuecomment-345011690, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABTEvjgUc74H9t3WuLozuL4Ub_vVnsUnks5s3HyVgaJpZM4QgpSC\n.\n. The reason I ask is because our internal build failed due to okbuck trying\nto download it, so I wasn't sure where in the pipeline that was happening\nOn Thu, Nov 16, 2017 at 10:19 AM Gautam Korlam notifications@github.com\nwrote:\nDid you not need to handle the annotation processing jar?\nIts not required for compilation. kapt support is being handled separately\nby @cwoodwar6 https://github.com/cwoodwar6 's kapt PR that will attach\nthe jar as a compiler argument instead\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1627#issuecomment-345011690, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABTEvjgUc74H9t3WuLozuL4Ub_vVnsUnks5s3HyVgaJpZM4QgpSC\n.\n. :+1: LGTM then\nOn Thu, Nov 16, 2017 at 10:21 AM Gautam Korlam notifications@github.com\nwrote:\nThe reason I ask is because our internal build failed due to okbuck trying\nto download it, so I wasn't sure where in the pipeline that was happening\nThats handled separately in uber/okbuck@00b9638\nhttps://github.com/uber/okbuck/commit/00b96385c4879cace766894d20820866cc74d182\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1627#issuecomment-345012466, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABTEvr2RRf5B9CasOfEP3hYAz4jBs9PFks5s3H05gaJpZM4QgpSC\n.\n. :+1: LGTM then\nOn Thu, Nov 16, 2017 at 10:21 AM Gautam Korlam notifications@github.com\nwrote:\nThe reason I ask is because our internal build failed due to okbuck trying\nto download it, so I wasn't sure where in the pipeline that was happening\nThats handled separately in uber/okbuck@00b9638\nhttps://github.com/uber/okbuck/commit/00b96385c4879cace766894d20820866cc74d182\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/pull/1627#issuecomment-345012466, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABTEvr2RRf5B9CasOfEP3hYAz4jBs9PFks5s3H05gaJpZM4QgpSC\n.\n. CC @kageiit . CC @tyvsmith @kageiit . I do see it wired in\n\nhttps://github.com/facebook/buck/blob/06ecade50006cfb4b0a5e63a04eea0d63792b91c/src/com/facebook/buck/jvm/kotlin/KotlincToJarStepFactory.java#L88\nhttps://github.com/facebook/buck/blob/06ecade50006cfb4b0a5e63a04eea0d63792b91c/src/com/facebook/buck/jvm/kotlin/KotlincToJarStepFactory.java#L137-L138\nAnd those directories are getting generated, but there's no output in them. After some grep magic, I'm seeing them, but in really random places\nIf I have a project under /libraries/foundation/modelgen/thrift-utilities\nthey end up duplicated in several places, and none of them are linked in buck project\n./buck-out/gen/libraries/foundation/modelgen/thrifty-utilities/lib__src_main____working_directory/com/uber/thrifty/ThriftFieldJsonAdapter.kt\n./buck-out/annotation/libraries/foundation/modelgen/thrifty-utilities/__src_main_kapt_generated__/com/uber/thrifty/ThriftFieldJsonAdapter.kt\n./buck-out/bin/libraries/foundation/modelgen/thrifty-utilities/__src_main_gen_sources__/com/uber/thrifty/ThriftFieldJsonAdapter.kt\n./build/buildScript/project-build/libraries/foundation/modelgen/thrifty-utilities/build/generated/source/kaptKotlin/main/com/uber/thrifty/ThriftFieldJsonAdapter.kt\n./build/buildScript2/project-build/libraries/foundation/modelgen/thrifty-utilities/build/generated/source/kaptKotlin/main/com/uber/thrifty/ThriftFieldJsonAdapter.kt\nDoes this imply the processor is being invoked multiple times with different output locations?. One of them does appear on the classpath, but not sure how to see which. CC @thalescm . Agreed on deleting being the best path forward to clear up confusion. Will try the gradle config (I'm a bit worried we'd have to end up pointing somewhere in buck-out), but shouldn't buck project pick this up correctly in native buck?. Hey - it would be great if someone from the buck team could acknowledge this. It's a major blocker for kotlin-first annotation processors. This would be a pretty standard thing to support in kotlin. Is it the position of the buck team that kotlin issues shouldn't be fixed?. I see this is still marked as wontfix?. CC @kageiit @thalescm . Not sure, this is all configured by okbuck. Will wait for @kageiit to chime in. My question I think is more - why is there such a strict upper bound? . My question I think is more - why is there such a strict upper bound? . Why not allow users to hit those issues though? Worst case it's incompatible and you can say it's not supported yet. Best case it works out of the box (as has been the cast in most updates), and middle-ground is you get early bug reports. Why not allow users to hit those issues though? Worst case it's incompatible and you can say it's not supported yet. Best case it works out of the box (as has been the cast in most updates), and middle-ground is you get early bug reports. can the plugin just no-op itself? Or pick up the port from the specific project? This issue came up on our end because right now it is impossible to run two clones of the same project locally. Note that I'm not very familiar with the project and am not sure if/where to add tests, so guidance welcome!. The CI failures look unrelated. I've taken a full documentation pass an opted to just remove the old style for args (mostly copying from the Kotlin compiler args docs themselves). Before I move on to tests, I'd like to get another review of the current implementation (particularly from the buck folks).\nThe CI failures look unrelated. I've noticed them on a few other PRs as well. \n. \n. I've rebased and run GJF over the files. I've rebased and run GJF over the files. Hard to keep track, as it was failing due to issues on master before I rebased too. I don't really know what's going on with it. Some sort of interface merging issue in Immutables? setLanguageVersion isn't part of the android library description, so I don't know why it's pointing there\njava.lang.IllegalStateException: Couldn't find declared getter for class com.facebook.buck.android.AndroidLibraryDescriptionArg$Builder#setLanguageVersion. Tried parent classes [interface com.facebook.buck.android.AndroidLibraryDescription$AbstractAndroidLibraryDescriptionArg, class java.lang.Object, interface com.facebook.buck.android.AndroidLibraryDescription$CoreArg, interface com.facebook.buck.jvm.java.JavaLibraryDescription$CoreArg, interface com.facebook.buck.android.AndroidKotlinCoreArg, interface com.facebook.buck.core.description.arg.HasDepsQuery, interface com.facebook.buck.core.description.arg.HasProvidedDepsQuery, interface com.facebook.buck.jvm.java.JvmLibraryArg, interface com.facebook.buck.core.description.arg.HasDeclaredDeps, interface com.facebook.buck.core.description.arg.HasProvidedDeps, interface com.facebook.buck.core.description.arg.HasSrcs, interface com.facebook.buck.core.description.arg.HasTests, interface com.facebook.buck.jvm.kotlin.KotlinLibraryDescription$CoreArg, interface com.facebook.buck.core.description.arg.CommonDescriptionArg, interface com.facebook.buck.jvm.java.MaybeRequiredForSourceOnlyAbiArg, interface com.facebook.buck.core.description.arg.HasTargetCompatibleWith] methods: [getLanguageVersion, isLanguageVersion]\n    at com.facebook.buck.rules.coercer.ParamInfo.findClosestGetterOnAbstractClassOrInterface(ParamInfo.java:317)\n    at com.facebook.buck.util.function.ThrowingSupplier.lambda$1(ThrowingSupplier.java:41)\n    at com.facebook.buck.util.AbstractMemoizer.get(AbstractMemoizer.java:42). Hard to keep track, as it was failing due to issues on master before I rebased too. I don't really know what's going on with it. Some sort of interface merging issue in Immutables? setLanguageVersion isn't part of the android library description, so I don't know why it's pointing there\njava.lang.IllegalStateException: Couldn't find declared getter for class com.facebook.buck.android.AndroidLibraryDescriptionArg$Builder#setLanguageVersion. Tried parent classes [interface com.facebook.buck.android.AndroidLibraryDescription$AbstractAndroidLibraryDescriptionArg, class java.lang.Object, interface com.facebook.buck.android.AndroidLibraryDescription$CoreArg, interface com.facebook.buck.jvm.java.JavaLibraryDescription$CoreArg, interface com.facebook.buck.android.AndroidKotlinCoreArg, interface com.facebook.buck.core.description.arg.HasDepsQuery, interface com.facebook.buck.core.description.arg.HasProvidedDepsQuery, interface com.facebook.buck.jvm.java.JvmLibraryArg, interface com.facebook.buck.core.description.arg.HasDeclaredDeps, interface com.facebook.buck.core.description.arg.HasProvidedDeps, interface com.facebook.buck.core.description.arg.HasSrcs, interface com.facebook.buck.core.description.arg.HasTests, interface com.facebook.buck.jvm.kotlin.KotlinLibraryDescription$CoreArg, interface com.facebook.buck.core.description.arg.CommonDescriptionArg, interface com.facebook.buck.jvm.java.MaybeRequiredForSourceOnlyAbiArg, interface com.facebook.buck.core.description.arg.HasTargetCompatibleWith] methods: [getLanguageVersion, isLanguageVersion]\n    at com.facebook.buck.rules.coercer.ParamInfo.findClosestGetterOnAbstractClassOrInterface(ParamInfo.java:317)\n    at com.facebook.buck.util.function.ThrowingSupplier.lambda$1(ThrowingSupplier.java:41)\n    at com.facebook.buck.util.AbstractMemoizer.get(AbstractMemoizer.java:42). Abandoning this on account of lack of feedback/interest from the BUCK team.. Abandoning this on account of lack of feedback/interest from the BUCK team.. Does @Value.Default ensure that an implementation still gets generated under the hood too?. 02d8940. any good prior examples you could point me to?. I think that was incorrect before, as the default is false. True, I can move these as well. I admittedly am not familiar with these args. ~~Consolidated in b48992c~~ nevermind, been a minute. It actually looks like these two are false by default and not exactly documented. I'm not sure if they're maybe just required for kapt, so going to leave them as-is for now rather than move to the standard options. If they're not required for kapt either, we can just look at getting rid of them. I was naming these to match the naming semantics that the kotlin tooling itself uses for consistency. ",
    "scottrice": "You can do this by creating a target like the following:\n(Note - I'm freehanding this so it might not build exactly, but you'll get the general idea)\n```\napple_bundle(\n  name = 'CoolFramework'\n  binary = ':CoolFrameworkBinary',\n  # Tell Buck it will be a framework\n  extension = 'framework',\n  info_plist = ...,\n)\nNow for the important parts...\napple_library(\n  name = 'CoolFrameworkBinary',\n  # Tell Buck that consumers of this binary should use the #shared (aka dylib) version\n  preferred_linkage = 'shared',\n  # But that the library itself is going to be statically linked\n  link_style = 'static',\n  # Set the install_name so consumers know where to find it\n  linker_flags = ['-Wl,-install_name,@rpath/CoolFramework.framework/CoolFramework']\n  # For the above to work, we need to have rpath set to the Frameworks directory of our bundle. This line makes sure that all dylib consumers know that.\n  exported_linker_flags = ['-Wl,-rpath,@executable_path/Frameworks'],\n  # And then you just fill in the rest like normal...\n  srcs = ...,\n)\n```\nThat should do what you want. I'm not sure how this works with Xcode project generation, but it should work if you do buck build. If you want to include a bundle which already exists in your binary, then you can do so by adding an apple_resource rule with dirs that includes a path to your .bundle folder. This of course assumes that you have the bundle on disk already and that you want to place that in your binary exactly as is.\nIf some of the contents of the bundle are unknown though (like they are the output of another build step), then putting together a bundle is a bit more difficult. Buck currently doesn't have anything set up, although since a .bundle is just a directory you could create a genrule to do what you want.\nSomething like this:\ngenrule(\n  name = 'SomeOutput.bundle',\n  out = 'SomeOutput.bundle',\n  bash = 'some_script_to_put_files_in_a_folder.sh $OUT $SRCS',\n  srcs = [\n    # All the files you want in your bundle\n  ],\n)\nMy bash-foo is weak, but theres probably a bash one-liner to copy all sources to the out folder. Anyway, a genrule like that will let you generate a bundle and then you can build it with buck build //path/to/buck/file:SomeOutput.bundle.\nThere is also the apple_bundle rule, but it is meant for the bundle which contains binaries (like .framework, .app, or .appex bundles). If you are just looking for a folder which can hold your files, a genrule is easiest.. This actually already exists - its a semi-secret \"compilation-database\" flavor. Its only briefly mentioned in the docs, and not in a very useful location - https://buckbuild.com/concept/buckconfig.html#client.skip-action-graph-cache\nAnyway, you use it like:\nbuck build --show-output //lib/FooKit:FooKit#compilation-database,iphonesimulator-x86_64,static. Hijacking this old issue with a workaround + more details.\nThe Issue\nAs mentioned in the original post, the issue is the use of iteritems() in make_pex.py, which doesn't exist in python3 (items now does what iteritems does). This is a problem because we execute make_pex.py with whatever the configured python interpreter is - https://github.com/facebook/buck/blob/71e515269fc54693a18f8d13c68f65a939644d48/src/com/facebook/buck/features/python/toolchain/impl/DefaultPexToolProvider.java#L87-L88\nThis means setting your interpreter to python3 is a trap, since Buck-internal code doesn't work in that environment.\nThe fix is to either make make_pex.py work with all Python versions, or somehow use a different interpreter for it (since Buck itself relies on Python2 it means an interpreter for it must exist somewhere on the system, so maybe hijack that? Not sure how difficult it is to make a file work on every possible Python version)\nThe Immediate Workaround\nIf you want to use Python3 for a project and this issue hasn't been solved yet, there is an easy workaround.\nRather than doing\n[python]\ninterpreter = python3\nYou change it to the following\n[python#py3]\ninterpreter = python3\nand then change your BUCK file accordingly\npython_binary(\n  name = \"TooCoolForSchool\",\n  platform = \"py3\",  # <<< THIS IS THE CRUCIAL LINE\n  # ...\n)\nThis tells Buck to use the py3 interpreter for your binary, but still lets it run make_pex.py with the old one.. There are a few ways to change the way headers are mapped in Buck.\nOn Apple rules, there is the header_prefix_path argument\nOn cxx rules, there is the header_namespace argument\nAnd on both, the headers parameter allows specifying a dictionary, where the value is the path to the header and the key is the path you want it accessible by. So you could have a dictionary like\nheaders = {\n  \"history.hpp\": \"history.hpp\",\n  \"synchistory.hpp\": \"sync/history.hpp\",\n}\n(I'm not suggesting those are the names you should use, just illustrating how it works). There are a few ways to change the way headers are mapped in Buck.\nOn Apple rules, there is the header_prefix_path argument\nOn cxx rules, there is the header_namespace argument\nAnd on both, the headers parameter allows specifying a dictionary, where the value is the path to the header and the key is the path you want it accessible by. So you could have a dictionary like\nheaders = {\n  \"history.hpp\": \"history.hpp\",\n  \"synchistory.hpp\": \"sync/history.hpp\",\n}\n(I'm not suggesting those are the names you should use, just illustrating how it works). This error is due to make_pex.py not supporting Python3. When you do which python and python -v on the command line, what do you get?. This error is due to make_pex.py not supporting Python3. When you do which python and python -v on the command line, what do you get?. ",
    "michaeleisel": "great, thanks!. ",
    "zhan-xiong": "Having some delays with getting the CLA signed :( will update when it's settled (probably a few more days). CLA should be accepted now, I think. @styurin any updates about this?. Hmm thought I did o.o reformatting now. Hmm thought I did o.o reformatting now. I've made the ResourceFolderFactory change but I'm not entirely sure if it makes things neater, since ResourceFolders have to eventually inherit from IjFolder, which requires an IjFolderFactory getFactory() method for merging. This means we have two kinds of factory for each resource folder, which seems confusing.\nAlso, I think that source folders in the context of the addSourceFolders etc methods actually refer to IjFolders (which are given as  in the module xml), perhaps keeping the old factories and renaming the methods to addIjFolders might make more sense?. I've made the ResourceFolderFactory change but I'm not entirely sure if it makes things neater, since ResourceFolders have to eventually inherit from IjFolder, which requires an IjFolderFactory getFactory() method for merging. This means we have two kinds of factory for each resource folder, which seems confusing.\nAlso, I think that source folders in the context of the addSourceFolders etc methods actually refer to IjFolders (which are given as  in the module xml), perhaps keeping the old factories and renaming the methods to addIjFolders might make more sense?. Yeah, I realize that I'm wrong about not needing to handle relativeOutputPath if the resources root isn't set, since source folders can have a packagePrefix that will still change where resources end up away from the regular one. Will put up a fix soon.. Yeah, I realize that I'm wrong about not needing to handle relativeOutputPath if the resources root isn't set, since source folders can have a packagePrefix that will still change where resources end up away from the regular one. Will put up a fix soon.. Here's a fix that tries to detect the effective resource root for each file and uses that to compute the relative output path. A few questions though:\n1) I had a couple of bugs where calling Path::startsWith() on an empty path returns false, which seems unintuitive to me. Is there a better way of handling this rather than checking against an empty path in addition to using startsWith()?\n2) After thinking about it some more, it doesn't make sense for there not to be a resources root ever (at worst, buck uses the project root path as the \"resources root\"), so I removed Nullable from it. I'm not sure if I'm missing any corner cases though. Here's a fix that tries to detect the effective resource root for each file and uses that to compute the relative output path. A few questions though:\n1) I had a couple of bugs where calling Path::startsWith() on an empty path returns false, which seems unintuitive to me. Is there a better way of handling this rather than checking against an empty path in addition to using startsWith()?\n2) After thinking about it some more, it doesn't make sense for there not to be a resources root ever (at worst, buck uses the project root path as the \"resources root\"), so I removed Nullable from it. I'm not sure if I'm missing any corner cases though. Just realized part of it is implemented here two days ago, will rework to use some of the features there. Just realized part of it is implemented here two days ago, will rework to use some of the features there. Having some delays with getting the CLA signed :( will update when it's settled (probably a few more days). CLA should be accepted now, I think. * Fixed ant lint\n* The PR can save configurations from the current file when right-clicking on a test method/class, updated description to be clearer. 1. Filtered out non-test files from the test config producer. Still kind of slow (~1-2 seconds lag for me) when right-clicking in test files (I guess buck query just isn't fast enough..?). I can't think of a good way around it; line actions isn't affected because it runs in the background, so all that happens is that it takes a good number of seconds on startup to generate the button.\n\nNot sure if it's caused by this change, but the first run of a buck test when starting up (regardless of the method used) doesn't seem to process the buck output correctly, so doesn't notice the number of tests that have actually passed.\n\nI think I'm going to need to do a lot more testing for this change first, but any other comments would be welcome.\n. 1. Filtered out non-test files from the test config producer. Still kind of slow (~1-2 seconds lag for me) when right-clicking in test files (I guess buck query just isn't fast enough..?). I can't think of a good way around it; line actions isn't affected because it runs in the background, so all that happens is that it takes a good number of seconds on startup to generate the button.\n\nNot sure if it's caused by this change, but the first run of a buck test when starting up (regardless of the method used) doesn't seem to process the buck output correctly, so doesn't notice the number of tests that have actually passed.\n\nI think I'm going to need to do a lot more testing for this change first, but any other comments would be welcome.\n. Any updates about this one?. I think what happens is that when annotated with Guice, then guice handles all of the dependency injection, so that anything in https://github.com/google/guice/wiki/Injections will work. We use injection via constructor rather frequently throughout our unit tests; it works correctly with this fix applied.. @styurin Sorry for the delay, was busier than expected for the past few weeks. I can't seem to reproduce the test failure locally either, do you have more details maybe?. Actually after thinking about it, killing it is probably fine, though it does make my life marginally easier (I have a few versions of buck that I need to test in parallel, having different .fakebuckversion files in each one makes it slightly easier for me). Done. Good point, would it be fine to change it to \".*_test\"? Or are there other kinds that it might not be a good idea to filter out?\nOur codebase adds test files to a bunch of other genrules, etc. for things like static analysis, so the above code won't do the detection correctly without some kind of filter. The fields are used by the template (ij-module.st); since IjSourceFolder is generated, I need the getter here to create the field.. Ditto above. Is there a way to make it more explicit? . Being able to build and run in IntelliJ improves our iteration speed. Specifically, a lot of built-in features (e.g. automatically attaching debugger, more informative testing UI, easier-to-customize run/debug configurations) in IntelliJ are better for our workflows than command-line buck.\nThe IntelliJ buck plugin is an okay alternative, but for now doesn't have enough features compared to native IntelliJ for our liking (though I'm also adding a couple of changes there, hopefully we can start using it soon), so being able to support this natively in IntelliJ in addition would be really nice for us.\nAre there any concerns I can help address about including this additional functionality?. I'm not exactly sure what you mean here? (same for next two comments). Done. Removed. Removed check. Done. Changed, though actually I think regardless of whether it's set to SourceFolder or TestFolder in this case, it's not going to work correctly, but TestFolder is probably a better attempt in that case. Done. Sorry for the delay, was traveling for the past few days; will update today. Thanks for this advice too, that's a much nicer way of doing it. Rewrote the comment to give a bit more context for why the method exists and has the given return type. If it still isn't too helpful, then I'll just remove it?. Actually, based on https://buckbuild.com/rule/java_library.html (and on my own testing), if resources_root is not set, then it basically uses the corresponding src_root as a resources_root. Good point, removed. Changed. ",
    "guhan121": "@styurin @cjhopman because main apk is 0x7f, other apk will build for a plugin , the plugin will package as a lib_plugin_name.so in mian apk libs.we will config some plugins,so res id must be different.. ",
    "joelmccall": "Interesting, I expect this might happen if you are adding those classes in from two different locations, such as from a prebuilt jar file as well as java_library rules. @thalescm , overall the changes look good, would you mind rebasing it to more recent commit?. Builds are hitting this error with this change:\ncompile:\n    [javac] Compiling 2679 source files to /home/travis/build/facebook/buck/ant-out/classes\n    [javac] [compiled 590084 lines in 37867 ms: 15583.0 lines/s]\n    [javac] [5021 .class files generated]\n    [javac] ----------\n    [javac] 1. ERROR in /home/travis/build/facebook/buck/src/com/facebook/buck/android/AabBuilderStep.java (at line 154)\n    [javac]     ApkBuilder moduleBuilder = new ApkBuilder(\n    [javac]           moduleGenPath.toFile(),\n    [javac]           fakeResApk,\n    [javac]           null,\n    [javac]           null,\n    [javac]           verboseStream\n    [javac]       );\n    [javac]                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    [javac] The constructor ApkBuilder(File, File, null, null, PrintStream) is undefined\n    [javac] ----------\n    [javac] 1 problem (1 error). ",
    "SMohamedMubarish": "Yes lee... Thanks for your input.. if I am using my dependent module in three different modules.. do I need to rebuild each module after building the changes in dependent module. . ",
    "silentnuke": "@ttsugriy sure, I've just accepted.. ",
    "lyrachord": "both env and project config may be\nbut this case env was set, so the problem should be at project config.\nsee https://buckbuild.com/concept/buckconfig.html#android.build_tools_version\nmodifiy .buckconfig in project should be ok\nf.e. \n[ndk]\n  ndk_version = 15.1.4119039. ",
    "erhu": "@krossford\nAdd \nANDROID_HOME=/Users/xxx/Library/Android/sdk\nANDROID_NDK=/Users/xxx/Library/Android/sdk/ndk-bundle\nto your .buckconfig file.. @krossford\nAdd \nANDROID_HOME=/Users/xxx/Library/Android/sdk\nANDROID_NDK=/Users/xxx/Library/Android/sdk/ndk-bundle\nto your .buckconfig file.. Add \nANDROID_HOME=/Users/xxx/Library/Android/sdk\nANDROID_NDK=/Users/xxx/Library/Android/sdk/ndk-bundle\nto your .buckconfig file.. Add \nANDROID_HOME=/Users/xxx/Library/Android/sdk\nANDROID_NDK=/Users/xxx/Library/Android/sdk/ndk-bundle\nto your .buckconfig file.. ",
    "shaliniprajeshwynk": "This wasn't working for me too.After hit and trial, following got this working...\nI uninstalled android ndk then installed and added following lines in bash and buckconfig file respectively.\nbash file \nexport ANDROID_SDK=\"/Users/username/Library/Android/sdk/\"\nexport ANDROID_HOME=\"/Users/username/Library/Android/sdk/\"\nexport ANDROID_NDK=\"/Users/username/Library/Android/sdk/ndk-bundle\"\nexport NDK_HOME=\"/Users/username/Library/Android/sdk/ndk-bundle\"\nbuckconfig file\n  ndk_path = /Users/username/Library/Android/sdk/ndk-bundle\n  ndk_version = 17.1.4828580[note the version while it is installing]\nAnd it worked . ",
    "jbarr21": "\nyou need to re-format java files\n\nsorry, i installed the pre-commit hook after last time. will double check it. Rebased and squashed. All feedback should be addressed. > I'm trying to test this change, but I can't see which feature it enables. Can you provide some screenshots, please?\nthis re-enables the extra \"Design\" tab when editing Android Layout XML files. as of IntelliJ 2017.2, XML layouts won't display the tab without this change. screenshots added to the description. > I'm trying to test this change, but I can't see which feature it enables. Can you provide some screenshots, please?\nthis re-enables the extra \"Design\" tab when editing Android Layout XML files. as of IntelliJ 2017.2, XML layouts won't display the tab without this change. screenshots added to the description. >> this re-enables the extra \"Design\" tab when editing Android Layout XML files. as of IntelliJ 2017.2, XML layouts won't display the tab without this change. screenshots added to the description\n\nDo you use aggregation of modules with Android resources (option intellij.aggregate_android_resource_modules in .buckconfig)? This is the only reason I can think of why IntelliJ isn't showing that tab.\nIf you don't use this option, can you provide a sample project where this tab isn't shown?\n\nThe .buckconfig option has no effect on the issue.\nAny project (I used the OkBuck sample app), when opened with the IntelliJ 2017.2 build, does not display the editor tab. This is because the condition for the Layout Preview Editor to be displayed fails since the GradleFeatureEnableService requires the project to be built with Gradle.\nThis PR adds a FeatureEnableService extension that checks if the project was built with Buck, and enables the Layout Preview editor tab.. >> this re-enables the extra \"Design\" tab when editing Android Layout XML files. as of IntelliJ 2017.2, XML layouts won't display the tab without this change. screenshots added to the description\n\nDo you use aggregation of modules with Android resources (option intellij.aggregate_android_resource_modules in .buckconfig)? This is the only reason I can think of why IntelliJ isn't showing that tab.\nIf you don't use this option, can you provide a sample project where this tab isn't shown?\n\nThe .buckconfig option has no effect on the issue.\nAny project (I used the OkBuck sample app), when opened with the IntelliJ 2017.2 build, does not display the editor tab. This is because the condition for the Layout Preview Editor to be displayed fails since the GradleFeatureEnableService requires the project to be built with Gradle.\nThis PR adds a FeatureEnableService extension that checks if the project was built with Buck, and enables the Layout Preview editor tab.. @styurin can you please clarify the android.jar via ideabuck.iml comment? shouldn't the dependency be provided via the buck configuration, i'll just update the script to not stub the android.jar?. @styurin just wanted to check on the status of your IntelliJ installs. is this PR still blocked on that?\nas for building the plugin from IntelliJ, that sounds outside of the scope of this PR. IntelliJ 2017.2.4 picks up this fix for the issue, though I think it's still a good idea to continue this PR in case their legacy logic changes in the future https://github.com/JetBrains/android/commit/09d47f3a608659723b98f46505b2c35d32436048. Abandoning for now in favor of waiting for https://android-review.googlesource.com/c/platform/tools/adt/idea/+/474539 to get merged and picked up by a new Jetbrains release.. @sbalabanov Why is this a won't fix? I understand that you don't have bandwidth, but can we still leave this open for potential contributors?. it was a default fallback incase the manifest wasn't present (since it is optional - but it shouldn't happen). AIDL is an Android-specific interface. since a target can have multiple source-generating rules, we want to prefer the Android/Java-Library one instead of the AIDL since it will be less important to the layout preview. but, if this is switched over to logic in the apply() of Rules, then we shouldn't need this. it should probably always be non-null since we're unpacking the aar in this rule, but since it was looking at file paths, I was defensive since the Layout Preview is more optional than generating the project. this should've been used on new L140. in the added test condition. will fix my copy/paste error. yep, will do. I got this JAR from IntelliJ installation. it was needed so that we could find the FeatureEnableService symbol. stubbing this JAR reduces is to 5.1 MB. yes, it's from the Android Plugin for the IntelliJ installation. it needs to be IJ 2017.2 or higher (/Applications/IntelliJ IDEA.app/Contents/plugins/android/lib/android.jar)\n@styurin which piece of that do you want in a separate PR?. buck config should be enough, i was just following what seemed like convention to do both. i can remove this. I created it. This is a new folder that we use to store our synthetic library modules so that we don't clutter our project view. we are creating a synthetic library module so that we can use it's compiler output path to put the r class files on the class path for the Layout Preview. the module is created based off of the base path, which, might not already exist for a clean build. if it doesn't, then the IjProjectTemplateDataPreparer runs into a NoSuchFileException when it expects the synthetic library module's base path to exist. this prevents that from occurring. Added in #1448. good catch, updated this w/ some separators.. I created it. This is a new folder that we use to store our synthetic library modules so that we don't clutter our project view. The path is arbitrary and can go somewhere else if you prefer. the logic is already gated on https://github.com/facebook/buck/pull/1429/files/3c9b7a377ec8cbaf2a2d847ca19765603d2440a5#diff-4b53a690d0d3ac329da62c36fcacf204R306 by the buck flag enable_extra_compiler_output_modules. is that still necessary?. We are adding synthetic modules to the module graph here. In order for the module to be properly created and added to the graph, it's module root must be created (since there is no actual code there already). This depends upon knowledge of each module, so it can't happen before the main logic of buck project. Attached is what the module structure would look like for the uber/okbuck sample app. The directories that it would create are listed below. They would only be created for Android libraries and if the project configuration flag enabled them.\n- buck-out/extra-intellij-output/another-app\n- buck-out/extra-intellij-output/libraries/common\n- buck-out/extra-intellij-output/libraries/empty-library\n\n. this creates an extra library, but we need to create an extra module so that we can specify the compiler output (since that's where the Layout Preview loads classes from). I was trying to keep it generalized so that other build steps could leverage this synthetic modules functionality. If you prefer, I can just use a single Path.. My mistake. I will remove the 2nd call. In a prior PR (https://github.com/facebook/buck/pull/1412/files#diff-3edfe4c74fe850fc67a4d5eb7422c512R388), I already added the compiler output property to the IML for every Android module. The synthetic modules don't have the Android facet, which is why the check has been updated to accommodate both scenarios. When generating a real project (I used uber/okbuck sample app), without this logic, I get the exception below. It looks like the FakeProjectFilesystem used in the test code does not throw the same exception since it's .exists() method only checks whether its a file or directory and not the presence of the actual file on disk\n[2017-08-11 11:56:17.363][error][command:null][tid:106][com.facebook.buck.cli.Main] /Users/jbarr/Uber/okbuck/buck-out/extra-intellij-output/app\njava.nio.file.NoSuchFileException: /Users/jbarr/Uber/okbuck/buck-out/extra-intellij-output/app\n    at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n    at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n    at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)\n    at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144)\n    at java.nio.file.Files.readAttributes(Files.java:1737)\n    at com.facebook.buck.io.ProjectFilesystem$FileTreeWalker.getAttributes(ProjectFilesystem.java:1190)\n    at com.facebook.buck.io.ProjectFilesystem$FileTreeWalker.walk(ProjectFilesystem.java:1107)\n    at com.facebook.buck.io.ProjectFilesystem$FileTreeWalker.access$2(ProjectFilesystem.java:1106)\n    at com.facebook.buck.io.ProjectFilesystem.walkFileTree(ProjectFilesystem.java:535)\n    at com.facebook.buck.io.ProjectFilesystem.walkRelativeFileTree(ProjectFilesystem.java:524)\n    at com.facebook.buck.io.ProjectFilesystem.walkRelativeFileTree(ProjectFilesystem.java:481)\n    at com.facebook.buck.ide.intellij.IjProjectTemplateDataPreparer.createExcludes(IjProjectTemplateDataPreparer.java:228)\n    at com.facebook.buck.ide.intellij.IjProjectTemplateDataPreparer.getContentRoots(IjProjectTemplateDataPreparer.java:291)\n    at com.facebook.buck.ide.intellij.IjProjectWriter.write(IjProjectWriter.java:59)\n    at com.facebook.buck.ide.intellij.IjProject.write(IjProject.java:113)\n    at com.facebook.buck.ide.intellij.IjProjectCommandHelper.writeProjectAndGetRequiredBuildTargets(IjProjectCommandHelper.java:269)\n    at com.facebook.buck.ide.intellij.IjProjectCommandHelper.runIntellijProjectGenerator(IjProjectCommandHelper.java:233)\n    at com.facebook.buck.ide.intellij.IjProjectCommandHelper.parseTargetsAndRunProjectGenerator(IjProjectCommandHelper.java:196)\n    at com.facebook.buck.cli.ProjectCommand.runWithoutHelp(ProjectCommand.java:317)\n    at com.facebook.buck.cli.AbstractCommand.run(AbstractCommand.java:227)\n    at com.facebook.buck.cli.AbstractContainerCommand.run(AbstractContainerCommand.java:67)\n    at com.facebook.buck.cli.BuckCommand.run(BuckCommand.java:81)\n    at com.facebook.buck.cli.Main.runMainWithExitCode(Main.java:983)\n    at com.facebook.buck.cli.Main.runMainThenExit(Main.java:372)\n    at com.facebook.buck.cli.Main.nailMain(Main.java:1725)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.martiansoftware.nailgun.NGSession.run(NGSession.java:329). ",
    "kolen": "I get the same error when trying to cross compile with mingw. It looks for .dylib despite linker_platform is set to WINDOWS.. I get the same error when trying to cross compile with mingw. It looks for .dylib despite linker_platform is set to WINDOWS.. Removed UNKNOWN option.. ",
    "weakish": "\nWhat if you override the linker using a .buckconfig\n\n@njlr  This does not work. I even removed g++ and libstdc++-dev, which also does not work.. ldd. @njlr Thanks a lot! ld = /usr/bin/gcc does do the trick.. ",
    "jonathandann": "@ttsugriy Without this as a first class citizen, what's the recommended way to migrate projects that use scripts?. ",
    "Qard": "I just ran into this too, writing a buck build file for libuv. Building libuv itself works fine, as does building a library that depends on it, but when I build a binary that depends on it, either directly or indirectly, it fails to build.. I just ran into this too, writing a buck build file for libuv. Building libuv itself works fine, as does building a library that depends on it, but when I build a binary that depends on it, either directly or indirectly, it fails to build.. ",
    "katelyn-weingart": "Hi, I'm looking into this. It could easily be my change but I'm not sure what would have caused the failure because this test is only checking the results of XmlDomParser, not XmlDomParserWithLineNumbers.\nThe only significant change here related to the failure is that I moved XmlDomParser into the buck.util.xml package from the buck.util package.. One potential cause for this failure is that in the BUCK file I added, the XmlDomParser is under java_library rule instead of a java_immutables_library rule. Will change if I get confirmation from @styurin or someone else in buck that this change could cause this failure. ",
    "cpsauer": "I wanted to say that I'd had the same expectations as @njlr. It's problematic to not be able to set, e.g., language standards, deployment targets (see referenced issue above), optimization levels, and debug symbols project-wide. Perhaps a better behavior would just be to have cells inherit their parent's configuration by default?\nIn the meantime, for anyone else reading, you can solve this with a bit of a hack. Just prefix each cell's .buckconfig with an import of the parent cell's .buckconfig, i.e., <file:../../../../.buckconfig>. This should really be inheritance, because buck's INI parser takes the second value if you specify something twice (at least in my tests on macOS 10.14).. ",
    "milend": "Closing issue as we've implemented Swift support without the need for the refactor (as discussed offline with @robbertvanginkel).. LGTM. LGTM. Thanks for flagging this, @robbertvanginkel. This was done intentionally but I agree with your reasoning and I'll get this amended soon.. As we spoke about this offline, the reason for the file to be placed inside buck-out is that we need to know the full path in advance. Putting it inside $BUILT_PRODUCTS_DIR would be tricky because we have to guess where Xcode would place the files (and this can be affected by Xcode settings and the Xcode build system used). Trying to replicate Xcode's hashing behaviour would be fragile and prone to breakage in the future, so I think we should keep things predictable for now.. As we spoke about this offline, the reason for the file to be placed inside buck-out is that we need to know the full path in advance. Putting it inside $BUILT_PRODUCTS_DIR would be tricky because we have to guess where Xcode would place the files (and this can be affected by Xcode settings and the Xcode build system used). Trying to replicate Xcode's hashing behaviour would be fragile and prone to breakage in the future, so I think we should keep things predictable for now.. @robbertvanginkel LGTM, apologies for the delayed review. Do you mind rebasing on top of the latest master so I can land it? Thanks!. @robbertvanginkel LGTM, apologies for the delayed review. Do you mind rebasing on top of the latest master so I can land it? Thanks!. @robbertvanginkel Yup, I'll take a look tomorrow.. LGTM.. @rmaz LGTM, I'd just want to add one more test that asserts success (in addition to the other two tests that assert failure).. @rmaz Yup!. @robbertvanginkel LGTM.. @robbertvanginkel Land failed due to merge conflict, can you please rebase?. @rmaz I'm extremely busy at the moment but I'll try to set aside some time to look at this. Apologies in advance for the delay.. @rmaz Did you test your PR with your latest changes? Does it produce the same output as Xcode?. @robbertvanginkel:\n\nI copied this behaviour from buck build\n\nI think it's fine in that case because we're preserving behaviour existing buck build behaviour.. If an apple_library has Swift sources, it needs a swift_version = \"4\" declaration, otherwise buck project won't work (there's certain logic that only kicks it once you've defined you want Swift support using that declaration).\nLet me know if that fixes your issue.. @mgrebenets:\n\nDo you know if there's a way to get latest documentation? Can I generate it from buck source maybe?\n\nThe docs have not been updated, the most authoritative source of truth would be the examples included as part of the integration tests (e.g., AppleLibraryIntegrationTest.java) and ProjectGeneratorTest.java for the Xcode project generation.\n@mgrebenets:\n\nNone worked.\n\nIf you want to generate Xcode projects with WMO, you need to add the following to .buckconfig:\n[swift]\nproject_wmo = true\n\nNote that buck build will compile all Swift sources using a single compiler invocation, so there's no need to enable WMO there.. @robbertvanginkel LGTM, I'm landing #1769 first. It seems this PR still has the code to update fbxctest, so we should probs revert that particular commit?. LGTM. LGTM. LGTM.. LGTM.. @mgrebenets You can see the public commit on master here https://github.com/facebook/buck/commit/4fe9a4b3c88728e7aac70a43961d38a0c1f54b9d.. @shepting The PR has been on my plate for a while but I've been overwhelmed with other work, I've finally made some time to go through it.. @robbertvanginkel LGTM, should be good after a rebase together with #1874.. @robbertvanginkel This would not work for macOS, we will need to use @executable_path/../Frameworks (same for the line below).. I'd use targetNode.castArg here instead.. We should mark this as private.. Let's use swiftBuckConfig.getFlags() instead because that's what's used by SwiftCompile, so that we pass the same sets of flags in Xcode + buck build.. My main concern here is the hardcoded string value which can get out of sync with other places and end up in different flags being passed in Xcode vs buck build. Can we instead expose enum in SwiftBuckconfigthat defines all valid flags?. Do we want to allow custom umbrella header names? I'm thinking about the case where the user provides their manually written one (or have pre-existing header with the name of the module).\nIf so, I think we should also be passing the umbrella header name explicitly as an input.. This implies that umbrella headers are not exported as those imports would not work from other libraries. Do we plan to expose those umbrella headers, so that non-modular libraries can do #import <Module/Module.h>?. I'd try to clarify what contents is (i.e., fileList). Should Directory instead accept a list of File to make it even more explicit?. Do we want to enforce any properties of realPath, i.e., does it have to be absolute or can it be relative?. - For clarity, I feel like we should name this VirtualDirectory.\n- My other observation is that Directory does not support nested Directory even though the Clang spec says it's supported. I think that's fine for now but we should add a test case for this.. Would VirtualFile be more descriptive?. Let's add a Precondition in that case to make sure the inputs are valid.. Nit: seems like leftover temporary code.. SwiftCompile actually gets args.getModuleName().orElse(buildTarget.getShortName()) as the module name, I think we should be consistent here. It might be best to centralise this logic in a static method on SwiftLibraryDescription.. Nit: I'd give resolvedContents a more descriptive name.. My only comment here is that this setting might have to be on a per-target basis. But I think it's okay to cross that bridge when needed as we can just change this method to accept the TargetNode.. I'd be consistent with the naming of objc-module-overlay.yaml and name this testing-overlay.yaml.. Nit: I'd name this getFlagsForExcludesForModulesUnderTests so that it's clear that it returns flags.. Nit: Let's clarify that targetNode is actually the testingTarget.. Nit: I think it would be more descriptive for nativeNode to be named libBeingTested.. If I understand correctly, this implies that testing targets written in Obj-C cannot @import the libs under testing and have to resort to #import. Is that right?. @robbertvanginkel Can we make this a config option? I think it will be useful for debugging and logging.. Nit: let's update the comment.. We should introduce this behaviour behind a config option as this has the potential to break existing apps which already include duplicate resources (which means we cannot update Buck without fixing any offending apps which is impractical).\nThe config for this should be off by default.. It seems that this is duplicating the resource paths form lines 427-429:\nresources.getResourceDirs(),\nresources.getDirsContainingResourceDirs(),\nresources.getResourceFiles()\n\nWe should extract those and pass them into the method instead.. Nit: filename can be inaccurate as it can be directories, too. Can we improve the naming?. This check won't work correctly because it's the contents inside that get copied to the root of the resources dir, not the dirs themselves.\nThe deeper issue here is that those dirs will usually not have the contents at this point but only be generated later (e.g., a genrule). So you won't be able to perform the check here.\nGiven the above, you'd have to move the check to be part of the CopyStep itself.. Can you add another test where we have duplicate nested filenames, so something like:\nFolderA/Image.png\nFolderB/Image.png. @rmaz I had to look into it and it seems it's only used for `js_bundle` (see `JsBundleDescription::addAppleBundleResources()`). I couldn't find any integration tests for `js_bundle`, so I think we can ignore `DirsContainingResourceDirs` for now (but please put a `TODO`).. @rmaz As per my above comment, I don't think we can easily test this as `js_bundle` doesn't seem to have integration tests.. @rmaz We should add another test that actually tests for success but has files with the same name inside the folders. We can just copy `app_bundle_with_conflicting_nested_resources` and change:\n\nfiles = glob([\"**/*.png\"]),\n\nto:\ndirs = [\"ImagesA\", \"ImagesB\"],\n\nAlternatively, we can just skip the images as the localizable strings all have the same file names inside.. I think we should be testing apple_library in the very least, having a separate test for swift_library might be beneficial, too.. We definitely want a separate test on macOS where we should force static linking of the Swift runtime (I think we can do that by setting link_style = \"static\", on the apple_library that contains Swift).. Same comment as above.. My only concern here is that we're adding a new constraint which has the potential to break project generation for existing codebases. Changing the behaviour of Buck in this way can be painful when deploying new builds at Facebook (which would lead to reverts and then having to do the whole commit dance again). Instead, I'd suggest one of the following (or a combination):\n\nEmit a warning rather than throw an exception.\nIf we want to keep the ability to throw an exception, we can add a config option for it.\n\nI'm wondering, what happens when Buck itself builds an app that has multiple catalogs with app_icon defined?. I think we should be conservative here and check that args.getModuleName() is not empty.. @robbertvanginkel:\n\nI'm not sure this is the correct place to put this. It seems like this might be better in the CxxSourceRuleFactory, but I couldn't find a simple place to inject it.\n\nThere's at least one other place that might need this logic: CxxDescriptionEnhancer::createBuildRulesForCxxBinary which contains the following code (which is almost 1:1 duplicated):\njava\nImmutableListMultimap.copyOf(\n  Multimaps.transformValues(\n      CxxFlags.getLanguageFlagsWithMacros(\n          preprocessorFlags,\n          platformPreprocessorFlags,\n          langPreprocessorFlags,\n          cxxPlatform),\n      f -> toStringWithMacrosArgs(target, cellRoots, resolver, cxxPlatform, f))),\nAdding it as a @Value.Parameter to AbstractCxxSourceRuleFactory would make sure that we definitely add the module name parameter to all source rules rather than relying on hunting down all call sites.\nHaving said that, I'm not sure whether it's useful to pass -fmodule-name for rules like apple_binary. Do we know that we want to add the compiler flag everywhere? Another aspect that comes to mind is whether we want to have this flag added for (Objective-)C++ files where modules are not yet finalised.. @rmaz Why do we now need to override the value for APPLICATION_IDENTIFIER? How did this work beforehand? Was it part of the value returned from getMergeableEntitlements()?\nI think we should preserve the pre-existing behaviour and specify APPLICATION_IDENTIFIER as part of the additionalKeys parameter to PlistProcessStep, rather than as override. My concern here is that it might override a value already set in entitlementsPlist. On the other hand, the argument could be made that if those values did differ, the app will fail to launch due to a code signing issue. Still, it might be safer to err on the side of caution and preserve existing behaviour.. @rmaz To improve readability, I would actually write this out as:\njava\nString appID = bestProfile.get().getAppID().getFirst() + \".\" + bundleID;\nImmutableMap<String, NSObject> overrideKeys = ImmutableMap.of(APPLICATION_IDENTIFIER, new NSString(appID));\nBecause the purpose of ImmutableMap.of(APPLICATION_IDENTIFIER, new NSString(appID)) is not clear in the constructor of PlistProcessStep.\nI'd also move this inside the if statement (entitlementsPlist.isPresent()) as it's only used inside that scope.. @robbertvanginkel I remember helping @marekcirkos with his efforts to add UI tests for macOS last year but my memory is a bit fuzzy. I know that we currently support logic tests without test_host_app and UI tests where both test_host_app and ui_test_target_app are specified (only on macOS 10.13+).\nAs long as we don't break logic tests with Swift on macOS, we should be good to go.. @robbertvanginkel Doesn't AppleNativeTargetDescriptionArg have moduleName? I feel like this logic of determining an effective module name is duplicated in quite a few places.. @robbertvanginkel Can we not create a prebuilt Obj-C framework so that there's no need to recompile as Swift versions change? That would still be able to test whether the framework path is passed to the Swift compiler, right?. @robbertvanginkel I believe having it in the above order is beneficial as it allows developer control in both local and remote environments. In a local env, a developer can control both --test-runner-env and BUCK files. In a remote env, developers can usually only control BUCK files.. @robbertvanginkel controll -> control. @robbertvanginkel Seems like the code from 851-862 is duplicated from CxxLibraryMetadataFactory. Can we just extract and expose it instead?. @robbertvanginkel Shouldn't we just delete the whole if branch, as if buildTarget.getFlavors().contains(AppleDescriptions.FRAMEWORK_FLAVOR will always be false?. @robbertvanginkel If we keep the if branch, why did we remove this code?. ",
    "romanoid": "Can you please suggest if this travis failure is expected or it is something I need to take care of: \n\"No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.\nCheck the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received\". Can you please suggest if this travis failure is expected or it is something I need to take care of: \n\"No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.\nCheck the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received\". @ttsugriy Can you please elaborate on suggestion about \"multiValued argument instead of option\"?  . http://args4j.kohsuke.org/apidocs/org/kohsuke/args4j/spi/EnumOptionHandler.html works only for single Enum argument and it's implemented in a way of framework supplying it special value, I attempted to implement generic repeated enum handler, but current args4j does not support it.. Rebased + squished the commits addressing suggestion to original commit. I were considering using external runner, but here's what stopped me: \n1. Existing runner already handles a lot of corner cases and re-implementing these sounded less then optimal for me. Copy-pasting existing one and diverging sounds like a nightmare too, since we're not going to receive all the upstream goodness. \n2. --flaky_test_attempts seems to be useful for community, flaky tests are always problem for any big enough repo and having some built-in support for it sounds like a great idea. . Here's few comments: \n \"don't want to force one way or another\" \u2013 I were not proposing forcing anything, but instead optional flag similar to Bazel's one that you can pass when running tests. (as buck test my/target/...  --flaky_test_attempts=3)\n \"I don't think we are going to do any changes here.\" \u2013 I understand that this request is very custom to limited amount of use cases and were wondering if you will be ok with me contributing this functionality, I'd rather have conversation we have now then on PR. \n* \"What would be useful for community is to create a test runner outside of buck repository which can be configured however you want.\" \u2013 that's an awesome idea, if we end up going the custom runner direction, we probably should publish \"BaseExternalRunner\" or something that is easy to start from when creating own runners.. Thank you for all the suggestions and discussion, I'm closing the issue for now.. Thank you for all the suggestions and discussion, I'm closing the issue for now.. @philipjameson thanks for suggestion, added integration tests. \nMavenUrlDecoder is already covered by unit tests. Please advice if any specific unit test you have in mind is desired.. @bobyangyf Hi Bob, please see the example I linked in description I constructed with resources: \nhttps://github.com/romanoid/buck-tinkering/blob/master/deps-experiment/buildables/BUCK\nI may construct more sophisticated example with opensource library usages if needed for clarification, I though having clear minimal example is preferred though.\nReiterating, tests see resource contents as: \n /1-2.txt: 2\n /1-3.txt: 1\n /1-4.txt: 1\n /1-5.txt: 1\n /2-3.txt: 2\n /2-4.txt: 2\n /2-5.txt: 2\n /3-4.txt: 4\n /3-5.txt: 3\n /4-5.txt: 4\nWhile java binary sees resources as: \n /1-2.txt: 1\n /1-3.txt: 1\n /1-4.txt: 1\n /1-5.txt: 1\n /2-3.txt: 2\n /2-4.txt: 2\n /2-5.txt: 2\n /3-4.txt: 3\n /3-5.txt: 3\n /4-5.txt: 4. I don't like option 1 since it gives individual developers no control at all to resolve conflicts (if they happen to depend on 2 versions), so it provides the worse behavior possible.\nIt is still good from consistency perspective though. . \"Depending on 2 versions is never a good thing ;)\" \u2013 totally agree, but that's not something easy to solve for us at the moment. \n@styurin @ttsugriy, do you share the same opinion as @bobyangyf ?\n. Meanwhile, can you please take a look on https://github.com/facebook/buck/pull/1841 this should be useful regardless. . Sounds good, I'll have PR shortly. (in addition to https://github.com/facebook/buck/pull/1841). PR: https://github.com/facebook/buck/pull/1844. Replaced with https://github.com/facebook/buck/pull/1844. Addressed feedback besides splitting it into specific integration testing.\nI intentionally had all of these in the same test so it is clear that these are related and have to be in the same ordering.\nI can split it across specific tests if you still think it is more clean.. @styurin regarding comments on junit jars, I cleaned up the place I copied it from (and a lot of other places) : https://github.com/facebook/buck/pull/1845. @styurin regarding comments on junit jars, I cleaned up the place I copied it from (and a lot of other places) : https://github.com/facebook/buck/pull/1845. You've imported this while ago, do you see any problem with the change? . You've imported this while ago, do you see any problem with the change? . I guess, you are not 100% duplicate-free youself. Will be waiting for update!. I guess, you are not 100% duplicate-free youself. Will be waiting for update!. @styurin We noticed that boot classpath entries (for android tests specifically) will have path outside of repository and so sorting can both prepend or append it depending on the path names in the system. \n@raviagarwal7 instead offered to sort 2 sections separately: classpath and additional classpath. \nI've updated the PR with the changes. . done. done. Tests failing on travis pass locally for me, do you think it may be travis setup problem?. Tests failing on travis pass locally for me, do you think it may be travis setup problem?. rebased. I've rebased on master again and there were again 0 merge conflicts. \nCan the merge conflict be related to some publishing caveat? I.e. is there chance internal branch has something that is not published to github? . Fixed tests, looks like I've fixed some of them before, but haven't pushed the changes. . will add some tests early next week, please not import before that .. I assume commits will be squashed on land automatically, please let me know if it is cleaner to squash them on my side. . I've managed to fail PMD: \npmd:\n      [pmd] /home/travis/build/facebook/buck/test/com/facebook/buck/cli/PublishCommandIntegrationTest.java:198: Unnecessary use of fully qualified name 'Assert.assertTrue' due to existing static import 'org.junit.Assert.assertTrue'\nUploaded new revision with the issue fixed.. Added unit test, let's see if I haven't broke build on the way.\nPlease let me know if you think this needs integration test too. . Added unit test, let's see if I haven't broke build on the way.\nPlease let me know if you think this needs integration test too. . @ttsugriy @styurin \nI do agree with the intention and the fact that a single way to declare target is less confusing.  \nOn the other hand this decision was likely made before the decision to use skylark and does not 100% hold with skylark anymore, for example even now, when using skylark, in some of the cases short names work: \nload('//tooling/experimental/genrules/rules.bzl', 'some_rule') is expanded into load('//tooling/experimental/genrules/rules.bzl:rules.bzl', 'some_rule') (and I think this is an excellent example highlighting why expansion is confusing)\nExpanding in some but not all contexts may lead to even more confusion.\nI think all and all it is worth to discuss it again in the new context (skylark) and re-consider or consciously accept inconsistency tradeoff instead of just deferring to past decision.\n. @ttsugriy @styurin \nI do agree with the intention and the fact that a single way to declare target is less confusing.  \nOn the other hand this decision was likely made before the decision to use skylark and does not 100% hold with skylark anymore, for example even now, when using skylark, in some of the cases short names work: \nload('//tooling/experimental/genrules/rules.bzl', 'some_rule') is expanded into load('//tooling/experimental/genrules/rules.bzl:rules.bzl', 'some_rule') (and I think this is an excellent example highlighting why expansion is confusing)\nExpanding in some but not all contexts may lead to even more confusion.\nI think all and all it is worth to discuss it again in the new context (skylark) and re-consider or consciously accept inconsistency tradeoff instead of just deferring to past decision.\n. Can you please advice why it is done as change in buck code and not as a small script outside of buck? \nI don't see any information that it uses not available otherwise. . The reason why maven publish needs to be implemented in buck are more intricated: \nIt needs to understand classpath and dependency graph for both pom generation and uberjar creation from multiple targets. \nThis is not possible to do outside of Buck. \nUnlike that, current addition seems to be easily implementable. \nAccording to the approach shared by the BUCK team, they prefer to not include in BUCK itself features that can easily be implemented outside of BUCK source code. \nWill rely on @styurin feedback besides my comment that current change breaks existing workflows.. The reason why maven publish needs to be implemented in buck are more intricated: \nIt needs to understand classpath and dependency graph for both pom generation and uberjar creation from multiple targets. \nThis is not possible to do outside of Buck. \nUnlike that, current addition seems to be easily implementable. \nAccording to the approach shared by the BUCK team, they prefer to not include in BUCK itself features that can easily be implemented outside of BUCK source code. \nWill rely on @styurin feedback besides my comment that current change breaks existing workflows.. To be more specific, this is Scalatest (which is compatible with both) and is used in junction with Junit4.\n . I found how the problem manifests itself and will have PR with remedy shortly. . the problem I found only fixes some of the examples (that behave the same with debugger and without). I'm perplexed by one test that fails correctly if (--debug or --filter are applied, but not otherwise). Found the source of discrepancy between --debug and --filter specified and not: https://github.com/facebook/buck/blob/a6c7d7391a7a8e575c6372cac6690a240b5907ea/src/com/facebook/buck/testrunner/JUnitRunner.java#L221\n--debug implies timeout=0 so either of them return original runner rather than DelegateRunnerWithTimeout, so it is most likely race condition. . PR is UP: https://github.com/facebook/buck/pull/2009. We never did. Unfortunately I did not have time to investigate more / fix it and instead had put some lint/safeguards on our side.  \nI think overall this one: https://github.com/facebook/buck/issues/2036 is much more dangerous. . Added comments inline. \nThis does not fix if you run test with default Junit runner, i.e @RunWith(Junit4.class), Junit4 is properly wrapping all the errors. \nOn the other hand some other runners may not behave the same. \nThis fixes 2 separate issues that I mentioned inline on this PR. . After applying this fix to the repo, discovered single non-scala test (using @RunWith(PowerMockRunner.class) ) that had been failing silently before.. I hope it means it uncovered your test failures were silently swallowed too. \nPlease let me know (what you can), once you know anything. . @bobyangyf any updates? . Interesting. Test result report (out xml) has method=\"null\" for failures of runners that happened outside of running any method. \nI.e. failures that this change intended to detect will look exactly like this. . cc @styurin can you please take a look? . cc @styurin can you please take a look? . Thanks, switched to EnumSet where possible. unfortunately I were not able to make args4j option to work with anything but array though.. Incidentally the way code written right now array will never be empty, but extra safety measure will never hurt, updated the code according to your suggestion.. multiValued attribute support was removed while ago: https://github.com/kohsuke/args4j/issues/24\nLet me try updating CoverageReportFormatsHandler to parse multiple values. CoverageReportFormatsHandler will throw the human readable option exception in case of it being empty, that's why it will never be empty by this point. . All right, I experimented a little, \"--code-coverage-format=HTML --code-coverage-format=XML\" is not supported, what you can do though is \"--code-coverage-format HTML XML\", but I'd argue it is even worse than csv.. Also maybe I'm not configuring output verbosity correctly, but if I throw any exception from this context, buck just silently exits, that's why I Option handler returning user facing is preferable . this was formats.size() in one of the previous revisions, which is incorrect. For csv arg we always consume only single one.. I intentionally had all of these in the same test so it is clear that these are related and have to be in the same ordering. I can split it across specific tests if you still think it is more clean. . I intentionally had all of these in the same test so it is clear that these are related and have to be in the same ordering. I can split it across specific tests if you still think it is more clean. . done. Yes, we should, thank you, updated PR.\nI kept dep graph though. I don't see why not, I can clean this up in another diff (since I've already started) . done. done. Yes, Ravi discovered this nuance with android installation location.\nYou've tried merging this change early and had some failing tests, it may be possible that this android nuance was at fault. . this changes the logic and breaks existing use cases:\n1) it requires toMaven when it otherwise would not. \n2) it makes new behavior default.\n3) it changes flag names and logic.. Breakage of existing users seems unnecessary here. isMaven does not need to be mutually exclusive with to-maven-central and to-maven-central can imply isMaven=true and fail if isMaven=false\n. This fixes when Runner start test and then encounters failure that prevents it from continuing the run. . This properly wraps runner failing completely. \nBefore this change testrunner will behave differently in case of crash depending on if it runs directly (because --filter= or --debug was passed to run command) or if wrapped by this class. \n. Previously public void testAssumptionFailure(Failure failure) { would just swallow the error since resultListener is not null, but testFinished is never called, so this failure is lost.. From the test runner build file: \n```\nIMPORTANT! This library limits itself to types that are available in both the JDK and Android\n# Java API. The objective is to limit the set of files added to the ClassLoader that runs the\n# test, as not to interfere with the results of the test.\n\n``\nI'd prefer to not add such heavyweight dependency as guava there.. that's not necessarytestAssumptionFailure`\nHere's how rest runner execution works in the bugged example: \n\ncall testStarted\ncall testFailure (this is attached to test, so we don't record it as unbounded, since we record all of these in testFinished)\ndo not call testFinished (since this was kind of failure that prevents runner to continue)\ncall testRunFinished \n\nsince during call of the method testFailure we don't yet know if runner will call testFinished or not (normally we'd like to record all the failures in testFinished) we can not make a decision yet. \ntestFinished wraps up the test and makes resultListener = null, so check resultListener != null detects where some test was started but not finished. In this case we otherwise will lose the error causing runner to terminate the execution. . is it possible to use hash here to accommodate the case where gradle cache may have different versions of the same artifact present? . ",
    "shybovycha": "Just manual finding: it is not possible to build OSX bundle (apple_bundle rule) without providing a flavor.\nThere is, however, a comment, describing how to implement a custom build rule (and flavors, briefly):\n\nStart by implementing Description. The type parameter of the Description is referred to as the \"constructor arg\" for historical reasons, but the public fields of the class of the type parameter are used as the parameter names in your BUCK files (take a look at ExportFileDescription for a lightweight example). The BuildRuleType returned by getBuildRuleType gives you the rule name.\nDescriptions are typically named after the rule that they (uhh..) describe. That is GenruleDescription is the root of how a Genrule is constructed, JavaTestDescription is how a JavaTest is constructed and so on. Generally, you can guess the class name by taking the rule name as used in build files, un-snake-casing and appending Description\nA Description is a factory of BuildRule instances. The Flavor of a BuildTarget can be used to make the Description return a different kind of BuildRule, but in the common case, you don't need to use them. BuildRule implementations typically extend AbstractBuildRule. To keep things simple, you can annotate fields with @addtorulekey on your BuildRule and it'll automatically be added to the RuleKey (which is used to determine whether or not a rule needs to be rebuilt)\nA BuildRule is used to construct Step instances. These are the things that actually do the work, and if you're creating a new type of build rule, it's likely you'll need to add new steps. That's cool.\nWe like unit tests where possible, so go nuts adding them too. We use junit. If you'd like an end to end test, take a look at calling it something ending with *IntegrationTest (ExportFileIntegrationTest is one example). These tend to use files from testdata directories to run tiny builds.\nFinal thoughts:\n\nOutputs of build rules go in the gen/ directory. Scratch files, that aren't outputs, can be found in the bin/ directory. You can use BuildTargets.get{Bin,Gen}Path to create a Path to one of these quickly and easily.\nA SourcePath is something that could either be a Path on the disk (relative to the project root) or the output of a BuildRule. Use the SourcePathResolver to get a concrete Path out of it.. Everything works fine, brew installs v2017.10.01.01 and upgrades buck to this version.\n\n\nGood job! Thanks!. Just wondering: what is in master what's not in that release?. Was able to fix this by exposing dependency all the way through up to //main. Still, the problem with transitive dependencies persists. Will probably need to take a closer look at transitive dependencies linking.. This problem does not exist on master branch.. @ttsugriy done. Okay, figured out how to \"fix\" this with my custom Buck patch ( #1570 ) - one needs to specify the \"flavor\" (which is not quite documented, AFAIK):\n```\nbuck build //target:bundle-osx#macosx10.13-x86_64\nor\nbuck build //target:bundle-osx#macosx10.13-i386\nor\nbuck build //target:bundle-osx#macosx-x86_64\nor\nbuck build //target:bundle-osx#macosx-i386\n```\nor any other from the list, provided by Buck' output when the patch is applied.\nThe question is still present, however: what are the flavors and why I can't build the target without it? Is there any documentation on them?. So almost in a year of time, no docs are still there? That's sad =(. Damn fonts, it's CL, not C1... Re-tying now.... Okay, so I've installed Visual Studio with the C++ compiler and all-the-things; verified it works (just a simple HelloWorld program does work), but Buck still can't find the CL. Maybe I should register it in PowerShell or globally?. Okay, figured it out. Might be worth adding a few lines to the docs:\n\nafter installing the VisualStudio, there was/is a vcvarsall.bat, which registers the environment variables, including the paths to the linker and the compiler (CL)\nPowerShell is not affected by those changes (for whatever reason), so it needs its own environment variables (which vcvarsall.bat does not provide)\nthere is a PowerShell module, VSSetup, which does exactly what we want - registers the environment variables for PowerShell environment\n\nSo, for PowerShell:\n\ninstalling the module: Install-Module -Name PSCX -AllowClobber\ninstalling the module: Install-Module -Name VSSetup -AllowClobber\ninitializing the environment variables: Import-VisualStudioVars 2017 amd64\nprofit!\n\nAfter that, the build works.. Rebased on master from facebook/buck#maste. Can't actually test on Windows machine, since after the rebase clean ant build does not work for whatever reason =(. Whoops, my bad - messed up the imports, probably as the result of a rebase. Had to go out for a couple of hours, so will fix it now. Seems like with the correct imports the build passes, but I still receive a lot (~12) failing tests when running ./bin/buck test (e.g. on the whole project; locally). Will now also test on Windows.. And now both Windows and OSX builds succeed, tests... Well, tests, I'd say, \"fail normally\" - in ~20 minutes only these failed:\nFAILURE scripts.stampede.find_undeclared_source_files_test.TestStampedeProcessing test_process_empty_includes: AssertionError: 2 != 0\nFAILURE scripts.stampede.find_undeclared_source_files_test.TestStampedeProcessing test_process_selective_includes: AssertionError: 1 != 0\nFAILURE scripts.stampede.find_undeclared_source_files_test.TestStraceProcessing test_absolute_path: AssertionError: 1 != 0\nFAILURE scripts.stampede.find_undeclared_source_files_test.TestStraceProcessing test_relative_path: AssertionError: 1 != 0\nFAILURE com.facebook.buck.apple.endtoend.AppleEndToEndTest TestMobileBuildBuckdOffshouldBuild: Did not successfully build Expected exit code 0 but was 1.\nFAILURE com.facebook.buck.apple.endtoend.AppleEndToEndTest TestMobileBuildBuckdOffTrueEnabledshouldBuild: Did not successfully build Expected exit code 0 but was 1.\nFAILURE com.facebook.buck.features.dotnet.CsharpLibraryIntegrationTest shouldBeAbleToEmbedResourcesIntoTheBuiltDll: Expected exit code 0 but was 1.\nFAILURE com.facebook.buck.features.dotnet.CsharpLibraryIntegrationTest shouldCompileLibraryWithAPrebuiltDependency: Expected exit code 0 but was 1.\nFAILURE com.facebook.buck.features.dotnet.CsharpLibraryIntegrationTest shouldCompileLibraryWithSystemProvidedDeps: Expected exit code 0 but was 1.\nFAILURE com.facebook.buck.features.dotnet.CsharpLibraryIntegrationTest shouldBeAbleToDependOnAnotherCsharpLibrary: Expected exit code 0 but was 1.\nFAILURE com.facebook.buck.cli.BuildCommandIntegrationTest lastOutputDirForAppleBundle: Expected exit code 0 but was 1.\nFAILURE com.facebook.buck.cxx.endtoend.CxxDependentOnPyTestEndToEndTest TestCxx_dependent_on_pyTest_runnersTestBuckdOnPython neverending_test_runner.pyinterruptTestsGracefully: Can't find started_neverending_test_runner.txt after 25 seconds. I just wanted to keep consistency across the project - other methods in the same file are using plain-old for loops. But that doesn't mean it's not worth refactoring, right? ;). Awesome! Did not know this collector exists =(. And again, to make code more consistent I've changed getInvalidFlavors to the same approach, since both methods are private and are used in the same context.. Hmm... What should I dedup, given both methods use Sets?. Well, that could be a separate feature - grouping flavors and platforms, but it also has an edge case: what if some flavors do not support some specific platforms?\nWill split flavors by a newline and update this PR.. Now there are some =). Oh, okay. I didn't know there are separate BUCK files for each test package. Seems like a bit of an overkill to me. But sure, will do. Will see how it goes now =). Uhm, sorry but the first symbol in quotes is not shown. I assume you mean \\ ?\nNow, we are talking about tests only, right? There is nothing to do on a logic level, since it does not work with any slashes =). Oh, so you're saying tests are broken on a build server? That's why we need this assertion - to prevent running those tests on non-windows OS?. Will now run the tests on Windows machine. ",
    "lelandrichardson": "@shs96c FYI, using yarn should not ruin the hermetic nature of the build, since we are using it with yarn's --offline option using an local offline cache of all of the package tarballs. as a result, it should be a pure operation.\nEither way, I'm using yarn in this example as it's our actual use case, but I feel like this is easily generalizable into something that takes some set of files (in our case a package.json and a set of tarballs) and produces a set of source files (.m and .h). This could definitely apply to various forms of code generation in the same way. (ie, some transformation of json src => generated .java / .objc files etc). ",
    "epkugelmass": "Nevermind -- buck is already using 6.0. I'll update the patch to take advantage of that.. Known problem, though I don't know if there is a GitHub issue open for it.\nYou can fix it by passing the --java11-test-mode flag.\nhttps://github.com/facebook/buck/blame/master/programs/buck.py#L187. Appears to be fixed here:\nhttps://github.com/facebook/buck/commit/9e22f68e19d5f28cd6c8200343581a81658fdb0e. ",
    "TarasMazepa": "Actually google/auto#563 is merged so @ttsugriy it is good time to revisit this issue ;). Actually google/auto#563 is merged so @ttsugriy it is good time to revisit this issue ;). ",
    "jongerrish": "With the current implementation Robolectric has to load all the value resources in the test runner at startup and process the R class as we need to build a complete resource table, so the more resources you have in your dependencies the more raw XML parsing Robolectric has to do, for example, even if you just want to load a single string, we have no idea what resource file that string lives in so need to real all files.\nThere is the option of specifying @Config(manifest = Config.NONE) which caused Robolectric not to load any resources, but the problem there is that if any code in your test execution path suddenly changes to load a resource the test will fail, so we don't recommend that (ideally we'd remove it at some point).\nOur hope is if we can make Robolectric's resource loading time negligible (i.e: ~10-20ms for app and framework) we would benefit from build caching of merged / binary resources between test run invocations and any performance improvements upstream in the tool chain.. Hi, just an update on this. The final API for build systems to integrate with Robolectric is documented here:-\nhttp://robolectric.org/build-system-integration/\nThis API supports both merged raw resources, assets + manifest and also will soon support consuming a binary resources.ap_ file.\nThis is now supported in Bazel via the android_local_test rule https://docs.bazel.build/versions/master/be/android.html#android_local_test and support will be coming to Gradle, hopefully soon.\nSwitching to a resources.ap_ is really compelling as we're seeing around a two second improvement in startup time for the interactive use case, plus there is an increase in resource fidelity as we are no longer emulating aapt behaviour.\nWe will keep the existing support around for as long as we can, but we'd like to remove it sooner rather than later.\n. Hi, just an update on this. The final API for build systems to integrate with Robolectric is documented here:-\nhttp://robolectric.org/build-system-integration/\nThis API supports both merged raw resources, assets + manifest and also will soon support consuming a binary resources.ap_ file.\nThis is now supported in Bazel via the android_local_test rule https://docs.bazel.build/versions/master/be/android.html#android_local_test and support will be coming to Gradle, hopefully soon.\nSwitching to a resources.ap_ is really compelling as we're seeing around a two second improvement in startup time for the interactive use case, plus there is an increase in resource fidelity as we are no longer emulating aapt behaviour.\nWe will keep the existing support around for as long as we can, but we'd like to remove it sooner rather than later.\n. Just a friendly ping on this issue.\nBinary resource support is now enabled for both Gradle (AGP) and Bazel.\nI'd strongly urge implementing this functionality as we've seen 20-35% performance gains internally on test start up time, plus there is a whole lot of resources bugs that can be avoided just by using binary resources (we're not actively fixing any bugs in the old raw resource implementation which will be removed probably sometime in the 3-6 month time period). ",
    "zzzunov": "As temp solution we can use bridging headers.. ",
    "DavidGDD": "Yeah of course, but it only download a single file, not? What happend with the dependencies of this jar?\nI mean, with the maven repo config and a remote_file per first level dependency of my project is enough?. ",
    "flevour": "@kageiit can you confirm and close the issue?. ",
    "Sayary": "Hi @jkeljo !~ I happen to see your last comment about running kapt in-process, is there any approach that we change it to out-of-process? There's a known issue about running ButterKnife with kotlinc in-process config, see https://github.com/JakeWharton/butterknife/issues/1148 . Hi @jkeljo !~ I happen to see your last comment about running kapt in-process, is there any approach that we change it to out-of-process? There's a known issue about running ButterKnife with kotlinc in-process config, see https://github.com/JakeWharton/butterknife/issues/1148 . @kageiit I agree in-process has lots of benefits about taking advantage of JIT, but could we make it an option like what kotlin gradle plugin does https://github.com/JetBrains/kotlin/blob/149b197b2491be178f9e46b09559d7e9e6f5867a/libraries/tools/kotlin-gradle-plugin/src/main/kotlin/org/jetbrains/kotlin/compilerRunner/GradleKotlinCompilerRunner.kt#L43\nAt least this will unblock users who use butterknife & kotlin and want to adopt BUCK. . @kageiit I agree in-process has lots of benefits about taking advantage of JIT, but could we make it an option like what kotlin gradle plugin does https://github.com/JetBrains/kotlin/blob/149b197b2491be178f9e46b09559d7e9e6f5867a/libraries/tools/kotlin-gradle-plugin/src/main/kotlin/org/jetbrains/kotlin/compilerRunner/GradleKotlinCompilerRunner.kt#L43\nAt least this will unblock users who use butterknife & kotlin and want to adopt BUCK. . ",
    "techyvish": "@ttsugriy @jkeljo I'm using java 9.0.1. Thanks @ttsugriy, will use older version for now.. ",
    "artem-zinnatullin": "@kageiit thanks for heads up! \u2764\ufe0f  \nUpdated Buck literally 30 minutes ago, uh, will probably just revert it back for now. Yep, we're getting exact same error. \nI've tried to figure out the cause and current guess is that @BuckStyleImmutable doesn't support Optional and value continues to be null after BUCK file parsing which codegen version of AndroidBinaryDescriptionArg.java treats as absent Optional, but I might be wrong of course.. @dreiss hmmmmmm, I don't really see difference in behavior between problematic and fixed code in your diff\u2026\nPrevious Optional method Chaining should have produced same result, no?. Ahhh, yeah Java computes parameters before method call..\n\ud83d\udc4d\nOn Fri, Nov 17, 2017, 12:25 PM David Reiss notifications@github.com wrote:\n\nYeah, I thought so too, which is why I felt confident landing the broken\nversion.\nThe subexpression\narg.getManifestSkeleton()\n    .orElseThrow(\n        () ->\n            new IllegalArgumentException(\n                \"android_binary \"\n                    + targetNode.getBuildTarget()\n                    + \" did not specify manifest or manifest_skeleton\"));\nis not a lambda. It's evaluated unconditionally, so we throw if\nmanifest_skeleton is not specified.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1633#issuecomment-345356403, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AA7B3FAva_VkZDAw5XzBLS46CCDKQQARks5s3eu5gaJpZM4Qidf7\n.\n. Short update, cherry-picking following commits fixed this issue\n\n(append facebook/buck/commit):\n\ne1d4e585b93e8cf5cb10d4c788af5a354f892bc4 Upgrade Nailgun and tune daemon integration tests\nd01f49fd4d0e929d182b0e45bda5de9ba870dad3 Improve daemon termination by hard killing a process\n3f53c4853ba7d79215c36ed9ac3abb48aa7a33a2 Add CONNECTION_BROKEN Nailgun exception to fail buckd presence check\n58a9e88a689484a3ecf333c4bc59cf938b11f31e update Nailgun (fix broken pipe problem)\n. I'm going to work on a fix, but I also want to confirm that on a sample project it worked fine other than having to use fully qualified names in code, so I think it's reasonable to explore that direction in future.. Update: \n\nLooking at original PR https://github.com/facebook/buck/pull/2086 it seems that this behavior was always opt-in (android_resource(resource_union = True), default value is False).\nIt's unclear to me why was it removed if you could always explicitly pass False or just not set resource_union to True since it's False by default. Moreover, that PR didn't remove the resource_union arg from android_resource rule while removing its behavior. @raviagarwal7, @kageiit can you please comment on that?\nI think if we bring that code back, you should be able to opt-out as I mentioned before so it'll be win-win for both people using resource_union_package and those who don't.\n\nAlso, here is discussion of resource namespacing and isolated R classes with @ducrohet if you're interested: https://twitter.com/droidxav/status/1103736664701100032\n. fixed. added \ud83d\udc4d . \ud83d\udc4d . yis yis, nice. nit: unnecessary changes here?. ",
    "jchensc": "@kageiit thanks it works. @kageiit thanks it works. ",
    "taotaoping": "@jchensc @kageiit  I have the same issue, after add '-Aobjectbox.modelPath=xxxx' to android_library extra_arguments, still have same issue, could you tell me how to make it work?. ",
    "bhagyas": "Example artefact resolution : https://github.com/apache/maven-resolver/blob/master/maven-resolver-api/src/test/java/org/eclipse/aether/artifact/DefaultArtifactTest.java. Example artefact resolution : https://github.com/apache/maven-resolver/blob/master/maven-resolver-api/src/test/java/org/eclipse/aether/artifact/DefaultArtifactTest.java. @sbalabanov Would like to see the requirement for SHA1 specification removed. remote_file is not suited for Maven artifacts, since it adds a significant migration overhead. \nAlso the ~/.m2/repository already contains the SHA1 for each Maven artifact. maven_library should automatically resolve the SHA1 from the Maven local cache.. @sbalabanov Would like to see the requirement for SHA1 specification removed. remote_file is not suited for Maven artifacts, since it adds a significant migration overhead. \nAlso the ~/.m2/repository already contains the SHA1 for each Maven artifact. maven_library should automatically resolve the SHA1 from the Maven local cache.. ",
    "sbalabanov": "There is not sufficient information in this proposal. Could you please post what exactly is to be changed, what is the purpose of the change, and provide a couple examples or may be link a discussion thread?. There is not sufficient information in this proposal. Could you please post what exactly is to be changed, what is the purpose of the change, and provide a couple examples or may be link a discussion thread?. Ant may infer to older version, you may have a mess up with dependencies. Related: http://stackoverflow.com/questions/2335655/why-is-javac-failing-on-override-annotation\n. Better late than never. Does it still repro?. Apparently if Nailgun's input stream is explicitly closed (that's what happening in project generation after it prompts) it also terminates client connection followed by termination of Buck itself.\nI'll have it fixed in a couple days.. Why should it have the unix attribute? I do not believe Jar specification requires that.\nThe problem is, if we write Unix attributes to jar archive, then Buck also sets the minimum version required to unpack the zip to be unx:\nhttps://github.com/facebook/buck/blob/c24aa0986b46a19aa6445c9351940081f45c7ea9/src/com/facebook/buck/util/zip/EntryAccounting.java#L149\nThis can potentially break other scenarios. Each ZIP implementation may read this field and act accordingly, for example, refuse to decompress.\nJava itself detects that entry is a directory only by looking to a trailing slash.. Why should it have the unix attribute? I do not believe Jar specification requires that.\nThe problem is, if we write Unix attributes to jar archive, then Buck also sets the minimum version required to unpack the zip to be unx:\nhttps://github.com/facebook/buck/blob/c24aa0986b46a19aa6445c9351940081f45c7ea9/src/com/facebook/buck/util/zip/EntryAccounting.java#L149\nThis can potentially break other scenarios. Each ZIP implementation may read this field and act accordingly, for example, refuse to decompress.\nJava itself detects that entry is a directory only by looking to a trailing slash.. @msridhar I imagine this might happen on slow drives when trace listener's background thread cannot write events fast enough and starts accumulating jobs.\n@kageiit It says it did 1099 jobs, which means 1099 build rule. Each build rule has steps, everything is recorded. You can however open trace file in any editor and check which events are prevailing in your case.. @kageiit Build rules are still recorded I guess, at least one record per each :) I agree though that 4Gb is way more than I would expect. I do not see your trace, so please investigate what record types are really busting it.. @msridhar The way how this listener works is not quite straightforward but still simple. Any message dispatched from message bus is converted into ChromeRecord, which only has primitive types, so once dispatched, no memory is held for complex types like build rules. ChromeRecord then is passed as a parameter to a single thread build executor's task which will\n1) serialize it into json\n2) write it into a file\nfor each record synchronously.\nSo, if you see that executor keeps piling up tasks it means it does not have enough bandwidth to complete 1) and 2) (either can potentially be a bottleneck). Because tasks are piling up, memory is wasted to keep tasks' context.\nI do not have a repro so I can't investigate myself what the real issue is, but you can add some simple instrumentation to find it out. Depending on the issue the possible solution might be\n- Reduce write rate, for example do not record steps\n- Batch writes to disk\n- Serialize with multiple threads, may be speed it up somehow\nAs I mentioned above, I'd try to debug / heap dump first to detect which record types create the most of the burden.. @msridhar the thing I mostly interested in, is to group all pending tasks by category and name and see counts. This is to find out the abuser. It can be done by parsing a heap dump for the collection you mentioned above, or may be by just looking to the resulting trace file, which should be plain json.\nClearly it's just too many events to process at the given rate.. Didn't it show the same before the upgrade? socket.read() is a blocking operation and supposed to 'hang'. What I meant is that YourKit is probably wrong detecting that the issue is in socket.read() operation. So the issue might be somewhere else.\nIf that happens after the build completes, then there might be several reasons for that, let me list a few\n- Deinitialization of thread pools (various executors) may be time consuming\n- If build results in error, Buck closes event listeners and output traces synchronously and that may be time consuming\nIt is hard to say without having your particular case in hands, I would probably look at the YourKit data but only for the afterbuild portion. It will probably require instrumentation, not sampling, method to get right data.. So what is happening here is that at the end of each command, dir artifact cache is closed and it tries to clean dir cache by removing last accessed file. To do so, it traverses dir cache directory and stats each file there (in fact it stats each file twice, on traversal first and in a cleaner second). In case of a big directory this can be really slow. It then sorts all files by date accessed and removes oldest file until a threshold is met.\nIt tries to do it asynchronously by executing ArtifactCaches.close() on a separate executor service, but in fact Buck still waits for the service to complete all tasks before returning control to the user.\nAs a short term solution we can try to find a way to walk directory tree without stat, currently it uses Files.walkFileTree(). I doubt we can do it as traversal itself wants to know if the entry is a file or directory.\nA longer term solution is to have Buck support post-command asynchronous tasks and submit cleaner job there, not doing anything on artifact cache shutdown.\nA quickfix solution may be to totally purge dir cache folder and limit it's size.\ncc @bobyangyf . So what is happening here is that at the end of each command, dir artifact cache is closed and it tries to clean dir cache by removing last accessed file. To do so, it traverses dir cache directory and stats each file there (in fact it stats each file twice, on traversal first and in a cleaner second). In case of a big directory this can be really slow. It then sorts all files by date accessed and removes oldest file until a threshold is met.\nIt tries to do it asynchronously by executing ArtifactCaches.close() on a separate executor service, but in fact Buck still waits for the service to complete all tasks before returning control to the user.\nAs a short term solution we can try to find a way to walk directory tree without stat, currently it uses Files.walkFileTree(). I doubt we can do it as traversal itself wants to know if the entry is a file or directory.\nA longer term solution is to have Buck support post-command asynchronous tasks and submit cleaner job there, not doing anything on artifact cache shutdown.\nA quickfix solution may be to totally purge dir cache folder and limit it's size.\ncc @bobyangyf . @kageiit they do but for some reason this is not that of a problem. May be faster drives?\nBuck right now is pretty vague in scheduling cleanup jobs - each function does it on its own way. What we want to have instead is a unified piece of infrastructure with some sort of API that allows functions to submit cleanup jobs to daemon in a more less unified and supported way, and close all the resources synchronously. This in in plans for Buck team but at the moment we are not giving it a top pri, still happy to accept a PR, though it's probably be a set of PRs most likely.\nAnother short fix might be to move executor service timeout to configuration then increase the value in your case:\nhttps://github.com/facebook/buck/blob/012a59d5d2e5a45b483e85fb190d2b67ea0c56ab/src/com/facebook/buck/cli/Main.java#L246\nActually, I'd rather introduce a brand new setting for io executor service, not reuse this one.. @kageiit they do but for some reason this is not that of a problem. May be faster drives?\nBuck right now is pretty vague in scheduling cleanup jobs - each function does it on its own way. What we want to have instead is a unified piece of infrastructure with some sort of API that allows functions to submit cleanup jobs to daemon in a more less unified and supported way, and close all the resources synchronously. This in in plans for Buck team but at the moment we are not giving it a top pri, still happy to accept a PR, though it's probably be a set of PRs most likely.\nAnother short fix might be to move executor service timeout to configuration then increase the value in your case:\nhttps://github.com/facebook/buck/blob/012a59d5d2e5a45b483e85fb190d2b67ea0c56ab/src/com/facebook/buck/cli/Main.java#L246\nActually, I'd rather introduce a brand new setting for io executor service, not reuse this one.. What I do not like about this solution is potential thread number outbreak. Running many short living buck commands in a row may leave executors running and thread number exploding.. What I do not like about this solution is potential thread number outbreak. Running many short living buck commands in a row may leave executors running and thread number exploding.. I am happy to accept a PR, please include relevant comments in the code.. I am happy to accept a PR, please include relevant comments in the code.. You will still have to close an executor and increase timeout.. You will still have to close an executor and increase timeout.. Might be related to https://github.com/facebook/nailgun/pull/131 but at this point not sure how. It seems that buckd server just crashes on ng-stats request. Is it possible for you to debug the failure?. I do not know if any logs are generated; what you can do is to get the latest source codes from github and then run buckd with debugger\nbuck kill && BUCK_DEBUG_MODE=1 buck project <your args> then connect a debugger (like IntelliJ).\nI am prepping a change that will give some more logs in this case but it is not in trunk yet.\n. Are you building buck with buck? which version is \"bin\\buck\" and where does it come from?\nAlso, could you please the full output of cat src/com/facebook/buck/apple/xcode/BUCK. Are you building buck with buck? which version is \"bin\\buck\" and where does it come from?\nAlso, could you please the full output of cat src/com/facebook/buck/apple/xcode/BUCK. I think you can just move diskIO executor service to here: https://github.com/kageiit/buck/blob/49fce8e6b791bdbf76a59b210852c2b67a68e887/src/com/facebook/buck/cli/Main.java#L829\nPlease do not forget comments explaning why we let it go beyond client connection lifetime.. As you may have noticed :) we did not have bandwidth to work on this. Please come up with PR if this is still relevant.. How would you suggest to process it gracefully? If a symlink is an input and does not point to a valid file, build should fail anyways. Do you have in mind better error message?\nAlso please post the full trace and steps to repro.. How would you suggest to process it gracefully? If a symlink is an input and does not point to a valid file, build should fail anyways. Do you have in mind better error message?\nAlso please post the full trace and steps to repro.. What is this link for, is it served as an input to the rule? In this case I do not believe that we want to ignore that file does not exist, even with a warning. That might create some absurd non-determinism issues.. What is this link for, is it served as an input to the rule? In this case I do not believe that we want to ignore that file does not exist, even with a warning. That might create some absurd non-determinism issues.. I believe Buck does not want to ignore anything that matches as it may be a source of non-determinism. Please delete broken link.. I believe Buck does not want to ignore anything that matches as it may be a source of non-determinism. Please delete broken link.. lgtm. I will review.. Sorry, Kotlin is not currently in Buck team support path. However you are very welcome to debug the issue and come up with the fix :). tests are failing, seems like soy template is incorrect. You can have a genrule that wraps java call with required parameters. But it will have to directly call 'java' anyways.. Yes we removed custom logging (and custom exception processing) from build command in favor of generic error handler which should do all the logging and exit code transformation. This change is by design. Doesn't it work for you to hook into generic logger?. I believe ErrorLogger does log into java logging api here:\nhttps://github.com/facebook/buck/blob/018eaa6b2e8752655cc767cc8cd20310bdccb845/src/com/facebook/buck/cli/Main.java#L495\nIf you look to the log you will see things like that:\n[2018-11-13 11:53:04.831][warn ][command:null][tid:13][com.facebook.buck.cli.Main] Command failed:\ncom.facebook.buck.command.Build$BuildExecutionException: com.facebook.buck.util.exceptions.BuckUncheckedExecutionException: When building rule //src/com/facebook/buck/util/cache:cache#source-abi.\n    at com.facebook.buck.command.Build.waitForBuildToFinish(Build.java:323)\n    at com.facebook.buck.command.Build.waitForBuildToFinishAndPrintFailuresToEventBus(Build.java:421)\n    at com.facebook.buck.command.Build.executeAndPrintFailuresToEventBus(Build.java:144)\nSo it reports to com.facebook.buck.cli.Main logger. Will not it suffice? If not, we can dup errors to a separate logger specifically, defaulting to devnull.. I will be happy to accept the fix when you have one. I would only ask to check that parser speed is unaffected.. I will be happy to accept the fix when you have one. I would only ask to check that parser speed is unaffected.. Use getExecutorWrapper() function to get a safe wrapper that shutdowns safely. ",
    "roxma": "No\nlinuxbrew is using jdk 1.9. No\nlinuxbrew is using jdk 1.9. ",
    "cdeange": "For those looking for a quick fix, I've written up a python script that post-processes .iml files after buck project has generated them, and touches up the folder definitions to correct them. We use this internally at Square and it seems to cover all the use cases we have for misconfigured modules.\nIf you're using okbuck, append this to your buck wrapper after running BUCK_BINARY to invoke the script automatically:\nbash\nif [[ $? == 0 && \"project\" == $1 ]]; then\n    python $SCRIPT_DIR/scripts/fix_sources.py -p $SCRIPT_DIR\nfi. For those looking for a quick fix, I've written up a python script that post-processes .iml files after buck project has generated them, and touches up the folder definitions to correct them. We use this internally at Square and it seems to cover all the use cases we have for misconfigured modules.\nIf you're using okbuck, append this to your buck wrapper after running BUCK_BINARY to invoke the script automatically:\nbash\nif [[ $? == 0 && \"project\" == $1 ]]; then\n    python $SCRIPT_DIR/scripts/fix_sources.py -p $SCRIPT_DIR\nfi. ",
    "noiz354": "i also face that issue, u can reproduce at this link \nhttps://github.com/noiz354/okbuck/tree/dbflow_illegalstateexception\nis there any new update for this issue?. i also face that issue, u can reproduce at this link \nhttps://github.com/noiz354/okbuck/tree/dbflow_illegalstateexception\nis there any new update for this issue?. ",
    "hkocinneide": "I found this issue as well in some Android unit tests. I had some anonymous objects in my code, and removing either the backtick'd method name or the anonymous objects resolved the issue.. ",
    "kburovsc": "Are there any plans to get this fixed?. Are there any plans to get this fixed?. ",
    "uri-canva": "\nif we end up going the custom runner direction, we probably should publish \"BaseExternalRunner\" or something that is easy to start from when creating own runners.\n\nCustom runners would be invoked through the test.external_runner config, so they wouldn't necessarily have to be written in Java or have anything to do with the Buck codebase.. ",
    "mohammed-rampurawala": "Any resolution found for this issue?. ",
    "barancev": "Ping! Another monday is coming soon ;). Ping! Another monday is coming soon ;). Yes, fixed, thanks!. ",
    "marekcirkos": "That approach would work like a charm! Thank you.. @philipjameson Thanks for having a look at it. I'll check it out today to confirm :)\n. @philipjameson Unfortunately it doesn't work for me :/. Can you link zipped BUCK file with whl?. ",
    "mjpieters": "This has landed as 5f3fc36a93b63d569aba5dada70aa49bd04b78a0.. This has landed as 5f3fc36a93b63d569aba5dada70aa49bd04b78a0.. ",
    "jsgf": "Yeah, that use-case hasn't come up here. I'm not sure what it would take - my gut feeling is that it shouldn't be too hard because they're all within the scope of C/C++/ObjC targets.. Yeah, that use-case hasn't come up here. I'm not sure what it would take - my gut feeling is that it shouldn't be too hard because they're all within the scope of C/C++/ObjC targets.. It looks like there are two things here:\n1. rust_library does nothing unless you specify a flavour\n2. you need to specify all the sources your target depends on, but buck will only pass the root module source to rustc.\nBy default, rust_library will do nothing unless you give it a flavour to specify the target. Normally you'd build a rust_binary and have the library targets build as needed. You can set one explicitly with the buck build //mytarget#flavour syntax; the flavours are the same for C++ targets (or #check for quick syntax/typecheck builds).\nYou need to add all your sources to srcs. Buck will identify the root module and pass it (alone) to rustc, or complain if it can't identify it (either because it's not lib.rs (main.rs for executables) or named after the crate name).\nYou can use crate_root to explicitly set the top-level module, but you still need to include all the sources in srcs. (If you're including non-source things like binaries or text, you should put those in srcs too.) \n\nIf I try to include log.rs into the srcs array, then it will try to build log.rs independently, which is not what's supposed to happen and will also fail.\n...\nThe issue is that if I add it to srcs then buck will try to compile it with rustc, which is not what I want\n\nCould you provide the log output from buck? That sounds very unexpected; we don't see anything like that. (I assume you're running a current version of Buck? The Rust support changes regularly.)\n@styurin:\n\nLooks like we don't test rust at all. Tests are not working at all.\n\nTests need an installed rust toolchain. I've been meaning to raise that.. It looks like there are two things here:\n1. rust_library does nothing unless you specify a flavour\n2. you need to specify all the sources your target depends on, but buck will only pass the root module source to rustc.\nBy default, rust_library will do nothing unless you give it a flavour to specify the target. Normally you'd build a rust_binary and have the library targets build as needed. You can set one explicitly with the buck build //mytarget#flavour syntax; the flavours are the same for C++ targets (or #check for quick syntax/typecheck builds).\nYou need to add all your sources to srcs. Buck will identify the root module and pass it (alone) to rustc, or complain if it can't identify it (either because it's not lib.rs (main.rs for executables) or named after the crate name).\nYou can use crate_root to explicitly set the top-level module, but you still need to include all the sources in srcs. (If you're including non-source things like binaries or text, you should put those in srcs too.) \n\nIf I try to include log.rs into the srcs array, then it will try to build log.rs independently, which is not what's supposed to happen and will also fail.\n...\nThe issue is that if I add it to srcs then buck will try to compile it with rustc, which is not what I want\n\nCould you provide the log output from buck? That sounds very unexpected; we don't see anything like that. (I assume you're running a current version of Buck? The Rust support changes regularly.)\n@styurin:\n\nLooks like we don't test rust at all. Tests are not working at all.\n\nTests need an installed rust toolchain. I've been meaning to raise that.. You need to specify \"timer\" as a dependency in deps = [].. You need to specify \"timer\" as a dependency in deps = [].. Yeah, that's tricky. There's no integrated support for cargo or crates.io as yet. You could do something like use genrule to invoke cargo, to produce the rlib file from crates.io, reference that output file as the input to rust_prebuilt_library and then use that as a dependency.\nBut I haven't tried that out. . As I mentioned https://github.com/jsgf/rust-buck-skeleton/issues/1#issuecomment-414776556, the way we do this is to pre-build third-party deps and commit the .rlib files, then build with buck against those.. ",
    "jprobichaud": "almost a year later, I'm in the same situation\n```http_archive(\n  name = 'eigen3-archive',\n  urls = [\n    'https://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2',\n  ],\n  sha256 = '722a63d672b70f39c271c5e2a4a43ba14d12015674331790414fcb167c357e55',\n  type='tar.bz2',\n  strip_prefix='eigen-eigen-07105f7124f9'\n)\nprebuilt_cxx_library(\n    name = \"Eigen\",\n    deps = [ 'eigen3-archive' ],\n    header_only = True,\n    header_dirs = [ '$(location :eigen3-archive)/Eigen'],\n    exported_headers = subdir_glob(\n        [\n            (\"$(location :eigen3-archive)/Eigen\", \"*\")\n        ],\n        prefix=\"Eigen\"),\n    visibility = ['PUBLIC']\n)\n``` \nyield the same error about the location not being found. ",
    "remirobert": "Anyone got the chance to make it works with tests?\nI am maybe doing something wrong, but impossible to fix it.. ",
    "kapfab": "That seems indeed a much better way to merge entitlements than the current incomplete list of excluded entitlements.\nThough, is the specific com.apple.developer.icloud-container-environment entitlement correctly addressed? It is dynamically added by Xcode during export and is not meant to be part of App Entitlements (or potentially populated with a Development value).. That seems indeed a much better way to merge entitlements than the current incomplete list of excluded entitlements.\nThough, is the specific com.apple.developer.icloud-container-environment entitlement correctly addressed? It is dynamically added by Xcode during export and is not meant to be part of App Entitlements (or potentially populated with a Development value).. OK, so you expect it to be forced in the app entitlements.\nThe approach we took in a recent PR made for the fastlane project is to add this entitlement dynamically, depending on the type of Provisioning Profile being used for signing (Production for Distribution PP, Development otherwise). This prevents an app using Development to be pushed to Apple, but the downside is that it also prevents developers to release test apps using Production data\u2026 We'll probably need to add an optional parameter to allow that.\nThere\u2019s no perfect way to do this, but I\u2019m pleased to discuss the different options with someone else!. OK, so you expect it to be forced in the app entitlements.\nThe approach we took in a recent PR made for the fastlane project is to add this entitlement dynamically, depending on the type of Provisioning Profile being used for signing (Production for Distribution PP, Development otherwise). This prevents an app using Development to be pushed to Apple, but the downside is that it also prevents developers to release test apps using Production data\u2026 We'll probably need to add an optional parameter to allow that.\nThere\u2019s no perfect way to do this, but I\u2019m pleased to discuss the different options with someone else!. ",
    "dmitry-zaitsev": "I believe this is not an issue of Buck but of okBuck.\nLooking at the generated BUCK file we can see that test resources are not properly defined (res argument is missing):\nandroid_resource(\n    name = 'res_debug_test',\n    package = 'machado.thales.app.test',\n    resource_union = True,\n    deps = [\n        '//.okbuck/cache:com.android.support.animated-vector-drawable-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.appcompat-v7-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.constraint.constraint-layout-1.0.2.aar',\n        '//.okbuck/cache:com.android.support.support-compat-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-core-ui-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-core-utils-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-fragment-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-media-compat-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-v4-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-vector-drawable-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.test.espresso.espresso-core-3.0.1.aar',\n        '//.okbuck/cache:com.android.support.test.espresso.espresso-idling-resource-3.0.1.aar',\n        '//.okbuck/cache:com.android.support.test.rules-1.0.1.aar',\n        '//.okbuck/cache:com.android.support.test.runner-1.0.1.aar',\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n). I believe this is not an issue of Buck but of okBuck.\nLooking at the generated BUCK file we can see that test resources are not properly defined (res argument is missing):\nandroid_resource(\n    name = 'res_debug_test',\n    package = 'machado.thales.app.test',\n    resource_union = True,\n    deps = [\n        '//.okbuck/cache:com.android.support.animated-vector-drawable-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.appcompat-v7-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.constraint.constraint-layout-1.0.2.aar',\n        '//.okbuck/cache:com.android.support.support-compat-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-core-ui-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-core-utils-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-fragment-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-media-compat-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-v4-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.support-vector-drawable-25.4.0.aar',\n        '//.okbuck/cache:com.android.support.test.espresso.espresso-core-3.0.1.aar',\n        '//.okbuck/cache:com.android.support.test.espresso.espresso-idling-resource-3.0.1.aar',\n        '//.okbuck/cache:com.android.support.test.rules-1.0.1.aar',\n        '//.okbuck/cache:com.android.support.test.runner-1.0.1.aar',\n    ],\n    visibility = [\n        'PUBLIC',\n    ],\n). I think it would make sense to move it to SynchronizedToolProvider as it is not exactly obvious.. This synchronized block was moved into SynchronizedToolProvider\nsynchronized (ToolProvider.class) {\n     compiler = ToolProvider.getSystemJavaCompiler();\n}\nIt is not really obvious why this synchronization is performed, so there was a comment left to explain that. Now that this logic is moved into a new class the comment is removed and the purpose of SynchronizedToolProvider is not documented anywhere. Would be great to move the contents of this comment into the JavaDoc of SynchronizedToolProvider.. ",
    "HsuanTingLu": "yes it is\n' java -version' gets\njava version \"1.8.0_121\"\nJava(TM) SE Runtime Environment (build 1.8.0_121-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode). but my java is installed from Oracle not linuxbrew\n(and this used to work. but my java is installed from Oracle not linuxbrew\n(and this used to work. in my original case, I don't have java installed by linuxbrew, which the method suggested by @JoakimCh works, I'm going to close this one. in my original case, I don't have java installed by linuxbrew, which the method suggested by @JoakimCh works, I'm going to close this one. I need some time to dig out the project, but here's the summary:\nfrom what I recall,\nit's a tiny class that I built the test for, to set the unit test environment ready,\nproject built and ran on macOS,\nincluding the prebuilt BOOST lib and my c++ class code\none interesting thing is that, \nbuck run //test:main did the job, with the primitive output from BOOST\nwhile buck test //test:main seems to have failed to parse the output\nI'll leave a link in the comments if I find the project repo afterwards. ",
    "JoakimCh": "I have the same problem on Debian 9.\nTurns out linuxbrew installed JDK 9 and tried to use that. Solution was to download the .deb package instead.. I also have a Java installed by Debian on my system, but linuxbrew still installed another one without asking me about it. So are you really sure it didn't do that on your computer also? It should be in the \"/home/linuxbrew/.linuxbrew/Cellar\" folder I think, as \"JDK\" maybe.. ",
    "matthargett": "same issue on MacOS using homebrew installed cask/java.\n[javac] 212. ERROR in /Users/mhargett/workspace/yoga/csharp/lib/buck-2017.11.16.01/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 162)\n    [javac]     String parameterName, Map<? extends ExecutableElement, ? extends AnnotationValue> values) {\n    [javac]                                                                      ^^^^^^^^^^^^^^^\n    [javac] AnnotationValue cannot be resolved to a type\n    [javac] ----------\n    [javac] 213. ERROR in /Users/mhargett/workspace/yoga/csharp/lib/buck-2017.11.16.01/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 163)\n    [javac]     for (Map.Entry<? extends ExecutableElement, ? extends AnnotationValue> entry :\n    [javac]          ^^^\n    [javac] Map cannot be resolved to a type\n    [javac] ----------\n    [javac] 214. ERROR in /Users/mhargett/workspace/yoga/csharp/lib/buck-2017.11.16.01/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 163)\n    [javac]     for (Map.Entry<? extends ExecutableElement, ? extends AnnotationValue> entry :\n    [javac]                              ^^^^^^^^^^^^^^^^^\n    [javac] ExecutableElement cannot be resolved to a type\n    [javac] ----------\n    [javac] 215. ERROR in /Users/mhargett/workspace/yoga/csharp/lib/buck-2017.11.16.01/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 163)\n    [javac]     for (Map.Entry<? extends ExecutableElement, ? extends AnnotationValue> entry :\n    [javac]                                                           ^^^^^^^^^^^^^^^\n    [javac] AnnotationValue cannot be resolved to a type\n    [javac] ----------\n    [javac] 216. ERROR in /Users/mhargett/workspace/yoga/csharp/lib/buck-2017.11.16.01/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 172)\n    [javac]     public String getPackageName(Element element) {\n    [javac]            ^^^^^^\n    [javac] String cannot be resolved to a type\n    [javac] ----------\n    [javac] 217. ERROR in /Users/mhargett/workspace/yoga/csharp/lib/buck-2017.11.16.01/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 172)\n    [javac]     public String getPackageName(Element element) {\n    [javac]                                  ^^^^^^^\n    [javac] Element cannot be resolved to a type\n    [javac] ----------\n    [javac] 218. ERROR in /Users/mhargett/workspace/yoga/csharp/lib/buck-2017.11.16.01/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 173)\n    [javac]     return processingEnv.getElementUtils().getPackageOf(element).getQualifiedName().toString();\n    [javac]            ^^^^^^^^^^^^^\n    [javac] ProcessingEnvironment cannot be resolved to a type. ",
    "dread-uo": "It is still reproducible on Ubuntu 16.04\n```\n\u279c  ~ brew install facebook/fb/buck     \n==> Installing buck from facebook/fb\n==> Downloading https://api.github.com/repos/facebook/buck/tarball/v2017.11.16.01\nAlready downloaded: /home/litten/.cache/Homebrew/buck-2017.11.16.01.01\n==> ant\nLast 15 lines from /home/litten/.cache/Homebrew/Logs/buck/01.ant:\n    [javac]                                  ^^^^^^^\n    [javac] Element cannot be resolved to a type\n    [javac] ----------\n    [javac] 218. ERROR in /tmp/buck-20180123-17675-44bouf/facebook-buck-1531ce7/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 173)\n    [javac]     return processingEnv.getElementUtils().getPackageOf(element).getQualifiedName().toString();\n    [javac]            ^^^^^^^^^^^^^\n    [javac] ProcessingEnvironment cannot be resolved to a type\n    [javac] ----------\n    [javac] 218 problems (218 errors)\nBUILD FAILED\n/tmp/buck-20180123-17675-44bouf/facebook-buck-1531ce7/build.xml:479: The following error occurred while executing this line:\n/tmp/buck-20180123-17675-44bouf/facebook-buck-1531ce7/build.xml:411: Compile failed; see the compiler error output for details.\nTotal time: 1 second\n```. It is still reproducible on Ubuntu 16.04\n```\n\u279c  ~ brew install facebook/fb/buck     \n==> Installing buck from facebook/fb\n==> Downloading https://api.github.com/repos/facebook/buck/tarball/v2017.11.16.01\nAlready downloaded: /home/litten/.cache/Homebrew/buck-2017.11.16.01.01\n==> ant\nLast 15 lines from /home/litten/.cache/Homebrew/Logs/buck/01.ant:\n    [javac]                                  ^^^^^^^\n    [javac] Element cannot be resolved to a type\n    [javac] ----------\n    [javac] 218. ERROR in /tmp/buck-20180123-17675-44bouf/facebook-buck-1531ce7/src/com/facebook/buck/module/annotationprocessor/BuckModuleVisitor.java (at line 173)\n    [javac]     return processingEnv.getElementUtils().getPackageOf(element).getQualifiedName().toString();\n    [javac]            ^^^^^^^^^^^^^\n    [javac] ProcessingEnvironment cannot be resolved to a type\n    [javac] ----------\n    [javac] 218 problems (218 errors)\nBUILD FAILED\n/tmp/buck-20180123-17675-44bouf/facebook-buck-1531ce7/build.xml:479: The following error occurred while executing this line:\n/tmp/buck-20180123-17675-44bouf/facebook-buck-1531ce7/build.xml:411: Compile failed; see the compiler error output for details.\nTotal time: 1 second\n```. ",
    "SirWindfield": "Generating the rlib file would still need to be done by calling cargo build on the project that uses that library. So you basically do not generate any advantage from using buck instead of writing a shell script directly that invokes cargo build in the right order.\n@jsgf Maybe I am not aware of a way to actually just compile a crate without having to have it as a dependency in a project.. ",
    "monty-uber": "This pull request should fix this by making the FileScrubberStep a non-critical failure: https://github.com/facebook/buck/pull/1787.. This change updates the scrubber methods to better handle cgo files while still correctly scrubbing other Mach-O object files. The point of these scrubbers is to remove non-deterministic metadata found in certain LC_SEGMENT(_64) commands with the name __LINKEDIT and LC_UUID commands, neither of which are present in cgo files. . This change updates the scrubber methods to better handle cgo files while still correctly scrubbing other Mach-O object files. The point of these scrubbers is to remove non-deterministic metadata found in certain LC_SEGMENT(_64) commands with the name __LINKEDIT and LC_UUID commands, neither of which are present in cgo files. . So here is the otool output for a typical Cxx binary. This was grabbed from the integration test PrecompiledHeaderIntegrationTest.changingPchReferencedHeaderFromSameTargetCausesLibraryToRecompile:\n/private/var/folders/tm/gwcshss96p38tws3h9bv6bq00000gn/T/junit-temp-path6252725710168779344/buck-out/gen/some_binary#default:\nMach header\n      magic cputype cpusubtype  caps    filetype ncmds sizeofcmds      flags\n 0xfeedfacf 16777223          3  0x80           2    15        776 0x00200085\nLoad command 0\n      cmd LC_SEGMENT_64\n  cmdsize 72\n  segname __PAGEZERO\n   vmaddr 0x0000000000000000\n   vmsize 0x0000000100000000\n  fileoff 0\n filesize 0\n  maxprot 0x00000000\n initprot 0x00000000\n   nsects 0\n    flags 0x0\nLoad command 1\n      cmd LC_SEGMENT_64\n  cmdsize 232\n  segname __TEXT\n   vmaddr 0x0000000100000000\n   vmsize 0x0000000000001000\n  fileoff 0\n filesize 4096\n  maxprot 0x00000007\n initprot 0x00000005\n   nsects 2\n    flags 0x0\nSection\n  sectname __text\n   segname __TEXT\n      addr 0x0000000100000f70\n      size 0x000000000000003b\n    offset 3952\n     align 2^4 (16)\n    reloff 0\n    nreloc 0\n     flags 0x80000400\n reserved1 0\n reserved2 0\nSection\n  sectname __unwind_info\n   segname __TEXT\n      addr 0x0000000100000fac\n      size 0x0000000000000048\n    offset 4012\n     align 2^2 (4)\n    reloff 0\n    nreloc 0\n     flags 0x00000000\n reserved1 0\n reserved2 0\nLoad command 2\n      cmd LC_SEGMENT_64\n  cmdsize 72\n  segname __LINKEDIT\n   vmaddr 0x0000000100001000\n   vmsize 0x0000000000001000\n  fileoff 4096\n filesize 192\n  maxprot 0x00000007\n initprot 0x00000001\n   nsects 0\n    flags 0x0\nLoad command 3\n            cmd LC_DYLD_INFO_ONLY\n        cmdsize 48\n     rebase_off 0\n    rebase_size 0\n       bind_off 0\n      bind_size 0\n  weak_bind_off 0\n weak_bind_size 0\n  lazy_bind_off 0\n lazy_bind_size 0\n     export_off 4096\n    export_size 64\nLoad command 4\n     cmd LC_SYMTAB\n cmdsize 24\n  symoff 4168\n   nsyms 4\n  stroff 4232\n strsize 56\nLoad command 5\n            cmd LC_DYSYMTAB\n        cmdsize 80\n      ilocalsym 0\n      nlocalsym 0\n     iextdefsym 0\n     nextdefsym 3\n      iundefsym 3\n      nundefsym 1\n         tocoff 0\n           ntoc 0\n      modtaboff 0\n        nmodtab 0\n   extrefsymoff 0\n    nextrefsyms 0\n indirectsymoff 0\n  nindirectsyms 0\n      extreloff 0\n        nextrel 0\n      locreloff 0\n        nlocrel 0\nLoad command 6\n          cmd LC_LOAD_DYLINKER\n      cmdsize 32\n         name /usr/lib/dyld (offset 12)\nLoad command 7\n     cmd LC_UUID\n cmdsize 24\n    uuid BE5D599D-9758-3FD5-A41D-425FBEF87975\nLoad command 8\n      cmd LC_VERSION_MIN_MACOSX\n  cmdsize 16\n  version 10.13\n      sdk 10.13\nLoad command 9\n      cmd LC_SOURCE_VERSION\n  cmdsize 16\n  version 0.0\nLoad command 10\n       cmd LC_MAIN\n   cmdsize 24\n  entryoff 3952\n stacksize 0\nLoad command 11\n          cmd LC_LOAD_DYLIB\n      cmdsize 48\n         name /usr/lib/libc++.1.dylib (offset 24)\n   time stamp 2 Wed Dec 31 16:00:02 1969\n      current version 400.9.0\ncompatibility version 1.0.0\nLoad command 12\n          cmd LC_LOAD_DYLIB\n      cmdsize 56\n         name /usr/lib/libSystem.B.dylib (offset 24)\n   time stamp 2 Wed Dec 31 16:00:02 1969\n      current version 1252.0.0\ncompatibility version 1.0.0\nLoad command 13\n      cmd LC_FUNCTION_STARTS\n  cmdsize 16\n  dataoff 4160\n datasize 8\nLoad command 14\n      cmd LC_DATA_IN_CODE\n  cmdsize 16\n  dataoff 4168\n datasize 0\n\nYou can see this has the segment named __LINKEDIT as well as the LC_UUID load command, both of which need scrubbing.\nBy comparison, this is a binary from the integration test GoBinaryIntegrationTest.binaryWithCgo:\n/private/var/folders/tm/gwcshss96p38tws3h9bv6bq00000gn/T/junit-temp-path3368601601184085808/buck-out/gen/src/cgo_test/cgo#cgo-second-step:\nMach header\n      magic cputype cpusubtype  caps    filetype ncmds sizeofcmds      flags\n 0xfeedfacf 16777223          3  0x00           1     4        448 0x00002000\nLoad command 0\n      cmd LC_SEGMENT_64\n  cmdsize 392\n  segname \n   vmaddr 0x0000000000000000\n   vmsize 0x0000000000000518\n  fileoff 512\n filesize 1304\n  maxprot 0x00000007\n initprot 0x00000007\n   nsects 4\n    flags 0x0\nSection\n  sectname __text\n   segname __TEXT\n      addr 0x0000000000000000\n      size 0x0000000000000213\n    offset 512\n     align 2^4 (16)\n    reloff 1816\n    nreloc 18\n     flags 0x80000400\n reserved1 0\n reserved2 0\nSection\n  sectname __cstring\n   segname __TEXT\n      addr 0x0000000000000213\n      size 0x0000000000000034\n    offset 1043\n     align 2^0 (1)\n    reloff 0\n    nreloc 0\n     flags 0x00000002\n reserved1 0\n reserved2 0\nSection\n  sectname __eh_frame\n   segname __TEXT\n      addr 0x0000000000000248\n      size 0x00000000000001b0\n    offset 1096\n     align 2^3 (8)\n    reloff 1960\n    nreloc 36\n     flags 0x00000000\n reserved1 0\n reserved2 0\nSection\n  sectname __compact_unwind\n   segname __LD\n      addr 0x00000000000003f8\n      size 0x0000000000000120\n    offset 1528\n     align 2^3 (8)\n    reloff 2248\n    nreloc 9\n     flags 0x02000000\n reserved1 0\n reserved2 0\nLoad command 1\n     cmd LC_SYMTAB\n cmdsize 24\n  symoff 2320\n   nsyms 29\n  stroff 2784\n strsize 400\nLoad command 2\n      cmd LC_VERSION_MIN_MACOSX\n  cmdsize 16\n  version 10.13\n      sdk 10.13\nLoad command 3\n      cmd LC_DATA_IN_CODE\n  cmdsize 16\n  dataoff 2320\n datasize 0\n\nIt has no __LINKEDIT segment, nor a LC_UUID load command. This matches what we've seen in our projects using cgo.. So here is the otool output for a typical Cxx binary. This was grabbed from the integration test PrecompiledHeaderIntegrationTest.changingPchReferencedHeaderFromSameTargetCausesLibraryToRecompile:\n/private/var/folders/tm/gwcshss96p38tws3h9bv6bq00000gn/T/junit-temp-path6252725710168779344/buck-out/gen/some_binary#default:\nMach header\n      magic cputype cpusubtype  caps    filetype ncmds sizeofcmds      flags\n 0xfeedfacf 16777223          3  0x80           2    15        776 0x00200085\nLoad command 0\n      cmd LC_SEGMENT_64\n  cmdsize 72\n  segname __PAGEZERO\n   vmaddr 0x0000000000000000\n   vmsize 0x0000000100000000\n  fileoff 0\n filesize 0\n  maxprot 0x00000000\n initprot 0x00000000\n   nsects 0\n    flags 0x0\nLoad command 1\n      cmd LC_SEGMENT_64\n  cmdsize 232\n  segname __TEXT\n   vmaddr 0x0000000100000000\n   vmsize 0x0000000000001000\n  fileoff 0\n filesize 4096\n  maxprot 0x00000007\n initprot 0x00000005\n   nsects 2\n    flags 0x0\nSection\n  sectname __text\n   segname __TEXT\n      addr 0x0000000100000f70\n      size 0x000000000000003b\n    offset 3952\n     align 2^4 (16)\n    reloff 0\n    nreloc 0\n     flags 0x80000400\n reserved1 0\n reserved2 0\nSection\n  sectname __unwind_info\n   segname __TEXT\n      addr 0x0000000100000fac\n      size 0x0000000000000048\n    offset 4012\n     align 2^2 (4)\n    reloff 0\n    nreloc 0\n     flags 0x00000000\n reserved1 0\n reserved2 0\nLoad command 2\n      cmd LC_SEGMENT_64\n  cmdsize 72\n  segname __LINKEDIT\n   vmaddr 0x0000000100001000\n   vmsize 0x0000000000001000\n  fileoff 4096\n filesize 192\n  maxprot 0x00000007\n initprot 0x00000001\n   nsects 0\n    flags 0x0\nLoad command 3\n            cmd LC_DYLD_INFO_ONLY\n        cmdsize 48\n     rebase_off 0\n    rebase_size 0\n       bind_off 0\n      bind_size 0\n  weak_bind_off 0\n weak_bind_size 0\n  lazy_bind_off 0\n lazy_bind_size 0\n     export_off 4096\n    export_size 64\nLoad command 4\n     cmd LC_SYMTAB\n cmdsize 24\n  symoff 4168\n   nsyms 4\n  stroff 4232\n strsize 56\nLoad command 5\n            cmd LC_DYSYMTAB\n        cmdsize 80\n      ilocalsym 0\n      nlocalsym 0\n     iextdefsym 0\n     nextdefsym 3\n      iundefsym 3\n      nundefsym 1\n         tocoff 0\n           ntoc 0\n      modtaboff 0\n        nmodtab 0\n   extrefsymoff 0\n    nextrefsyms 0\n indirectsymoff 0\n  nindirectsyms 0\n      extreloff 0\n        nextrel 0\n      locreloff 0\n        nlocrel 0\nLoad command 6\n          cmd LC_LOAD_DYLINKER\n      cmdsize 32\n         name /usr/lib/dyld (offset 12)\nLoad command 7\n     cmd LC_UUID\n cmdsize 24\n    uuid BE5D599D-9758-3FD5-A41D-425FBEF87975\nLoad command 8\n      cmd LC_VERSION_MIN_MACOSX\n  cmdsize 16\n  version 10.13\n      sdk 10.13\nLoad command 9\n      cmd LC_SOURCE_VERSION\n  cmdsize 16\n  version 0.0\nLoad command 10\n       cmd LC_MAIN\n   cmdsize 24\n  entryoff 3952\n stacksize 0\nLoad command 11\n          cmd LC_LOAD_DYLIB\n      cmdsize 48\n         name /usr/lib/libc++.1.dylib (offset 24)\n   time stamp 2 Wed Dec 31 16:00:02 1969\n      current version 400.9.0\ncompatibility version 1.0.0\nLoad command 12\n          cmd LC_LOAD_DYLIB\n      cmdsize 56\n         name /usr/lib/libSystem.B.dylib (offset 24)\n   time stamp 2 Wed Dec 31 16:00:02 1969\n      current version 1252.0.0\ncompatibility version 1.0.0\nLoad command 13\n      cmd LC_FUNCTION_STARTS\n  cmdsize 16\n  dataoff 4160\n datasize 8\nLoad command 14\n      cmd LC_DATA_IN_CODE\n  cmdsize 16\n  dataoff 4168\n datasize 0\n\nYou can see this has the segment named __LINKEDIT as well as the LC_UUID load command, both of which need scrubbing.\nBy comparison, this is a binary from the integration test GoBinaryIntegrationTest.binaryWithCgo:\n/private/var/folders/tm/gwcshss96p38tws3h9bv6bq00000gn/T/junit-temp-path3368601601184085808/buck-out/gen/src/cgo_test/cgo#cgo-second-step:\nMach header\n      magic cputype cpusubtype  caps    filetype ncmds sizeofcmds      flags\n 0xfeedfacf 16777223          3  0x00           1     4        448 0x00002000\nLoad command 0\n      cmd LC_SEGMENT_64\n  cmdsize 392\n  segname \n   vmaddr 0x0000000000000000\n   vmsize 0x0000000000000518\n  fileoff 512\n filesize 1304\n  maxprot 0x00000007\n initprot 0x00000007\n   nsects 4\n    flags 0x0\nSection\n  sectname __text\n   segname __TEXT\n      addr 0x0000000000000000\n      size 0x0000000000000213\n    offset 512\n     align 2^4 (16)\n    reloff 1816\n    nreloc 18\n     flags 0x80000400\n reserved1 0\n reserved2 0\nSection\n  sectname __cstring\n   segname __TEXT\n      addr 0x0000000000000213\n      size 0x0000000000000034\n    offset 1043\n     align 2^0 (1)\n    reloff 0\n    nreloc 0\n     flags 0x00000002\n reserved1 0\n reserved2 0\nSection\n  sectname __eh_frame\n   segname __TEXT\n      addr 0x0000000000000248\n      size 0x00000000000001b0\n    offset 1096\n     align 2^3 (8)\n    reloff 1960\n    nreloc 36\n     flags 0x00000000\n reserved1 0\n reserved2 0\nSection\n  sectname __compact_unwind\n   segname __LD\n      addr 0x00000000000003f8\n      size 0x0000000000000120\n    offset 1528\n     align 2^3 (8)\n    reloff 2248\n    nreloc 9\n     flags 0x02000000\n reserved1 0\n reserved2 0\nLoad command 1\n     cmd LC_SYMTAB\n cmdsize 24\n  symoff 2320\n   nsyms 29\n  stroff 2784\n strsize 400\nLoad command 2\n      cmd LC_VERSION_MIN_MACOSX\n  cmdsize 16\n  version 10.13\n      sdk 10.13\nLoad command 3\n      cmd LC_DATA_IN_CODE\n  cmdsize 16\n  dataoff 2320\n datasize 0\n\nIt has no __LINKEDIT segment, nor a LC_UUID load command. This matches what we've seen in our projects using cgo.. Let me know if there is anything else preventing this from being pulled in.. Let me know if there is anything else preventing this from being pulled in.. It looks like the main difference between building cgo with buck versus go build is that buck runs the cgo commands from the buck project root whereas go runs cgo from the same folder where the sources are. \nBuck running the cgo command:\ncd /Users/monty/gocode/src/github.com/monty-uber/cgo-buck-example && GOROOT=/usr/local/Cellar/go/1.9.4/libexec GOOS=darwin GOARCH=amd64 /usr/local/Cellar/go/1.9.4/libexec/pkg/tool/darwin_amd64/cgo -importpath /Users/monty/gocode/src/github.com/monty-uber/cgo-buck-example -srcdir /Users/monty/gocode/src/github.com/monty-uber/cgo-buck-example -objdir buck-out/gen/go-calls-c/call_from_go#cgo-gen-sources/gen go-calls-c/cgo_source.go\nVersus go running the cgo command:\ncd /Users/monty/gocode/src/github.com/monty-uber/cgo-buck-example/go-calls-c &&\nCGO_LDFLAGS=\"-g\" \"-O2\" /usr/local/Cellar/go/1.9.4/libexec/pkg/tool/darwin_amd64/cgo -objdir $WORK/github.com/monty-uber/cgo-buck-example/go-calls-c/_obj/ -importpath github.com/monty-uber/cgo-buck-example/go-calls-c -- -I $WORK/github.com/monty-uber/cgo-buck-example/go-calls-c/_obj/ -g -O2 cgo_source.go\nIf buck were to call cgo from the same directory that the go toolchain uses, the import paths in cgo files wouldn't have to be changed when migrating from building with go to building with buck.. It looks like the main difference between building cgo with buck versus go build is that buck runs the cgo commands from the buck project root whereas go runs cgo from the same folder where the sources are. \nBuck running the cgo command:\ncd /Users/monty/gocode/src/github.com/monty-uber/cgo-buck-example && GOROOT=/usr/local/Cellar/go/1.9.4/libexec GOOS=darwin GOARCH=amd64 /usr/local/Cellar/go/1.9.4/libexec/pkg/tool/darwin_amd64/cgo -importpath /Users/monty/gocode/src/github.com/monty-uber/cgo-buck-example -srcdir /Users/monty/gocode/src/github.com/monty-uber/cgo-buck-example -objdir buck-out/gen/go-calls-c/call_from_go#cgo-gen-sources/gen go-calls-c/cgo_source.go\nVersus go running the cgo command:\ncd /Users/monty/gocode/src/github.com/monty-uber/cgo-buck-example/go-calls-c &&\nCGO_LDFLAGS=\"-g\" \"-O2\" /usr/local/Cellar/go/1.9.4/libexec/pkg/tool/darwin_amd64/cgo -objdir $WORK/github.com/monty-uber/cgo-buck-example/go-calls-c/_obj/ -importpath github.com/monty-uber/cgo-buck-example/go-calls-c -- -I $WORK/github.com/monty-uber/cgo-buck-example/go-calls-c/_obj/ -g -O2 cgo_source.go\nIf buck were to call cgo from the same directory that the go toolchain uses, the import paths in cgo files wouldn't have to be changed when migrating from building with go to building with buck.. It looks like the srubber fails on cgo binaries because it doesn't find the absolute paths for the dynamic linker that are present in other Mach-O binaries. I think I can fix that instead. Currently the scrubber fails hard if it doesn't find anything to scrub, in this instance would it be acceptable to succeed if it doesn't find what it's looking for?. The point of this method is to scrub non-deterministic metadata found in the LC_UUID command in the binary. If that command is not present (which it is not in cgo binaries), then nothing needs to be scrubbed, it shouldn't fail if it's not found.. My change will address https://github.com/facebook/buck/issues/1809, which will include this change as well as a backwards compatible change as a side effect. I mentioned it in the slack channel yesterday, basically I will propose running the Cgo and C compiler commands in the source directory the same way the go toolchain does it. This change would only affect Cxx rules generated by Cgo builds.. ",
    "sheldonneuberger": "Setting a cwd for relative path resolution in the debugger sounded like the\ncorrect approach to me but I was surprised to find no setting for this in\nStudio or lldb. What are others doing to debug native buck builds in\nAndroid Studio?\nOn Jan 20, 2018 9:33 PM, \"Taras Tsugrii\" notifications@github.com wrote:\n\nReferences to environment where binaries were produced are intentionally\nremoved by scrubbers since they make remote caching ineffective, build\nrules non-hermetic and non-repeatable which is against what Buck was\ncreated for. In general IDEs should not force usage of absolute paths and\nprovide a way to configure a CWD when running a debugger.\nMaybe there is a way to solve this problem without making builds\nnon-hermetic, but unfortunately there isn't one on top of my head.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1719#issuecomment-359225283, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AC42aHUMrf98_zuGIBDYhf0q66Wnl5xWks5tMswhgaJpZM4RlqAU\n.\n. I spoke too soon on this, there is an lldb command to do path replacement. settings set target.source-map . /thepath\n\nThis will replace the first path with the second path. In our case, we use a dot and it works to resolve relative paths to the second path given.\nYou can type that command each time you start an lldb debugging session in Studio. Just need a way to make that happen automatically now.. You get a similar failure if you try to workaround this by deleting the buildfile from .buckconfig and instead adding include_defs(\"//BUCK_DEFS_FILE\") to cell/BUCK:\nBuck wasn't able to parse /Users/sheldon.neuberger/Snapchat/Dev/buckbug/cell/BUCK:\nIOError: [Errno 2] No such file or directory: '/Users/sheldon.neuberger/Snapchat/Dev/buckbug/BUCK_DEFS'. You get a similar failure if you try to workaround this by deleting the buildfile from .buckconfig and instead adding include_defs(\"//BUCK_DEFS_FILE\") to cell/BUCK:\nBuck wasn't able to parse /Users/sheldon.neuberger/Snapchat/Dev/buckbug/cell/BUCK:\nIOError: [Errno 2] No such file or directory: '/Users/sheldon.neuberger/Snapchat/Dev/buckbug/BUCK_DEFS'. I've created a minimal example to repro:\ngit clone git@github.com:sheldonneuberger/buckbug.git\ncd buckbug\nbuck build :buckbug   #this step succeeds as expected\nbuck test   #this step fails\nThe 'buck test' step will succeed if you move the 'cell' directory to be a sibling to buckbug and change the .buckconfig cell directory from \"./cell\" to \"../cell\". However, that approach does not work for submodules. And if \"buck build\" works when it's a subdir then \"buck test\" should too.. I've created a minimal example to repro:\ngit clone git@github.com:sheldonneuberger/buckbug.git\ncd buckbug\nbuck build :buckbug   #this step succeeds as expected\nbuck test   #this step fails\nThe 'buck test' step will succeed if you move the 'cell' directory to be a sibling to buckbug and change the .buckconfig cell directory from \"./cell\" to \"../cell\". However, that approach does not work for submodules. And if \"buck build\" works when it's a subdir then \"buck test\" should too.. @styurin reimport this if you can. The __ANDROID_API__ should only be defined when unified headers is on. Forgot to push this a while ago, sorry about that.. @styurin reimport this if you can. The __ANDROID_API__ should only be defined when unified headers is on. Forgot to push this a while ago, sorry about that.. Was able to make this work by adding \"preferred_linkage\" flags to both mylibx and myliby (and setting link_whole of course, otherwise it drops all the symbols). I also had to add a dummy.cpp src file to the :jni-shared target.\nOnly remaining problem is that buck automatically links against the NDK's static c++ runtime, but I still want to use the shared c++ runtime. Seems there's no way around that, so I'll make a change to buck to allow a choice there.. Ah I see, so specify the headers in a prebuilt_cxx_library and specify the source in a cxx_library. We just gave that a try but prebuilt_cxx_library doesn't work with generated xcode projects (https://github.com/facebook/buck/issues/1098).. The linked issue was closed because the workaround was to use cxx_library instead of prebuilt_cxx_library, the original issue wasn't fixed.. That would make philip's approach work for us, but is that just a hack or is it a reasonable way to use buck? Splitting the headers and source into two separate rules seems obtuse. That being said, I'd be happy with either of these solutions working (although I don't have time to prepare a PR for the generator).. I believe this is ready for merge, if someone could review. Thanks.. Friendly ping.. Friendly ping.. Any update on this?. ",
    "Nickersoft": "@kageiit Is there any particular reason that it's not mentioned in the documentation? Should I add it?\nAlso, I had previously tried this... and had library pointed to a BUCK file which attempted to download the Scala library via remote_file() and the URL org.scala-lang:scala-library-all:pom:2.12.4, however, it errored and said it couldn't download it with no explanation. I've since deleted that code, but can try it again in order to provide more detail about my setup and the error.. @kageiit Alright I got a quick setup going with the same error. Here's my BUCK file:\n```python\nremote_file(\n    name = 'scala-compiler-source',\n    out = 'scala-compiler-source.jar',\n    url = 'org.scala-lang:scala-compiler:jar:2.12.4',\n    sha1 = '557edd918fd41f9260963583ebf5a61a43a6b423',\n)\nprebuilt_jar(\n    name = 'scala-compiler-lib',\n    binary_jar = ':scala-compiler-source',\n    visibility = ['//:rake']\n)\njava_binary(\n    name='scala-compiler',\n    main_class='scala.tools.nsc.Main',\n    deps=[':scala-compiler-lib'],\n)\nremote_file(\n    name = 'scala-library-source',\n    out = 'scala-library-source.jar',\n    url = 'org.scala-lang:scala-library-all:pom:2.12.4',\n    sha1 = '557edd918fd41f9260963583ebf5a61a43a6b423',\n)\nprebuilt_jar(\n    name = 'scala-library',\n    binary_jar = ':scala-library-source',\n    visibility = ['//:rake']\n)\nscala_library(\n    name = \"rake\",\n    source = \"1.8\",\n    target = \"1.8\",\n    srcs = glob([\n        \"src/*/.java\"\n    ])\n)\n```\nwhich was based loosely off of some of the source code I found in this repo. My .buckconfig:\n```config\n[httpserver]\n    port = 0\n[download]\n    in_build = true\n    maven_repo = http://central.maven.org/maven2/\n[scala]\n    compiler = //:scala-compiler\n    library = //:scala-library\n```\nand the output I get running buck build //:rake:\nUnable to download: org.scala-lang:scala-library-all:pom:2.12.4\nUnable to download: org.scala-lang:scala-compiler:jar:2.12.4\nBuild failed: Command failed with exit code -1.\n    When running <curl>.\n    When building rule //:scala-library-source.\nand here's a gist of the full output when the verbosity level is set to 8.\nHopefully this is useful.. skimming through the output the errors seem pretty generic, but I could be overlooking something. Also, I'll start looking into the contributing guidelines and how to update the docs. The Scala code in this repo is from two years ago so it's crazy it never got added.. @kageiit Alright I got a quick setup going with the same error. Here's my BUCK file:\n```python\nremote_file(\n    name = 'scala-compiler-source',\n    out = 'scala-compiler-source.jar',\n    url = 'org.scala-lang:scala-compiler:jar:2.12.4',\n    sha1 = '557edd918fd41f9260963583ebf5a61a43a6b423',\n)\nprebuilt_jar(\n    name = 'scala-compiler-lib',\n    binary_jar = ':scala-compiler-source',\n    visibility = ['//:rake']\n)\njava_binary(\n    name='scala-compiler',\n    main_class='scala.tools.nsc.Main',\n    deps=[':scala-compiler-lib'],\n)\nremote_file(\n    name = 'scala-library-source',\n    out = 'scala-library-source.jar',\n    url = 'org.scala-lang:scala-library-all:pom:2.12.4',\n    sha1 = '557edd918fd41f9260963583ebf5a61a43a6b423',\n)\nprebuilt_jar(\n    name = 'scala-library',\n    binary_jar = ':scala-library-source',\n    visibility = ['//:rake']\n)\nscala_library(\n    name = \"rake\",\n    source = \"1.8\",\n    target = \"1.8\",\n    srcs = glob([\n        \"src/*/.java\"\n    ])\n)\n```\nwhich was based loosely off of some of the source code I found in this repo. My .buckconfig:\n```config\n[httpserver]\n    port = 0\n[download]\n    in_build = true\n    maven_repo = http://central.maven.org/maven2/\n[scala]\n    compiler = //:scala-compiler\n    library = //:scala-library\n```\nand the output I get running buck build //:rake:\nUnable to download: org.scala-lang:scala-library-all:pom:2.12.4\nUnable to download: org.scala-lang:scala-compiler:jar:2.12.4\nBuild failed: Command failed with exit code -1.\n    When running <curl>.\n    When building rule //:scala-library-source.\nand here's a gist of the full output when the verbosity level is set to 8.\nHopefully this is useful.. skimming through the output the errors seem pretty generic, but I could be overlooking something. Also, I'll start looking into the contributing guidelines and how to update the docs. The Scala code in this repo is from two years ago so it's crazy it never got added.. @kageiit Oh wow, my bad. I forgot to include the mvn: prefix this time around, but in my original code I had it in and still got an error. I added the prefix back to my URLs and updating the hashes to rule out hash errors I still get an error:\nUnable to download: mvn:org.scala-lang:scala-library-all:pom:2.12.4\nBuild failed: Command failed with exit code -1.\n    When running <curl>.\n    When building rule //:scala-library-source.\nAnd like before, here's the v8 output. \nIt would appear it's checking for the existence of http://central.maven.org/maven2/org/scala-lang/scala-library-all/2.12.4/scala-library-all-2.12.4-pom.jar, which doesn't exist. However, http://central.maven.org/maven2/org/scala-lang/scala-library-all/2.12.4/scala-library-all-2.12.4.pom does exist, which Gradle still seems to be able to understand despite Buck failing to.\nI actually just did a check and changed my task to:\npython\nremote_file(\n    name = 'scala-library-source',\n    out = 'scala-library-source.jar',\n    url = 'mvn:org.scala-lang:scala-library:jar:2.12.4',\n    sha1 = '7663f74ef944453c86cc7e6597ed33e9281f6412',\n)\nand it seems to work now... I'm not super familiar with how pom files are handled, so I guess I'll just ignore it. Anyway, I'll close this for now seeing it seems to be working and I'll look into updating the docs.. @kageiit Oh wow, my bad. I forgot to include the mvn: prefix this time around, but in my original code I had it in and still got an error. I added the prefix back to my URLs and updating the hashes to rule out hash errors I still get an error:\nUnable to download: mvn:org.scala-lang:scala-library-all:pom:2.12.4\nBuild failed: Command failed with exit code -1.\n    When running <curl>.\n    When building rule //:scala-library-source.\nAnd like before, here's the v8 output. \nIt would appear it's checking for the existence of http://central.maven.org/maven2/org/scala-lang/scala-library-all/2.12.4/scala-library-all-2.12.4-pom.jar, which doesn't exist. However, http://central.maven.org/maven2/org/scala-lang/scala-library-all/2.12.4/scala-library-all-2.12.4.pom does exist, which Gradle still seems to be able to understand despite Buck failing to.\nI actually just did a check and changed my task to:\npython\nremote_file(\n    name = 'scala-library-source',\n    out = 'scala-library-source.jar',\n    url = 'mvn:org.scala-lang:scala-library:jar:2.12.4',\n    sha1 = '7663f74ef944453c86cc7e6597ed33e9281f6412',\n)\nand it seems to work now... I'm not super familiar with how pom files are handled, so I guess I'll just ignore it. Anyway, I'll close this for now seeing it seems to be working and I'll look into updating the docs.. @kageiit Interesting... should I open a PR for this or just a use a custom fork of Buck or something?. ",
    "vkalintiris": "I've updated the vkalintiris:codesign branch. Is there anything else I should do, or should I just wait for someone to review my changes? No hurry on my part. I'm just asking because I'm not familiar with github's PR process.. Ping.. Ping.. Ping.. Gentle ping.\nAFAICT, the failures in the AppVeyor job are not caused by this patch.. It's been a while since I wrote this patch but I do remember that iteration order would affect which toolchain buck would pick given that Files.newDirectoryStream() doesn't have a well defined iteration order. Having said that, I can't reproduce the problem with the current master.\nI only kept this to minimize the number of changes we had to do in AppleToolchainDiscoveryTest.java due to the usage of ImmutableMaps.. ",
    "beauby": "@kageiit I believe obfuscated env vars are not visible from pull requests from forks, as otherwise anyone could issue a PR modifying the .travis.yml, get the new config to run and add a statement to print the env var in the build logs.. ",
    "DavidLaidlaw": "It would be helpful to know how to do this, in general, since the \"sign in\" page suggest contacting a workspace admin. It would be helpful to know how to do this, in general, since the \"sign in\" page suggest contacting a workspace admin. The message on the public face of the slack channel says it requires an\ninvitation and to contact an administrator.  But it does not list any\nidentity or contact info for an administrator, so I don't know whom to\ncontact or how to do so.\nMy question was how to identify a contact person or administrator.\nThanks,\n-David Laidlaw\nOn Tue, Mar 27, 2018 at 2:49 AM, Taras Tsugrii notifications@github.com\nwrote:\n\n@DavidLaidlaw https://github.com/DavidLaidlaw, the slack channel is\ninvitation only, so you can either contact us or anyone else who's already\na member to send an invitation.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1779#issuecomment-376416144, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AMV3okMoh0y5tIVrwUL1HFby_60n-jySks5tieEQgaJpZM4SH16z\n.\n\n\n-- \nDavid Laidlaw, Professor, Brown Computer Science\nBox 1910, Providence, RI 02912, +1-401-354-2819\nhttp://www.cs.brown.edu/~dhl\n. No, never did.  Ended up getting connected outside of slack\nOn Fri, Jan 18, 2019 at 2:46 PM bherman1 notifications@github.com wrote:\n\nHi @DavidLaidlaw https://github.com/DavidLaidlaw :\nDid you ever find out the answer to your question in this thread?\nI have same issue. I know the Workspace URL/Slack subdomain, but I don't\nsee anyway to request an invite or find out contact info. for the admin.\nThanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1779#issuecomment-455665955, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AMV3ohbNxMPq08udxokRojTTkNK-kuERks5vEiSqgaJpZM4SH16z\n.\n\n\n-- \nDavid Laidlaw, Professor, Brown Computer Science\nBox 1910, Providence, RI 02912, +1-401-354-2819\nhttp://www.cs.brown.edu/~dhl\n. No, never did.  Ended up getting connected outside of slack\nOn Fri, Jan 18, 2019 at 2:46 PM bherman1 notifications@github.com wrote:\n\nHi @DavidLaidlaw https://github.com/DavidLaidlaw :\nDid you ever find out the answer to your question in this thread?\nI have same issue. I know the Workspace URL/Slack subdomain, but I don't\nsee anyway to request an invite or find out contact info. for the admin.\nThanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1779#issuecomment-455665955, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AMV3ohbNxMPq08udxokRojTTkNK-kuERks5vEiSqgaJpZM4SH16z\n.\n\n\n-- \nDavid Laidlaw, Professor, Brown Computer Science\nBox 1910, Providence, RI 02912, +1-401-354-2819\nhttp://www.cs.brown.edu/~dhl\n. ",
    "bherman1": "Hi @DavidLaidlaw : \nDid you ever find out the answer to your question in this thread?  \nI have same issue.  I know the Workspace URL/Slack subdomain, but I don't see anyway to request an invite or find out contact info. for the admin.\nThanks!. Hi @DavidLaidlaw : \nDid you ever find out the answer to your question in this thread?  \nI have same issue.  I know the Workspace URL/Slack subdomain, but I don't see anyway to request an invite or find out contact info. for the admin.\nThanks!. ",
    "dlo": "You are correct, thanks for the heads up! Cheers.. ",
    "bturner": "Interesting that aarch64 would need a 16 byte structure, because ALIGN_GNUC on x86-64 is wrong.\neventpoll.h on x86-64, at least the distributions I have handy (Mint 19, Fedora 28, CentOS 7), looks something like this:\n```c\n/ \n * On x86-64 make the 64bit structure have the same alignment as the\n * 32bit structure. This makes 32bit emulation easier.\n \n * UML/x86_64 needs the same packing as x86_64\n */\nifdef x86_64\ndefine EPOLL_PACKED attribute((packed))\nelse\ndefine EPOLL_PACKED\nendif\nstruct epoll_event {\n        __u32 events;\n        __u64 data;\n} EPOLL_PACKED;\n```\nThe packing means the struct is 12 bytes, even on 64-bit, and requires ALIGN_NONE. Here's a simple test:\n```c\ninclude \ninclude \nint main(int argc, char *argv[]) {\n    printf(\"sizeof(epoll_event) = %ld\\n\", sizeof(struct epoll_event));\nreturn 0;\n\n}\n```\nWith the following output:\nbturner@auvry:~$ uname -a\nLinux auvry 4.15.0-20-generic #21-Ubuntu SMP Tue Apr 24 06:16:15 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\nbturner@auvry:~$ file a.out\na.out: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=40a6f0bfb5eb1904c2c7951faa2068b87b6680cd, not stripped\nbturner@auvry:~$ ./a.out\nsizeof(epoll_event) = 12\n(The output is similar on CentOS and Fedora)\nI don't have an ARM64 machine, or a cross-compile environment, where I can test. As discussed here, though, it may be that the most expeditious way to move forward, so that Buck can get the JNA improvements made in newer versions of NuProcess, is to switch the library back to ALIGN_GNUC, at least for the moment, because the library doesn't currently ever pass an array larger than 1 to epoll_wait. If it did, though, then ALIGN_GNUC fails on x86-64 Linux.. ",
    "AttilaTheFun": "@mgrebenets I generated the project with buck project //Application:App\nMy buck build rule is in the BuckTestApp repo I linked above:\n```apple_binary(\n    name = 'Binary',\n    srcs = glob([\n        'Binary/Sources/*.swift',\n    ]),\n    deps = [\n        '//Application/Binary/Resources:Resources', \n        '//Application/Binary/Assets:Assets',\n        '//Application/Services/Users/API:UsersAPI',\n        '//Application/Services/Users/Impl:UsersImpl',\n        '//Application/Components/Onboarding/Sources:Onboarding',\n    ],\n    frameworks = [\n        '$SDKROOT/System/Library/Frameworks/Foundation.framework',\n        '$SDKROOT/System/Library/Frameworks/UIKit.framework',\n    ],\n)\napple_bundle(\n    name = 'App',\n    binary = ':Binary',\n    tests = [':AppTest'],\n    extension = 'app',\n    info_plist = 'Info.plist',\n    info_plist_substitutions = {\n        'PRODUCT_BUNDLE_IDENTIFIER': 'com.Test.BuckTestApp',\n        'CURRENT_PROJECT_VERSION': '1',\n    },\n)\n```\nAnd the .plist generated for the application target is:\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n<plist version=\"1.0\">\n<dict>\n    <key>CFBundleDevelopmentRegion</key>\n    <string>en</string>\n    <key>CFBundleExecutable</key>\n    <string>$(EXECUTABLE_NAME)</string>\n    <key>CFBundleIdentifier</key>\n    <string>$(PRODUCT_BUNDLE_IDENTIFIER)</string>\n    <key>CFBundleInfoDictionaryVersion</key>\n    <string>6.0</string>\n    <key>CFBundleName</key>\n    <string>$(PRODUCT_NAME)</string>\n    <key>CFBundlePackageType</key>\n    <string>APPL</string>\n    <key>CFBundleShortVersionString</key>\n    <string>1.0</string>\n    <key>CFBundleVersion</key>\n    <string>1</string>\n    <key>LSRequiresIPhoneOS</key>\n    <true/>\n    <key>UILaunchStoryboardName</key>\n    <string>LaunchScreen</string>\n    <key>UIMainStoryboardFile</key>\n    <string>Main</string>\n    <key>UIRequiredDeviceCapabilities</key>\n    <array>\n        <string>armv7</string>\n    </array>\n    <key>UISupportedInterfaceOrientations</key>\n    <array>\n        <string>UIInterfaceOrientationPortrait</string>\n        <string>UIInterfaceOrientationLandscapeLeft</string>\n        <string>UIInterfaceOrientationLandscapeRight</string>\n    </array>\n    <key>UISupportedInterfaceOrientations~ipad</key>\n    <array>\n        <string>UIInterfaceOrientationPortrait</string>\n        <string>UIInterfaceOrientationPortraitUpsideDown</string>\n        <string>UIInterfaceOrientationLandscapeLeft</string>\n        <string>UIInterfaceOrientationLandscapeRight</string>\n    </array>\n</dict>\n</plist>\nIt looks like you may be right, because I don't see the bundle identifier in the general information tab for that target in xcode. How do I properly generate the plist?. @mgrebenets I've also noticed that the deployment target for all targets was unset - do you know how to set that through buck?. @dinhviethoa Yes, thanks! I've since updated my sample project with a BUCK file that allows the project to be built + run in the simulator via both buck in the terminal as well as Xcode.. @dinhviethoa Yes, thanks! I've since updated my sample project with a BUCK file that allows the project to be built + run in the simulator via both buck in the terminal as well as Xcode.. ",
    "ChuntaoLu": "I spent some time looking into the issue, but couldn't come up a fix with my limited understanding of buck internals and cxx_lib compilation. I did find a couple of issues in the source code:\n- the documentation says .go source files are compiled with cgo compiler, however, buck evokes cgo tool with cgo_library srcs as arguments while the cgo command expects arguments to be .go files. This would not be a problem if cgo_library srcs contain only .go files.\n- buck passes incorrect directory with the -I flag to cgo, the directory buck passes is the parent directory of the correct header directory. Notice in the following example the header file is in the a nested sub-directory:\n```bash\nfrom buck debug log\ncd /Users/lu/cgo-buck-example && GOROOT=/usr/local/Cellar/go/1.11.2/libexec GOOS=darwin \nGOARCH=amd64 GOARM='' /usr/local/Cellar/go/1.11.2/libexec/pkg/tool/darwin_amd64/cgo \n-importpath /Users/lu/cgo-buck-example -srcdir /Users/lu/cgo-buck-example \n-objdir buck-out/gen/go-calls-c/call_from_go#cgo,cgo-gen-sources,default/gen\n -- -I/Users/lu/cgo-buck-example/buck-out/gen/go-calls-c/call_from_go#cgo,default,headers\ngo-calls-c/cgo_source.g\nbash\n\u279c  cgo-buck-example git:(master) \u2717 tree /Users/lu/cgo-buck-example/buck-out/gen/go-calls-c/call_from_go#cgo,default,headers     21:39:56\n/Users/lu/cgo-buck-example/buck-out/gen/go-calls-c/call_from_go#cgo,default,headers\n\u2514\u2500\u2500 go-calls-c\n    \u2514\u2500\u2500 call_from_go.h -> /Users/lu/cgo-buck-example/go-calls-c/call_from_go.h\n- I suspect the `-I` flag is also incorrect in the C code compilation step of the cgo_library rule, instead of a directory, buck passes a .hmap binary file:bash\nfrom buck debug log\n/usr/bin/clang -x c -fPIC -fPIC\n -I buck-out/gen/go-calls-c/call_from_go#cgo,cgo-first-step,default,private-headers.hmap \n-I buck-out -Wno-unknown-attributes -Xclang -fdebug-compilation-dir \n-Xclang . '-fdebug-prefix-map=/Users/lu/Uber/cgo-buck-example=.' \n-o buck-out/gen/go-calls-c/call_from_go#cgo,cgo-first-step,compile-pic_cgo_export.c.o8114ac55,default/call_from_go#cgo,cgo-gen-sources,default/gen/_cgo_export.c.o\n -c -MD -MF buck-out/gen/go-calls-c/call_from_go#cgo,cgo-first-step,compile-pic-_cgo_export.c.o8114ac55,default/call_from_go#cgo,cgo-gen-sources,default/gen/_cgo_export.c.o.dep buck-out/gen/go-calls-c/call_from_go#cgo,cgo-gen-sources,default/gen/_cgo_export.c\nI am not familiar with C compilation, but the Clang man page says the `-I` flag should specify a directory:man\n-I\n              Add the specified directory to the search path for include files.\n```\nI was able to fix the first two issues, but couldn't sort things through for the third one. Hope above information helps.. I spent some time looking into the issue, but couldn't come up a fix with my limited understanding of buck internals and cxx_lib compilation. I did find a couple of issues in the source code:\n- the documentation says .go source files are compiled with cgo compiler, however, buck evokes cgo tool with cgo_library srcs as arguments while the cgo command expects arguments to be .go files. This would not be a problem if cgo_library srcs contain only .go files.\n- buck passes incorrect directory with the -I flag to cgo, the directory buck passes is the parent directory of the correct header directory. Notice in the following example the header file is in the a nested sub-directory:\n```bash\nfrom buck debug log\ncd /Users/lu/cgo-buck-example && GOROOT=/usr/local/Cellar/go/1.11.2/libexec GOOS=darwin \nGOARCH=amd64 GOARM='' /usr/local/Cellar/go/1.11.2/libexec/pkg/tool/darwin_amd64/cgo \n-importpath /Users/lu/cgo-buck-example -srcdir /Users/lu/cgo-buck-example \n-objdir buck-out/gen/go-calls-c/call_from_go#cgo,cgo-gen-sources,default/gen\n -- -I/Users/lu/cgo-buck-example/buck-out/gen/go-calls-c/call_from_go#cgo,default,headers\ngo-calls-c/cgo_source.g\nbash\n\u279c  cgo-buck-example git:(master) \u2717 tree /Users/lu/cgo-buck-example/buck-out/gen/go-calls-c/call_from_go#cgo,default,headers     21:39:56\n/Users/lu/cgo-buck-example/buck-out/gen/go-calls-c/call_from_go#cgo,default,headers\n\u2514\u2500\u2500 go-calls-c\n    \u2514\u2500\u2500 call_from_go.h -> /Users/lu/cgo-buck-example/go-calls-c/call_from_go.h\n- I suspect the `-I` flag is also incorrect in the C code compilation step of the cgo_library rule, instead of a directory, buck passes a .hmap binary file:bash\nfrom buck debug log\n/usr/bin/clang -x c -fPIC -fPIC\n -I buck-out/gen/go-calls-c/call_from_go#cgo,cgo-first-step,default,private-headers.hmap \n-I buck-out -Wno-unknown-attributes -Xclang -fdebug-compilation-dir \n-Xclang . '-fdebug-prefix-map=/Users/lu/Uber/cgo-buck-example=.' \n-o buck-out/gen/go-calls-c/call_from_go#cgo,cgo-first-step,compile-pic_cgo_export.c.o8114ac55,default/call_from_go#cgo,cgo-gen-sources,default/gen/_cgo_export.c.o\n -c -MD -MF buck-out/gen/go-calls-c/call_from_go#cgo,cgo-first-step,compile-pic-_cgo_export.c.o8114ac55,default/call_from_go#cgo,cgo-gen-sources,default/gen/_cgo_export.c.o.dep buck-out/gen/go-calls-c/call_from_go#cgo,cgo-gen-sources,default/gen/_cgo_export.c\nI am not familiar with C compilation, but the Clang man page says the `-I` flag should specify a directory:man\n-I\n              Add the specified directory to the search path for include files.\n```\nI was able to fix the first two issues, but couldn't sort things through for the third one. Hope above information helps.. ",
    "matanster": "Right. This is implied in the prerequisites section. Unfortunately setting a python2 environment with virtualenv (virtualenv --python=/usr/bin/python2.7), after an ant clean and running ant again, a different error yields on the same get-buck-info step:\ngen-buck-info:\n     [exec] Traceback (most recent call last):\n     [exec]   File \"programs/gen_buck_info.py\", line 51, in <module>\n     [exec]     sys.exit(main(sys.argv))\n     [exec]   File \"programs/gen_buck_info.py\", line 21, in main\n     [exec]     version = buck_version.get_clean_buck_version(path)\n     [exec]   File \"..../buck/programs/buck_version.py\", line 85, in get_clean_buck_version\n     [exec]     if allow_dirty or not is_dirty(dirpath):\n     [exec]   File \"..../buck/programs/buck_version.py\", line 65, in is_dirty\n     [exec]     output = '\\n'.join([line for line in output.splitlines() if not IGNORE_PATHS_RE.search(line)])\n     [exec]   File \"..../buck/programs/buck_version.py\", line 65, in <listcomp>\n     [exec]     output = '\\n'.join([line for line in output.splitlines() if not IGNORE_PATHS_RE.search(line)])\n     [exec] TypeError: cannot use a string pattern on a bytes-like object\n. I wonder whether it stumbles on this only for me.... or maybe there's some older (yet recent) stable commit where this doesn't happen yet.. I guess I should. Actually I just wish to have it for Nuclide (https://nuclide.io/docs/languages/cpp/), whereas the jitpack page of it (https://jitpack.io/#facebook/buck/v2018.02.16.01) only implies a\ndevelopment project use case setup. Any idea how would Nuclide use it? maybe I should ask that on the Nuclide project....\nBTW what's the justification for buck over plain old maven repositories for your projects? I guess it's really popular at FB so must be a reason..\n. Well I'm lost on how to install buck for Nuclide's C++ support. Its mentioned it is a prerequisite, but the buck download page only mentions how to include it in development projects. I'll fetch my answer on the nuclide github repo \u2015 thanks for all your support so far!. Yep, on mac. Less so linux, but thanks anyway.. I wasn't aware of the deb file on the releases page (\nhttps://github.com/facebook/buck/releases). it works!\nAs to jitpack I've no idea how to install from it, the jitpack page only\nmentions how to include buck as a project dependency.... perhaps you might\ncomment\nOn Wed, Mar 28, 2018 at 6:15 PM, Taras Tsugrii notifications@github.com\nwrote:\n\nOur release page has deb package for Linux in case it works for you and\njitpack works for all OSes and distributions.\nOn Wed, Mar 28, 2018, 6:27 AM matanster notifications@github.com wrote:\n\nYep, on mac. Less so linux, but thanks anyway.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1812#issuecomment-376885975,\nor mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAKhBgMythvj-\nDK2qO2ZmTfWJLUtGwIxks5ti4-jgaJpZM4SzLS2\n.\n\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1812#issuecomment-376923843, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AEw74zP4dXM136ykGK8ZzmHp-D4CApXXks5ti6kAgaJpZM4SzLS2\n.\n. \n",
    "jhdub23": "I can build and run a simple HelloWorld application.\n\"ant -diagnostics\" gives:\njava.runtime.name : OpenJDK Runtime Environment\nsun.boot.library.path : /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-3.b14.el6_9.x86_64/jre/lib/amd64\njava.vm.version : 25.161-b14\n. I can build and run a simple HelloWorld application.\n\"ant -diagnostics\" gives:\njava.runtime.name : OpenJDK Runtime Environment\nsun.boot.library.path : /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.161-3.b14.el6_9.x86_64/jre/lib/amd64\njava.vm.version : 25.161-b14\n. First thing I tried.  Scoured the web.  Closest I came were for other applications:\nhttps://github.com/tensorflow/tensorflow/issues/14208\nhttps://github.com/java-native-access/jna/issues/853\nThis led me to believe that buck has java code that is directly using GLIBC_2_14 features, via the JNI.  I'm from the C/C++ world and don't use JAVA, so I'm not familiar with how JAVA interacts with the system.. First thing I tried.  Scoured the web.  Closest I came were for other applications:\nhttps://github.com/tensorflow/tensorflow/issues/14208\nhttps://github.com/java-native-access/jna/issues/853\nThis led me to believe that buck has java code that is directly using GLIBC_2_14 features, via the JNI.  I'm from the C/C++ world and don't use JAVA, so I'm not familiar with how JAVA interacts with the system.. Perhaps the requirement of glibc 2.14 should be in the installation notes.  I finally got buck to work on our CentOS6 system.  I used linuxbrew to install the latest tool chain with an updated glibc.  Making things work without using LD_LIBRARY_PATH (which makes all the existing tools break) was a bit tricky.  I had to use \"brew edit ant\", \"brew edit buck\" to add additional dependencies (glibc, python2, jdk@8).. Perhaps the requirement of glibc 2.14 should be in the installation notes.  I finally got buck to work on our CentOS6 system.  I used linuxbrew to install the latest tool chain with an updated glibc.  Making things work without using LD_LIBRARY_PATH (which makes all the existing tools break) was a bit tricky.  I had to use \"brew edit ant\", \"brew edit buck\" to add additional dependencies (glibc, python2, jdk@8).. ",
    "luisxiaomai": "I got the same problem to\n[ndk]\nndk_version = 16.1.4479499\napp_platform = android-23. ",
    "fess89": "same issue for me while trying to compile the sample project\n[ndk]\n  ndk_version = 16.1.4479499\n  app_platform = android-21. ",
    "kafji": "@styurin thanks.\nThe error is actually because ideabuck is unable to locate adb.\nLog:\n2018-03-27 12:14:39,208 [ thread 12]  ERROR - ck.config.BuckSettingsProvider - java.lang.RuntimeException: Unable to locate adb based on environment variables, or it's not marked as being executable. You can specify the adb path from Preferences/Settings > Tools > Buck > Adb Executable Path \njava.lang.RuntimeException: Unable to locate adb based on environment variables, or it's not marked as being executable\n    at com.facebook.buck.intellij.ideabuck.util.ExecutableFinder.getExecutable(ExecutableFinder.java:63)\n    at com.facebook.buck.intellij.ideabuck.config.BuckExecutableDetector.getAdbExecutable(BuckExecutableDetector.java:50)\n    at com.facebook.buck.intellij.ideabuck.config.BuckSettingsProvider.resolveAdbExecutable(BuckSettingsProvider.java:153)\n    at com.facebook.buck.intellij.ideabuck.debugger.AndroidDebugger.init(AndroidDebugger.java:49)\n    at com.facebook.buck.intellij.ideabuck.ui.BuckEventsConsumer$14.run(BuckEventsConsumer.java:640)\n    at com.intellij.openapi.application.impl.ApplicationImpl$2.run(ApplicationImpl.java:334)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nBut in Buck console it just shows: \n\nI've solved my issue but I think it would be better if ideabuck can show a more meaningful error directly in the buck console.. ",
    "R1kk3r": "Sounds complicated... I tried to dig into the source code of buck to understand how flavours works and what is their syntax for each rules but I didn't found it.\nBTW, is it normal that buck build //common:hello#macosx-x86_64 does not build anything nor print any error? It works fine with buck build //common:hello or buck build //common:hello#macosx-x86_64,static. Since buck audit flavors //common:hello is showing only the first part (macosx-x86_64), it is quite confusing that it didn't work when you want to use it. Any idea if this behaviour is expected?\n. cxx_library(\n  name = 'hello',\n  srcs = glob(['file_*.c'],[custom.c']), \n  visibility = [ \n    'PUBLIC',\n  ],  \n)\nYes you are right, my errors occurs because of glob(). Since cxx_library can be headers only (without sources), it does not trigger any build error when glob() return an empty array. So, having any sort of bad path or typo inside glob() will not fail the build. This happened while I was refactoring/moving some source files which invalidate the paths inside glob() without triggering any build errors (I noticed later that there was nothing generated inside ./buck-out/gen/). So, it is not a bug.\n. > This is why you're not seeing anything get built when you do 'buck build //:a'. 'a' internally is a noop rule, so no deps get built either.\nWhat you say makes sense if there was no build output at all. But actually, buck build //:a builds and generates a static library but does not trigger the genrule. So this is not a noop rule actually, it is automatically mapped to the default flavour.\n$ buck build :a\nPARSING BUCK FILES: FINISHED IN 0.0s\nCREATING ACTION GRAPH: FINISHED IN 0.0s\nBUILT 1/4 JOBS 0.0s //:a#default,private-headers\nBUILT 2/4 JOBS 0.0s //:a#default,preprocessor-deps\nBUILT 3/4 JOBS 0.2s //:a#compile-lib.c.o13e6a2fc,default\nBUILT 4/4 JOBS 0.1s //:a#default,static\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES\nBUILDING: FINISHED IN 0.3s (100%) 4/4 JOBS, 4 UPDATED, 50.0% CACHE MISS\nBUILD SUCCEEDED\nYou are right, calling a certain invalid flavoured library rule directly triggers the genrule but there's no output for the library under buck-out/gen/...\n$ buck build :a#default\nPARSING BUCK FILES: FINISHED IN 0.0s\nCREATING ACTION GRAPH: FINISHED IN 0.0s\nBUILT 1/2 JOBS 0.0s //:a#default\nBUILT 2/2 JOBS 0.0s //:rule\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES\nBUILDING: FINISHED IN 0.1s (100%) 2/2 JOBS, 2 UPDATED, 50.0% CACHE MISS\nBUILD SUCCEEDED\nCalling another but valid flavoured library rule does not trigger the genrule but the library is builded correctly.\n$ buck build :a#default,static\nPARSING BUCK FILES: FINISHED IN 0.0s\nCREATING ACTION GRAPH: FINISHED IN 0.0s\nBUILT 1/4 JOBS 0.0s //:a#default,private-headers\nBUILT 2/4 JOBS 0.0s //:a#default,preprocessor-deps\nBUILT 3/4 JOBS 0.1s //:a#compile-lib.c.o13e6a2fc,default\nBUILT 4/4 JOBS 0.1s //:a#default,static\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES\nBUILDING: FINISHED IN 0.2s (100%) 4/4 JOBS, 4 UPDATED, 50.0% CACHE MISS\nBUILD SUCCEEDED\nFinally having a cxx_binary with deps on cxx_library which have deps on a genrule. The genrule is not triggered when we build the cxx_binary rule.\nbuck build //:b\nPARSING BUCK FILES... 0.0s (100%)\nCREATING ACTION GRAPH: FINISHED IN 0.3s\nBUILT 2/11 JOBS 0.0s //:a\nBUILT 4/10 JOBS 0.0s //:b#default,private-headers\nBUILT 5/10 JOBS 0.0s //:b#default,preprocessor-deps\nBUILT 6/10 JOBS 0.2s //:a#compile-lib.c.o13e6a2fc,default\nBUILT 7/10 JOBS 0.2s //:b#compile-hello.c.o1f717d69,default\nBUILT 8/10 JOBS 0.1s //:a#default,static\nBUILT 9/10 JOBS 0.0s //:b\nBUILT 10/10 JOBS 0.4s //:b#binary\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES\nBUILDING: FINISHED IN 1.2s (100%) 10/10 JOBS, 8 UPDATED, 40.0% CACHE MISS\nBUILD SUCCEEDED\nThose results does not make sense to me...\n$ buck --version\nbuck version v2018.03.26.01. Another tiny example.\nA shared library that depend on a static library which need crc32(..) from zlib.\nBUCK\ncxx_library(\nname='main',\nsrcs=['main.c'],\nlink_style='shared',\ndeps=['//lib:lib'],\n)\nmain.c\nint main()\n{\n    return 0;\n}\nlib/BUCK\ncxx_library(\n    name='lib',\n    srcs=['test.c'],\n    exported_linker_flags=['-lz'],\n    preferred_linkage='static',\n    link_style='static',\n    link_whole=True,\n    visibility=['PUBLIC']\n)\nlib/test.c\n```\ninclude \ninclude \nint test()\n{\n    # Just for the example of using crc32(), the code below does not make any sense\n    long crc = 10;\n    const unsigned char buf = (const unsigned char) &crc\n    int len = 10;\n    crc32(crc, buf, len);\n    return 1;\n}\n```\n$ buck build :main#android-arm64,shared\nbuck-out/gen/lib/lib#android-arm64,static-pic/liblib.a(test.c.o): In function `test':\n./lib/test.c:9: undefined reference to `crc32'\nclang++: error: linker command failed with exit code 1 (use -v to see invocation)\nLooking at the ld command, the -lz flags is placed before the lib.a. When using CMake with the NDK, the linking phase is done without any issue. There's two main differences between Buck and CMake here:\n- Buck use the --as-needed flags while CMake doesn't\n- CMake place the -lz flags after the library.\nIn fact, adding the --as-needed to the CMake command works fine too. So the error is definitely about the -lz flag order on the Buck side. \nHere's a linker command example:\nCMake\n.../bin/ld ... -m aarch64linux -shared ... --as-needed -soname libmain.so CMakeFiles/slib.dir/main.c.o  --whole-archive liblib.a --no-whole-archive -lz ...\nBuck\n.../bin/ld  ... -m aarch64linux -shared ...  -soname libmain.so buck-out/gen/lib#android-arm64,compile-pic-main.c.ofc85ff2c/main.c.o  -lz --whole-archive buck-out/gen/lib/lib#android-arm64,static-pic/liblib.a --no-whole-archive ...\n-lz is a shared library and should be placed at the end of the command line (https://blogs.oracle.com/d/library-order-is-important).\n. Thank you for your reply I will try with master and see if it works. But I guess it works with GCC but not with Clang. In the mean time, here\u2019s my version of buck: \n$ buck --version\nbuck version v2018.03.26.01\nand I am using the NDK 15c and Andro\u00efd SDK 26.0.2. Also I have this in my buckconfig:\n[ndk]\ncpu_abis = armv7, arm64\ncompiler = clang\ncxx_runtime = libcxx\n. Thank you for your reply I will try with master and see if it works. But I guess it works with GCC but not with Clang. In the mean time, here\u2019s my version of buck: \n$ buck --version\nbuck version v2018.03.26.01\nand I am using the NDK 15c and Andro\u00efd SDK 26.0.2. Also I have this in my buckconfig:\n[ndk]\ncpu_abis = armv7, arm64\ncompiler = clang\ncxx_runtime = libcxx\n. Not directly related to my issue (https://github.com/facebook/buck/issues/1853) but definitely linked to the flavoured trickiness.\nFrom my understanding, the cxx_genrule is a flavoured version of a genrule. Calling it without any flavour has no effect. If you call it like buck build //:test-file#default, it will work. I guess cxx_genrule is most of the time used to generate source code, assembly or object file and should be referenced inside srcs/headers/deps of a cxx_library/cxx_binary. That way, when you build the top target, it magically propagate the flavour to your cxx_genrule. As the online documentation is most of the time deprecated and never show all options, I got into the habit to look at the source code to really see how it works. Most of the time you find what you want inside the test cases, for example in https://github.com/facebook/buck/tree/master/test/com/facebook/buck/cxx/testdata/sources_from_cxx_genrule. ",
    "davidaurelio": "Done, it removed unused imports.. ",
    "timmych": "@cwoodwar6, thanks for reporting the issue! This should have been resolved now with a8de566. Let us know if you still experience any issue.. @cwoodwar6, thanks for reporting the issue! This should have been resolved now with a8de566. Let us know if you still experience any issue.. With 63369ad239f737c39c510da974dca712f8aa4691 this error message will be \"File not found: {path}\" and it should be more informative now.  \nIt is a bit hard to make it specific about executable and PATH because SourcePath can be any kind of files. \n. With 63369ad239f737c39c510da974dca712f8aa4691 this error message will be \"File not found: {path}\" and it should be more informative now.  \nIt is a bit hard to make it specific about executable and PATH because SourcePath can be any kind of files. \n. Hi! All C++ coverage options get enabled by passing command line options to the compiler and/or linker, so all you need to do is read the compiler documentation and instruct Buck to pass the right arguments. For gcov/lcov, you'd pass -coverage to the compiler and to the linker. We use coverage mapping. https://llvm.org/docs/CoverageMappingFormat.html explains the flags that need to be passed to clang. \nNext, after running the tests you'd have to extract the coverage data. How you do that depends on what type of coverage instrumentation was used. For coverage mapping, the same page (https://llvm.org/docs/CoverageMappingFormat.html) explains in the \"Quick Start\" section how to do it. Extensive documentation is also available for gcov/lcov. But all of this is pretty much beyond the duties of the build system.. Can you please add more context to help us understand the issue? (e.g. what were you trying to accomplish, and what project is this, what command you ran). Hmm I can't repro this issue.  It looks like an environment issue to me that Buck couldn't build or run the binary. \nCan you make sure you correctly installed Buck as the documentation?\nYou can also try running buck build --show-output //com/facebook/buck/demo:hello-buck-java to see if Buck builds correctly.. > <test message=\"\nExpected: \"Meow\\n\"\n     but: was \"Meow\\nMeow\\n\u0000\u0000\u0000\fe\"\"\nIt seems the 2nd test result of SimpleProcessListenerTest.catTextSentToStdinReceivedOnStdout contains an invalid char &#0;\nI can't reproduce it with multiple test runs though... \n. @ghvg1313 can you explain why this function doesnt work as you expected? Throwable is a parent class of Exception so I dont understand why it doesn't work for NoSuchBuildTargetException. I think this is in the documentation:\n\nNote that if you specify the cxx_genrule as a command-line target to buck build, you must include a platform flavor. . I think this is in the documentation:\nNote that if you specify the cxx_genrule as a command-line target to buck build, you must include a platform flavor. . Generating VS projects directly from buck project is not supported. But you can use buck query to generate CMake files and then to visual studio projects. If you want, you can also consider contributing to make buck project support VS proj generation.. @carljparker . There isn't a plan to upgrade to Python3. However, if you'd like to contribute and keep it compatible with both Python 2 and 3, please feel free to submit a PR. Thanks.. @jtorkkola . There isn't a plan to upgrade to Python3. However, if you'd like to contribute and keep it compatible with both Python 2 and 3, feel free to submit a PR.. Thanks. Feel free to submit a PR. I am not familiar with Swift Package Manager but from the documentation it sounds more like an artifact repository manager for cross-package dependency management, while Buck is suitable for mono-repo development.. cc @jtorkkola  . \n",
    "kohidave": "Thanks @timmych !!!!!. Thanks @timmych !!!!!. ",
    "LLITCHEV": "It looks like @styurin 's comment addresses the issue. Please, reopen if this is still existing issue.. Thanks for the report! I tried to repro it and I could not. Relatively recently we have made changes to our linker flags and I see (in the code) that the --no-as-needed flag is passed with the \"-Wl,\" prefix. Could you please the code from get master and try with that? Or if you give me the version of Buck (buck --version) I can go back to that version and try to reproduce the problem. Thanks again!. Hi, sorry for the hustle...\nOur internal linter is still giving warning - we use buildifier internally...\nHere is the exact warning for file test/com/facebook/buck/features/go/testdata/go_test/testOutput/\nBUCK.fixture\ngo_test(\n    name='all_tests',\n    srcs=glob(['_test.go']),\n    resources=[\"file.jpg\"]\n)\nphabricatorlintersuggested changes to lines 1-5\nBUCK files should be formatted using buildifier.\nSee https://fburl.com/auto-format-build-files for details.\nLint code: BUILDIFIERFORMAT\nLint name: buildifier formatting violation\n go_test(\n-    name='all_tests',\n-    srcs=glob(['_test.go']),\n-    resources=[\"file.jpg\"]\n+    name = \"all_tests\",\n+    srcs = glob([\"*_test.go\"]),\n+    resources = [\"file.jpg\"],\n ). The test that this PR adds is not passing on Windows. In order to make it pass you could add the assumeTrue(Platform.detect() != Platform.WINDOWS); line at the beginning of the test.. Could you indent these lines with 4 spaces. Our formatter complains and will prevent checkin in our internal repo.. ",
    "gengjiawen": "Nope, Look my pr for this issue, I only enable this for 64bit cpu.. Let's put it in another way. If without buck, we build native module using Android.mk and Application.mk or cmake and gradle to get arm64 support, do I have to set app_modules to android-21 ?\nNope.\nThe reason arm64 need android-21 to build is because with 21 we have arm64 support. You can't just drop armeabi-v7a support on device before android-21 just because you need arm64 support.\nAn example you can see is fresco. It supports Android 2.3 (Gingerbread) and later with arm64 support.. It can be a solution. A fix to this is all I needed.. It can be a solution. A fix to this is all I needed.. @styurin Any action on this issue ?. Have you have looked the discussion in this issue ? I think the configuration is correct. It's buck which handle the build wrong.. > If this configuration is not flexible enough you can add additional options, for example, platform level by ABI\nCan you be more specific, in this way can I still have one aar with multi abi in it.. @styurin Please see this issue page https://github.com/facebook/buck/issues/1836 for detailed discussion, it's not a user config bug. It's a bug in buck.. ",
    "ryanrhee": "~~cc @mzlee do y'all not see this often in fbsource?~~\nnvm you don't work on buck much these days. ",
    "Ziv-Barber": "bin\\buck build --show-output buck\nPARSING BUCK FILES: FINISHED IN 0.1s\nCREATING ACTION GRAPH: FINISHED IN 0.0s\nBuild failed: No system compiler found. Did you install the JRE instead of the JDK?\n    When running .\n    When building rule //src/com/facebook/buck/apple/xcode:xcode.\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES\nBUILDING: FINISHED IN 0.5s 468/1107 JOBS, 4 UPDATED, 0.4% CACHE MISS\nBUILD FAILED\nWindows 8.1\nJDK 1.8 172 64 bit\njava -version\njava version \"1.8.0_172\"\nJava(TM) SE Runtime Environment (build 1.8.0_172-b11)\nJava HotSpot(TM) 64-Bit Server VM (build 25.172-b11, mixed mode)\nThe JDK version of java.exe is the first in my path setting (to the same version above).. ",
    "sergd2005": "Thank you for answer!\nThat would be super cool feature buck audit rule  command to do this automatically.\nMeanwhile - can I assume @Nullable are optional arguments ?  \nHowever in doc it says:\nentitlements_file (required)\nAn optional name of a plist file to be embedded in the binary. Some platforms likeiphonesimulator require this to run properly\nname (required)\nThe name of the rule.\n. I see. Well - then bottom line I ll be asking stupid questions here )) Would be cool to have updated docs... but I know it could be tricky to do. \nThx for help! . ",
    "bobyangyf": "Thanks. We'll import it now.. @romanoid I forgot if we fixed/addressed this.\nBut it should be fine if we assume top level classes \"could\" be a test.\nWe still have to verify that they are actual test-classes by ensuring they have @Test tags for Java. Hi @HsuanTingLu,\nIs this a custom target that you are running tests on?\nDo you have a repro test that you can possibly send to us?. Do you have buck-out in your .gitignore? the git plugin shouldn't be looking into ignored dirs.\nWe'll be pushing out buck workspace soon and that should resolve this fully.. For what use cases do you want only certain targets to be rebuilt?. Can we delete these comments about different sorting orders since all we have is lexicographic sorting now. Are you trying to strip the file extension here?\nPerhaps we can use https://google.github.io/guava/releases/19.0/api/docs/com/google/common/io/Files.html#getNameWithoutExtension(java.lang.String). Is there some unit tests we can possibly add for this?. Please use import org.junit.Test;. Please make sure this builds with buck\nhttps://travis-ci.org/facebook/buck/jobs/370932370#L4067\nyou need to add \"//third-party/java/easymock:easymock\"to the deps of the BUCK file for this test.. seems like you are still failing the checks.\nThis needs a license. Just copy it over from some other file :). Sorry for the back and forth. the windows builds https://ci.appveyor.com/project/Facebook/buck/build/6783 are kinda broken by itself and I missed the error here.\nOn windows paths are \"\\\" as opposed to \"/\".\nSince this is for Visual C++, which is windows, you should probably make everything \"\\\" and use Junit Assume(Platform.detect == Platform.WINDOWS), with com.facebook.buck.util.environment.Platform so that the test only runs on windows.\nMake sure to include the corresponding target in the BUCK file.. The tests currently fail on windows (the appveyor tests) because currently, the test asserts path to be with forward slashes, but on windows will have back slashes. Since we only need this to run on windows properly, we should make the tests assert for backslashes and skip the test for all other platforms.. 2018. no need to add extra line. I don't think we need to make this null. Leave it as is before. Internally, the NdkIntegration tests are failing due to this import being missing.\nAre you expecting some specific installation of android?. It looks like only ndk20+ has this header file.\nhttps://android.googlesource.com/platform/development/+/73a5a3b/ndk/platforms\nWe can change it so that\n`#ifdef ANDROID_NDK\ninclude \nendif`\nHowever, this breaks your tests at the places that I am highlighting on your code review.. This fails. This fails.. nit: Use one of these?\nhttps://google.github.io/guava/releases/21.0/api/docs/com/google/common/base/Throwables.html#throwIfInstanceOf-java.lang.Throwable-java.lang.Class-. would it not make sense to change line 399 then??\nWe can check whether the failure is actually an assumptionViolationException, or else record as a failure.. whats with this character?. lets make this atleast a named constant. private?. Let's move all the instance of checks into a separate method so it looks nicer and we only need to call getDescription() once. don't need this. Just refer to entry.getName() in both places. ",
    "zach-klippenstein": "This issue seems to also prevent the use of certain Kotlin reflection APIs (e.g. isSealed). The reflection library defines a couple service loaders that are accessed lazily, and they're missing from Buck builds. I'm observing this on an older version of kotlin (1.2.61), but newer versions define the same service loaders so I expect the issue affects them as well.. This issue seems to also prevent the use of certain Kotlin reflection APIs (e.g. isSealed). The reflection library defines a couple service loaders that are accessed lazily, and they're missing from Buck builds. I'm observing this on an older version of kotlin (1.2.61), but newer versions define the same service loaders so I expect the issue affects them as well.. ",
    "wjmelements": "I want it to output a warning that contains the path of the bad link but skip it and move on.. The link was reached because of a recursive glob (ex. src/**/*.m) path specified in the BUCK.. Even you think it should fail, at least stop it from crashing.\nOn Tue, Jun 26, 2018 at 7:44 AM Sergey Balabanov notifications@github.com\nwrote:\n\nI believe Buck does not want to ignore anything that matches as it may be\na source of non-determinism. Please delete broken link.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1924#issuecomment-400403160, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAwzVV_rRTi4wlG2X5BrrAH7qFHTavmHks5uAnMOgaJpZM4Uo4Re\n.\n. \n",
    "ghvg1313": "I think this is resolved by https://github.com/facebook/buck/commit/19999963e4b635fabcd0615318abf13d41f5c669#diff-6d7c1429a28d3416822c55287d317a40. I think this is resolved by https://github.com/facebook/buck/commit/19999963e4b635fabcd0615318abf13d41f5c669#diff-6d7c1429a28d3416822c55287d317a40. This might be fixed by https://github.com/facebook/buck/pull/2055. This might be fixed by https://github.com/facebook/buck/pull/2055. @ttsugriy Thanks for the quick response, it is fixed now. We might need more investigation on this one, found some side effect and potential regression under certain conditions. We might need more investigation on this one, found some side effect and potential regression under certain conditions. >Are these all prebuilt frameworks? In that case they will be embedded in the first containing bundle (ie App).\n@yiding Does that make sense? Only bundle container would package the framework, in your example, only app would package Framework3 instead of Framework 1 and 2 (it does overwrite framework3 twice, but only one copy would stay inside bundle, assuming everything is dylib) . > Someone on the buck team should probably import this and test to make sure it doesn't break for our internal apps which relies on this property.\n@yiding Should I reach out to the team on Slack? I actually don't know who's the contact person now . @styurin Do you mind give it a review and import this if everything checks out?. @styurin just checked the test, however I don't think this change would cause that travis test failure, could it be some master change today that failed the test? \nAlso included #2016 here since it's solving an issue related to this PR. @styurin My bad, it was using the wrong arch to test, fixed now. @styurin How's the progress on importing this? Is there any issue that I can help on?. @styurin Fixed the local provisioning file assumption. @williamtwilson ping. @hutley Thanks for the feedback! There're actually two goals of this PR, setting defaults and merge configs (the first one is more or less depending on the second)\nFor the defaults, my aim is to eliminate differences with Xcode, which has different defaults for debug and other configs. While DEAD_CODE_STRIPPING might be a little bit too much, the other two have different settings for Xcode than default buck-generated project. Doing this might prevent new buck users/developers having wrong flags' expectations, also lowers on-boarding cost for new buck users and encourage them use it IMO.\nAs for merging defaults, I'm quite surprised that setting custom config would wipe out some very basic c flags (current c++ defaults in project generator), maybe I'm wrong but I'm quite certain this is not the original intention.\nI'm happy to keep this open, let me know how do you guys think. @hutley sorry for the confusion, GCC_SYMBOLS_PRIVATE_EXTERN should works the same as ENABLE_TESTABILITY, only ENABLE_TESTABILITY has higher precedence over GCC_SYMBOLS_PRIVATE_EXTERN, the later is more lower-level control IMO. Enable this setting in debug avoid the issue test host can't access source code sometimes.\nAs for merging config, if no Debug is predefined, buck has no knowledge of which config is used for debug and might produce the wrong settings, since all the options here are only for debug.\nI'll amend the test for other configs if we are all onboard with this.. @williamtwilson ping. good catch. It's fixed now. Oops, fixed now. It's used by the tests, since this class is part of the test, I don't think it should be using annotation. ",
    "mikeandmore": "Confirm. I think you can do a \nsed -i '.bak' 's/\\$(SRCROOT)\\///g' buck-out/gen/*.xcconfig\nto workaround this.. I have similar issues, but I think once you have watchman installed, buck will reuse the JVM process. So it should not invoke a new JVM.\nI suspect it's PEX is slow to boot.. I just did a no-op build with no source modified at all. It takes buck 1.1 seconds to exit.\n```\n[nix-shell:~/workspace/dolly]$ time ./buck.pex build db_release                                                                                                                                            \nBuilding: finished in 0.3 sec (100%) 3/3 jobs, 0 updated\n  Total time: 0.3 sec\nreal    0m1.145s\nuser    0m0.499s\nsys     0m0.661s\n```\nIn contrast, if I call nailgun directly, it takes 0.6 seconds.\n```\n[nix-shell:~/workspace/dolly]$ time NAILGUN_SERVER=local:.buckd/sock ng com.facebook.buck.cli.Main build db_release                                                                                        \nBuilding: finished in 0.4 sec (100%) 3/3 jobs, 0 updated\n  Total time: 0.4 sec\nreal    0m0.634s\nuser    0m0.001s\nsys     0m0.006s\n``. I just realized that it might be JVM's internal threads. So I-XX:ParallelGCThreads=4 -XX:ConcGCThreads=4` and now there are only 83 threads for buck.\nMaybe add this into the tuning guide?. ",
    "ildarsharafutdinov": "@ttsugriy ,\nThank you.\nHowever, it results in:\n//:Texture#iphoneos-arm64,iphonesimulator-x86_64: Fat binaries can only be generated from binaries compiled for the same SDK.\nWhich makes me think the only way to go is to build separately for iphoneos-arm64, iphonesimulator-x86_64 and then lipo results into a single fat binary.. thank you.. ",
    "burakcoskun": "ok didn't know of -buildifier_disable=label this option . ",
    "nroberson": "Ah, you're right. Python 3 is default on my path. I'll give it another go.\nSorry for the noise.\nOn Thu, Aug 2, 2018, 18:28 Taras Tsugrii notifications@github.com wrote:\n\nthis is most likely because you're probably not using the version 2.7 of\nPython as mentioned in https://buckbuild.com/setup/getting_started.html\nYou can probably get away with using a different version if you enable\n[Skylark parser] instead of Python DSL.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/facebook/buck/issues/1989#issuecomment-410087700, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABMXKDBqYZNm2bLqEqmBT02iGQVS2JRnks5uM30igaJpZM4VtGG2\n.\n. \n",
    "andriantosg": "Do you have any solution for the issue?. ",
    "tayloryork": "I see the same error - but @timmych note your suggestion is for 'build' not run.\nbuck version 2018.08.27.01\nC:\\source\\OTHER\\bucksamples\\hello-buck-java>buck build --show-output hello_buck_java\nNot using buckd because watchman isn't installed.\nPARSING BUCK FILES... 0.0s (100%)\nCREATING ACTION GRAPH: FINISHED IN 0.3s\n//com/facebook/buck/demo:hello-buck-java buck-out\\gen\\com\\facebook\\buck\\demo\\hello-buck-java.jar\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES, 0.0% CACHE MISS\nBUILDING: FINISHED IN 2.2s (100%) 1/1 JOBS, 0 UPDATED\nBUILD SUCCEEDED\nC:\\source\\OTHER\\bucksamples\\hello-buck-java>buck run hello_buck_java\nNot using buckd because watchman isn't installed.\nPARSING BUCK FILES... 0.0s (100%)\nCREATING ACTION GRAPH: FINISHED IN 0.2s\nDOWNLOADED 0 ARTIFACTS, 0.00 BYTES, 0.0% CACHE MISS\nBUILDING: FINISHED IN 2.2s (100%) 1/1 JOBS, 0 UPDATED\nBUILD SUCCEEDED\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\chocolatey\\lib\\buck\\tools\\buck.pex\\.bootstrap\\_pex\\pex.py\", line 328, in execute\n  File \"C:\\ProgramData\\chocolatey\\lib\\buck\\tools\\buck.pex\\.bootstrap\\_pex\\pex.py\", line 261, in _wrap_coverage\n  File \"C:\\ProgramData\\chocolatey\\lib\\buck\\tools\\buck.pex\\.bootstrap\\_pex\\pex.py\", line 293, in _wrap_profiling\n  File \"C:\\ProgramData\\chocolatey\\lib\\buck\\tools\\buck.pex\\.bootstrap\\_pex\\pex.py\", line 371, in _execute\n  File \"C:\\ProgramData\\chocolatey\\lib\\buck\\tools\\buck.pex\\.bootstrap\\_pex\\pex.py\", line 429, in execute_entry\n  File \"C:\\ProgramData\\chocolatey\\lib\\buck\\tools\\buck.pex\\.bootstrap\\_pex\\pex.py\", line 434, in execute_module\n  File \"C:\\Python27\\lib\\runpy.py\", line 192, in run_module\n    fname, loader, pkg_name)\n  File \"C:\\Python27\\lib\\runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"C:\\ProgramData\\chocolatey\\lib\\buck\\tools\\buck.pex\\programs\\buck.py\", line 261, in <module>\n  File \"C:\\ProgramData\\chocolatey\\lib\\buck\\tools\\buck.pex\\programs\\buck_tool.py\", line 116, in execve\n  File \"C:\\Python27\\lib\\subprocess.py\", line 394, in __init__\n    errread, errwrite)\n  File \"C:\\Python27\\lib\\subprocess.py\", line 644, in _execute_child\n    startupinfo)\nWindowsError: [Error 2] The system cannot find the file specified\nA little digging - the line in question from buck_tool.py:\nchild = subprocess.Popen(\n                self._argv, executable=self._path, env=self._envp, cwd=self._cwd\n            ). I found a fix, but i'm no python expert, so I don't know if it's acceptable.\nI logged everything on that line.  For brevity, I simplified by environment variables and only used a shorter simplified PATH to my jdk.  It stills fails in the same way.\nsubprocess.Popen(\n['java', '-jar', 'C:\\\\source\\\\OTHER\\\\bucksamples\\\\hello-buck-java\\\\buck-out\\\\gen\\\\com\\\\facebook\\\\buck\\\\demo\\\\hello-buck-java.jar'],\nexecutable=java,\nenv={'PATH': 'C:\\\\PROGRA~1\\\\Java\\\\jdk1.8.0_144\\\\bin'},\ncwd=C:\\source\\OTHER\\bucksamples\\hello-buck-java\n)\nI found it odd that the 'arguments' lists 'java', and so does the executable.\nSo i took out the exectuable, so the new code is:\nchild = subprocess.Popen(\nself._argv, env=self._envp, cwd=self._cwd\n)\nAnd voila, I see:\nHello Buck. @HarikaReddyRamidi Can you pull and see if that fixed your problem?. The cpp sample fail to run for a different problem. It looks like it needs some \"lib\" but I have no idea what lib.\nC:\\source\\OTHER\\bucksamples\\hello-buck-cxx>C:\\source\\OTHER\\buck\\bin\\buck run :main\nNot using buckd because watchman isn't installed.\nParsing buck files: finished in 0.6 sec (100%)\nBuilding: finished in 1.1 sec\n  Total time: 2.2 sec\nFile not found: lib\n    When amending path.\n    When amending tool.. ",
    "lemtronix": "What I'm attempting to do is cross-compile on Windows to an MCU (embedded ARM Cortex-M0+) using the IAR compiler.\nAs I dig through the source code, the issue goes beyond simply not having certain flags passed in for the compile step, the link step is also incorrect as well as the information that is entered into the argvar files (i.e. ppandcompile.argsfile and linker.argsfile).\nTo close the loop on this issue, BUCK currently does not currently support other compilers.  It appears that only Visual Studio, GCC, and Xcode are supported at this time.. ",
    "zmanji": "I think to fix this we should just upgrade our asm dependency from 6.0 to 6.2.1 (latest).. Yes, I think the dependencies here are outdated.. ",
    "jtorkkola": "I'm currently working on upgrading ASM to 6.2.1. Unfortunately, there are some breaking behavioral changes, so it isn't totally trivial.. @kageiit Can you prune the jars before passing them into ApkBuilder, i.e. do essentially what SignedJarBuilder::writeZip does? I understand there'd be a performance hit with that approach, but we'd really like to remove as much of our AOSP fork as possible.. @kageiit I might have been unclear. I was suggesting that you create pruned copies of any jars that you feed into ApkBuilder in ApkBuilderStep. This should be equivalent to what you're trying to do in the PR, though with a performance hit.. We're actively working on migrating to Java 11 by EOY. There are various issues to solve.. @brettwooldridge Sorry for the delayed response (was on Thanksgiving holiday). I'd love to get some help.\nThe status is that buck can be built against Java 10 with ant (point JAVA_HOME at a Java 10 installation, and run ant clean default), and that produced build of Buck can be used to build non-Java code pretty well (you just need to pass the --java10-test-mode flag to buck). We started with Java 10, as Java 11 wasn't available when we started, and we generally expected the move from Java 10 to Java 11 to be relatively easy. With building Java code, there are primarily issues with in-proc compilation (custom compiler JARs and ABI generation). I'm concentrating on this. There are also miscellaneous minor issues.\nAs for Java 11, there is currently a mysterious annotation processor issue when building Buck. If you point JAVA_HOME at Java 11 and run ant clean default, you'll see lots of missing symbol issues for classes we expect to be generated by Immutables. I looked into this a bit, and it looks like sometimes Immutables sources do get generated, but they don't get picked up by the compiler for some reason, and sometimes they just don't get generated (tried with both ECJ and javac; the behavior varies a bit). It's possible ECJ doesn't properly support Java 11 annotation processing yet for one thing. I could definitely use someone's help to investigate further.. @brettwooldridge That's great. Thanks for looking into this!. @kageiit Both source ABI and source-only ABI are the problem areas, yes.. @brettwooldridge Upgrading to ECJ 4.10 fixed the Immutables issue. Thanks for your help!\nAfter submitting a few other fixes, Buck now builds on Java 11, and can be run with the --java11-test-mode flag. Please note that this mode is experimental and unsupported, and you need to run buck clean before and after using it. But if you try it out, please do report any issues.\nIn-process Java compilation and source ABI generation are in much better shape now, but I expect to find a few more issues with additional testing.. @brettwooldridge Upgrading to ECJ 4.10 fixed the Immutables issue. Thanks for your help!\nAfter submitting a few other fixes, Buck now builds on Java 11, and can be run with the --java11-test-mode flag. Please note that this mode is experimental and unsupported, and you need to run buck clean before and after using it. But if you try it out, please do report any issues.\nIn-process Java compilation and source ABI generation are in much better shape now, but I expect to find a few more issues with additional testing.. --java11-test-mode has been removed and no longer needs to be specified when running Java 11 builds of Buck.. This is expected. .buckjavaargs is meant for Java runtime args that apply to Buck itself, not to compilation for Java targets that Buck produces. You should be using extra_arguments on java_library for the latter. I'm also unclear on why you're using -Xbootclasspath/p. Is there some reason you can't depend on a prebuilt_jar target?. I'll take a look within the next day or so.. I'll take a look within the next day or so.. Sorry for the delay. I'll try to take a look on Monday when I return from vacation.. @thalescm can you please rebase to latest master? Then we should be able to get this in. I'll fix the linter stuff after importing.. --java11-test-mode is not a supported config option. It exists only to allow users to try the experimental Java 11 support. So we probably won't be adding any mode change detection. You need to buck clean before using it. Will make this clear in my original comment. Thanks for trying it out!. > @jtorkkola Can I still file issues related to the experimental Java\u00a011 support?\nYes, absolutely. That would be very much appreciated! Just edited my comment to include that as well.. > @jtorkkola Can I still file issues related to the experimental Java\u00a011 support?\nYes, absolutely. That would be very much appreciated! Just edited my comment to include that as well.. Compiling buck with Java 10 is not and will not be supported. You can try Java 11, which will be fully supported soon.. The javadoc for com.sun.source.util.Plugin says:\n\nPlug-ins are located via a ServiceLoader, using the same class path as annotation processors (i.e. StandardLocation#ANNOTATION_PROCESSOR_PATH ANNOTATION_PROCESSOR_PATH or -processorpath).\n\nSo why are we using classpath instead of processorpath?. Why do we need to set an empty classpath in this case?. Remove.. Echoing my other comment: why do we need to set an empty classpath at all?. This needs to use File.pathSeparator. The current code causes test failures on Windows.. Shouldn't this use \":\" rather than File.pathSeparator?. Nit: I think these constants just make the code harder to read, and constants aren't used for any of the other options in this class.. What are these .js file changes?. So we're calling the rule java_plugin, though we refer to it in code as JavacPlugin. The fields on this rule also don't match Bazel's java_plugin, which looks to be for annotation processors only. @styurin, do you have a preference on the rule name (or API more generally) here?. My question was not about whether or not we should separate java_plugin and java_annotation_processor (we should), but rather whether or not java_plugin is a good name, vs. for example javac_plugin. I don't have a strong opinion here. java_plugin is probably fine, but has the downside of not being what a Bazel user might expect it to be.. So why do we need a behavior change in GroovycStep along with this change? Was this an existing bug? If so, this should probably be done separately.. But what is java_annotation_processor_plugin (vs. java_annotation_processor/java_plugin)?. Should be java_plugin in both places.. The import causes test failures in our CI. Comparing against ':'-delimited strings doesn't work on Windows. You need to incorporate File.pathSeparator.. This is a slight breaking change for people relying on buck query to find annotation processors. I'd prefer if we didn't rename the build rule class.. Nit: Combine string constants to \"Xplugin:\".. How about an integration test that leverages both a javac plugin and an annotation processor?. java_plugin is ok by me.. Do subclasses instead of an enum make less sense?. Please run GJF over all Java files, including test cases and test data files.. BUCK files need to be formatted with Buildifier. deps should come last here. Same issue in multiple places.. This is failing on Windows both in our internal CI and in AppVeyor.. We run a Buildifier linter internally with every code review, which also covers BUCK files inside buck srcs. Looks like we've either switched this on after the fact, or have been ignoring it lately (I don't have any historical knowledge on this). Will check with the team on whether we want to add this to the contributing doc.\n@styurin for the pre-commit hook question.. The following files still aren't GJF formatted:\nsrc/com/facebook/buck/jvm/java/JavaPluginDescription.java\nsrc/com/facebook/buck/jvm/java/JavacPluginArgs.java\nsrc/com/facebook/buck/jvm/java/StandardJavacPlugin.java\ntest/com/facebook/buck/jvm/java/JavaAnnotationProcessorBuilder.java\ntest/com/facebook/buck/jvm/java/JavaPluginDescriptionTest.java\ntest/com/facebook/buck/jvm/java/testdata/javac_plugin/Main.java\ntest/com/facebook/buck/jvm/java/testdata/javac_plugin/Util.java\ntest/com/facebook/buck/jvm/java/testdata/javac_plugin_crashes/Main.java\ntest/com/facebook/buck/jvm/java/testdata/javac_plugin_crashes/Util.java\ntest/com/facebook/buck/jvm/java/testdata/mixed_javac_plugin_annotation_processors/Main.java. ",
    "Exide": "Cool, thanks!\nI will keep an eye on the Chocolatey gallery for an updated version of Buck and try again.. What kind of time frame should I expect to see this new release on Chocolatey? I looked at the dates on the previous versions and it appears they went up within 24 hours after release (with the first being an exception).\nThis is the link I've been checking: https://chocolatey.org/packages/buck. ",
    "kkaefer": "I can try that, but removing the line ending-related directives from the config makes the gen-buck-info step function as intended.. (fwiw, I'm using the stock python that ships with macOS 10.12). ",
    "mmdango": "cc @thalescm @cwoodwar6 . @kageiit done! btw, what's the landing process look like for buck?. @sbalabanov I believe I fixed the soy tests, but looks like there are unrelated tests that are failing in AppVeyor. I'm also a bit confused what the error message for the Travis CI is: https://travis-ci.org/facebook/buck/jobs/439005432#L7325 it just seems like the script always throws 1.... @thalescm done. oof, good catch. yeah, i meant it for the kapt_apoptions param. thanks!. ",
    "williamtwilson": "@ghvg1313, could you rebase this and fix the test? Otherwise looks good to me \ud83d\udc4d. @hutley had concerns about this. Could you enumerate those concerns, @hutley?. @hutley had concerns about this. Could you enumerate those concerns, @hutley?. ",
    "hutley": "@ghvg1313  thanks for the pull request. As @williamtwilson mentioned I do have some concerns.  BUCK generally doesn't set default options but it does allow for an individual target to do so pretty easily and seems pretty flexible already. I am not sure that we should prescribe any set of default options since they can be set in the BUCK files pretty simply - for example using the \"configs\" param of https://github.com/facebook/buck/blob/master/src/com/facebook/buck/apple/AppleNativeTargetDescriptionArg.java#L31 - you can set something like configs = {\"Debug\": {'DEAD_CODE_STRIPPING': 'NO'}, \"Release\": {'DEAD_CODE_STRIPPING': 'YES'}}. If you wanted some code reuse across many targets, this can then be wrapped into a higher level macro where you pass your default config on the \"configs\" param to the native.cxx_library etc. . @ghvg1313  thanks for the pull request. As @williamtwilson mentioned I do have some concerns.  BUCK generally doesn't set default options but it does allow for an individual target to do so pretty easily and seems pretty flexible already. I am not sure that we should prescribe any set of default options since they can be set in the BUCK files pretty simply - for example using the \"configs\" param of https://github.com/facebook/buck/blob/master/src/com/facebook/buck/apple/AppleNativeTargetDescriptionArg.java#L31 - you can set something like configs = {\"Debug\": {'DEAD_CODE_STRIPPING': 'NO'}, \"Release\": {'DEAD_CODE_STRIPPING': 'YES'}}. If you wanted some code reuse across many targets, this can then be wrapped into a higher level macro where you pass your default config on the \"configs\" param to the native.cxx_library etc. . @ghvg1313  I just did a basic workspace with a new project via Xcode and of the three settings you mention only the ONLY_ACTIVE_ARCH has a value defined in the auto-generated config, the other two have the same default as you propose to set already. I am concerned about setting global defaults mainly because there was no merging previously so you are changing behavior for established users of BUCK. If you can put this behind a configuration option and just set the bare minimum of flags then that would minimize the changes to downstream users. Also, it would be good to have tests that exercise both with the config option and without. . @ghvg1313  I just did a basic workspace with a new project via Xcode and of the three settings you mention only the ONLY_ACTIVE_ARCH has a value defined in the auto-generated config, the other two have the same default as you propose to set already. I am concerned about setting global defaults mainly because there was no merging previously so you are changing behavior for established users of BUCK. If you can put this behind a configuration option and just set the bare minimum of flags then that would minimize the changes to downstream users. Also, it would be good to have tests that exercise both with the config option and without. . ",
    "thedavidharris": "Is there any workaround for this? Getting the usual Library not loaded: @rpath/MyFramework.framework/MyFramework errors.. @styurin is it possible to add @ford.com as well? We're starting to use/exploring Buck a bit. ",
    "ejdhzopu": "Done! There were not unit tests for this method: it was tested indirectly by a couple of other tests. Added a separate unit test class.. Added license and fixed format to fix build failures.. Makes sense. Done.. ",
    "naveenOnarayanan": "\nIt looks fine, but I'm just curios, is that something that blocks you in some way?\n\nHey Tyurin, unfortunately we utilized the uppercase approach in our internal plugins when interacting with BUCK and have been passing in INTELLIJ whenever we run buck project. Due to the fact that plugin rollouts are slow, we needed to have backwards compatibility support.\nSince this fix is not that large and retains the same functionality we decided to put this upstream instead of making this change in our internal fork.. Reformatted the code using google-java-format 1.6. Resolved with latest changes. ",
    "demon-xxi": "@kageiit, I'd like to get your input on this PR. I've already tested this on building all the FB android apps and it seems to be have as expected on release and debug builds with predex. We do have less java 8 modules in use though. Maybe you can verify this against your codebase?. I tested this both with current d8.jar as well as building master (with computeReferencedResources patch only). We may not have as much interface methods used for now but all the java 8 code from libraries that we pulled in recently does work well. \nI see that minSdk is needed for Type Annotations and some new Java 8 Language API. Yeah those we are not using. I don't think that is in the scope of this PR. This one is targeted only on the code that can be realistically desugared to java 7 with a practical min sdk of 16. I may need to adjust description. \nI'm not even sure how we can uniformly add min sdk attribute to java_library element since it is used for regular java as well. Maybe let's address it separately later. Seem like a bigger change and less likely be used in a real world. \nAre you relying on or planning to use any of this SDK 24+ stuff from java8?. So am going to add to this PR: \n\n[x] Changing the fork of d8 in buck to stop turning off interface and method desugaring by default\n[x] Use abi for the deps tree\n[ ] Add unit tests to verify above logic applied\n[x] Update Summary to reflect that this PR is targeted to non sdk 24+ exclusive j8 features \n[x] Add .buckconfig option to enable/disable static and interface method desugaring \n[x] Make classpath available for D8 runs if no preDex is enabled (release builds)\n\nSounds reasonable? . Agree. Same intentions here. I like an option with .buckconfig. I had previous attempt with per module setting here internally but that makes stuff over complicated end error prone as deps may have different settings as well as desuagring making no sense in scope of non android java_library. I think for safety to roll out and allowing OSS users to test this out .buckconfig would suffice.\nbtw, is tha AppVeyor check expected to fail? Seems like fails on some code unrelated to my changes.. > > btw, is tha AppVeyor check expected to fail? Seems like fails on some code unrelated to my changes.\n\nYeah, TravisCI should test your changes.\n\nTravisCI also failed flaky. Is there a keyword to restart checks scripts?. > > btw, is tha AppVeyor check expected to fail? Seems like fails on some code unrelated to my changes.\n\nYeah, TravisCI should test your changes.\n\nTravisCI also failed flaky. Is there a keyword to restart checks scripts?. @kageiit, I've done all the changes except of tests. Will be working on those as well as estimating perf impact of the 3rd commit here (non predexed scenario). \nWould be cool if you can look through the changes and maybe try this PR on your builds. \nI was also thinking if it makes more sense to move isInterfaceMethodsDesugarEnabled to the AndroidPlatformTarget class. That would simplify code changes as AndroidPlatformTarget is available in all call sites without extra params and also it is a global setting for most build scenarios. . I'ver used the same old 17cf75eec2e19d10749462b69480a54762dbe614 revision for d8.jar to be safe. We can maybe look into upgrading it later.. Maybe you have some jars or aar files that were already desugared? They may include the extra classes for lambda or other libraries which then cause conflicts because d8 does not know they are of the same version.. Looks like your error is a bit different case because it complains about android.support.v4 classes. Is it possible that you are including multiple copies of support library? DxStep uses set function so the jar paths should be unique. . Don't forget to include java.desugar_interface_methods=true. Just double checking.. Awesome! I'll add some test and import this PR to run compete test suite here as well. Thank you for extended testing. @kageiit sorry for delay. got 5 more internal revisions to accept it. Mostly perf tweaks around using java streams in buck codebase. Should be landing this week.. Merged this in with extra fixes and unit tests. Please give it a try. It is opt in currently using java.desugar_interface_methods=true.. Is it necessary for this PR? We can probably do that in a separate PR. Moreover I've live to experiment with dex merge using pure D8 and allow it producing primary and secondary dex files as it designed. Not using current split mechanism. Again that's a separate change.. May be but I have no examples to back this up with. I saw both examples of aar files as java 8 classes and already predexed. My guess is that it won't hurt to dex them one more time in case they are pure java 8 compiled but again I a have no test for that or real use case.. Does this.additionalJarsForProguard ever get assigned or we don't use it at all?. ",
    "christolliday": "Can you rebase and make this build? There's a method missing.. ",
    "marlonandrade": "Done :metal: thank you :) . ",
    "mikeb01": "Any idea when a version with this fix will be released?. Any idea when a version with this fix will be released?. We're facing a similar issue using Buck from within pyrun.  The hacky fix works in this case, but the more complete fix doesn't.  Pyrun do some slightly strange things to the module path (e.g. it looks like '/encodings/init.py').. We're facing a similar issue using Buck from within pyrun.  The hacky fix works in this case, but the more complete fix doesn't.  Pyrun do some slightly strange things to the module path (e.g. it looks like '/encodings/init.py').. Not using this configure any more.. The most common case is debugging a custom rule within the context of a larger project. It allows rebuilding of one specific target without the need to modify the code for that module.. The most common case is debugging a custom rule within the context of a larger project. It allows rebuilding of one specific target without the need to modify the code for that module.. ",
    "alexjlockwood": "FYI, this change breaks resource merging for us: https://github.com/facebook/buck/issues/2196. +1 I am seeing the same issue. @artem-zinnatullin . ",
    "Blisse": "Hey @alexfdz, it turns out this issue was slightly different for us, in that upon upgrading to use ManifestMerger2, it turns out our manifests are merged in the wrong order, so the tools:replace was never applied to the 2nd element.\nLibrary A -> Manifest A => android:enabled=false\nModule B -> Manifest B => android:enabled=true, tools:replace=android:enabled\nModule B depends on Library A\nPreviously, this would compile fine, and the final manifest would have enabled=true.\nAfter upgrading OkBuck, compilation failed with the errors I mentioned above, until I added:\nApp Module C -> Manifest C => android:enabled=true, tools:replace=android:enabled\nApp Module C depends on Module B\nand now we're able to compile. This is not a great solution but at least it unblocks our work. . ",
    "edsilfer": "@sbalabanov we found what you mean, at first we did not understand that the error log was being published inside LogRecord as one of its causes. We are now looping through LogRecord and it works as expected. Thanks for the support!. Hi guys, just some context on how we are leveraging this for our particular use case. Our goal is to parse logs that comes from Buck in order to:\n 1. gather analytics, e.g. how long does a rule takes to build;\n 2. parse error messages in something actionable from developer's point of view.\nWe currently specify a custom java Handler in .bucklogging.properties. This handler is added, afaik, to Buck's root logger, then we can listen to anything that Buck publishes. In order for Buck to find our custom logger, I believe that we add our jar to bootclasspath by adding it in .buckjavaargs.   . ",
    "groob": "@ttsugriy how would I go about joining the Buck slack?\nedit: FWIW I work at Kolide (github.com/kolide) and contribute to osquery. The osquery project is now adopting Buck which is the reason for looking into Buck for our own projects that mostly center around osquery. If osquery adopts buck it might be nice to whitelist the @kolide.co domain. . Does this issue count, or should I open a separate one?. ",
    "Itaybre": "Compiled from HEAD and it worked, seems to be a problem with the version from Homebrew. ",
    "chrisczupak": "Thanks for posting this. I ran in to this same issue as well. It took me a while to come across this thread, but re-installing Buck from HEAD worked for me also.. ",
    "marpaia": "Thanks!. ",
    "dulmandakh": "I'll create another PR with cleaner history and enhancements. I accidentally deleted this branch, sorry.\n. I think that there is a bug that is failing unit tests.. getting error like this in NDK tests, please help\njava\n[2018-12-10 16:21:33.461][warn ][tid:1091][com.facebook.buck.event.listener.LoggingBuildListener] Error: Can't read [/usr/local/android-sdk-25.2.3/platforms/android-26/android.jar] (Can't process class [org/apache/http/params/HttpConnectionParams.class] (Unsupported class version number [52.0] (maximum 51.0, Java 1.7))). Once landed Circle CI setup will be much simpler.. ",
    "carljparker": "Hi Peter, thanks for calling this out. I am working on a rewrite of the Build Target topic today and will address this issue. I will publish that sometime tomorrow (Friday).. The updates to Build Target did not make it into today's doc push . . . :-P\nThey will be up on the public site on Monday. . ",
    "thelvis4": "\n@williamtwilson has imported this pull request. If you are a Facebook employee, you can view this diff on Phabricator.\n\n@williamtwilson ^Does this mean that the change is going to be merged soon? \ud83d\ude43\nPlease let me know if the PR needs any modifications. Thanks!. ",
    "theopolis": "Sorry for the noise, fixed by reading #2044.. ",
    "CeciliaGuo47": "This bug is fixed in this PR https://github.com/facebook/buck/pull/2153. ",
    "dfed": "@rmaz since I'm doing the filtering work in UmbrellaHeader.java (which generates the umbrella header), rather than the code that calls into UmbrellaHeader, I can get away with only doing the work in one spot.\nHowever, your test is on point, and I've included it in this PR.. @rmaz since I'm doing the filtering work in UmbrellaHeader.java (which generates the umbrella header), rather than the code that calls into UmbrellaHeader, I can get away with only doing the work in one spot.\nHowever, your test is on point, and I've included it in this PR.. ",
    "rajyengi": "If there are errors uploading, the HttpArtifactCache will log errors on store.\nhttps://github.com/facebook/buck/blob/47953021e8359d4ae32d874f0513ddc4bb3c0894/src/com/facebook/buck/artifact_cache/HttpArtifactCache.java#L178\nI'm not sure why you're using a cache.mode dir on the local instance, and your local dev machine has cache.mode http. Which one are you using to upload artifacts? I'd expect it's the local dev machine, if you're seeing data going over to your http server on wireshark. I'd recommend adding some logging to your http server to verify if you're actually getting data in the store requests.. If there are errors uploading, the HttpArtifactCache will log errors on store.\nhttps://github.com/facebook/buck/blob/47953021e8359d4ae32d874f0513ddc4bb3c0894/src/com/facebook/buck/artifact_cache/HttpArtifactCache.java#L178\nI'm not sure why you're using a cache.mode dir on the local instance, and your local dev machine has cache.mode http. Which one are you using to upload artifacts? I'd expect it's the local dev machine, if you're seeing data going over to your http server on wireshark. I'd recommend adding some logging to your http server to verify if you're actually getting data in the store requests.. ",
    "qyang-nj": "We are observing the same thing. . ",
    "rneatherway": "Ah, you're right. I was using a newer version of google-java-format (1.7) than the CI (1.6). I've made this PR just the extra format argument and split out the dominated conditional to https://github.com/facebook/buck/pull/2179. Thanks for merging! If you're interested in spotting issues before they are introduced by PRs next time, you can turn on LGTM code review at https://lgtm.com/projects/g/facebook/buck/ci/. ",
    "thoughton": "Ah great, thanks! That'd explain it.\nIs there anywhere I can find which flags are required?. ",
    "fredemmott": "To actually fix things in practice, this might mean \"rewrite how buck-out/ works\" :'(. https://docs.microsoft.com/en-us/windows/desktop/fileio/naming-a-file#fully-qualified-vs-relative-paths documents a registry setting. Will see if that works this evening\nIt also documents enabling it per-app in the manifest which would be a better user-experience:\n<application xmlns=\"urn:schemas-microsoft-com:asm.v3\">\n    <windowsSettings xmlns:ws2=\"https://schemas.microsoft.com/SMI/2016/WindowsSettings\">\n        <ws2:longPathAware>true</ws2:longPathAware>\n    </windowsSettings>\n</application>. The per-app version might be best, assuming that msbuild and the microsoft compilers also opt-in in their manifests. ",
    "rhencke": "In this particular case, running with --dry-run would actually prevent the updated index from being written to index_file.name.  (--index-output prevents our modifications from being written back to the original index file)\n(I got to the same point on the man page... had to just poke at it a lot!  If it's worth some explanatory comments in the code, please feel free to request they be added)\n. ",
    "zecke": "\nOn 16 May 2016, at 13:02, Coneko notifications@github.com wrote:\n\n@@ -70,3 +70,18 @@ def _monotonic_time_nanos_cygwin():\n         k32.QueryPerformanceCounter(ctypes.byref(perf_counter))\n         return perf_counter.value * NSEC_PER_SEC / perf_frequency.value\n     monotonic_time_nanos = _monotonic_time_nanos_cygwin\n+elif platform.system() == 'FreeBSD':\n-    CLOCK_MONOTONIC = 4\n-    # On FreeBSD9 and FreeBSD10\n-    libc = ctypes.CDLL('libc.so.7', use_errno=True)\n\nSince this is the only difference between this case and the linux case, can you extract the common parts?\n\nOne is CLOCK_MONOTONIC, the other is CLOCK_MONOTONIC_RAW (they both happen to have the same integer value). I can update if you want to? Should I rename method names from _linux to _posix?\nholger\n. ",
    "JonShemitz": "Looks reasonable - fwiw, though, I went with this format because it's pretty much what the time command uses. I'm not against this change, but I do think there is some value to using what people are used to seeing.\n. ",
    "piotrwach": "I would like to be able to define module map myself, as we have a lot of Objective-C, Objective-C++, and C++ headers, and to define module correctly for library like that, we have to specify correct requires objc/cplusplus option for each header. This will not be possible with auto generated header.\n. We pass a flag to generate it, so yes: https://github.com/facebook/buck/pull/911/files#diff-6d7c1429a28d3416822c55287d317a40R190\n. ",
    "rjrjr": "Should mirror the @ServiceName @NonNull parameter annotations found in Context.java. Ideally would also add @Nullable to the return value, though Context.java neglects that.. Actually, the most important place to do that is on the interface.. ",
    "paveldudka": "we also pass this map to getStyleableResources() method where we retrieve actual RDotTxtEntry instance (which should contain proper \"parent\" information). Otherwise parent info will be lost here.\nChanging to Map makes sense - Ill make proper changes. yeah, our IntelliJ runs google-java-format automatically now, so should be good . ",
    "Bill": "That is indeed another way to say the same thing. I don't feel like it is obviously an improvement. If lots of people feel like @nemith though, I'm ok with that change.. ",
    "tinaroh": "Yes, thanks for the catch! This should be android_binary as an android_library cannot be packaged into a java_binary. Updated, along with a similar change for exported_deps.\n  . ",
    "yanex": "Strictly speaking, this doesn't look as a apClassPaths. I'd rename this to kaptPluginOptions or something similar.. I'd add a test with spaces and commas in the project directory name.\nThere might be issues with passing paths with spaces to the Kotlin compiler, so it may be good to encode kapt options as we do so in Kotlin Gradle plugin.\nThe encoded list is passed as a single configuration option.. While other options (\"light analysis\" or \"verbose\") are rather used for debugging kapt itself, \"correctErrorTypes\" is an option that users might want to enable, so providing a way to turn it on would be really nice. You can read more about correctErrorTypes here.. Maybe I'm just overlooking something, but why the comma (stubs,) is needed here \u2013 (and below)?. Also, there's a new option, mapDiagnosticLocations, available from Kotlin 1.2.30.\nBy default, diagnostics reported by Javac and annotation processors are linked to kapt stubs (.java files), and it might be harder to figure out the problem. With the mapDiagnosticLocations option enabled, the original location (inside a .kt file) is returned instead.. ",
    "vitarb": "Can you please add some comments on how it works and what assumptions we make.. s/HashMap/Map in the declaration. else fail the build? Are there any valid cases when go library may have no package name?. Should we remove some line breaks from these chaining calls? (same relates to some other statements below). This will not handle sub-packages well.\nFor example if we have:\ngithub.com/foo/bar\ngithub.com/foo/bar/A\nand process the later first then contents of A will be removed while processing root package of the repo.\nLet's make sure we cleanup only contents of the current package.\n. Do you see any difficulties with changing this in future?. It's not really repository-specific. Vendor folder is a golang concept: https://golang.org/cmd/go/#hdr-Vendor_Directories. Note that in contrast to java Go currently doesn't have ability to link sources/jars from random locations. There is a WIP workspaces feature on Google's side that should enable better integration of go toolchain with build tools like buck or bazel but it's not released yet and final ETA is not clear.\nCurrently we are in the situation when all generated or downloaded code would not be discoverable in the IDE. Putting it in vendor allows us to easily browse code and be able to run third-party tools not integrated with buck that are expecting valid GOPATH folder with all dependencies in place. Although can probably be more generic, with this change we are going from the state where buck project is barely useful for go to the state where it sets up a project with valid dependencies.. "
}